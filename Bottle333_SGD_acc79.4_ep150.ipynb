{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYXxzqGtjO4o",
        "outputId": "e82e4d55-cc71-4e6a-b3e4-7bbb532b5870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "# from models import *\n",
        "# from utils import progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzYmUhpMhnGU"
      },
      "outputs": [],
      "source": [
        "# !cp drive/MyDrive/utils.py .\n",
        "# !cp drive/MyDrive/ResNet.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5HlTaCxhxMy"
      },
      "outputs": [],
      "source": [
        "# import ResNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s0H94RJKjX0D"
      },
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "# parser.add_argument('--resume', '-r', action='store_true',\n",
        "#                     help='resume from checkpoint')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P98wVKH1jkFQ",
        "outputId": "07ba54b6-55a1-43e7-af54-6ec221e70289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.3),\n",
        "    #transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
        "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
        "    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "43dac162838e4ebe84fce40c9deea8aa",
            "75509578bcf04a51a6476978e5f22955",
            "7163b26ae7a14712a6e38c0d68ed9d2d",
            "33965e45b4474dbcb52bd5527f08551d",
            "8250cd946cfe47c5910b8e4f226ce293",
            "2fd847978efa4e67a391dbbc528c82b3",
            "7c410baeefef49bea460908d72038bce",
            "2ecf629d11b141448933a360a5b066cd",
            "6fa97d222cb14aec8429e79390a9f054",
            "a351465dacda4ff5bf9a7e242172f6a1",
            "11fe4deb10a146178770da0c8887c7f9"
          ]
        },
        "id": "ET3HGuTnjX5-",
        "outputId": "d66068a9-e09f-4aeb-e506-1a148ab00b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43dac162838e4ebe84fce40c9deea8aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2) #128\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2) #100\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BCLozv6sxiG",
        "outputId": "19af36dd-a3ec-41a8-f811-663f1be8116b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391\n"
          ]
        }
      ],
      "source": [
        "print(len(trainloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6PkueVcjshd",
        "outputId": "91534b9a-f91c-4224-bdb7-19e91e22af05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vZScwCXMjskX"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2zFlIhMQjsox"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(1024*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        #out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkevL8y4kKVI",
        "outputId": "c9772fd4-7de9-402d-b989-ca122ca98a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "ResNet                                   [128, 10]                 --\n",
            "├─Conv2d: 1-1                            [128, 64, 32, 32]         1,728\n",
            "├─BatchNorm2d: 1-2                       [128, 64, 32, 32]         128\n",
            "├─Sequential: 1-3                        [128, 256, 32, 32]        --\n",
            "│    └─Bottleneck: 2-1                   [128, 256, 32, 32]        --\n",
            "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         4,096\n",
            "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-3                  [128, 64, 32, 32]         36,864\n",
            "│    │    └─BatchNorm2d: 3-4             [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-5                  [128, 256, 32, 32]        16,384\n",
            "│    │    └─BatchNorm2d: 3-6             [128, 256, 32, 32]        512\n",
            "│    │    └─Sequential: 3-7              [128, 256, 32, 32]        16,896\n",
            "│    └─Bottleneck: 2-2                   [128, 256, 32, 32]        --\n",
            "│    │    └─Conv2d: 3-8                  [128, 64, 32, 32]         16,384\n",
            "│    │    └─BatchNorm2d: 3-9             [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-10                 [128, 64, 32, 32]         36,864\n",
            "│    │    └─BatchNorm2d: 3-11            [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-12                 [128, 256, 32, 32]        16,384\n",
            "│    │    └─BatchNorm2d: 3-13            [128, 256, 32, 32]        512\n",
            "│    │    └─Sequential: 3-14             [128, 256, 32, 32]        --\n",
            "│    └─Bottleneck: 2-3                   [128, 256, 32, 32]        --\n",
            "│    │    └─Conv2d: 3-15                 [128, 64, 32, 32]         16,384\n",
            "│    │    └─BatchNorm2d: 3-16            [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-17                 [128, 64, 32, 32]         36,864\n",
            "│    │    └─BatchNorm2d: 3-18            [128, 64, 32, 32]         128\n",
            "│    │    └─Conv2d: 3-19                 [128, 256, 32, 32]        16,384\n",
            "│    │    └─BatchNorm2d: 3-20            [128, 256, 32, 32]        512\n",
            "│    │    └─Sequential: 3-21             [128, 256, 32, 32]        --\n",
            "├─Sequential: 1-4                        [128, 512, 16, 16]        --\n",
            "│    └─Bottleneck: 2-4                   [128, 512, 16, 16]        --\n",
            "│    │    └─Conv2d: 3-22                 [128, 128, 32, 32]        32,768\n",
            "│    │    └─BatchNorm2d: 3-23            [128, 128, 32, 32]        256\n",
            "│    │    └─Conv2d: 3-24                 [128, 128, 16, 16]        147,456\n",
            "│    │    └─BatchNorm2d: 3-25            [128, 128, 16, 16]        256\n",
            "│    │    └─Conv2d: 3-26                 [128, 512, 16, 16]        65,536\n",
            "│    │    └─BatchNorm2d: 3-27            [128, 512, 16, 16]        1,024\n",
            "│    │    └─Sequential: 3-28             [128, 512, 16, 16]        132,096\n",
            "│    └─Bottleneck: 2-5                   [128, 512, 16, 16]        --\n",
            "│    │    └─Conv2d: 3-29                 [128, 128, 16, 16]        65,536\n",
            "│    │    └─BatchNorm2d: 3-30            [128, 128, 16, 16]        256\n",
            "│    │    └─Conv2d: 3-31                 [128, 128, 16, 16]        147,456\n",
            "│    │    └─BatchNorm2d: 3-32            [128, 128, 16, 16]        256\n",
            "│    │    └─Conv2d: 3-33                 [128, 512, 16, 16]        65,536\n",
            "│    │    └─BatchNorm2d: 3-34            [128, 512, 16, 16]        1,024\n",
            "│    │    └─Sequential: 3-35             [128, 512, 16, 16]        --\n",
            "│    └─Bottleneck: 2-6                   [128, 512, 16, 16]        --\n",
            "│    │    └─Conv2d: 3-36                 [128, 128, 16, 16]        65,536\n",
            "│    │    └─BatchNorm2d: 3-37            [128, 128, 16, 16]        256\n",
            "│    │    └─Conv2d: 3-38                 [128, 128, 16, 16]        147,456\n",
            "│    │    └─BatchNorm2d: 3-39            [128, 128, 16, 16]        256\n",
            "│    │    └─Conv2d: 3-40                 [128, 512, 16, 16]        65,536\n",
            "│    │    └─BatchNorm2d: 3-41            [128, 512, 16, 16]        1,024\n",
            "│    │    └─Sequential: 3-42             [128, 512, 16, 16]        --\n",
            "├─Sequential: 1-5                        [128, 1024, 8, 8]         --\n",
            "│    └─Bottleneck: 2-7                   [128, 1024, 8, 8]         --\n",
            "│    │    └─Conv2d: 3-43                 [128, 256, 16, 16]        131,072\n",
            "│    │    └─BatchNorm2d: 3-44            [128, 256, 16, 16]        512\n",
            "│    │    └─Conv2d: 3-45                 [128, 256, 8, 8]          589,824\n",
            "│    │    └─BatchNorm2d: 3-46            [128, 256, 8, 8]          512\n",
            "│    │    └─Conv2d: 3-47                 [128, 1024, 8, 8]         262,144\n",
            "│    │    └─BatchNorm2d: 3-48            [128, 1024, 8, 8]         2,048\n",
            "│    │    └─Sequential: 3-49             [128, 1024, 8, 8]         526,336\n",
            "│    └─Bottleneck: 2-8                   [128, 1024, 8, 8]         --\n",
            "│    │    └─Conv2d: 3-50                 [128, 256, 8, 8]          262,144\n",
            "│    │    └─BatchNorm2d: 3-51            [128, 256, 8, 8]          512\n",
            "│    │    └─Conv2d: 3-52                 [128, 256, 8, 8]          589,824\n",
            "│    │    └─BatchNorm2d: 3-53            [128, 256, 8, 8]          512\n",
            "│    │    └─Conv2d: 3-54                 [128, 1024, 8, 8]         262,144\n",
            "│    │    └─BatchNorm2d: 3-55            [128, 1024, 8, 8]         2,048\n",
            "│    │    └─Sequential: 3-56             [128, 1024, 8, 8]         --\n",
            "│    └─Bottleneck: 2-9                   [128, 1024, 8, 8]         --\n",
            "│    │    └─Conv2d: 3-57                 [128, 256, 8, 8]          262,144\n",
            "│    │    └─BatchNorm2d: 3-58            [128, 256, 8, 8]          512\n",
            "│    │    └─Conv2d: 3-59                 [128, 256, 8, 8]          589,824\n",
            "│    │    └─BatchNorm2d: 3-60            [128, 256, 8, 8]          512\n",
            "│    │    └─Conv2d: 3-61                 [128, 1024, 8, 8]         262,144\n",
            "│    │    └─BatchNorm2d: 3-62            [128, 1024, 8, 8]         2,048\n",
            "│    │    └─Sequential: 3-63             [128, 1024, 8, 8]         --\n",
            "├─Linear: 1-6                            [128, 10]                 40,970\n",
            "==========================================================================================\n",
            "Total params: 4,944,970\n",
            "Trainable params: 4,944,970\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 95.80\n",
            "==========================================================================================\n",
            "Input size (MB): 1.57\n",
            "Forward/backward pass size (MB): 5603.60\n",
            "Params size (MB): 19.78\n",
            "Estimated Total Size (MB): 5624.95\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "net = ResNet(Bottleneck, [3, 3, 3, 3])\n",
        "\n",
        "print(summary(net,input_size=(128,3,32,32)))#input_size = (batch_size, #channel,imgsize)\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wGV6CjKekg_y"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "#                       momentum=0.9, weight_decay=6e-4)\n",
        "optimizer = optim.SGD(net.parameters(),lr = 1e-3, weight_decay=6e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "64Oo01YMkhBJ"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print('Train Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                % (epoch, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "        #              % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bFiXz9dZkhCt"
      },
      "outputs": [],
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            print('Test Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                  % (epoch, test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "            #              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "    return acc, 100.*correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzse6BCAlB10",
        "outputId": "4991ece1-0129-4f6e-9a31-132e7b049890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Test Epoch: 89 | Loss: 0.729 | Acc: 76.611% (2758/3600)\n",
            "Test Epoch: 89 | Loss: 0.733 | Acc: 76.622% (2835/3700)\n",
            "Test Epoch: 89 | Loss: 0.735 | Acc: 76.605% (2911/3800)\n",
            "Test Epoch: 89 | Loss: 0.733 | Acc: 76.692% (2991/3900)\n",
            "Test Epoch: 89 | Loss: 0.734 | Acc: 76.675% (3067/4000)\n",
            "Test Epoch: 89 | Loss: 0.736 | Acc: 76.634% (3142/4100)\n",
            "Test Epoch: 89 | Loss: 0.736 | Acc: 76.714% (3222/4200)\n",
            "Test Epoch: 89 | Loss: 0.730 | Acc: 76.953% (3309/4300)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 77.068% (3391/4400)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.978% (3464/4500)\n",
            "Test Epoch: 89 | Loss: 0.729 | Acc: 76.891% (3537/4600)\n",
            "Test Epoch: 89 | Loss: 0.729 | Acc: 76.894% (3614/4700)\n",
            "Test Epoch: 89 | Loss: 0.731 | Acc: 76.896% (3691/4800)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.939% (3770/4900)\n",
            "Test Epoch: 89 | Loss: 0.730 | Acc: 76.860% (3843/5000)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 77.039% (3929/5100)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 77.058% (4007/5200)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.094% (4086/5300)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 77.167% (4167/5400)\n",
            "Test Epoch: 89 | Loss: 0.722 | Acc: 77.182% (4245/5500)\n",
            "Test Epoch: 89 | Loss: 0.722 | Acc: 77.196% (4323/5600)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 77.175% (4399/5700)\n",
            "Test Epoch: 89 | Loss: 0.722 | Acc: 77.276% (4482/5800)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.153% (4552/5900)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 77.100% (4626/6000)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 77.197% (4709/6100)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.145% (4783/6200)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 77.143% (4860/6300)\n",
            "Test Epoch: 89 | Loss: 0.722 | Acc: 77.234% (4943/6400)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.215% (5019/6500)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.152% (5092/6600)\n",
            "Test Epoch: 89 | Loss: 0.722 | Acc: 77.254% (5176/6700)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.162% (5247/6800)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 77.145% (5323/6900)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 77.086% (5396/7000)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 77.056% (5471/7100)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.097% (5551/7200)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 77.137% (5631/7300)\n",
            "Test Epoch: 89 | Loss: 0.721 | Acc: 77.176% (5711/7400)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 77.080% (5781/7500)\n",
            "Test Epoch: 89 | Loss: 0.721 | Acc: 77.184% (5866/7600)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 77.117% (5938/7700)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 77.000% (6006/7800)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.924% (6077/7900)\n",
            "Test Epoch: 89 | Loss: 0.728 | Acc: 76.938% (6155/8000)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 76.926% (6231/8100)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 76.902% (6306/8200)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 76.880% (6381/8300)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 76.857% (6456/8400)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 76.812% (6529/8500)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 76.884% (6612/8600)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.770% (6679/8700)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.739% (6753/8800)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.719% (6828/8900)\n",
            "Test Epoch: 89 | Loss: 0.727 | Acc: 76.733% (6906/9000)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 76.824% (6991/9100)\n",
            "Test Epoch: 89 | Loss: 0.723 | Acc: 76.913% (7076/9200)\n",
            "Test Epoch: 89 | Loss: 0.724 | Acc: 76.871% (7149/9300)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 76.830% (7222/9400)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 76.842% (7300/9500)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 76.844% (7377/9600)\n",
            "Test Epoch: 89 | Loss: 0.725 | Acc: 76.897% (7459/9700)\n",
            "Test Epoch: 89 | Loss: 0.726 | Acc: 76.837% (7530/9800)\n",
            "Test Epoch: 89 | Loss: 0.728 | Acc: 76.778% (7601/9900)\n",
            "Test Epoch: 89 | Loss: 0.729 | Acc: 76.770% (7677/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 90\n",
            "Train Epoch: 90 | Loss: 0.598 | Acc: 74.219% (95/128)\n",
            "Train Epoch: 90 | Loss: 0.570 | Acc: 79.297% (203/256)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 80.990% (311/384)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.445% (417/512)\n",
            "Train Epoch: 90 | Loss: 0.499 | Acc: 82.969% (531/640)\n",
            "Train Epoch: 90 | Loss: 0.509 | Acc: 82.943% (637/768)\n",
            "Train Epoch: 90 | Loss: 0.511 | Acc: 82.701% (741/896)\n",
            "Train Epoch: 90 | Loss: 0.501 | Acc: 83.008% (850/1024)\n",
            "Train Epoch: 90 | Loss: 0.513 | Acc: 82.118% (946/1152)\n",
            "Train Epoch: 90 | Loss: 0.503 | Acc: 82.578% (1057/1280)\n",
            "Train Epoch: 90 | Loss: 0.526 | Acc: 81.960% (1154/1408)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.576% (1253/1536)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.490% (1356/1664)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.306% (1457/1792)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.406% (1563/1920)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.250% (1664/2048)\n",
            "Train Epoch: 90 | Loss: 0.545 | Acc: 81.204% (1767/2176)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.207% (1871/2304)\n",
            "Train Epoch: 90 | Loss: 0.546 | Acc: 80.880% (1967/2432)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.250% (2080/2560)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.362% (2187/2688)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.143% (2285/2816)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.148% (2389/2944)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 80.990% (2488/3072)\n",
            "Train Epoch: 90 | Loss: 0.548 | Acc: 80.812% (2586/3200)\n",
            "Train Epoch: 90 | Loss: 0.552 | Acc: 80.589% (2682/3328)\n",
            "Train Epoch: 90 | Loss: 0.559 | Acc: 80.411% (2779/3456)\n",
            "Train Epoch: 90 | Loss: 0.557 | Acc: 80.525% (2886/3584)\n",
            "Train Epoch: 90 | Loss: 0.553 | Acc: 80.657% (2994/3712)\n",
            "Train Epoch: 90 | Loss: 0.554 | Acc: 80.677% (3098/3840)\n",
            "Train Epoch: 90 | Loss: 0.551 | Acc: 80.696% (3202/3968)\n",
            "Train Epoch: 90 | Loss: 0.551 | Acc: 80.762% (3308/4096)\n",
            "Train Epoch: 90 | Loss: 0.547 | Acc: 80.919% (3418/4224)\n",
            "Train Epoch: 90 | Loss: 0.549 | Acc: 80.836% (3518/4352)\n",
            "Train Epoch: 90 | Loss: 0.551 | Acc: 80.826% (3621/4480)\n",
            "Train Epoch: 90 | Loss: 0.550 | Acc: 80.773% (3722/4608)\n",
            "Train Epoch: 90 | Loss: 0.552 | Acc: 80.638% (3819/4736)\n",
            "Train Epoch: 90 | Loss: 0.550 | Acc: 80.757% (3928/4864)\n",
            "Train Epoch: 90 | Loss: 0.549 | Acc: 80.869% (4037/4992)\n",
            "Train Epoch: 90 | Loss: 0.549 | Acc: 80.898% (4142/5120)\n",
            "Train Epoch: 90 | Loss: 0.545 | Acc: 80.945% (4248/5248)\n",
            "Train Epoch: 90 | Loss: 0.545 | Acc: 80.990% (4354/5376)\n",
            "Train Epoch: 90 | Loss: 0.544 | Acc: 81.050% (4461/5504)\n",
            "Train Epoch: 90 | Loss: 0.544 | Acc: 81.072% (4566/5632)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.146% (4674/5760)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.080% (4774/5888)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.200% (4885/6016)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.120% (4984/6144)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.091% (5086/6272)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.156% (5194/6400)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.127% (5296/6528)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.160% (5402/6656)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.132% (5504/6784)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.105% (5606/6912)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.193% (5716/7040)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.222% (5822/7168)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.209% (5925/7296)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.237% (6031/7424)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.303% (6140/7552)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.276% (6242/7680)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.237% (6343/7808)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.250% (6448/7936)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.188% (6547/8064)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.152% (6648/8192)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.274% (6762/8320)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.214% (6861/8448)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.227% (6966/8576)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.239% (7071/8704)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.239% (7175/8832)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.362% (7290/8960)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.470% (7404/9088)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.467% (7508/9216)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.464% (7612/9344)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.472% (7717/9472)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.500% (7824/9600)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.548% (7933/9728)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.534% (8036/9856)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.490% (8136/9984)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.468% (8238/10112)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.484% (8344/10240)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.510% (8451/10368)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.517% (8556/10496)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.485% (8657/10624)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.492% (8762/10752)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.517% (8869/10880)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.486% (8970/11008)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.430% (9068/11136)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.419% (9171/11264)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.417% (9275/11392)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.406% (9378/11520)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.362% (9477/11648)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.369% (9582/11776)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.359% (9685/11904)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.425% (9797/12032)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.414% (9900/12160)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.462% (10010/12288)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.508% (10120/12416)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.489% (10222/12544)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.503% (10328/12672)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.477% (10429/12800)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.459% (10531/12928)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.464% (10636/13056)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.462% (10740/13184)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.438% (10841/13312)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.436% (10945/13440)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.375% (11041/13568)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.425% (11152/13696)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.402% (11253/13824)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.422% (11360/13952)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.442% (11467/14080)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.433% (11570/14208)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.403% (11670/14336)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.374% (11770/14464)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.387% (11876/14592)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.325% (11971/14720)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.297% (12071/14848)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.337% (12181/14976)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.310% (12281/15104)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.303% (12384/15232)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.341% (12494/15360)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.347% (12599/15488)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.301% (12696/15616)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.282% (12797/15744)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.294% (12903/15872)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.306% (13009/16000)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.275% (13108/16128)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.213% (13202/16256)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.171% (13299/16384)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.195% (13407/16512)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.208% (13513/16640)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.202% (13616/16768)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.161% (13713/16896)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.174% (13819/17024)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.180% (13924/17152)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.204% (14032/17280)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.221% (14139/17408)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.233% (14245/17536)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.210% (14345/17664)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.199% (14447/17792)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.233% (14557/17920)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.200% (14655/18048)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.167% (14753/18176)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.146% (14853/18304)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.174% (14962/18432)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.196% (15070/18560)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.191% (15173/18688)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.176% (15274/18816)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.176% (15378/18944)\n",
            "Train Epoch: 90 | Loss: 0.544 | Acc: 81.198% (15486/19072)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.208% (15592/19200)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.224% (15699/19328)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.214% (15801/19456)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.240% (15910/19584)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.199% (16006/19712)\n",
            "Train Epoch: 90 | Loss: 0.543 | Acc: 81.184% (16107/19840)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.180% (16210/19968)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.210% (16320/20096)\n",
            "Train Epoch: 90 | Loss: 0.542 | Acc: 81.210% (16424/20224)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.265% (16539/20352)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.274% (16645/20480)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.250% (16744/20608)\n",
            "Train Epoch: 90 | Loss: 0.541 | Acc: 81.260% (16850/20736)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.298% (16962/20864)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.264% (17059/20992)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.283% (17167/21120)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.311% (17277/21248)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.306% (17380/21376)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.310% (17485/21504)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.338% (17595/21632)\n",
            "Train Epoch: 90 | Loss: 0.540 | Acc: 81.310% (17693/21760)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.332% (17802/21888)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.314% (17902/22016)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.318% (18007/22144)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.322% (18112/22272)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.339% (18220/22400)\n",
            "Train Epoch: 90 | Loss: 0.539 | Acc: 81.339% (18324/22528)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.356% (18432/22656)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.355% (18536/22784)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.381% (18646/22912)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.372% (18748/23040)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.371% (18852/23168)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.383% (18959/23296)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.391% (19065/23424)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.407% (19173/23552)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.398% (19275/23680)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.355% (19369/23808)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.338% (19469/23936)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.341% (19574/24064)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.329% (19675/24192)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.324% (19778/24320)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.332% (19884/24448)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.340% (19990/24576)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.347% (20096/24704)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.359% (20203/24832)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.358% (20307/24960)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.330% (20404/25088)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.353% (20514/25216)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.345% (20616/25344)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.360% (20724/25472)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.348% (20825/25600)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.324% (20923/25728)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.331% (21029/25856)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.350% (21138/25984)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.334% (21238/26112)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.338% (21343/26240)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.314% (21441/26368)\n",
            "Train Epoch: 90 | Loss: 0.538 | Acc: 81.307% (21543/26496)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.321% (21651/26624)\n",
            "Train Epoch: 90 | Loss: 0.537 | Acc: 81.317% (21754/26752)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.373% (21873/26880)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.383% (21980/27008)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.420% (22094/27136)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.408% (22195/27264)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.392% (22295/27392)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.410% (22404/27520)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.420% (22511/27648)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.419% (22615/27776)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.454% (22729/27904)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.443% (22830/28032)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.428% (22930/28160)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.437% (23037/28288)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.458% (23147/28416)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.467% (23254/28544)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.477% (23361/28672)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.483% (23467/28800)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.482% (23571/28928)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.481% (23675/29056)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.486% (23781/29184)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.502% (23890/29312)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.481% (23988/29440)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.466% (24088/29568)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.492% (24200/29696)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.485% (24302/29824)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.460% (24399/29952)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.479% (24509/30080)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.455% (24606/30208)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.474% (24716/30336)\n",
            "Train Epoch: 90 | Loss: 0.536 | Acc: 81.444% (24811/30464)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.466% (24922/30592)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.475% (25029/30720)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.487% (25137/30848)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.495% (25244/30976)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.507% (25352/31104)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.503% (25455/31232)\n",
            "Train Epoch: 90 | Loss: 0.535 | Acc: 81.476% (25551/31360)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.498% (25662/31488)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.509% (25770/31616)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.524% (25879/31744)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.536% (25987/31872)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.528% (26089/32000)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.521% (26191/32128)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.517% (26294/32256)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.516% (26398/32384)\n",
            "Train Epoch: 90 | Loss: 0.534 | Acc: 81.508% (26500/32512)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.529% (26611/32640)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.540% (26719/32768)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.566% (26832/32896)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.580% (26941/33024)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.588% (27048/33152)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.590% (27153/33280)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.579% (27254/33408)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.575% (27357/33536)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.580% (27463/33664)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.558% (27560/33792)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.580% (27672/33920)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.597% (27782/34048)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.598% (27887/34176)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.597% (27991/34304)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.607% (28099/34432)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.603% (28202/34560)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.607% (28308/34688)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.609% (28413/34816)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.619% (28521/34944)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.621% (28626/35072)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.631% (28734/35200)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.635% (28840/35328)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.636% (28945/35456)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.610% (29040/35584)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.603% (29142/35712)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.616% (29251/35840)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.614% (29355/35968)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.610% (29458/36096)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.579% (29551/36224)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.575% (29654/36352)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.565% (29755/36480)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.572% (29862/36608)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.579% (29969/36736)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.603% (30082/36864)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.580% (30178/36992)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.565% (30277/37120)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.561% (30380/37248)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.550% (30480/37376)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.546% (30583/37504)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.550% (30689/37632)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.536% (30788/37760)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.527% (30889/37888)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.516% (30989/38016)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.517% (31094/38144)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.506% (31194/38272)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.518% (31303/38400)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.528% (31411/38528)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.540% (31520/38656)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.552% (31629/38784)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.538% (31728/38912)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.537% (31832/39040)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.554% (31943/39168)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.555% (32048/39296)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.567% (32157/39424)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.576% (32265/39552)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.588% (32374/39680)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.582% (32476/39808)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.588% (32583/39936)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.594% (32690/40064)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.593% (32794/40192)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.597% (32900/40320)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.596% (33004/40448)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.615% (33116/40576)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.614% (33220/40704)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.608% (33322/40832)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.614% (33429/40960)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.610% (33532/41088)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.597% (33631/41216)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.596% (33735/41344)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.612% (33846/41472)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.599% (33945/41600)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.605% (34052/41728)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.577% (34145/41856)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.569% (34246/41984)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.544% (34340/42112)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.539% (34442/42240)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.531% (34543/42368)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.563% (34661/42496)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.571% (34769/42624)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.575% (34875/42752)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.581% (34982/42880)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.580% (35086/43008)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.584% (35192/43136)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.597% (35302/43264)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.596% (35406/43392)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.583% (35505/43520)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.571% (35604/43648)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.563% (35705/43776)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.585% (35819/43904)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.584% (35923/44032)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.585% (36028/44160)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.584% (36132/44288)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.574% (36232/44416)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.573% (36336/44544)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.568% (36438/44672)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.551% (36535/44800)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.544% (36636/44928)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.547% (36742/45056)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.540% (36843/45184)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.532% (36944/45312)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.525% (37045/45440)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.516% (37145/45568)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.510% (37247/45696)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.523% (37357/45824)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.548% (37473/45952)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.543% (37575/46080)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.523% (37670/46208)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.528% (37777/46336)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.517% (37876/46464)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.493% (37969/46592)\n",
            "Train Epoch: 90 | Loss: 0.533 | Acc: 81.492% (38073/46720)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.502% (38182/46848)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.501% (38286/46976)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.509% (38394/47104)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.515% (38501/47232)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.520% (38608/47360)\n",
            "Train Epoch: 90 | Loss: 0.532 | Acc: 81.517% (38711/47488)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.531% (38822/47616)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.552% (38936/47744)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.555% (39042/47872)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.562% (39150/48000)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.570% (39258/48128)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.559% (39357/48256)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.566% (39465/48384)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.572% (39572/48512)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.569% (39675/48640)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.556% (39773/48768)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.561% (39880/48896)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.560% (39984/49024)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.557% (40087/49152)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.575% (40200/49280)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.586% (40310/49408)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.589% (40416/49536)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.598% (40525/49664)\n",
            "Train Epoch: 90 | Loss: 0.530 | Acc: 81.593% (40627/49792)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.579% (40724/49920)\n",
            "Train Epoch: 90 | Loss: 0.531 | Acc: 81.570% (40785/50000)\n",
            "Test Epoch: 90 | Loss: 0.628 | Acc: 79.000% (79/100)\n",
            "Test Epoch: 90 | Loss: 0.719 | Acc: 76.000% (152/200)\n",
            "Test Epoch: 90 | Loss: 0.718 | Acc: 76.333% (229/300)\n",
            "Test Epoch: 90 | Loss: 0.720 | Acc: 76.250% (305/400)\n",
            "Test Epoch: 90 | Loss: 0.691 | Acc: 76.800% (384/500)\n",
            "Test Epoch: 90 | Loss: 0.637 | Acc: 78.000% (468/600)\n",
            "Test Epoch: 90 | Loss: 0.636 | Acc: 77.857% (545/700)\n",
            "Test Epoch: 90 | Loss: 0.654 | Acc: 77.375% (619/800)\n",
            "Test Epoch: 90 | Loss: 0.667 | Acc: 77.000% (693/900)\n",
            "Test Epoch: 90 | Loss: 0.653 | Acc: 77.400% (774/1000)\n",
            "Test Epoch: 90 | Loss: 0.647 | Acc: 77.727% (855/1100)\n",
            "Test Epoch: 90 | Loss: 0.656 | Acc: 77.333% (928/1200)\n",
            "Test Epoch: 90 | Loss: 0.659 | Acc: 77.154% (1003/1300)\n",
            "Test Epoch: 90 | Loss: 0.666 | Acc: 77.000% (1078/1400)\n",
            "Test Epoch: 90 | Loss: 0.660 | Acc: 77.333% (1160/1500)\n",
            "Test Epoch: 90 | Loss: 0.675 | Acc: 77.312% (1237/1600)\n",
            "Test Epoch: 90 | Loss: 0.668 | Acc: 77.471% (1317/1700)\n",
            "Test Epoch: 90 | Loss: 0.666 | Acc: 77.389% (1393/1800)\n",
            "Test Epoch: 90 | Loss: 0.662 | Acc: 77.684% (1476/1900)\n",
            "Test Epoch: 90 | Loss: 0.686 | Acc: 77.050% (1541/2000)\n",
            "Test Epoch: 90 | Loss: 0.694 | Acc: 77.000% (1617/2100)\n",
            "Test Epoch: 90 | Loss: 0.695 | Acc: 76.955% (1693/2200)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 76.913% (1769/2300)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.958% (1847/2400)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 76.880% (1922/2500)\n",
            "Test Epoch: 90 | Loss: 0.722 | Acc: 76.615% (1992/2600)\n",
            "Test Epoch: 90 | Loss: 0.711 | Acc: 76.852% (2075/2700)\n",
            "Test Epoch: 90 | Loss: 0.711 | Acc: 76.964% (2155/2800)\n",
            "Test Epoch: 90 | Loss: 0.711 | Acc: 76.931% (2231/2900)\n",
            "Test Epoch: 90 | Loss: 0.706 | Acc: 77.133% (2314/3000)\n",
            "Test Epoch: 90 | Loss: 0.706 | Acc: 77.129% (2391/3100)\n",
            "Test Epoch: 90 | Loss: 0.705 | Acc: 77.000% (2464/3200)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 76.939% (2539/3300)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 76.882% (2614/3400)\n",
            "Test Epoch: 90 | Loss: 0.709 | Acc: 76.714% (2685/3500)\n",
            "Test Epoch: 90 | Loss: 0.708 | Acc: 76.722% (2762/3600)\n",
            "Test Epoch: 90 | Loss: 0.713 | Acc: 76.730% (2839/3700)\n",
            "Test Epoch: 90 | Loss: 0.716 | Acc: 76.658% (2913/3800)\n",
            "Test Epoch: 90 | Loss: 0.713 | Acc: 76.872% (2998/3900)\n",
            "Test Epoch: 90 | Loss: 0.714 | Acc: 76.850% (3074/4000)\n",
            "Test Epoch: 90 | Loss: 0.716 | Acc: 76.902% (3153/4100)\n",
            "Test Epoch: 90 | Loss: 0.716 | Acc: 76.952% (3232/4200)\n",
            "Test Epoch: 90 | Loss: 0.711 | Acc: 77.093% (3315/4300)\n",
            "Test Epoch: 90 | Loss: 0.708 | Acc: 77.227% (3398/4400)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 77.222% (3475/4500)\n",
            "Test Epoch: 90 | Loss: 0.708 | Acc: 77.174% (3550/4600)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 77.170% (3627/4700)\n",
            "Test Epoch: 90 | Loss: 0.709 | Acc: 77.188% (3705/4800)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 77.184% (3782/4900)\n",
            "Test Epoch: 90 | Loss: 0.708 | Acc: 77.080% (3854/5000)\n",
            "Test Epoch: 90 | Loss: 0.705 | Acc: 77.137% (3934/5100)\n",
            "Test Epoch: 90 | Loss: 0.706 | Acc: 77.077% (4008/5200)\n",
            "Test Epoch: 90 | Loss: 0.704 | Acc: 77.057% (4084/5300)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 77.037% (4160/5400)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 77.036% (4237/5500)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 77.071% (4316/5600)\n",
            "Test Epoch: 90 | Loss: 0.707 | Acc: 77.053% (4392/5700)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 77.155% (4475/5800)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 77.000% (4543/5900)\n",
            "Test Epoch: 90 | Loss: 0.706 | Acc: 76.900% (4614/6000)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 77.066% (4701/6100)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 77.048% (4777/6200)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 77.016% (4852/6300)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 77.125% (4936/6400)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 77.092% (5011/6500)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 77.076% (5087/6600)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 77.119% (5167/6700)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 77.015% (5237/6800)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.986% (5312/6900)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 76.871% (5381/7000)\n",
            "Test Epoch: 90 | Loss: 0.704 | Acc: 76.873% (5458/7100)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 76.931% (5539/7200)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.986% (5620/7300)\n",
            "Test Epoch: 90 | Loss: 0.697 | Acc: 77.054% (5702/7400)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 77.013% (5776/7500)\n",
            "Test Epoch: 90 | Loss: 0.697 | Acc: 77.092% (5859/7600)\n",
            "Test Epoch: 90 | Loss: 0.698 | Acc: 77.078% (5935/7700)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.974% (6004/7800)\n",
            "Test Epoch: 90 | Loss: 0.702 | Acc: 76.911% (6076/7900)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 76.925% (6154/8000)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.926% (6231/8100)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.951% (6310/8200)\n",
            "Test Epoch: 90 | Loss: 0.698 | Acc: 76.952% (6387/8300)\n",
            "Test Epoch: 90 | Loss: 0.698 | Acc: 76.905% (6460/8400)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.859% (6533/8500)\n",
            "Test Epoch: 90 | Loss: 0.699 | Acc: 76.884% (6612/8600)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.828% (6684/8700)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.818% (6760/8800)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.809% (6836/8900)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.822% (6914/9000)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.912% (6999/9100)\n",
            "Test Epoch: 90 | Loss: 0.697 | Acc: 76.989% (7083/9200)\n",
            "Test Epoch: 90 | Loss: 0.698 | Acc: 76.935% (7155/9300)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.915% (7230/9400)\n",
            "Test Epoch: 90 | Loss: 0.699 | Acc: 76.926% (7308/9500)\n",
            "Test Epoch: 90 | Loss: 0.699 | Acc: 76.917% (7384/9600)\n",
            "Test Epoch: 90 | Loss: 0.699 | Acc: 76.979% (7467/9700)\n",
            "Test Epoch: 90 | Loss: 0.700 | Acc: 76.918% (7538/9800)\n",
            "Test Epoch: 90 | Loss: 0.701 | Acc: 76.899% (7613/9900)\n",
            "Test Epoch: 90 | Loss: 0.703 | Acc: 76.920% (7692/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 91\n",
            "Train Epoch: 91 | Loss: 0.458 | Acc: 85.938% (110/128)\n",
            "Train Epoch: 91 | Loss: 0.508 | Acc: 80.469% (206/256)\n",
            "Train Epoch: 91 | Loss: 0.488 | Acc: 81.771% (314/384)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.031% (420/512)\n",
            "Train Epoch: 91 | Loss: 0.499 | Acc: 82.812% (530/640)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.250% (624/768)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.696% (732/896)\n",
            "Train Epoch: 91 | Loss: 0.530 | Acc: 81.641% (836/1024)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.292% (948/1152)\n",
            "Train Epoch: 91 | Loss: 0.542 | Acc: 81.250% (1040/1280)\n",
            "Train Epoch: 91 | Loss: 0.530 | Acc: 81.676% (1150/1408)\n",
            "Train Epoch: 91 | Loss: 0.528 | Acc: 81.836% (1257/1536)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.851% (1362/1664)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.143% (1472/1792)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.083% (1576/1920)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 82.129% (1682/2048)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.353% (1792/2176)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.509% (1901/2304)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.484% (2006/2432)\n",
            "Train Epoch: 91 | Loss: 0.508 | Acc: 82.617% (2115/2560)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.254% (2211/2688)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 82.138% (2313/2816)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.929% (2412/2944)\n",
            "Train Epoch: 91 | Loss: 0.527 | Acc: 81.934% (2517/3072)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 82.094% (2627/3200)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 82.031% (2730/3328)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 82.292% (2844/3456)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 82.338% (2951/3584)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 82.408% (3059/3712)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 82.214% (3157/3840)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.208% (3262/3968)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.300% (3371/4096)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.292% (3476/4224)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.238% (3579/4352)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 82.277% (3686/4480)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.313% (3793/4608)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.411% (3903/4736)\n",
            "Train Epoch: 91 | Loss: 0.512 | Acc: 82.566% (4016/4864)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.552% (4121/4992)\n",
            "Train Epoch: 91 | Loss: 0.513 | Acc: 82.617% (4230/5120)\n",
            "Train Epoch: 91 | Loss: 0.512 | Acc: 82.641% (4337/5248)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.478% (4434/5376)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.467% (4539/5504)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.511% (4647/5632)\n",
            "Train Epoch: 91 | Loss: 0.513 | Acc: 82.535% (4754/5760)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.439% (4854/5888)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.414% (4958/6016)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.422% (5064/6144)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.494% (5174/6272)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.469% (5278/6400)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.414% (5380/6528)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 82.392% (5484/6656)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.370% (5588/6784)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 82.335% (5691/6912)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.443% (5804/7040)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.506% (5914/7168)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.470% (6017/7296)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.408% (6118/7424)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 82.323% (6217/7552)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.344% (6324/7680)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.339% (6429/7808)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.371% (6537/7936)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.416% (6646/8064)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.507% (6759/8192)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.404% (6856/8320)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.422% (6963/8448)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.404% (7067/8576)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.295% (7163/8704)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 82.201% (7260/8832)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 82.266% (7371/8960)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.273% (7477/9088)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.237% (7579/9216)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 82.245% (7685/9344)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.285% (7794/9472)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.260% (7897/9600)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.268% (8003/9728)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.224% (8104/9856)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.252% (8212/9984)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.239% (8316/10112)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.227% (8420/10240)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.215% (8524/10368)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.184% (8626/10496)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.191% (8732/10624)\n",
            "Train Epoch: 91 | Loss: 0.514 | Acc: 82.189% (8837/10752)\n",
            "Train Epoch: 91 | Loss: 0.513 | Acc: 82.188% (8942/10880)\n",
            "Train Epoch: 91 | Loss: 0.513 | Acc: 82.158% (9044/11008)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.094% (9142/11136)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.076% (9245/11264)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.066% (9349/11392)\n",
            "Train Epoch: 91 | Loss: 0.515 | Acc: 82.083% (9456/11520)\n",
            "Train Epoch: 91 | Loss: 0.516 | Acc: 82.040% (9556/11648)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.972% (9653/11776)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.897% (9749/11904)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.907% (9855/12032)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.933% (9963/12160)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.901% (10064/12288)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.894% (10168/12416)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.872% (10270/12544)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.802% (10366/12672)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.828% (10474/12800)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.853% (10582/12928)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.809% (10681/13056)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.796% (10784/13184)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.836% (10894/13312)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.815% (10996/13440)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.810% (11100/13568)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.841% (11209/13696)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.872% (11318/13824)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.874% (11423/13952)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.854% (11525/14080)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.883% (11634/14208)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.892% (11740/14336)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.928% (11850/14464)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.935% (11956/14592)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.902% (12056/14720)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.910% (12162/14848)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.891% (12264/14976)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.939% (12376/15104)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.900% (12475/15232)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.908% (12581/15360)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.921% (12688/15488)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.948% (12797/15616)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.936% (12900/15744)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.912% (13001/15872)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.906% (13105/16000)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.870% (13204/16128)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.859% (13307/16256)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.836% (13408/16384)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.844% (13514/16512)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.815% (13614/16640)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.823% (13720/16768)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.866% (13832/16896)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.896% (13942/17024)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.915% (14050/17152)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.921% (14156/17280)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.916% (14260/17408)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.911% (14364/17536)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.901% (14467/17664)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.885% (14569/17792)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.903% (14677/17920)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 81.909% (14783/18048)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.888% (14884/18176)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 81.900% (14991/18304)\n",
            "Train Epoch: 91 | Loss: 0.517 | Acc: 81.896% (15095/18432)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.886% (15198/18560)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.860% (15298/18688)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.872% (15405/18816)\n",
            "Train Epoch: 91 | Loss: 0.518 | Acc: 81.905% (15516/18944)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.879% (15616/19072)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.870% (15719/19200)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.866% (15823/19328)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.851% (15925/19456)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.842% (16028/19584)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.833% (16131/19712)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.850% (16239/19840)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.816% (16337/19968)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.837% (16446/20096)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.829% (16549/20224)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.849% (16658/20352)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.826% (16758/20480)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.837% (16865/20608)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.824% (16967/20736)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.849% (17077/20864)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.836% (17179/20992)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.818% (17280/21120)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.824% (17386/21248)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.821% (17490/21376)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.822% (17595/21504)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.772% (17689/21632)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.792% (17798/21760)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.817% (17908/21888)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.822% (18014/22016)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.824% (18119/22144)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.793% (18217/22272)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.768% (18316/22400)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.756% (18418/22528)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.731% (18517/22656)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.728% (18621/22784)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.765% (18734/22912)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.771% (18840/23040)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.772% (18945/23168)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.774% (19050/23296)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.767% (19153/23424)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.751% (19254/23552)\n",
            "Train Epoch: 91 | Loss: 0.519 | Acc: 81.757% (19360/23680)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.733% (19459/23808)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.756% (19569/23936)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.740% (19670/24064)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.717% (19769/24192)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.711% (19872/24320)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.720% (19979/24448)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.710% (20081/24576)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.711% (20186/24704)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.713% (20291/24832)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.691% (20390/24960)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.688% (20494/25088)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.718% (20606/25216)\n",
            "Train Epoch: 91 | Loss: 0.520 | Acc: 81.747% (20718/25344)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.737% (20820/25472)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.719% (20920/25600)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.720% (21025/25728)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.733% (21133/25856)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.743% (21240/25984)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.752% (21347/26112)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.730% (21446/26240)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.709% (21545/26368)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.722% (21653/26496)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.712% (21755/26624)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.702% (21857/26752)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.719% (21966/26880)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.713% (22069/27008)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.725% (22177/27136)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.694% (22273/27264)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.695% (22378/27392)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.701% (22484/27520)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.724% (22595/27648)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.736% (22703/27776)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.727% (22805/27904)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.710% (22905/28032)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.708% (23009/28160)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.699% (23111/28288)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.686% (23212/28416)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.698% (23320/28544)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.700% (23425/28672)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.688% (23526/28800)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.703% (23635/28928)\n",
            "Train Epoch: 91 | Loss: 0.521 | Acc: 81.715% (23743/29056)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.689% (23840/29184)\n",
            "Train Epoch: 91 | Loss: 0.522 | Acc: 81.694% (23946/29312)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.661% (24041/29440)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.663% (24146/29568)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.620% (24238/29696)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.585% (24332/29824)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.567% (24431/29952)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.553% (24531/30080)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.548% (24634/30208)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.550% (24739/30336)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.559% (24846/30464)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.561% (24951/30592)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.562% (25056/30720)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.564% (25161/30848)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.547% (25260/30976)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.549% (25365/31104)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.573% (25477/31232)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.582% (25584/31360)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.583% (25689/31488)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.598% (25798/31616)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.609% (25906/31744)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.595% (26006/31872)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.572% (26103/32000)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.561% (26204/32128)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.541% (26302/32256)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.556% (26411/32384)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.551% (26514/32512)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.566% (26623/32640)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.589% (26735/32768)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.569% (26833/32896)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.589% (26944/33024)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.600% (27052/33152)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.620% (27163/33280)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.615% (27266/33408)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.632% (27376/33536)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.598% (27469/33664)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.596% (27573/33792)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.619% (27685/33920)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.611% (27787/34048)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.601% (27888/34176)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.594% (27990/34304)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.599% (28096/34432)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.600% (28201/34560)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.610% (28309/34688)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.621% (28417/34816)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.631% (28525/34944)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.626% (28628/35072)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.634% (28735/35200)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.615% (28833/35328)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.608% (28935/35456)\n",
            "Train Epoch: 91 | Loss: 0.523 | Acc: 81.641% (29051/35584)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.639% (29155/35712)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.604% (29247/35840)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.592% (29347/35968)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.602% (29455/36096)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.601% (29559/36224)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.586% (29658/36352)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.595% (29766/36480)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.591% (29869/36608)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.588% (29972/36736)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.584% (30075/36864)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.591% (30182/36992)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.603% (30291/37120)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.615% (30400/37248)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.625% (30508/37376)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.639% (30618/37504)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.649% (30726/37632)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.645% (30829/37760)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.662% (30940/37888)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.650% (31040/38016)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.656% (31147/38144)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.684% (31262/38272)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.659% (31357/38400)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.678% (31469/38528)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.674% (31572/38656)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.670% (31675/38784)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.648% (31771/38912)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.655% (31878/39040)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.653% (31982/39168)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.650% (32085/39296)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.638% (32185/39424)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.639% (32290/39552)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.623% (32388/39680)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.627% (32494/39808)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.651% (32608/39936)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.637% (32707/40064)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.636% (32811/40192)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.622% (32910/40320)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.618% (33013/40448)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.625% (33120/40576)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.619% (33222/40704)\n",
            "Train Epoch: 91 | Loss: 0.524 | Acc: 81.612% (33324/40832)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.604% (33425/40960)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.608% (33531/41088)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.595% (33630/41216)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.603% (33738/41344)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.590% (33837/41472)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.596% (33944/41600)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.566% (34036/41728)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.580% (34146/41856)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.583% (34252/41984)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.587% (34358/42112)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.598% (34467/42240)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.604% (34574/42368)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.608% (34680/42496)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.616% (34788/42624)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.613% (34891/42752)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.616% (34997/42880)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.608% (35098/43008)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.614% (35205/43136)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.634% (35318/43264)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.628% (35420/43392)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.636% (35528/43520)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.658% (35642/43648)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.647% (35742/43776)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.628% (35838/43904)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.620% (35939/44032)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.619% (36043/44160)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.616% (36146/44288)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.621% (36253/44416)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.627% (36360/44544)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.608% (36456/44672)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.621% (36566/44800)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.617% (36669/44928)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.616% (36773/45056)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.613% (36876/45184)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.612% (36980/45312)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.609% (37083/45440)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.606% (37186/45568)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.609% (37292/45696)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.610% (37397/45824)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.613% (37503/45952)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.617% (37609/46080)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.618% (37714/46208)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.615% (37817/46336)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.605% (37917/46464)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.623% (38030/46592)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.631% (38138/46720)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.624% (38239/46848)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.627% (38345/46976)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.619% (38446/47104)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.623% (38552/47232)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.634% (38662/47360)\n",
            "Train Epoch: 91 | Loss: 0.525 | Acc: 81.648% (38773/47488)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.628% (38868/47616)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.644% (38980/47744)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.634% (39080/47872)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.635% (39185/48000)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.645% (39294/48128)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.631% (39392/48256)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.643% (39502/48384)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.646% (39608/48512)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.647% (39713/48640)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.654% (39821/48768)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.655% (39926/48896)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.648% (40027/49024)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.647% (40131/49152)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.648% (40236/49280)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.643% (40338/49408)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.642% (40442/49536)\n",
            "Train Epoch: 91 | Loss: 0.527 | Acc: 81.637% (40544/49664)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.640% (40650/49792)\n",
            "Train Epoch: 91 | Loss: 0.526 | Acc: 81.649% (40759/49920)\n",
            "Train Epoch: 91 | Loss: 0.527 | Acc: 81.638% (40819/50000)\n",
            "Test Epoch: 91 | Loss: 0.584 | Acc: 80.000% (80/100)\n",
            "Test Epoch: 91 | Loss: 0.703 | Acc: 77.500% (155/200)\n",
            "Test Epoch: 91 | Loss: 0.695 | Acc: 76.667% (230/300)\n",
            "Test Epoch: 91 | Loss: 0.721 | Acc: 76.000% (304/400)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.400% (382/500)\n",
            "Test Epoch: 91 | Loss: 0.652 | Acc: 77.833% (467/600)\n",
            "Test Epoch: 91 | Loss: 0.648 | Acc: 77.571% (543/700)\n",
            "Test Epoch: 91 | Loss: 0.668 | Acc: 77.125% (617/800)\n",
            "Test Epoch: 91 | Loss: 0.674 | Acc: 76.889% (692/900)\n",
            "Test Epoch: 91 | Loss: 0.661 | Acc: 76.900% (769/1000)\n",
            "Test Epoch: 91 | Loss: 0.652 | Acc: 77.273% (850/1100)\n",
            "Test Epoch: 91 | Loss: 0.653 | Acc: 77.333% (928/1200)\n",
            "Test Epoch: 91 | Loss: 0.657 | Acc: 77.077% (1002/1300)\n",
            "Test Epoch: 91 | Loss: 0.663 | Acc: 77.214% (1081/1400)\n",
            "Test Epoch: 91 | Loss: 0.657 | Acc: 77.600% (1164/1500)\n",
            "Test Epoch: 91 | Loss: 0.672 | Acc: 77.438% (1239/1600)\n",
            "Test Epoch: 91 | Loss: 0.668 | Acc: 77.412% (1316/1700)\n",
            "Test Epoch: 91 | Loss: 0.667 | Acc: 77.556% (1396/1800)\n",
            "Test Epoch: 91 | Loss: 0.668 | Acc: 77.632% (1475/1900)\n",
            "Test Epoch: 91 | Loss: 0.690 | Acc: 76.950% (1539/2000)\n",
            "Test Epoch: 91 | Loss: 0.699 | Acc: 76.905% (1615/2100)\n",
            "Test Epoch: 91 | Loss: 0.702 | Acc: 76.864% (1691/2200)\n",
            "Test Epoch: 91 | Loss: 0.710 | Acc: 76.783% (1766/2300)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 76.833% (1844/2400)\n",
            "Test Epoch: 91 | Loss: 0.717 | Acc: 76.480% (1912/2500)\n",
            "Test Epoch: 91 | Loss: 0.733 | Acc: 76.231% (1982/2600)\n",
            "Test Epoch: 91 | Loss: 0.722 | Acc: 76.519% (2066/2700)\n",
            "Test Epoch: 91 | Loss: 0.723 | Acc: 76.571% (2144/2800)\n",
            "Test Epoch: 91 | Loss: 0.725 | Acc: 76.517% (2219/2900)\n",
            "Test Epoch: 91 | Loss: 0.720 | Acc: 76.667% (2300/3000)\n",
            "Test Epoch: 91 | Loss: 0.720 | Acc: 76.613% (2375/3100)\n",
            "Test Epoch: 91 | Loss: 0.718 | Acc: 76.625% (2452/3200)\n",
            "Test Epoch: 91 | Loss: 0.714 | Acc: 76.727% (2532/3300)\n",
            "Test Epoch: 91 | Loss: 0.719 | Acc: 76.735% (2609/3400)\n",
            "Test Epoch: 91 | Loss: 0.719 | Acc: 76.657% (2683/3500)\n",
            "Test Epoch: 91 | Loss: 0.718 | Acc: 76.722% (2762/3600)\n",
            "Test Epoch: 91 | Loss: 0.722 | Acc: 76.730% (2839/3700)\n",
            "Test Epoch: 91 | Loss: 0.723 | Acc: 76.737% (2916/3800)\n",
            "Test Epoch: 91 | Loss: 0.720 | Acc: 76.949% (3001/3900)\n",
            "Test Epoch: 91 | Loss: 0.720 | Acc: 76.900% (3076/4000)\n",
            "Test Epoch: 91 | Loss: 0.722 | Acc: 76.854% (3151/4100)\n",
            "Test Epoch: 91 | Loss: 0.721 | Acc: 76.929% (3231/4200)\n",
            "Test Epoch: 91 | Loss: 0.717 | Acc: 77.023% (3312/4300)\n",
            "Test Epoch: 91 | Loss: 0.714 | Acc: 77.114% (3393/4400)\n",
            "Test Epoch: 91 | Loss: 0.714 | Acc: 77.022% (3466/4500)\n",
            "Test Epoch: 91 | Loss: 0.715 | Acc: 76.913% (3538/4600)\n",
            "Test Epoch: 91 | Loss: 0.715 | Acc: 76.872% (3613/4700)\n",
            "Test Epoch: 91 | Loss: 0.716 | Acc: 76.917% (3692/4800)\n",
            "Test Epoch: 91 | Loss: 0.713 | Acc: 76.837% (3765/4900)\n",
            "Test Epoch: 91 | Loss: 0.715 | Acc: 76.740% (3837/5000)\n",
            "Test Epoch: 91 | Loss: 0.711 | Acc: 76.804% (3917/5100)\n",
            "Test Epoch: 91 | Loss: 0.711 | Acc: 76.788% (3993/5200)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.868% (4074/5300)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 76.852% (4150/5400)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.836% (4226/5500)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 76.821% (4302/5600)\n",
            "Test Epoch: 91 | Loss: 0.712 | Acc: 76.825% (4379/5700)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.948% (4463/5800)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.864% (4535/5900)\n",
            "Test Epoch: 91 | Loss: 0.712 | Acc: 76.833% (4610/6000)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 77.000% (4697/6100)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 76.935% (4770/6200)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.921% (4846/6300)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 77.062% (4932/6400)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 77.046% (5008/6500)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 77.000% (5082/6600)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 77.090% (5165/6700)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 77.044% (5239/6800)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 77.058% (5317/6900)\n",
            "Test Epoch: 91 | Loss: 0.710 | Acc: 76.971% (5388/7000)\n",
            "Test Epoch: 91 | Loss: 0.710 | Acc: 76.944% (5463/7100)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 77.014% (5545/7200)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 77.055% (5625/7300)\n",
            "Test Epoch: 91 | Loss: 0.704 | Acc: 77.149% (5709/7400)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 77.053% (5779/7500)\n",
            "Test Epoch: 91 | Loss: 0.703 | Acc: 77.132% (5862/7600)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 77.078% (5935/7700)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.987% (6005/7800)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.975% (6081/7900)\n",
            "Test Epoch: 91 | Loss: 0.709 | Acc: 76.975% (6158/8000)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.988% (6236/8100)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 77.037% (6317/8200)\n",
            "Test Epoch: 91 | Loss: 0.704 | Acc: 77.036% (6394/8300)\n",
            "Test Epoch: 91 | Loss: 0.704 | Acc: 77.012% (6469/8400)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 76.953% (6541/8500)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.977% (6620/8600)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.943% (6694/8700)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.898% (6767/8800)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.876% (6842/8900)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.889% (6920/9000)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.967% (7004/9100)\n",
            "Test Epoch: 91 | Loss: 0.703 | Acc: 77.065% (7090/9200)\n",
            "Test Epoch: 91 | Loss: 0.704 | Acc: 77.032% (7164/9300)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 76.957% (7234/9400)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.958% (7311/9500)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.958% (7388/9600)\n",
            "Test Epoch: 91 | Loss: 0.705 | Acc: 76.990% (7468/9700)\n",
            "Test Epoch: 91 | Loss: 0.706 | Acc: 76.929% (7539/9800)\n",
            "Test Epoch: 91 | Loss: 0.707 | Acc: 76.889% (7612/9900)\n",
            "Test Epoch: 91 | Loss: 0.708 | Acc: 76.910% (7691/10000)\n",
            "\n",
            "Epoch: 92\n",
            "Train Epoch: 92 | Loss: 0.715 | Acc: 71.875% (92/128)\n",
            "Train Epoch: 92 | Loss: 0.640 | Acc: 75.781% (194/256)\n",
            "Train Epoch: 92 | Loss: 0.622 | Acc: 77.604% (298/384)\n",
            "Train Epoch: 92 | Loss: 0.606 | Acc: 78.125% (400/512)\n",
            "Train Epoch: 92 | Loss: 0.584 | Acc: 79.531% (509/640)\n",
            "Train Epoch: 92 | Loss: 0.573 | Acc: 79.818% (613/768)\n",
            "Train Epoch: 92 | Loss: 0.568 | Acc: 80.469% (721/896)\n",
            "Train Epoch: 92 | Loss: 0.554 | Acc: 80.859% (828/1024)\n",
            "Train Epoch: 92 | Loss: 0.550 | Acc: 81.771% (942/1152)\n",
            "Train Epoch: 92 | Loss: 0.548 | Acc: 81.875% (1048/1280)\n",
            "Train Epoch: 92 | Loss: 0.539 | Acc: 81.960% (1154/1408)\n",
            "Train Epoch: 92 | Loss: 0.537 | Acc: 82.031% (1260/1536)\n",
            "Train Epoch: 92 | Loss: 0.534 | Acc: 82.332% (1370/1664)\n",
            "Train Epoch: 92 | Loss: 0.533 | Acc: 82.366% (1476/1792)\n",
            "Train Epoch: 92 | Loss: 0.535 | Acc: 82.240% (1579/1920)\n",
            "Train Epoch: 92 | Loss: 0.540 | Acc: 82.080% (1681/2048)\n",
            "Train Epoch: 92 | Loss: 0.544 | Acc: 81.893% (1782/2176)\n",
            "Train Epoch: 92 | Loss: 0.542 | Acc: 81.944% (1888/2304)\n",
            "Train Epoch: 92 | Loss: 0.547 | Acc: 81.826% (1990/2432)\n",
            "Train Epoch: 92 | Loss: 0.546 | Acc: 81.836% (2095/2560)\n",
            "Train Epoch: 92 | Loss: 0.540 | Acc: 82.031% (2205/2688)\n",
            "Train Epoch: 92 | Loss: 0.542 | Acc: 81.889% (2306/2816)\n",
            "Train Epoch: 92 | Loss: 0.543 | Acc: 81.963% (2413/2944)\n",
            "Train Epoch: 92 | Loss: 0.543 | Acc: 81.673% (2509/3072)\n",
            "Train Epoch: 92 | Loss: 0.540 | Acc: 81.781% (2617/3200)\n",
            "Train Epoch: 92 | Loss: 0.539 | Acc: 81.821% (2723/3328)\n",
            "Train Epoch: 92 | Loss: 0.539 | Acc: 81.713% (2824/3456)\n",
            "Train Epoch: 92 | Loss: 0.536 | Acc: 81.808% (2932/3584)\n",
            "Train Epoch: 92 | Loss: 0.535 | Acc: 81.870% (3039/3712)\n",
            "Train Epoch: 92 | Loss: 0.532 | Acc: 82.031% (3150/3840)\n",
            "Train Epoch: 92 | Loss: 0.531 | Acc: 82.082% (3257/3968)\n",
            "Train Epoch: 92 | Loss: 0.527 | Acc: 82.178% (3366/4096)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 82.055% (3466/4224)\n",
            "Train Epoch: 92 | Loss: 0.527 | Acc: 82.077% (3572/4352)\n",
            "Train Epoch: 92 | Loss: 0.531 | Acc: 81.808% (3665/4480)\n",
            "Train Epoch: 92 | Loss: 0.530 | Acc: 81.836% (3771/4608)\n",
            "Train Epoch: 92 | Loss: 0.529 | Acc: 81.799% (3874/4736)\n",
            "Train Epoch: 92 | Loss: 0.530 | Acc: 81.805% (3979/4864)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 81.991% (4093/4992)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.051% (4201/5120)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.107% (4309/5248)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.236% (4421/5376)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.286% (4529/5504)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.333% (4637/5632)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.222% (4736/5760)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.218% (4841/5888)\n",
            "Train Epoch: 92 | Loss: 0.523 | Acc: 82.214% (4946/6016)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.292% (5056/6144)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.207% (5156/6272)\n",
            "Train Epoch: 92 | Loss: 0.523 | Acc: 82.156% (5258/6400)\n",
            "Train Epoch: 92 | Loss: 0.525 | Acc: 82.047% (5356/6528)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.031% (5460/6656)\n",
            "Train Epoch: 92 | Loss: 0.527 | Acc: 82.002% (5563/6784)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 81.887% (5660/6912)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 81.918% (5767/7040)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 81.906% (5871/7168)\n",
            "Train Epoch: 92 | Loss: 0.528 | Acc: 81.935% (5978/7296)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.018% (6089/7424)\n",
            "Train Epoch: 92 | Loss: 0.525 | Acc: 82.071% (6198/7552)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.031% (6300/7680)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.031% (6405/7808)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.056% (6512/7936)\n",
            "Train Epoch: 92 | Loss: 0.525 | Acc: 82.118% (6622/8064)\n",
            "Train Epoch: 92 | Loss: 0.525 | Acc: 82.092% (6725/8192)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.139% (6834/8320)\n",
            "Train Epoch: 92 | Loss: 0.523 | Acc: 82.185% (6943/8448)\n",
            "Train Epoch: 92 | Loss: 0.523 | Acc: 82.253% (7054/8576)\n",
            "Train Epoch: 92 | Loss: 0.523 | Acc: 82.250% (7159/8704)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.269% (7266/8832)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.266% (7371/8960)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.196% (7470/9088)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.140% (7570/9216)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.128% (7674/9344)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.095% (7776/9472)\n",
            "Train Epoch: 92 | Loss: 0.525 | Acc: 82.083% (7880/9600)\n",
            "Train Epoch: 92 | Loss: 0.526 | Acc: 82.093% (7986/9728)\n",
            "Train Epoch: 92 | Loss: 0.524 | Acc: 82.133% (8095/9856)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.181% (8205/9984)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.219% (8314/10112)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.236% (8421/10240)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.234% (8526/10368)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.203% (8628/10496)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.257% (8739/10624)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.310% (8850/10752)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.325% (8957/10880)\n",
            "Train Epoch: 92 | Loss: 0.515 | Acc: 82.367% (9067/11008)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.328% (9168/11136)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.360% (9277/11264)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.356% (9382/11392)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.335% (9485/11520)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.383% (9596/11648)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.320% (9694/11776)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.308% (9798/11904)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.347% (9908/12032)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.319% (10010/12160)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.340% (10118/12288)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.313% (10220/12416)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.302% (10324/12544)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.323% (10432/12672)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.273% (10531/12800)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.317% (10642/12928)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.315% (10747/13056)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.357% (10858/13184)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.332% (10960/13312)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.299% (11061/13440)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.326% (11170/13568)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.367% (11281/13696)\n",
            "Train Epoch: 92 | Loss: 0.516 | Acc: 82.407% (11392/13824)\n",
            "Train Epoch: 92 | Loss: 0.517 | Acc: 82.404% (11497/13952)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.330% (11592/14080)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.383% (11705/14208)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.345% (11805/14336)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.349% (11911/14464)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.319% (12012/14592)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.262% (12109/14720)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.240% (12211/14848)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.252% (12318/14976)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.243% (12422/15104)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.215% (12523/15232)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.233% (12631/15360)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.206% (12732/15488)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.204% (12837/15616)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.171% (12937/15744)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.157% (13040/15872)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.175% (13148/16000)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.192% (13256/16128)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.210% (13364/16256)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.257% (13477/16384)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.280% (13586/16512)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.272% (13690/16640)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.252% (13792/16768)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.256% (13898/16896)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.260% (14004/17024)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.294% (14115/17152)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.251% (14213/17280)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.232% (14315/17408)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.248% (14423/17536)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.229% (14525/17664)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.245% (14633/17792)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.260% (14741/17920)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.253% (14845/18048)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.251% (14950/18176)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.261% (15057/18304)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.243% (15159/18432)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.220% (15260/18560)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.267% (15374/18688)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.292% (15484/18816)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.290% (15589/18944)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.241% (15685/19072)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.214% (15785/19200)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.223% (15892/19328)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.232% (15999/19456)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.210% (16100/19584)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.244% (16212/19712)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.193% (16307/19840)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.192% (16412/19968)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.205% (16520/20096)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.199% (16624/20224)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.203% (16730/20352)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.217% (16838/20480)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.211% (16942/20608)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.219% (17049/20736)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.175% (17145/20864)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.169% (17249/20992)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.126% (17345/21120)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.135% (17452/21248)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.148% (17560/21376)\n",
            "Train Epoch: 92 | Loss: 0.518 | Acc: 82.161% (17668/21504)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.138% (17768/21632)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.142% (17874/21760)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.141% (17979/21888)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.154% (18087/22016)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.153% (18192/22144)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.126% (18291/22272)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.165% (18405/22400)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.156% (18508/22528)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.168% (18616/22656)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.159% (18719/22784)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.162% (18825/22912)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.166% (18931/23040)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.187% (19041/23168)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.177% (19144/23296)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.181% (19250/23424)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.201% (19360/23552)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.196% (19464/23680)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.195% (19569/23808)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.207% (19677/23936)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.189% (19778/24064)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.164% (19877/24192)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.171% (19984/24320)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.162% (20087/24448)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.145% (20188/24576)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.132% (20290/24704)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.128% (20394/24832)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.151% (20505/24960)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.147% (20609/25088)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.166% (20719/25216)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.158% (20822/25344)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.161% (20928/25472)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.168% (21035/25600)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.163% (21139/25728)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.151% (21241/25856)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.162% (21349/25984)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.169% (21456/26112)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.149% (21556/26240)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.153% (21662/26368)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.167% (21771/26496)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.144% (21870/26624)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.155% (21978/26752)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.150% (22082/26880)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.131% (22182/27008)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.123% (22285/27136)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.138% (22394/27264)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.119% (22494/27392)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.118% (22599/27520)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.125% (22706/27648)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.114% (22808/27776)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.074% (22902/27904)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.088% (23011/28032)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.085% (23115/28160)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.102% (23225/28288)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.088% (23326/28416)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.087% (23431/28544)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.094% (23538/28672)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.087% (23641/28800)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.093% (23748/28928)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.079% (23849/29056)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.069% (23951/29184)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.069% (24056/29312)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.052% (24156/29440)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.068% (24266/29568)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.051% (24366/29696)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.048% (24470/29824)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.031% (24570/29952)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.015% (24670/30080)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.018% (24776/30208)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.008% (24878/30336)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.012% (24984/30464)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.999% (25085/30592)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.012% (25194/30720)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.012% (25299/30848)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.009% (25403/30976)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.022% (25512/31104)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.009% (25613/31232)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 82.012% (25719/31360)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.031% (25830/31488)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.015% (25930/31616)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.015% (26035/31744)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.025% (26143/31872)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.025% (26248/32000)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.009% (26348/32128)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.006% (26452/32256)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.997% (26554/32384)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.007% (26662/32512)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.001% (26765/32640)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.001% (26870/32768)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.010% (26978/32896)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 82.007% (27082/33024)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.968% (27174/33152)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.983% (27284/33280)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.965% (27383/33408)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.948% (27482/33536)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.915% (27576/33664)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.925% (27684/33792)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.916% (27786/33920)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.931% (27896/34048)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.946% (28006/34176)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.947% (28111/34304)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.953% (28218/34432)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.970% (28329/34560)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.974% (28435/34688)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.982% (28543/34816)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.951% (28637/34944)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.940% (28738/35072)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.935% (28841/35200)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.949% (28951/35328)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.949% (29056/35456)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.933% (29155/35584)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.930% (29259/35712)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.920% (29360/35840)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.931% (29469/35968)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.932% (29574/36096)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.940% (29682/36224)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.935% (29785/36352)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.944% (29893/36480)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.944% (29998/36608)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.941% (30102/36736)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.944% (30208/36864)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.939% (30311/36992)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.959% (30423/37120)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.940% (30521/37248)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.938% (30625/37376)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.935% (30729/37504)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.928% (30831/37632)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.939% (30940/37760)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.968% (31056/37888)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.971% (31162/38016)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.968% (31266/38144)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.948% (31363/38272)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.951% (31469/38400)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.961% (31578/38528)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.967% (31685/38656)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.967% (31790/38784)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.957% (31891/38912)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.949% (31993/39040)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.960% (32102/39168)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.957% (32206/39296)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.937% (32303/39424)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.950% (32413/39552)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.956% (32520/39680)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.958% (32626/39808)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.961% (32732/39936)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.961% (32837/40064)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.952% (32938/40192)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.962% (33047/40320)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.957% (33150/40448)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.952% (33253/40576)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.943% (33354/40704)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.958% (33465/40832)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.946% (33565/40960)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.956% (33674/41088)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.949% (33776/41216)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.939% (33877/41344)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.940% (33982/41472)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.940% (34087/41600)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.943% (34193/41728)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.950% (34301/41856)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.962% (34411/41984)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.958% (34514/42112)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.946% (34614/42240)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.939% (34716/42368)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.942% (34822/42496)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.919% (34917/42624)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.938% (35030/42752)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.945% (35138/42880)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.955% (35247/43008)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.959% (35354/43136)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.960% (35459/43264)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.962% (35565/43392)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.958% (35668/43520)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.953% (35771/43648)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.960% (35879/43776)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.963% (35985/43904)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.954% (36086/44032)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.968% (36197/44160)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.954% (36296/44288)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.957% (36402/44416)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.950% (36504/44544)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.944% (36606/44672)\n",
            "Train Epoch: 92 | Loss: 0.522 | Acc: 81.951% (36714/44800)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.956% (36821/44928)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.962% (36929/45056)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.969% (37037/45184)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.978% (37146/45312)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.978% (37251/45440)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.970% (37352/45568)\n",
            "Train Epoch: 92 | Loss: 0.521 | Acc: 81.979% (37461/45696)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.972% (37563/45824)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.981% (37672/45952)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.994% (37783/46080)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 81.997% (37889/46208)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.008% (37999/46336)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.005% (38103/46464)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.003% (38207/46592)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.010% (38315/46720)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.023% (38426/46848)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.031% (38535/46976)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.012% (38631/47104)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.016% (38738/47232)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.031% (38850/47360)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.035% (38957/47488)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.044% (39066/47616)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.035% (39167/47744)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.042% (39275/47872)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.025% (39372/48000)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.029% (39479/48128)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.029% (39584/48256)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.040% (39694/48384)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.037% (39798/48512)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.046% (39907/48640)\n",
            "Train Epoch: 92 | Loss: 0.519 | Acc: 82.050% (40014/48768)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.039% (40114/48896)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.043% (40221/49024)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.041% (40325/49152)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.039% (40429/49280)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.037% (40533/49408)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.043% (40641/49536)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.045% (40747/49664)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.041% (40850/49792)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.037% (40953/49920)\n",
            "Train Epoch: 92 | Loss: 0.520 | Acc: 82.038% (41019/50000)\n",
            "Test Epoch: 92 | Loss: 0.592 | Acc: 79.000% (79/100)\n",
            "Test Epoch: 92 | Loss: 0.721 | Acc: 77.000% (154/200)\n",
            "Test Epoch: 92 | Loss: 0.699 | Acc: 77.667% (233/300)\n",
            "Test Epoch: 92 | Loss: 0.733 | Acc: 77.500% (310/400)\n",
            "Test Epoch: 92 | Loss: 0.712 | Acc: 77.200% (386/500)\n",
            "Test Epoch: 92 | Loss: 0.655 | Acc: 78.000% (468/600)\n",
            "Test Epoch: 92 | Loss: 0.655 | Acc: 78.000% (546/700)\n",
            "Test Epoch: 92 | Loss: 0.679 | Acc: 77.500% (620/800)\n",
            "Test Epoch: 92 | Loss: 0.689 | Acc: 77.222% (695/900)\n",
            "Test Epoch: 92 | Loss: 0.676 | Acc: 77.300% (773/1000)\n",
            "Test Epoch: 92 | Loss: 0.665 | Acc: 77.727% (855/1100)\n",
            "Test Epoch: 92 | Loss: 0.673 | Acc: 77.250% (927/1200)\n",
            "Test Epoch: 92 | Loss: 0.677 | Acc: 76.846% (999/1300)\n",
            "Test Epoch: 92 | Loss: 0.686 | Acc: 76.786% (1075/1400)\n",
            "Test Epoch: 92 | Loss: 0.680 | Acc: 77.000% (1155/1500)\n",
            "Test Epoch: 92 | Loss: 0.694 | Acc: 77.000% (1232/1600)\n",
            "Test Epoch: 92 | Loss: 0.688 | Acc: 77.118% (1311/1700)\n",
            "Test Epoch: 92 | Loss: 0.689 | Acc: 76.889% (1384/1800)\n",
            "Test Epoch: 92 | Loss: 0.688 | Acc: 77.158% (1466/1900)\n",
            "Test Epoch: 92 | Loss: 0.706 | Acc: 76.700% (1534/2000)\n",
            "Test Epoch: 92 | Loss: 0.715 | Acc: 76.571% (1608/2100)\n",
            "Test Epoch: 92 | Loss: 0.720 | Acc: 76.545% (1684/2200)\n",
            "Test Epoch: 92 | Loss: 0.729 | Acc: 76.522% (1760/2300)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.458% (1835/2400)\n",
            "Test Epoch: 92 | Loss: 0.737 | Acc: 76.280% (1907/2500)\n",
            "Test Epoch: 92 | Loss: 0.753 | Acc: 75.962% (1975/2600)\n",
            "Test Epoch: 92 | Loss: 0.743 | Acc: 76.185% (2057/2700)\n",
            "Test Epoch: 92 | Loss: 0.741 | Acc: 76.286% (2136/2800)\n",
            "Test Epoch: 92 | Loss: 0.743 | Acc: 76.276% (2212/2900)\n",
            "Test Epoch: 92 | Loss: 0.738 | Acc: 76.467% (2294/3000)\n",
            "Test Epoch: 92 | Loss: 0.738 | Acc: 76.516% (2372/3100)\n",
            "Test Epoch: 92 | Loss: 0.737 | Acc: 76.438% (2446/3200)\n",
            "Test Epoch: 92 | Loss: 0.734 | Acc: 76.424% (2522/3300)\n",
            "Test Epoch: 92 | Loss: 0.738 | Acc: 76.441% (2599/3400)\n",
            "Test Epoch: 92 | Loss: 0.738 | Acc: 76.257% (2669/3500)\n",
            "Test Epoch: 92 | Loss: 0.737 | Acc: 76.306% (2747/3600)\n",
            "Test Epoch: 92 | Loss: 0.740 | Acc: 76.270% (2822/3700)\n",
            "Test Epoch: 92 | Loss: 0.743 | Acc: 76.237% (2897/3800)\n",
            "Test Epoch: 92 | Loss: 0.740 | Acc: 76.410% (2980/3900)\n",
            "Test Epoch: 92 | Loss: 0.741 | Acc: 76.400% (3056/4000)\n",
            "Test Epoch: 92 | Loss: 0.743 | Acc: 76.439% (3134/4100)\n",
            "Test Epoch: 92 | Loss: 0.741 | Acc: 76.500% (3213/4200)\n",
            "Test Epoch: 92 | Loss: 0.737 | Acc: 76.605% (3294/4300)\n",
            "Test Epoch: 92 | Loss: 0.733 | Acc: 76.727% (3376/4400)\n",
            "Test Epoch: 92 | Loss: 0.733 | Acc: 76.689% (3451/4500)\n",
            "Test Epoch: 92 | Loss: 0.733 | Acc: 76.630% (3525/4600)\n",
            "Test Epoch: 92 | Loss: 0.732 | Acc: 76.681% (3604/4700)\n",
            "Test Epoch: 92 | Loss: 0.733 | Acc: 76.750% (3684/4800)\n",
            "Test Epoch: 92 | Loss: 0.730 | Acc: 76.755% (3761/4900)\n",
            "Test Epoch: 92 | Loss: 0.732 | Acc: 76.640% (3832/5000)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.765% (3915/5100)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.788% (3993/5200)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.774% (4069/5300)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.833% (4149/5400)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.800% (4224/5500)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.768% (4299/5600)\n",
            "Test Epoch: 92 | Loss: 0.731 | Acc: 76.737% (4374/5700)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.879% (4459/5800)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.678% (4524/5900)\n",
            "Test Epoch: 92 | Loss: 0.730 | Acc: 76.633% (4598/6000)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.721% (4680/6100)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.694% (4755/6200)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.698% (4832/6300)\n",
            "Test Epoch: 92 | Loss: 0.724 | Acc: 76.828% (4917/6400)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.800% (4992/6500)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.788% (5068/6600)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.836% (5148/6700)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.750% (5219/6800)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.725% (5294/6900)\n",
            "Test Epoch: 92 | Loss: 0.729 | Acc: 76.657% (5366/7000)\n",
            "Test Epoch: 92 | Loss: 0.729 | Acc: 76.634% (5441/7100)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.667% (5520/7200)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.685% (5598/7300)\n",
            "Test Epoch: 92 | Loss: 0.723 | Acc: 76.757% (5680/7400)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.653% (5749/7500)\n",
            "Test Epoch: 92 | Loss: 0.724 | Acc: 76.737% (5832/7600)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.662% (5903/7700)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.564% (5972/7800)\n",
            "Test Epoch: 92 | Loss: 0.730 | Acc: 76.506% (6044/7900)\n",
            "Test Epoch: 92 | Loss: 0.730 | Acc: 76.525% (6122/8000)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.556% (6201/8100)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.561% (6278/8200)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.602% (6358/8300)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.560% (6431/8400)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.506% (6503/8500)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.547% (6583/8600)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.552% (6660/8700)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.557% (6737/8800)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.528% (6811/8900)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.544% (6889/9000)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.615% (6972/9100)\n",
            "Test Epoch: 92 | Loss: 0.723 | Acc: 76.728% (7059/9200)\n",
            "Test Epoch: 92 | Loss: 0.724 | Acc: 76.710% (7134/9300)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.649% (7205/9400)\n",
            "Test Epoch: 92 | Loss: 0.726 | Acc: 76.632% (7280/9500)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.635% (7357/9600)\n",
            "Test Epoch: 92 | Loss: 0.724 | Acc: 76.691% (7439/9700)\n",
            "Test Epoch: 92 | Loss: 0.725 | Acc: 76.633% (7510/9800)\n",
            "Test Epoch: 92 | Loss: 0.727 | Acc: 76.566% (7580/9900)\n",
            "Test Epoch: 92 | Loss: 0.728 | Acc: 76.550% (7655/10000)\n",
            "\n",
            "Epoch: 93\n",
            "Train Epoch: 93 | Loss: 0.396 | Acc: 87.500% (112/128)\n",
            "Train Epoch: 93 | Loss: 0.432 | Acc: 85.156% (218/256)\n",
            "Train Epoch: 93 | Loss: 0.464 | Acc: 84.896% (326/384)\n",
            "Train Epoch: 93 | Loss: 0.470 | Acc: 84.180% (431/512)\n",
            "Train Epoch: 93 | Loss: 0.482 | Acc: 83.438% (534/640)\n",
            "Train Epoch: 93 | Loss: 0.497 | Acc: 82.292% (632/768)\n",
            "Train Epoch: 93 | Loss: 0.485 | Acc: 83.036% (744/896)\n",
            "Train Epoch: 93 | Loss: 0.505 | Acc: 82.422% (844/1024)\n",
            "Train Epoch: 93 | Loss: 0.502 | Acc: 82.726% (953/1152)\n",
            "Train Epoch: 93 | Loss: 0.504 | Acc: 82.422% (1055/1280)\n",
            "Train Epoch: 93 | Loss: 0.503 | Acc: 82.741% (1165/1408)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.617% (1269/1536)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.272% (1369/1664)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.199% (1473/1792)\n",
            "Train Epoch: 93 | Loss: 0.525 | Acc: 81.875% (1572/1920)\n",
            "Train Epoch: 93 | Loss: 0.532 | Acc: 81.641% (1672/2048)\n",
            "Train Epoch: 93 | Loss: 0.538 | Acc: 81.388% (1771/2176)\n",
            "Train Epoch: 93 | Loss: 0.531 | Acc: 81.424% (1876/2304)\n",
            "Train Epoch: 93 | Loss: 0.527 | Acc: 81.702% (1987/2432)\n",
            "Train Epoch: 93 | Loss: 0.525 | Acc: 81.875% (2096/2560)\n",
            "Train Epoch: 93 | Loss: 0.524 | Acc: 82.031% (2205/2688)\n",
            "Train Epoch: 93 | Loss: 0.527 | Acc: 82.138% (2313/2816)\n",
            "Train Epoch: 93 | Loss: 0.523 | Acc: 82.303% (2423/2944)\n",
            "Train Epoch: 93 | Loss: 0.523 | Acc: 82.259% (2527/3072)\n",
            "Train Epoch: 93 | Loss: 0.523 | Acc: 82.312% (2634/3200)\n",
            "Train Epoch: 93 | Loss: 0.521 | Acc: 82.512% (2746/3328)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.784% (2861/3456)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.785% (2967/3584)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.732% (3071/3712)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.734% (3177/3840)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.686% (3281/3968)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.715% (3388/4096)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.765% (3496/4224)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.858% (3606/4352)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.879% (3713/4480)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 83.030% (3826/4608)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 83.003% (3931/4736)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 83.018% (4038/4864)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.913% (4139/4992)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.949% (4247/5120)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.965% (4354/5248)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.868% (4455/5376)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.776% (4556/5504)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.795% (4663/5632)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.917% (4776/5760)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.914% (4882/5888)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.862% (4985/6016)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.796% (5087/6144)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.844% (5196/6272)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.781% (5298/6400)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.797% (5405/6528)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.828% (5513/6656)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.724% (5612/6784)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.812% (5724/6912)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.670% (5820/7040)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.659% (5925/7168)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.552% (6023/7296)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.530% (6127/7424)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.534% (6233/7552)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.539% (6339/7680)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.582% (6448/7808)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.611% (6556/7936)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.602% (6661/8064)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.483% (6757/8192)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.464% (6861/8320)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.457% (6966/8448)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.521% (7077/8576)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.422% (7174/8704)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.416% (7279/8832)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.400% (7383/8960)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.482% (7496/9088)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.389% (7593/9216)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.470% (7706/9344)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.432% (7808/9472)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.427% (7913/9600)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.453% (8021/9728)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.488% (8130/9856)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.452% (8232/9984)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.516% (8344/10112)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.539% (8452/10240)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.504% (8554/10368)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.631% (8673/10496)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.624% (8778/10624)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.515% (8872/10752)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.528% (8979/10880)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.504% (9082/11008)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.534% (9191/11136)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.537% (9297/11264)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.567% (9406/11392)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.500% (9504/11520)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.512% (9611/11648)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.515% (9717/11776)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.510% (9822/11904)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.488% (9925/12032)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.516% (10034/12160)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.528% (10141/12288)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.531% (10247/12416)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.518% (10351/12544)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.528% (10458/12672)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.492% (10559/12800)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.480% (10663/12928)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.521% (10774/13056)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.517% (10879/13184)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.557% (10990/13312)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.582% (11099/13440)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.562% (11202/13568)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.586% (11311/13696)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.617% (11421/13824)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.683% (11536/13952)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.649% (11637/14080)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.679% (11747/14208)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.673% (11852/14336)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.653% (11955/14464)\n",
            "Train Epoch: 93 | Loss: 0.504 | Acc: 82.710% (12069/14592)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.656% (12167/14720)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.604% (12265/14848)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.579% (12367/14976)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.521% (12464/15104)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.517% (12569/15232)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.513% (12674/15360)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.522% (12781/15488)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.537% (12889/15616)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.558% (12998/15744)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.529% (13099/15872)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.519% (13203/16000)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.540% (13312/16128)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.554% (13420/16256)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.581% (13530/16384)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.601% (13639/16512)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.584% (13742/16640)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.556% (13843/16768)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.588% (13954/16896)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.583% (14059/17024)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.620% (14171/17152)\n",
            "Train Epoch: 93 | Loss: 0.506 | Acc: 82.598% (14273/17280)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.565% (14373/17408)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.539% (14474/17536)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.558% (14583/17664)\n",
            "Train Epoch: 93 | Loss: 0.507 | Acc: 82.560% (14689/17792)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.550% (14793/17920)\n",
            "Train Epoch: 93 | Loss: 0.508 | Acc: 82.541% (14897/18048)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.488% (14993/18176)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.479% (15097/18304)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.476% (15202/18432)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.484% (15309/18560)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.491% (15416/18688)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.504% (15524/18816)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.459% (15621/18944)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.419% (15719/19072)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.427% (15826/19200)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.409% (15928/19328)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.417% (16035/19456)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.409% (16139/19584)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.483% (16259/19712)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.460% (16360/19840)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.427% (16459/19968)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.449% (16569/20096)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.452% (16675/20224)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.444% (16779/20352)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.402% (16876/20480)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.410% (16983/20608)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.422% (17091/20736)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.424% (17197/20864)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.398% (17297/20992)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.401% (17403/21120)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.398% (17508/21248)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.382% (17610/21376)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.347% (17708/21504)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.355% (17815/21632)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.371% (17924/21760)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.337% (18022/21888)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.322% (18124/22016)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.302% (18225/22144)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.305% (18331/22272)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.321% (18440/22400)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.311% (18543/22528)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.345% (18656/22656)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.360% (18765/22784)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.380% (18875/22912)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.344% (18972/23040)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.338% (19076/23168)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.323% (19178/23296)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.356% (19291/23424)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.371% (19400/23552)\n",
            "Train Epoch: 93 | Loss: 0.509 | Acc: 82.365% (19504/23680)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.338% (19603/23808)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.294% (19698/23936)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.297% (19804/24064)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.288% (19907/24192)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.282% (20011/24320)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.252% (20109/24448)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.300% (20226/24576)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.250% (20319/24704)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.237% (20421/24832)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.224% (20523/24960)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.211% (20625/25088)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.237% (20737/25216)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.229% (20840/25344)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.228% (20945/25472)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.223% (21049/25600)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.210% (21151/25728)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.217% (21258/25856)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.231% (21367/25984)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.238% (21474/26112)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.237% (21579/26240)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.209% (21677/26368)\n",
            "Train Epoch: 93 | Loss: 0.510 | Acc: 82.235% (21789/26496)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.230% (21893/26624)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.214% (21994/26752)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.225% (22102/26880)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.242% (22212/27008)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.230% (22314/27136)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.222% (22417/27264)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.206% (22518/27392)\n",
            "Train Epoch: 93 | Loss: 0.511 | Acc: 82.198% (22621/27520)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.190% (22724/27648)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.172% (22824/27776)\n",
            "Train Epoch: 93 | Loss: 0.512 | Acc: 82.182% (22932/27904)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.153% (23029/28032)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.109% (23122/28160)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.109% (23227/28288)\n",
            "Train Epoch: 93 | Loss: 0.513 | Acc: 82.133% (23339/28416)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.108% (23437/28544)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.104% (23541/28672)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.122% (23651/28800)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.100% (23750/28928)\n",
            "Train Epoch: 93 | Loss: 0.514 | Acc: 82.086% (23851/29056)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.079% (23954/29184)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.076% (24058/29312)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.089% (24167/29440)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.048% (24260/29568)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.028% (24359/29696)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.041% (24468/29824)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.045% (24574/29952)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.051% (24681/30080)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.041% (24783/30208)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.028% (24884/30336)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.064% (25000/30464)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.080% (25110/30592)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.077% (25214/30720)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.060% (25314/30848)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.076% (25424/30976)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.063% (25525/31104)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.076% (25634/31232)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.057% (25733/31360)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.038% (25832/31488)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (25936/31616)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (26041/31744)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (26146/31872)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.031% (26250/32000)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.019% (26351/32128)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.025% (26458/32256)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.022% (26562/32384)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.031% (26670/32512)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.025% (26773/32640)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.013% (26874/32768)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.010% (26978/32896)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.007% (27082/33024)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.998% (27184/33152)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.013% (27294/33280)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.004% (27396/33408)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.987% (27495/33536)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.993% (27602/33664)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.981% (27703/33792)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.958% (27800/33920)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.961% (27906/34048)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.958% (28010/34176)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.964% (28117/34304)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.962% (28221/34432)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.970% (28329/34560)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.968% (28433/34688)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.977% (28541/34816)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.983% (28648/34944)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.966% (28747/35072)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.983% (28858/35200)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.994% (28967/35328)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.023% (29082/35456)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.006% (29181/35584)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.012% (29288/35712)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.001% (29389/35840)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.017% (29500/35968)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.037% (29612/36096)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.020% (29711/36224)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.017% (29815/36352)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.023% (29922/36480)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.026% (30028/36608)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.045% (30140/36736)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.026% (30238/36864)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.007% (30336/36992)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.002% (30439/37120)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.986% (30538/37248)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.010% (30652/37376)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.013% (30758/37504)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.023% (30867/37632)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.021% (30971/37760)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.021% (31076/37888)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.013% (31178/38016)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.016% (31284/38144)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.018% (31390/38272)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.026% (31498/38400)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.008% (31596/38528)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.023% (31707/38656)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.995% (31801/38784)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.998% (31907/38912)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.011% (32017/39040)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.011% (32122/39168)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.008% (32226/39296)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.016% (32334/39424)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.014% (32438/39552)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 82.016% (32544/39680)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (32656/39808)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.044% (32765/39936)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.059% (32876/40064)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.064% (32983/40192)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.071% (33091/40320)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.078% (33199/40448)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.068% (33300/40576)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.058% (33401/40704)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.043% (33500/40832)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.056% (33610/40960)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.046% (33711/41088)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.053% (33819/41216)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.031% (33915/41344)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (34021/41472)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.041% (34129/41600)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (34231/41728)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.036% (34337/41856)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (34441/41984)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.036% (34547/42112)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.038% (34653/42240)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.062% (34768/42368)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.067% (34875/42496)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.059% (34977/42624)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.048% (35077/42752)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.038% (35178/42880)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.034% (35281/43008)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.034% (35386/43136)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.020% (35485/43264)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.011% (35586/43392)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.027% (35698/43520)\n",
            "Train Epoch: 93 | Loss: 0.515 | Acc: 82.040% (35809/43648)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.034% (35911/43776)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.022% (36011/43904)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.011% (36111/44032)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 82.002% (36212/44160)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.979% (36307/44288)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.961% (36404/44416)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.968% (36512/44544)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.966% (36616/44672)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.955% (36716/44800)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.967% (36826/44928)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.965% (36930/45056)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.956% (37031/45184)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.961% (37138/45312)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.967% (37246/45440)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.970% (37352/45568)\n",
            "Train Epoch: 93 | Loss: 0.516 | Acc: 81.963% (37454/45696)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.948% (37552/45824)\n",
            "Train Epoch: 93 | Loss: 0.517 | Acc: 81.933% (37650/45952)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.925% (37751/46080)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.930% (37858/46208)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.945% (37970/46336)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.947% (38076/46464)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.926% (38171/46592)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.941% (38283/46720)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.939% (38387/46848)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.944% (38494/46976)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.936% (38595/47104)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.917% (38691/47232)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.928% (38801/47360)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.922% (38903/47488)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.937% (39015/47616)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.933% (39118/47744)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.931% (39222/47872)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.948% (39335/48000)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.927% (39430/48128)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.923% (39533/48256)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.924% (39638/48384)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.922% (39742/48512)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.926% (39849/48640)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.923% (39952/48768)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.925% (40058/48896)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.931% (40166/49024)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.923% (40267/49152)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.916% (40368/49280)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.912% (40471/49408)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.916% (40578/49536)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.921% (40685/49664)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.927% (40793/49792)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.933% (40901/49920)\n",
            "Train Epoch: 93 | Loss: 0.518 | Acc: 81.920% (40960/50000)\n",
            "Test Epoch: 93 | Loss: 0.570 | Acc: 79.000% (79/100)\n",
            "Test Epoch: 93 | Loss: 0.674 | Acc: 77.500% (155/200)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.333% (232/300)\n",
            "Test Epoch: 93 | Loss: 0.711 | Acc: 77.250% (309/400)\n",
            "Test Epoch: 93 | Loss: 0.689 | Acc: 77.400% (387/500)\n",
            "Test Epoch: 93 | Loss: 0.629 | Acc: 78.833% (473/600)\n",
            "Test Epoch: 93 | Loss: 0.626 | Acc: 78.857% (552/700)\n",
            "Test Epoch: 93 | Loss: 0.649 | Acc: 78.500% (628/800)\n",
            "Test Epoch: 93 | Loss: 0.659 | Acc: 77.889% (701/900)\n",
            "Test Epoch: 93 | Loss: 0.645 | Acc: 78.100% (781/1000)\n",
            "Test Epoch: 93 | Loss: 0.637 | Acc: 78.455% (863/1100)\n",
            "Test Epoch: 93 | Loss: 0.641 | Acc: 78.333% (940/1200)\n",
            "Test Epoch: 93 | Loss: 0.644 | Acc: 78.154% (1016/1300)\n",
            "Test Epoch: 93 | Loss: 0.651 | Acc: 77.714% (1088/1400)\n",
            "Test Epoch: 93 | Loss: 0.641 | Acc: 78.000% (1170/1500)\n",
            "Test Epoch: 93 | Loss: 0.658 | Acc: 77.625% (1242/1600)\n",
            "Test Epoch: 93 | Loss: 0.652 | Acc: 77.824% (1323/1700)\n",
            "Test Epoch: 93 | Loss: 0.646 | Acc: 78.000% (1404/1800)\n",
            "Test Epoch: 93 | Loss: 0.645 | Acc: 78.000% (1482/1900)\n",
            "Test Epoch: 93 | Loss: 0.665 | Acc: 77.450% (1549/2000)\n",
            "Test Epoch: 93 | Loss: 0.674 | Acc: 77.333% (1624/2100)\n",
            "Test Epoch: 93 | Loss: 0.678 | Acc: 77.318% (1701/2200)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.217% (1776/2300)\n",
            "Test Epoch: 93 | Loss: 0.684 | Acc: 77.250% (1854/2400)\n",
            "Test Epoch: 93 | Loss: 0.693 | Acc: 77.200% (1930/2500)\n",
            "Test Epoch: 93 | Loss: 0.707 | Acc: 77.154% (2006/2600)\n",
            "Test Epoch: 93 | Loss: 0.698 | Acc: 77.370% (2089/2700)\n",
            "Test Epoch: 93 | Loss: 0.698 | Acc: 77.393% (2167/2800)\n",
            "Test Epoch: 93 | Loss: 0.700 | Acc: 77.414% (2245/2900)\n",
            "Test Epoch: 93 | Loss: 0.696 | Acc: 77.500% (2325/3000)\n",
            "Test Epoch: 93 | Loss: 0.697 | Acc: 77.516% (2403/3100)\n",
            "Test Epoch: 93 | Loss: 0.697 | Acc: 77.438% (2478/3200)\n",
            "Test Epoch: 93 | Loss: 0.693 | Acc: 77.485% (2557/3300)\n",
            "Test Epoch: 93 | Loss: 0.698 | Acc: 77.353% (2630/3400)\n",
            "Test Epoch: 93 | Loss: 0.696 | Acc: 77.286% (2705/3500)\n",
            "Test Epoch: 93 | Loss: 0.695 | Acc: 77.278% (2782/3600)\n",
            "Test Epoch: 93 | Loss: 0.700 | Acc: 77.297% (2860/3700)\n",
            "Test Epoch: 93 | Loss: 0.701 | Acc: 77.237% (2935/3800)\n",
            "Test Epoch: 93 | Loss: 0.698 | Acc: 77.333% (3016/3900)\n",
            "Test Epoch: 93 | Loss: 0.700 | Acc: 77.275% (3091/4000)\n",
            "Test Epoch: 93 | Loss: 0.702 | Acc: 77.317% (3170/4100)\n",
            "Test Epoch: 93 | Loss: 0.700 | Acc: 77.405% (3251/4200)\n",
            "Test Epoch: 93 | Loss: 0.695 | Acc: 77.605% (3337/4300)\n",
            "Test Epoch: 93 | Loss: 0.693 | Acc: 77.682% (3418/4400)\n",
            "Test Epoch: 93 | Loss: 0.692 | Acc: 77.622% (3493/4500)\n",
            "Test Epoch: 93 | Loss: 0.694 | Acc: 77.609% (3570/4600)\n",
            "Test Epoch: 93 | Loss: 0.694 | Acc: 77.596% (3647/4700)\n",
            "Test Epoch: 93 | Loss: 0.696 | Acc: 77.604% (3725/4800)\n",
            "Test Epoch: 93 | Loss: 0.692 | Acc: 77.633% (3804/4900)\n",
            "Test Epoch: 93 | Loss: 0.694 | Acc: 77.600% (3880/5000)\n",
            "Test Epoch: 93 | Loss: 0.690 | Acc: 77.765% (3966/5100)\n",
            "Test Epoch: 93 | Loss: 0.691 | Acc: 77.769% (4044/5200)\n",
            "Test Epoch: 93 | Loss: 0.689 | Acc: 77.811% (4124/5300)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.815% (4202/5400)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.818% (4280/5500)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.786% (4356/5600)\n",
            "Test Epoch: 93 | Loss: 0.691 | Acc: 77.702% (4429/5700)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.879% (4517/5800)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.780% (4589/5900)\n",
            "Test Epoch: 93 | Loss: 0.690 | Acc: 77.700% (4662/6000)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.836% (4748/6100)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.742% (4820/6200)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.730% (4897/6300)\n",
            "Test Epoch: 93 | Loss: 0.684 | Acc: 77.875% (4984/6400)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.815% (5058/6500)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.773% (5133/6600)\n",
            "Test Epoch: 93 | Loss: 0.684 | Acc: 77.866% (5217/6700)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.794% (5290/6800)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.812% (5369/6900)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.714% (5440/7000)\n",
            "Test Epoch: 93 | Loss: 0.689 | Acc: 77.690% (5516/7100)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.722% (5596/7200)\n",
            "Test Epoch: 93 | Loss: 0.685 | Acc: 77.795% (5679/7300)\n",
            "Test Epoch: 93 | Loss: 0.683 | Acc: 77.811% (5758/7400)\n",
            "Test Epoch: 93 | Loss: 0.685 | Acc: 77.733% (5830/7500)\n",
            "Test Epoch: 93 | Loss: 0.683 | Acc: 77.789% (5912/7600)\n",
            "Test Epoch: 93 | Loss: 0.684 | Acc: 77.740% (5986/7700)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.667% (6058/7800)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.620% (6132/7900)\n",
            "Test Epoch: 93 | Loss: 0.689 | Acc: 77.612% (6209/8000)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.580% (6284/8100)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.573% (6361/8200)\n",
            "Test Epoch: 93 | Loss: 0.685 | Acc: 77.566% (6438/8300)\n",
            "Test Epoch: 93 | Loss: 0.685 | Acc: 77.548% (6514/8400)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.529% (6590/8500)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.535% (6668/8600)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.471% (6740/8700)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.432% (6814/8800)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.416% (6890/8900)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.422% (6968/9000)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.484% (7051/9100)\n",
            "Test Epoch: 93 | Loss: 0.684 | Acc: 77.565% (7136/9200)\n",
            "Test Epoch: 93 | Loss: 0.685 | Acc: 77.538% (7211/9300)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.511% (7286/9400)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.495% (7362/9500)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.531% (7443/9600)\n",
            "Test Epoch: 93 | Loss: 0.686 | Acc: 77.577% (7525/9700)\n",
            "Test Epoch: 93 | Loss: 0.687 | Acc: 77.531% (7598/9800)\n",
            "Test Epoch: 93 | Loss: 0.688 | Acc: 77.455% (7668/9900)\n",
            "Test Epoch: 93 | Loss: 0.690 | Acc: 77.480% (7748/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 94\n",
            "Train Epoch: 94 | Loss: 0.393 | Acc: 85.156% (109/128)\n",
            "Train Epoch: 94 | Loss: 0.405 | Acc: 85.156% (218/256)\n",
            "Train Epoch: 94 | Loss: 0.491 | Acc: 81.510% (313/384)\n",
            "Train Epoch: 94 | Loss: 0.500 | Acc: 81.055% (415/512)\n",
            "Train Epoch: 94 | Loss: 0.483 | Acc: 81.875% (524/640)\n",
            "Train Epoch: 94 | Loss: 0.491 | Acc: 81.901% (629/768)\n",
            "Train Epoch: 94 | Loss: 0.491 | Acc: 82.031% (735/896)\n",
            "Train Epoch: 94 | Loss: 0.505 | Acc: 81.250% (832/1024)\n",
            "Train Epoch: 94 | Loss: 0.501 | Acc: 81.250% (936/1152)\n",
            "Train Epoch: 94 | Loss: 0.500 | Acc: 81.484% (1043/1280)\n",
            "Train Epoch: 94 | Loss: 0.503 | Acc: 81.463% (1147/1408)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.250% (1248/1536)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.250% (1352/1664)\n",
            "Train Epoch: 94 | Loss: 0.506 | Acc: 81.529% (1461/1792)\n",
            "Train Epoch: 94 | Loss: 0.500 | Acc: 81.771% (1570/1920)\n",
            "Train Epoch: 94 | Loss: 0.504 | Acc: 81.494% (1669/2048)\n",
            "Train Epoch: 94 | Loss: 0.501 | Acc: 81.756% (1779/2176)\n",
            "Train Epoch: 94 | Loss: 0.503 | Acc: 81.771% (1884/2304)\n",
            "Train Epoch: 94 | Loss: 0.502 | Acc: 81.867% (1991/2432)\n",
            "Train Epoch: 94 | Loss: 0.499 | Acc: 82.109% (2102/2560)\n",
            "Train Epoch: 94 | Loss: 0.500 | Acc: 82.031% (2205/2688)\n",
            "Train Epoch: 94 | Loss: 0.502 | Acc: 81.996% (2309/2816)\n",
            "Train Epoch: 94 | Loss: 0.506 | Acc: 81.793% (2408/2944)\n",
            "Train Epoch: 94 | Loss: 0.501 | Acc: 82.064% (2521/3072)\n",
            "Train Epoch: 94 | Loss: 0.508 | Acc: 81.938% (2622/3200)\n",
            "Train Epoch: 94 | Loss: 0.509 | Acc: 81.851% (2724/3328)\n",
            "Train Epoch: 94 | Loss: 0.508 | Acc: 81.858% (2829/3456)\n",
            "Train Epoch: 94 | Loss: 0.508 | Acc: 81.808% (2932/3584)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 81.654% (3031/3712)\n",
            "Train Epoch: 94 | Loss: 0.509 | Acc: 81.641% (3135/3840)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.426% (3231/3968)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.421% (3335/4096)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.392% (3438/4224)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.342% (3540/4352)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.384% (3646/4480)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.402% (3751/4608)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.419% (3856/4736)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.291% (3954/4864)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.250% (4056/4992)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.289% (4162/5120)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.326% (4268/5248)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.455% (4379/5376)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.523% (4487/5504)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.463% (4588/5632)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.458% (4692/5760)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.522% (4800/5888)\n",
            "Train Epoch: 94 | Loss: 0.522 | Acc: 81.449% (4900/6016)\n",
            "Train Epoch: 94 | Loss: 0.522 | Acc: 81.396% (5001/6144)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.537% (5114/6272)\n",
            "Train Epoch: 94 | Loss: 0.522 | Acc: 81.484% (5215/6400)\n",
            "Train Epoch: 94 | Loss: 0.523 | Acc: 81.403% (5314/6528)\n",
            "Train Epoch: 94 | Loss: 0.523 | Acc: 81.430% (5420/6656)\n",
            "Train Epoch: 94 | Loss: 0.524 | Acc: 81.427% (5524/6784)\n",
            "Train Epoch: 94 | Loss: 0.524 | Acc: 81.438% (5629/6912)\n",
            "Train Epoch: 94 | Loss: 0.523 | Acc: 81.491% (5737/7040)\n",
            "Train Epoch: 94 | Loss: 0.523 | Acc: 81.473% (5840/7168)\n",
            "Train Epoch: 94 | Loss: 0.524 | Acc: 81.565% (5951/7296)\n",
            "Train Epoch: 94 | Loss: 0.521 | Acc: 81.627% (6060/7424)\n",
            "Train Epoch: 94 | Loss: 0.522 | Acc: 81.541% (6158/7552)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.667% (6272/7680)\n",
            "Train Epoch: 94 | Loss: 0.521 | Acc: 81.609% (6372/7808)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.704% (6484/7936)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.672% (6586/8064)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.665% (6690/8192)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.695% (6797/8320)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.641% (6897/8448)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.646% (7002/8576)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.687% (7110/8704)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.680% (7214/8832)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.663% (7317/8960)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.657% (7421/9088)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.673% (7527/9216)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.699% (7634/9344)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.746% (7743/9472)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.729% (7846/9600)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.743% (7952/9728)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.757% (8058/9856)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.801% (8167/9984)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.794% (8271/10112)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.816% (8378/10240)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.829% (8484/10368)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.860% (8592/10496)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.824% (8693/10624)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.817% (8797/10752)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.811% (8901/10880)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.813% (9006/11008)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.861% (9116/11136)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.854% (9220/11264)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.856% (9325/11392)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.840% (9428/11520)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.860% (9535/11648)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.938% (9649/11776)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.947% (9755/11904)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.873% (9851/12032)\n",
            "Train Epoch: 94 | Loss: 0.521 | Acc: 81.826% (9950/12160)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.860% (10059/12288)\n",
            "Train Epoch: 94 | Loss: 0.520 | Acc: 81.886% (10167/12416)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.904% (10274/12544)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.897% (10378/12672)\n",
            "Train Epoch: 94 | Loss: 0.519 | Acc: 81.898% (10483/12800)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.931% (10592/12928)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.962% (10701/13056)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 81.993% (10810/13184)\n",
            "Train Epoch: 94 | Loss: 0.518 | Acc: 81.949% (10909/13312)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.942% (11013/13440)\n",
            "Train Epoch: 94 | Loss: 0.517 | Acc: 81.965% (11121/13568)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 82.002% (11231/13696)\n",
            "Train Epoch: 94 | Loss: 0.516 | Acc: 82.024% (11339/13824)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 82.053% (11448/13952)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.102% (11560/14080)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.102% (11665/14208)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.164% (11779/14336)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.114% (11877/14464)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.100% (11980/14592)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.160% (12094/14720)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.173% (12201/14848)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.192% (12309/14976)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.190% (12414/15104)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.182% (12518/15232)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.148% (12618/15360)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.160% (12725/15488)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.172% (12832/15616)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.146% (12933/15744)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.101% (13031/15872)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.069% (13131/16000)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.056% (13234/16128)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.093% (13345/16256)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.098% (13451/16384)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.098% (13556/16512)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.115% (13664/16640)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.121% (13770/16768)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.102% (13872/16896)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.090% (13975/17024)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.072% (14077/17152)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.060% (14180/17280)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.060% (14285/17408)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.048% (14388/17536)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.037% (14491/17664)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.048% (14598/17792)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.042% (14702/17920)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.009% (14801/18048)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.971% (14899/18176)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.015% (15012/18304)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.042% (15122/18432)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.037% (15226/18560)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.042% (15332/18688)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.037% (15436/18816)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.021% (15538/18944)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.031% (15645/19072)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.052% (15754/19200)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.021% (15853/19328)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.036% (15961/19456)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.067% (16072/19584)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.072% (16178/19712)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.061% (16281/19840)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.066% (16387/19968)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.116% (16502/20096)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.115% (16607/20224)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.110% (16711/20352)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.100% (16814/20480)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.094% (16918/20608)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.104% (17025/20736)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.118% (17133/20864)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.141% (17243/20992)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.154% (17351/21120)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.144% (17454/21248)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.120% (17554/21376)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.120% (17659/21504)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.096% (17759/21632)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.114% (17868/21760)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.109% (17972/21888)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.090% (18073/22016)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.117% (18184/22144)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.135% (18293/22272)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.129% (18397/22400)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.129% (18502/22528)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.150% (18612/22656)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.163% (18720/22784)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.145% (18821/22912)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.122% (18921/23040)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.118% (19025/23168)\n",
            "Train Epoch: 94 | Loss: 0.510 | Acc: 82.126% (19132/23296)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.108% (19233/23424)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.086% (19333/23552)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.090% (19439/23680)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.086% (19543/23808)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.056% (19641/23936)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.064% (19748/24064)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.064% (19853/24192)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.064% (19958/24320)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.039% (20057/24448)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.048% (20164/24576)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.031% (20265/24704)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.035% (20371/24832)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.051% (20480/24960)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.063% (20588/25088)\n",
            "Train Epoch: 94 | Loss: 0.511 | Acc: 82.087% (20699/25216)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.071% (20800/25344)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.063% (20903/25472)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.043% (21003/25600)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.031% (21105/25728)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.043% (21213/25856)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.050% (21320/25984)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.050% (21425/26112)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.066% (21534/26240)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.081% (21643/26368)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.099% (21753/26496)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.088% (21855/26624)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.061% (21953/26752)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.061% (22058/26880)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.072% (22166/27008)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.042% (22263/27136)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.024% (22363/27264)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.050% (22475/27392)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.057% (22582/27520)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.071% (22691/27648)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.067% (22795/27776)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.071% (22901/27904)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.067% (23005/28032)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.063% (23109/28160)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.074% (23217/28288)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.045% (23314/28416)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.063% (23424/28544)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.070% (23531/28672)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.090% (23642/28800)\n",
            "Train Epoch: 94 | Loss: 0.512 | Acc: 82.083% (23745/28928)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.066% (23845/29056)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.048% (23945/29184)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.041% (24048/29312)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.048% (24155/29440)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.055% (24262/29568)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.035% (24361/29696)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.035% (24466/29824)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.038% (24572/29952)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.031% (24675/30080)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (24776/30208)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (24879/30336)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (24986/30464)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.012% (25089/30592)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (25196/30720)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.012% (25299/30848)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.005% (25402/30976)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.009% (25508/31104)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.002% (25611/31232)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.987% (25711/31360)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.974% (25812/31488)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.987% (25921/31616)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.984% (26025/31744)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.990% (26132/31872)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.987% (26236/32000)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.975% (26337/32128)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.982% (26444/32256)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.979% (26548/32384)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.970% (26650/32512)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.970% (26755/32640)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.958% (26856/32768)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.958% (26961/32896)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.949% (27063/33024)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.956% (27170/33152)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.959% (27276/33280)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.959% (27381/33408)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.995% (27498/33536)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.007% (27607/33664)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.005% (27711/33792)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.993% (27812/33920)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.999% (27919/34048)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (28028/34176)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.020% (28136/34304)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.005% (28236/34432)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.988% (28335/34560)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.979% (28437/34688)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.988% (28545/34816)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.974% (28645/34944)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.977% (28751/35072)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.974% (28855/35200)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.980% (28962/35328)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.966% (29062/35456)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.958% (29164/35584)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.967% (29272/35712)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.934% (29365/35840)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.951% (29476/35968)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.948% (29580/36096)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.937% (29681/36224)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.938% (29786/36352)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.930% (29888/36480)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.941% (29997/36608)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.933% (30099/36736)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.925% (30201/36864)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.934% (30309/36992)\n",
            "Train Epoch: 94 | Loss: 0.515 | Acc: 81.950% (30420/37120)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.959% (30528/37248)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.959% (30633/37376)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.981% (30746/37504)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.978% (30850/37632)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.997% (30962/37760)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.981% (31061/37888)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.002% (31174/38016)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.997% (31277/38144)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.005% (31385/38272)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.997% (31487/38400)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.974% (31583/38528)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.972% (31687/38656)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.962% (31788/38784)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.988% (31903/38912)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.975% (32003/39040)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.985% (32112/39168)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.001% (32223/39296)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.988% (32323/39424)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.001% (32433/39552)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (32542/39680)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.999% (32642/39808)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.004% (32749/39936)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.004% (32854/40064)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.014% (32963/40192)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.999% (33062/40320)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.997% (33166/40448)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.007% (33275/40576)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.002% (33378/40704)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.990% (33478/40832)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 81.980% (33579/40960)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.968% (33679/41088)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.978% (33788/41216)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.990% (33898/41344)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.000% (34007/41472)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.005% (34114/41600)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.010% (34221/41728)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.019% (34330/41856)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.000% (34427/41984)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.017% (34539/42112)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.003% (34638/42240)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.017% (34749/42368)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.012% (34852/42496)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.005% (34954/42624)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.013% (35062/42752)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.996% (35160/42880)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.989% (35262/43008)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.969% (35358/43136)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.976% (35466/43264)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.983% (35574/43392)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.997% (35685/43520)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.006% (35794/43648)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.004% (35898/43776)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.022% (36011/43904)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (36114/44032)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.024% (36222/44160)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (36321/44288)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.013% (36427/44416)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.029% (36539/44544)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (36636/44672)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.025% (36747/44800)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (36849/44928)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.020% (36955/45056)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.029% (37064/45184)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.022% (37166/45312)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.027% (37273/45440)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.027% (37378/45568)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.016% (37478/45696)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.029% (37589/45824)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.025% (37692/45952)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.029% (37799/46080)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.027% (37903/46208)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.025% (38007/46336)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.016% (38108/46464)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.018% (38214/46592)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.023% (38321/46720)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.004% (38417/46848)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.993% (38517/46976)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.995% (38623/47104)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.004% (38732/47232)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.000% (38835/47360)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.006% (38943/47488)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.004% (39047/47616)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.012% (39156/47744)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.998% (39254/47872)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 81.998% (39359/48000)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.000% (39465/48128)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.011% (39575/48256)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.027% (39688/48384)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.027% (39793/48512)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.033% (39901/48640)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.039% (40009/48768)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.039% (40114/48896)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.046% (40222/49024)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.052% (40330/49152)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.035% (40427/49280)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.051% (40540/49408)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.039% (40639/49536)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.031% (40740/49664)\n",
            "Train Epoch: 94 | Loss: 0.514 | Acc: 82.043% (40851/49792)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.051% (40960/49920)\n",
            "Train Epoch: 94 | Loss: 0.513 | Acc: 82.052% (41026/50000)\n",
            "Test Epoch: 94 | Loss: 0.592 | Acc: 79.000% (79/100)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.500% (153/200)\n",
            "Test Epoch: 94 | Loss: 0.689 | Acc: 76.333% (229/300)\n",
            "Test Epoch: 94 | Loss: 0.722 | Acc: 76.500% (306/400)\n",
            "Test Epoch: 94 | Loss: 0.708 | Acc: 77.200% (386/500)\n",
            "Test Epoch: 94 | Loss: 0.649 | Acc: 78.500% (471/600)\n",
            "Test Epoch: 94 | Loss: 0.648 | Acc: 78.286% (548/700)\n",
            "Test Epoch: 94 | Loss: 0.670 | Acc: 77.500% (620/800)\n",
            "Test Epoch: 94 | Loss: 0.677 | Acc: 77.556% (698/900)\n",
            "Test Epoch: 94 | Loss: 0.663 | Acc: 77.900% (779/1000)\n",
            "Test Epoch: 94 | Loss: 0.653 | Acc: 78.364% (862/1100)\n",
            "Test Epoch: 94 | Loss: 0.659 | Acc: 78.083% (937/1200)\n",
            "Test Epoch: 94 | Loss: 0.664 | Acc: 77.692% (1010/1300)\n",
            "Test Epoch: 94 | Loss: 0.670 | Acc: 77.429% (1084/1400)\n",
            "Test Epoch: 94 | Loss: 0.661 | Acc: 77.733% (1166/1500)\n",
            "Test Epoch: 94 | Loss: 0.677 | Acc: 77.562% (1241/1600)\n",
            "Test Epoch: 94 | Loss: 0.676 | Acc: 77.706% (1321/1700)\n",
            "Test Epoch: 94 | Loss: 0.675 | Acc: 77.389% (1393/1800)\n",
            "Test Epoch: 94 | Loss: 0.679 | Acc: 77.368% (1470/1900)\n",
            "Test Epoch: 94 | Loss: 0.701 | Acc: 76.500% (1530/2000)\n",
            "Test Epoch: 94 | Loss: 0.708 | Acc: 76.476% (1606/2100)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.500% (1683/2200)\n",
            "Test Epoch: 94 | Loss: 0.717 | Acc: 76.522% (1760/2300)\n",
            "Test Epoch: 94 | Loss: 0.714 | Acc: 76.500% (1836/2400)\n",
            "Test Epoch: 94 | Loss: 0.722 | Acc: 76.320% (1908/2500)\n",
            "Test Epoch: 94 | Loss: 0.736 | Acc: 76.269% (1983/2600)\n",
            "Test Epoch: 94 | Loss: 0.726 | Acc: 76.556% (2067/2700)\n",
            "Test Epoch: 94 | Loss: 0.726 | Acc: 76.643% (2146/2800)\n",
            "Test Epoch: 94 | Loss: 0.728 | Acc: 76.655% (2223/2900)\n",
            "Test Epoch: 94 | Loss: 0.722 | Acc: 76.733% (2302/3000)\n",
            "Test Epoch: 94 | Loss: 0.723 | Acc: 76.742% (2379/3100)\n",
            "Test Epoch: 94 | Loss: 0.721 | Acc: 76.656% (2453/3200)\n",
            "Test Epoch: 94 | Loss: 0.716 | Acc: 76.697% (2531/3300)\n",
            "Test Epoch: 94 | Loss: 0.721 | Acc: 76.647% (2606/3400)\n",
            "Test Epoch: 94 | Loss: 0.719 | Acc: 76.571% (2680/3500)\n",
            "Test Epoch: 94 | Loss: 0.718 | Acc: 76.583% (2757/3600)\n",
            "Test Epoch: 94 | Loss: 0.721 | Acc: 76.541% (2832/3700)\n",
            "Test Epoch: 94 | Loss: 0.723 | Acc: 76.474% (2906/3800)\n",
            "Test Epoch: 94 | Loss: 0.720 | Acc: 76.590% (2987/3900)\n",
            "Test Epoch: 94 | Loss: 0.722 | Acc: 76.575% (3063/4000)\n",
            "Test Epoch: 94 | Loss: 0.724 | Acc: 76.634% (3142/4100)\n",
            "Test Epoch: 94 | Loss: 0.724 | Acc: 76.690% (3221/4200)\n",
            "Test Epoch: 94 | Loss: 0.720 | Acc: 76.767% (3301/4300)\n",
            "Test Epoch: 94 | Loss: 0.718 | Acc: 76.841% (3381/4400)\n",
            "Test Epoch: 94 | Loss: 0.717 | Acc: 76.689% (3451/4500)\n",
            "Test Epoch: 94 | Loss: 0.718 | Acc: 76.587% (3523/4600)\n",
            "Test Epoch: 94 | Loss: 0.718 | Acc: 76.617% (3601/4700)\n",
            "Test Epoch: 94 | Loss: 0.720 | Acc: 76.646% (3679/4800)\n",
            "Test Epoch: 94 | Loss: 0.717 | Acc: 76.612% (3754/4900)\n",
            "Test Epoch: 94 | Loss: 0.719 | Acc: 76.600% (3830/5000)\n",
            "Test Epoch: 94 | Loss: 0.715 | Acc: 76.686% (3911/5100)\n",
            "Test Epoch: 94 | Loss: 0.715 | Acc: 76.673% (3987/5200)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.679% (4064/5300)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.685% (4141/5400)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.636% (4215/5500)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.643% (4292/5600)\n",
            "Test Epoch: 94 | Loss: 0.716 | Acc: 76.596% (4366/5700)\n",
            "Test Epoch: 94 | Loss: 0.712 | Acc: 76.672% (4447/5800)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.576% (4518/5900)\n",
            "Test Epoch: 94 | Loss: 0.715 | Acc: 76.500% (4590/6000)\n",
            "Test Epoch: 94 | Loss: 0.712 | Acc: 76.623% (4674/6100)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.581% (4748/6200)\n",
            "Test Epoch: 94 | Loss: 0.712 | Acc: 76.587% (4825/6300)\n",
            "Test Epoch: 94 | Loss: 0.708 | Acc: 76.750% (4912/6400)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.723% (4987/6500)\n",
            "Test Epoch: 94 | Loss: 0.712 | Acc: 76.682% (5061/6600)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.776% (5144/6700)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.676% (5214/6800)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.725% (5294/6900)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.671% (5367/7000)\n",
            "Test Epoch: 94 | Loss: 0.712 | Acc: 76.634% (5441/7100)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.681% (5521/7200)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.712% (5600/7300)\n",
            "Test Epoch: 94 | Loss: 0.707 | Acc: 76.770% (5681/7400)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.680% (5751/7500)\n",
            "Test Epoch: 94 | Loss: 0.708 | Acc: 76.724% (5831/7600)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.675% (5904/7700)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.577% (5973/7800)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.519% (6045/7900)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.537% (6123/8000)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.568% (6202/8100)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.610% (6282/8200)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.602% (6358/8300)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.607% (6435/8400)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.612% (6512/8500)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.674% (6594/8600)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.621% (6666/8700)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.602% (6741/8800)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.629% (6820/8900)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.633% (6897/9000)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.703% (6980/9100)\n",
            "Test Epoch: 94 | Loss: 0.707 | Acc: 76.804% (7066/9200)\n",
            "Test Epoch: 94 | Loss: 0.708 | Acc: 76.774% (7140/9300)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.713% (7211/9400)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.705% (7287/9500)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.729% (7366/9600)\n",
            "Test Epoch: 94 | Loss: 0.709 | Acc: 76.784% (7448/9700)\n",
            "Test Epoch: 94 | Loss: 0.710 | Acc: 76.735% (7520/9800)\n",
            "Test Epoch: 94 | Loss: 0.711 | Acc: 76.636% (7587/9900)\n",
            "Test Epoch: 94 | Loss: 0.713 | Acc: 76.630% (7663/10000)\n",
            "\n",
            "Epoch: 95\n",
            "Train Epoch: 95 | Loss: 0.479 | Acc: 83.594% (107/128)\n",
            "Train Epoch: 95 | Loss: 0.499 | Acc: 83.594% (214/256)\n",
            "Train Epoch: 95 | Loss: 0.507 | Acc: 84.115% (323/384)\n",
            "Train Epoch: 95 | Loss: 0.481 | Acc: 85.156% (436/512)\n",
            "Train Epoch: 95 | Loss: 0.480 | Acc: 84.688% (542/640)\n",
            "Train Epoch: 95 | Loss: 0.480 | Acc: 84.505% (649/768)\n",
            "Train Epoch: 95 | Loss: 0.481 | Acc: 84.487% (757/896)\n",
            "Train Epoch: 95 | Loss: 0.471 | Acc: 84.766% (868/1024)\n",
            "Train Epoch: 95 | Loss: 0.474 | Acc: 84.722% (976/1152)\n",
            "Train Epoch: 95 | Loss: 0.488 | Acc: 83.906% (1074/1280)\n",
            "Train Epoch: 95 | Loss: 0.493 | Acc: 83.594% (1177/1408)\n",
            "Train Epoch: 95 | Loss: 0.490 | Acc: 83.594% (1284/1536)\n",
            "Train Epoch: 95 | Loss: 0.491 | Acc: 83.594% (1391/1664)\n",
            "Train Epoch: 95 | Loss: 0.499 | Acc: 83.259% (1492/1792)\n",
            "Train Epoch: 95 | Loss: 0.502 | Acc: 83.073% (1595/1920)\n",
            "Train Epoch: 95 | Loss: 0.505 | Acc: 83.057% (1701/2048)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.675% (1799/2176)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.769% (1907/2304)\n",
            "Train Epoch: 95 | Loss: 0.508 | Acc: 82.895% (2016/2432)\n",
            "Train Epoch: 95 | Loss: 0.507 | Acc: 82.891% (2122/2560)\n",
            "Train Epoch: 95 | Loss: 0.504 | Acc: 83.073% (2233/2688)\n",
            "Train Epoch: 95 | Loss: 0.505 | Acc: 83.097% (2340/2816)\n",
            "Train Epoch: 95 | Loss: 0.505 | Acc: 82.982% (2443/2944)\n",
            "Train Epoch: 95 | Loss: 0.505 | Acc: 82.910% (2547/3072)\n",
            "Train Epoch: 95 | Loss: 0.499 | Acc: 83.125% (2660/3200)\n",
            "Train Epoch: 95 | Loss: 0.497 | Acc: 83.233% (2770/3328)\n",
            "Train Epoch: 95 | Loss: 0.498 | Acc: 83.073% (2871/3456)\n",
            "Train Epoch: 95 | Loss: 0.500 | Acc: 82.924% (2972/3584)\n",
            "Train Epoch: 95 | Loss: 0.500 | Acc: 83.055% (3083/3712)\n",
            "Train Epoch: 95 | Loss: 0.501 | Acc: 82.917% (3184/3840)\n",
            "Train Epoch: 95 | Loss: 0.501 | Acc: 82.964% (3292/3968)\n",
            "Train Epoch: 95 | Loss: 0.504 | Acc: 82.861% (3394/4096)\n",
            "Train Epoch: 95 | Loss: 0.508 | Acc: 82.694% (3493/4224)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.445% (3588/4352)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.500% (3696/4480)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.595% (3806/4608)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.622% (3913/4736)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.586% (4017/4864)\n",
            "Train Epoch: 95 | Loss: 0.509 | Acc: 82.612% (4124/4992)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.559% (4227/5120)\n",
            "Train Epoch: 95 | Loss: 0.509 | Acc: 82.679% (4339/5248)\n",
            "Train Epoch: 95 | Loss: 0.508 | Acc: 82.664% (4444/5376)\n",
            "Train Epoch: 95 | Loss: 0.509 | Acc: 82.649% (4549/5504)\n",
            "Train Epoch: 95 | Loss: 0.507 | Acc: 82.724% (4659/5632)\n",
            "Train Epoch: 95 | Loss: 0.508 | Acc: 82.674% (4762/5760)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.558% (4861/5888)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.480% (4962/6016)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.406% (5063/6144)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.414% (5169/6272)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.375% (5272/6400)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.276% (5371/6528)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.332% (5480/6656)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.208% (5577/6784)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.219% (5683/6912)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.244% (5790/7040)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.157% (5889/7168)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.155% (5994/7296)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.126% (6097/7424)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.190% (6207/7552)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.201% (6313/7680)\n",
            "Train Epoch: 95 | Loss: 0.519 | Acc: 82.121% (6412/7808)\n",
            "Train Epoch: 95 | Loss: 0.519 | Acc: 82.132% (6518/7936)\n",
            "Train Epoch: 95 | Loss: 0.520 | Acc: 82.118% (6622/8064)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.153% (6730/8192)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.200% (6839/8320)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.173% (6942/8448)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.171% (7047/8576)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.158% (7151/8704)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.167% (7257/8832)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.210% (7366/8960)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.196% (7470/9088)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.216% (7577/9216)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.235% (7684/9344)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.264% (7792/9472)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.302% (7901/9600)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.329% (8009/9728)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.244% (8106/9856)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.222% (8209/9984)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.170% (8309/10112)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.139% (8411/10240)\n",
            "Train Epoch: 95 | Loss: 0.519 | Acc: 82.089% (8511/10368)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.174% (8625/10496)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.229% (8736/10624)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.227% (8841/10752)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.252% (8949/10880)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.249% (9054/11008)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.247% (9159/11136)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.271% (9267/11264)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.251% (9370/11392)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.240% (9474/11520)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.246% (9580/11648)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.227% (9683/11776)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.224% (9788/11904)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.247% (9896/12032)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.237% (10000/12160)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.235% (10105/12288)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.208% (10207/12416)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.239% (10316/12544)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.260% (10424/12672)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.281% (10532/12800)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.333% (10644/12928)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.276% (10742/13056)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.228% (10841/13184)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.234% (10947/13312)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.247% (11054/13440)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.208% (11154/13568)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.228% (11262/13696)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.212% (11365/13824)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.218% (11471/13952)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.223% (11577/14080)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.179% (11676/14208)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.171% (11780/14336)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.197% (11889/14464)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.175% (11991/14592)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.147% (12092/14720)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.152% (12198/14848)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.138% (12301/14976)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.157% (12409/15104)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.156% (12514/15232)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.168% (12621/15360)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.186% (12729/15488)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.217% (12839/15616)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.209% (12943/15744)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.233% (13052/15872)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.244% (13159/16000)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.174% (13253/16128)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.197% (13362/16256)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.178% (13464/16384)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.134% (13562/16512)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.145% (13669/16640)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.079% (13763/16768)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.079% (13868/16896)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.014% (13962/17024)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.014% (14067/17152)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.043% (14177/17280)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.077% (14288/17408)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.048% (14388/17536)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.037% (14491/17664)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.065% (14601/17792)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.070% (14707/17920)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.081% (14814/18048)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.081% (14919/18176)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.059% (15020/18304)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.037% (15121/18432)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.058% (15230/18560)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.053% (15334/18688)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.037% (15436/18816)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.073% (15548/18944)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.042% (15647/19072)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.016% (15747/19200)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.047% (15858/19328)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.021% (15958/19456)\n",
            "Train Epoch: 95 | Loss: 0.518 | Acc: 82.011% (16061/19584)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.026% (16169/19712)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.026% (16274/19840)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.011% (16376/19968)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 81.991% (16477/20096)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 81.997% (16583/20224)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.017% (16692/20352)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.031% (16800/20480)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.056% (16910/20608)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.065% (17017/20736)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.065% (17122/20864)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.088% (17232/20992)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.088% (17337/21120)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.083% (17441/21248)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.064% (17542/21376)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.087% (17652/21504)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.068% (17753/21632)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.091% (17863/21760)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.104% (17971/21888)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.149% (18086/22016)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.131% (18187/22144)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.130% (18292/22272)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.121% (18395/22400)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.133% (18503/22528)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.128% (18607/22656)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.119% (18710/22784)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.079% (18806/22912)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.057% (18906/23040)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.074% (19015/23168)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.070% (19119/23296)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.065% (19223/23424)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.086% (19333/23552)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.090% (19439/23680)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.082% (19542/23808)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.073% (19645/23936)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.077% (19751/24064)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.102% (19862/24192)\n",
            "Train Epoch: 95 | Loss: 0.517 | Acc: 82.068% (19959/24320)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.093% (20070/24448)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.121% (20182/24576)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.100% (20282/24704)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.112% (20390/24832)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.135% (20501/24960)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.143% (20608/25088)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.130% (20710/25216)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.146% (20819/25344)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.161% (20928/25472)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.180% (21038/25600)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.191% (21146/25728)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.194% (21252/25856)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.177% (21353/25984)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.165% (21455/26112)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.191% (21567/26240)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.202% (21675/26368)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.224% (21786/26496)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.212% (21888/26624)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.192% (21988/26752)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.169% (22087/26880)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.183% (22196/27008)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.175% (22299/27136)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.178% (22405/27264)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.181% (22511/27392)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.162% (22611/27520)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.129% (22707/27648)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.118% (22809/27776)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.132% (22918/27904)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.138% (23025/28032)\n",
            "Train Epoch: 95 | Loss: 0.516 | Acc: 82.141% (23131/28160)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.151% (23239/28288)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.158% (23346/28416)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.161% (23452/28544)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.174% (23561/28672)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.160% (23662/28800)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.173% (23771/28928)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.165% (23874/29056)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.172% (23981/29184)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.161% (24083/29312)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.191% (24197/29440)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.183% (24300/29568)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.173% (24402/29696)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.189% (24512/29824)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.155% (24607/29952)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.168% (24716/30080)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.147% (24815/30208)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.157% (24923/30336)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.156% (25028/30464)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.162% (25135/30592)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.174% (25244/30720)\n",
            "Train Epoch: 95 | Loss: 0.515 | Acc: 82.167% (25347/30848)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.202% (25463/30976)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.211% (25571/31104)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.214% (25677/31232)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.223% (25785/31360)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.219% (25889/31488)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.224% (25996/31616)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.205% (26095/31744)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.201% (26199/31872)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.191% (26301/32000)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.174% (26401/32128)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.174% (26506/32256)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.161% (26607/32384)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.173% (26716/32512)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.191% (26827/32640)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.190% (26932/32768)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.168% (27030/32896)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.171% (27136/33024)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.170% (27241/33152)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.181% (27350/33280)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.178% (27454/33408)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.183% (27561/33536)\n",
            "Train Epoch: 95 | Loss: 0.514 | Acc: 82.177% (27664/33664)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.194% (27775/33792)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.199% (27882/33920)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.193% (27985/34048)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.192% (28090/34176)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.194% (28196/34304)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.182% (28297/34432)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.193% (28406/34560)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.190% (28510/34688)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.192% (28616/34816)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.197% (28723/34944)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.205% (28831/35072)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.196% (28933/35200)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.193% (29037/35328)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.178% (29137/35456)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.183% (29244/35584)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.168% (29344/35712)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.154% (29444/35840)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.162% (29552/35968)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.167% (29659/36096)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.158% (29761/36224)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.147% (29862/36352)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.146% (29967/36480)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.151% (30074/36608)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.154% (30180/36736)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.134% (30278/36864)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.139% (30385/36992)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.120% (30483/37120)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.123% (30589/37248)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.112% (30690/37376)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.117% (30797/37504)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.106% (30898/37632)\n",
            "Train Epoch: 95 | Loss: 0.513 | Acc: 82.113% (31006/37760)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.116% (31112/37888)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.134% (31224/38016)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.141% (31332/38144)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.136% (31435/38272)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.146% (31544/38400)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.161% (31655/38528)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.199% (31775/38656)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.181% (31873/38784)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.170% (31974/38912)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.180% (32083/39040)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.164% (32182/39168)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.166% (32288/39296)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.166% (32393/39424)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.168% (32499/39552)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.170% (32605/39680)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.172% (32711/39808)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.176% (32818/39936)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.179% (32924/40064)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.178% (33029/40192)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.163% (33128/40320)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.143% (33225/40448)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.145% (33331/40576)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.142% (33435/40704)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.154% (33545/40832)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.144% (33646/40960)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.138% (33749/41088)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.133% (33852/41216)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.138% (33959/41344)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.145% (34067/41472)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.142% (34171/41600)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.139% (34275/41728)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.134% (34378/41856)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.141% (34486/41984)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.150% (34595/42112)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.154% (34702/42240)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.175% (34816/42368)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.165% (34917/42496)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.177% (35027/42624)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.186% (35136/42752)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.181% (35239/42880)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.180% (35344/43008)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.187% (35452/43136)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.188% (35558/43264)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.188% (35663/43392)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.178% (35764/43520)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.196% (35877/43648)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.198% (35983/43776)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.204% (36091/43904)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.204% (36196/44032)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.206% (36302/44160)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.205% (36407/44288)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.202% (36511/44416)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.193% (36612/44544)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.199% (36720/44672)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.205% (36828/44800)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.209% (36935/44928)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.204% (37038/45056)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.217% (37149/45184)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.210% (37251/45312)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.199% (37351/45440)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.200% (37457/45568)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.209% (37566/45696)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.212% (37673/45824)\n",
            "Train Epoch: 95 | Loss: 0.510 | Acc: 82.194% (37770/45952)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.168% (37863/46080)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.163% (37966/46208)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.148% (38064/46336)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.145% (38168/46464)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.143% (38272/46592)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.119% (38366/46720)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.108% (38466/46848)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.110% (38572/46976)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.112% (38678/47104)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.114% (38784/47232)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.114% (38889/47360)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.109% (38992/47488)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.115% (39100/47616)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.123% (39209/47744)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.136% (39320/47872)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.133% (39424/48000)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.123% (39524/48128)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.118% (39627/48256)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.128% (39737/48384)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.141% (39848/48512)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.138% (39952/48640)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.138% (40057/48768)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.127% (40157/48896)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.139% (40268/49024)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.131% (40369/49152)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.131% (40474/49280)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.128% (40578/49408)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.136% (40687/49536)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.144% (40796/49664)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.150% (40904/49792)\n",
            "Train Epoch: 95 | Loss: 0.511 | Acc: 82.157% (41013/49920)\n",
            "Train Epoch: 95 | Loss: 0.512 | Acc: 82.154% (41077/50000)\n",
            "Test Epoch: 95 | Loss: 0.567 | Acc: 79.000% (79/100)\n",
            "Test Epoch: 95 | Loss: 0.715 | Acc: 75.500% (151/200)\n",
            "Test Epoch: 95 | Loss: 0.698 | Acc: 76.333% (229/300)\n",
            "Test Epoch: 95 | Loss: 0.718 | Acc: 76.500% (306/400)\n",
            "Test Epoch: 95 | Loss: 0.688 | Acc: 77.000% (385/500)\n",
            "Test Epoch: 95 | Loss: 0.634 | Acc: 78.667% (472/600)\n",
            "Test Epoch: 95 | Loss: 0.629 | Acc: 78.571% (550/700)\n",
            "Test Epoch: 95 | Loss: 0.650 | Acc: 77.875% (623/800)\n",
            "Test Epoch: 95 | Loss: 0.658 | Acc: 77.667% (699/900)\n",
            "Test Epoch: 95 | Loss: 0.646 | Acc: 78.000% (780/1000)\n",
            "Test Epoch: 95 | Loss: 0.636 | Acc: 78.273% (861/1100)\n",
            "Test Epoch: 95 | Loss: 0.639 | Acc: 78.167% (938/1200)\n",
            "Test Epoch: 95 | Loss: 0.643 | Acc: 77.615% (1009/1300)\n",
            "Test Epoch: 95 | Loss: 0.646 | Acc: 77.714% (1088/1400)\n",
            "Test Epoch: 95 | Loss: 0.638 | Acc: 78.133% (1172/1500)\n",
            "Test Epoch: 95 | Loss: 0.653 | Acc: 77.750% (1244/1600)\n",
            "Test Epoch: 95 | Loss: 0.648 | Acc: 77.765% (1322/1700)\n",
            "Test Epoch: 95 | Loss: 0.646 | Acc: 77.722% (1399/1800)\n",
            "Test Epoch: 95 | Loss: 0.647 | Acc: 77.895% (1480/1900)\n",
            "Test Epoch: 95 | Loss: 0.670 | Acc: 77.100% (1542/2000)\n",
            "Test Epoch: 95 | Loss: 0.679 | Acc: 77.000% (1617/2100)\n",
            "Test Epoch: 95 | Loss: 0.682 | Acc: 77.136% (1697/2200)\n",
            "Test Epoch: 95 | Loss: 0.692 | Acc: 77.087% (1773/2300)\n",
            "Test Epoch: 95 | Loss: 0.690 | Acc: 77.000% (1848/2400)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 76.920% (1923/2500)\n",
            "Test Epoch: 95 | Loss: 0.716 | Acc: 76.615% (1992/2600)\n",
            "Test Epoch: 95 | Loss: 0.708 | Acc: 76.778% (2073/2700)\n",
            "Test Epoch: 95 | Loss: 0.708 | Acc: 76.893% (2153/2800)\n",
            "Test Epoch: 95 | Loss: 0.711 | Acc: 76.862% (2229/2900)\n",
            "Test Epoch: 95 | Loss: 0.706 | Acc: 76.933% (2308/3000)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 76.968% (2386/3100)\n",
            "Test Epoch: 95 | Loss: 0.706 | Acc: 76.781% (2457/3200)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 76.848% (2536/3300)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 76.794% (2611/3400)\n",
            "Test Epoch: 95 | Loss: 0.708 | Acc: 76.657% (2683/3500)\n",
            "Test Epoch: 95 | Loss: 0.708 | Acc: 76.611% (2758/3600)\n",
            "Test Epoch: 95 | Loss: 0.711 | Acc: 76.622% (2835/3700)\n",
            "Test Epoch: 95 | Loss: 0.713 | Acc: 76.632% (2912/3800)\n",
            "Test Epoch: 95 | Loss: 0.712 | Acc: 76.718% (2992/3900)\n",
            "Test Epoch: 95 | Loss: 0.712 | Acc: 76.700% (3068/4000)\n",
            "Test Epoch: 95 | Loss: 0.714 | Acc: 76.683% (3144/4100)\n",
            "Test Epoch: 95 | Loss: 0.714 | Acc: 76.762% (3224/4200)\n",
            "Test Epoch: 95 | Loss: 0.709 | Acc: 76.977% (3310/4300)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 77.068% (3391/4400)\n",
            "Test Epoch: 95 | Loss: 0.706 | Acc: 77.044% (3467/4500)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 77.065% (3545/4600)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 77.064% (3622/4700)\n",
            "Test Epoch: 95 | Loss: 0.707 | Acc: 77.125% (3702/4800)\n",
            "Test Epoch: 95 | Loss: 0.704 | Acc: 77.122% (3779/4900)\n",
            "Test Epoch: 95 | Loss: 0.706 | Acc: 77.060% (3853/5000)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.157% (3935/5100)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.173% (4013/5200)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.245% (4094/5300)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.241% (4171/5400)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.273% (4250/5500)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.179% (4322/5600)\n",
            "Test Epoch: 95 | Loss: 0.704 | Acc: 77.140% (4397/5700)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.259% (4481/5800)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.169% (4553/5900)\n",
            "Test Epoch: 95 | Loss: 0.704 | Acc: 77.117% (4627/6000)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.230% (4711/6100)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.226% (4788/6200)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.254% (4867/6300)\n",
            "Test Epoch: 95 | Loss: 0.698 | Acc: 77.375% (4952/6400)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.354% (5028/6500)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.333% (5104/6600)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.388% (5185/6700)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.309% (5257/6800)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.333% (5336/6900)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.229% (5406/7000)\n",
            "Test Epoch: 95 | Loss: 0.703 | Acc: 77.239% (5484/7100)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.306% (5566/7200)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.370% (5648/7300)\n",
            "Test Epoch: 95 | Loss: 0.697 | Acc: 77.419% (5729/7400)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.347% (5801/7500)\n",
            "Test Epoch: 95 | Loss: 0.698 | Acc: 77.408% (5883/7600)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.338% (5955/7700)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.256% (6026/7800)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.241% (6102/7900)\n",
            "Test Epoch: 95 | Loss: 0.703 | Acc: 77.263% (6181/8000)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.259% (6258/8100)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.280% (6337/8200)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.265% (6413/8300)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.238% (6488/8400)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.259% (6567/8500)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.279% (6646/8600)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.195% (6716/8700)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.193% (6793/8800)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.169% (6868/8900)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.222% (6950/9000)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.319% (7036/9100)\n",
            "Test Epoch: 95 | Loss: 0.697 | Acc: 77.391% (7120/9200)\n",
            "Test Epoch: 95 | Loss: 0.699 | Acc: 77.387% (7197/9300)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.340% (7270/9400)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.337% (7347/9500)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.354% (7426/9600)\n",
            "Test Epoch: 95 | Loss: 0.700 | Acc: 77.392% (7507/9700)\n",
            "Test Epoch: 95 | Loss: 0.701 | Acc: 77.296% (7575/9800)\n",
            "Test Epoch: 95 | Loss: 0.702 | Acc: 77.232% (7646/9900)\n",
            "Test Epoch: 95 | Loss: 0.703 | Acc: 77.230% (7723/10000)\n",
            "\n",
            "Epoch: 96\n",
            "Train Epoch: 96 | Loss: 0.586 | Acc: 76.562% (98/128)\n",
            "Train Epoch: 96 | Loss: 0.561 | Acc: 78.125% (200/256)\n",
            "Train Epoch: 96 | Loss: 0.522 | Acc: 80.729% (310/384)\n",
            "Train Epoch: 96 | Loss: 0.559 | Acc: 80.078% (410/512)\n",
            "Train Epoch: 96 | Loss: 0.577 | Acc: 80.156% (513/640)\n",
            "Train Epoch: 96 | Loss: 0.559 | Acc: 80.729% (620/768)\n",
            "Train Epoch: 96 | Loss: 0.543 | Acc: 81.027% (726/896)\n",
            "Train Epoch: 96 | Loss: 0.526 | Acc: 81.934% (839/1024)\n",
            "Train Epoch: 96 | Loss: 0.523 | Acc: 81.944% (944/1152)\n",
            "Train Epoch: 96 | Loss: 0.530 | Acc: 81.484% (1043/1280)\n",
            "Train Epoch: 96 | Loss: 0.530 | Acc: 81.534% (1148/1408)\n",
            "Train Epoch: 96 | Loss: 0.540 | Acc: 81.315% (1249/1536)\n",
            "Train Epoch: 96 | Loss: 0.534 | Acc: 81.550% (1357/1664)\n",
            "Train Epoch: 96 | Loss: 0.532 | Acc: 81.752% (1465/1792)\n",
            "Train Epoch: 96 | Loss: 0.538 | Acc: 81.406% (1563/1920)\n",
            "Train Epoch: 96 | Loss: 0.534 | Acc: 81.689% (1673/2048)\n",
            "Train Epoch: 96 | Loss: 0.531 | Acc: 81.526% (1774/2176)\n",
            "Train Epoch: 96 | Loss: 0.531 | Acc: 81.554% (1879/2304)\n",
            "Train Epoch: 96 | Loss: 0.538 | Acc: 81.373% (1979/2432)\n",
            "Train Epoch: 96 | Loss: 0.541 | Acc: 81.250% (2080/2560)\n",
            "Train Epoch: 96 | Loss: 0.534 | Acc: 81.548% (2192/2688)\n",
            "Train Epoch: 96 | Loss: 0.539 | Acc: 81.321% (2290/2816)\n",
            "Train Epoch: 96 | Loss: 0.542 | Acc: 81.284% (2393/2944)\n",
            "Train Epoch: 96 | Loss: 0.537 | Acc: 81.576% (2506/3072)\n",
            "Train Epoch: 96 | Loss: 0.533 | Acc: 81.750% (2616/3200)\n",
            "Train Epoch: 96 | Loss: 0.529 | Acc: 81.821% (2723/3328)\n",
            "Train Epoch: 96 | Loss: 0.531 | Acc: 81.800% (2827/3456)\n",
            "Train Epoch: 96 | Loss: 0.531 | Acc: 81.948% (2937/3584)\n",
            "Train Epoch: 96 | Loss: 0.532 | Acc: 81.816% (3037/3712)\n",
            "Train Epoch: 96 | Loss: 0.534 | Acc: 81.719% (3138/3840)\n",
            "Train Epoch: 96 | Loss: 0.533 | Acc: 81.830% (3247/3968)\n",
            "Train Epoch: 96 | Loss: 0.531 | Acc: 81.885% (3354/4096)\n",
            "Train Epoch: 96 | Loss: 0.528 | Acc: 82.055% (3466/4224)\n",
            "Train Epoch: 96 | Loss: 0.527 | Acc: 82.146% (3575/4352)\n",
            "Train Epoch: 96 | Loss: 0.528 | Acc: 81.942% (3671/4480)\n",
            "Train Epoch: 96 | Loss: 0.525 | Acc: 82.053% (3781/4608)\n",
            "Train Epoch: 96 | Loss: 0.523 | Acc: 82.095% (3888/4736)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.216% (3999/4864)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.272% (4107/4992)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.344% (4216/5120)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.470% (4328/5248)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.478% (4434/5376)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.485% (4540/5504)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.422% (4642/5632)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.465% (4750/5760)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.371% (4850/5888)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.447% (4960/6016)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.389% (5062/6144)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.430% (5170/6272)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.391% (5273/6400)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.399% (5379/6528)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.497% (5491/6656)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.606% (5604/6784)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.552% (5706/6912)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.528% (5810/7040)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.575% (5919/7168)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.497% (6019/7296)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.557% (6129/7424)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.415% (6224/7552)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.409% (6329/7680)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.428% (6436/7808)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.422% (6541/7936)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.440% (6648/8064)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.385% (6749/8192)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.308% (6848/8320)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.351% (6957/8448)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.346% (7062/8576)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.422% (7174/8704)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.416% (7279/8832)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.467% (7389/8960)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.504% (7498/9088)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.530% (7606/9216)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.577% (7716/9344)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.580% (7822/9472)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.562% (7926/9600)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.504% (8026/9728)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.528% (8134/9856)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.482% (8235/9984)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.476% (8340/10112)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.461% (8444/10240)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.417% (8545/10368)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.422% (8651/10496)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.417% (8756/10624)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.385% (8858/10752)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.335% (8958/10880)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.367% (9067/11008)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.390% (9175/11136)\n",
            "Train Epoch: 96 | Loss: 0.521 | Acc: 82.280% (9268/11264)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.295% (9375/11392)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.318% (9483/11520)\n",
            "Train Epoch: 96 | Loss: 0.519 | Acc: 82.366% (9594/11648)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.303% (9692/11776)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.300% (9797/11904)\n",
            "Train Epoch: 96 | Loss: 0.520 | Acc: 82.372% (9911/12032)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.410% (10021/12160)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.446% (10131/12288)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.434% (10235/12416)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.398% (10336/12544)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.394% (10441/12672)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.422% (10550/12800)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.410% (10654/12928)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.460% (10766/13056)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.456% (10871/13184)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.482% (10980/13312)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.500% (11088/13440)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.510% (11195/13568)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.455% (11293/13696)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.451% (11398/13824)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.425% (11500/13952)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.415% (11604/14080)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.454% (11715/14208)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.471% (11823/14336)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.501% (11933/14464)\n",
            "Train Epoch: 96 | Loss: 0.518 | Acc: 82.436% (12029/14592)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.486% (12142/14720)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.523% (12253/14848)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.519% (12358/14976)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.541% (12467/15104)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.537% (12572/15232)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.487% (12670/15360)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.438% (12768/15488)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.415% (12870/15616)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.406% (12974/15744)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.384% (13076/15872)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.344% (13175/16000)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.316% (13276/16128)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.314% (13381/16256)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.336% (13490/16384)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.376% (13602/16512)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.392% (13710/16640)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.401% (13817/16768)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.404% (13923/16896)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.372% (14023/17024)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.387% (14131/17152)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.396% (14238/17280)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.347% (14335/17408)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.311% (14434/17536)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.337% (14544/17664)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.335% (14649/17792)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.299% (14748/17920)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.325% (14858/18048)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.334% (14965/18176)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.299% (15064/18304)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.308% (15171/18432)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.295% (15274/18560)\n",
            "Train Epoch: 96 | Loss: 0.517 | Acc: 82.315% (15383/18688)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.318% (15489/18816)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.306% (15592/18944)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.304% (15697/19072)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.286% (15799/19200)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.280% (15903/19328)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.293% (16011/19456)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.292% (16116/19584)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.320% (16227/19712)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.308% (16330/19840)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.312% (16436/19968)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.305% (16540/20096)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.288% (16642/20224)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.311% (16752/20352)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.319% (16859/20480)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.318% (16964/20608)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.282% (17062/20736)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.295% (17170/20864)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.279% (17272/20992)\n",
            "Train Epoch: 96 | Loss: 0.516 | Acc: 82.263% (17374/21120)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.276% (17482/21248)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.303% (17593/21376)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.320% (17702/21504)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.304% (17804/21632)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.289% (17906/21760)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.241% (18001/21888)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.254% (18109/22016)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.271% (18218/22144)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.233% (18315/22272)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.210% (18415/22400)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.213% (18521/22528)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.208% (18625/22656)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.176% (18723/22784)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.210% (18836/22912)\n",
            "Train Epoch: 96 | Loss: 0.515 | Acc: 82.214% (18942/23040)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.225% (19050/23168)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.224% (19155/23296)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.232% (19262/23424)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.239% (19369/23552)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.242% (19475/23680)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.262% (19585/23808)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.261% (19690/23936)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.276% (19799/24064)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.300% (19910/24192)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.294% (20014/24320)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.301% (20121/24448)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.292% (20224/24576)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.274% (20325/24704)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.293% (20435/24832)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.292% (20540/24960)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.290% (20645/25088)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.273% (20746/25216)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.280% (20853/25344)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.267% (20955/25472)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.262% (21059/25600)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.261% (21164/25728)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.275% (21273/25856)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.285% (21381/25984)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.322% (21496/26112)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.348% (21608/26240)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.342% (21712/26368)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.337% (21816/26496)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.339% (21922/26624)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.330% (22025/26752)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.318% (22127/26880)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.320% (22233/27008)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.293% (22331/27136)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.251% (22425/27264)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.254% (22531/27392)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.249% (22635/27520)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.255% (22742/27648)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.258% (22848/27776)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.225% (22944/27904)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.238% (23053/28032)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.234% (23157/28160)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.212% (23256/28288)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.239% (23369/28416)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.227% (23471/28544)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.230% (23577/28672)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.240% (23685/28800)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.246% (23792/28928)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.227% (23892/29056)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.196% (23988/29184)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.209% (24097/29312)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.208% (24202/29440)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.207% (24307/29568)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.193% (24408/29696)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.209% (24518/29824)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.222% (24627/29952)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.227% (24734/30080)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.207% (24833/30208)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.196% (24935/30336)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.199% (25041/30464)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.208% (25149/30592)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.197% (25251/30720)\n",
            "Train Epoch: 96 | Loss: 0.514 | Acc: 82.197% (25356/30848)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.189% (25459/30976)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.186% (25563/31104)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.191% (25670/31232)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.216% (25783/31360)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.209% (25886/31488)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.189% (25985/31616)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.192% (26091/31744)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.198% (26198/31872)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.197% (26303/32000)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.199% (26409/32128)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.202% (26515/32256)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.213% (26624/32384)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.225% (26733/32512)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.233% (26841/32640)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.214% (26940/32768)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.214% (27045/32896)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.195% (27144/33024)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.200% (27251/33152)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.206% (27358/33280)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.223% (27469/33408)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.228% (27576/33536)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.254% (27690/33664)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.256% (27796/33792)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.252% (27900/33920)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.243% (28002/34048)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.248% (28109/34176)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.250% (28215/34304)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.249% (28320/34432)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.280% (28436/34560)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.291% (28545/34688)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.307% (28656/34816)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.329% (28769/34944)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.316% (28870/35072)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.310% (28973/35200)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.306% (29077/35328)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.319% (29187/35456)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.298% (29285/35584)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.314% (29396/35712)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.291% (29493/35840)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.287% (29597/35968)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.300% (29707/36096)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.313% (29817/36224)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.306% (29920/36352)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.292% (30020/36480)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.302% (30129/36608)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.293% (30231/36736)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.319% (30346/36864)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.310% (30448/36992)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.276% (30541/37120)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.276% (30646/37248)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.259% (30745/37376)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.261% (30851/37504)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.262% (30957/37632)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.275% (31067/37760)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.287% (31177/37888)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.257% (31271/38016)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.275% (31383/38144)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.277% (31489/38272)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.271% (31592/38400)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.283% (31702/38528)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.285% (31808/38656)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.276% (31910/38784)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.281% (32017/38912)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.262% (32115/39040)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.264% (32221/39168)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.265% (32327/39296)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.275% (32436/39424)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.254% (32533/39552)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.251% (32637/39680)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.235% (32736/39808)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.239% (32843/39936)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.233% (32946/40064)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.228% (33049/40192)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.225% (33153/40320)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.209% (33252/40448)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.209% (33357/40576)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.223% (33468/40704)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.235% (33578/40832)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.222% (33678/40960)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.216% (33781/41088)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.230% (33892/41216)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.227% (33996/41344)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.239% (34106/41472)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.233% (34209/41600)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.235% (34315/41728)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.249% (34426/41856)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.246% (34530/41984)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.245% (34635/42112)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.237% (34737/42240)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.241% (34844/42368)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.252% (34954/42496)\n",
            "Train Epoch: 96 | Loss: 0.511 | Acc: 82.233% (35051/42624)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.218% (35150/42752)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.215% (35254/42880)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.217% (35360/43008)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.231% (35471/43136)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.230% (35576/43264)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.223% (35678/43392)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.215% (35780/43520)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.217% (35886/43648)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.219% (35992/43776)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.229% (36102/43904)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.229% (36207/44032)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.228% (36312/44160)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.216% (36412/44288)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.214% (36516/44416)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.209% (36619/44544)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.213% (36726/44672)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.221% (36835/44800)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.212% (36936/44928)\n",
            "Train Epoch: 96 | Loss: 0.513 | Acc: 82.207% (37039/45056)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.239% (37159/45184)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.250% (37269/45312)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.249% (37374/45440)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.249% (37479/45568)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.248% (37584/45696)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.245% (37688/45824)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.260% (37800/45952)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.250% (37901/46080)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.243% (38003/46208)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.243% (38108/46336)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.255% (38219/46464)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.248% (38321/46592)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.241% (38423/46720)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.243% (38529/46848)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.255% (38640/46976)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.256% (38746/47104)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.247% (38847/47232)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.268% (38962/47360)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.248% (39058/47488)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.256% (39167/47616)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.260% (39274/47744)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.263% (39381/47872)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.252% (39481/48000)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.245% (39583/48128)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.251% (39691/48256)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.242% (39792/48384)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.246% (39899/48512)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.241% (40002/48640)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.247% (40110/48768)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.246% (40215/48896)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.250% (40322/49024)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.249% (40427/49152)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.248% (40532/49280)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.256% (40641/49408)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.255% (40746/49536)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.253% (40850/49664)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.248% (40953/49792)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.264% (41066/49920)\n",
            "Train Epoch: 96 | Loss: 0.512 | Acc: 82.260% (41130/50000)\n",
            "Test Epoch: 96 | Loss: 0.554 | Acc: 80.000% (80/100)\n",
            "Test Epoch: 96 | Loss: 0.701 | Acc: 77.000% (154/200)\n",
            "Test Epoch: 96 | Loss: 0.675 | Acc: 78.000% (234/300)\n",
            "Test Epoch: 96 | Loss: 0.707 | Acc: 78.250% (313/400)\n",
            "Test Epoch: 96 | Loss: 0.691 | Acc: 78.200% (391/500)\n",
            "Test Epoch: 96 | Loss: 0.635 | Acc: 79.333% (476/600)\n",
            "Test Epoch: 96 | Loss: 0.635 | Acc: 79.000% (553/700)\n",
            "Test Epoch: 96 | Loss: 0.652 | Acc: 78.625% (629/800)\n",
            "Test Epoch: 96 | Loss: 0.661 | Acc: 78.222% (704/900)\n",
            "Test Epoch: 96 | Loss: 0.649 | Acc: 78.000% (780/1000)\n",
            "Test Epoch: 96 | Loss: 0.636 | Acc: 78.545% (864/1100)\n",
            "Test Epoch: 96 | Loss: 0.638 | Acc: 78.417% (941/1200)\n",
            "Test Epoch: 96 | Loss: 0.643 | Acc: 78.308% (1018/1300)\n",
            "Test Epoch: 96 | Loss: 0.647 | Acc: 78.143% (1094/1400)\n",
            "Test Epoch: 96 | Loss: 0.640 | Acc: 78.267% (1174/1500)\n",
            "Test Epoch: 96 | Loss: 0.654 | Acc: 78.062% (1249/1600)\n",
            "Test Epoch: 96 | Loss: 0.648 | Acc: 78.176% (1329/1700)\n",
            "Test Epoch: 96 | Loss: 0.646 | Acc: 78.222% (1408/1800)\n",
            "Test Epoch: 96 | Loss: 0.647 | Acc: 78.368% (1489/1900)\n",
            "Test Epoch: 96 | Loss: 0.668 | Acc: 77.650% (1553/2000)\n",
            "Test Epoch: 96 | Loss: 0.675 | Acc: 77.524% (1628/2100)\n",
            "Test Epoch: 96 | Loss: 0.678 | Acc: 77.545% (1706/2200)\n",
            "Test Epoch: 96 | Loss: 0.689 | Acc: 77.478% (1782/2300)\n",
            "Test Epoch: 96 | Loss: 0.687 | Acc: 77.417% (1858/2400)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.200% (1930/2500)\n",
            "Test Epoch: 96 | Loss: 0.712 | Acc: 77.000% (2002/2600)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.333% (2088/2700)\n",
            "Test Epoch: 96 | Loss: 0.704 | Acc: 77.357% (2166/2800)\n",
            "Test Epoch: 96 | Loss: 0.706 | Acc: 77.379% (2244/2900)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.433% (2323/3000)\n",
            "Test Epoch: 96 | Loss: 0.704 | Acc: 77.419% (2400/3100)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.312% (2474/3200)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.424% (2555/3300)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.324% (2629/3400)\n",
            "Test Epoch: 96 | Loss: 0.705 | Acc: 77.143% (2700/3500)\n",
            "Test Epoch: 96 | Loss: 0.704 | Acc: 77.056% (2774/3600)\n",
            "Test Epoch: 96 | Loss: 0.709 | Acc: 77.054% (2851/3700)\n",
            "Test Epoch: 96 | Loss: 0.711 | Acc: 76.974% (2925/3800)\n",
            "Test Epoch: 96 | Loss: 0.709 | Acc: 76.974% (3002/3900)\n",
            "Test Epoch: 96 | Loss: 0.710 | Acc: 76.975% (3079/4000)\n",
            "Test Epoch: 96 | Loss: 0.712 | Acc: 77.024% (3158/4100)\n",
            "Test Epoch: 96 | Loss: 0.712 | Acc: 77.095% (3238/4200)\n",
            "Test Epoch: 96 | Loss: 0.708 | Acc: 77.209% (3320/4300)\n",
            "Test Epoch: 96 | Loss: 0.705 | Acc: 77.341% (3403/4400)\n",
            "Test Epoch: 96 | Loss: 0.704 | Acc: 77.244% (3476/4500)\n",
            "Test Epoch: 96 | Loss: 0.705 | Acc: 77.196% (3551/4600)\n",
            "Test Epoch: 96 | Loss: 0.705 | Acc: 77.149% (3626/4700)\n",
            "Test Epoch: 96 | Loss: 0.707 | Acc: 77.188% (3705/4800)\n",
            "Test Epoch: 96 | Loss: 0.704 | Acc: 77.265% (3786/4900)\n",
            "Test Epoch: 96 | Loss: 0.706 | Acc: 77.240% (3862/5000)\n",
            "Test Epoch: 96 | Loss: 0.702 | Acc: 77.314% (3943/5100)\n",
            "Test Epoch: 96 | Loss: 0.702 | Acc: 77.269% (4018/5200)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.245% (4094/5300)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.296% (4174/5400)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.291% (4251/5500)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.304% (4329/5600)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.316% (4407/5700)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.448% (4492/5800)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.356% (4564/5900)\n",
            "Test Epoch: 96 | Loss: 0.703 | Acc: 77.267% (4636/6000)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.393% (4721/6100)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.403% (4799/6200)\n",
            "Test Epoch: 96 | Loss: 0.701 | Acc: 77.413% (4877/6300)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.562% (4964/6400)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.554% (5041/6500)\n",
            "Test Epoch: 96 | Loss: 0.701 | Acc: 77.530% (5117/6600)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.582% (5198/6700)\n",
            "Test Epoch: 96 | Loss: 0.700 | Acc: 77.500% (5270/6800)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.536% (5350/6900)\n",
            "Test Epoch: 96 | Loss: 0.701 | Acc: 77.429% (5420/7000)\n",
            "Test Epoch: 96 | Loss: 0.701 | Acc: 77.394% (5495/7100)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.486% (5579/7200)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.589% (5664/7300)\n",
            "Test Epoch: 96 | Loss: 0.694 | Acc: 77.662% (5747/7400)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.600% (5820/7500)\n",
            "Test Epoch: 96 | Loss: 0.694 | Acc: 77.658% (5902/7600)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.610% (5976/7700)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.526% (6047/7800)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.481% (6121/7900)\n",
            "Test Epoch: 96 | Loss: 0.699 | Acc: 77.475% (6198/8000)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.494% (6277/8100)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.512% (6356/8200)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.494% (6432/8300)\n",
            "Test Epoch: 96 | Loss: 0.695 | Acc: 77.524% (6512/8400)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.541% (6591/8500)\n",
            "Test Epoch: 96 | Loss: 0.695 | Acc: 77.535% (6668/8600)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.506% (6743/8700)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.511% (6821/8800)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.528% (6900/8900)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.533% (6978/9000)\n",
            "Test Epoch: 96 | Loss: 0.695 | Acc: 77.615% (7063/9100)\n",
            "Test Epoch: 96 | Loss: 0.693 | Acc: 77.685% (7147/9200)\n",
            "Test Epoch: 96 | Loss: 0.694 | Acc: 77.624% (7219/9300)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.574% (7292/9400)\n",
            "Test Epoch: 96 | Loss: 0.695 | Acc: 77.589% (7371/9500)\n",
            "Test Epoch: 96 | Loss: 0.695 | Acc: 77.635% (7453/9600)\n",
            "Test Epoch: 96 | Loss: 0.694 | Acc: 77.670% (7534/9700)\n",
            "Test Epoch: 96 | Loss: 0.696 | Acc: 77.612% (7606/9800)\n",
            "Test Epoch: 96 | Loss: 0.697 | Acc: 77.566% (7679/9900)\n",
            "Test Epoch: 96 | Loss: 0.698 | Acc: 77.540% (7754/10000)\n",
            "Saving..\n",
            "\n",
            "Epoch: 97\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 79.688% (102/128)\n",
            "Train Epoch: 97 | Loss: 0.515 | Acc: 78.906% (202/256)\n",
            "Train Epoch: 97 | Loss: 0.489 | Acc: 80.469% (309/384)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 81.055% (415/512)\n",
            "Train Epoch: 97 | Loss: 0.489 | Acc: 80.781% (517/640)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 81.120% (623/768)\n",
            "Train Epoch: 97 | Loss: 0.519 | Acc: 80.915% (725/896)\n",
            "Train Epoch: 97 | Loss: 0.509 | Acc: 81.445% (834/1024)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 81.597% (940/1152)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 81.406% (1042/1280)\n",
            "Train Epoch: 97 | Loss: 0.495 | Acc: 81.818% (1152/1408)\n",
            "Train Epoch: 97 | Loss: 0.487 | Acc: 82.292% (1264/1536)\n",
            "Train Epoch: 97 | Loss: 0.488 | Acc: 82.212% (1368/1664)\n",
            "Train Epoch: 97 | Loss: 0.485 | Acc: 82.310% (1475/1792)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.188% (1578/1920)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.178% (1683/2048)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.169% (1788/2176)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.292% (1896/2304)\n",
            "Train Epoch: 97 | Loss: 0.505 | Acc: 82.072% (1996/2432)\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 81.875% (2096/2560)\n",
            "Train Epoch: 97 | Loss: 0.507 | Acc: 82.106% (2207/2688)\n",
            "Train Epoch: 97 | Loss: 0.506 | Acc: 82.280% (2317/2816)\n",
            "Train Epoch: 97 | Loss: 0.514 | Acc: 82.031% (2415/2944)\n",
            "Train Epoch: 97 | Loss: 0.511 | Acc: 82.129% (2523/3072)\n",
            "Train Epoch: 97 | Loss: 0.516 | Acc: 82.000% (2624/3200)\n",
            "Train Epoch: 97 | Loss: 0.517 | Acc: 81.941% (2727/3328)\n",
            "Train Epoch: 97 | Loss: 0.517 | Acc: 81.973% (2833/3456)\n",
            "Train Epoch: 97 | Loss: 0.516 | Acc: 82.059% (2941/3584)\n",
            "Train Epoch: 97 | Loss: 0.514 | Acc: 82.058% (3046/3712)\n",
            "Train Epoch: 97 | Loss: 0.515 | Acc: 82.161% (3155/3840)\n",
            "Train Epoch: 97 | Loss: 0.515 | Acc: 82.132% (3259/3968)\n",
            "Train Epoch: 97 | Loss: 0.514 | Acc: 82.251% (3369/4096)\n",
            "Train Epoch: 97 | Loss: 0.518 | Acc: 82.150% (3470/4224)\n",
            "Train Epoch: 97 | Loss: 0.520 | Acc: 82.031% (3570/4352)\n",
            "Train Epoch: 97 | Loss: 0.520 | Acc: 82.210% (3683/4480)\n",
            "Train Epoch: 97 | Loss: 0.520 | Acc: 82.161% (3786/4608)\n",
            "Train Epoch: 97 | Loss: 0.521 | Acc: 82.116% (3889/4736)\n",
            "Train Epoch: 97 | Loss: 0.521 | Acc: 82.196% (3998/4864)\n",
            "Train Epoch: 97 | Loss: 0.520 | Acc: 82.232% (4105/4992)\n",
            "Train Epoch: 97 | Loss: 0.518 | Acc: 82.324% (4215/5120)\n",
            "Train Epoch: 97 | Loss: 0.516 | Acc: 82.431% (4326/5248)\n",
            "Train Epoch: 97 | Loss: 0.517 | Acc: 82.440% (4432/5376)\n",
            "Train Epoch: 97 | Loss: 0.517 | Acc: 82.449% (4538/5504)\n",
            "Train Epoch: 97 | Loss: 0.517 | Acc: 82.386% (4640/5632)\n",
            "Train Epoch: 97 | Loss: 0.514 | Acc: 82.569% (4756/5760)\n",
            "Train Epoch: 97 | Loss: 0.511 | Acc: 82.677% (4868/5888)\n",
            "Train Epoch: 97 | Loss: 0.513 | Acc: 82.613% (4970/6016)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.731% (5083/6144)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.653% (5184/6272)\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 82.500% (5280/6400)\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 82.552% (5389/6528)\n",
            "Train Epoch: 97 | Loss: 0.511 | Acc: 82.632% (5500/6656)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.665% (5608/6784)\n",
            "Train Epoch: 97 | Loss: 0.511 | Acc: 82.726% (5718/6912)\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 82.642% (5818/7040)\n",
            "Train Epoch: 97 | Loss: 0.512 | Acc: 82.520% (5915/7168)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.634% (6029/7296)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.624% (6134/7424)\n",
            "Train Epoch: 97 | Loss: 0.510 | Acc: 82.667% (6243/7552)\n",
            "Train Epoch: 97 | Loss: 0.509 | Acc: 82.656% (6348/7680)\n",
            "Train Epoch: 97 | Loss: 0.509 | Acc: 82.697% (6457/7808)\n",
            "Train Epoch: 97 | Loss: 0.509 | Acc: 82.674% (6561/7936)\n",
            "Train Epoch: 97 | Loss: 0.508 | Acc: 82.726% (6671/8064)\n",
            "Train Epoch: 97 | Loss: 0.507 | Acc: 82.788% (6782/8192)\n",
            "Train Epoch: 97 | Loss: 0.505 | Acc: 82.873% (6895/8320)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.931% (7006/8448)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.999% (7118/8576)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 83.031% (7227/8704)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.960% (7327/8832)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 83.036% (7440/8960)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 83.033% (7546/9088)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 83.062% (7655/9216)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 83.091% (7764/9344)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 83.076% (7869/9472)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 83.146% (7982/9600)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 83.039% (8078/9728)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 83.005% (8181/9856)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.973% (8284/9984)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.981% (8391/10112)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.998% (8499/10240)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.986% (8604/10368)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 83.032% (8715/10496)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 83.020% (8820/10624)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 83.017% (8926/10752)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.969% (9027/10880)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 83.031% (9140/11008)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.992% (9242/11136)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.972% (9346/11264)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.935% (9448/11392)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.934% (9554/11520)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.933% (9660/11648)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.889% (9761/11776)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.905% (9869/11904)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.862% (9970/12032)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.812% (10070/12160)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.812% (10176/12288)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.804% (10281/12416)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.781% (10384/12544)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.765% (10488/12672)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.766% (10594/12800)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.735% (10696/12928)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.767% (10806/13056)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.759% (10911/13184)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.745% (11015/13312)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.753% (11122/13440)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.739% (11226/13568)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.739% (11332/13696)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.784% (11444/13824)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.748% (11545/13952)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.713% (11646/14080)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.679% (11747/14208)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.722% (11859/14336)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.730% (11966/14464)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.723% (12071/14592)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.717% (12176/14720)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.691% (12278/14848)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.679% (12382/14976)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.726% (12495/15104)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.721% (12600/15232)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.728% (12707/15360)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.703% (12809/15488)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.684% (12912/15616)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.692% (13019/15744)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.686% (13124/15872)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.731% (13237/16000)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.732% (13343/16128)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.751% (13452/16256)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.733% (13555/16384)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.752% (13664/16512)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.704% (13762/16640)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.699% (13867/16768)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.694% (13972/16896)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.754% (14088/17024)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.772% (14197/17152)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.784% (14305/17280)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.778% (14410/17408)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.784% (14517/17536)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.790% (14624/17664)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.779% (14728/17792)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.779% (14834/17920)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.768% (14938/18048)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.730% (15037/18176)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.720% (15141/18304)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.737% (15250/18432)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.759% (15360/18560)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.775% (15469/18688)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.797% (15579/18816)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.807% (15687/18944)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.812% (15794/19072)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.812% (15900/19200)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.812% (16006/19328)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.797% (16109/19456)\n",
            "Train Epoch: 97 | Loss: 0.495 | Acc: 82.833% (16222/19584)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.818% (16325/19712)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.772% (16422/19840)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.727% (16519/19968)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.678% (16615/20096)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.699% (16725/20224)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.675% (16826/20352)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.690% (16935/20480)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.701% (17043/20608)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.735% (17156/20736)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.731% (17261/20864)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.736% (17368/20992)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.704% (17467/21120)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.714% (17575/21248)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.710% (17680/21376)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.719% (17788/21504)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.711% (17892/21632)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.702% (17996/21760)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.689% (18099/21888)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.681% (18203/22016)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.682% (18309/22144)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.664% (18411/22272)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.683% (18521/22400)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.688% (18628/22528)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.689% (18734/22656)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.712% (18845/22784)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.730% (18955/22912)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.717% (19058/23040)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.726% (19166/23168)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.722% (19271/23296)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.723% (19377/23424)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.740% (19487/23552)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.741% (19593/23680)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.758% (19703/23808)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.787% (19816/23936)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.783% (19921/24064)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.796% (20030/24192)\n",
            "Train Epoch: 97 | Loss: 0.495 | Acc: 82.796% (20136/24320)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.768% (20235/24448)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.768% (20341/24576)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.788% (20452/24704)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.764% (20552/24832)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.748% (20654/24960)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.737% (20757/25088)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.757% (20868/25216)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.749% (20972/25344)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.738% (21075/25472)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.734% (21180/25600)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.708% (21279/25728)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.677% (21377/25856)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.682% (21484/25984)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.678% (21589/26112)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.679% (21695/26240)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.676% (21800/26368)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.635% (21895/26496)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.625% (21998/26624)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.626% (22104/26752)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.619% (22208/26880)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.638% (22319/27008)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.665% (22432/27136)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.662% (22537/27264)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.685% (22649/27392)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.693% (22757/27520)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.697% (22864/27648)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.697% (22970/27776)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.701% (23077/27904)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.741% (23194/28032)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.741% (23300/28160)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.724% (23401/28288)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.735% (23510/28416)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.732% (23615/28544)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.743% (23724/28672)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.729% (23826/28800)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.723% (23930/28928)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.723% (24036/29056)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.730% (24144/29184)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.731% (24250/29312)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.721% (24353/29440)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.684% (24448/29568)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.671% (24550/29696)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.682% (24659/29824)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.682% (24765/29952)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.680% (24870/30080)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.683% (24977/30208)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.671% (25079/30336)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.678% (25187/30464)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.685% (25295/30592)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.679% (25399/30720)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.644% (25494/30848)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.628% (25595/30976)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.655% (25709/31104)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.662% (25817/31232)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.679% (25928/31360)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.679% (26034/31488)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.692% (26144/31616)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.712% (26256/31744)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.731% (26368/31872)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.722% (26471/32000)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.744% (26584/32128)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.735% (26687/32256)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.708% (26784/32384)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.708% (26890/32512)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.714% (26998/32640)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.718% (27105/32768)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.733% (27216/32896)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.740% (27324/33024)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.743% (27431/33152)\n",
            "Train Epoch: 97 | Loss: 0.496 | Acc: 82.737% (27535/33280)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.714% (27633/33408)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.690% (27731/33536)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.691% (27837/33664)\n",
            "Train Epoch: 97 | Loss: 0.497 | Acc: 82.679% (27939/33792)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.656% (28037/33920)\n",
            "Train Epoch: 97 | Loss: 0.498 | Acc: 82.630% (28134/34048)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.616% (28235/34176)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.600% (28335/34304)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.571% (28431/34432)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.575% (28538/34560)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.593% (28650/34688)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.597% (28757/34816)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.589% (28860/34944)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.579% (28962/35072)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.560% (29061/35200)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.561% (29167/35328)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.564% (29274/35456)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.571% (29382/35584)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.577% (29490/35712)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.598% (29603/35840)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.587% (29705/35968)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.574% (29806/36096)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.567% (29909/36224)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.570% (30016/36352)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.569% (30121/36480)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.578% (30230/36608)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.595% (30342/36736)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.609% (30453/36864)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.612% (30560/36992)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.616% (30667/37120)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.608% (30770/37248)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.612% (30877/37376)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.607% (30981/37504)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.605% (31086/37632)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.619% (31197/37760)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.615% (31301/37888)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.620% (31409/38016)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.621% (31515/38144)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.624% (31622/38272)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.612% (31723/38400)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.613% (31829/38528)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.613% (31935/38656)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.606% (32038/38784)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.604% (32143/38912)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.605% (32249/39040)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.613% (32358/39168)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.614% (32464/39296)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.599% (32564/39424)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.598% (32669/39552)\n",
            "Train Epoch: 97 | Loss: 0.499 | Acc: 82.611% (32780/39680)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.612% (32886/39808)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.607% (32990/39936)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.610% (33097/40064)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.611% (33203/40192)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.626% (33315/40320)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.620% (33418/40448)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.613% (33521/40576)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.594% (33619/40704)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.602% (33728/40832)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.595% (33831/40960)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.603% (33940/41088)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.606% (34047/41216)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.617% (34157/41344)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.634% (34270/41472)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.651% (34383/41600)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.630% (34480/41728)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.636% (34588/41856)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.653% (34701/41984)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.644% (34803/42112)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.640% (34907/42240)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.624% (35006/42368)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.622% (35111/42496)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.613% (35213/42624)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.618% (35321/42752)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.610% (35423/42880)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.594% (35522/43008)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.578% (35621/43136)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.579% (35727/43264)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.580% (35833/43392)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.580% (35939/43520)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.588% (36048/43648)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.595% (36157/43776)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.589% (36260/43904)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.608% (36374/44032)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.606% (36479/44160)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.591% (36578/44288)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.592% (36684/44416)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.584% (36786/44544)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.591% (36895/44672)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.583% (36997/44800)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.597% (37109/44928)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.593% (37213/45056)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.613% (37328/45184)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.603% (37429/45312)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.603% (37535/45440)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.606% (37642/45568)\n",
            "Train Epoch: 97 | Loss: 0.500 | Acc: 82.605% (37747/45696)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.590% (37846/45824)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.575% (37945/45952)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.589% (38057/46080)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.585% (38161/46208)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.586% (38267/46336)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.576% (38368/46464)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.568% (38470/46592)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.545% (38565/46720)\n",
            "Train Epoch: 97 | Loss: 0.501 | Acc: 82.550% (38673/46848)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.553% (38780/46976)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.545% (38882/47104)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.531% (38981/47232)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.534% (39088/47360)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.530% (39192/47488)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.514% (39290/47616)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.515% (39396/47744)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.505% (39497/47872)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.513% (39606/48000)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.501% (39706/48128)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.502% (39812/48256)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.511% (39922/48384)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.518% (40031/48512)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.531% (40143/48640)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.534% (40250/48768)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.522% (40350/48896)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.515% (40452/49024)\n",
            "Train Epoch: 97 | Loss: 0.502 | Acc: 82.507% (40554/49152)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.502% (40657/49280)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.501% (40762/49408)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.494% (40864/49536)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.482% (40964/49664)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.469% (41063/49792)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.476% (41172/49920)\n",
            "Train Epoch: 97 | Loss: 0.503 | Acc: 82.476% (41238/50000)\n",
            "Test Epoch: 97 | Loss: 0.552 | Acc: 82.000% (82/100)\n",
            "Test Epoch: 97 | Loss: 0.687 | Acc: 78.000% (156/200)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.667% (233/300)\n",
            "Test Epoch: 97 | Loss: 0.710 | Acc: 77.750% (311/400)\n",
            "Test Epoch: 97 | Loss: 0.688 | Acc: 77.800% (389/500)\n",
            "Test Epoch: 97 | Loss: 0.633 | Acc: 79.000% (474/600)\n",
            "Test Epoch: 97 | Loss: 0.634 | Acc: 78.714% (551/700)\n",
            "Test Epoch: 97 | Loss: 0.648 | Acc: 78.625% (629/800)\n",
            "Test Epoch: 97 | Loss: 0.661 | Acc: 78.000% (702/900)\n",
            "Test Epoch: 97 | Loss: 0.648 | Acc: 78.200% (782/1000)\n",
            "Test Epoch: 97 | Loss: 0.637 | Acc: 78.636% (865/1100)\n",
            "Test Epoch: 97 | Loss: 0.643 | Acc: 78.250% (939/1200)\n",
            "Test Epoch: 97 | Loss: 0.644 | Acc: 78.077% (1015/1300)\n",
            "Test Epoch: 97 | Loss: 0.650 | Acc: 78.214% (1095/1400)\n",
            "Test Epoch: 97 | Loss: 0.644 | Acc: 78.600% (1179/1500)\n",
            "Test Epoch: 97 | Loss: 0.655 | Acc: 78.500% (1256/1600)\n",
            "Test Epoch: 97 | Loss: 0.647 | Acc: 78.529% (1335/1700)\n",
            "Test Epoch: 97 | Loss: 0.647 | Acc: 78.333% (1410/1800)\n",
            "Test Epoch: 97 | Loss: 0.647 | Acc: 78.474% (1491/1900)\n",
            "Test Epoch: 97 | Loss: 0.668 | Acc: 77.850% (1557/2000)\n",
            "Test Epoch: 97 | Loss: 0.677 | Acc: 77.619% (1630/2100)\n",
            "Test Epoch: 97 | Loss: 0.681 | Acc: 77.636% (1708/2200)\n",
            "Test Epoch: 97 | Loss: 0.692 | Acc: 77.478% (1782/2300)\n",
            "Test Epoch: 97 | Loss: 0.688 | Acc: 77.500% (1860/2400)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.200% (1930/2500)\n",
            "Test Epoch: 97 | Loss: 0.714 | Acc: 76.962% (2001/2600)\n",
            "Test Epoch: 97 | Loss: 0.706 | Acc: 77.111% (2082/2700)\n",
            "Test Epoch: 97 | Loss: 0.707 | Acc: 77.036% (2157/2800)\n",
            "Test Epoch: 97 | Loss: 0.709 | Acc: 77.034% (2234/2900)\n",
            "Test Epoch: 97 | Loss: 0.705 | Acc: 77.100% (2313/3000)\n",
            "Test Epoch: 97 | Loss: 0.705 | Acc: 77.129% (2391/3100)\n",
            "Test Epoch: 97 | Loss: 0.704 | Acc: 77.031% (2465/3200)\n",
            "Test Epoch: 97 | Loss: 0.700 | Acc: 77.182% (2547/3300)\n",
            "Test Epoch: 97 | Loss: 0.703 | Acc: 77.118% (2622/3400)\n",
            "Test Epoch: 97 | Loss: 0.704 | Acc: 77.057% (2697/3500)\n",
            "Test Epoch: 97 | Loss: 0.703 | Acc: 77.111% (2776/3600)\n",
            "Test Epoch: 97 | Loss: 0.708 | Acc: 77.054% (2851/3700)\n",
            "Test Epoch: 97 | Loss: 0.711 | Acc: 76.921% (2923/3800)\n",
            "Test Epoch: 97 | Loss: 0.710 | Acc: 77.026% (3004/3900)\n",
            "Test Epoch: 97 | Loss: 0.711 | Acc: 77.025% (3081/4000)\n",
            "Test Epoch: 97 | Loss: 0.712 | Acc: 77.122% (3162/4100)\n",
            "Test Epoch: 97 | Loss: 0.711 | Acc: 77.214% (3243/4200)\n",
            "Test Epoch: 97 | Loss: 0.706 | Acc: 77.442% (3330/4300)\n",
            "Test Epoch: 97 | Loss: 0.703 | Acc: 77.568% (3413/4400)\n",
            "Test Epoch: 97 | Loss: 0.704 | Acc: 77.444% (3485/4500)\n",
            "Test Epoch: 97 | Loss: 0.706 | Acc: 77.391% (3560/4600)\n",
            "Test Epoch: 97 | Loss: 0.705 | Acc: 77.447% (3640/4700)\n",
            "Test Epoch: 97 | Loss: 0.706 | Acc: 77.500% (3720/4800)\n",
            "Test Epoch: 97 | Loss: 0.703 | Acc: 77.551% (3800/4900)\n",
            "Test Epoch: 97 | Loss: 0.705 | Acc: 77.540% (3877/5000)\n",
            "Test Epoch: 97 | Loss: 0.701 | Acc: 77.608% (3958/5100)\n",
            "Test Epoch: 97 | Loss: 0.701 | Acc: 77.596% (4035/5200)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.642% (4115/5300)\n",
            "Test Epoch: 97 | Loss: 0.700 | Acc: 77.667% (4194/5400)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.655% (4271/5500)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.554% (4343/5600)\n",
            "Test Epoch: 97 | Loss: 0.703 | Acc: 77.544% (4420/5700)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.690% (4506/5800)\n",
            "Test Epoch: 97 | Loss: 0.700 | Acc: 77.542% (4575/5900)\n",
            "Test Epoch: 97 | Loss: 0.701 | Acc: 77.450% (4647/6000)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.508% (4728/6100)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.484% (4804/6200)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.508% (4883/6300)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.656% (4970/6400)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.615% (5045/6500)\n",
            "Test Epoch: 97 | Loss: 0.700 | Acc: 77.561% (5119/6600)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.597% (5199/6700)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.515% (5271/6800)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.522% (5349/6900)\n",
            "Test Epoch: 97 | Loss: 0.701 | Acc: 77.471% (5423/7000)\n",
            "Test Epoch: 97 | Loss: 0.701 | Acc: 77.451% (5499/7100)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.500% (5580/7200)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.575% (5663/7300)\n",
            "Test Epoch: 97 | Loss: 0.694 | Acc: 77.662% (5747/7400)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.587% (5819/7500)\n",
            "Test Epoch: 97 | Loss: 0.694 | Acc: 77.645% (5901/7600)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.610% (5976/7700)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.538% (6048/7800)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.506% (6123/7900)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.562% (6205/8000)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.580% (6284/8100)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.585% (6362/8200)\n",
            "Test Epoch: 97 | Loss: 0.695 | Acc: 77.614% (6442/8300)\n",
            "Test Epoch: 97 | Loss: 0.695 | Acc: 77.571% (6516/8400)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.541% (6591/8500)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.547% (6669/8600)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.529% (6745/8700)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.489% (6819/8800)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.472% (6895/8900)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.511% (6976/9000)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.582% (7060/9100)\n",
            "Test Epoch: 97 | Loss: 0.694 | Acc: 77.652% (7144/9200)\n",
            "Test Epoch: 97 | Loss: 0.695 | Acc: 77.613% (7218/9300)\n",
            "Test Epoch: 97 | Loss: 0.697 | Acc: 77.553% (7290/9400)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.526% (7365/9500)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.552% (7445/9600)\n",
            "Test Epoch: 97 | Loss: 0.695 | Acc: 77.598% (7527/9700)\n",
            "Test Epoch: 97 | Loss: 0.696 | Acc: 77.490% (7594/9800)\n",
            "Test Epoch: 97 | Loss: 0.698 | Acc: 77.414% (7664/9900)\n",
            "Test Epoch: 97 | Loss: 0.699 | Acc: 77.410% (7741/10000)\n",
            "\n",
            "Epoch: 98\n",
            "Train Epoch: 98 | Loss: 0.549 | Acc: 78.906% (101/128)\n",
            "Train Epoch: 98 | Loss: 0.484 | Acc: 80.859% (207/256)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 80.469% (309/384)\n",
            "Train Epoch: 98 | Loss: 0.516 | Acc: 80.273% (411/512)\n",
            "Train Epoch: 98 | Loss: 0.543 | Acc: 79.844% (511/640)\n",
            "Train Epoch: 98 | Loss: 0.537 | Acc: 79.948% (614/768)\n",
            "Train Epoch: 98 | Loss: 0.538 | Acc: 80.022% (717/896)\n",
            "Train Epoch: 98 | Loss: 0.530 | Acc: 80.566% (825/1024)\n",
            "Train Epoch: 98 | Loss: 0.518 | Acc: 80.469% (927/1152)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 81.484% (1043/1280)\n",
            "Train Epoch: 98 | Loss: 0.489 | Acc: 81.889% (1153/1408)\n",
            "Train Epoch: 98 | Loss: 0.478 | Acc: 82.422% (1266/1536)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 81.911% (1363/1664)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 81.864% (1467/1792)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 81.823% (1571/1920)\n",
            "Train Epoch: 98 | Loss: 0.493 | Acc: 81.982% (1679/2048)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 82.307% (1791/2176)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 82.422% (1899/2304)\n",
            "Train Epoch: 98 | Loss: 0.489 | Acc: 82.730% (2012/2432)\n",
            "Train Epoch: 98 | Loss: 0.487 | Acc: 82.969% (2124/2560)\n",
            "Train Epoch: 98 | Loss: 0.488 | Acc: 83.147% (2235/2688)\n",
            "Train Epoch: 98 | Loss: 0.492 | Acc: 83.061% (2339/2816)\n",
            "Train Epoch: 98 | Loss: 0.486 | Acc: 83.424% (2456/2944)\n",
            "Train Epoch: 98 | Loss: 0.483 | Acc: 83.561% (2567/3072)\n",
            "Train Epoch: 98 | Loss: 0.481 | Acc: 83.594% (2675/3200)\n",
            "Train Epoch: 98 | Loss: 0.483 | Acc: 83.383% (2775/3328)\n",
            "Train Epoch: 98 | Loss: 0.482 | Acc: 83.478% (2885/3456)\n",
            "Train Epoch: 98 | Loss: 0.482 | Acc: 83.650% (2998/3584)\n",
            "Train Epoch: 98 | Loss: 0.484 | Acc: 83.459% (3098/3712)\n",
            "Train Epoch: 98 | Loss: 0.484 | Acc: 83.516% (3207/3840)\n",
            "Train Epoch: 98 | Loss: 0.482 | Acc: 83.619% (3318/3968)\n",
            "Train Epoch: 98 | Loss: 0.483 | Acc: 83.447% (3418/4096)\n",
            "Train Epoch: 98 | Loss: 0.483 | Acc: 83.333% (3520/4224)\n",
            "Train Epoch: 98 | Loss: 0.486 | Acc: 83.295% (3625/4352)\n",
            "Train Epoch: 98 | Loss: 0.485 | Acc: 83.348% (3734/4480)\n",
            "Train Epoch: 98 | Loss: 0.485 | Acc: 83.355% (3841/4608)\n",
            "Train Epoch: 98 | Loss: 0.486 | Acc: 83.404% (3950/4736)\n",
            "Train Epoch: 98 | Loss: 0.489 | Acc: 83.285% (4051/4864)\n",
            "Train Epoch: 98 | Loss: 0.488 | Acc: 83.313% (4159/4992)\n",
            "Train Epoch: 98 | Loss: 0.488 | Acc: 83.262% (4263/5120)\n",
            "Train Epoch: 98 | Loss: 0.490 | Acc: 83.175% (4365/5248)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.017% (4463/5376)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.049% (4571/5504)\n",
            "Train Epoch: 98 | Loss: 0.493 | Acc: 83.114% (4681/5632)\n",
            "Train Epoch: 98 | Loss: 0.491 | Acc: 83.281% (4797/5760)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 83.118% (4894/5888)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 83.211% (5006/6016)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 83.187% (5111/6144)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 83.147% (5215/6272)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 83.109% (5319/6400)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.088% (5424/6528)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.113% (5532/6656)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 83.063% (5635/6784)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.087% (5743/6912)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.011% (5844/7040)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.008% (5950/7168)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.991% (6055/7296)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 83.001% (6162/7424)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 83.038% (6271/7552)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 83.021% (6376/7680)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 83.030% (6483/7808)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 83.002% (6587/7936)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.949% (6689/8064)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.971% (6797/8192)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.981% (6904/8320)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.966% (7009/8448)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.952% (7114/8576)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.985% (7223/8704)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 83.073% (7337/8832)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 83.069% (7443/8960)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 83.044% (7547/9088)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 83.116% (7660/9216)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 83.134% (7768/9344)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.214% (7882/9472)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.177% (7985/9600)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.213% (8095/9728)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.198% (8200/9856)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 83.163% (8303/9984)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.198% (8413/10112)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.174% (8517/10240)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.198% (8626/10368)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.222% (8735/10496)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.264% (8846/10624)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.268% (8953/10752)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.318% (9065/10880)\n",
            "Train Epoch: 98 | Loss: 0.493 | Acc: 83.339% (9174/11008)\n",
            "Train Epoch: 98 | Loss: 0.492 | Acc: 83.324% (9279/11136)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.265% (9379/11264)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.260% (9485/11392)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.238% (9589/11520)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.199% (9691/11648)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.169% (9794/11776)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.132% (9896/11904)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.112% (10000/12032)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.125% (10108/12160)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.154% (10218/12288)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.070% (10314/12416)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.123% (10427/12544)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.112% (10532/12672)\n",
            "Train Epoch: 98 | Loss: 0.494 | Acc: 83.109% (10638/12800)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.037% (10735/12928)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.019% (10839/13056)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.048% (10949/13184)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.053% (11056/13312)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.006% (11156/13440)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.982% (11259/13568)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.980% (11365/13696)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.979% (11471/13824)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.942% (11572/13952)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.976% (11683/14080)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.003% (11793/14208)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 83.001% (11899/14336)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.972% (12001/14464)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.956% (12105/14592)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.942% (12209/14720)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.940% (12315/14848)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 82.993% (12429/14976)\n",
            "Train Epoch: 98 | Loss: 0.495 | Acc: 83.011% (12538/15104)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 82.983% (12640/15232)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.975% (12745/15360)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.974% (12851/15488)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.947% (12953/15616)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.940% (13058/15744)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.939% (13164/15872)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 82.938% (13270/16000)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.949% (13378/16128)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.936% (13482/16256)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 82.971% (13594/16384)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.915% (13691/16512)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.873% (13790/16640)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.830% (13889/16768)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.824% (13994/16896)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.824% (14100/17024)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.842% (14209/17152)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.807% (14309/17280)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.824% (14418/17408)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.807% (14521/17536)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.812% (14628/17664)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.857% (14742/17792)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.840% (14845/17920)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.812% (14946/18048)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.768% (15044/18176)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.741% (15145/18304)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.747% (15252/18432)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.764% (15361/18560)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.754% (15465/18688)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.722% (15565/18816)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.717% (15670/18944)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.723% (15777/19072)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.755% (15889/19200)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.750% (15994/19328)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.746% (16099/19456)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.721% (16200/19584)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.686% (16299/19712)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.707% (16409/19840)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.712% (16516/19968)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.748% (16629/20096)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.753% (16736/20224)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.734% (16838/20352)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.744% (16946/20480)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.740% (17051/20608)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.731% (17155/20736)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.745% (17264/20864)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.760% (17373/20992)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.775% (17482/21120)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.794% (17592/21248)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.808% (17701/21376)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.780% (17801/21504)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.785% (17908/21632)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.780% (18013/21760)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.785% (18120/21888)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.763% (18221/22016)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.799% (18335/22144)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.821% (18446/22272)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.795% (18546/22400)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.821% (18658/22528)\n",
            "Train Epoch: 98 | Loss: 0.496 | Acc: 82.848% (18770/22656)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.804% (18866/22784)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.769% (18964/22912)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.778% (19072/23040)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.756% (19173/23168)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.757% (19279/23296)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.744% (19382/23424)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.753% (19490/23552)\n",
            "Train Epoch: 98 | Loss: 0.497 | Acc: 82.787% (19604/23680)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.762% (19704/23808)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.771% (19812/23936)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.742% (19911/24064)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.755% (20020/24192)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.767% (20129/24320)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.768% (20235/24448)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.768% (20341/24576)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.772% (20448/24704)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.780% (20556/24832)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.760% (20657/24960)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.757% (20762/25088)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.765% (20870/25216)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.753% (20973/25344)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.761% (21081/25472)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.766% (21188/25600)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.770% (21295/25728)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.754% (21397/25856)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.751% (21502/25984)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.770% (21613/26112)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.793% (21725/26240)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.790% (21830/26368)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.782% (21934/26496)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.786% (22041/26624)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.764% (22141/26752)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.749% (22243/26880)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.753% (22350/27008)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.772% (22461/27136)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.776% (22568/27264)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.769% (22672/27392)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.780% (22781/27520)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.787% (22889/27648)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.820% (23004/27776)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.827% (23112/27904)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.816% (23215/28032)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.834% (23326/28160)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.805% (23424/28288)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.816% (23533/28416)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.805% (23636/28544)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.816% (23745/28672)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.837% (23857/28800)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.833% (23962/28928)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.843% (24071/29056)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.819% (24170/29184)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.795% (24269/29312)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.809% (24379/29440)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.802% (24483/29568)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.799% (24588/29696)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.819% (24700/29824)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.819% (24806/29952)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.796% (24905/30080)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.796% (25011/30208)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.786% (25114/30336)\n",
            "Train Epoch: 98 | Loss: 0.498 | Acc: 82.773% (25216/30464)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.760% (25318/30592)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.747% (25420/30720)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.731% (25521/30848)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.748% (25632/30976)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.742% (25736/31104)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.758% (25847/31232)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.761% (25954/31360)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.784% (26067/31488)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.781% (26172/31616)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.768% (26274/31744)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.759% (26377/31872)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.772% (26487/32000)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.763% (26590/32128)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.772% (26699/32256)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.785% (26809/32384)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.800% (26920/32512)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.797% (27025/32640)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.782% (27126/32768)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.776% (27230/32896)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.782% (27338/33024)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.770% (27440/33152)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.752% (27540/33280)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.720% (27635/33408)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.726% (27743/33536)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.706% (27842/33664)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.700% (27946/33792)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.703% (28053/33920)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.727% (28167/34048)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.728% (28273/34176)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.710% (28373/34304)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.708% (28478/34432)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.708% (28584/34560)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.694% (28685/34688)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.689% (28789/34816)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.689% (28895/34944)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.696% (29003/35072)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.705% (29112/35200)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.694% (29214/35328)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.697% (29321/35456)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.692% (29425/35584)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.686% (29529/35712)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.676% (29631/35840)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.687% (29741/35968)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.668% (29840/36096)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.677% (29949/36224)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.678% (30055/36352)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.634% (30145/36480)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.629% (30249/36608)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.614% (30349/36736)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.623% (30458/36864)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.607% (30558/36992)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.608% (30664/37120)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.603% (30768/37248)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.585% (30867/37376)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.575% (30969/37504)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.573% (31074/37632)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.572% (31179/37760)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.572% (31285/37888)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.570% (31390/38016)\n",
            "Train Epoch: 98 | Loss: 0.504 | Acc: 82.553% (31489/38144)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.572% (31602/38272)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.583% (31712/38400)\n",
            "Train Epoch: 98 | Loss: 0.503 | Acc: 82.579% (31816/38528)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.598% (31929/38656)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.604% (32037/38784)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.609% (32145/38912)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.613% (32252/39040)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.631% (32365/39168)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.629% (32470/39296)\n",
            "Train Epoch: 98 | Loss: 0.502 | Acc: 82.625% (32574/39424)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.641% (32686/39552)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.659% (32799/39680)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.652% (32902/39808)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.662% (33012/39936)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.645% (33111/40064)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.631% (33211/40192)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.654% (33326/40320)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.639% (33426/40448)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.618% (33523/40576)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.631% (33634/40704)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.626% (33738/40832)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.620% (33841/40960)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.628% (33950/41088)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.628% (34056/41216)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.619% (34158/41344)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.617% (34263/41472)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.615% (34368/41600)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.616% (34474/41728)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.629% (34585/41856)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.622% (34688/41984)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.601% (34785/42112)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.611% (34895/42240)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.614% (35002/42368)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.617% (35109/42496)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.618% (35215/42624)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.609% (35317/42752)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.603% (35420/42880)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.610% (35529/43008)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.604% (35632/43136)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.604% (35738/43264)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.600% (35842/43392)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.599% (35947/43520)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.606% (36056/43648)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.611% (36164/43776)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.610% (36269/43904)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.610% (36375/44032)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.609% (36480/44160)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.618% (36590/44288)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.626% (36699/44416)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.613% (36799/44544)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.618% (36907/44672)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.625% (37016/44800)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.632% (37125/44928)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.626% (37228/45056)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.633% (37337/45184)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.643% (37447/45312)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.643% (37553/45440)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.633% (37654/45568)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.631% (37759/45696)\n",
            "Train Epoch: 98 | Loss: 0.499 | Acc: 82.634% (37866/45824)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.636% (37973/45952)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.626% (38074/46080)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.613% (38174/46208)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.607% (38277/46336)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.608% (38383/46464)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.602% (38486/46592)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.607% (38594/46720)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.582% (38688/46848)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.587% (38796/46976)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.585% (38901/47104)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.588% (39008/47232)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.593% (39116/47360)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.602% (39226/47488)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.596% (39329/47616)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.588% (39431/47744)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.591% (39538/47872)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.592% (39644/48000)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.584% (39746/48128)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.589% (39854/48256)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.585% (39958/48384)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.584% (40063/48512)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.576% (40165/48640)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.568% (40267/48768)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.563% (40370/48896)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.568% (40478/49024)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.574% (40587/49152)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.589% (40700/49280)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.596% (40809/49408)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.588% (40911/49536)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.585% (41015/49664)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.580% (41118/49792)\n",
            "Train Epoch: 98 | Loss: 0.501 | Acc: 82.568% (41218/49920)\n",
            "Train Epoch: 98 | Loss: 0.500 | Acc: 82.576% (41288/50000)\n",
            "Test Epoch: 98 | Loss: 0.592 | Acc: 81.000% (81/100)\n",
            "Test Epoch: 98 | Loss: 0.726 | Acc: 76.000% (152/200)\n",
            "Test Epoch: 98 | Loss: 0.718 | Acc: 77.000% (231/300)\n",
            "Test Epoch: 98 | Loss: 0.735 | Acc: 77.500% (310/400)\n",
            "Test Epoch: 98 | Loss: 0.708 | Acc: 77.800% (389/500)\n",
            "Test Epoch: 98 | Loss: 0.650 | Acc: 79.333% (476/600)\n",
            "Test Epoch: 98 | Loss: 0.652 | Acc: 79.000% (553/700)\n",
            "Test Epoch: 98 | Loss: 0.665 | Acc: 78.750% (630/800)\n",
            "Test Epoch: 98 | Loss: 0.679 | Acc: 78.000% (702/900)\n",
            "Test Epoch: 98 | Loss: 0.667 | Acc: 78.000% (780/1000)\n",
            "Test Epoch: 98 | Loss: 0.654 | Acc: 78.273% (861/1100)\n",
            "Test Epoch: 98 | Loss: 0.660 | Acc: 78.000% (936/1200)\n",
            "Test Epoch: 98 | Loss: 0.659 | Acc: 77.923% (1013/1300)\n",
            "Test Epoch: 98 | Loss: 0.665 | Acc: 77.929% (1091/1400)\n",
            "Test Epoch: 98 | Loss: 0.653 | Acc: 78.333% (1175/1500)\n",
            "Test Epoch: 98 | Loss: 0.666 | Acc: 78.062% (1249/1600)\n",
            "Test Epoch: 98 | Loss: 0.660 | Acc: 78.176% (1329/1700)\n",
            "Test Epoch: 98 | Loss: 0.657 | Acc: 78.056% (1405/1800)\n",
            "Test Epoch: 98 | Loss: 0.658 | Acc: 78.158% (1485/1900)\n",
            "Test Epoch: 98 | Loss: 0.680 | Acc: 77.550% (1551/2000)\n",
            "Test Epoch: 98 | Loss: 0.691 | Acc: 77.333% (1624/2100)\n",
            "Test Epoch: 98 | Loss: 0.694 | Acc: 77.182% (1698/2200)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.174% (1775/2300)\n",
            "Test Epoch: 98 | Loss: 0.701 | Acc: 77.042% (1849/2400)\n",
            "Test Epoch: 98 | Loss: 0.710 | Acc: 76.960% (1924/2500)\n",
            "Test Epoch: 98 | Loss: 0.724 | Acc: 76.808% (1997/2600)\n",
            "Test Epoch: 98 | Loss: 0.715 | Acc: 77.074% (2081/2700)\n",
            "Test Epoch: 98 | Loss: 0.714 | Acc: 77.143% (2160/2800)\n",
            "Test Epoch: 98 | Loss: 0.717 | Acc: 77.138% (2237/2900)\n",
            "Test Epoch: 98 | Loss: 0.714 | Acc: 77.200% (2316/3000)\n",
            "Test Epoch: 98 | Loss: 0.714 | Acc: 77.226% (2394/3100)\n",
            "Test Epoch: 98 | Loss: 0.712 | Acc: 77.156% (2469/3200)\n",
            "Test Epoch: 98 | Loss: 0.708 | Acc: 77.273% (2550/3300)\n",
            "Test Epoch: 98 | Loss: 0.713 | Acc: 77.176% (2624/3400)\n",
            "Test Epoch: 98 | Loss: 0.714 | Acc: 77.029% (2696/3500)\n",
            "Test Epoch: 98 | Loss: 0.713 | Acc: 77.028% (2773/3600)\n",
            "Test Epoch: 98 | Loss: 0.717 | Acc: 77.027% (2850/3700)\n",
            "Test Epoch: 98 | Loss: 0.721 | Acc: 76.974% (2925/3800)\n",
            "Test Epoch: 98 | Loss: 0.719 | Acc: 77.077% (3006/3900)\n",
            "Test Epoch: 98 | Loss: 0.719 | Acc: 77.100% (3084/4000)\n",
            "Test Epoch: 98 | Loss: 0.720 | Acc: 77.171% (3164/4100)\n",
            "Test Epoch: 98 | Loss: 0.719 | Acc: 77.286% (3246/4200)\n",
            "Test Epoch: 98 | Loss: 0.714 | Acc: 77.465% (3331/4300)\n",
            "Test Epoch: 98 | Loss: 0.712 | Acc: 77.568% (3413/4400)\n",
            "Test Epoch: 98 | Loss: 0.712 | Acc: 77.511% (3488/4500)\n",
            "Test Epoch: 98 | Loss: 0.713 | Acc: 77.413% (3561/4600)\n",
            "Test Epoch: 98 | Loss: 0.713 | Acc: 77.404% (3638/4700)\n",
            "Test Epoch: 98 | Loss: 0.713 | Acc: 77.417% (3716/4800)\n",
            "Test Epoch: 98 | Loss: 0.710 | Acc: 77.490% (3797/4900)\n",
            "Test Epoch: 98 | Loss: 0.712 | Acc: 77.500% (3875/5000)\n",
            "Test Epoch: 98 | Loss: 0.707 | Acc: 77.588% (3957/5100)\n",
            "Test Epoch: 98 | Loss: 0.708 | Acc: 77.558% (4033/5200)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.585% (4112/5300)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.574% (4189/5400)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.527% (4264/5500)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.536% (4342/5600)\n",
            "Test Epoch: 98 | Loss: 0.710 | Acc: 77.474% (4416/5700)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.603% (4501/5800)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.475% (4571/5900)\n",
            "Test Epoch: 98 | Loss: 0.709 | Acc: 77.350% (4641/6000)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.426% (4723/6100)\n",
            "Test Epoch: 98 | Loss: 0.707 | Acc: 77.371% (4797/6200)\n",
            "Test Epoch: 98 | Loss: 0.707 | Acc: 77.381% (4875/6300)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.562% (4964/6400)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.569% (5042/6500)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.500% (5115/6600)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.567% (5197/6700)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.471% (5268/6800)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.449% (5344/6900)\n",
            "Test Epoch: 98 | Loss: 0.708 | Acc: 77.329% (5413/7000)\n",
            "Test Epoch: 98 | Loss: 0.709 | Acc: 77.338% (5491/7100)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.389% (5572/7200)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.438% (5653/7300)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.473% (5733/7400)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.440% (5808/7500)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.513% (5891/7600)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.468% (5965/7700)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.397% (6037/7800)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.367% (6112/7900)\n",
            "Test Epoch: 98 | Loss: 0.706 | Acc: 77.362% (6189/8000)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.444% (6273/8100)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.427% (6349/8200)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.398% (6424/8300)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.429% (6504/8400)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.435% (6582/8500)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.465% (6662/8600)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.391% (6733/8700)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.375% (6809/8800)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.360% (6885/8900)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.378% (6964/9000)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.451% (7048/9100)\n",
            "Test Epoch: 98 | Loss: 0.700 | Acc: 77.533% (7133/9200)\n",
            "Test Epoch: 98 | Loss: 0.701 | Acc: 77.516% (7209/9300)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.468% (7282/9400)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.495% (7362/9500)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.521% (7442/9600)\n",
            "Test Epoch: 98 | Loss: 0.702 | Acc: 77.557% (7523/9700)\n",
            "Test Epoch: 98 | Loss: 0.703 | Acc: 77.469% (7592/9800)\n",
            "Test Epoch: 98 | Loss: 0.704 | Acc: 77.404% (7663/9900)\n",
            "Test Epoch: 98 | Loss: 0.705 | Acc: 77.400% (7740/10000)\n",
            "\n",
            "Epoch: 99\n",
            "Train Epoch: 99 | Loss: 0.395 | Acc: 86.719% (111/128)\n",
            "Train Epoch: 99 | Loss: 0.468 | Acc: 85.547% (219/256)\n",
            "Train Epoch: 99 | Loss: 0.480 | Acc: 84.375% (324/384)\n",
            "Train Epoch: 99 | Loss: 0.504 | Acc: 83.594% (428/512)\n",
            "Train Epoch: 99 | Loss: 0.506 | Acc: 82.500% (528/640)\n",
            "Train Epoch: 99 | Loss: 0.518 | Acc: 82.552% (634/768)\n",
            "Train Epoch: 99 | Loss: 0.517 | Acc: 82.589% (740/896)\n",
            "Train Epoch: 99 | Loss: 0.517 | Acc: 82.422% (844/1024)\n",
            "Train Epoch: 99 | Loss: 0.510 | Acc: 82.899% (955/1152)\n",
            "Train Epoch: 99 | Loss: 0.514 | Acc: 83.125% (1064/1280)\n",
            "Train Epoch: 99 | Loss: 0.509 | Acc: 83.310% (1173/1408)\n",
            "Train Epoch: 99 | Loss: 0.503 | Acc: 83.529% (1283/1536)\n",
            "Train Epoch: 99 | Loss: 0.504 | Acc: 83.353% (1387/1664)\n",
            "Train Epoch: 99 | Loss: 0.510 | Acc: 83.147% (1490/1792)\n",
            "Train Epoch: 99 | Loss: 0.510 | Acc: 82.865% (1591/1920)\n",
            "Train Epoch: 99 | Loss: 0.507 | Acc: 82.910% (1698/2048)\n",
            "Train Epoch: 99 | Loss: 0.500 | Acc: 83.272% (1812/2176)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 83.333% (1920/2304)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 83.512% (2031/2432)\n",
            "Train Epoch: 99 | Loss: 0.487 | Acc: 83.555% (2139/2560)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 83.631% (2248/2688)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 83.523% (2352/2816)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 83.424% (2456/2944)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 83.203% (2556/3072)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 83.312% (2666/3200)\n",
            "Train Epoch: 99 | Loss: 0.485 | Acc: 83.534% (2780/3328)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 83.333% (2880/3456)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 83.315% (2986/3584)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 83.163% (3087/3712)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 82.995% (3187/3840)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 82.913% (3290/3968)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 83.081% (3403/4096)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 82.907% (3502/4224)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.744% (3601/4352)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.679% (3704/4480)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.661% (3809/4608)\n",
            "Train Epoch: 99 | Loss: 0.498 | Acc: 82.622% (3913/4736)\n",
            "Train Epoch: 99 | Loss: 0.498 | Acc: 82.648% (4020/4864)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.853% (4136/4992)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.930% (4246/5120)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.851% (4348/5248)\n",
            "Train Epoch: 99 | Loss: 0.499 | Acc: 82.757% (4449/5376)\n",
            "Train Epoch: 99 | Loss: 0.498 | Acc: 82.703% (4552/5504)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.706% (4658/5632)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.639% (4760/5760)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.728% (4871/5888)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.713% (4976/6016)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.699% (5081/6144)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.637% (5183/6272)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.734% (5295/6400)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.797% (5405/6528)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.933% (5520/6656)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 83.004% (5631/6784)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 82.972% (5735/6912)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.898% (5836/7040)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.840% (5938/7168)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.895% (6048/7296)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 82.961% (6159/7424)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 82.945% (6264/7552)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 82.891% (6366/7680)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 82.928% (6475/7808)\n",
            "Train Epoch: 99 | Loss: 0.488 | Acc: 82.926% (6581/7936)\n",
            "Train Epoch: 99 | Loss: 0.489 | Acc: 82.912% (6686/8064)\n",
            "Train Epoch: 99 | Loss: 0.490 | Acc: 82.898% (6791/8192)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.861% (6894/8320)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.789% (6994/8448)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.824% (7103/8576)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.709% (7199/8704)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.620% (7297/8832)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.634% (7404/8960)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.680% (7514/9088)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.747% (7626/9216)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.748% (7732/9344)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.791% (7842/9472)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.750% (7944/9600)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.792% (8054/9728)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.772% (8158/9856)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.752% (8262/9984)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.793% (8372/10112)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.812% (8480/10240)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.803% (8585/10368)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.841% (8695/10496)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.878% (8805/10624)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.840% (8907/10752)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.831% (9012/10880)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.867% (9122/11008)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.875% (9229/11136)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.892% (9337/11264)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.918% (9446/11392)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.830% (9542/11520)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.847% (9650/11648)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.931% (9766/11776)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.905% (9869/11904)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.929% (9978/12032)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.928% (10084/12160)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.951% (10193/12288)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.957% (10300/12416)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.924% (10402/12544)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.915% (10507/12672)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.891% (10610/12800)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.867% (10713/12928)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.897% (10823/13056)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.919% (10932/13184)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.858% (11030/13312)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.790% (11127/13440)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.820% (11237/13568)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.812% (11342/13696)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.769% (11442/13824)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.712% (11540/13952)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.663% (11639/14080)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.665% (11745/14208)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.687% (11854/14336)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.688% (11960/14464)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.655% (12061/14592)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.582% (12156/14720)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.624% (12268/14848)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.606% (12371/14976)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.640% (12482/15104)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.648% (12589/15232)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.630% (12692/15360)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.612% (12795/15488)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.640% (12905/15616)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.603% (13005/15744)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.630% (13115/15872)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.650% (13224/16000)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.664% (13332/16128)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.665% (13438/16256)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.666% (13544/16384)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.631% (13644/16512)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.626% (13749/16640)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.646% (13858/16768)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.641% (13963/16896)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.607% (14063/17024)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.614% (14170/17152)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.662% (14284/17280)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.646% (14387/17408)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.636% (14491/17536)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.665% (14602/17664)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.655% (14706/17792)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.651% (14811/17920)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.624% (14912/18048)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.647% (15022/18176)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.638% (15126/18304)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.639% (15232/18432)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.645% (15339/18560)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.700% (15455/18688)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.706% (15562/18816)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.675% (15662/18944)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.650% (15763/19072)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.677% (15874/19200)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.668% (15978/19328)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.612% (16073/19456)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.598% (16176/19584)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.605% (16283/19712)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.601% (16388/19840)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.597% (16493/19968)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.599% (16599/20096)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.595% (16704/20224)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.611% (16813/20352)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.612% (16919/20480)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.638% (17030/20608)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.673% (17143/20736)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.693% (17253/20864)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.722% (17365/20992)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.723% (17471/21120)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.723% (17577/21248)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.724% (17683/21376)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.752% (17795/21504)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.752% (17901/21632)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.748% (18006/21760)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.717% (18105/21888)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.717% (18211/22016)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.691% (18311/22144)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.682% (18415/22272)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.710% (18527/22400)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.702% (18631/22528)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.693% (18735/22656)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.707% (18844/22784)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.686% (18945/22912)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.674% (19048/23040)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.670% (19153/23168)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.679% (19261/23296)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.672% (19365/23424)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.685% (19474/23552)\n",
            "Train Epoch: 99 | Loss: 0.497 | Acc: 82.694% (19582/23680)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.728% (19696/23808)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.733% (19803/23936)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.754% (19914/24064)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.755% (20020/24192)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.763% (20128/24320)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.759% (20233/24448)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.764% (20340/24576)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.764% (20446/24704)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.776% (20555/24832)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.776% (20661/24960)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.773% (20766/25088)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.745% (20865/25216)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.761% (20975/25344)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.773% (21084/25472)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.762% (21187/25600)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.762% (21293/25728)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.774% (21402/25856)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.759% (21504/25984)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.740% (21605/26112)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.752% (21714/26240)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.767% (21824/26368)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.775% (21932/26496)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.782% (22040/26624)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.790% (22148/26752)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.801% (22257/26880)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.809% (22365/27008)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.849% (22482/27136)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.846% (22587/27264)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.831% (22689/27392)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.838% (22797/27520)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.809% (22895/27648)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.812% (23002/27776)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.798% (23104/27904)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.798% (23210/28032)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.802% (23317/28160)\n",
            "Train Epoch: 99 | Loss: 0.491 | Acc: 82.816% (23427/28288)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.805% (23530/28416)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.774% (23627/28544)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.778% (23734/28672)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.760% (23835/28800)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.757% (23940/28928)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.740% (24041/29056)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.703% (24136/29184)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.710% (24244/29312)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.711% (24350/29440)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.701% (24453/29568)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.722% (24565/29696)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.725% (24672/29824)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.729% (24779/29952)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.749% (24891/30080)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.756% (24999/30208)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.766% (25108/30336)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.786% (25220/30464)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.806% (25332/30592)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.793% (25434/30720)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.800% (25542/30848)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.829% (25657/30976)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.816% (25759/31104)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.803% (25861/31232)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.768% (25956/31360)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.762% (26060/31488)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.752% (26163/31616)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.778% (26277/31744)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.772% (26381/31872)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.750% (26480/32000)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.738% (26582/32128)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.763% (26696/32256)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.785% (26809/32384)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.785% (26915/32512)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.779% (27019/32640)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.779% (27125/32768)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.764% (27226/32896)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.779% (27337/33024)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.794% (27448/33152)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.791% (27553/33280)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.792% (27659/33408)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.807% (27770/33536)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.786% (27869/33664)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.783% (27974/33792)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.780% (28079/33920)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.780% (28185/34048)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.780% (28291/34176)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.757% (28389/34304)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.757% (28495/34432)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.769% (28605/34560)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.766% (28710/34688)\n",
            "Train Epoch: 99 | Loss: 0.492 | Acc: 82.781% (28821/34816)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.770% (28923/34944)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.770% (29029/35072)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.773% (29136/35200)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.759% (29237/35328)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.781% (29351/35456)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.793% (29461/35584)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.773% (29560/35712)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.776% (29667/35840)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.754% (29765/35968)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.746% (29868/36096)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.741% (29972/36224)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.755% (30083/36352)\n",
            "Train Epoch: 99 | Loss: 0.493 | Acc: 82.752% (30188/36480)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.731% (30286/36608)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.720% (30388/36736)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.718% (30493/36864)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.718% (30599/36992)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.705% (30700/37120)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.710% (30808/37248)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.716% (30916/37376)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.717% (31022/37504)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.727% (31132/37632)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.733% (31240/37760)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.720% (31341/37888)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.699% (31439/38016)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.681% (31538/38144)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.669% (31639/38272)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.661% (31742/38400)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.672% (31852/38528)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.670% (31957/38656)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.660% (32059/38784)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.658% (32164/38912)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.649% (32266/39040)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.654% (32374/39168)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.655% (32480/39296)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.655% (32586/39424)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.656% (32692/39552)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.656% (32798/39680)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.679% (32913/39808)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.695% (33025/39936)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.703% (33134/40064)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.703% (33240/40192)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.691% (33341/40320)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.674% (33440/40448)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.662% (33541/40576)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.665% (33648/40704)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.670% (33756/40832)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.666% (33860/40960)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.671% (33968/41088)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.669% (34073/41216)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.660% (34175/41344)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.653% (34278/41472)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.649% (34382/41600)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.640% (34484/41728)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.640% (34590/41856)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.653% (34701/41984)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.658% (34809/42112)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.654% (34913/42240)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.659% (35021/42368)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.683% (35137/42496)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.676% (35240/42624)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.679% (35347/42752)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.680% (35453/42880)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.671% (35555/43008)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.653% (35653/43136)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.665% (35764/43264)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.667% (35871/43392)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.672% (35979/43520)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.677% (36087/43648)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.685% (36196/43776)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.694% (36306/43904)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.692% (36411/44032)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.677% (36510/44160)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.688% (36621/44288)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.684% (36725/44416)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.680% (36829/44544)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.674% (36932/44672)\n",
            "Train Epoch: 99 | Loss: 0.494 | Acc: 82.679% (37040/44800)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.670% (37142/44928)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.659% (37243/45056)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.644% (37342/45184)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.636% (37444/45312)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.630% (37547/45440)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.626% (37651/45568)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.616% (37752/45696)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.618% (37859/45824)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.628% (37969/45952)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.632% (38077/46080)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.639% (38186/46208)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.629% (38287/46336)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.619% (38388/46464)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.619% (38494/46592)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.616% (38598/46720)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.614% (38703/46848)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.610% (38807/46976)\n",
            "Train Epoch: 99 | Loss: 0.496 | Acc: 82.611% (38913/47104)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.622% (39024/47232)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.629% (39133/47360)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.634% (39241/47488)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.632% (39346/47616)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.637% (39454/47744)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.627% (39555/47872)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.638% (39666/48000)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.636% (39771/48128)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.649% (39883/48256)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.651% (39990/48384)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.658% (40099/48512)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.660% (40206/48640)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.663% (40313/48768)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.665% (40420/48896)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.653% (40520/49024)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.650% (40624/49152)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.636% (40723/49280)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.632% (40827/49408)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.647% (40940/49536)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.635% (41040/49664)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.648% (41152/49792)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.644% (41256/49920)\n",
            "Train Epoch: 99 | Loss: 0.495 | Acc: 82.648% (41324/50000)\n",
            "Test Epoch: 99 | Loss: 0.544 | Acc: 82.000% (82/100)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.000% (154/200)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.333% (232/300)\n",
            "Test Epoch: 99 | Loss: 0.703 | Acc: 77.750% (311/400)\n",
            "Test Epoch: 99 | Loss: 0.682 | Acc: 78.000% (390/500)\n",
            "Test Epoch: 99 | Loss: 0.622 | Acc: 79.500% (477/600)\n",
            "Test Epoch: 99 | Loss: 0.627 | Acc: 79.429% (556/700)\n",
            "Test Epoch: 99 | Loss: 0.645 | Acc: 79.125% (633/800)\n",
            "Test Epoch: 99 | Loss: 0.656 | Acc: 78.778% (709/900)\n",
            "Test Epoch: 99 | Loss: 0.643 | Acc: 78.700% (787/1000)\n",
            "Test Epoch: 99 | Loss: 0.632 | Acc: 79.000% (869/1100)\n",
            "Test Epoch: 99 | Loss: 0.635 | Acc: 78.750% (945/1200)\n",
            "Test Epoch: 99 | Loss: 0.639 | Acc: 78.385% (1019/1300)\n",
            "Test Epoch: 99 | Loss: 0.643 | Acc: 78.500% (1099/1400)\n",
            "Test Epoch: 99 | Loss: 0.637 | Acc: 78.733% (1181/1500)\n",
            "Test Epoch: 99 | Loss: 0.650 | Acc: 78.500% (1256/1600)\n",
            "Test Epoch: 99 | Loss: 0.645 | Acc: 78.588% (1336/1700)\n",
            "Test Epoch: 99 | Loss: 0.644 | Acc: 78.333% (1410/1800)\n",
            "Test Epoch: 99 | Loss: 0.646 | Acc: 78.474% (1491/1900)\n",
            "Test Epoch: 99 | Loss: 0.667 | Acc: 77.550% (1551/2000)\n",
            "Test Epoch: 99 | Loss: 0.673 | Acc: 77.429% (1626/2100)\n",
            "Test Epoch: 99 | Loss: 0.676 | Acc: 77.318% (1701/2200)\n",
            "Test Epoch: 99 | Loss: 0.685 | Acc: 77.217% (1776/2300)\n",
            "Test Epoch: 99 | Loss: 0.682 | Acc: 77.292% (1855/2400)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.200% (1930/2500)\n",
            "Test Epoch: 99 | Loss: 0.708 | Acc: 76.885% (1999/2600)\n",
            "Test Epoch: 99 | Loss: 0.700 | Acc: 77.185% (2084/2700)\n",
            "Test Epoch: 99 | Loss: 0.700 | Acc: 77.250% (2163/2800)\n",
            "Test Epoch: 99 | Loss: 0.702 | Acc: 77.379% (2244/2900)\n",
            "Test Epoch: 99 | Loss: 0.699 | Acc: 77.400% (2322/3000)\n",
            "Test Epoch: 99 | Loss: 0.698 | Acc: 77.484% (2402/3100)\n",
            "Test Epoch: 99 | Loss: 0.697 | Acc: 77.438% (2478/3200)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.606% (2561/3300)\n",
            "Test Epoch: 99 | Loss: 0.697 | Acc: 77.500% (2635/3400)\n",
            "Test Epoch: 99 | Loss: 0.699 | Acc: 77.371% (2708/3500)\n",
            "Test Epoch: 99 | Loss: 0.698 | Acc: 77.333% (2784/3600)\n",
            "Test Epoch: 99 | Loss: 0.701 | Acc: 77.243% (2858/3700)\n",
            "Test Epoch: 99 | Loss: 0.705 | Acc: 77.184% (2933/3800)\n",
            "Test Epoch: 99 | Loss: 0.702 | Acc: 77.308% (3015/3900)\n",
            "Test Epoch: 99 | Loss: 0.703 | Acc: 77.400% (3096/4000)\n",
            "Test Epoch: 99 | Loss: 0.705 | Acc: 77.415% (3174/4100)\n",
            "Test Epoch: 99 | Loss: 0.704 | Acc: 77.476% (3254/4200)\n",
            "Test Epoch: 99 | Loss: 0.699 | Acc: 77.651% (3339/4300)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.795% (3423/4400)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.800% (3501/4500)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.717% (3575/4600)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.702% (3652/4700)\n",
            "Test Epoch: 99 | Loss: 0.698 | Acc: 77.708% (3730/4800)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.714% (3808/4900)\n",
            "Test Epoch: 99 | Loss: 0.697 | Acc: 77.680% (3884/5000)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.725% (3964/5100)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.769% (4044/5200)\n",
            "Test Epoch: 99 | Loss: 0.691 | Acc: 77.792% (4123/5300)\n",
            "Test Epoch: 99 | Loss: 0.691 | Acc: 77.870% (4205/5400)\n",
            "Test Epoch: 99 | Loss: 0.691 | Acc: 77.855% (4282/5500)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.804% (4357/5600)\n",
            "Test Epoch: 99 | Loss: 0.698 | Acc: 77.772% (4433/5700)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.879% (4517/5800)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.746% (4587/5900)\n",
            "Test Epoch: 99 | Loss: 0.698 | Acc: 77.683% (4661/6000)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.820% (4747/6100)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.726% (4819/6200)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.730% (4897/6300)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.859% (4983/6400)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.877% (5062/6500)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.833% (5137/6600)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.896% (5219/6700)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.868% (5295/6800)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.913% (5376/6900)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.786% (5445/7000)\n",
            "Test Epoch: 99 | Loss: 0.697 | Acc: 77.746% (5520/7100)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.806% (5602/7200)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.877% (5685/7300)\n",
            "Test Epoch: 99 | Loss: 0.690 | Acc: 77.905% (5765/7400)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.813% (5836/7500)\n",
            "Test Epoch: 99 | Loss: 0.691 | Acc: 77.855% (5917/7600)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.792% (5990/7700)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.679% (6059/7800)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.671% (6136/7900)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.675% (6214/8000)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.654% (6290/8100)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.659% (6368/8200)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.663% (6446/8300)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.679% (6525/8400)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.671% (6602/8500)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.709% (6683/8600)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.678% (6758/8700)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.670% (6835/8800)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.674% (6913/8900)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.711% (6994/9000)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.780% (7078/9100)\n",
            "Test Epoch: 99 | Loss: 0.691 | Acc: 77.859% (7163/9200)\n",
            "Test Epoch: 99 | Loss: 0.692 | Acc: 77.839% (7239/9300)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.798% (7313/9400)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.821% (7393/9500)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.844% (7473/9600)\n",
            "Test Epoch: 99 | Loss: 0.693 | Acc: 77.887% (7555/9700)\n",
            "Test Epoch: 99 | Loss: 0.694 | Acc: 77.786% (7623/9800)\n",
            "Test Epoch: 99 | Loss: 0.695 | Acc: 77.717% (7694/9900)\n",
            "Test Epoch: 99 | Loss: 0.696 | Acc: 77.740% (7774/10000)\n",
            "Saving..\n"
          ]
        }
      ],
      "source": [
        "acc_list = []\n",
        "loss_list = []\n",
        "for epoch in range(start_epoch, start_epoch+100):\n",
        "    train(epoch)\n",
        "    loss, acc = test(epoch)\n",
        "    acc_list.append(acc)\n",
        "    loss_list.append(loss)\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list2 = acc_list\n",
        "loss_list2 = loss_list\n",
        "for epoch in range(start_epoch, start_epoch+50):\n",
        "    train(epoch)\n",
        "    loss, acc =  test(epoch)\n",
        "    acc_list2.append(acc)\n",
        "    loss_list2.append(loss)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "e4iZLyY85H6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a66af7-fe58-4a27-e64e-66f9a3e87a0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 79.062% (2530/3200)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 79.212% (2614/3300)\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 79.088% (2689/3400)\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 78.886% (2761/3500)\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 78.861% (2839/3600)\n",
            "Test Epoch: 39 | Loss: 0.694 | Acc: 78.811% (2916/3700)\n",
            "Test Epoch: 39 | Loss: 0.698 | Acc: 78.658% (2989/3800)\n",
            "Test Epoch: 39 | Loss: 0.697 | Acc: 78.744% (3071/3900)\n",
            "Test Epoch: 39 | Loss: 0.696 | Acc: 78.725% (3149/4000)\n",
            "Test Epoch: 39 | Loss: 0.697 | Acc: 78.707% (3227/4100)\n",
            "Test Epoch: 39 | Loss: 0.695 | Acc: 78.786% (3309/4200)\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 78.860% (3391/4300)\n",
            "Test Epoch: 39 | Loss: 0.687 | Acc: 79.000% (3476/4400)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 79.000% (3555/4500)\n",
            "Test Epoch: 39 | Loss: 0.687 | Acc: 78.978% (3633/4600)\n",
            "Test Epoch: 39 | Loss: 0.688 | Acc: 79.000% (3713/4700)\n",
            "Test Epoch: 39 | Loss: 0.690 | Acc: 78.979% (3791/4800)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 79.061% (3874/4900)\n",
            "Test Epoch: 39 | Loss: 0.689 | Acc: 79.020% (3951/5000)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 79.078% (4033/5100)\n",
            "Test Epoch: 39 | Loss: 0.684 | Acc: 79.077% (4112/5200)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.094% (4192/5300)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 79.111% (4272/5400)\n",
            "Test Epoch: 39 | Loss: 0.680 | Acc: 79.109% (4351/5500)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 79.071% (4428/5600)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 79.070% (4507/5700)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.190% (4593/5800)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.102% (4667/5900)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 79.050% (4743/6000)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.164% (4829/6100)\n",
            "Test Epoch: 39 | Loss: 0.684 | Acc: 79.145% (4907/6200)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 79.127% (4985/6300)\n",
            "Test Epoch: 39 | Loss: 0.680 | Acc: 79.281% (5074/6400)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.246% (5151/6500)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.197% (5227/6600)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 79.209% (5307/6700)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 79.132% (5381/6800)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 79.188% (5464/6900)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 79.129% (5539/7000)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 79.113% (5617/7100)\n",
            "Test Epoch: 39 | Loss: 0.684 | Acc: 79.167% (5700/7200)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 79.233% (5784/7300)\n",
            "Test Epoch: 39 | Loss: 0.678 | Acc: 79.243% (5864/7400)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 79.133% (5935/7500)\n",
            "Test Epoch: 39 | Loss: 0.680 | Acc: 79.171% (6017/7600)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 79.117% (6092/7700)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 79.013% (6163/7800)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 78.949% (6237/7900)\n",
            "Test Epoch: 39 | Loss: 0.686 | Acc: 78.963% (6317/8000)\n",
            "Test Epoch: 39 | Loss: 0.684 | Acc: 78.926% (6393/8100)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 78.915% (6471/8200)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 78.952% (6553/8300)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 78.905% (6628/8400)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 78.871% (6704/8500)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 78.884% (6784/8600)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 78.851% (6860/8700)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 78.841% (6938/8800)\n",
            "Test Epoch: 39 | Loss: 0.685 | Acc: 78.854% (7018/8900)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 78.889% (7100/9000)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 78.945% (7184/9100)\n",
            "Test Epoch: 39 | Loss: 0.680 | Acc: 79.011% (7269/9200)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 78.968% (7344/9300)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 78.915% (7418/9400)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 78.905% (7496/9500)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 78.927% (7577/9600)\n",
            "Test Epoch: 39 | Loss: 0.681 | Acc: 78.969% (7660/9700)\n",
            "Test Epoch: 39 | Loss: 0.682 | Acc: 78.878% (7730/9800)\n",
            "Test Epoch: 39 | Loss: 0.683 | Acc: 78.818% (7803/9900)\n",
            "Test Epoch: 39 | Loss: 0.684 | Acc: 78.800% (7880/10000)\n",
            "\n",
            "Epoch: 40\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.719% (111/128)\n",
            "Train Epoch: 40 | Loss: 0.339 | Acc: 89.844% (230/256)\n",
            "Train Epoch: 40 | Loss: 0.362 | Acc: 88.802% (341/384)\n",
            "Train Epoch: 40 | Loss: 0.379 | Acc: 87.695% (449/512)\n",
            "Train Epoch: 40 | Loss: 0.365 | Acc: 88.594% (567/640)\n",
            "Train Epoch: 40 | Loss: 0.381 | Acc: 88.021% (676/768)\n",
            "Train Epoch: 40 | Loss: 0.381 | Acc: 87.835% (787/896)\n",
            "Train Epoch: 40 | Loss: 0.387 | Acc: 87.207% (893/1024)\n",
            "Train Epoch: 40 | Loss: 0.393 | Acc: 86.892% (1001/1152)\n",
            "Train Epoch: 40 | Loss: 0.396 | Acc: 86.719% (1110/1280)\n",
            "Train Epoch: 40 | Loss: 0.403 | Acc: 86.222% (1214/1408)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.068% (1322/1536)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.697% (1426/1664)\n",
            "Train Epoch: 40 | Loss: 0.423 | Acc: 85.491% (1532/1792)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.625% (1644/1920)\n",
            "Train Epoch: 40 | Loss: 0.415 | Acc: 85.742% (1756/2048)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.616% (1863/2176)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.460% (1969/2304)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.567% (2081/2432)\n",
            "Train Epoch: 40 | Loss: 0.421 | Acc: 85.352% (2185/2560)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.565% (2300/2688)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.511% (2408/2816)\n",
            "Train Epoch: 40 | Loss: 0.424 | Acc: 85.360% (2513/2944)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.547% (2628/3072)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.562% (2738/3200)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.637% (2850/3328)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.648% (2960/3456)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.742% (3073/3584)\n",
            "Train Epoch: 40 | Loss: 0.420 | Acc: 85.668% (3180/3712)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.703% (3291/3840)\n",
            "Train Epoch: 40 | Loss: 0.414 | Acc: 85.736% (3402/3968)\n",
            "Train Epoch: 40 | Loss: 0.415 | Acc: 85.693% (3510/4096)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.559% (3614/4224)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.478% (3720/4352)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.513% (3831/4480)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.612% (3945/4608)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.494% (4049/4736)\n",
            "Train Epoch: 40 | Loss: 0.414 | Acc: 85.629% (4165/4864)\n",
            "Train Epoch: 40 | Loss: 0.414 | Acc: 85.677% (4277/4992)\n",
            "Train Epoch: 40 | Loss: 0.415 | Acc: 85.664% (4386/5120)\n",
            "Train Epoch: 40 | Loss: 0.420 | Acc: 85.499% (4487/5248)\n",
            "Train Epoch: 40 | Loss: 0.423 | Acc: 85.379% (4590/5376)\n",
            "Train Epoch: 40 | Loss: 0.426 | Acc: 85.283% (4694/5504)\n",
            "Train Epoch: 40 | Loss: 0.424 | Acc: 85.387% (4809/5632)\n",
            "Train Epoch: 40 | Loss: 0.423 | Acc: 85.382% (4918/5760)\n",
            "Train Epoch: 40 | Loss: 0.421 | Acc: 85.479% (5033/5888)\n",
            "Train Epoch: 40 | Loss: 0.419 | Acc: 85.539% (5146/6016)\n",
            "Train Epoch: 40 | Loss: 0.419 | Acc: 85.579% (5258/6144)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.571% (5367/6272)\n",
            "Train Epoch: 40 | Loss: 0.418 | Acc: 85.594% (5478/6400)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.677% (5593/6528)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.637% (5700/6656)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.672% (5812/6784)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.706% (5924/6912)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.724% (6035/7040)\n",
            "Train Epoch: 40 | Loss: 0.415 | Acc: 85.826% (6152/7168)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.773% (6258/7296)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.789% (6369/7424)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.805% (6480/7552)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.781% (6588/7680)\n",
            "Train Epoch: 40 | Loss: 0.417 | Acc: 85.809% (6700/7808)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.799% (6809/7936)\n",
            "Train Epoch: 40 | Loss: 0.416 | Acc: 85.789% (6918/8064)\n",
            "Train Epoch: 40 | Loss: 0.413 | Acc: 85.852% (7033/8192)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.865% (7144/8320)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.938% (7260/8448)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.938% (7370/8576)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.926% (7479/8704)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.926% (7589/8832)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.016% (7707/8960)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.081% (7823/9088)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.057% (7931/9216)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.045% (8040/9344)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.064% (8152/9472)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.083% (8264/9600)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.061% (8372/9728)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.090% (8485/9856)\n",
            "Train Epoch: 40 | Loss: 0.404 | Acc: 86.128% (8599/9984)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.106% (8707/10112)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.094% (8816/10240)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.053% (8922/10368)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.061% (9033/10496)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.098% (9147/10624)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.096% (9257/10752)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.085% (9366/10880)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.056% (9473/11008)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.054% (9583/11136)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.106% (9699/11264)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.096% (9808/11392)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.111% (9920/11520)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.118% (10031/11648)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.116% (10141/11776)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.080% (10247/11904)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.070% (10356/12032)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.086% (10468/12160)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.035% (10572/12288)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.026% (10681/12416)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.033% (10792/12544)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.032% (10902/12672)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.000% (11008/12800)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.945% (11111/12928)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.953% (11222/13056)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.960% (11333/13184)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.915% (11437/13312)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.915% (11547/13440)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.967% (11664/13568)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.959% (11773/13696)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.017% (11891/13824)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.002% (11999/13952)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.009% (12110/14080)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.008% (12220/14208)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.965% (12324/14336)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.965% (12434/14464)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.931% (12539/14592)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 85.924% (12648/14720)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.890% (12753/14848)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.884% (12862/14976)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.891% (12973/15104)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.918% (13087/15232)\n",
            "Train Epoch: 40 | Loss: 0.413 | Acc: 85.872% (13190/15360)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.879% (13301/15488)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.918% (13417/15616)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.918% (13527/15744)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.912% (13636/15872)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.925% (13748/16000)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.956% (13863/16128)\n",
            "Train Epoch: 40 | Loss: 0.412 | Acc: 85.944% (13971/16256)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.956% (14083/16384)\n",
            "Train Epoch: 40 | Loss: 0.411 | Acc: 85.974% (14196/16512)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 86.004% (14311/16640)\n",
            "Train Epoch: 40 | Loss: 0.410 | Acc: 86.003% (14421/16768)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.050% (14539/16896)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.073% (14653/17024)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.066% (14762/17152)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.094% (14877/17280)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.098% (14988/17408)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.074% (15094/17536)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.073% (15204/17664)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.061% (15312/17792)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.044% (15419/17920)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.059% (15532/18048)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.075% (15645/18176)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.058% (15752/18304)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.062% (15863/18432)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.067% (15974/18560)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.071% (16085/18688)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.076% (16196/18816)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.080% (16307/18944)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.121% (16425/19072)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.135% (16538/19200)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.124% (16646/19328)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.123% (16756/19456)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.096% (16861/19584)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.115% (16975/19712)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.149% (17092/19840)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.173% (17207/19968)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.161% (17315/20096)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.165% (17426/20224)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.173% (17538/20352)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.167% (17647/20480)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.185% (17761/20608)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.169% (17868/20736)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.182% (17981/20864)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.190% (18093/20992)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.198% (18205/21120)\n",
            "Train Epoch: 40 | Loss: 0.404 | Acc: 86.210% (18318/21248)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.185% (18423/21376)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.198% (18536/21504)\n",
            "Train Epoch: 40 | Loss: 0.405 | Acc: 86.210% (18649/21632)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.172% (18751/21760)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.171% (18861/21888)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.146% (18966/22016)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.150% (19077/22144)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.162% (19190/22272)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.147% (19297/22400)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.155% (19409/22528)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.154% (19519/22656)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.135% (19625/22784)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.112% (19730/22912)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.115% (19841/23040)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.076% (19942/23168)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.075% (20052/23296)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.057% (20158/23424)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.073% (20272/23552)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.039% (20374/23680)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.026% (20481/23808)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.050% (20597/23936)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.041% (20705/24064)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.991% (20803/24192)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.007% (20917/24320)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.995% (21024/24448)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.990% (21133/24576)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.006% (21247/24704)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.010% (21358/24832)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.006% (21467/24960)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.033% (21584/25088)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.037% (21695/25216)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.032% (21804/25344)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.028% (21913/25472)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.016% (22020/25600)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.011% (22129/25728)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.015% (22240/25856)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.022% (22352/25984)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.026% (22463/26112)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.018% (22571/26240)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.021% (22682/26368)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.017% (22791/26496)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.024% (22903/26624)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.023% (23013/26752)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.042% (23128/26880)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.037% (23237/27008)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.019% (23342/27136)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.026% (23454/27264)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.014% (23561/27392)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.043% (23679/27520)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.039% (23788/27648)\n",
            "Train Epoch: 40 | Loss: 0.406 | Acc: 86.053% (23902/27776)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.049% (24011/27904)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.055% (24123/28032)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.026% (24225/28160)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.026% (24335/28288)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.029% (24446/28416)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.015% (24552/28544)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.004% (24659/28672)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.014% (24772/28800)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.007% (24880/28928)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.999% (24988/29056)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.996% (25097/29184)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.006% (25210/29312)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.988% (25315/29440)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.012% (25432/29568)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.995% (25537/29696)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.005% (25650/29824)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.998% (25758/29952)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.997% (25868/30080)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.997% (25978/30208)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.007% (26091/30336)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.026% (26207/30464)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.032% (26319/30592)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.009% (26422/30720)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.028% (26538/30848)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.012% (26643/30976)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.989% (26746/31104)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.011% (26863/31232)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.017% (26975/31360)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.998% (27079/31488)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.975% (27182/31616)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.963% (27288/31744)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.972% (27401/31872)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.994% (27518/32000)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.003% (27631/32128)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.996% (27739/32256)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.005% (27852/32384)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.981% (27954/32512)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.987% (28066/32640)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.974% (28172/32768)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.986% (28286/32896)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.974% (28392/33024)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.983% (28505/33152)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.974% (28612/33280)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.985% (28726/33408)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.006% (28843/33536)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.006% (28953/33664)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.994% (29059/33792)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (29170/33920)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (29280/34048)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.005% (29393/34176)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.016% (29507/34304)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.033% (29623/34432)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.030% (29732/34560)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.018% (29838/34688)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.027% (29951/34816)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.012% (30056/34944)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.023% (30170/35072)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.020% (30279/35200)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.005% (30384/35328)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.005% (30494/35456)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.994% (30600/35584)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (30711/35712)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.004% (30824/35840)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.021% (30940/35968)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.021% (31050/36096)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.023% (31161/36224)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.017% (31269/36352)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.995% (31371/36480)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.992% (31480/36608)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.992% (31590/36736)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.003% (31704/36864)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.002% (31814/36992)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.005% (31925/37120)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.994% (32031/37248)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.994% (32141/37376)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.977% (32245/37504)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.988% (32359/37632)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.990% (32470/37760)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (32582/37888)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.985% (32688/38016)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.982% (32797/38144)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.969% (32902/38272)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.943% (33002/38400)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.945% (33113/38528)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.948% (33224/38656)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.950% (33335/38784)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.963% (33450/38912)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.971% (33563/39040)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.973% (33674/39168)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.960% (33779/39296)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.973% (33894/39424)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.973% (34004/39552)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.958% (34108/39680)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.975% (34225/39808)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.975% (34335/39936)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.965% (34441/40064)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.985% (34559/40192)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.985% (34669/40320)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.994% (34783/40448)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.004% (34897/40576)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.009% (35009/40704)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.011% (35120/40832)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.008% (35229/40960)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (35334/41088)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.010% (35450/41216)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.003% (35557/41344)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.988% (35661/41472)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.988% (35771/41600)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.997% (35885/41728)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.995% (35994/41856)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.011% (36111/41984)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.013% (36222/42112)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.009% (36330/42240)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.015% (36443/42368)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.020% (36555/42496)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.017% (36664/42624)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.998% (36766/42752)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.003% (36878/42880)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.007% (36990/43008)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.002% (37098/43136)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.991% (37203/43264)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.000% (37317/43392)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.000% (37427/43520)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.015% (37544/43648)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.020% (37656/43776)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.006% (37760/43904)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.994% (37865/44032)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.001% (37978/44160)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 85.996% (38086/44288)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.012% (38203/44416)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.018% (38316/44544)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.036% (38434/44672)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.042% (38547/44800)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.051% (38661/44928)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.055% (38773/45056)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.055% (38883/45184)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.046% (38989/45312)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.061% (39106/45440)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.069% (39220/45568)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.060% (39326/45696)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.062% (39437/45824)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.062% (39547/45952)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.055% (39654/46080)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.052% (39763/46208)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.048% (39871/46336)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.039% (39977/46464)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.030% (40083/46592)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.040% (40198/46720)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.046% (40311/46848)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.046% (40421/46976)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.052% (40534/47104)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.054% (40645/47232)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.052% (40754/47360)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.051% (40864/47488)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.055% (40976/47616)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.036% (41077/47744)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.042% (41190/47872)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.046% (41302/48000)\n",
            "Train Epoch: 40 | Loss: 0.407 | Acc: 86.037% (41408/48128)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.035% (41517/48256)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.026% (41623/48384)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.030% (41735/48512)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.022% (41841/48640)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 86.007% (41944/48768)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.015% (42058/48896)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.019% (42170/49024)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.011% (42276/49152)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.011% (42386/49280)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 86.002% (42492/49408)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.990% (42596/49536)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.990% (42706/49664)\n",
            "Train Epoch: 40 | Loss: 0.409 | Acc: 85.994% (42818/49792)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.996% (42929/49920)\n",
            "Train Epoch: 40 | Loss: 0.408 | Acc: 85.998% (42999/50000)\n",
            "Test Epoch: 40 | Loss: 0.510 | Acc: 83.000% (83/100)\n",
            "Test Epoch: 40 | Loss: 0.632 | Acc: 79.500% (159/200)\n",
            "Test Epoch: 40 | Loss: 0.616 | Acc: 79.000% (237/300)\n",
            "Test Epoch: 40 | Loss: 0.647 | Acc: 78.750% (315/400)\n",
            "Test Epoch: 40 | Loss: 0.626 | Acc: 79.600% (398/500)\n",
            "Test Epoch: 40 | Loss: 0.575 | Acc: 81.333% (488/600)\n",
            "Test Epoch: 40 | Loss: 0.590 | Acc: 81.000% (567/700)\n",
            "Test Epoch: 40 | Loss: 0.609 | Acc: 81.000% (648/800)\n",
            "Test Epoch: 40 | Loss: 0.626 | Acc: 80.111% (721/900)\n",
            "Test Epoch: 40 | Loss: 0.616 | Acc: 80.200% (802/1000)\n",
            "Test Epoch: 40 | Loss: 0.609 | Acc: 80.455% (885/1100)\n",
            "Test Epoch: 40 | Loss: 0.610 | Acc: 80.083% (961/1200)\n",
            "Test Epoch: 40 | Loss: 0.609 | Acc: 79.923% (1039/1300)\n",
            "Test Epoch: 40 | Loss: 0.615 | Acc: 79.929% (1119/1400)\n",
            "Test Epoch: 40 | Loss: 0.610 | Acc: 80.067% (1201/1500)\n",
            "Test Epoch: 40 | Loss: 0.629 | Acc: 79.875% (1278/1600)\n",
            "Test Epoch: 40 | Loss: 0.623 | Acc: 79.941% (1359/1700)\n",
            "Test Epoch: 40 | Loss: 0.621 | Acc: 79.944% (1439/1800)\n",
            "Test Epoch: 40 | Loss: 0.619 | Acc: 80.263% (1525/1900)\n",
            "Test Epoch: 40 | Loss: 0.641 | Acc: 79.550% (1591/2000)\n",
            "Test Epoch: 40 | Loss: 0.653 | Acc: 79.381% (1667/2100)\n",
            "Test Epoch: 40 | Loss: 0.656 | Acc: 79.318% (1745/2200)\n",
            "Test Epoch: 40 | Loss: 0.666 | Acc: 79.261% (1823/2300)\n",
            "Test Epoch: 40 | Loss: 0.662 | Acc: 79.333% (1904/2400)\n",
            "Test Epoch: 40 | Loss: 0.673 | Acc: 79.120% (1978/2500)\n",
            "Test Epoch: 40 | Loss: 0.689 | Acc: 78.885% (2051/2600)\n",
            "Test Epoch: 40 | Loss: 0.681 | Acc: 79.000% (2133/2700)\n",
            "Test Epoch: 40 | Loss: 0.681 | Acc: 79.000% (2212/2800)\n",
            "Test Epoch: 40 | Loss: 0.683 | Acc: 78.897% (2288/2900)\n",
            "Test Epoch: 40 | Loss: 0.680 | Acc: 78.867% (2366/3000)\n",
            "Test Epoch: 40 | Loss: 0.680 | Acc: 78.871% (2445/3100)\n",
            "Test Epoch: 40 | Loss: 0.680 | Acc: 78.844% (2523/3200)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 78.970% (2606/3300)\n",
            "Test Epoch: 40 | Loss: 0.679 | Acc: 78.882% (2682/3400)\n",
            "Test Epoch: 40 | Loss: 0.679 | Acc: 78.771% (2757/3500)\n",
            "Test Epoch: 40 | Loss: 0.679 | Acc: 78.667% (2832/3600)\n",
            "Test Epoch: 40 | Loss: 0.683 | Acc: 78.649% (2910/3700)\n",
            "Test Epoch: 40 | Loss: 0.688 | Acc: 78.500% (2983/3800)\n",
            "Test Epoch: 40 | Loss: 0.686 | Acc: 78.590% (3065/3900)\n",
            "Test Epoch: 40 | Loss: 0.686 | Acc: 78.650% (3146/4000)\n",
            "Test Epoch: 40 | Loss: 0.687 | Acc: 78.659% (3225/4100)\n",
            "Test Epoch: 40 | Loss: 0.686 | Acc: 78.762% (3308/4200)\n",
            "Test Epoch: 40 | Loss: 0.681 | Acc: 78.907% (3393/4300)\n",
            "Test Epoch: 40 | Loss: 0.678 | Acc: 79.045% (3478/4400)\n",
            "Test Epoch: 40 | Loss: 0.678 | Acc: 79.089% (3559/4500)\n",
            "Test Epoch: 40 | Loss: 0.679 | Acc: 79.022% (3635/4600)\n",
            "Test Epoch: 40 | Loss: 0.680 | Acc: 79.021% (3714/4700)\n",
            "Test Epoch: 40 | Loss: 0.681 | Acc: 79.021% (3793/4800)\n",
            "Test Epoch: 40 | Loss: 0.678 | Acc: 79.122% (3877/4900)\n",
            "Test Epoch: 40 | Loss: 0.681 | Acc: 79.020% (3951/5000)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.098% (4034/5100)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.096% (4113/5200)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.132% (4194/5300)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.204% (4277/5400)\n",
            "Test Epoch: 40 | Loss: 0.672 | Acc: 79.255% (4359/5500)\n",
            "Test Epoch: 40 | Loss: 0.673 | Acc: 79.232% (4437/5600)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.228% (4516/5700)\n",
            "Test Epoch: 40 | Loss: 0.673 | Acc: 79.293% (4599/5800)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.153% (4670/5900)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 79.117% (4747/6000)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.230% (4833/6100)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.161% (4908/6200)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 79.143% (4986/6300)\n",
            "Test Epoch: 40 | Loss: 0.671 | Acc: 79.281% (5074/6400)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.215% (5149/6500)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.136% (5223/6600)\n",
            "Test Epoch: 40 | Loss: 0.672 | Acc: 79.194% (5306/6700)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.118% (5380/6800)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.174% (5463/6900)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 79.100% (5537/7000)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.085% (5615/7100)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.139% (5698/7200)\n",
            "Test Epoch: 40 | Loss: 0.672 | Acc: 79.219% (5783/7300)\n",
            "Test Epoch: 40 | Loss: 0.670 | Acc: 79.243% (5864/7400)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.147% (5936/7500)\n",
            "Test Epoch: 40 | Loss: 0.672 | Acc: 79.211% (6020/7600)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.117% (6092/7700)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.064% (6167/7800)\n",
            "Test Epoch: 40 | Loss: 0.678 | Acc: 79.051% (6245/7900)\n",
            "Test Epoch: 40 | Loss: 0.678 | Acc: 79.075% (6326/8000)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 79.086% (6406/8100)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.098% (6486/8200)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.145% (6569/8300)\n",
            "Test Epoch: 40 | Loss: 0.673 | Acc: 79.131% (6647/8400)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.082% (6722/8500)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.116% (6804/8600)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.046% (6877/8700)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 78.966% (6949/8800)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 78.944% (7026/8900)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 78.978% (7108/9000)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.044% (7193/9100)\n",
            "Test Epoch: 40 | Loss: 0.673 | Acc: 79.109% (7278/9200)\n",
            "Test Epoch: 40 | Loss: 0.674 | Acc: 79.075% (7354/9300)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 79.000% (7426/9400)\n",
            "Test Epoch: 40 | Loss: 0.676 | Acc: 78.989% (7504/9500)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.031% (7587/9600)\n",
            "Test Epoch: 40 | Loss: 0.675 | Acc: 79.072% (7670/9700)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 79.000% (7742/9800)\n",
            "Test Epoch: 40 | Loss: 0.677 | Acc: 78.949% (7816/9900)\n",
            "Test Epoch: 40 | Loss: 0.679 | Acc: 78.960% (7896/10000)\n",
            "\n",
            "Epoch: 41\n",
            "Train Epoch: 41 | Loss: 0.441 | Acc: 82.812% (106/128)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 83.984% (215/256)\n",
            "Train Epoch: 41 | Loss: 0.398 | Acc: 84.635% (325/384)\n",
            "Train Epoch: 41 | Loss: 0.405 | Acc: 84.766% (434/512)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 83.906% (537/640)\n",
            "Train Epoch: 41 | Loss: 0.441 | Acc: 83.203% (639/768)\n",
            "Train Epoch: 41 | Loss: 0.433 | Acc: 83.817% (751/896)\n",
            "Train Epoch: 41 | Loss: 0.435 | Acc: 83.496% (855/1024)\n",
            "Train Epoch: 41 | Loss: 0.433 | Acc: 83.854% (966/1152)\n",
            "Train Epoch: 41 | Loss: 0.438 | Acc: 83.984% (1075/1280)\n",
            "Train Epoch: 41 | Loss: 0.450 | Acc: 83.310% (1173/1408)\n",
            "Train Epoch: 41 | Loss: 0.438 | Acc: 83.789% (1287/1536)\n",
            "Train Epoch: 41 | Loss: 0.433 | Acc: 84.135% (1400/1664)\n",
            "Train Epoch: 41 | Loss: 0.431 | Acc: 84.208% (1509/1792)\n",
            "Train Epoch: 41 | Loss: 0.436 | Acc: 84.167% (1616/1920)\n",
            "Train Epoch: 41 | Loss: 0.435 | Acc: 84.375% (1728/2048)\n",
            "Train Epoch: 41 | Loss: 0.428 | Acc: 84.651% (1842/2176)\n",
            "Train Epoch: 41 | Loss: 0.426 | Acc: 84.852% (1955/2304)\n",
            "Train Epoch: 41 | Loss: 0.421 | Acc: 85.115% (2070/2432)\n",
            "Train Epoch: 41 | Loss: 0.417 | Acc: 85.352% (2185/2560)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.417% (2296/2688)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.547% (2409/2816)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.530% (2518/2944)\n",
            "Train Epoch: 41 | Loss: 0.419 | Acc: 85.384% (2623/3072)\n",
            "Train Epoch: 41 | Loss: 0.418 | Acc: 85.469% (2735/3200)\n",
            "Train Epoch: 41 | Loss: 0.418 | Acc: 85.547% (2847/3328)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.764% (2964/3456)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.798% (3075/3584)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.722% (3182/3712)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.677% (3290/3840)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.811% (3405/3968)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.815% (3515/4096)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.701% (3620/4224)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.685% (3729/4352)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.513% (3831/4480)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.547% (3942/4608)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.557% (4052/4736)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.526% (4160/4864)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.497% (4268/4992)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.547% (4380/5120)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.575% (4491/5248)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.510% (4597/5376)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.610% (4712/5504)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.618% (4822/5632)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.608% (4931/5760)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.819% (5053/5888)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.854% (5165/6016)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.921% (5279/6144)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.938% (5390/6272)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.984% (5503/6400)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.029% (5616/6528)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.028% (5726/6656)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.967% (5832/6784)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.995% (5944/6912)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.938% (6050/7040)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.979% (6163/7168)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.924% (6269/7296)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.870% (6375/7424)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.924% (6489/7552)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.859% (6594/7680)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.899% (6707/7808)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.900% (6817/7936)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.875% (6925/8064)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.889% (7036/8192)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.877% (7145/8320)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.878% (7255/8448)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.868% (7364/8576)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.823% (7470/8704)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.813% (7579/8832)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.804% (7688/8960)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.816% (7799/9088)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.796% (7907/9216)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.830% (8020/9344)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.790% (8126/9472)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.802% (8237/9600)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.773% (8344/9728)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.765% (8453/9856)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.687% (8555/9984)\n",
            "Train Epoch: 41 | Loss: 0.417 | Acc: 85.700% (8666/10112)\n",
            "Train Epoch: 41 | Loss: 0.416 | Acc: 85.742% (8780/10240)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.802% (8896/10368)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.814% (9007/10496)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.890% (9125/10624)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.928% (9239/10752)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.928% (9349/10880)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.938% (9460/11008)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.893% (9565/11136)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.884% (9674/11264)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.885% (9784/11392)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.929% (9899/11520)\n",
            "Train Epoch: 41 | Loss: 0.415 | Acc: 85.946% (10011/11648)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.954% (10122/11776)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.980% (10235/11904)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.996% (10347/12032)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.970% (10454/12160)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.921% (10558/12288)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.921% (10668/12416)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.953% (10782/12544)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.977% (10895/12672)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.977% (11005/12800)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 86.023% (11121/12928)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 86.045% (11234/13056)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.991% (11337/13184)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.953% (11442/13312)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.967% (11554/13440)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.974% (11665/13568)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.967% (11774/13696)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.923% (11878/13824)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.909% (11986/13952)\n",
            "Train Epoch: 41 | Loss: 0.414 | Acc: 85.930% (12099/14080)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.945% (12211/14208)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.951% (12322/14336)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.965% (12434/14464)\n",
            "Train Epoch: 41 | Loss: 0.413 | Acc: 85.931% (12539/14592)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.958% (12653/14720)\n",
            "Train Epoch: 41 | Loss: 0.412 | Acc: 85.978% (12766/14848)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 86.018% (12882/14976)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.984% (12987/15104)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.990% (13098/15232)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.990% (13208/15360)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.989% (13318/15488)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.982% (13427/15616)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.957% (13533/15744)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.963% (13644/15872)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.969% (13755/16000)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.981% (13867/16128)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.931% (13969/16256)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.968% (14085/16384)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.980% (14197/16512)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.986% (14308/16640)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.991% (14419/16768)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.009% (14532/16896)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.049% (14649/17024)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.019% (14754/17152)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.059% (14871/17280)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.070% (14983/17408)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.086% (15096/17536)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.062% (15202/17664)\n",
            "Train Epoch: 41 | Loss: 0.407 | Acc: 86.050% (15310/17792)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.988% (15409/17920)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.004% (15522/18048)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.998% (15631/18176)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.003% (15742/18304)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.986% (15849/18432)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.991% (15960/18560)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.959% (16064/18688)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.953% (16173/18816)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.943% (16281/18944)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.948% (16392/19072)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.948% (16502/19200)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.943% (16611/19328)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.958% (16724/19456)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.932% (16829/19584)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.938% (16940/19712)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.953% (17053/19840)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.938% (17160/19968)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.918% (17266/20096)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.928% (17378/20224)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.918% (17486/20352)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.952% (17603/20480)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.962% (17715/20608)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.957% (17824/20736)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.971% (17937/20864)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.966% (18046/20992)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.975% (18158/21120)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.970% (18267/21248)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.956% (18374/21376)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.933% (18479/21504)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.928% (18588/21632)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.947% (18702/21760)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.951% (18813/21888)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.915% (18915/22016)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.928% (19028/22144)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.920% (19136/22272)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.929% (19248/22400)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.951% (19363/22528)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.960% (19475/22656)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.959% (19585/22784)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.981% (19700/22912)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.959% (19805/23040)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.976% (19919/23168)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.019% (20039/23296)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.031% (20152/23424)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.010% (20257/23552)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 86.009% (20367/23680)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.996% (20474/23808)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.983% (20581/23936)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.996% (20694/24064)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.995% (20804/24192)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.970% (20908/24320)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.946% (21012/24448)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.950% (21123/24576)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.933% (21229/24704)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.917% (21335/24832)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.901% (21441/24960)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.906% (21552/25088)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.910% (21663/25216)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.898% (21770/25344)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.890% (21878/25472)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.906% (21992/25600)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.906% (22102/25728)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.907% (22212/25856)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.891% (22318/25984)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.876% (22424/26112)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.857% (22529/26240)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.839% (22634/26368)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.862% (22750/26496)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.862% (22860/26624)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.840% (22964/26752)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.837% (23073/26880)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.845% (23185/27008)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.853% (23297/27136)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.842% (23404/27264)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.832% (23511/27392)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.847% (23625/27520)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.851% (23736/27648)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.855% (23847/27776)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.826% (23949/27904)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.809% (24054/28032)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.806% (24163/28160)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.785% (24267/28288)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.783% (24376/28416)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.801% (24491/28544)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.812% (24604/28672)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.809% (24713/28800)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.803% (24821/28928)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.800% (24930/29056)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.807% (25042/29184)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.801% (25150/29312)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.778% (25253/29440)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.782% (25364/29568)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.806% (25481/29696)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.813% (25593/29824)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.787% (25695/29952)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.755% (25795/30080)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.742% (25901/30208)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.746% (26012/30336)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.757% (26125/30464)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.768% (26238/30592)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.758% (26345/30720)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.753% (26453/30848)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.773% (26569/30976)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.780% (26681/31104)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.781% (26791/31232)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.762% (26895/31360)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.728% (26994/31488)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.719% (27101/31616)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.711% (27208/31744)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.715% (27319/31872)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.709% (27427/32000)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.729% (27543/32128)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.730% (27653/32256)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.731% (27763/32384)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.719% (27869/32512)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.702% (27973/32640)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.703% (28083/32768)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.694% (28190/32896)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.723% (28309/33024)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.729% (28421/33152)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.730% (28531/33280)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.728% (28640/33408)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.723% (28748/33536)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.715% (28855/33664)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.724% (28968/33792)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.719% (29076/33920)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.723% (29187/34048)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.741% (29303/34176)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.733% (29410/34304)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.752% (29526/34432)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.752% (29636/34560)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.765% (29750/34688)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.771% (29862/34816)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.754% (29966/34944)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.746% (30073/35072)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.767% (30190/35200)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.765% (30299/35328)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.777% (30413/35456)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.775% (30522/35584)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.781% (30634/35712)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.773% (30741/35840)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.776% (30852/35968)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.777% (30962/36096)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.772% (31070/36224)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.764% (31177/36352)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.776% (31291/36480)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.763% (31396/36608)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.761% (31505/36736)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.753% (31612/36864)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.756% (31723/36992)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.754% (31832/37120)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.766% (31946/37248)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.766% (32056/37376)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.775% (32169/37504)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.773% (32278/37632)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.768% (32386/37760)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.742% (32486/37888)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.751% (32599/38016)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.762% (32713/38144)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.765% (32824/38272)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.745% (32926/38400)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.745% (33036/38528)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.741% (33144/38656)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.744% (33255/38784)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.742% (33364/38912)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.748% (33476/39040)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.766% (33593/39168)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.772% (33705/39296)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.770% (33814/39424)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.768% (33923/39552)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.769% (34033/39680)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.779% (34147/39808)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.782% (34258/39936)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.778% (34366/40064)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.781% (34477/40192)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.771% (34583/40320)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.769% (34692/40448)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.760% (34798/40576)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.773% (34913/40704)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.771% (35022/40832)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.776% (35134/40960)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.767% (35240/41088)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.768% (35350/41216)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.771% (35461/41344)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.757% (35565/41472)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.752% (35673/41600)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.746% (35780/41728)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.751% (35892/41856)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.749% (36001/41984)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.752% (36112/42112)\n",
            "Train Epoch: 41 | Loss: 0.411 | Acc: 85.748% (36220/42240)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.765% (36337/42368)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.770% (36449/42496)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.764% (36556/42624)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.757% (36663/42752)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.765% (36776/42880)\n",
            "Train Epoch: 41 | Loss: 0.410 | Acc: 85.777% (36891/43008)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.791% (37007/43136)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.801% (37121/43264)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.797% (37229/43392)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.807% (37343/43520)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.800% (37450/43648)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.800% (37560/43776)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.796% (37668/43904)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.810% (37784/44032)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.806% (37892/44160)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.798% (37998/44288)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.807% (38112/44416)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.807% (38222/44544)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.812% (38334/44672)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.806% (38441/44800)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.802% (38549/44928)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.798% (38657/45056)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.785% (38761/45184)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.794% (38875/45312)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.797% (38986/45440)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.819% (39106/45568)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.826% (39219/45696)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.828% (39330/45824)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.835% (39443/45952)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.833% (39552/46080)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.847% (39668/46208)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.849% (39779/46336)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.858% (39893/46464)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.862% (40005/46592)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.835% (40102/46720)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.835% (40212/46848)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.827% (40318/46976)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.821% (40425/47104)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.821% (40535/47232)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.834% (40651/47360)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.813% (40751/47488)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.809% (40859/47616)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.801% (40965/47744)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.808% (41078/47872)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.798% (41183/48000)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.805% (41296/48128)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.805% (41406/48256)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.801% (41514/48384)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.801% (41624/48512)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.796% (41731/48640)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.800% (41843/48768)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.798% (41952/48896)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.803% (42064/49024)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.799% (42172/49152)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.785% (42275/49280)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.772% (42378/49408)\n",
            "Train Epoch: 41 | Loss: 0.409 | Acc: 85.774% (42489/49536)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.782% (42603/49664)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.785% (42714/49792)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.783% (42823/49920)\n",
            "Train Epoch: 41 | Loss: 0.408 | Acc: 85.778% (42889/50000)\n",
            "Test Epoch: 41 | Loss: 0.514 | Acc: 83.000% (83/100)\n",
            "Test Epoch: 41 | Loss: 0.629 | Acc: 81.500% (163/200)\n",
            "Test Epoch: 41 | Loss: 0.627 | Acc: 79.667% (239/300)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.500% (318/400)\n",
            "Test Epoch: 41 | Loss: 0.649 | Acc: 80.000% (400/500)\n",
            "Test Epoch: 41 | Loss: 0.591 | Acc: 81.500% (489/600)\n",
            "Test Epoch: 41 | Loss: 0.601 | Acc: 81.000% (567/700)\n",
            "Test Epoch: 41 | Loss: 0.616 | Acc: 81.125% (649/800)\n",
            "Test Epoch: 41 | Loss: 0.632 | Acc: 80.333% (723/900)\n",
            "Test Epoch: 41 | Loss: 0.623 | Acc: 80.200% (802/1000)\n",
            "Test Epoch: 41 | Loss: 0.613 | Acc: 80.455% (885/1100)\n",
            "Test Epoch: 41 | Loss: 0.617 | Acc: 80.000% (960/1200)\n",
            "Test Epoch: 41 | Loss: 0.613 | Acc: 79.923% (1039/1300)\n",
            "Test Epoch: 41 | Loss: 0.618 | Acc: 79.643% (1115/1400)\n",
            "Test Epoch: 41 | Loss: 0.612 | Acc: 79.867% (1198/1500)\n",
            "Test Epoch: 41 | Loss: 0.629 | Acc: 79.562% (1273/1600)\n",
            "Test Epoch: 41 | Loss: 0.624 | Acc: 79.588% (1353/1700)\n",
            "Test Epoch: 41 | Loss: 0.625 | Acc: 79.611% (1433/1800)\n",
            "Test Epoch: 41 | Loss: 0.624 | Acc: 79.842% (1517/1900)\n",
            "Test Epoch: 41 | Loss: 0.648 | Acc: 79.200% (1584/2000)\n",
            "Test Epoch: 41 | Loss: 0.659 | Acc: 79.095% (1661/2100)\n",
            "Test Epoch: 41 | Loss: 0.662 | Acc: 78.909% (1736/2200)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.783% (1812/2300)\n",
            "Test Epoch: 41 | Loss: 0.667 | Acc: 78.833% (1892/2400)\n",
            "Test Epoch: 41 | Loss: 0.678 | Acc: 78.640% (1966/2500)\n",
            "Test Epoch: 41 | Loss: 0.694 | Acc: 78.423% (2039/2600)\n",
            "Test Epoch: 41 | Loss: 0.685 | Acc: 78.593% (2122/2700)\n",
            "Test Epoch: 41 | Loss: 0.684 | Acc: 78.714% (2204/2800)\n",
            "Test Epoch: 41 | Loss: 0.685 | Acc: 78.586% (2279/2900)\n",
            "Test Epoch: 41 | Loss: 0.682 | Acc: 78.533% (2356/3000)\n",
            "Test Epoch: 41 | Loss: 0.683 | Acc: 78.516% (2434/3100)\n",
            "Test Epoch: 41 | Loss: 0.684 | Acc: 78.469% (2511/3200)\n",
            "Test Epoch: 41 | Loss: 0.678 | Acc: 78.606% (2594/3300)\n",
            "Test Epoch: 41 | Loss: 0.683 | Acc: 78.500% (2669/3400)\n",
            "Test Epoch: 41 | Loss: 0.683 | Acc: 78.400% (2744/3500)\n",
            "Test Epoch: 41 | Loss: 0.683 | Acc: 78.306% (2819/3600)\n",
            "Test Epoch: 41 | Loss: 0.686 | Acc: 78.378% (2900/3700)\n",
            "Test Epoch: 41 | Loss: 0.690 | Acc: 78.263% (2974/3800)\n",
            "Test Epoch: 41 | Loss: 0.689 | Acc: 78.385% (3057/3900)\n",
            "Test Epoch: 41 | Loss: 0.688 | Acc: 78.400% (3136/4000)\n",
            "Test Epoch: 41 | Loss: 0.689 | Acc: 78.488% (3218/4100)\n",
            "Test Epoch: 41 | Loss: 0.687 | Acc: 78.643% (3303/4200)\n",
            "Test Epoch: 41 | Loss: 0.682 | Acc: 78.791% (3388/4300)\n",
            "Test Epoch: 41 | Loss: 0.679 | Acc: 78.932% (3473/4400)\n",
            "Test Epoch: 41 | Loss: 0.679 | Acc: 78.911% (3551/4500)\n",
            "Test Epoch: 41 | Loss: 0.679 | Acc: 78.826% (3626/4600)\n",
            "Test Epoch: 41 | Loss: 0.680 | Acc: 78.851% (3706/4700)\n",
            "Test Epoch: 41 | Loss: 0.681 | Acc: 78.833% (3784/4800)\n",
            "Test Epoch: 41 | Loss: 0.678 | Acc: 78.898% (3866/4900)\n",
            "Test Epoch: 41 | Loss: 0.681 | Acc: 78.760% (3938/5000)\n",
            "Test Epoch: 41 | Loss: 0.677 | Acc: 78.843% (4021/5100)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.808% (4098/5200)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.811% (4177/5300)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.889% (4260/5400)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.945% (4342/5500)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.946% (4421/5600)\n",
            "Test Epoch: 41 | Loss: 0.677 | Acc: 78.947% (4500/5700)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.069% (4586/5800)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.983% (4660/5900)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.950% (4737/6000)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.066% (4823/6100)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.016% (4899/6200)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 79.016% (4978/6300)\n",
            "Test Epoch: 41 | Loss: 0.670 | Acc: 79.172% (5067/6400)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 79.123% (5143/6500)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 79.030% (5216/6600)\n",
            "Test Epoch: 41 | Loss: 0.671 | Acc: 79.090% (5299/6700)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.000% (5372/6800)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.000% (5451/6900)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.943% (5526/7000)\n",
            "Test Epoch: 41 | Loss: 0.677 | Acc: 78.915% (5603/7100)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.972% (5686/7200)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 79.068% (5772/7300)\n",
            "Test Epoch: 41 | Loss: 0.670 | Acc: 79.108% (5854/7400)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 79.000% (5925/7500)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 79.053% (6008/7600)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.987% (6082/7700)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.910% (6155/7800)\n",
            "Test Epoch: 41 | Loss: 0.677 | Acc: 78.861% (6230/7900)\n",
            "Test Epoch: 41 | Loss: 0.678 | Acc: 78.888% (6311/8000)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.914% (6392/8100)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.951% (6474/8200)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.964% (6554/8300)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.940% (6631/8400)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.882% (6705/8500)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.895% (6785/8600)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.839% (6859/8700)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.784% (6933/8800)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.764% (7010/8900)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.822% (7094/9000)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.912% (7181/9100)\n",
            "Test Epoch: 41 | Loss: 0.671 | Acc: 78.967% (7265/9200)\n",
            "Test Epoch: 41 | Loss: 0.672 | Acc: 78.914% (7339/9300)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.851% (7412/9400)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.842% (7490/9500)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.865% (7571/9600)\n",
            "Test Epoch: 41 | Loss: 0.673 | Acc: 78.918% (7655/9700)\n",
            "Test Epoch: 41 | Loss: 0.674 | Acc: 78.847% (7727/9800)\n",
            "Test Epoch: 41 | Loss: 0.675 | Acc: 78.808% (7802/9900)\n",
            "Test Epoch: 41 | Loss: 0.676 | Acc: 78.800% (7880/10000)\n",
            "\n",
            "Epoch: 42\n",
            "Train Epoch: 42 | Loss: 0.361 | Acc: 85.156% (109/128)\n",
            "Train Epoch: 42 | Loss: 0.311 | Acc: 87.500% (224/256)\n",
            "Train Epoch: 42 | Loss: 0.342 | Acc: 86.979% (334/384)\n",
            "Train Epoch: 42 | Loss: 0.368 | Acc: 86.328% (442/512)\n",
            "Train Epoch: 42 | Loss: 0.361 | Acc: 86.875% (556/640)\n",
            "Train Epoch: 42 | Loss: 0.370 | Acc: 86.849% (667/768)\n",
            "Train Epoch: 42 | Loss: 0.375 | Acc: 86.942% (779/896)\n",
            "Train Epoch: 42 | Loss: 0.385 | Acc: 86.328% (884/1024)\n",
            "Train Epoch: 42 | Loss: 0.376 | Acc: 86.632% (998/1152)\n",
            "Train Epoch: 42 | Loss: 0.379 | Acc: 86.562% (1108/1280)\n",
            "Train Epoch: 42 | Loss: 0.375 | Acc: 86.719% (1221/1408)\n",
            "Train Epoch: 42 | Loss: 0.388 | Acc: 86.393% (1327/1536)\n",
            "Train Epoch: 42 | Loss: 0.384 | Acc: 86.599% (1441/1664)\n",
            "Train Epoch: 42 | Loss: 0.377 | Acc: 86.830% (1556/1792)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.562% (1662/1920)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.621% (1774/2048)\n",
            "Train Epoch: 42 | Loss: 0.391 | Acc: 86.397% (1880/2176)\n",
            "Train Epoch: 42 | Loss: 0.387 | Acc: 86.502% (1993/2304)\n",
            "Train Epoch: 42 | Loss: 0.383 | Acc: 86.678% (2108/2432)\n",
            "Train Epoch: 42 | Loss: 0.383 | Acc: 86.758% (2221/2560)\n",
            "Train Epoch: 42 | Loss: 0.390 | Acc: 86.570% (2327/2688)\n",
            "Train Epoch: 42 | Loss: 0.388 | Acc: 86.719% (2442/2816)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.855% (2557/2944)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.751% (2665/3072)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.688% (2774/3200)\n",
            "Train Epoch: 42 | Loss: 0.387 | Acc: 86.749% (2887/3328)\n",
            "Train Epoch: 42 | Loss: 0.387 | Acc: 86.690% (2996/3456)\n",
            "Train Epoch: 42 | Loss: 0.384 | Acc: 86.775% (3110/3584)\n",
            "Train Epoch: 42 | Loss: 0.385 | Acc: 86.800% (3222/3712)\n",
            "Train Epoch: 42 | Loss: 0.383 | Acc: 86.849% (3335/3840)\n",
            "Train Epoch: 42 | Loss: 0.385 | Acc: 86.794% (3444/3968)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.719% (3552/4096)\n",
            "Train Epoch: 42 | Loss: 0.385 | Acc: 86.766% (3665/4224)\n",
            "Train Epoch: 42 | Loss: 0.384 | Acc: 86.788% (3777/4352)\n",
            "Train Epoch: 42 | Loss: 0.384 | Acc: 86.830% (3890/4480)\n",
            "Train Epoch: 42 | Loss: 0.382 | Acc: 86.871% (4003/4608)\n",
            "Train Epoch: 42 | Loss: 0.384 | Acc: 86.845% (4113/4736)\n",
            "Train Epoch: 42 | Loss: 0.385 | Acc: 86.883% (4226/4864)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.919% (4339/4992)\n",
            "Train Epoch: 42 | Loss: 0.388 | Acc: 86.816% (4445/5120)\n",
            "Train Epoch: 42 | Loss: 0.389 | Acc: 86.795% (4555/5248)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.849% (4669/5376)\n",
            "Train Epoch: 42 | Loss: 0.386 | Acc: 86.828% (4779/5504)\n",
            "Train Epoch: 42 | Loss: 0.388 | Acc: 86.790% (4888/5632)\n",
            "Train Epoch: 42 | Loss: 0.391 | Acc: 86.736% (4996/5760)\n",
            "Train Epoch: 42 | Loss: 0.391 | Acc: 86.736% (5107/5888)\n",
            "Train Epoch: 42 | Loss: 0.392 | Acc: 86.735% (5218/6016)\n",
            "Train Epoch: 42 | Loss: 0.393 | Acc: 86.735% (5329/6144)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.655% (5435/6272)\n",
            "Train Epoch: 42 | Loss: 0.392 | Acc: 86.734% (5551/6400)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.673% (5658/6528)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.599% (5764/6656)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.660% (5879/6784)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.617% (5987/6912)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.648% (6100/7040)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.663% (6212/7168)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.678% (6324/7296)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.678% (6435/7424)\n",
            "Train Epoch: 42 | Loss: 0.393 | Acc: 86.732% (6550/7552)\n",
            "Train Epoch: 42 | Loss: 0.393 | Acc: 86.732% (6661/7680)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.732% (6772/7808)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.744% (6884/7936)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.806% (7000/8064)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.816% (7112/8192)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.791% (7221/8320)\n",
            "Train Epoch: 42 | Loss: 0.392 | Acc: 86.790% (7332/8448)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.754% (7440/8576)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.742% (7550/8704)\n",
            "Train Epoch: 42 | Loss: 0.393 | Acc: 86.787% (7665/8832)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.696% (7768/8960)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.686% (7878/9088)\n",
            "Train Epoch: 42 | Loss: 0.394 | Acc: 86.664% (7987/9216)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.665% (8098/9344)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.613% (8204/9472)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.615% (8315/9600)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.647% (8429/9728)\n",
            "Train Epoch: 42 | Loss: 0.395 | Acc: 86.668% (8542/9856)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.528% (8639/9984)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.561% (8753/10112)\n",
            "Train Epoch: 42 | Loss: 0.396 | Acc: 86.553% (8863/10240)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.497% (8968/10368)\n",
            "Train Epoch: 42 | Loss: 0.398 | Acc: 86.452% (9074/10496)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.483% (9188/10624)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.477% (9298/10752)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.443% (9405/10880)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.419% (9513/11008)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.458% (9628/11136)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.444% (9737/11264)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.455% (9849/11392)\n",
            "Train Epoch: 42 | Loss: 0.398 | Acc: 86.432% (9957/11520)\n",
            "Train Epoch: 42 | Loss: 0.398 | Acc: 86.418% (10066/11648)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.472% (10183/11776)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.475% (10294/11904)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.486% (10406/12032)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.480% (10516/12160)\n",
            "Train Epoch: 42 | Loss: 0.397 | Acc: 86.475% (10626/12288)\n",
            "Train Epoch: 42 | Loss: 0.398 | Acc: 86.453% (10734/12416)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.408% (10839/12544)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.419% (10951/12672)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.422% (11062/12800)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.371% (11166/12928)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.389% (11279/13056)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.431% (11395/13184)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.418% (11504/13312)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.391% (11611/13440)\n",
            "Train Epoch: 42 | Loss: 0.399 | Acc: 86.387% (11721/13568)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.339% (11825/13696)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.314% (11932/13824)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.310% (12042/13952)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.293% (12150/14080)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.254% (12255/14208)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.237% (12363/14336)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.242% (12474/14464)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.266% (12588/14592)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.257% (12697/14720)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.254% (12807/14848)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.251% (12917/14976)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.302% (13035/15104)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.345% (13152/15232)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.309% (13257/15360)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.338% (13372/15488)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.296% (13476/15616)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.280% (13584/15744)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.278% (13694/15872)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.294% (13807/16000)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.291% (13917/16128)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.300% (14029/16256)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.346% (14147/16384)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.331% (14255/16512)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.340% (14367/16640)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.355% (14480/16768)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.358% (14591/16896)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.355% (14701/17024)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.334% (14808/17152)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.348% (14921/17280)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.357% (15033/17408)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.342% (15141/17536)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.322% (15248/17664)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.320% (15358/17792)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.317% (15468/17920)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.331% (15581/18048)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.328% (15691/18176)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.309% (15798/18304)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.312% (15909/18432)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.293% (16016/18560)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.285% (16125/18688)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.262% (16231/18816)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.275% (16344/18944)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.284% (16456/19072)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.292% (16568/19200)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.253% (16671/19328)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.230% (16777/19456)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.218% (16885/19584)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.232% (16998/19712)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.220% (17106/19840)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.248% (17222/19968)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.256% (17334/20096)\n",
            "Train Epoch: 42 | Loss: 0.400 | Acc: 86.259% (17445/20224)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.213% (17546/20352)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.226% (17659/20480)\n",
            "Train Epoch: 42 | Loss: 0.401 | Acc: 86.248% (17774/20608)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.222% (17879/20736)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.235% (17992/20864)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.219% (18099/20992)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.217% (18209/21120)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.201% (18316/21248)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.195% (18425/21376)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.203% (18537/21504)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.224% (18652/21632)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.199% (18757/21760)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.161% (18859/21888)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.137% (18964/22016)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.136% (19074/22144)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.140% (19185/22272)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.134% (19294/22400)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.155% (19409/22528)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.154% (19519/22656)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.157% (19630/22784)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.164% (19742/22912)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.159% (19851/23040)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.149% (19959/23168)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.165% (20073/23296)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.164% (20183/23424)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.163% (20293/23552)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.174% (20406/23680)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.202% (20523/23808)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.176% (20627/23936)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.162% (20734/24064)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.152% (20842/24192)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.139% (20949/24320)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.150% (21062/24448)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.165% (21176/24576)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.180% (21290/24704)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.187% (21402/24832)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.202% (21516/24960)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.161% (21616/25088)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.164% (21727/25216)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.178% (21841/25344)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.185% (21953/25472)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.176% (22061/25600)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.198% (22177/25728)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.197% (22287/25856)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.199% (22398/25984)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.206% (22510/26112)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.208% (22621/26240)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.214% (22733/26368)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.228% (22847/26496)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.227% (22957/26624)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.222% (23066/26752)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.202% (23171/26880)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.193% (23279/27008)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.184% (23387/27136)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.172% (23494/27264)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.186% (23608/27392)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.177% (23716/27520)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.180% (23827/27648)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.200% (23943/27776)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.213% (24057/27904)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.194% (24162/28032)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.222% (24280/28160)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.213% (24388/28288)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.226% (24502/28416)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.225% (24612/28544)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.213% (24719/28672)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.219% (24831/28800)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.231% (24945/28928)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.227% (25054/29056)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.218% (25162/29184)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.217% (25272/29312)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.206% (25379/29440)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.198% (25487/29568)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.207% (25600/29696)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.219% (25714/29824)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.218% (25824/29952)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.227% (25937/30080)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.219% (26045/30208)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.188% (26146/30336)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.171% (26251/30464)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.163% (26359/30592)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.149% (26465/30720)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.158% (26578/30848)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.170% (26692/30976)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.166% (26801/31104)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.181% (26916/31232)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.164% (27021/31360)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.166% (27132/31488)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.162% (27241/31616)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.183% (27358/31744)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.170% (27464/31872)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.153% (27569/32000)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.168% (27684/32128)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.170% (27795/32256)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.188% (27911/32384)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.180% (28019/32512)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.186% (28131/32640)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.191% (28243/32768)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.178% (28349/32896)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.171% (28457/33024)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.188% (28573/33152)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.181% (28681/33280)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.183% (28792/33408)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.173% (28899/33536)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.172% (29009/33664)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.174% (29120/33792)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.170% (29229/33920)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.164% (29337/34048)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.172% (29450/34176)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.177% (29562/34304)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.184% (29675/34432)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.186% (29786/34560)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.188% (29897/34688)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.173% (30002/34816)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.184% (30116/34944)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.191% (30229/35072)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.185% (30337/35200)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.184% (30447/35328)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.180% (30556/35456)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.176% (30665/35584)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.173% (30774/35712)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.172% (30884/35840)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.171% (30994/35968)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.198% (31114/36096)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.211% (31229/36224)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.226% (31345/36352)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.217% (31452/36480)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.211% (31560/36608)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.223% (31675/36736)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.203% (31778/36864)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.186% (31882/36992)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.183% (31991/37120)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.193% (32105/37248)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.208% (32221/37376)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.185% (32323/37504)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.203% (32440/37632)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.205% (32551/37760)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.204% (32661/37888)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.193% (32767/38016)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.181% (32873/38144)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.175% (32981/38272)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.174% (33091/38400)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.181% (33204/38528)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.168% (33309/38656)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.182% (33425/38784)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.174% (33532/38912)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.176% (33643/39040)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.177% (33754/39168)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.172% (33862/39296)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.163% (33969/39424)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.163% (34079/39552)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.177% (34195/39680)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.154% (34296/39808)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.135% (34399/39936)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.130% (34507/40064)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.127% (34616/40192)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.126% (34726/40320)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.133% (34839/40448)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.132% (34949/40576)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.127% (35057/40704)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.124% (35166/40832)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.140% (35283/40960)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.135% (35391/41088)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.144% (35505/41216)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.143% (35615/41344)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.147% (35727/41472)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.154% (35840/41600)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.146% (35947/41728)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.148% (36058/41856)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.149% (36169/41984)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.132% (36272/42112)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.151% (36390/42240)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.140% (36496/42368)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.142% (36607/42496)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.144% (36718/42624)\n",
            "Train Epoch: 42 | Loss: 0.402 | Acc: 86.155% (36833/42752)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.152% (36942/42880)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.156% (37054/43008)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.148% (37161/43136)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.150% (37272/43264)\n",
            "Train Epoch: 42 | Loss: 0.403 | Acc: 86.131% (37374/43392)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.117% (37478/43520)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.105% (37583/43648)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.097% (37690/43776)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.101% (37802/43904)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.087% (37906/44032)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.073% (38010/44160)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.075% (38121/44288)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.068% (38228/44416)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.056% (38333/44544)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.063% (38446/44672)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.076% (38562/44800)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.073% (38671/44928)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.080% (38784/45056)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.090% (38899/45184)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.090% (39009/45312)\n",
            "Train Epoch: 42 | Loss: 0.404 | Acc: 86.078% (39114/45440)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.074% (39222/45568)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.053% (39323/45696)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.053% (39433/45824)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.055% (39544/45952)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.048% (39651/46080)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.046% (39760/46208)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.039% (39867/46336)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.049% (39982/46464)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.060% (40097/46592)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.055% (40205/46720)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.061% (40318/46848)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.063% (40429/46976)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.069% (40542/47104)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.073% (40654/47232)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.058% (40757/47360)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.055% (40866/47488)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.049% (40973/47616)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.049% (41083/47744)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.052% (41195/47872)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.054% (41306/48000)\n",
            "Train Epoch: 42 | Loss: 0.405 | Acc: 86.041% (41410/48128)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.031% (41515/48256)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.028% (41624/48384)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.022% (41731/48512)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.034% (41847/48640)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.036% (41958/48768)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.046% (42073/48896)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.037% (42179/49024)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.037% (42289/49152)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.051% (42406/49280)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.053% (42517/49408)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.047% (42624/49536)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.054% (42738/49664)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.052% (42847/49792)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.054% (42958/49920)\n",
            "Train Epoch: 42 | Loss: 0.406 | Acc: 86.054% (43027/50000)\n",
            "Test Epoch: 42 | Loss: 0.502 | Acc: 84.000% (84/100)\n",
            "Test Epoch: 42 | Loss: 0.629 | Acc: 80.000% (160/200)\n",
            "Test Epoch: 42 | Loss: 0.620 | Acc: 78.667% (236/300)\n",
            "Test Epoch: 42 | Loss: 0.657 | Acc: 78.750% (315/400)\n",
            "Test Epoch: 42 | Loss: 0.640 | Acc: 79.800% (399/500)\n",
            "Test Epoch: 42 | Loss: 0.582 | Acc: 81.667% (490/600)\n",
            "Test Epoch: 42 | Loss: 0.593 | Acc: 81.429% (570/700)\n",
            "Test Epoch: 42 | Loss: 0.606 | Acc: 81.500% (652/800)\n",
            "Test Epoch: 42 | Loss: 0.621 | Acc: 80.667% (726/900)\n",
            "Test Epoch: 42 | Loss: 0.613 | Acc: 80.700% (807/1000)\n",
            "Test Epoch: 42 | Loss: 0.602 | Acc: 81.000% (891/1100)\n",
            "Test Epoch: 42 | Loss: 0.608 | Acc: 80.750% (969/1200)\n",
            "Test Epoch: 42 | Loss: 0.606 | Acc: 80.692% (1049/1300)\n",
            "Test Epoch: 42 | Loss: 0.612 | Acc: 80.500% (1127/1400)\n",
            "Test Epoch: 42 | Loss: 0.607 | Acc: 80.667% (1210/1500)\n",
            "Test Epoch: 42 | Loss: 0.623 | Acc: 80.375% (1286/1600)\n",
            "Test Epoch: 42 | Loss: 0.618 | Acc: 80.412% (1367/1700)\n",
            "Test Epoch: 42 | Loss: 0.616 | Acc: 80.389% (1447/1800)\n",
            "Test Epoch: 42 | Loss: 0.616 | Acc: 80.421% (1528/1900)\n",
            "Test Epoch: 42 | Loss: 0.638 | Acc: 79.550% (1591/2000)\n",
            "Test Epoch: 42 | Loss: 0.649 | Acc: 79.429% (1668/2100)\n",
            "Test Epoch: 42 | Loss: 0.652 | Acc: 79.455% (1748/2200)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.304% (1824/2300)\n",
            "Test Epoch: 42 | Loss: 0.656 | Acc: 79.417% (1906/2400)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.360% (1984/2500)\n",
            "Test Epoch: 42 | Loss: 0.681 | Acc: 79.115% (2057/2600)\n",
            "Test Epoch: 42 | Loss: 0.672 | Acc: 79.259% (2140/2700)\n",
            "Test Epoch: 42 | Loss: 0.672 | Acc: 79.286% (2220/2800)\n",
            "Test Epoch: 42 | Loss: 0.673 | Acc: 79.310% (2300/2900)\n",
            "Test Epoch: 42 | Loss: 0.670 | Acc: 79.200% (2376/3000)\n",
            "Test Epoch: 42 | Loss: 0.671 | Acc: 79.129% (2453/3100)\n",
            "Test Epoch: 42 | Loss: 0.672 | Acc: 79.094% (2531/3200)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.182% (2613/3300)\n",
            "Test Epoch: 42 | Loss: 0.671 | Acc: 79.059% (2688/3400)\n",
            "Test Epoch: 42 | Loss: 0.671 | Acc: 79.086% (2768/3500)\n",
            "Test Epoch: 42 | Loss: 0.671 | Acc: 79.056% (2846/3600)\n",
            "Test Epoch: 42 | Loss: 0.674 | Acc: 79.081% (2926/3700)\n",
            "Test Epoch: 42 | Loss: 0.678 | Acc: 79.000% (3002/3800)\n",
            "Test Epoch: 42 | Loss: 0.677 | Acc: 79.051% (3083/3900)\n",
            "Test Epoch: 42 | Loss: 0.677 | Acc: 79.075% (3163/4000)\n",
            "Test Epoch: 42 | Loss: 0.677 | Acc: 79.146% (3245/4100)\n",
            "Test Epoch: 42 | Loss: 0.675 | Acc: 79.262% (3329/4200)\n",
            "Test Epoch: 42 | Loss: 0.670 | Acc: 79.419% (3415/4300)\n",
            "Test Epoch: 42 | Loss: 0.667 | Acc: 79.545% (3500/4400)\n",
            "Test Epoch: 42 | Loss: 0.668 | Acc: 79.578% (3581/4500)\n",
            "Test Epoch: 42 | Loss: 0.668 | Acc: 79.565% (3660/4600)\n",
            "Test Epoch: 42 | Loss: 0.669 | Acc: 79.553% (3739/4700)\n",
            "Test Epoch: 42 | Loss: 0.671 | Acc: 79.542% (3818/4800)\n",
            "Test Epoch: 42 | Loss: 0.668 | Acc: 79.633% (3902/4900)\n",
            "Test Epoch: 42 | Loss: 0.670 | Acc: 79.500% (3975/5000)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.549% (4057/5100)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.538% (4136/5200)\n",
            "Test Epoch: 42 | Loss: 0.664 | Acc: 79.566% (4217/5300)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.593% (4298/5400)\n",
            "Test Epoch: 42 | Loss: 0.660 | Acc: 79.600% (4378/5500)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.571% (4456/5600)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.561% (4535/5700)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.672% (4621/5800)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.542% (4693/5900)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.550% (4773/6000)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.623% (4857/6100)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.548% (4932/6200)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.540% (5011/6300)\n",
            "Test Epoch: 42 | Loss: 0.659 | Acc: 79.688% (5100/6400)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.646% (5177/6500)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.576% (5252/6600)\n",
            "Test Epoch: 42 | Loss: 0.660 | Acc: 79.642% (5336/6700)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.559% (5410/6800)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.594% (5492/6900)\n",
            "Test Epoch: 42 | Loss: 0.664 | Acc: 79.500% (5565/7000)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.465% (5642/7100)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.528% (5726/7200)\n",
            "Test Epoch: 42 | Loss: 0.660 | Acc: 79.562% (5808/7300)\n",
            "Test Epoch: 42 | Loss: 0.658 | Acc: 79.581% (5889/7400)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.480% (5961/7500)\n",
            "Test Epoch: 42 | Loss: 0.660 | Acc: 79.500% (6042/7600)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.455% (6118/7700)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.385% (6192/7800)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.316% (6266/7900)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.338% (6347/8000)\n",
            "Test Epoch: 42 | Loss: 0.664 | Acc: 79.346% (6427/8100)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.366% (6508/8200)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.349% (6586/8300)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.321% (6663/8400)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.259% (6737/8500)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.267% (6817/8600)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.218% (6892/8700)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.159% (6966/8800)\n",
            "Test Epoch: 42 | Loss: 0.666 | Acc: 79.135% (7043/8900)\n",
            "Test Epoch: 42 | Loss: 0.664 | Acc: 79.189% (7127/9000)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.264% (7213/9100)\n",
            "Test Epoch: 42 | Loss: 0.661 | Acc: 79.326% (7298/9200)\n",
            "Test Epoch: 42 | Loss: 0.662 | Acc: 79.323% (7377/9300)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.266% (7451/9400)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.253% (7529/9500)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.281% (7611/9600)\n",
            "Test Epoch: 42 | Loss: 0.663 | Acc: 79.309% (7693/9700)\n",
            "Test Epoch: 42 | Loss: 0.664 | Acc: 79.224% (7764/9800)\n",
            "Test Epoch: 42 | Loss: 0.665 | Acc: 79.141% (7835/9900)\n",
            "Test Epoch: 42 | Loss: 0.667 | Acc: 79.140% (7914/10000)\n",
            "\n",
            "Epoch: 43\n",
            "Train Epoch: 43 | Loss: 0.257 | Acc: 92.969% (119/128)\n",
            "Train Epoch: 43 | Loss: 0.300 | Acc: 91.016% (233/256)\n",
            "Train Epoch: 43 | Loss: 0.334 | Acc: 89.323% (343/384)\n",
            "Train Epoch: 43 | Loss: 0.322 | Acc: 89.258% (457/512)\n",
            "Train Epoch: 43 | Loss: 0.352 | Acc: 88.281% (565/640)\n",
            "Train Epoch: 43 | Loss: 0.366 | Acc: 87.891% (675/768)\n",
            "Train Epoch: 43 | Loss: 0.367 | Acc: 87.388% (783/896)\n",
            "Train Epoch: 43 | Loss: 0.380 | Acc: 87.207% (893/1024)\n",
            "Train Epoch: 43 | Loss: 0.394 | Acc: 86.719% (999/1152)\n",
            "Train Epoch: 43 | Loss: 0.393 | Acc: 86.875% (1112/1280)\n",
            "Train Epoch: 43 | Loss: 0.392 | Acc: 86.790% (1222/1408)\n",
            "Train Epoch: 43 | Loss: 0.391 | Acc: 86.654% (1331/1536)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.238% (1435/1664)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.105% (1543/1792)\n",
            "Train Epoch: 43 | Loss: 0.408 | Acc: 86.094% (1653/1920)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.328% (1768/2048)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.305% (1878/2176)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.068% (1983/2304)\n",
            "Train Epoch: 43 | Loss: 0.409 | Acc: 85.896% (2089/2432)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 85.977% (2201/2560)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.161% (2316/2688)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.364% (2432/2816)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.379% (2543/2944)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.458% (2656/3072)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.469% (2767/3200)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.508% (2879/3328)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.343% (2984/3456)\n",
            "Train Epoch: 43 | Loss: 0.408 | Acc: 86.189% (3089/3584)\n",
            "Train Epoch: 43 | Loss: 0.408 | Acc: 86.180% (3199/3712)\n",
            "Train Epoch: 43 | Loss: 0.409 | Acc: 86.016% (3303/3840)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.190% (3420/3968)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.206% (3531/4096)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.269% (3644/4224)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.213% (3752/4352)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.250% (3864/4480)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.220% (3973/4608)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.191% (4082/4736)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.164% (4191/4864)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.278% (4307/4992)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.250% (4416/5120)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.300% (4529/5248)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.291% (4639/5376)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.265% (4748/5504)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.293% (4860/5632)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.372% (4975/5760)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.226% (5077/5888)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.303% (5192/6016)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.361% (5306/6144)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.352% (5416/6272)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.375% (5528/6400)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.290% (5633/6528)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.253% (5741/6656)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.350% (5858/6784)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.372% (5970/6912)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.378% (6081/7040)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.244% (6182/7168)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.280% (6295/7296)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.315% (6408/7424)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.269% (6515/7552)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.237% (6623/7680)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.270% (6736/7808)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.290% (6848/7936)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.198% (6951/8064)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.121% (7055/8192)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.142% (7167/8320)\n",
            "Train Epoch: 43 | Loss: 0.407 | Acc: 86.127% (7276/8448)\n",
            "Train Epoch: 43 | Loss: 0.406 | Acc: 86.147% (7388/8576)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.133% (7497/8704)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.141% (7608/8832)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.205% (7724/8960)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.213% (7835/9088)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.187% (7943/9216)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.205% (8055/9344)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.233% (8168/9472)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.292% (8284/9600)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.287% (8394/9728)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.323% (8508/9856)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.348% (8621/9984)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.333% (8730/10112)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.270% (8834/10240)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.285% (8946/10368)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.328% (9061/10496)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.220% (9160/10624)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.170% (9265/10752)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.186% (9377/10880)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.128% (9481/11008)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.144% (9593/11136)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.106% (9699/11264)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.148% (9814/11392)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.128% (9922/11520)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.126% (10032/11648)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.133% (10143/11776)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.148% (10255/11904)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.154% (10366/12032)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.176% (10479/12160)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.206% (10593/12288)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.236% (10707/12416)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.272% (10822/12544)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.245% (10929/12672)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.250% (11040/12800)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.278% (11154/12928)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.297% (11267/13056)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.302% (11378/13184)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.268% (11484/13312)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.250% (11592/13440)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.195% (11695/13568)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.200% (11806/13696)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.241% (11922/13824)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.260% (12035/13952)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.300% (12151/14080)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.311% (12263/14208)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.286% (12370/14336)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.283% (12480/14464)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.287% (12591/14592)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.277% (12700/14720)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.301% (12814/14848)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.278% (12921/14976)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.282% (13032/15104)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.305% (13146/15232)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.328% (13260/15360)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.306% (13367/15488)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.283% (13474/15616)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.274% (13583/15744)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.253% (13690/15872)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.244% (13799/16000)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.260% (13912/16128)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.220% (14016/16256)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.230% (14128/16384)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.246% (14241/16512)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.286% (14358/16640)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.331% (14476/16768)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.316% (14584/16896)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.319% (14695/17024)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.334% (14808/17152)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.337% (14919/17280)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.311% (15025/17408)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.297% (15133/17536)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.305% (15245/17664)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.314% (15357/17792)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.339% (15472/17920)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.364% (15587/18048)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.367% (15698/18176)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.396% (15814/18304)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.399% (15925/18432)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.379% (16032/18560)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.392% (16145/18688)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.352% (16248/18816)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.307% (16350/18944)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.320% (16463/19072)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.297% (16569/19200)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.346% (16689/19328)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.338% (16798/19456)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.315% (16904/19584)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.323% (17016/19712)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.336% (17129/19840)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.343% (17241/19968)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.331% (17349/20096)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.328% (17459/20224)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.331% (17570/20352)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.323% (17679/20480)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.335% (17792/20608)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.314% (17898/20736)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.297% (18005/20864)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.300% (18116/20992)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.297% (18226/21120)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.286% (18334/21248)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.316% (18451/21376)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.323% (18563/21504)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.321% (18673/21632)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.347% (18789/21760)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.362% (18903/21888)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.333% (19007/22016)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.321% (19115/22144)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.328% (19227/22272)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.312% (19334/22400)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.337% (19450/22528)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.326% (19558/22656)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.319% (19667/22784)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.339% (19782/22912)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.328% (19890/23040)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.343% (20004/23168)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.358% (20118/23296)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.339% (20224/23424)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.349% (20337/23552)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.326% (20442/23680)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.324% (20552/23808)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.305% (20658/23936)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.332% (20775/24064)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.305% (20879/24192)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.316% (20992/24320)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.310% (21101/24448)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.287% (21206/24576)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.273% (21313/24704)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.288% (21427/24832)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.298% (21540/24960)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.304% (21652/25088)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.283% (21757/25216)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.297% (21871/25344)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.314% (21986/25472)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.344% (22104/25600)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.326% (22210/25728)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.320% (22319/25856)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.326% (22431/25984)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.317% (22539/26112)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.330% (22653/26240)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.305% (22757/26368)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.311% (22869/26496)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.287% (22973/26624)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.285% (23083/26752)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.287% (23194/26880)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.315% (23312/27008)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.317% (23423/27136)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.315% (23533/27264)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.310% (23642/27392)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.297% (23749/27520)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.321% (23866/27648)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.337% (23981/27776)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.332% (24090/27904)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.330% (24200/28032)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.317% (24307/28160)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.330% (24421/28288)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.349% (24537/28416)\n",
            "Train Epoch: 43 | Loss: 0.398 | Acc: 86.368% (24653/28544)\n",
            "Train Epoch: 43 | Loss: 0.398 | Acc: 86.363% (24762/28672)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.347% (24868/28800)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.349% (24979/28928)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.340% (25087/29056)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.342% (25198/29184)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.326% (25304/29312)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.328% (25415/29440)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.326% (25525/29568)\n",
            "Train Epoch: 43 | Loss: 0.398 | Acc: 86.325% (25635/29696)\n",
            "Train Epoch: 43 | Loss: 0.398 | Acc: 86.326% (25746/29824)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.298% (25848/29952)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.300% (25959/30080)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.315% (26074/30208)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.333% (26190/30336)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.328% (26299/30464)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.330% (26410/30592)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.335% (26522/30720)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.346% (26636/30848)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.357% (26750/30976)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.346% (26857/31104)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.363% (26973/31232)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.362% (27083/31360)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.360% (27193/31488)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.355% (27302/31616)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.350% (27411/31744)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.342% (27519/31872)\n",
            "Train Epoch: 43 | Loss: 0.399 | Acc: 86.331% (27626/32000)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.320% (27733/32128)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.319% (27843/32256)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.320% (27954/32384)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.297% (28057/32512)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.302% (28169/32640)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.298% (28278/32768)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.281% (28383/32896)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.271% (28490/33024)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.290% (28607/33152)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.283% (28715/33280)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.273% (28822/33408)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.280% (28935/33536)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.276% (29044/33664)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.281% (29156/33792)\n",
            "Train Epoch: 43 | Loss: 0.400 | Acc: 86.277% (29265/33920)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.261% (29370/34048)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.256% (29479/34176)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.258% (29590/34304)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.254% (29699/34432)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.256% (29810/34560)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.263% (29923/34688)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.256% (30031/34816)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.258% (30142/34944)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.248% (30249/35072)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.250% (30360/35200)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.249% (30470/35328)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.251% (30581/35456)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.235% (30686/35584)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.229% (30794/35712)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.242% (30909/35840)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.263% (31027/35968)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.267% (31139/36096)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.260% (31247/36224)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.257% (31356/36352)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.239% (31460/36480)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.216% (31562/36608)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.221% (31674/36736)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.209% (31780/36864)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.211% (31891/36992)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.226% (32007/37120)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.225% (32117/37248)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.240% (32233/37376)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.236% (32342/37504)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.240% (32454/37632)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.239% (32564/37760)\n",
            "Train Epoch: 43 | Loss: 0.401 | Acc: 86.238% (32674/37888)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.227% (32780/38016)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.213% (32885/38144)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.209% (32994/38272)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.221% (33109/38400)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.213% (33216/38528)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.209% (33325/38656)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.206% (33434/38784)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.210% (33546/38912)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.227% (33663/39040)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.236% (33777/39168)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.225% (33883/39296)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.214% (33989/39424)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.223% (34103/39552)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.217% (34211/39680)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.204% (34316/39808)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.195% (34423/39936)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.202% (34536/40064)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.206% (34648/40192)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.220% (34764/40320)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.219% (34874/40448)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.196% (34975/40576)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.198% (35086/40704)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.200% (35197/40832)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.191% (35304/40960)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.171% (35406/41088)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.153% (35509/41216)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.172% (35627/41344)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.183% (35742/41472)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.192% (35856/41600)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.177% (35960/41728)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.164% (36065/41856)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.145% (36167/41984)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.163% (36285/42112)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.153% (36391/42240)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.157% (36503/42368)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.154% (36612/42496)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.151% (36721/42624)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.153% (36832/42752)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.152% (36942/42880)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.158% (37055/43008)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.146% (37160/43136)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.148% (37271/43264)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.150% (37382/43392)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.124% (37481/43520)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.118% (37589/43648)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.116% (37698/43776)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.115% (37808/43904)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.119% (37920/44032)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.130% (38035/44160)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.123% (38142/44288)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.127% (38254/44416)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.113% (38358/44544)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.110% (38467/44672)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.109% (38577/44800)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.098% (38682/44928)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.095% (38791/45056)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.092% (38900/45184)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.112% (39019/45312)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.103% (39125/45440)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.111% (39239/45568)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.099% (39344/45696)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.095% (39452/45824)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.090% (39560/45952)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.096% (39673/46080)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.093% (39782/46208)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.102% (39896/46336)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.088% (40000/46464)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.096% (40114/46592)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.104% (40228/46720)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.089% (40331/46848)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.084% (40439/46976)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.069% (40542/47104)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.069% (40652/47232)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.066% (40761/47360)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.068% (40872/47488)\n",
            "Train Epoch: 43 | Loss: 0.405 | Acc: 86.061% (40979/47616)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.067% (41092/47744)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.071% (41204/47872)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.067% (41312/48000)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.075% (41426/48128)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.085% (41541/48256)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.078% (41648/48384)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.082% (41760/48512)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.075% (41867/48640)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.067% (41973/48768)\n",
            "Train Epoch: 43 | Loss: 0.404 | Acc: 86.058% (42079/48896)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.074% (42197/49024)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.076% (42308/49152)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.084% (42422/49280)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.083% (42532/49408)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.087% (42644/49536)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.095% (42758/49664)\n",
            "Train Epoch: 43 | Loss: 0.402 | Acc: 86.106% (42874/49792)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.098% (42980/49920)\n",
            "Train Epoch: 43 | Loss: 0.403 | Acc: 86.098% (43049/50000)\n",
            "Test Epoch: 43 | Loss: 0.542 | Acc: 83.000% (83/100)\n",
            "Test Epoch: 43 | Loss: 0.664 | Acc: 80.500% (161/200)\n",
            "Test Epoch: 43 | Loss: 0.644 | Acc: 79.667% (239/300)\n",
            "Test Epoch: 43 | Loss: 0.684 | Acc: 79.500% (318/400)\n",
            "Test Epoch: 43 | Loss: 0.664 | Acc: 80.200% (401/500)\n",
            "Test Epoch: 43 | Loss: 0.601 | Acc: 81.667% (490/600)\n",
            "Test Epoch: 43 | Loss: 0.611 | Acc: 81.429% (570/700)\n",
            "Test Epoch: 43 | Loss: 0.624 | Acc: 81.375% (651/800)\n",
            "Test Epoch: 43 | Loss: 0.638 | Acc: 80.556% (725/900)\n",
            "Test Epoch: 43 | Loss: 0.625 | Acc: 80.900% (809/1000)\n",
            "Test Epoch: 43 | Loss: 0.616 | Acc: 81.091% (892/1100)\n",
            "Test Epoch: 43 | Loss: 0.623 | Acc: 80.750% (969/1200)\n",
            "Test Epoch: 43 | Loss: 0.622 | Acc: 80.462% (1046/1300)\n",
            "Test Epoch: 43 | Loss: 0.627 | Acc: 80.143% (1122/1400)\n",
            "Test Epoch: 43 | Loss: 0.622 | Acc: 80.133% (1202/1500)\n",
            "Test Epoch: 43 | Loss: 0.641 | Acc: 79.938% (1279/1600)\n",
            "Test Epoch: 43 | Loss: 0.636 | Acc: 80.059% (1361/1700)\n",
            "Test Epoch: 43 | Loss: 0.635 | Acc: 80.167% (1443/1800)\n",
            "Test Epoch: 43 | Loss: 0.633 | Acc: 80.211% (1524/1900)\n",
            "Test Epoch: 43 | Loss: 0.654 | Acc: 79.550% (1591/2000)\n",
            "Test Epoch: 43 | Loss: 0.664 | Acc: 79.333% (1666/2100)\n",
            "Test Epoch: 43 | Loss: 0.667 | Acc: 79.318% (1745/2200)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.217% (1822/2300)\n",
            "Test Epoch: 43 | Loss: 0.672 | Acc: 79.208% (1901/2400)\n",
            "Test Epoch: 43 | Loss: 0.680 | Acc: 79.080% (1977/2500)\n",
            "Test Epoch: 43 | Loss: 0.696 | Acc: 78.808% (2049/2600)\n",
            "Test Epoch: 43 | Loss: 0.687 | Acc: 78.963% (2132/2700)\n",
            "Test Epoch: 43 | Loss: 0.686 | Acc: 78.964% (2211/2800)\n",
            "Test Epoch: 43 | Loss: 0.687 | Acc: 79.000% (2291/2900)\n",
            "Test Epoch: 43 | Loss: 0.683 | Acc: 79.000% (2370/3000)\n",
            "Test Epoch: 43 | Loss: 0.684 | Acc: 79.000% (2449/3100)\n",
            "Test Epoch: 43 | Loss: 0.685 | Acc: 78.938% (2526/3200)\n",
            "Test Epoch: 43 | Loss: 0.680 | Acc: 79.091% (2610/3300)\n",
            "Test Epoch: 43 | Loss: 0.685 | Acc: 79.000% (2686/3400)\n",
            "Test Epoch: 43 | Loss: 0.685 | Acc: 78.914% (2762/3500)\n",
            "Test Epoch: 43 | Loss: 0.685 | Acc: 78.778% (2836/3600)\n",
            "Test Epoch: 43 | Loss: 0.688 | Acc: 78.811% (2916/3700)\n",
            "Test Epoch: 43 | Loss: 0.693 | Acc: 78.605% (2987/3800)\n",
            "Test Epoch: 43 | Loss: 0.691 | Acc: 78.718% (3070/3900)\n",
            "Test Epoch: 43 | Loss: 0.692 | Acc: 78.700% (3148/4000)\n",
            "Test Epoch: 43 | Loss: 0.693 | Acc: 78.707% (3227/4100)\n",
            "Test Epoch: 43 | Loss: 0.691 | Acc: 78.810% (3310/4200)\n",
            "Test Epoch: 43 | Loss: 0.686 | Acc: 78.977% (3396/4300)\n",
            "Test Epoch: 43 | Loss: 0.683 | Acc: 79.091% (3480/4400)\n",
            "Test Epoch: 43 | Loss: 0.683 | Acc: 79.067% (3558/4500)\n",
            "Test Epoch: 43 | Loss: 0.683 | Acc: 79.022% (3635/4600)\n",
            "Test Epoch: 43 | Loss: 0.684 | Acc: 79.000% (3713/4700)\n",
            "Test Epoch: 43 | Loss: 0.686 | Acc: 78.979% (3791/4800)\n",
            "Test Epoch: 43 | Loss: 0.683 | Acc: 78.939% (3868/4900)\n",
            "Test Epoch: 43 | Loss: 0.686 | Acc: 78.840% (3942/5000)\n",
            "Test Epoch: 43 | Loss: 0.681 | Acc: 78.941% (4026/5100)\n",
            "Test Epoch: 43 | Loss: 0.680 | Acc: 78.981% (4107/5200)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 79.038% (4189/5300)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.111% (4272/5400)\n",
            "Test Epoch: 43 | Loss: 0.675 | Acc: 79.145% (4353/5500)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.125% (4431/5600)\n",
            "Test Epoch: 43 | Loss: 0.681 | Acc: 79.140% (4511/5700)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.224% (4595/5800)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.119% (4668/5900)\n",
            "Test Epoch: 43 | Loss: 0.680 | Acc: 79.083% (4745/6000)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.180% (4830/6100)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.177% (4909/6200)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 79.159% (4987/6300)\n",
            "Test Epoch: 43 | Loss: 0.674 | Acc: 79.312% (5076/6400)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.292% (5154/6500)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.227% (5229/6600)\n",
            "Test Epoch: 43 | Loss: 0.676 | Acc: 79.224% (5308/6700)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.132% (5381/6800)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.159% (5462/6900)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 79.086% (5536/7000)\n",
            "Test Epoch: 43 | Loss: 0.681 | Acc: 79.056% (5613/7100)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.125% (5697/7200)\n",
            "Test Epoch: 43 | Loss: 0.675 | Acc: 79.192% (5781/7300)\n",
            "Test Epoch: 43 | Loss: 0.673 | Acc: 79.230% (5863/7400)\n",
            "Test Epoch: 43 | Loss: 0.676 | Acc: 79.147% (5936/7500)\n",
            "Test Epoch: 43 | Loss: 0.674 | Acc: 79.158% (6016/7600)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.091% (6090/7700)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 79.038% (6165/7800)\n",
            "Test Epoch: 43 | Loss: 0.681 | Acc: 79.000% (6241/7900)\n",
            "Test Epoch: 43 | Loss: 0.681 | Acc: 79.013% (6321/8000)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 79.000% (6399/8100)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 79.024% (6480/8200)\n",
            "Test Epoch: 43 | Loss: 0.676 | Acc: 79.024% (6559/8300)\n",
            "Test Epoch: 43 | Loss: 0.675 | Acc: 79.000% (6636/8400)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 78.965% (6712/8500)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 78.965% (6791/8600)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 78.897% (6864/8700)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 78.841% (6938/8800)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 78.820% (7015/8900)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 78.844% (7096/9000)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 78.956% (7185/9100)\n",
            "Test Epoch: 43 | Loss: 0.675 | Acc: 79.022% (7270/9200)\n",
            "Test Epoch: 43 | Loss: 0.676 | Acc: 78.989% (7346/9300)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 78.968% (7423/9400)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 78.958% (7501/9500)\n",
            "Test Epoch: 43 | Loss: 0.676 | Acc: 78.990% (7583/9600)\n",
            "Test Epoch: 43 | Loss: 0.677 | Acc: 79.021% (7665/9700)\n",
            "Test Epoch: 43 | Loss: 0.678 | Acc: 78.939% (7736/9800)\n",
            "Test Epoch: 43 | Loss: 0.679 | Acc: 78.879% (7809/9900)\n",
            "Test Epoch: 43 | Loss: 0.680 | Acc: 78.870% (7887/10000)\n",
            "\n",
            "Epoch: 44\n",
            "Train Epoch: 44 | Loss: 0.357 | Acc: 88.281% (113/128)\n",
            "Train Epoch: 44 | Loss: 0.348 | Acc: 88.672% (227/256)\n",
            "Train Epoch: 44 | Loss: 0.321 | Acc: 89.062% (342/384)\n",
            "Train Epoch: 44 | Loss: 0.354 | Acc: 87.500% (448/512)\n",
            "Train Epoch: 44 | Loss: 0.367 | Acc: 87.344% (559/640)\n",
            "Train Epoch: 44 | Loss: 0.348 | Acc: 88.281% (678/768)\n",
            "Train Epoch: 44 | Loss: 0.359 | Acc: 87.612% (785/896)\n",
            "Train Epoch: 44 | Loss: 0.368 | Acc: 87.500% (896/1024)\n",
            "Train Epoch: 44 | Loss: 0.370 | Acc: 87.153% (1004/1152)\n",
            "Train Epoch: 44 | Loss: 0.366 | Acc: 86.953% (1113/1280)\n",
            "Train Epoch: 44 | Loss: 0.374 | Acc: 86.648% (1220/1408)\n",
            "Train Epoch: 44 | Loss: 0.373 | Acc: 86.784% (1333/1536)\n",
            "Train Epoch: 44 | Loss: 0.369 | Acc: 86.779% (1444/1664)\n",
            "Train Epoch: 44 | Loss: 0.364 | Acc: 87.109% (1561/1792)\n",
            "Train Epoch: 44 | Loss: 0.364 | Acc: 87.240% (1675/1920)\n",
            "Train Epoch: 44 | Loss: 0.365 | Acc: 87.256% (1787/2048)\n",
            "Train Epoch: 44 | Loss: 0.362 | Acc: 87.362% (1901/2176)\n",
            "Train Epoch: 44 | Loss: 0.367 | Acc: 87.283% (2011/2304)\n",
            "Train Epoch: 44 | Loss: 0.369 | Acc: 87.294% (2123/2432)\n",
            "Train Epoch: 44 | Loss: 0.371 | Acc: 87.266% (2234/2560)\n",
            "Train Epoch: 44 | Loss: 0.370 | Acc: 87.277% (2346/2688)\n",
            "Train Epoch: 44 | Loss: 0.376 | Acc: 87.145% (2454/2816)\n",
            "Train Epoch: 44 | Loss: 0.376 | Acc: 87.194% (2567/2944)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.077% (2675/3072)\n",
            "Train Epoch: 44 | Loss: 0.381 | Acc: 87.094% (2787/3200)\n",
            "Train Epoch: 44 | Loss: 0.375 | Acc: 87.230% (2903/3328)\n",
            "Train Epoch: 44 | Loss: 0.375 | Acc: 87.326% (3018/3456)\n",
            "Train Epoch: 44 | Loss: 0.374 | Acc: 87.388% (3132/3584)\n",
            "Train Epoch: 44 | Loss: 0.384 | Acc: 87.150% (3235/3712)\n",
            "Train Epoch: 44 | Loss: 0.382 | Acc: 87.161% (3347/3840)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.223% (3461/3968)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.256% (3574/4096)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.192% (3683/4224)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.155% (3793/4352)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.098% (3902/4480)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.023% (4010/4608)\n",
            "Train Epoch: 44 | Loss: 0.381 | Acc: 87.057% (4123/4736)\n",
            "Train Epoch: 44 | Loss: 0.381 | Acc: 86.965% (4230/4864)\n",
            "Train Epoch: 44 | Loss: 0.382 | Acc: 86.959% (4341/4992)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.051% (4457/5120)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.005% (4566/5248)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.072% (4681/5376)\n",
            "Train Epoch: 44 | Loss: 0.376 | Acc: 87.155% (4797/5504)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.109% (4906/5632)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.101% (5017/5760)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.058% (5126/5888)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.035% (5236/6016)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.061% (5349/6144)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.038% (5459/6272)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.047% (5571/6400)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.040% (5682/6528)\n",
            "Train Epoch: 44 | Loss: 0.377 | Acc: 87.139% (5800/6656)\n",
            "Train Epoch: 44 | Loss: 0.375 | Acc: 87.249% (5919/6784)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.095% (6020/6912)\n",
            "Train Epoch: 44 | Loss: 0.380 | Acc: 87.003% (6125/7040)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.054% (6240/7168)\n",
            "Train Epoch: 44 | Loss: 0.378 | Acc: 87.061% (6352/7296)\n",
            "Train Epoch: 44 | Loss: 0.379 | Acc: 87.015% (6460/7424)\n",
            "Train Epoch: 44 | Loss: 0.381 | Acc: 86.904% (6563/7552)\n",
            "Train Epoch: 44 | Loss: 0.381 | Acc: 86.901% (6674/7680)\n",
            "Train Epoch: 44 | Loss: 0.382 | Acc: 86.872% (6783/7808)\n",
            "Train Epoch: 44 | Loss: 0.383 | Acc: 86.870% (6894/7936)\n",
            "Train Epoch: 44 | Loss: 0.384 | Acc: 86.806% (7000/8064)\n",
            "Train Epoch: 44 | Loss: 0.383 | Acc: 86.890% (7118/8192)\n",
            "Train Epoch: 44 | Loss: 0.384 | Acc: 86.899% (7230/8320)\n",
            "Train Epoch: 44 | Loss: 0.385 | Acc: 86.837% (7336/8448)\n",
            "Train Epoch: 44 | Loss: 0.384 | Acc: 86.894% (7452/8576)\n",
            "Train Epoch: 44 | Loss: 0.386 | Acc: 86.880% (7562/8704)\n",
            "Train Epoch: 44 | Loss: 0.385 | Acc: 86.889% (7674/8832)\n",
            "Train Epoch: 44 | Loss: 0.386 | Acc: 86.897% (7786/8960)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.851% (7893/9088)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.838% (8003/9216)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.751% (8106/9344)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.761% (8218/9472)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.781% (8331/9600)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.688% (8433/9728)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.698% (8545/9856)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.729% (8659/9984)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.748% (8772/10112)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.689% (8877/10240)\n",
            "Train Epoch: 44 | Loss: 0.392 | Acc: 86.671% (8986/10368)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.690% (9099/10496)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.756% (9217/10624)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.765% (9329/10752)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.746% (9438/10880)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.764% (9551/11008)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.782% (9664/11136)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.754% (9772/11264)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.798% (9888/11392)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.823% (10002/11520)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.753% (10105/11648)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.787% (10220/11776)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.744% (10326/11904)\n",
            "Train Epoch: 44 | Loss: 0.386 | Acc: 86.810% (10445/12032)\n",
            "Train Epoch: 44 | Loss: 0.386 | Acc: 86.776% (10552/12160)\n",
            "Train Epoch: 44 | Loss: 0.386 | Acc: 86.816% (10668/12288)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.767% (10773/12416)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.798% (10888/12544)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.774% (10996/12672)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.742% (11103/12800)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.757% (11216/12928)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.757% (11327/13056)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.749% (11437/13184)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.741% (11547/13312)\n",
            "Train Epoch: 44 | Loss: 0.388 | Acc: 86.734% (11657/13440)\n",
            "Train Epoch: 44 | Loss: 0.387 | Acc: 86.770% (11773/13568)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.682% (11872/13696)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.661% (11980/13824)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.640% (12088/13952)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.648% (12200/14080)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.634% (12309/14208)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.642% (12421/14336)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.663% (12535/14464)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.643% (12643/14592)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.658% (12756/14720)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.685% (12871/14848)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.705% (12985/14976)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.732% (13100/15104)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.745% (13213/15232)\n",
            "Train Epoch: 44 | Loss: 0.389 | Acc: 86.745% (13324/15360)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.725% (13432/15488)\n",
            "Train Epoch: 44 | Loss: 0.390 | Acc: 86.719% (13542/15616)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.700% (13650/15744)\n",
            "Train Epoch: 44 | Loss: 0.391 | Acc: 86.687% (13759/15872)\n",
            "Train Epoch: 44 | Loss: 0.392 | Acc: 86.656% (13865/16000)\n",
            "Train Epoch: 44 | Loss: 0.392 | Acc: 86.657% (13976/16128)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.608% (14079/16256)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.584% (14186/16384)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.592% (14298/16512)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.587% (14408/16640)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.588% (14519/16768)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.606% (14633/16896)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.601% (14743/17024)\n",
            "Train Epoch: 44 | Loss: 0.393 | Acc: 86.614% (14856/17152)\n",
            "Train Epoch: 44 | Loss: 0.393 | Acc: 86.597% (14964/17280)\n",
            "Train Epoch: 44 | Loss: 0.393 | Acc: 86.610% (15077/17408)\n",
            "Train Epoch: 44 | Loss: 0.393 | Acc: 86.622% (15190/17536)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.611% (15299/17664)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.612% (15410/17792)\n",
            "Train Epoch: 44 | Loss: 0.393 | Acc: 86.629% (15524/17920)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.619% (15633/18048)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.614% (15743/18176)\n",
            "Train Epoch: 44 | Loss: 0.394 | Acc: 86.631% (15857/18304)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.616% (15965/18432)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.606% (16074/18560)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.606% (16185/18688)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.581% (16291/18816)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.608% (16407/18944)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.577% (16512/19072)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.562% (16620/19200)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.548% (16728/19328)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.559% (16841/19456)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.555% (16951/19584)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.501% (17051/19712)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.492% (17160/19840)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.503% (17273/19968)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.490% (17381/20096)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.526% (17499/20224)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.522% (17609/20352)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.499% (17715/20480)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.486% (17823/20608)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.487% (17934/20736)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.489% (18045/20864)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.500% (18158/20992)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.501% (18269/21120)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.488% (18377/21248)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.490% (18488/21376)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.482% (18597/21504)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.515% (18715/21632)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.503% (18823/21760)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.522% (18938/21888)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.533% (19051/22016)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.547% (19165/22144)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.530% (19272/22272)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.536% (19384/22400)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.537% (19495/22528)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.551% (19609/22656)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.543% (19718/22784)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.522% (19824/22912)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.484% (19926/23040)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.486% (20037/23168)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.487% (20148/23296)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.497% (20261/23424)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.498% (20372/23552)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.495% (20482/23680)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.479% (20589/23808)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.481% (20700/23936)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.469% (20808/24064)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.467% (20918/24192)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.468% (21029/24320)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.482% (21143/24448)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.479% (21253/24576)\n",
            "Train Epoch: 44 | Loss: 0.395 | Acc: 86.508% (21371/24704)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.469% (21472/24832)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.458% (21580/24960)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.472% (21694/25088)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.493% (21810/25216)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.486% (21919/25344)\n",
            "Train Epoch: 44 | Loss: 0.396 | Acc: 86.467% (22025/25472)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.426% (22125/25600)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.439% (22239/25728)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.425% (22346/25856)\n",
            "Train Epoch: 44 | Loss: 0.397 | Acc: 86.419% (22455/25984)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.393% (22559/26112)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.399% (22671/26240)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.381% (22777/26368)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.375% (22886/26496)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.381% (22998/26624)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.386% (23110/26752)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.365% (23215/26880)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.382% (23330/27008)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.365% (23436/27136)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.381% (23551/27264)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.383% (23662/27392)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.399% (23777/27520)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.379% (23882/27648)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.384% (23994/27776)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.368% (24100/27904)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.333% (24201/28032)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.332% (24311/28160)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.337% (24423/28288)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.321% (24529/28416)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.347% (24647/28544)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.356% (24760/28672)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.344% (24867/28800)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.345% (24978/28928)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.364% (25094/29056)\n",
            "Train Epoch: 44 | Loss: 0.398 | Acc: 86.349% (25200/29184)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.333% (25306/29312)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.318% (25412/29440)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.333% (25527/29568)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.342% (25640/29696)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.333% (25748/29824)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.338% (25860/29952)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.326% (25967/30080)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.331% (26079/30208)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.343% (26193/30336)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.341% (26303/30464)\n",
            "Train Epoch: 44 | Loss: 0.399 | Acc: 86.346% (26415/30592)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.348% (26526/30720)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.343% (26635/30848)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.341% (26745/30976)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.333% (26853/31104)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.338% (26965/31232)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.342% (27077/31360)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.357% (27192/31488)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.355% (27302/31616)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.366% (27416/31744)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.342% (27519/31872)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.344% (27630/32000)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.342% (27740/32128)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.306% (27839/32256)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.299% (27947/32384)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.291% (28055/32512)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.296% (28167/32640)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.285% (28274/32768)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.275% (28381/32896)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.277% (28492/33024)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.275% (28602/33152)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.280% (28714/33280)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.276% (28823/33408)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.277% (28934/33536)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.282% (29046/33664)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.278% (29155/33792)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.271% (29263/33920)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.278% (29376/34048)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.289% (29490/34176)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.302% (29605/34304)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.292% (29712/34432)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.293% (29823/34560)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.292% (29933/34688)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.279% (30039/34816)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.295% (30155/34944)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.302% (30268/35072)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.304% (30379/35200)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.305% (30490/35328)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.299% (30598/35456)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.300% (30709/35584)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.307% (30822/35712)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.309% (30933/35840)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.302% (31041/35968)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.300% (31151/36096)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.294% (31259/36224)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.306% (31374/36352)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.291% (31479/36480)\n",
            "Train Epoch: 44 | Loss: 0.400 | Acc: 86.282% (31586/36608)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.272% (31693/36736)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.274% (31804/36864)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.270% (31913/36992)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.274% (32025/37120)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.249% (32126/37248)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.245% (32235/37376)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.241% (32344/37504)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.235% (32452/37632)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.224% (32558/37760)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.215% (32665/37888)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.243% (32786/38016)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.231% (32892/38144)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.233% (33003/38272)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.237% (33115/38400)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.231% (33223/38528)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.230% (33333/38656)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.231% (33444/38784)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.233% (33555/38912)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.222% (33661/39040)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.236% (33777/39168)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.235% (33887/39296)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.227% (33994/39424)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.231% (34106/39552)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.232% (34217/39680)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.234% (34328/39808)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.240% (34441/39936)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.237% (34550/40064)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.236% (34660/40192)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.235% (34770/40320)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.232% (34879/40448)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.216% (34983/40576)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.225% (35097/40704)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.239% (35213/40832)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.223% (35317/40960)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.208% (35421/41088)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.197% (35527/41216)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.199% (35638/41344)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.198% (35748/41472)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.214% (35865/41600)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.206% (35972/41728)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.198% (36079/41856)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.216% (36197/41984)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.218% (36308/42112)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.229% (36423/42240)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.221% (36530/42368)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.222% (36641/42496)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.224% (36752/42624)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.232% (36866/42752)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.224% (36973/42880)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.221% (37082/43008)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.216% (37190/43136)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.210% (37298/43264)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.219% (37412/43392)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.229% (37527/43520)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.217% (37632/43648)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.207% (37738/43776)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.197% (37844/43904)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.187% (37950/44032)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.193% (38063/44160)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.190% (38172/44288)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.178% (38277/44416)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.169% (38383/44544)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.177% (38497/44672)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.176% (38607/44800)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.187% (38722/44928)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.197% (38837/45056)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.194% (38946/45184)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.191% (39055/45312)\n",
            "Train Epoch: 44 | Loss: 0.401 | Acc: 86.191% (39165/45440)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.175% (39268/45568)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.169% (39376/45696)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.167% (39485/45824)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.164% (39594/45952)\n",
            "Train Epoch: 44 | Loss: 0.402 | Acc: 86.150% (39698/46080)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.137% (39802/46208)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.127% (39908/46336)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.131% (40020/46464)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.131% (40130/46592)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.130% (40240/46720)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.132% (40351/46848)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.123% (40457/46976)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.122% (40567/47104)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.130% (40681/47232)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.134% (40793/47360)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.119% (40896/47488)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.110% (41002/47616)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.099% (41107/47744)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.103% (41219/47872)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.094% (41325/48000)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.091% (41434/48128)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.095% (41546/48256)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.086% (41652/48384)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.090% (41764/48512)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.090% (41874/48640)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.093% (41986/48768)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.095% (42097/48896)\n",
            "Train Epoch: 44 | Loss: 0.404 | Acc: 86.111% (42215/49024)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.112% (42326/49152)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.118% (42439/49280)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.128% (42554/49408)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.125% (42663/49536)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.129% (42775/49664)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.128% (42885/49792)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.122% (42992/49920)\n",
            "Train Epoch: 44 | Loss: 0.403 | Acc: 86.124% (43062/50000)\n",
            "Test Epoch: 44 | Loss: 0.511 | Acc: 84.000% (84/100)\n",
            "Test Epoch: 44 | Loss: 0.643 | Acc: 80.500% (161/200)\n",
            "Test Epoch: 44 | Loss: 0.628 | Acc: 80.333% (241/300)\n",
            "Test Epoch: 44 | Loss: 0.661 | Acc: 80.000% (320/400)\n",
            "Test Epoch: 44 | Loss: 0.642 | Acc: 80.600% (403/500)\n",
            "Test Epoch: 44 | Loss: 0.586 | Acc: 82.167% (493/600)\n",
            "Test Epoch: 44 | Loss: 0.599 | Acc: 81.429% (570/700)\n",
            "Test Epoch: 44 | Loss: 0.615 | Acc: 81.000% (648/800)\n",
            "Test Epoch: 44 | Loss: 0.628 | Acc: 80.222% (722/900)\n",
            "Test Epoch: 44 | Loss: 0.617 | Acc: 80.200% (802/1000)\n",
            "Test Epoch: 44 | Loss: 0.607 | Acc: 80.636% (887/1100)\n",
            "Test Epoch: 44 | Loss: 0.614 | Acc: 80.333% (964/1200)\n",
            "Test Epoch: 44 | Loss: 0.615 | Acc: 80.231% (1043/1300)\n",
            "Test Epoch: 44 | Loss: 0.619 | Acc: 80.000% (1120/1400)\n",
            "Test Epoch: 44 | Loss: 0.614 | Acc: 80.000% (1200/1500)\n",
            "Test Epoch: 44 | Loss: 0.632 | Acc: 79.750% (1276/1600)\n",
            "Test Epoch: 44 | Loss: 0.627 | Acc: 79.706% (1355/1700)\n",
            "Test Epoch: 44 | Loss: 0.628 | Acc: 79.556% (1432/1800)\n",
            "Test Epoch: 44 | Loss: 0.627 | Acc: 79.632% (1513/1900)\n",
            "Test Epoch: 44 | Loss: 0.650 | Acc: 79.000% (1580/2000)\n",
            "Test Epoch: 44 | Loss: 0.660 | Acc: 79.000% (1659/2100)\n",
            "Test Epoch: 44 | Loss: 0.662 | Acc: 79.000% (1738/2200)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.913% (1815/2300)\n",
            "Test Epoch: 44 | Loss: 0.670 | Acc: 78.875% (1893/2400)\n",
            "Test Epoch: 44 | Loss: 0.679 | Acc: 78.760% (1969/2500)\n",
            "Test Epoch: 44 | Loss: 0.694 | Acc: 78.538% (2042/2600)\n",
            "Test Epoch: 44 | Loss: 0.685 | Acc: 78.778% (2127/2700)\n",
            "Test Epoch: 44 | Loss: 0.685 | Acc: 78.821% (2207/2800)\n",
            "Test Epoch: 44 | Loss: 0.686 | Acc: 78.793% (2285/2900)\n",
            "Test Epoch: 44 | Loss: 0.682 | Acc: 78.867% (2366/3000)\n",
            "Test Epoch: 44 | Loss: 0.682 | Acc: 78.871% (2445/3100)\n",
            "Test Epoch: 44 | Loss: 0.682 | Acc: 78.781% (2521/3200)\n",
            "Test Epoch: 44 | Loss: 0.677 | Acc: 79.000% (2607/3300)\n",
            "Test Epoch: 44 | Loss: 0.681 | Acc: 78.912% (2683/3400)\n",
            "Test Epoch: 44 | Loss: 0.681 | Acc: 78.886% (2761/3500)\n",
            "Test Epoch: 44 | Loss: 0.681 | Acc: 78.806% (2837/3600)\n",
            "Test Epoch: 44 | Loss: 0.685 | Acc: 78.784% (2915/3700)\n",
            "Test Epoch: 44 | Loss: 0.689 | Acc: 78.684% (2990/3800)\n",
            "Test Epoch: 44 | Loss: 0.687 | Acc: 78.769% (3072/3900)\n",
            "Test Epoch: 44 | Loss: 0.687 | Acc: 78.800% (3152/4000)\n",
            "Test Epoch: 44 | Loss: 0.688 | Acc: 78.829% (3232/4100)\n",
            "Test Epoch: 44 | Loss: 0.687 | Acc: 78.929% (3315/4200)\n",
            "Test Epoch: 44 | Loss: 0.682 | Acc: 79.116% (3402/4300)\n",
            "Test Epoch: 44 | Loss: 0.679 | Acc: 79.227% (3486/4400)\n",
            "Test Epoch: 44 | Loss: 0.679 | Acc: 79.178% (3563/4500)\n",
            "Test Epoch: 44 | Loss: 0.679 | Acc: 79.065% (3637/4600)\n",
            "Test Epoch: 44 | Loss: 0.680 | Acc: 79.021% (3714/4700)\n",
            "Test Epoch: 44 | Loss: 0.682 | Acc: 79.042% (3794/4800)\n",
            "Test Epoch: 44 | Loss: 0.679 | Acc: 79.122% (3877/4900)\n",
            "Test Epoch: 44 | Loss: 0.681 | Acc: 79.040% (3952/5000)\n",
            "Test Epoch: 44 | Loss: 0.677 | Acc: 79.098% (4034/5100)\n",
            "Test Epoch: 44 | Loss: 0.676 | Acc: 79.077% (4112/5200)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 79.094% (4192/5300)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.130% (4273/5400)\n",
            "Test Epoch: 44 | Loss: 0.671 | Acc: 79.164% (4354/5500)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.107% (4430/5600)\n",
            "Test Epoch: 44 | Loss: 0.676 | Acc: 79.140% (4511/5700)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.259% (4597/5800)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.153% (4670/5900)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 79.100% (4746/6000)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.180% (4830/6100)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.161% (4908/6200)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 79.159% (4987/6300)\n",
            "Test Epoch: 44 | Loss: 0.670 | Acc: 79.312% (5076/6400)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.277% (5153/6500)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.212% (5228/6600)\n",
            "Test Epoch: 44 | Loss: 0.671 | Acc: 79.239% (5309/6700)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.147% (5382/6800)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.203% (5465/6900)\n",
            "Test Epoch: 44 | Loss: 0.674 | Acc: 79.143% (5540/7000)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 79.127% (5618/7100)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.194% (5702/7200)\n",
            "Test Epoch: 44 | Loss: 0.670 | Acc: 79.247% (5785/7300)\n",
            "Test Epoch: 44 | Loss: 0.668 | Acc: 79.243% (5864/7400)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.147% (5936/7500)\n",
            "Test Epoch: 44 | Loss: 0.670 | Acc: 79.184% (6018/7600)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 79.091% (6090/7700)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 79.013% (6163/7800)\n",
            "Test Epoch: 44 | Loss: 0.676 | Acc: 78.987% (6240/7900)\n",
            "Test Epoch: 44 | Loss: 0.676 | Acc: 79.000% (6320/8000)\n",
            "Test Epoch: 44 | Loss: 0.674 | Acc: 79.000% (6399/8100)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.061% (6483/8200)\n",
            "Test Epoch: 44 | Loss: 0.671 | Acc: 79.060% (6562/8300)\n",
            "Test Epoch: 44 | Loss: 0.671 | Acc: 79.000% (6636/8400)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 78.965% (6712/8500)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.965% (6791/8600)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 78.908% (6865/8700)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 78.864% (6940/8800)\n",
            "Test Epoch: 44 | Loss: 0.675 | Acc: 78.854% (7018/8900)\n",
            "Test Epoch: 44 | Loss: 0.674 | Acc: 78.889% (7100/9000)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.967% (7186/9100)\n",
            "Test Epoch: 44 | Loss: 0.671 | Acc: 79.033% (7271/9200)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 78.989% (7346/9300)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.926% (7419/9400)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.916% (7497/9500)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 78.948% (7579/9600)\n",
            "Test Epoch: 44 | Loss: 0.672 | Acc: 79.000% (7663/9700)\n",
            "Test Epoch: 44 | Loss: 0.673 | Acc: 78.908% (7733/9800)\n",
            "Test Epoch: 44 | Loss: 0.674 | Acc: 78.859% (7807/9900)\n",
            "Test Epoch: 44 | Loss: 0.676 | Acc: 78.840% (7884/10000)\n",
            "\n",
            "Epoch: 45\n",
            "Train Epoch: 45 | Loss: 0.360 | Acc: 85.938% (110/128)\n",
            "Train Epoch: 45 | Loss: 0.373 | Acc: 87.500% (224/256)\n",
            "Train Epoch: 45 | Loss: 0.415 | Acc: 85.156% (327/384)\n",
            "Train Epoch: 45 | Loss: 0.415 | Acc: 85.742% (439/512)\n",
            "Train Epoch: 45 | Loss: 0.405 | Acc: 86.094% (551/640)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.068% (661/768)\n",
            "Train Epoch: 45 | Loss: 0.413 | Acc: 85.603% (767/896)\n",
            "Train Epoch: 45 | Loss: 0.431 | Acc: 85.156% (872/1024)\n",
            "Train Epoch: 45 | Loss: 0.418 | Acc: 85.590% (986/1152)\n",
            "Train Epoch: 45 | Loss: 0.405 | Acc: 85.859% (1099/1280)\n",
            "Train Epoch: 45 | Loss: 0.402 | Acc: 86.009% (1211/1408)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.872% (1319/1536)\n",
            "Train Epoch: 45 | Loss: 0.411 | Acc: 85.877% (1429/1664)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.603% (1534/1792)\n",
            "Train Epoch: 45 | Loss: 0.412 | Acc: 85.729% (1646/1920)\n",
            "Train Epoch: 45 | Loss: 0.420 | Acc: 85.449% (1750/2048)\n",
            "Train Epoch: 45 | Loss: 0.417 | Acc: 85.432% (1859/2176)\n",
            "Train Epoch: 45 | Loss: 0.413 | Acc: 85.634% (1973/2304)\n",
            "Train Epoch: 45 | Loss: 0.409 | Acc: 85.773% (2086/2432)\n",
            "Train Epoch: 45 | Loss: 0.409 | Acc: 85.703% (2194/2560)\n",
            "Train Epoch: 45 | Loss: 0.409 | Acc: 85.677% (2303/2688)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.689% (2413/2816)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.802% (2526/2944)\n",
            "Train Epoch: 45 | Loss: 0.413 | Acc: 85.677% (2632/3072)\n",
            "Train Epoch: 45 | Loss: 0.414 | Acc: 85.656% (2741/3200)\n",
            "Train Epoch: 45 | Loss: 0.413 | Acc: 85.667% (2851/3328)\n",
            "Train Epoch: 45 | Loss: 0.411 | Acc: 85.677% (2961/3456)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.770% (3074/3584)\n",
            "Train Epoch: 45 | Loss: 0.412 | Acc: 85.776% (3184/3712)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.859% (3297/3840)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.786% (3404/3968)\n",
            "Train Epoch: 45 | Loss: 0.412 | Acc: 85.693% (3510/4096)\n",
            "Train Epoch: 45 | Loss: 0.408 | Acc: 85.772% (3623/4224)\n",
            "Train Epoch: 45 | Loss: 0.408 | Acc: 85.823% (3735/4352)\n",
            "Train Epoch: 45 | Loss: 0.412 | Acc: 85.781% (3843/4480)\n",
            "Train Epoch: 45 | Loss: 0.412 | Acc: 85.764% (3952/4608)\n",
            "Train Epoch: 45 | Loss: 0.416 | Acc: 85.642% (4056/4736)\n",
            "Train Epoch: 45 | Loss: 0.413 | Acc: 85.752% (4171/4864)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.897% (4288/4992)\n",
            "Train Epoch: 45 | Loss: 0.409 | Acc: 85.820% (4394/5120)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.785% (4502/5248)\n",
            "Train Epoch: 45 | Loss: 0.409 | Acc: 85.789% (4612/5376)\n",
            "Train Epoch: 45 | Loss: 0.410 | Acc: 85.756% (4720/5504)\n",
            "Train Epoch: 45 | Loss: 0.408 | Acc: 85.813% (4833/5632)\n",
            "Train Epoch: 45 | Loss: 0.408 | Acc: 85.764% (4940/5760)\n",
            "Train Epoch: 45 | Loss: 0.408 | Acc: 85.751% (5049/5888)\n",
            "Train Epoch: 45 | Loss: 0.406 | Acc: 85.821% (5163/6016)\n",
            "Train Epoch: 45 | Loss: 0.407 | Acc: 85.710% (5266/6144)\n",
            "Train Epoch: 45 | Loss: 0.405 | Acc: 85.778% (5380/6272)\n",
            "Train Epoch: 45 | Loss: 0.406 | Acc: 85.766% (5489/6400)\n",
            "Train Epoch: 45 | Loss: 0.405 | Acc: 85.876% (5606/6528)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.832% (5713/6656)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.761% (5818/6784)\n",
            "Train Epoch: 45 | Loss: 0.403 | Acc: 85.749% (5927/6912)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.668% (6031/7040)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.658% (6140/7168)\n",
            "Train Epoch: 45 | Loss: 0.405 | Acc: 85.636% (6248/7296)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.749% (6366/7424)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.765% (6477/7552)\n",
            "Train Epoch: 45 | Loss: 0.404 | Acc: 85.742% (6585/7680)\n",
            "Train Epoch: 45 | Loss: 0.403 | Acc: 85.784% (6698/7808)\n",
            "Train Epoch: 45 | Loss: 0.403 | Acc: 85.811% (6810/7936)\n",
            "Train Epoch: 45 | Loss: 0.402 | Acc: 85.851% (6923/8064)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.925% (7039/8192)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.022% (7157/8320)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.068% (7271/8448)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.031% (7378/8576)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.041% (7489/8704)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.051% (7600/8832)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.038% (7709/8960)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.092% (7824/9088)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.155% (7940/9216)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.119% (8047/9344)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.149% (8160/9472)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.156% (8271/9600)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.153% (8381/9728)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.201% (8496/9856)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.268% (8613/9984)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.303% (8727/10112)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.299% (8837/10240)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.265% (8944/10368)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.271% (9055/10496)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.258% (9164/10624)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.226% (9271/10752)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.232% (9382/10880)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.201% (9489/11008)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.216% (9601/11136)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.222% (9712/11264)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.236% (9824/11392)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.189% (9929/11520)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.161% (10036/11648)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.065% (10135/11776)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.080% (10247/11904)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.087% (10358/12032)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.077% (10467/12160)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.068% (10576/12288)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.058% (10685/12416)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.089% (10799/12544)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.056% (10905/12672)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.078% (11018/12800)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.976% (11115/12928)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.983% (11226/13056)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.953% (11332/13184)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 85.900% (11435/13312)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 85.893% (11544/13440)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 85.901% (11655/13568)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.879% (11762/13696)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.909% (11876/13824)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.923% (11988/13952)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.916% (12097/14080)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.916% (12207/14208)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.875% (12311/14336)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.861% (12419/14464)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.903% (12535/14592)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.890% (12643/14720)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.890% (12753/14848)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.904% (12865/14976)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.911% (12976/15104)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 85.892% (13083/15232)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 85.924% (13198/15360)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 85.925% (13308/15488)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 85.938% (13420/15616)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 85.944% (13531/15744)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 85.956% (13643/15872)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 85.950% (13752/16000)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 85.993% (13869/16128)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.054% (13989/16256)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.060% (14100/16384)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.053% (14209/16512)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.052% (14319/16640)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.081% (14434/16768)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.080% (14544/16896)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.102% (14658/17024)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.124% (14772/17152)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.128% (14883/17280)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.144% (14996/17408)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.177% (15112/17536)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.192% (15225/17664)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.168% (15331/17792)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.177% (15443/17920)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.187% (15555/18048)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.229% (15673/18176)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.227% (15783/18304)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.192% (15887/18432)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.196% (15998/18560)\n",
            "Train Epoch: 45 | Loss: 0.392 | Acc: 86.205% (16110/18688)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.198% (16219/18816)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.191% (16328/18944)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.194% (16439/19072)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.193% (16549/19200)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.212% (16663/19328)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.210% (16773/19456)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.213% (16884/19584)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.232% (16998/19712)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.225% (17107/19840)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.223% (17217/19968)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.236% (17330/20096)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.205% (17434/20224)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.213% (17546/20352)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.201% (17654/20480)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.224% (17769/20608)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.241% (17883/20736)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.225% (17990/20864)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.219% (18099/20992)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.226% (18211/21120)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.225% (18321/21248)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.260% (18439/21376)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.263% (18550/21504)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.252% (18658/21632)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.241% (18766/21760)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.257% (18880/21888)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.246% (18988/22016)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.249% (19099/22144)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.220% (19203/22272)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.188% (19306/22400)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.182% (19415/22528)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.189% (19527/22656)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.223% (19645/22784)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.230% (19757/22912)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.237% (19869/23040)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.235% (19979/23168)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.268% (20097/23296)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.292% (20213/23424)\n",
            "Train Epoch: 45 | Loss: 0.393 | Acc: 86.303% (20326/23552)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.271% (20429/23680)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.253% (20535/23808)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.234% (20641/23936)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.233% (20751/24064)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.243% (20864/24192)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.283% (20984/24320)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.306% (21100/24448)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.296% (21208/24576)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.273% (21313/24704)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.292% (21428/24832)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.290% (21538/24960)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.280% (21646/25088)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.298% (21761/25216)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.289% (21869/25344)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.295% (21981/25472)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.289% (22090/25600)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.307% (22205/25728)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.309% (22316/25856)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.326% (22431/25984)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.317% (22539/26112)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.338% (22655/26240)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.321% (22761/26368)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.304% (22867/26496)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.309% (22979/26624)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.285% (23083/26752)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.269% (23189/26880)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.252% (23295/27008)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.277% (23412/27136)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.271% (23521/27264)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.284% (23635/27392)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.275% (23743/27520)\n",
            "Train Epoch: 45 | Loss: 0.394 | Acc: 86.292% (23858/27648)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.305% (23972/27776)\n",
            "Train Epoch: 45 | Loss: 0.395 | Acc: 86.303% (24082/27904)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.276% (24185/28032)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.278% (24296/28160)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.284% (24408/28288)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.289% (24520/28416)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.302% (24634/28544)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.283% (24739/28672)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.278% (24848/28800)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.262% (24954/28928)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.285% (25071/29056)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.280% (25180/29184)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.279% (25290/29312)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.270% (25398/29440)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.269% (25508/29568)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.257% (25615/29696)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.263% (25727/29824)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.285% (25844/29952)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.287% (25955/30080)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.292% (26067/30208)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.290% (26177/30336)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.292% (26288/30464)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.294% (26399/30592)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.289% (26508/30720)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.275% (26614/30848)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.270% (26723/30976)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.272% (26834/31104)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.261% (26941/31232)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.266% (27053/31360)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.268% (27164/31488)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.257% (27271/31616)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.256% (27381/31744)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.267% (27495/31872)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.272% (27607/32000)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.295% (27725/32128)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.297% (27836/32256)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.299% (27947/32384)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.300% (28058/32512)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.287% (28164/32640)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.282% (28273/32768)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.287% (28385/32896)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.298% (28499/33024)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.302% (28611/33152)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.319% (28727/33280)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.330% (28841/33408)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.334% (28953/33536)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.344% (29067/33664)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.355% (29181/33792)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.365% (29295/33920)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.357% (29403/34048)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.359% (29514/34176)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.360% (29625/34304)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.350% (29732/34432)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.340% (29839/34560)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.338% (29949/34688)\n",
            "Train Epoch: 45 | Loss: 0.396 | Acc: 86.348% (30063/34816)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.332% (30168/34944)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.345% (30283/35072)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.344% (30393/35200)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.337% (30501/35328)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.324% (30607/35456)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.325% (30718/35584)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.324% (30828/35712)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.320% (30937/35840)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.318% (31047/35968)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.317% (31157/36096)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.313% (31266/36224)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.314% (31377/36352)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.324% (31491/36480)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.325% (31602/36608)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.329% (31714/36736)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.336% (31827/36864)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.340% (31939/36992)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.339% (32049/37120)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.327% (32155/37248)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.331% (32267/37376)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.332% (32378/37504)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.333% (32489/37632)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.343% (32603/37760)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.360% (32720/37888)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.366% (32833/38016)\n",
            "Train Epoch: 45 | Loss: 0.397 | Acc: 86.370% (32945/38144)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.363% (33053/38272)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.346% (33157/38400)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.345% (33267/38528)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.338% (33375/38656)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.345% (33488/38784)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.336% (33595/38912)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.329% (33703/39040)\n",
            "Train Epoch: 45 | Loss: 0.398 | Acc: 86.313% (33807/39168)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.304% (33914/39296)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.313% (34028/39424)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.314% (34139/39552)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.310% (34248/39680)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.319% (34362/39808)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.318% (34472/39936)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.317% (34582/40064)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.333% (34699/40192)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.317% (34803/40320)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.311% (34911/40448)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.317% (35024/40576)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.308% (35131/40704)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.307% (35241/40832)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.311% (35353/40960)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.320% (35467/41088)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.331% (35582/41216)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.332% (35693/41344)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.333% (35804/41472)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.334% (35915/41600)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.331% (36024/41728)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.327% (36133/41856)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.331% (36245/41984)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.341% (36360/42112)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.354% (36476/42240)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.351% (36585/42368)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.330% (36687/42496)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.339% (36801/42624)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.340% (36912/42752)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.341% (37023/42880)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.351% (37138/43008)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.350% (37248/43136)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.347% (37357/43264)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.334% (37462/43392)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.321% (37567/43520)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.329% (37681/43648)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.324% (37789/43776)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.336% (37905/43904)\n",
            "Train Epoch: 45 | Loss: 0.399 | Acc: 86.344% (38019/44032)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.325% (38121/44160)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.303% (38222/44288)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.302% (38332/44416)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.288% (38436/44544)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.298% (38551/44672)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.286% (38656/44800)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.287% (38767/44928)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.273% (38871/45056)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.278% (38984/45184)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.277% (39094/45312)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.265% (39199/45440)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.275% (39314/45568)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.272% (39423/45696)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.278% (39536/45824)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.277% (39646/45952)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.283% (39759/46080)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.273% (39865/46208)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.263% (39971/46336)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.258% (40079/46464)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.255% (40188/46592)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.259% (40300/46720)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.262% (40412/46848)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.255% (40519/46976)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.260% (40632/47104)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.261% (40743/47232)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.269% (40857/47360)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.266% (40966/47488)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.263% (41075/47616)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.252% (41180/47744)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.257% (41293/47872)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.263% (41406/48000)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.276% (41523/48128)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.273% (41632/48256)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.270% (41741/48384)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.263% (41848/48512)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.256% (41955/48640)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.261% (42068/48768)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.248% (42172/48896)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.252% (42284/49024)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.251% (42394/49152)\n",
            "Train Epoch: 45 | Loss: 0.400 | Acc: 86.252% (42505/49280)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.249% (42614/49408)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.248% (42724/49536)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.246% (42833/49664)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.233% (42937/49792)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.218% (43040/49920)\n",
            "Train Epoch: 45 | Loss: 0.401 | Acc: 86.218% (43109/50000)\n",
            "Test Epoch: 45 | Loss: 0.506 | Acc: 84.000% (84/100)\n",
            "Test Epoch: 45 | Loss: 0.632 | Acc: 81.000% (162/200)\n",
            "Test Epoch: 45 | Loss: 0.619 | Acc: 80.000% (240/300)\n",
            "Test Epoch: 45 | Loss: 0.653 | Acc: 80.250% (321/400)\n",
            "Test Epoch: 45 | Loss: 0.631 | Acc: 81.000% (405/500)\n",
            "Test Epoch: 45 | Loss: 0.573 | Acc: 82.333% (494/600)\n",
            "Test Epoch: 45 | Loss: 0.586 | Acc: 81.714% (572/700)\n",
            "Test Epoch: 45 | Loss: 0.604 | Acc: 81.375% (651/800)\n",
            "Test Epoch: 45 | Loss: 0.620 | Acc: 80.556% (725/900)\n",
            "Test Epoch: 45 | Loss: 0.608 | Acc: 80.800% (808/1000)\n",
            "Test Epoch: 45 | Loss: 0.599 | Acc: 81.091% (892/1100)\n",
            "Test Epoch: 45 | Loss: 0.605 | Acc: 80.667% (968/1200)\n",
            "Test Epoch: 45 | Loss: 0.608 | Acc: 80.538% (1047/1300)\n",
            "Test Epoch: 45 | Loss: 0.611 | Acc: 80.500% (1127/1400)\n",
            "Test Epoch: 45 | Loss: 0.607 | Acc: 80.667% (1210/1500)\n",
            "Test Epoch: 45 | Loss: 0.625 | Acc: 80.500% (1288/1600)\n",
            "Test Epoch: 45 | Loss: 0.620 | Acc: 80.471% (1368/1700)\n",
            "Test Epoch: 45 | Loss: 0.619 | Acc: 80.389% (1447/1800)\n",
            "Test Epoch: 45 | Loss: 0.617 | Acc: 80.579% (1531/1900)\n",
            "Test Epoch: 45 | Loss: 0.639 | Acc: 79.800% (1596/2000)\n",
            "Test Epoch: 45 | Loss: 0.650 | Acc: 79.762% (1675/2100)\n",
            "Test Epoch: 45 | Loss: 0.654 | Acc: 79.500% (1749/2200)\n",
            "Test Epoch: 45 | Loss: 0.666 | Acc: 79.348% (1825/2300)\n",
            "Test Epoch: 45 | Loss: 0.662 | Acc: 79.333% (1904/2400)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.200% (1980/2500)\n",
            "Test Epoch: 45 | Loss: 0.688 | Acc: 78.923% (2052/2600)\n",
            "Test Epoch: 45 | Loss: 0.679 | Acc: 79.111% (2136/2700)\n",
            "Test Epoch: 45 | Loss: 0.679 | Acc: 79.143% (2216/2800)\n",
            "Test Epoch: 45 | Loss: 0.680 | Acc: 79.103% (2294/2900)\n",
            "Test Epoch: 45 | Loss: 0.676 | Acc: 79.100% (2373/3000)\n",
            "Test Epoch: 45 | Loss: 0.677 | Acc: 79.097% (2452/3100)\n",
            "Test Epoch: 45 | Loss: 0.677 | Acc: 79.031% (2529/3200)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.212% (2614/3300)\n",
            "Test Epoch: 45 | Loss: 0.678 | Acc: 79.118% (2690/3400)\n",
            "Test Epoch: 45 | Loss: 0.678 | Acc: 79.029% (2766/3500)\n",
            "Test Epoch: 45 | Loss: 0.678 | Acc: 78.972% (2843/3600)\n",
            "Test Epoch: 45 | Loss: 0.682 | Acc: 78.973% (2922/3700)\n",
            "Test Epoch: 45 | Loss: 0.687 | Acc: 78.816% (2995/3800)\n",
            "Test Epoch: 45 | Loss: 0.685 | Acc: 78.897% (3077/3900)\n",
            "Test Epoch: 45 | Loss: 0.685 | Acc: 78.925% (3157/4000)\n",
            "Test Epoch: 45 | Loss: 0.686 | Acc: 78.951% (3237/4100)\n",
            "Test Epoch: 45 | Loss: 0.684 | Acc: 79.024% (3319/4200)\n",
            "Test Epoch: 45 | Loss: 0.680 | Acc: 79.209% (3406/4300)\n",
            "Test Epoch: 45 | Loss: 0.676 | Acc: 79.318% (3490/4400)\n",
            "Test Epoch: 45 | Loss: 0.677 | Acc: 79.333% (3570/4500)\n",
            "Test Epoch: 45 | Loss: 0.677 | Acc: 79.261% (3646/4600)\n",
            "Test Epoch: 45 | Loss: 0.677 | Acc: 79.255% (3725/4700)\n",
            "Test Epoch: 45 | Loss: 0.679 | Acc: 79.250% (3804/4800)\n",
            "Test Epoch: 45 | Loss: 0.675 | Acc: 79.286% (3885/4900)\n",
            "Test Epoch: 45 | Loss: 0.678 | Acc: 79.220% (3961/5000)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.314% (4045/5100)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.327% (4125/5200)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.340% (4205/5300)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.407% (4288/5400)\n",
            "Test Epoch: 45 | Loss: 0.669 | Acc: 79.418% (4368/5500)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.393% (4446/5600)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.386% (4525/5700)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.483% (4610/5800)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.339% (4681/5900)\n",
            "Test Epoch: 45 | Loss: 0.673 | Acc: 79.283% (4757/6000)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.328% (4839/6100)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.290% (4916/6200)\n",
            "Test Epoch: 45 | Loss: 0.673 | Acc: 79.286% (4995/6300)\n",
            "Test Epoch: 45 | Loss: 0.668 | Acc: 79.453% (5085/6400)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.415% (5162/6500)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.364% (5238/6600)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.403% (5320/6700)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.338% (5395/6800)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.391% (5478/6900)\n",
            "Test Epoch: 45 | Loss: 0.673 | Acc: 79.329% (5553/7000)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.324% (5632/7100)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.375% (5715/7200)\n",
            "Test Epoch: 45 | Loss: 0.669 | Acc: 79.425% (5798/7300)\n",
            "Test Epoch: 45 | Loss: 0.667 | Acc: 79.446% (5879/7400)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.347% (5951/7500)\n",
            "Test Epoch: 45 | Loss: 0.669 | Acc: 79.395% (6034/7600)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.338% (6109/7700)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.308% (6186/7800)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.316% (6266/7900)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.325% (6346/8000)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.321% (6425/8100)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.341% (6506/8200)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.325% (6584/8300)\n",
            "Test Epoch: 45 | Loss: 0.669 | Acc: 79.274% (6659/8400)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.212% (6733/8500)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.233% (6814/8600)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.172% (6888/8700)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.125% (6963/8800)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.090% (7039/8900)\n",
            "Test Epoch: 45 | Loss: 0.673 | Acc: 79.144% (7123/9000)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.220% (7209/9100)\n",
            "Test Epoch: 45 | Loss: 0.669 | Acc: 79.283% (7294/9200)\n",
            "Test Epoch: 45 | Loss: 0.670 | Acc: 79.258% (7371/9300)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.202% (7445/9400)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.189% (7523/9500)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.229% (7606/9600)\n",
            "Test Epoch: 45 | Loss: 0.671 | Acc: 79.268% (7689/9700)\n",
            "Test Epoch: 45 | Loss: 0.672 | Acc: 79.184% (7760/9800)\n",
            "Test Epoch: 45 | Loss: 0.673 | Acc: 79.121% (7833/9900)\n",
            "Test Epoch: 45 | Loss: 0.674 | Acc: 79.120% (7912/10000)\n",
            "\n",
            "Epoch: 46\n",
            "Train Epoch: 46 | Loss: 0.331 | Acc: 87.500% (112/128)\n",
            "Train Epoch: 46 | Loss: 0.368 | Acc: 84.766% (217/256)\n",
            "Train Epoch: 46 | Loss: 0.351 | Acc: 86.458% (332/384)\n",
            "Train Epoch: 46 | Loss: 0.360 | Acc: 86.719% (444/512)\n",
            "Train Epoch: 46 | Loss: 0.394 | Acc: 85.781% (549/640)\n",
            "Train Epoch: 46 | Loss: 0.389 | Acc: 85.938% (660/768)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 84.933% (761/896)\n",
            "Train Epoch: 46 | Loss: 0.393 | Acc: 85.156% (872/1024)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 85.243% (982/1152)\n",
            "Train Epoch: 46 | Loss: 0.415 | Acc: 84.375% (1080/1280)\n",
            "Train Epoch: 46 | Loss: 0.413 | Acc: 84.659% (1192/1408)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 84.961% (1305/1536)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 85.517% (1423/1664)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.324% (1529/1792)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 85.625% (1644/1920)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 85.791% (1757/2048)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 85.662% (1864/2176)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.634% (1973/2304)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.896% (2089/2432)\n",
            "Train Epoch: 46 | Loss: 0.414 | Acc: 85.664% (2193/2560)\n",
            "Train Epoch: 46 | Loss: 0.416 | Acc: 85.528% (2299/2688)\n",
            "Train Epoch: 46 | Loss: 0.412 | Acc: 85.760% (2415/2816)\n",
            "Train Epoch: 46 | Loss: 0.411 | Acc: 85.768% (2525/2944)\n",
            "Train Epoch: 46 | Loss: 0.413 | Acc: 85.645% (2631/3072)\n",
            "Train Epoch: 46 | Loss: 0.415 | Acc: 85.531% (2737/3200)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.727% (2853/3328)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.764% (2964/3456)\n",
            "Train Epoch: 46 | Loss: 0.411 | Acc: 85.742% (3073/3584)\n",
            "Train Epoch: 46 | Loss: 0.411 | Acc: 85.722% (3182/3712)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.911% (3299/3840)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.988% (3412/3968)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.791% (3514/4096)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.724% (3621/4224)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.800% (3734/4352)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.737% (3841/4480)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.764% (3952/4608)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.895% (4068/4736)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.979% (4182/4864)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 85.978% (4292/4992)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.016% (4404/5120)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.033% (4515/5248)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.882% (4617/5376)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 85.901% (4728/5504)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.884% (4837/5632)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.868% (4946/5760)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.853% (5055/5888)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.821% (5163/6016)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.758% (5269/6144)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.730% (5377/6272)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.703% (5485/6400)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.616% (5589/6528)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.682% (5703/6656)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.731% (5816/6784)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.720% (5925/6912)\n",
            "Train Epoch: 46 | Loss: 0.410 | Acc: 85.568% (6024/7040)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.617% (6137/7168)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.732% (6255/7296)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.709% (6363/7424)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.712% (6473/7552)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.742% (6585/7680)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.733% (6694/7808)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.748% (6805/7936)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.789% (6918/8064)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.828% (7031/8192)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.805% (7139/8320)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.760% (7245/8448)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.704% (7350/8576)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.696% (7459/8704)\n",
            "Train Epoch: 46 | Loss: 0.410 | Acc: 85.632% (7563/8832)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.625% (7672/8960)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.684% (7787/9088)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.666% (7895/9216)\n",
            "Train Epoch: 46 | Loss: 0.409 | Acc: 85.681% (8006/9344)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.737% (8121/9472)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.760% (8233/9600)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.814% (8348/9728)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.846% (8461/9856)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.747% (8561/9984)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.799% (8676/10112)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.801% (8786/10240)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.783% (8894/10368)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.776% (9003/10496)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.759% (9111/10624)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.742% (9219/10752)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.754% (9330/10880)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.747% (9439/11008)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.731% (9547/11136)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.716% (9655/11264)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.727% (9766/11392)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.738% (9877/11520)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.783% (9992/11648)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.793% (10103/11776)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.727% (10205/11904)\n",
            "Train Epoch: 46 | Loss: 0.408 | Acc: 85.696% (10311/12032)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.724% (10424/12160)\n",
            "Train Epoch: 46 | Loss: 0.407 | Acc: 85.742% (10536/12288)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.768% (10649/12416)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.778% (10760/12544)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.772% (10869/12672)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.805% (10983/12800)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.798% (11092/12928)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.815% (11204/13056)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.862% (11320/13184)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.825% (11425/13312)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.841% (11537/13440)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.864% (11650/13568)\n",
            "Train Epoch: 46 | Loss: 0.406 | Acc: 85.901% (11765/13696)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.952% (11882/13824)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.988% (11997/13952)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.973% (12105/14080)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.966% (12214/14208)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.972% (12325/14336)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.972% (12435/14464)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 85.972% (12545/14592)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.019% (12662/14720)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.012% (12771/14848)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.004% (12880/14976)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 85.984% (12987/15104)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.003% (13100/15232)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.029% (13214/15360)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 86.009% (13321/15488)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.027% (13434/15616)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.058% (13549/15744)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.076% (13662/15872)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.062% (13770/16000)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.068% (13881/16128)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.079% (13993/16256)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 86.047% (14098/16384)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.077% (14213/16512)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.124% (14331/16640)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.093% (14436/16768)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.109% (14549/16896)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.114% (14660/17024)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.101% (14768/17152)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.082% (14875/17280)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.098% (14988/17408)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.109% (15100/17536)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.113% (15211/17664)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.106% (15320/17792)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.110% (15431/17920)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.093% (15538/18048)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.097% (15649/18176)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.112% (15762/18304)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.155% (15880/18432)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.110% (15982/18560)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.093% (16089/18688)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.070% (16195/18816)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.085% (16308/18944)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.111% (16423/19072)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.104% (16532/19200)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.082% (16638/19328)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.071% (16746/19456)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.065% (16855/19584)\n",
            "Train Epoch: 46 | Loss: 0.405 | Acc: 86.044% (16961/19712)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.069% (17076/19840)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.093% (17191/19968)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.087% (17300/20096)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.091% (17411/20224)\n",
            "Train Epoch: 46 | Loss: 0.404 | Acc: 86.075% (17518/20352)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.104% (17634/20480)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.098% (17743/20608)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.097% (17853/20736)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.081% (17960/20864)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.071% (18068/20992)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.070% (18178/21120)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.083% (18291/21248)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.097% (18404/21376)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.096% (18514/21504)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.118% (18629/21632)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.098% (18735/21760)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.107% (18847/21888)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.101% (18956/22016)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.082% (19062/22144)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.099% (19176/22272)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.080% (19282/22400)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.062% (19388/22528)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.061% (19498/22656)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.034% (19602/22784)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.025% (19710/22912)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.033% (19822/23040)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.020% (19929/23168)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.045% (20045/23296)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.057% (20158/23424)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.078% (20273/23552)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.081% (20384/23680)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.093% (20497/23808)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.096% (20608/23936)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.083% (20715/24064)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.066% (20821/24192)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.094% (20938/24320)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.105% (21051/24448)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.104% (21161/24576)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.087% (21267/24704)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.095% (21379/24832)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.114% (21494/24960)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.125% (21607/25088)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.128% (21718/25216)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.162% (21837/25344)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.161% (21947/25472)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.168% (22059/25600)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.186% (22174/25728)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.204% (22289/25856)\n",
            "Train Epoch: 46 | Loss: 0.398 | Acc: 86.226% (22405/25984)\n",
            "Train Epoch: 46 | Loss: 0.398 | Acc: 86.221% (22514/26112)\n",
            "Train Epoch: 46 | Loss: 0.398 | Acc: 86.216% (22623/26240)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.173% (22722/26368)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.153% (22827/26496)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.140% (22934/26624)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.166% (23051/26752)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.146% (23156/26880)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.126% (23261/27008)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.114% (23368/27136)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.117% (23479/27264)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.116% (23589/27392)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.101% (23695/27520)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.071% (23797/27648)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.064% (23905/27776)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.045% (24010/27904)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.048% (24121/28032)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.062% (24235/28160)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.051% (24342/28288)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.061% (24455/28416)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.074% (24569/28544)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.077% (24680/28672)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.062% (24786/28800)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.086% (24903/28928)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.103% (25018/29056)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.099% (25127/29184)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.098% (25237/29312)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.087% (25344/29440)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.076% (25451/29568)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.079% (25562/29696)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.065% (25668/29824)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.038% (25770/29952)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.027% (25877/30080)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.020% (25985/30208)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.023% (26096/30336)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.020% (26205/30464)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.013% (26313/30592)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.019% (26425/30720)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.025% (26537/30848)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.041% (26652/30976)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.056% (26767/31104)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.034% (26870/31232)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.024% (26977/31360)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.011% (27083/31488)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.010% (27193/31616)\n",
            "Train Epoch: 46 | Loss: 0.403 | Acc: 86.001% (27300/31744)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.019% (27416/31872)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.031% (27530/32000)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.037% (27642/32128)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.049% (27756/32256)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.049% (27866/32384)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.036% (27972/32512)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.023% (28078/32640)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.038% (28193/32768)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.038% (28303/32896)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.059% (28420/33024)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.070% (28534/33152)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.091% (28651/33280)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.105% (28766/33408)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.125% (28883/33536)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.125% (28993/33664)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.124% (29103/33792)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.103% (29206/33920)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.108% (29318/34048)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.098% (29425/34176)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.101% (29536/34304)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.109% (29649/34432)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.123% (29764/34560)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.119% (29873/34688)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.133% (29988/34816)\n",
            "Train Epoch: 46 | Loss: 0.399 | Acc: 86.138% (30100/34944)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.129% (30207/35072)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.134% (30319/35200)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.133% (30429/35328)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.118% (30534/35456)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.120% (30645/35584)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.111% (30752/35712)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.110% (30862/35840)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.107% (30971/35968)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.093% (31076/36096)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.092% (31186/36224)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.086% (31294/36352)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.091% (31406/36480)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.088% (31515/36608)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.090% (31626/36736)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.095% (31738/36864)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.094% (31848/36992)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.083% (31954/37120)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.082% (32064/37248)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.079% (32173/37376)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.073% (32281/37504)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.068% (32389/37632)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.073% (32501/37760)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.075% (32612/37888)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.061% (32717/38016)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.066% (32829/38144)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.084% (32946/38272)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.081% (33055/38400)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.083% (33166/38528)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.082% (33276/38656)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.092% (33390/38784)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.084% (33497/38912)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.089% (33609/39040)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.075% (33714/39168)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.062% (33819/39296)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.069% (33932/39424)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.064% (34040/39552)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.071% (34153/39680)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.086% (34269/39808)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.083% (34378/39936)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.087% (34490/40064)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.084% (34599/40192)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.091% (34712/40320)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.093% (34823/40448)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.100% (34936/40576)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.105% (35048/40704)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.114% (35162/40832)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.111% (35271/40960)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.088% (35372/41088)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.090% (35483/41216)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.085% (35591/41344)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.085% (35701/41472)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.084% (35811/41600)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.072% (35916/41728)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.076% (36028/41856)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.078% (36139/41984)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.075% (36248/42112)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.087% (36363/42240)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.091% (36475/42368)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.088% (36584/42496)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.085% (36693/42624)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.076% (36799/42752)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.094% (36917/42880)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.100% (37030/43008)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.088% (37135/43136)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.104% (37252/43264)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.106% (37363/43392)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.110% (37475/43520)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.116% (37588/43648)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.111% (37696/43776)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.090% (37797/43904)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.092% (37908/44032)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.094% (38019/44160)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.105% (38134/44288)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.102% (38243/44416)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.110% (38357/44544)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.105% (38465/44672)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.089% (38568/44800)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.089% (38678/44928)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.088% (38788/45056)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.088% (38898/45184)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.085% (39007/45312)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.087% (39118/45440)\n",
            "Train Epoch: 46 | Loss: 0.402 | Acc: 86.096% (39232/45568)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.113% (39350/45696)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.121% (39464/45824)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.133% (39580/45952)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.141% (39694/46080)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.139% (39803/46208)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.145% (39916/46336)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.159% (40033/46464)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.159% (40143/46592)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.162% (40255/46720)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.151% (40360/46848)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.148% (40469/46976)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.160% (40585/47104)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.158% (40694/47232)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.147% (40799/47360)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.140% (40906/47488)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.135% (41014/47616)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.132% (41123/47744)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.134% (41234/47872)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.146% (41350/48000)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.168% (41471/48128)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.168% (41581/48256)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.159% (41687/48384)\n",
            "Train Epoch: 46 | Loss: 0.401 | Acc: 86.150% (41793/48512)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.149% (41903/48640)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.159% (42018/48768)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.156% (42127/48896)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.158% (42238/49024)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.151% (42345/49152)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.163% (42461/49280)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.170% (42575/49408)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.188% (42694/49536)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.169% (42795/49664)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.166% (42904/49792)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.168% (43015/49920)\n",
            "Train Epoch: 46 | Loss: 0.400 | Acc: 86.172% (43086/50000)\n",
            "Test Epoch: 46 | Loss: 0.528 | Acc: 83.000% (83/100)\n",
            "Test Epoch: 46 | Loss: 0.648 | Acc: 80.500% (161/200)\n",
            "Test Epoch: 46 | Loss: 0.626 | Acc: 80.000% (240/300)\n",
            "Test Epoch: 46 | Loss: 0.671 | Acc: 80.250% (321/400)\n",
            "Test Epoch: 46 | Loss: 0.651 | Acc: 80.800% (404/500)\n",
            "Test Epoch: 46 | Loss: 0.589 | Acc: 82.167% (493/600)\n",
            "Test Epoch: 46 | Loss: 0.604 | Acc: 81.571% (571/700)\n",
            "Test Epoch: 46 | Loss: 0.624 | Acc: 81.250% (650/800)\n",
            "Test Epoch: 46 | Loss: 0.638 | Acc: 80.444% (724/900)\n",
            "Test Epoch: 46 | Loss: 0.625 | Acc: 80.500% (805/1000)\n",
            "Test Epoch: 46 | Loss: 0.613 | Acc: 80.909% (890/1100)\n",
            "Test Epoch: 46 | Loss: 0.622 | Acc: 80.333% (964/1200)\n",
            "Test Epoch: 46 | Loss: 0.620 | Acc: 80.231% (1043/1300)\n",
            "Test Epoch: 46 | Loss: 0.621 | Acc: 80.143% (1122/1400)\n",
            "Test Epoch: 46 | Loss: 0.618 | Acc: 80.267% (1204/1500)\n",
            "Test Epoch: 46 | Loss: 0.638 | Acc: 80.125% (1282/1600)\n",
            "Test Epoch: 46 | Loss: 0.632 | Acc: 80.059% (1361/1700)\n",
            "Test Epoch: 46 | Loss: 0.631 | Acc: 80.111% (1442/1800)\n",
            "Test Epoch: 46 | Loss: 0.631 | Acc: 80.158% (1523/1900)\n",
            "Test Epoch: 46 | Loss: 0.653 | Acc: 79.500% (1590/2000)\n",
            "Test Epoch: 46 | Loss: 0.663 | Acc: 79.381% (1667/2100)\n",
            "Test Epoch: 46 | Loss: 0.667 | Acc: 79.227% (1743/2200)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.087% (1819/2300)\n",
            "Test Epoch: 46 | Loss: 0.673 | Acc: 79.208% (1901/2400)\n",
            "Test Epoch: 46 | Loss: 0.682 | Acc: 79.120% (1978/2500)\n",
            "Test Epoch: 46 | Loss: 0.697 | Acc: 78.885% (2051/2600)\n",
            "Test Epoch: 46 | Loss: 0.687 | Acc: 79.185% (2138/2700)\n",
            "Test Epoch: 46 | Loss: 0.687 | Acc: 79.250% (2219/2800)\n",
            "Test Epoch: 46 | Loss: 0.687 | Acc: 79.138% (2295/2900)\n",
            "Test Epoch: 46 | Loss: 0.683 | Acc: 79.133% (2374/3000)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 79.097% (2452/3100)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 79.031% (2529/3200)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.212% (2614/3300)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 79.088% (2689/3400)\n",
            "Test Epoch: 46 | Loss: 0.683 | Acc: 79.029% (2766/3500)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 78.944% (2842/3600)\n",
            "Test Epoch: 46 | Loss: 0.688 | Acc: 78.973% (2922/3700)\n",
            "Test Epoch: 46 | Loss: 0.692 | Acc: 78.895% (2998/3800)\n",
            "Test Epoch: 46 | Loss: 0.690 | Acc: 78.949% (3079/3900)\n",
            "Test Epoch: 46 | Loss: 0.690 | Acc: 78.900% (3156/4000)\n",
            "Test Epoch: 46 | Loss: 0.691 | Acc: 78.902% (3235/4100)\n",
            "Test Epoch: 46 | Loss: 0.689 | Acc: 78.952% (3316/4200)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 79.163% (3404/4300)\n",
            "Test Epoch: 46 | Loss: 0.681 | Acc: 79.273% (3488/4400)\n",
            "Test Epoch: 46 | Loss: 0.682 | Acc: 79.200% (3564/4500)\n",
            "Test Epoch: 46 | Loss: 0.683 | Acc: 79.174% (3642/4600)\n",
            "Test Epoch: 46 | Loss: 0.683 | Acc: 79.170% (3721/4700)\n",
            "Test Epoch: 46 | Loss: 0.685 | Acc: 79.167% (3800/4800)\n",
            "Test Epoch: 46 | Loss: 0.682 | Acc: 79.224% (3882/4900)\n",
            "Test Epoch: 46 | Loss: 0.684 | Acc: 79.120% (3956/5000)\n",
            "Test Epoch: 46 | Loss: 0.680 | Acc: 79.216% (4040/5100)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.212% (4119/5200)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.245% (4200/5300)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.315% (4283/5400)\n",
            "Test Epoch: 46 | Loss: 0.673 | Acc: 79.345% (4364/5500)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.321% (4442/5600)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.333% (4522/5700)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.466% (4609/5800)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.356% (4682/5900)\n",
            "Test Epoch: 46 | Loss: 0.678 | Acc: 79.300% (4758/6000)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.361% (4841/6100)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.371% (4921/6200)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.365% (5000/6300)\n",
            "Test Epoch: 46 | Loss: 0.673 | Acc: 79.531% (5090/6400)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.492% (5167/6500)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.394% (5240/6600)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.433% (5322/6700)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.309% (5393/6800)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.348% (5475/6900)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.286% (5550/7000)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.268% (5628/7100)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.319% (5711/7200)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.384% (5795/7300)\n",
            "Test Epoch: 46 | Loss: 0.671 | Acc: 79.419% (5877/7400)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.347% (5951/7500)\n",
            "Test Epoch: 46 | Loss: 0.673 | Acc: 79.368% (6032/7600)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.299% (6106/7700)\n",
            "Test Epoch: 46 | Loss: 0.678 | Acc: 79.231% (6180/7800)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.177% (6255/7900)\n",
            "Test Epoch: 46 | Loss: 0.679 | Acc: 79.188% (6335/8000)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.210% (6416/8100)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.220% (6496/8200)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.229% (6576/8300)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.202% (6653/8400)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.141% (6727/8500)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.116% (6804/8600)\n",
            "Test Epoch: 46 | Loss: 0.678 | Acc: 79.057% (6878/8700)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.011% (6953/8800)\n",
            "Test Epoch: 46 | Loss: 0.678 | Acc: 78.978% (7029/8900)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.033% (7113/9000)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.110% (7199/9100)\n",
            "Test Epoch: 46 | Loss: 0.673 | Acc: 79.174% (7284/9200)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.140% (7360/9300)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.117% (7437/9400)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.095% (7514/9500)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.115% (7595/9600)\n",
            "Test Epoch: 46 | Loss: 0.674 | Acc: 79.165% (7679/9700)\n",
            "Test Epoch: 46 | Loss: 0.675 | Acc: 79.102% (7752/9800)\n",
            "Test Epoch: 46 | Loss: 0.676 | Acc: 79.051% (7826/9900)\n",
            "Test Epoch: 46 | Loss: 0.677 | Acc: 79.050% (7905/10000)\n",
            "\n",
            "Epoch: 47\n",
            "Train Epoch: 47 | Loss: 0.417 | Acc: 88.281% (113/128)\n",
            "Train Epoch: 47 | Loss: 0.406 | Acc: 86.719% (222/256)\n",
            "Train Epoch: 47 | Loss: 0.380 | Acc: 88.021% (338/384)\n",
            "Train Epoch: 47 | Loss: 0.367 | Acc: 87.891% (450/512)\n",
            "Train Epoch: 47 | Loss: 0.364 | Acc: 88.125% (564/640)\n",
            "Train Epoch: 47 | Loss: 0.358 | Acc: 88.281% (678/768)\n",
            "Train Epoch: 47 | Loss: 0.365 | Acc: 87.835% (787/896)\n",
            "Train Epoch: 47 | Loss: 0.355 | Acc: 87.793% (899/1024)\n",
            "Train Epoch: 47 | Loss: 0.352 | Acc: 87.760% (1011/1152)\n",
            "Train Epoch: 47 | Loss: 0.368 | Acc: 87.031% (1114/1280)\n",
            "Train Epoch: 47 | Loss: 0.370 | Acc: 86.861% (1223/1408)\n",
            "Train Epoch: 47 | Loss: 0.375 | Acc: 86.719% (1332/1536)\n",
            "Train Epoch: 47 | Loss: 0.375 | Acc: 86.779% (1444/1664)\n",
            "Train Epoch: 47 | Loss: 0.380 | Acc: 86.607% (1552/1792)\n",
            "Train Epoch: 47 | Loss: 0.376 | Acc: 86.719% (1665/1920)\n",
            "Train Epoch: 47 | Loss: 0.378 | Acc: 86.572% (1773/2048)\n",
            "Train Epoch: 47 | Loss: 0.373 | Acc: 86.765% (1888/2176)\n",
            "Train Epoch: 47 | Loss: 0.372 | Acc: 86.806% (2000/2304)\n",
            "Train Epoch: 47 | Loss: 0.370 | Acc: 86.924% (2114/2432)\n",
            "Train Epoch: 47 | Loss: 0.369 | Acc: 87.031% (2228/2560)\n",
            "Train Epoch: 47 | Loss: 0.371 | Acc: 86.905% (2336/2688)\n",
            "Train Epoch: 47 | Loss: 0.372 | Acc: 86.683% (2441/2816)\n",
            "Train Epoch: 47 | Loss: 0.371 | Acc: 86.719% (2553/2944)\n",
            "Train Epoch: 47 | Loss: 0.369 | Acc: 86.882% (2669/3072)\n",
            "Train Epoch: 47 | Loss: 0.370 | Acc: 86.875% (2780/3200)\n",
            "Train Epoch: 47 | Loss: 0.366 | Acc: 86.959% (2894/3328)\n",
            "Train Epoch: 47 | Loss: 0.371 | Acc: 86.834% (3001/3456)\n",
            "Train Epoch: 47 | Loss: 0.375 | Acc: 86.663% (3106/3584)\n",
            "Train Epoch: 47 | Loss: 0.375 | Acc: 86.638% (3216/3712)\n",
            "Train Epoch: 47 | Loss: 0.377 | Acc: 86.667% (3328/3840)\n",
            "Train Epoch: 47 | Loss: 0.380 | Acc: 86.568% (3435/3968)\n",
            "Train Epoch: 47 | Loss: 0.380 | Acc: 86.646% (3549/4096)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.695% (3662/4224)\n",
            "Train Epoch: 47 | Loss: 0.380 | Acc: 86.742% (3775/4352)\n",
            "Train Epoch: 47 | Loss: 0.381 | Acc: 86.741% (3886/4480)\n",
            "Train Epoch: 47 | Loss: 0.383 | Acc: 86.762% (3998/4608)\n",
            "Train Epoch: 47 | Loss: 0.385 | Acc: 86.655% (4104/4736)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.698% (4217/4864)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.599% (4323/4992)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.680% (4438/5120)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.719% (4551/5248)\n",
            "Train Epoch: 47 | Loss: 0.383 | Acc: 86.775% (4665/5376)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.791% (4777/5504)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.808% (4889/5632)\n",
            "Train Epoch: 47 | Loss: 0.381 | Acc: 86.892% (5005/5760)\n",
            "Train Epoch: 47 | Loss: 0.381 | Acc: 86.855% (5114/5888)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.752% (5219/6016)\n",
            "Train Epoch: 47 | Loss: 0.383 | Acc: 86.702% (5327/6144)\n",
            "Train Epoch: 47 | Loss: 0.381 | Acc: 86.798% (5444/6272)\n",
            "Train Epoch: 47 | Loss: 0.383 | Acc: 86.781% (5554/6400)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.765% (5664/6528)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.779% (5776/6656)\n",
            "Train Epoch: 47 | Loss: 0.385 | Acc: 86.733% (5884/6784)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.704% (5993/6912)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.761% (6108/7040)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.775% (6220/7168)\n",
            "Train Epoch: 47 | Loss: 0.383 | Acc: 86.815% (6334/7296)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.813% (6445/7424)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.785% (6554/7552)\n",
            "Train Epoch: 47 | Loss: 0.382 | Acc: 86.810% (6667/7680)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.744% (6773/7808)\n",
            "Train Epoch: 47 | Loss: 0.385 | Acc: 86.731% (6883/7936)\n",
            "Train Epoch: 47 | Loss: 0.384 | Acc: 86.744% (6995/8064)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.658% (7099/8192)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.695% (7213/8320)\n",
            "Train Epoch: 47 | Loss: 0.385 | Acc: 86.754% (7329/8448)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.742% (7439/8576)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.707% (7547/8704)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.628% (7651/8832)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.629% (7762/8960)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.675% (7877/9088)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.654% (7986/9216)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.644% (8096/9344)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.624% (8205/9472)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.604% (8314/9600)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.554% (8420/9728)\n",
            "Train Epoch: 47 | Loss: 0.391 | Acc: 86.556% (8531/9856)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.639% (8650/9984)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.669% (8764/10112)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.650% (8873/10240)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.642% (8983/10368)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.690% (9099/10496)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.662% (9207/10624)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.626% (9314/10752)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.572% (9419/10880)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.537% (9526/11008)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.584% (9642/11136)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.586% (9753/11264)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.640% (9870/11392)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.606% (9977/11520)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.650% (10093/11648)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.693% (10209/11776)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.685% (10319/11904)\n",
            "Train Epoch: 47 | Loss: 0.386 | Acc: 86.760% (10439/12032)\n",
            "Train Epoch: 47 | Loss: 0.387 | Acc: 86.785% (10553/12160)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.727% (10657/12288)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.735% (10769/12416)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.727% (10879/12544)\n",
            "Train Epoch: 47 | Loss: 0.388 | Acc: 86.695% (10986/12672)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.633% (11089/12800)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.634% (11200/12928)\n",
            "Train Epoch: 47 | Loss: 0.389 | Acc: 86.619% (11309/13056)\n",
            "Train Epoch: 47 | Loss: 0.390 | Acc: 86.575% (11414/13184)\n",
            "Train Epoch: 47 | Loss: 0.391 | Acc: 86.538% (11520/13312)\n",
            "Train Epoch: 47 | Loss: 0.391 | Acc: 86.540% (11631/13440)\n",
            "Train Epoch: 47 | Loss: 0.392 | Acc: 86.520% (11739/13568)\n",
            "Train Epoch: 47 | Loss: 0.391 | Acc: 86.565% (11856/13696)\n",
            "Train Epoch: 47 | Loss: 0.391 | Acc: 86.545% (11964/13824)\n",
            "Train Epoch: 47 | Loss: 0.392 | Acc: 86.525% (12072/13952)\n",
            "Train Epoch: 47 | Loss: 0.393 | Acc: 86.484% (12177/14080)\n",
            "Train Epoch: 47 | Loss: 0.393 | Acc: 86.458% (12284/14208)\n",
            "Train Epoch: 47 | Loss: 0.394 | Acc: 86.426% (12390/14336)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.387% (12495/14464)\n",
            "Train Epoch: 47 | Loss: 0.394 | Acc: 86.397% (12607/14592)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.399% (12718/14720)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.362% (12823/14848)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.338% (12930/14976)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.341% (13041/15104)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.351% (13153/15232)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.361% (13265/15360)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.370% (13377/15488)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.392% (13491/15616)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.338% (13593/15744)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.309% (13699/15872)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.338% (13814/16000)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.347% (13926/16128)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.325% (14033/16256)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.304% (14140/16384)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.307% (14251/16512)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.316% (14363/16640)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.337% (14477/16768)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.352% (14590/16896)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.331% (14697/17024)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.334% (14808/17152)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.372% (14925/17280)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.397% (15040/17408)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.428% (15156/17536)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.441% (15269/17664)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.460% (15383/17792)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.456% (15493/17920)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.458% (15604/18048)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.455% (15714/18176)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.451% (15824/18304)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.442% (15933/18432)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.449% (16045/18560)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.462% (16158/18688)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.448% (16266/18816)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.418% (16371/18944)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.441% (16486/19072)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.417% (16592/19200)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.424% (16704/19328)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.374% (16805/19456)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.372% (16915/19584)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.359% (17023/19712)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.305% (17123/19840)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.298% (17232/19968)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.286% (17340/20096)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.274% (17448/20224)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.267% (17557/20352)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.260% (17666/20480)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.272% (17779/20608)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.261% (17887/20736)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.263% (17998/20864)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.266% (18109/20992)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.255% (18217/21120)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.267% (18330/21248)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.237% (18434/21376)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.268% (18551/21504)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.289% (18666/21632)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.310% (18781/21760)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.312% (18892/21888)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.269% (18993/22016)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.249% (19099/22144)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.252% (19210/22272)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.246% (19319/22400)\n",
            "Train Epoch: 47 | Loss: 0.402 | Acc: 86.230% (19426/22528)\n",
            "Train Epoch: 47 | Loss: 0.402 | Acc: 86.220% (19534/22656)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.249% (19651/22784)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.269% (19766/22912)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.280% (19879/23040)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.287% (19991/23168)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.281% (20100/23296)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.300% (20215/23424)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.324% (20331/23552)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.343% (20446/23680)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.345% (20557/23808)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.351% (20669/23936)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.366% (20783/24064)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.338% (20887/24192)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.345% (20999/24320)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.342% (21109/24448)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.353% (21222/24576)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.354% (21333/24704)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.336% (21439/24832)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.326% (21547/24960)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.308% (21653/25088)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.310% (21764/25216)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.285% (21868/25344)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.318% (21987/25472)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.328% (22100/25600)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.342% (22214/25728)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.344% (22325/25856)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.330% (22432/25984)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.324% (22541/26112)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.319% (22650/26240)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.317% (22760/26368)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.330% (22874/26496)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.332% (22985/26624)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.352% (23101/26752)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.347% (23210/26880)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.356% (23323/27008)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.350% (23432/27136)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.345% (23541/27264)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.365% (23657/27392)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.384% (23773/27520)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.397% (23887/27648)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.398% (23998/27776)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.400% (24109/27904)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.412% (24223/28032)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.424% (24337/28160)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.425% (24448/28288)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.409% (24554/28416)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.438% (24673/28544)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.443% (24785/28672)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.458% (24900/28800)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.463% (25012/28928)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.481% (25128/29056)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.486% (25240/29184)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.473% (25347/29312)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.461% (25454/29440)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.472% (25568/29568)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.463% (25676/29696)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.481% (25792/29824)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.485% (25904/29952)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.493% (26017/30080)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.487% (26126/30208)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.485% (26236/30336)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.486% (26347/30464)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.490% (26459/30592)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.520% (26579/30720)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.502% (26684/30848)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.496% (26793/30976)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.507% (26907/31104)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.504% (27017/31232)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.496% (27125/31360)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.487% (27233/31488)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.494% (27346/31616)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.492% (27456/31744)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.512% (27573/31872)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.506% (27682/32000)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.513% (27795/32128)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.514% (27906/32256)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.527% (28021/32384)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.547% (28138/32512)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.547% (28249/32640)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.533% (28355/32768)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.530% (28465/32896)\n",
            "Train Epoch: 47 | Loss: 0.395 | Acc: 86.519% (28572/33024)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.499% (28676/33152)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.496% (28786/33280)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.488% (28894/33408)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.468% (28998/33536)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.469% (29109/33664)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.470% (29220/33792)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.489% (29337/33920)\n",
            "Train Epoch: 47 | Loss: 0.396 | Acc: 86.484% (29446/34048)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.479% (29555/34176)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.486% (29668/34304)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.486% (29779/34432)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.484% (29889/34560)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.477% (29997/34688)\n",
            "Train Epoch: 47 | Loss: 0.397 | Acc: 86.472% (30106/34816)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.447% (30208/34944)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.445% (30318/35072)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.446% (30429/35200)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.444% (30539/35328)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.442% (30649/35456)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.435% (30757/35584)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.439% (30869/35712)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.437% (30979/35840)\n",
            "Train Epoch: 47 | Loss: 0.398 | Acc: 86.455% (31096/35968)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.414% (31192/36096)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.401% (31298/36224)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.391% (31405/36352)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.387% (31514/36480)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.391% (31626/36608)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.384% (31734/36736)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.366% (31838/36864)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.357% (31945/36992)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.360% (32057/37120)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.343% (32161/37248)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.333% (32268/37376)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.327% (32376/37504)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.320% (32484/37632)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.324% (32596/37760)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.328% (32708/37888)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.329% (32819/38016)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.310% (32922/38144)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.303% (33030/38272)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.299% (33139/38400)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.301% (33250/38528)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.294% (33358/38656)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.309% (33474/38784)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.310% (33585/38912)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.304% (33693/39040)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.300% (33802/39168)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.301% (33913/39296)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.295% (34021/39424)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.307% (34136/39552)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.316% (34250/39680)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.312% (34359/39808)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.326% (34475/39936)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.324% (34585/40064)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.328% (34697/40192)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.344% (34814/40320)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.328% (34918/40448)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.317% (35024/40576)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.308% (35131/40704)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.310% (35242/40832)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.326% (35359/40960)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.327% (35470/41088)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.333% (35583/41216)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.334% (35694/41344)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.340% (35807/41472)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.327% (35912/41600)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.331% (36024/41728)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.327% (36133/41856)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.316% (36239/41984)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.308% (36346/42112)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.316% (36460/42240)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.310% (36568/42368)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.307% (36677/42496)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.313% (36790/42624)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.312% (36900/42752)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.304% (37007/42880)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.314% (37122/43008)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.322% (37236/43136)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.324% (37347/43264)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.315% (37454/43392)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.317% (37565/43520)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.311% (37673/43648)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.317% (37786/43776)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.302% (37890/43904)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.290% (37995/44032)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.277% (38100/44160)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.281% (38212/44288)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.284% (38324/44416)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.281% (38433/44544)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.278% (38542/44672)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.286% (38656/44800)\n",
            "Train Epoch: 47 | Loss: 0.401 | Acc: 86.296% (38771/44928)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.299% (38883/45056)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.300% (38994/45184)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.291% (39100/45312)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.292% (39211/45440)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.293% (39322/45568)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.294% (39433/45696)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.308% (39550/45824)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.312% (39662/45952)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.322% (39777/46080)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.325% (39889/46208)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.326% (40000/46336)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.331% (40113/46464)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.328% (40222/46592)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.331% (40334/46720)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.322% (40440/46848)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.312% (40546/46976)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.318% (40659/47104)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.323% (40772/47232)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.324% (40883/47360)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.335% (40999/47488)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.345% (41114/47616)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.350% (41227/47744)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.336% (41331/47872)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.327% (41437/48000)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.322% (41545/48128)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.327% (41658/48256)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.328% (41769/48384)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.325% (41878/48512)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.324% (41988/48640)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.337% (42105/48768)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.328% (42211/48896)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.327% (42321/49024)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.314% (42425/49152)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.321% (42539/49280)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.318% (42648/49408)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.313% (42756/49536)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.318% (42869/49664)\n",
            "Train Epoch: 47 | Loss: 0.399 | Acc: 86.323% (42982/49792)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.310% (43086/49920)\n",
            "Train Epoch: 47 | Loss: 0.400 | Acc: 86.310% (43155/50000)\n",
            "Test Epoch: 47 | Loss: 0.513 | Acc: 83.000% (83/100)\n",
            "Test Epoch: 47 | Loss: 0.637 | Acc: 80.500% (161/200)\n",
            "Test Epoch: 47 | Loss: 0.624 | Acc: 79.333% (238/300)\n",
            "Test Epoch: 47 | Loss: 0.662 | Acc: 79.250% (317/400)\n",
            "Test Epoch: 47 | Loss: 0.643 | Acc: 80.000% (400/500)\n",
            "Test Epoch: 47 | Loss: 0.585 | Acc: 81.500% (489/600)\n",
            "Test Epoch: 47 | Loss: 0.597 | Acc: 81.143% (568/700)\n",
            "Test Epoch: 47 | Loss: 0.616 | Acc: 80.875% (647/800)\n",
            "Test Epoch: 47 | Loss: 0.634 | Acc: 80.111% (721/900)\n",
            "Test Epoch: 47 | Loss: 0.622 | Acc: 80.300% (803/1000)\n",
            "Test Epoch: 47 | Loss: 0.611 | Acc: 80.636% (887/1100)\n",
            "Test Epoch: 47 | Loss: 0.617 | Acc: 80.167% (962/1200)\n",
            "Test Epoch: 47 | Loss: 0.617 | Acc: 80.154% (1042/1300)\n",
            "Test Epoch: 47 | Loss: 0.621 | Acc: 80.071% (1121/1400)\n",
            "Test Epoch: 47 | Loss: 0.619 | Acc: 80.133% (1202/1500)\n",
            "Test Epoch: 47 | Loss: 0.637 | Acc: 79.938% (1279/1600)\n",
            "Test Epoch: 47 | Loss: 0.634 | Acc: 80.000% (1360/1700)\n",
            "Test Epoch: 47 | Loss: 0.634 | Acc: 79.944% (1439/1800)\n",
            "Test Epoch: 47 | Loss: 0.632 | Acc: 80.158% (1523/1900)\n",
            "Test Epoch: 47 | Loss: 0.656 | Acc: 79.500% (1590/2000)\n",
            "Test Epoch: 47 | Loss: 0.666 | Acc: 79.381% (1667/2100)\n",
            "Test Epoch: 47 | Loss: 0.669 | Acc: 79.182% (1742/2200)\n",
            "Test Epoch: 47 | Loss: 0.680 | Acc: 79.174% (1821/2300)\n",
            "Test Epoch: 47 | Loss: 0.673 | Acc: 79.292% (1903/2400)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.160% (1979/2500)\n",
            "Test Epoch: 47 | Loss: 0.700 | Acc: 78.846% (2050/2600)\n",
            "Test Epoch: 47 | Loss: 0.691 | Acc: 79.000% (2133/2700)\n",
            "Test Epoch: 47 | Loss: 0.691 | Acc: 79.000% (2212/2800)\n",
            "Test Epoch: 47 | Loss: 0.692 | Acc: 78.966% (2290/2900)\n",
            "Test Epoch: 47 | Loss: 0.688 | Acc: 79.000% (2370/3000)\n",
            "Test Epoch: 47 | Loss: 0.689 | Acc: 78.935% (2447/3100)\n",
            "Test Epoch: 47 | Loss: 0.688 | Acc: 78.906% (2525/3200)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 78.970% (2606/3300)\n",
            "Test Epoch: 47 | Loss: 0.689 | Acc: 78.853% (2681/3400)\n",
            "Test Epoch: 47 | Loss: 0.688 | Acc: 78.800% (2758/3500)\n",
            "Test Epoch: 47 | Loss: 0.688 | Acc: 78.778% (2836/3600)\n",
            "Test Epoch: 47 | Loss: 0.691 | Acc: 78.784% (2915/3700)\n",
            "Test Epoch: 47 | Loss: 0.696 | Acc: 78.658% (2989/3800)\n",
            "Test Epoch: 47 | Loss: 0.694 | Acc: 78.744% (3071/3900)\n",
            "Test Epoch: 47 | Loss: 0.694 | Acc: 78.725% (3149/4000)\n",
            "Test Epoch: 47 | Loss: 0.695 | Acc: 78.707% (3227/4100)\n",
            "Test Epoch: 47 | Loss: 0.693 | Acc: 78.833% (3311/4200)\n",
            "Test Epoch: 47 | Loss: 0.689 | Acc: 79.023% (3398/4300)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.205% (3485/4400)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.133% (3561/4500)\n",
            "Test Epoch: 47 | Loss: 0.687 | Acc: 79.022% (3635/4600)\n",
            "Test Epoch: 47 | Loss: 0.688 | Acc: 79.021% (3714/4700)\n",
            "Test Epoch: 47 | Loss: 0.690 | Acc: 79.000% (3792/4800)\n",
            "Test Epoch: 47 | Loss: 0.687 | Acc: 79.102% (3876/4900)\n",
            "Test Epoch: 47 | Loss: 0.690 | Acc: 79.020% (3951/5000)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.098% (4034/5100)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.077% (4112/5200)\n",
            "Test Epoch: 47 | Loss: 0.684 | Acc: 79.132% (4194/5300)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.204% (4277/5400)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.218% (4357/5500)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.214% (4436/5600)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.193% (4514/5700)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.310% (4600/5800)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.203% (4673/5900)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.150% (4749/6000)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.262% (4835/6100)\n",
            "Test Epoch: 47 | Loss: 0.684 | Acc: 79.242% (4913/6200)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.222% (4991/6300)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.375% (5080/6400)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.338% (5157/6500)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.273% (5232/6600)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.358% (5317/6700)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.279% (5391/6800)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.290% (5471/6900)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.171% (5542/7000)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.155% (5620/7100)\n",
            "Test Epoch: 47 | Loss: 0.684 | Acc: 79.222% (5704/7200)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.260% (5786/7300)\n",
            "Test Epoch: 47 | Loss: 0.679 | Acc: 79.270% (5866/7400)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.187% (5939/7500)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.237% (6022/7600)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.195% (6098/7700)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 79.115% (6171/7800)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.063% (6246/7900)\n",
            "Test Epoch: 47 | Loss: 0.686 | Acc: 79.062% (6325/8000)\n",
            "Test Epoch: 47 | Loss: 0.684 | Acc: 79.099% (6407/8100)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.122% (6488/8200)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.120% (6567/8300)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.071% (6642/8400)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.024% (6717/8500)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.023% (6796/8600)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 78.966% (6870/8700)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 78.943% (6947/8800)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 78.921% (7024/8900)\n",
            "Test Epoch: 47 | Loss: 0.684 | Acc: 78.978% (7108/9000)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.066% (7195/9100)\n",
            "Test Epoch: 47 | Loss: 0.680 | Acc: 79.130% (7280/9200)\n",
            "Test Epoch: 47 | Loss: 0.681 | Acc: 79.108% (7357/9300)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.064% (7432/9400)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.063% (7511/9500)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.083% (7592/9600)\n",
            "Test Epoch: 47 | Loss: 0.682 | Acc: 79.134% (7676/9700)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 79.051% (7747/9800)\n",
            "Test Epoch: 47 | Loss: 0.683 | Acc: 78.980% (7819/9900)\n",
            "Test Epoch: 47 | Loss: 0.685 | Acc: 78.970% (7897/10000)\n",
            "\n",
            "Epoch: 48\n",
            "Train Epoch: 48 | Loss: 0.358 | Acc: 87.500% (112/128)\n",
            "Train Epoch: 48 | Loss: 0.363 | Acc: 87.500% (224/256)\n",
            "Train Epoch: 48 | Loss: 0.374 | Acc: 87.240% (335/384)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.523% (443/512)\n",
            "Train Epoch: 48 | Loss: 0.381 | Acc: 86.719% (555/640)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.458% (664/768)\n",
            "Train Epoch: 48 | Loss: 0.390 | Acc: 86.272% (773/896)\n",
            "Train Epoch: 48 | Loss: 0.384 | Acc: 86.426% (885/1024)\n",
            "Train Epoch: 48 | Loss: 0.384 | Acc: 86.458% (996/1152)\n",
            "Train Epoch: 48 | Loss: 0.378 | Acc: 86.797% (1111/1280)\n",
            "Train Epoch: 48 | Loss: 0.372 | Acc: 87.003% (1225/1408)\n",
            "Train Epoch: 48 | Loss: 0.374 | Acc: 86.849% (1334/1536)\n",
            "Train Epoch: 48 | Loss: 0.369 | Acc: 87.200% (1451/1664)\n",
            "Train Epoch: 48 | Loss: 0.371 | Acc: 87.109% (1561/1792)\n",
            "Train Epoch: 48 | Loss: 0.373 | Acc: 87.083% (1672/1920)\n",
            "Train Epoch: 48 | Loss: 0.379 | Acc: 86.572% (1773/2048)\n",
            "Train Epoch: 48 | Loss: 0.382 | Acc: 86.581% (1884/2176)\n",
            "Train Epoch: 48 | Loss: 0.388 | Acc: 86.502% (1993/2304)\n",
            "Train Epoch: 48 | Loss: 0.392 | Acc: 86.431% (2102/2432)\n",
            "Train Epoch: 48 | Loss: 0.388 | Acc: 86.602% (2217/2560)\n",
            "Train Epoch: 48 | Loss: 0.383 | Acc: 86.868% (2335/2688)\n",
            "Train Epoch: 48 | Loss: 0.384 | Acc: 86.719% (2442/2816)\n",
            "Train Epoch: 48 | Loss: 0.388 | Acc: 86.515% (2547/2944)\n",
            "Train Epoch: 48 | Loss: 0.388 | Acc: 86.491% (2657/3072)\n",
            "Train Epoch: 48 | Loss: 0.385 | Acc: 86.594% (2771/3200)\n",
            "Train Epoch: 48 | Loss: 0.388 | Acc: 86.508% (2879/3328)\n",
            "Train Epoch: 48 | Loss: 0.391 | Acc: 86.458% (2988/3456)\n",
            "Train Epoch: 48 | Loss: 0.390 | Acc: 86.607% (3104/3584)\n",
            "Train Epoch: 48 | Loss: 0.392 | Acc: 86.476% (3210/3712)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.380% (3317/3840)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.416% (3429/3968)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.401% (3539/4096)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.458% (3652/4224)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.420% (3761/4352)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.429% (3872/4480)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.437% (3983/4608)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.444% (4094/4736)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.493% (4207/4864)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.358% (4311/4992)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.426% (4425/5120)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.471% (4538/5248)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.458% (4648/5376)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.392% (4755/5504)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.417% (4867/5632)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.493% (4982/5760)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.515% (5094/5888)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.519% (5205/6016)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.458% (5312/6144)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.480% (5424/6272)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.453% (5533/6400)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.489% (5646/6528)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.463% (5755/6656)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.394% (5861/6784)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.328% (5967/6912)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.378% (6081/7040)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.328% (6188/7168)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.335% (6299/7296)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.274% (6405/7424)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.255% (6514/7552)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.315% (6629/7680)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.270% (6736/7808)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.290% (6848/7936)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.260% (6956/8064)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.255% (7066/8192)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.274% (7178/8320)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.222% (7284/8448)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.252% (7397/8576)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.271% (7509/8704)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.311% (7623/8832)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.373% (7739/8960)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.411% (7853/9088)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.437% (7966/9216)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.419% (8075/9344)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.339% (8178/9472)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.406% (8295/9600)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.421% (8407/9728)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.404% (8516/9856)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.358% (8622/9984)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.402% (8737/10112)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.289% (8836/10240)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.285% (8946/10368)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.309% (9059/10496)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.305% (9169/10624)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.328% (9282/10752)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.342% (9394/10880)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.328% (9503/11008)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.333% (9614/11136)\n",
            "Train Epoch: 48 | Loss: 0.393 | Acc: 86.390% (9731/11264)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.350% (9837/11392)\n",
            "Train Epoch: 48 | Loss: 0.394 | Acc: 86.337% (9946/11520)\n",
            "Train Epoch: 48 | Loss: 0.395 | Acc: 86.281% (10050/11648)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.277% (10160/11776)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.290% (10272/11904)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.262% (10379/12032)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.275% (10491/12160)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.206% (10593/12288)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.244% (10708/12416)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.240% (10818/12544)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.261% (10931/12672)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.258% (11041/12800)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.255% (11151/12928)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.282% (11265/13056)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.302% (11378/13184)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.328% (11492/13312)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.324% (11602/13440)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.321% (11712/13568)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.354% (11827/13696)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.364% (11939/13824)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.346% (12047/13952)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.328% (12155/14080)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.318% (12264/14208)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.321% (12375/14336)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.276% (12479/14464)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.273% (12589/14592)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.257% (12697/14720)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.274% (12810/14848)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.291% (12923/14976)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.341% (13041/15104)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.318% (13148/15232)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.322% (13259/15360)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.325% (13370/15488)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.328% (13481/15616)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.344% (13594/15744)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.353% (13706/15872)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.356% (13817/16000)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.347% (13926/16128)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.350% (14037/16256)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.328% (14144/16384)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.374% (14262/16512)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.394% (14376/16640)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.403% (14488/16768)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.399% (14598/16896)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.378% (14705/17024)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.398% (14819/17152)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.418% (14933/17280)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.420% (15044/17408)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.388% (15149/17536)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.385% (15259/17664)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.398% (15372/17792)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.423% (15487/17920)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.403% (15594/18048)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.389% (15702/18176)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.396% (15814/18304)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.415% (15928/18432)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.395% (16035/18560)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.408% (16148/18688)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.421% (16261/18816)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.444% (16376/18944)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.472% (16492/19072)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.474% (16603/19200)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.491% (16717/19328)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.498% (16829/19456)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.504% (16941/19584)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.501% (17051/19712)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.497% (17161/19840)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.478% (17268/19968)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.480% (17379/20096)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.472% (17488/20224)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.429% (17590/20352)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.450% (17705/20480)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.462% (17818/20608)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.444% (17925/20736)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.436% (18034/20864)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.442% (18146/20992)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.444% (18257/21120)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.460% (18371/21248)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.447% (18479/21376)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.454% (18591/21504)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.446% (18700/21632)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.434% (18808/21760)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.417% (18915/21888)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.419% (19026/22016)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.425% (19138/22144)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.422% (19248/22272)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.451% (19365/22400)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.461% (19478/22528)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.441% (19584/22656)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.425% (19691/22784)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.422% (19801/22912)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.432% (19914/23040)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.421% (20022/23168)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.444% (20138/23296)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.441% (20248/23424)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.439% (20358/23552)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.410% (20462/23680)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.421% (20575/23808)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.418% (20685/23936)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.415% (20795/24064)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.425% (20908/24192)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.423% (21018/24320)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.445% (21134/24448)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.454% (21247/24576)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.435% (21353/24704)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.433% (21463/24832)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.466% (21582/24960)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.464% (21692/25088)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.473% (21805/25216)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.490% (21920/25344)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.487% (22030/25472)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.484% (22140/25600)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.478% (22249/25728)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.444% (22351/25856)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.449% (22463/25984)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.470% (22579/26112)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.463% (22688/26240)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.453% (22796/26368)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.436% (22902/26496)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.426% (23010/26624)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.401% (23114/26752)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.410% (23227/26880)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.411% (23338/27008)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.398% (23445/27136)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.407% (23558/27264)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.408% (23669/27392)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.406% (23779/27520)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.404% (23889/27648)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.391% (23996/27776)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.393% (24107/27904)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.398% (24219/28032)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.413% (24334/28160)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.394% (24439/28288)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.402% (24552/28416)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.393% (24660/28544)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.391% (24770/28672)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.375% (24876/28800)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.377% (24987/28928)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.402% (25105/29056)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.390% (25212/29184)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.388% (25322/29312)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.365% (25426/29440)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.360% (25535/29568)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.369% (25648/29696)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.380% (25762/29824)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.375% (25871/29952)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.370% (25980/30080)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.351% (26085/30208)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.333% (26190/30336)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.345% (26304/30464)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.366% (26421/30592)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.370% (26533/30720)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.365% (26642/30848)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.373% (26755/30976)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.388% (26870/31104)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.379% (26978/31232)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.384% (27090/31360)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.379% (27199/31488)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.364% (27305/31616)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.366% (27416/31744)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.374% (27529/31872)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.384% (27643/32000)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.401% (27759/32128)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.399% (27869/32256)\n",
            "Train Epoch: 48 | Loss: 0.396 | Acc: 86.407% (27982/32384)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.402% (28091/32512)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.394% (28199/32640)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.380% (28305/32768)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.390% (28419/32896)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.389% (28529/33024)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.384% (28638/33152)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.367% (28743/33280)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.360% (28851/33408)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.358% (28961/33536)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.350% (29069/33664)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.328% (29172/33792)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.344% (29288/33920)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.346% (29399/34048)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.356% (29513/34176)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.360% (29625/34304)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.362% (29736/34432)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.383% (29854/34560)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.373% (29961/34688)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.391% (30078/34816)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.401% (30192/34944)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.382% (30296/35072)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.375% (30404/35200)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.368% (30512/35328)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.352% (30617/35456)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.356% (30729/35584)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.358% (30840/35712)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.350% (30948/35840)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.343% (31056/35968)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.336% (31164/36096)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.338% (31275/36224)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.325% (31381/36352)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.321% (31490/36480)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.331% (31604/36608)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.327% (31713/36736)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.325% (31823/36864)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.324% (31933/36992)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.325% (32044/37120)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.321% (32153/37248)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.325% (32265/37376)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.327% (32376/37504)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.336% (32490/37632)\n",
            "Train Epoch: 48 | Loss: 0.397 | Acc: 86.345% (32604/37760)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.315% (32703/37888)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.282% (32801/38016)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.268% (32906/38144)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.254% (33011/38272)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.266% (33126/38400)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.257% (33233/38528)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.251% (33341/38656)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.257% (33454/38784)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.266% (33568/38912)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.276% (33682/39040)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.280% (33794/39168)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.289% (33908/39296)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.295% (34021/39424)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.291% (34130/39552)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.300% (34244/39680)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.297% (34353/39808)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.293% (34462/39936)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.292% (34572/40064)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.286% (34680/40192)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.285% (34790/40320)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.291% (34903/40448)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.302% (35018/40576)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.308% (35131/40704)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.307% (35241/40832)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.294% (35346/40960)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.295% (35457/41088)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.304% (35571/41216)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.295% (35678/41344)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.304% (35792/41472)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.317% (35908/41600)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.314% (36017/41728)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.317% (36129/41856)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.307% (36235/41984)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.301% (36343/42112)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.302% (36454/42240)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.301% (36564/42368)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.302% (36675/42496)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.306% (36787/42624)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.298% (36894/42752)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.301% (37006/42880)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.296% (37114/43008)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.283% (37219/43136)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.277% (37327/43264)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.265% (37432/43392)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.261% (37541/43520)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.256% (37649/43648)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.241% (37753/43776)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.229% (37858/43904)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.237% (37972/44032)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.225% (38077/44160)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.215% (38183/44288)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.221% (38296/44416)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.227% (38409/44544)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.224% (38518/44672)\n",
            "Train Epoch: 48 | Loss: 0.401 | Acc: 86.221% (38627/44800)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.222% (38738/44928)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.228% (38851/45056)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.227% (38961/45184)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.242% (39078/45312)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.250% (39192/45440)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.247% (39301/45568)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.250% (39413/45696)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.247% (39522/45824)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.257% (39637/45952)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.248% (39743/46080)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.247% (39853/46208)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.250% (39965/46336)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.269% (40084/46464)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.266% (40193/46592)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.267% (40304/46720)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.279% (40420/46848)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.282% (40532/46976)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.281% (40642/47104)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.276% (40750/47232)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.280% (40862/47360)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.283% (40974/47488)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.284% (41085/47616)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.279% (41193/47744)\n",
            "Train Epoch: 48 | Loss: 0.400 | Acc: 86.280% (41304/47872)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.290% (41419/48000)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.301% (41535/48128)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.313% (41651/48256)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.310% (41760/48384)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.298% (41865/48512)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.299% (41976/48640)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.290% (42082/48768)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.299% (42197/48896)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.294% (42305/49024)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.294% (42415/49152)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.307% (42532/49280)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.320% (42649/49408)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.323% (42761/49536)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.316% (42868/49664)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.323% (42982/49792)\n",
            "Train Epoch: 48 | Loss: 0.398 | Acc: 86.332% (43097/49920)\n",
            "Train Epoch: 48 | Loss: 0.399 | Acc: 86.314% (43157/50000)\n",
            "Test Epoch: 48 | Loss: 0.526 | Acc: 84.000% (84/100)\n",
            "Test Epoch: 48 | Loss: 0.638 | Acc: 79.500% (159/200)\n",
            "Test Epoch: 48 | Loss: 0.618 | Acc: 79.333% (238/300)\n",
            "Test Epoch: 48 | Loss: 0.660 | Acc: 78.750% (315/400)\n",
            "Test Epoch: 48 | Loss: 0.640 | Acc: 79.400% (397/500)\n",
            "Test Epoch: 48 | Loss: 0.583 | Acc: 81.000% (486/600)\n",
            "Test Epoch: 48 | Loss: 0.595 | Acc: 81.000% (567/700)\n",
            "Test Epoch: 48 | Loss: 0.611 | Acc: 80.750% (646/800)\n",
            "Test Epoch: 48 | Loss: 0.628 | Acc: 79.889% (719/900)\n",
            "Test Epoch: 48 | Loss: 0.620 | Acc: 80.000% (800/1000)\n",
            "Test Epoch: 48 | Loss: 0.609 | Acc: 80.273% (883/1100)\n",
            "Test Epoch: 48 | Loss: 0.616 | Acc: 79.833% (958/1200)\n",
            "Test Epoch: 48 | Loss: 0.614 | Acc: 79.692% (1036/1300)\n",
            "Test Epoch: 48 | Loss: 0.617 | Acc: 79.786% (1117/1400)\n",
            "Test Epoch: 48 | Loss: 0.613 | Acc: 80.000% (1200/1500)\n",
            "Test Epoch: 48 | Loss: 0.632 | Acc: 79.688% (1275/1600)\n",
            "Test Epoch: 48 | Loss: 0.629 | Acc: 79.588% (1353/1700)\n",
            "Test Epoch: 48 | Loss: 0.627 | Acc: 79.500% (1431/1800)\n",
            "Test Epoch: 48 | Loss: 0.626 | Acc: 79.789% (1516/1900)\n",
            "Test Epoch: 48 | Loss: 0.649 | Acc: 79.150% (1583/2000)\n",
            "Test Epoch: 48 | Loss: 0.660 | Acc: 79.000% (1659/2100)\n",
            "Test Epoch: 48 | Loss: 0.663 | Acc: 78.955% (1737/2200)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 78.826% (1813/2300)\n",
            "Test Epoch: 48 | Loss: 0.668 | Acc: 78.917% (1894/2400)\n",
            "Test Epoch: 48 | Loss: 0.678 | Acc: 78.760% (1969/2500)\n",
            "Test Epoch: 48 | Loss: 0.694 | Acc: 78.577% (2043/2600)\n",
            "Test Epoch: 48 | Loss: 0.684 | Acc: 78.889% (2130/2700)\n",
            "Test Epoch: 48 | Loss: 0.684 | Acc: 78.964% (2211/2800)\n",
            "Test Epoch: 48 | Loss: 0.685 | Acc: 78.897% (2288/2900)\n",
            "Test Epoch: 48 | Loss: 0.682 | Acc: 78.867% (2366/3000)\n",
            "Test Epoch: 48 | Loss: 0.682 | Acc: 78.839% (2444/3100)\n",
            "Test Epoch: 48 | Loss: 0.682 | Acc: 78.844% (2523/3200)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.000% (2607/3300)\n",
            "Test Epoch: 48 | Loss: 0.681 | Acc: 78.971% (2685/3400)\n",
            "Test Epoch: 48 | Loss: 0.681 | Acc: 78.829% (2759/3500)\n",
            "Test Epoch: 48 | Loss: 0.681 | Acc: 78.750% (2835/3600)\n",
            "Test Epoch: 48 | Loss: 0.684 | Acc: 78.730% (2913/3700)\n",
            "Test Epoch: 48 | Loss: 0.689 | Acc: 78.632% (2988/3800)\n",
            "Test Epoch: 48 | Loss: 0.687 | Acc: 78.615% (3066/3900)\n",
            "Test Epoch: 48 | Loss: 0.688 | Acc: 78.625% (3145/4000)\n",
            "Test Epoch: 48 | Loss: 0.688 | Acc: 78.634% (3224/4100)\n",
            "Test Epoch: 48 | Loss: 0.687 | Acc: 78.714% (3306/4200)\n",
            "Test Epoch: 48 | Loss: 0.682 | Acc: 78.930% (3394/4300)\n",
            "Test Epoch: 48 | Loss: 0.679 | Acc: 79.045% (3478/4400)\n",
            "Test Epoch: 48 | Loss: 0.680 | Acc: 79.022% (3556/4500)\n",
            "Test Epoch: 48 | Loss: 0.680 | Acc: 79.000% (3634/4600)\n",
            "Test Epoch: 48 | Loss: 0.681 | Acc: 78.957% (3711/4700)\n",
            "Test Epoch: 48 | Loss: 0.683 | Acc: 78.938% (3789/4800)\n",
            "Test Epoch: 48 | Loss: 0.680 | Acc: 79.020% (3872/4900)\n",
            "Test Epoch: 48 | Loss: 0.682 | Acc: 78.920% (3946/5000)\n",
            "Test Epoch: 48 | Loss: 0.678 | Acc: 79.039% (4031/5100)\n",
            "Test Epoch: 48 | Loss: 0.677 | Acc: 79.000% (4108/5200)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.075% (4191/5300)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.148% (4274/5400)\n",
            "Test Epoch: 48 | Loss: 0.671 | Acc: 79.164% (4354/5500)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.107% (4430/5600)\n",
            "Test Epoch: 48 | Loss: 0.677 | Acc: 79.105% (4509/5700)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.224% (4595/5800)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.119% (4668/5900)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.083% (4745/6000)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.213% (4832/6100)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.226% (4912/6200)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.222% (4991/6300)\n",
            "Test Epoch: 48 | Loss: 0.670 | Acc: 79.391% (5081/6400)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.354% (5158/6500)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.288% (5233/6600)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.343% (5316/6700)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.265% (5390/6800)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.304% (5472/6900)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.214% (5545/7000)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.197% (5623/7100)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.250% (5706/7200)\n",
            "Test Epoch: 48 | Loss: 0.671 | Acc: 79.315% (5790/7300)\n",
            "Test Epoch: 48 | Loss: 0.669 | Acc: 79.338% (5871/7400)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.267% (5945/7500)\n",
            "Test Epoch: 48 | Loss: 0.671 | Acc: 79.316% (6028/7600)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.312% (6107/7700)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.256% (6182/7800)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.215% (6258/7900)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.225% (6338/8000)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.259% (6420/8100)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.268% (6500/8200)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.265% (6579/8300)\n",
            "Test Epoch: 48 | Loss: 0.671 | Acc: 79.238% (6656/8400)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.176% (6730/8500)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.174% (6809/8600)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.126% (6884/8700)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.080% (6959/8800)\n",
            "Test Epoch: 48 | Loss: 0.677 | Acc: 79.022% (7033/8900)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.056% (7115/9000)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.132% (7201/9100)\n",
            "Test Epoch: 48 | Loss: 0.672 | Acc: 79.196% (7286/9200)\n",
            "Test Epoch: 48 | Loss: 0.673 | Acc: 79.161% (7362/9300)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.106% (7436/9400)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.105% (7515/9500)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.135% (7597/9600)\n",
            "Test Epoch: 48 | Loss: 0.674 | Acc: 79.165% (7679/9700)\n",
            "Test Epoch: 48 | Loss: 0.675 | Acc: 79.061% (7748/9800)\n",
            "Test Epoch: 48 | Loss: 0.676 | Acc: 79.010% (7822/9900)\n",
            "Test Epoch: 48 | Loss: 0.677 | Acc: 79.000% (7900/10000)\n",
            "\n",
            "Epoch: 49\n",
            "Train Epoch: 49 | Loss: 0.450 | Acc: 82.031% (105/128)\n",
            "Train Epoch: 49 | Loss: 0.413 | Acc: 84.766% (217/256)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.458% (332/384)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.523% (443/512)\n",
            "Train Epoch: 49 | Loss: 0.401 | Acc: 85.781% (549/640)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 85.807% (659/768)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 85.826% (769/896)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 85.938% (880/1024)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.111% (992/1152)\n",
            "Train Epoch: 49 | Loss: 0.380 | Acc: 86.484% (1107/1280)\n",
            "Train Epoch: 49 | Loss: 0.386 | Acc: 86.719% (1221/1408)\n",
            "Train Epoch: 49 | Loss: 0.388 | Acc: 86.654% (1331/1536)\n",
            "Train Epoch: 49 | Loss: 0.386 | Acc: 86.478% (1439/1664)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.551% (1551/1792)\n",
            "Train Epoch: 49 | Loss: 0.385 | Acc: 86.510% (1661/1920)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.621% (1774/2048)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.719% (1887/2176)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.502% (1993/2304)\n",
            "Train Epoch: 49 | Loss: 0.388 | Acc: 86.266% (2098/2432)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.250% (2208/2560)\n",
            "Train Epoch: 49 | Loss: 0.389 | Acc: 86.421% (2323/2688)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.541% (2437/2816)\n",
            "Train Epoch: 49 | Loss: 0.385 | Acc: 86.481% (2546/2944)\n",
            "Train Epoch: 49 | Loss: 0.385 | Acc: 86.556% (2659/3072)\n",
            "Train Epoch: 49 | Loss: 0.389 | Acc: 86.312% (2762/3200)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.148% (2867/3328)\n",
            "Train Epoch: 49 | Loss: 0.387 | Acc: 86.285% (2982/3456)\n",
            "Train Epoch: 49 | Loss: 0.387 | Acc: 86.244% (3091/3584)\n",
            "Train Epoch: 49 | Loss: 0.383 | Acc: 86.395% (3207/3712)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.354% (3316/3840)\n",
            "Train Epoch: 49 | Loss: 0.386 | Acc: 86.316% (3425/3968)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.426% (3540/4096)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.506% (3654/4224)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.558% (3767/4352)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.585% (3879/4480)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.610% (3991/4608)\n",
            "Train Epoch: 49 | Loss: 0.378 | Acc: 86.698% (4106/4736)\n",
            "Train Epoch: 49 | Loss: 0.377 | Acc: 86.698% (4217/4864)\n",
            "Train Epoch: 49 | Loss: 0.377 | Acc: 86.659% (4326/4992)\n",
            "Train Epoch: 49 | Loss: 0.377 | Acc: 86.680% (4438/5120)\n",
            "Train Epoch: 49 | Loss: 0.378 | Acc: 86.623% (4546/5248)\n",
            "Train Epoch: 49 | Loss: 0.376 | Acc: 86.644% (4658/5376)\n",
            "Train Epoch: 49 | Loss: 0.378 | Acc: 86.592% (4766/5504)\n",
            "Train Epoch: 49 | Loss: 0.380 | Acc: 86.559% (4875/5632)\n",
            "Train Epoch: 49 | Loss: 0.380 | Acc: 86.493% (4982/5760)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.447% (5090/5888)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.420% (5199/6016)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.458% (5312/6144)\n",
            "Train Epoch: 49 | Loss: 0.383 | Acc: 86.432% (5421/6272)\n",
            "Train Epoch: 49 | Loss: 0.383 | Acc: 86.406% (5530/6400)\n",
            "Train Epoch: 49 | Loss: 0.381 | Acc: 86.458% (5644/6528)\n",
            "Train Epoch: 49 | Loss: 0.379 | Acc: 86.553% (5761/6656)\n",
            "Train Epoch: 49 | Loss: 0.380 | Acc: 86.542% (5871/6784)\n",
            "Train Epoch: 49 | Loss: 0.379 | Acc: 86.632% (5988/6912)\n",
            "Train Epoch: 49 | Loss: 0.378 | Acc: 86.662% (6101/7040)\n",
            "Train Epoch: 49 | Loss: 0.379 | Acc: 86.621% (6209/7168)\n",
            "Train Epoch: 49 | Loss: 0.380 | Acc: 86.595% (6318/7296)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.476% (6420/7424)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.507% (6533/7552)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.549% (6647/7680)\n",
            "Train Epoch: 49 | Loss: 0.382 | Acc: 86.475% (6752/7808)\n",
            "Train Epoch: 49 | Loss: 0.384 | Acc: 86.467% (6862/7936)\n",
            "Train Epoch: 49 | Loss: 0.386 | Acc: 86.409% (6968/8064)\n",
            "Train Epoch: 49 | Loss: 0.387 | Acc: 86.401% (7078/8192)\n",
            "Train Epoch: 49 | Loss: 0.387 | Acc: 86.430% (7191/8320)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.328% (7293/8448)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.217% (7394/8576)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.190% (7502/8704)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.243% (7617/8832)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.317% (7734/8960)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.323% (7845/9088)\n",
            "Train Epoch: 49 | Loss: 0.389 | Acc: 86.339% (7957/9216)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.323% (8066/9344)\n",
            "Train Epoch: 49 | Loss: 0.389 | Acc: 86.391% (8183/9472)\n",
            "Train Epoch: 49 | Loss: 0.390 | Acc: 86.344% (8289/9600)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.256% (8391/9728)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.272% (8503/9856)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.338% (8620/9984)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.303% (8727/10112)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.338% (8841/10240)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.381% (8956/10368)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.328% (9061/10496)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.333% (9172/10624)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.310% (9280/10752)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.324% (9392/10880)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.301% (9500/11008)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.351% (9616/11136)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.355% (9727/11264)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.306% (9832/11392)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.267% (9938/11520)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.221% (10043/11648)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.260% (10158/11776)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.240% (10266/11904)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.278% (10381/12032)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.266% (10490/12160)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.312% (10606/12288)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.348% (10721/12416)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.368% (10834/12544)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.364% (10944/12672)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.367% (11055/12800)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.386% (11168/12928)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.366% (11276/13056)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.355% (11385/13184)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.351% (11495/13312)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.369% (11608/13440)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.358% (11717/13568)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.317% (11822/13696)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.270% (11926/13824)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.282% (12038/13952)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.300% (12151/14080)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.311% (12263/14208)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.300% (12372/14336)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.332% (12487/14464)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.273% (12589/14592)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.291% (12702/14720)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.247% (12806/14848)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.258% (12918/14976)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.249% (13027/15104)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.233% (13135/15232)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.283% (13253/15360)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.306% (13367/15488)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.347% (13484/15616)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.344% (13594/15744)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.347% (13705/15872)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.338% (13814/16000)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.316% (13921/16128)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.331% (14034/16256)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.322% (14143/16384)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.325% (14254/16512)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.310% (14362/16640)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.331% (14476/16768)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.370% (14593/16896)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.372% (14704/17024)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.375% (14815/17152)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.383% (14927/17280)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.397% (15040/17408)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.359% (15144/17536)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.368% (15256/17664)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.370% (15367/17792)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.356% (15475/17920)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.386% (15591/18048)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.356% (15696/18176)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.342% (15804/18304)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.355% (15917/18432)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.342% (16025/18560)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.296% (16127/18688)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.299% (16238/18816)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.286% (16346/18944)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.320% (16463/19072)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.354% (16580/19200)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.346% (16689/19328)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.354% (16801/19456)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.351% (16911/19584)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.374% (17026/19712)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.376% (17137/19840)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.398% (17252/19968)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.400% (17363/20096)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.387% (17471/20224)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.404% (17585/20352)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.416% (17698/20480)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.413% (17808/20608)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.400% (17916/20736)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.407% (18028/20864)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (18138/20992)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.416% (18251/21120)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.427% (18364/21248)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.443% (18478/21376)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.416% (18583/21504)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.400% (18690/21632)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.397% (18800/21760)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.367% (18904/21888)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.387% (19019/22016)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.394% (19131/22144)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.395% (19242/22272)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.402% (19354/22400)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.395% (19463/22528)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.414% (19578/22656)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.425% (19691/22784)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.448% (19807/22912)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.445% (19917/23040)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.464% (20032/23168)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.427% (20134/23296)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.428% (20245/23424)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.430% (20356/23552)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.440% (20469/23680)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.408% (20572/23808)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.418% (20685/23936)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.436% (20800/24064)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.434% (20910/24192)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.427% (21019/24320)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.424% (21129/24448)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.418% (21238/24576)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.391% (21342/24704)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.364% (21446/24832)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.350% (21553/24960)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.364% (21667/25088)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.386% (21783/25216)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.415% (21901/25344)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.432% (22016/25472)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.406% (22120/25600)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.431% (22237/25728)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.425% (22346/25856)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.411% (22453/25984)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.401% (22561/26112)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.418% (22676/26240)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.415% (22786/26368)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.413% (22896/26496)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.388% (23000/26624)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.397% (23113/26752)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.399% (23224/26880)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (23336/27008)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.406% (23447/27136)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.392% (23554/27264)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.390% (23664/27392)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.410% (23780/27520)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.433% (23897/27648)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.427% (24006/27776)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.432% (24118/27904)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.423% (24226/28032)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.442% (24342/28160)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.454% (24456/28288)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.444% (24564/28416)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.449% (24676/28544)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.464% (24791/28672)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.455% (24899/28800)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.459% (25011/28928)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.440% (25116/29056)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.438% (25226/29184)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.439% (25337/29312)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.433% (25446/29440)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.428% (25555/29568)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.419% (25663/29696)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.414% (25772/29824)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.415% (25883/29952)\n",
            "Train Epoch: 49 | Loss: 0.391 | Acc: 86.430% (25998/30080)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.411% (26103/30208)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.392% (26208/30336)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.400% (26321/30464)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.408% (26434/30592)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.416% (26547/30720)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (26654/30848)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.393% (26761/30976)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.397% (26873/31104)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.367% (26974/31232)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.374% (27087/31360)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.363% (27194/31488)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.358% (27303/31616)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.369% (27417/31744)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.367% (27527/31872)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.375% (27640/32000)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.395% (27757/32128)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.393% (27867/32256)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (27981/32384)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.423% (28098/32512)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.406% (28203/32640)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (28313/32768)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.406% (28424/32896)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.395% (28531/33024)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.420% (28650/33152)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.424% (28762/33280)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.404% (28866/33408)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.397% (28974/33536)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.413% (29090/33664)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.414% (29201/33792)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.409% (29310/33920)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.413% (29422/34048)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.412% (29532/34176)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.413% (29643/34304)\n",
            "Train Epoch: 49 | Loss: 0.392 | Acc: 86.402% (29750/34432)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.398% (29859/34560)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.376% (29962/34688)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.380% (30074/34816)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.375% (30183/34944)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.379% (30295/35072)\n",
            "Train Epoch: 49 | Loss: 0.393 | Acc: 86.384% (30407/35200)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.368% (30512/35328)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.349% (30616/35456)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.353% (30728/35584)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.341% (30834/35712)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.348% (30947/35840)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.357% (31061/35968)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.350% (31169/36096)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.363% (31284/36224)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.358% (31393/36352)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.354% (31502/36480)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.355% (31613/36608)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.373% (31730/36736)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.369% (31839/36864)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.338% (31938/36992)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.352% (32054/37120)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.346% (32162/37248)\n",
            "Train Epoch: 49 | Loss: 0.394 | Acc: 86.339% (32270/37376)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.321% (32374/37504)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.328% (32487/37632)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.322% (32595/37760)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.333% (32710/37888)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.337% (32822/38016)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.341% (32934/38144)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.342% (33045/38272)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.336% (33153/38400)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.348% (33268/38528)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.341% (33376/38656)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.335% (33484/38784)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.333% (33594/38912)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.345% (33709/39040)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.328% (33813/39168)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.332% (33925/39296)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.323% (34032/39424)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.324% (34143/39552)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.298% (34243/39680)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.294% (34352/39808)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.293% (34462/39936)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.284% (34569/40064)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.281% (34678/40192)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.285% (34790/40320)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.281% (34899/40448)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.290% (35013/40576)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.286% (35122/40704)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.285% (35232/40832)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.289% (35344/40960)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.310% (35463/41088)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.321% (35578/41216)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.315% (35686/41344)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.311% (35795/41472)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.322% (35910/41600)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.328% (36023/41728)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.336% (36137/41856)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.338% (36248/41984)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.332% (36356/42112)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.338% (36469/42240)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.341% (36581/42368)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.338% (36690/42496)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.348% (36805/42624)\n",
            "Train Epoch: 49 | Loss: 0.395 | Acc: 86.354% (36918/42752)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.348% (37026/42880)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.351% (37138/43008)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.334% (37241/43136)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.321% (37346/43264)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.315% (37454/43392)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.303% (37559/43520)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.299% (37668/43648)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.301% (37779/43776)\n",
            "Train Epoch: 49 | Loss: 0.396 | Acc: 86.320% (37898/43904)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.308% (38003/44032)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.311% (38115/44160)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.317% (38228/44288)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.313% (38337/44416)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.315% (38448/44544)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.311% (38557/44672)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.324% (38673/44800)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.318% (38781/44928)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.317% (38891/45056)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.316% (39001/45184)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.319% (39113/45312)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.314% (39221/45440)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.304% (39327/45568)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.312% (39441/45696)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.304% (39548/45824)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.303% (39658/45952)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.298% (39766/46080)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.295% (39875/46208)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.294% (39985/46336)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.286% (40092/46464)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.289% (40204/46592)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.295% (40317/46720)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.303% (40431/46848)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.291% (40536/46976)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.290% (40646/47104)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.293% (40758/47232)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.290% (40867/47360)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.291% (40978/47488)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.292% (41089/47616)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.291% (41199/47744)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.280% (41304/47872)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.290% (41419/48000)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.299% (41534/48128)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.304% (41647/48256)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.301% (41756/48384)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.296% (41864/48512)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.306% (41979/48640)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.300% (42087/48768)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.302% (42198/48896)\n",
            "Train Epoch: 49 | Loss: 0.397 | Acc: 86.301% (42308/49024)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.292% (42414/49152)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.278% (42518/49280)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.280% (42629/49408)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.281% (42740/49536)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.280% (42850/49664)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.277% (42959/49792)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.270% (43066/49920)\n",
            "Train Epoch: 49 | Loss: 0.398 | Acc: 86.272% (43136/50000)\n",
            "Test Epoch: 49 | Loss: 0.497 | Acc: 85.000% (85/100)\n",
            "Test Epoch: 49 | Loss: 0.615 | Acc: 82.000% (164/200)\n",
            "Test Epoch: 49 | Loss: 0.597 | Acc: 81.333% (244/300)\n",
            "Test Epoch: 49 | Loss: 0.636 | Acc: 81.000% (324/400)\n",
            "Test Epoch: 49 | Loss: 0.615 | Acc: 81.400% (407/500)\n",
            "Test Epoch: 49 | Loss: 0.561 | Acc: 82.833% (497/600)\n",
            "Test Epoch: 49 | Loss: 0.576 | Acc: 82.429% (577/700)\n",
            "Test Epoch: 49 | Loss: 0.595 | Acc: 82.250% (658/800)\n",
            "Test Epoch: 49 | Loss: 0.609 | Acc: 81.333% (732/900)\n",
            "Test Epoch: 49 | Loss: 0.602 | Acc: 81.300% (813/1000)\n",
            "Test Epoch: 49 | Loss: 0.592 | Acc: 81.364% (895/1100)\n",
            "Test Epoch: 49 | Loss: 0.600 | Acc: 80.917% (971/1200)\n",
            "Test Epoch: 49 | Loss: 0.598 | Acc: 80.692% (1049/1300)\n",
            "Test Epoch: 49 | Loss: 0.601 | Acc: 80.571% (1128/1400)\n",
            "Test Epoch: 49 | Loss: 0.597 | Acc: 80.467% (1207/1500)\n",
            "Test Epoch: 49 | Loss: 0.616 | Acc: 80.125% (1282/1600)\n",
            "Test Epoch: 49 | Loss: 0.610 | Acc: 80.294% (1365/1700)\n",
            "Test Epoch: 49 | Loss: 0.606 | Acc: 80.333% (1446/1800)\n",
            "Test Epoch: 49 | Loss: 0.605 | Acc: 80.474% (1529/1900)\n",
            "Test Epoch: 49 | Loss: 0.629 | Acc: 79.900% (1598/2000)\n",
            "Test Epoch: 49 | Loss: 0.639 | Acc: 79.714% (1674/2100)\n",
            "Test Epoch: 49 | Loss: 0.642 | Acc: 79.591% (1751/2200)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.435% (1827/2300)\n",
            "Test Epoch: 49 | Loss: 0.647 | Acc: 79.583% (1910/2400)\n",
            "Test Epoch: 49 | Loss: 0.658 | Acc: 79.360% (1984/2500)\n",
            "Test Epoch: 49 | Loss: 0.673 | Acc: 79.077% (2056/2600)\n",
            "Test Epoch: 49 | Loss: 0.663 | Acc: 79.370% (2143/2700)\n",
            "Test Epoch: 49 | Loss: 0.664 | Acc: 79.393% (2223/2800)\n",
            "Test Epoch: 49 | Loss: 0.665 | Acc: 79.414% (2303/2900)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.367% (2381/3000)\n",
            "Test Epoch: 49 | Loss: 0.663 | Acc: 79.323% (2459/3100)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.281% (2537/3200)\n",
            "Test Epoch: 49 | Loss: 0.657 | Acc: 79.424% (2621/3300)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.294% (2696/3400)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.286% (2775/3500)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.194% (2851/3600)\n",
            "Test Epoch: 49 | Loss: 0.665 | Acc: 79.189% (2930/3700)\n",
            "Test Epoch: 49 | Loss: 0.670 | Acc: 79.105% (3006/3800)\n",
            "Test Epoch: 49 | Loss: 0.669 | Acc: 79.128% (3086/3900)\n",
            "Test Epoch: 49 | Loss: 0.669 | Acc: 79.075% (3163/4000)\n",
            "Test Epoch: 49 | Loss: 0.670 | Acc: 79.073% (3242/4100)\n",
            "Test Epoch: 49 | Loss: 0.668 | Acc: 79.143% (3324/4200)\n",
            "Test Epoch: 49 | Loss: 0.663 | Acc: 79.349% (3412/4300)\n",
            "Test Epoch: 49 | Loss: 0.661 | Acc: 79.432% (3495/4400)\n",
            "Test Epoch: 49 | Loss: 0.661 | Acc: 79.422% (3574/4500)\n",
            "Test Epoch: 49 | Loss: 0.661 | Acc: 79.435% (3654/4600)\n",
            "Test Epoch: 49 | Loss: 0.662 | Acc: 79.447% (3734/4700)\n",
            "Test Epoch: 49 | Loss: 0.664 | Acc: 79.458% (3814/4800)\n",
            "Test Epoch: 49 | Loss: 0.660 | Acc: 79.592% (3900/4900)\n",
            "Test Epoch: 49 | Loss: 0.663 | Acc: 79.460% (3973/5000)\n",
            "Test Epoch: 49 | Loss: 0.659 | Acc: 79.510% (4055/5100)\n",
            "Test Epoch: 49 | Loss: 0.658 | Acc: 79.500% (4134/5200)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.528% (4215/5300)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.574% (4297/5400)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.600% (4378/5500)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.607% (4458/5600)\n",
            "Test Epoch: 49 | Loss: 0.658 | Acc: 79.579% (4536/5700)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.741% (4625/5800)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.661% (4700/5900)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.617% (4777/6000)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.738% (4864/6100)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.726% (4943/6200)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.714% (5022/6300)\n",
            "Test Epoch: 49 | Loss: 0.651 | Acc: 79.875% (5112/6400)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.846% (5190/6500)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.803% (5267/6600)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.866% (5351/6700)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.765% (5424/6800)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.812% (5507/6900)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.729% (5581/7000)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.690% (5658/7100)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.736% (5741/7200)\n",
            "Test Epoch: 49 | Loss: 0.651 | Acc: 79.781% (5824/7300)\n",
            "Test Epoch: 49 | Loss: 0.649 | Acc: 79.811% (5906/7400)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.693% (5977/7500)\n",
            "Test Epoch: 49 | Loss: 0.651 | Acc: 79.737% (6060/7600)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.688% (6136/7700)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.628% (6211/7800)\n",
            "Test Epoch: 49 | Loss: 0.657 | Acc: 79.557% (6285/7900)\n",
            "Test Epoch: 49 | Loss: 0.657 | Acc: 79.562% (6365/8000)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.568% (6445/8100)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.561% (6524/8200)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.566% (6604/8300)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.524% (6680/8400)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.471% (6755/8500)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.488% (6836/8600)\n",
            "Test Epoch: 49 | Loss: 0.657 | Acc: 79.425% (6910/8700)\n",
            "Test Epoch: 49 | Loss: 0.657 | Acc: 79.386% (6986/8800)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.393% (7066/8900)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.422% (7148/9000)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.505% (7235/9100)\n",
            "Test Epoch: 49 | Loss: 0.652 | Acc: 79.554% (7319/9200)\n",
            "Test Epoch: 49 | Loss: 0.653 | Acc: 79.527% (7396/9300)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.511% (7474/9400)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.484% (7551/9500)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.510% (7633/9600)\n",
            "Test Epoch: 49 | Loss: 0.654 | Acc: 79.536% (7715/9700)\n",
            "Test Epoch: 49 | Loss: 0.655 | Acc: 79.459% (7787/9800)\n",
            "Test Epoch: 49 | Loss: 0.656 | Acc: 79.404% (7861/9900)\n",
            "Test Epoch: 49 | Loss: 0.658 | Acc: 79.400% (7940/10000)\n",
            "Saving..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_acc)"
      ],
      "metadata": {
        "id": "Q8sWBnYVEDXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01d2686-6ff5-4d5b-b6e6-089ff25fa825"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(acc_list2)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ab7Ghab4kup8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3f2f2a17-5cbc-4185-b3de-8d57c0d39813"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_list2)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBE78E6Zk-se",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8be2cefb-ad56-417a-f64b-4f7bc515b948"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Qj_FyeZtx4p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb113457-1d29-47af-8626-73360af61a4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (linear): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "net"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "43dac162838e4ebe84fce40c9deea8aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75509578bcf04a51a6476978e5f22955",
              "IPY_MODEL_7163b26ae7a14712a6e38c0d68ed9d2d",
              "IPY_MODEL_33965e45b4474dbcb52bd5527f08551d"
            ],
            "layout": "IPY_MODEL_8250cd946cfe47c5910b8e4f226ce293"
          }
        },
        "75509578bcf04a51a6476978e5f22955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fd847978efa4e67a391dbbc528c82b3",
            "placeholder": "​",
            "style": "IPY_MODEL_7c410baeefef49bea460908d72038bce",
            "value": "100%"
          }
        },
        "7163b26ae7a14712a6e38c0d68ed9d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecf629d11b141448933a360a5b066cd",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fa97d222cb14aec8429e79390a9f054",
            "value": 170498071
          }
        },
        "33965e45b4474dbcb52bd5527f08551d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a351465dacda4ff5bf9a7e242172f6a1",
            "placeholder": "​",
            "style": "IPY_MODEL_11fe4deb10a146178770da0c8887c7f9",
            "value": " 170498071/170498071 [00:14&lt;00:00, 12652285.60it/s]"
          }
        },
        "8250cd946cfe47c5910b8e4f226ce293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd847978efa4e67a391dbbc528c82b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c410baeefef49bea460908d72038bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ecf629d11b141448933a360a5b066cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa97d222cb14aec8429e79390a9f054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a351465dacda4ff5bf9a7e242172f6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11fe4deb10a146178770da0c8887c7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}