{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYXxzqGtjO4o",
    "outputId": "56c9d4e5-ffee-4c18-8487-8bfe7919bd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.conda/envs/default/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: torchvision in ./.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: torch==1.13.0 in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: requests in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: torchinfo in ./.conda/envs/default/lib/python3.9/site-packages (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "!pip install torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "# from models import *\n",
    "# from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s0H94RJKjX0D"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P98wVKH1jkFQ",
    "outputId": "8bd95fbc-3d4b-46db-ab59-e8bb683582c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.3),\n",
    "    #transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "    #transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # augmentation\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET3HGuTnjX5-",
    "outputId": "723a7e92-b496-4f5e-bb3f-bdac2adebc13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2) #128\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2) #100\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BCLozv6sxiG",
    "outputId": "8d298b57-58d5-4a25-9f58-9345f9f9d2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6PkueVcjshd",
    "outputId": "6a36eb3c-53b3-492c-fac1-9917a3a57b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vZScwCXMjskX"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2zFlIhMQjsox"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkevL8y4kKVI",
    "outputId": "0eff75e8-0dbf-4c33-837c-d2de9feff54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [128, 10]                 --\n",
      "├─Conv2d: 1-1                            [128, 64, 32, 32]         1,728\n",
      "├─BatchNorm2d: 1-2                       [128, 64, 32, 32]         128\n",
      "├─Sequential: 1-3                        [128, 64, 32, 32]         --\n",
      "│    └─BasicBlock: 2-1                   [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-3                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-4             [128, 64, 32, 32]         128\n",
      "│    │    └─Sequential: 3-5              [128, 64, 32, 32]         --\n",
      "│    └─BasicBlock: 2-2                   [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-6                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-7             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-8                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-9             [128, 64, 32, 32]         128\n",
      "│    │    └─Sequential: 3-10             [128, 64, 32, 32]         --\n",
      "│    └─BasicBlock: 2-3                   [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-11                 [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-12            [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-13                 [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-14            [128, 64, 32, 32]         128\n",
      "│    │    └─Sequential: 3-15             [128, 64, 32, 32]         --\n",
      "├─Sequential: 1-4                        [128, 128, 16, 16]        --\n",
      "│    └─BasicBlock: 2-4                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-16                 [128, 128, 16, 16]        73,728\n",
      "│    │    └─BatchNorm2d: 3-17            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-18                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-19            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-20             [128, 128, 16, 16]        8,448\n",
      "│    └─BasicBlock: 2-5                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-21                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-22            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-23                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-24            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-25             [128, 128, 16, 16]        --\n",
      "│    └─BasicBlock: 2-6                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-26                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-27            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-28                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-29            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-30             [128, 128, 16, 16]        --\n",
      "│    └─BasicBlock: 2-7                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-31                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-32            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-33                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-34            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-35             [128, 128, 16, 16]        --\n",
      "├─Sequential: 1-5                        [128, 256, 8, 8]          --\n",
      "│    └─BasicBlock: 2-8                   [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-36                 [128, 256, 8, 8]          294,912\n",
      "│    │    └─BatchNorm2d: 3-37            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-38                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-39            [128, 256, 8, 8]          512\n",
      "│    │    └─Sequential: 3-40             [128, 256, 8, 8]          33,280\n",
      "│    └─BasicBlock: 2-9                   [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-41                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-42            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-43                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-44            [128, 256, 8, 8]          512\n",
      "│    │    └─Sequential: 3-45             [128, 256, 8, 8]          --\n",
      "│    └─BasicBlock: 2-10                  [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-46                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-47            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-48                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-49            [128, 256, 8, 8]          512\n",
      "│    │    └─Sequential: 3-50             [128, 256, 8, 8]          --\n",
      "├─Linear: 1-6                            [128, 10]                 10,250\n",
      "==========================================================================================\n",
      "Total params: 4,630,858\n",
      "Trainable params: 4,630,858\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 92.57\n",
      "==========================================================================================\n",
      "Input size (MB): 1.57\n",
      "Forward/backward pass size (MB): 1778.40\n",
      "Params size (MB): 18.52\n",
      "Estimated Total Size (MB): 1798.49\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(BasicBlock, [3, 4, 3, 3])\n",
    "\n",
    "print(summary(net,input_size=(128,3,32,32)))#input_size = (batch_size, #channel,imgsize)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wGV6CjKekg_y"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
    "                      momentum=0.9, weight_decay=6e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "64Oo01YMkhBJ"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Train Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (epoch, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #              % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bFiXz9dZkhCt"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Test Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                  % (epoch, test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "    return test_loss/(batch_idx+1), 100.*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzse6BCAlB10",
    "outputId": "e103cc7b-bc3a-47ae-9e91-5ae61b07fae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Epoch: 0 | Loss: 2.520 | Acc: 7.031% (9/128)\n",
      "Train Epoch: 0 | Loss: 2.478 | Acc: 7.031% (18/256)\n",
      "Train Epoch: 0 | Loss: 2.419 | Acc: 8.854% (34/384)\n",
      "Train Epoch: 0 | Loss: 2.390 | Acc: 9.766% (50/512)\n",
      "Train Epoch: 0 | Loss: 2.374 | Acc: 10.156% (65/640)\n",
      "Train Epoch: 0 | Loss: 2.363 | Acc: 10.286% (79/768)\n",
      "Train Epoch: 0 | Loss: 2.360 | Acc: 10.603% (95/896)\n",
      "Train Epoch: 0 | Loss: 2.363 | Acc: 10.352% (106/1024)\n",
      "Train Epoch: 0 | Loss: 2.374 | Acc: 10.069% (116/1152)\n",
      "Train Epoch: 0 | Loss: 2.383 | Acc: 9.844% (126/1280)\n",
      "Train Epoch: 0 | Loss: 2.386 | Acc: 9.659% (136/1408)\n",
      "Train Epoch: 0 | Loss: 2.384 | Acc: 9.766% (150/1536)\n",
      "Train Epoch: 0 | Loss: 2.377 | Acc: 9.736% (162/1664)\n",
      "Train Epoch: 0 | Loss: 2.370 | Acc: 10.212% (183/1792)\n",
      "Train Epoch: 0 | Loss: 2.366 | Acc: 10.521% (202/1920)\n",
      "Train Epoch: 0 | Loss: 2.364 | Acc: 10.303% (211/2048)\n",
      "Train Epoch: 0 | Loss: 2.361 | Acc: 10.524% (229/2176)\n",
      "Train Epoch: 0 | Loss: 2.359 | Acc: 10.460% (241/2304)\n",
      "Train Epoch: 0 | Loss: 2.356 | Acc: 10.403% (253/2432)\n",
      "Train Epoch: 0 | Loss: 2.352 | Acc: 10.508% (269/2560)\n",
      "Train Epoch: 0 | Loss: 2.349 | Acc: 10.677% (287/2688)\n",
      "Train Epoch: 0 | Loss: 2.346 | Acc: 10.760% (303/2816)\n",
      "Train Epoch: 0 | Loss: 2.343 | Acc: 11.141% (328/2944)\n",
      "Train Epoch: 0 | Loss: 2.342 | Acc: 11.263% (346/3072)\n",
      "Train Epoch: 0 | Loss: 2.340 | Acc: 11.312% (362/3200)\n",
      "Train Epoch: 0 | Loss: 2.337 | Acc: 11.478% (382/3328)\n",
      "Train Epoch: 0 | Loss: 2.335 | Acc: 11.690% (404/3456)\n",
      "Train Epoch: 0 | Loss: 2.331 | Acc: 11.942% (428/3584)\n",
      "Train Epoch: 0 | Loss: 2.327 | Acc: 12.069% (448/3712)\n",
      "Train Epoch: 0 | Loss: 2.323 | Acc: 12.240% (470/3840)\n",
      "Train Epoch: 0 | Loss: 2.321 | Acc: 12.324% (489/3968)\n",
      "Train Epoch: 0 | Loss: 2.316 | Acc: 12.842% (526/4096)\n",
      "Train Epoch: 0 | Loss: 2.312 | Acc: 13.116% (554/4224)\n",
      "Train Epoch: 0 | Loss: 2.309 | Acc: 13.350% (581/4352)\n",
      "Train Epoch: 0 | Loss: 2.306 | Acc: 13.527% (606/4480)\n",
      "Train Epoch: 0 | Loss: 2.303 | Acc: 13.672% (630/4608)\n",
      "Train Epoch: 0 | Loss: 2.299 | Acc: 13.809% (654/4736)\n",
      "Train Epoch: 0 | Loss: 2.296 | Acc: 13.980% (680/4864)\n",
      "Train Epoch: 0 | Loss: 2.291 | Acc: 14.183% (708/4992)\n",
      "Train Epoch: 0 | Loss: 2.287 | Acc: 14.238% (729/5120)\n",
      "Train Epoch: 0 | Loss: 2.285 | Acc: 14.386% (755/5248)\n",
      "Train Epoch: 0 | Loss: 2.283 | Acc: 14.472% (778/5376)\n",
      "Train Epoch: 0 | Loss: 2.278 | Acc: 14.680% (808/5504)\n",
      "Train Epoch: 0 | Loss: 2.276 | Acc: 14.862% (837/5632)\n",
      "Train Epoch: 0 | Loss: 2.271 | Acc: 14.965% (862/5760)\n",
      "Train Epoch: 0 | Loss: 2.267 | Acc: 15.149% (892/5888)\n",
      "Train Epoch: 0 | Loss: 2.263 | Acc: 15.492% (932/6016)\n",
      "Train Epoch: 0 | Loss: 2.260 | Acc: 15.641% (961/6144)\n",
      "Train Epoch: 0 | Loss: 2.258 | Acc: 15.800% (991/6272)\n",
      "Train Epoch: 0 | Loss: 2.255 | Acc: 15.844% (1014/6400)\n",
      "Train Epoch: 0 | Loss: 2.250 | Acc: 15.916% (1039/6528)\n",
      "Train Epoch: 0 | Loss: 2.246 | Acc: 16.061% (1069/6656)\n",
      "Train Epoch: 0 | Loss: 2.244 | Acc: 16.126% (1094/6784)\n",
      "Train Epoch: 0 | Loss: 2.241 | Acc: 16.233% (1122/6912)\n",
      "Train Epoch: 0 | Loss: 2.237 | Acc: 16.278% (1146/7040)\n",
      "Train Epoch: 0 | Loss: 2.233 | Acc: 16.490% (1182/7168)\n",
      "Train Epoch: 0 | Loss: 2.229 | Acc: 16.598% (1211/7296)\n",
      "Train Epoch: 0 | Loss: 2.226 | Acc: 16.662% (1237/7424)\n",
      "Train Epoch: 0 | Loss: 2.223 | Acc: 16.777% (1267/7552)\n",
      "Train Epoch: 0 | Loss: 2.220 | Acc: 16.940% (1301/7680)\n",
      "Train Epoch: 0 | Loss: 2.218 | Acc: 16.970% (1325/7808)\n",
      "Train Epoch: 0 | Loss: 2.216 | Acc: 17.011% (1350/7936)\n",
      "Train Epoch: 0 | Loss: 2.212 | Acc: 17.101% (1379/8064)\n",
      "Train Epoch: 0 | Loss: 2.209 | Acc: 17.249% (1413/8192)\n",
      "Train Epoch: 0 | Loss: 2.208 | Acc: 17.332% (1442/8320)\n",
      "Train Epoch: 0 | Loss: 2.205 | Acc: 17.472% (1476/8448)\n",
      "Train Epoch: 0 | Loss: 2.202 | Acc: 17.596% (1509/8576)\n",
      "Train Epoch: 0 | Loss: 2.199 | Acc: 17.727% (1543/8704)\n",
      "Train Epoch: 0 | Loss: 2.195 | Acc: 17.889% (1580/8832)\n",
      "Train Epoch: 0 | Loss: 2.191 | Acc: 18.114% (1623/8960)\n",
      "Train Epoch: 0 | Loss: 2.188 | Acc: 18.167% (1651/9088)\n",
      "Train Epoch: 0 | Loss: 2.187 | Acc: 18.175% (1675/9216)\n",
      "Train Epoch: 0 | Loss: 2.184 | Acc: 18.279% (1708/9344)\n",
      "Train Epoch: 0 | Loss: 2.182 | Acc: 18.328% (1736/9472)\n",
      "Train Epoch: 0 | Loss: 2.180 | Acc: 18.396% (1766/9600)\n",
      "Train Epoch: 0 | Loss: 2.179 | Acc: 18.442% (1794/9728)\n",
      "Train Epoch: 0 | Loss: 2.178 | Acc: 18.476% (1821/9856)\n",
      "Train Epoch: 0 | Loss: 2.174 | Acc: 18.540% (1851/9984)\n",
      "Train Epoch: 0 | Loss: 2.173 | Acc: 18.621% (1883/10112)\n",
      "Train Epoch: 0 | Loss: 2.170 | Acc: 18.691% (1914/10240)\n",
      "Train Epoch: 0 | Loss: 2.168 | Acc: 18.769% (1946/10368)\n",
      "Train Epoch: 0 | Loss: 2.165 | Acc: 18.883% (1982/10496)\n",
      "Train Epoch: 0 | Loss: 2.163 | Acc: 18.966% (2015/10624)\n",
      "Train Epoch: 0 | Loss: 2.160 | Acc: 19.038% (2047/10752)\n",
      "Train Epoch: 0 | Loss: 2.159 | Acc: 19.154% (2084/10880)\n",
      "Train Epoch: 0 | Loss: 2.156 | Acc: 19.241% (2118/11008)\n",
      "Train Epoch: 0 | Loss: 2.155 | Acc: 19.325% (2152/11136)\n",
      "Train Epoch: 0 | Loss: 2.153 | Acc: 19.363% (2181/11264)\n",
      "Train Epoch: 0 | Loss: 2.151 | Acc: 19.443% (2215/11392)\n",
      "Train Epoch: 0 | Loss: 2.148 | Acc: 19.557% (2253/11520)\n",
      "Train Epoch: 0 | Loss: 2.145 | Acc: 19.694% (2294/11648)\n",
      "Train Epoch: 0 | Loss: 2.141 | Acc: 19.778% (2329/11776)\n",
      "Train Epoch: 0 | Loss: 2.139 | Acc: 19.867% (2365/11904)\n",
      "Train Epoch: 0 | Loss: 2.137 | Acc: 19.972% (2403/12032)\n",
      "Train Epoch: 0 | Loss: 2.135 | Acc: 20.025% (2435/12160)\n",
      "Train Epoch: 0 | Loss: 2.132 | Acc: 20.142% (2475/12288)\n",
      "Train Epoch: 0 | Loss: 2.131 | Acc: 20.208% (2509/12416)\n",
      "Train Epoch: 0 | Loss: 2.129 | Acc: 20.281% (2544/12544)\n",
      "Train Epoch: 0 | Loss: 2.126 | Acc: 20.391% (2584/12672)\n",
      "Train Epoch: 0 | Loss: 2.123 | Acc: 20.500% (2624/12800)\n",
      "Train Epoch: 0 | Loss: 2.121 | Acc: 20.560% (2658/12928)\n",
      "Train Epoch: 0 | Loss: 2.118 | Acc: 20.695% (2702/13056)\n",
      "Train Epoch: 0 | Loss: 2.115 | Acc: 20.806% (2743/13184)\n",
      "Train Epoch: 0 | Loss: 2.114 | Acc: 20.861% (2777/13312)\n",
      "Train Epoch: 0 | Loss: 2.112 | Acc: 20.982% (2820/13440)\n",
      "Train Epoch: 0 | Loss: 2.111 | Acc: 21.027% (2853/13568)\n",
      "Train Epoch: 0 | Loss: 2.109 | Acc: 21.138% (2895/13696)\n",
      "Train Epoch: 0 | Loss: 2.108 | Acc: 21.137% (2922/13824)\n",
      "Train Epoch: 0 | Loss: 2.106 | Acc: 21.216% (2960/13952)\n",
      "Train Epoch: 0 | Loss: 2.104 | Acc: 21.342% (3005/14080)\n",
      "Train Epoch: 0 | Loss: 2.102 | Acc: 21.460% (3049/14208)\n",
      "Train Epoch: 0 | Loss: 2.099 | Acc: 21.575% (3093/14336)\n",
      "Train Epoch: 0 | Loss: 2.096 | Acc: 21.661% (3133/14464)\n",
      "Train Epoch: 0 | Loss: 2.095 | Acc: 21.690% (3165/14592)\n",
      "Train Epoch: 0 | Loss: 2.093 | Acc: 21.773% (3205/14720)\n",
      "Train Epoch: 0 | Loss: 2.091 | Acc: 21.855% (3245/14848)\n",
      "Train Epoch: 0 | Loss: 2.090 | Acc: 21.895% (3279/14976)\n",
      "Train Epoch: 0 | Loss: 2.088 | Acc: 21.954% (3316/15104)\n",
      "Train Epoch: 0 | Loss: 2.086 | Acc: 22.026% (3355/15232)\n",
      "Train Epoch: 0 | Loss: 2.084 | Acc: 22.064% (3389/15360)\n",
      "Train Epoch: 0 | Loss: 2.082 | Acc: 22.153% (3431/15488)\n",
      "Train Epoch: 0 | Loss: 2.081 | Acc: 22.170% (3462/15616)\n",
      "Train Epoch: 0 | Loss: 2.079 | Acc: 22.205% (3496/15744)\n",
      "Train Epoch: 0 | Loss: 2.078 | Acc: 22.272% (3535/15872)\n",
      "Train Epoch: 0 | Loss: 2.077 | Acc: 22.331% (3573/16000)\n",
      "Train Epoch: 0 | Loss: 2.077 | Acc: 22.328% (3601/16128)\n",
      "Train Epoch: 0 | Loss: 2.075 | Acc: 22.416% (3644/16256)\n",
      "Train Epoch: 0 | Loss: 2.073 | Acc: 22.467% (3681/16384)\n",
      "Train Epoch: 0 | Loss: 2.073 | Acc: 22.469% (3710/16512)\n",
      "Train Epoch: 0 | Loss: 2.072 | Acc: 22.512% (3746/16640)\n",
      "Train Epoch: 0 | Loss: 2.070 | Acc: 22.609% (3791/16768)\n",
      "Train Epoch: 0 | Loss: 2.070 | Acc: 22.633% (3824/16896)\n",
      "Train Epoch: 0 | Loss: 2.068 | Acc: 22.686% (3862/17024)\n",
      "Train Epoch: 0 | Loss: 2.067 | Acc: 22.732% (3899/17152)\n",
      "Train Epoch: 0 | Loss: 2.065 | Acc: 22.749% (3931/17280)\n",
      "Train Epoch: 0 | Loss: 2.063 | Acc: 22.817% (3972/17408)\n",
      "Train Epoch: 0 | Loss: 2.063 | Acc: 22.850% (4007/17536)\n",
      "Train Epoch: 0 | Loss: 2.062 | Acc: 22.871% (4040/17664)\n",
      "Train Epoch: 0 | Loss: 2.061 | Acc: 22.875% (4070/17792)\n",
      "Train Epoch: 0 | Loss: 2.059 | Acc: 23.002% (4122/17920)\n",
      "Train Epoch: 0 | Loss: 2.058 | Acc: 23.055% (4161/18048)\n",
      "Train Epoch: 0 | Loss: 2.056 | Acc: 23.151% (4208/18176)\n",
      "Train Epoch: 0 | Loss: 2.055 | Acc: 23.175% (4242/18304)\n",
      "Train Epoch: 0 | Loss: 2.053 | Acc: 23.237% (4283/18432)\n",
      "Train Epoch: 0 | Loss: 2.052 | Acc: 23.287% (4322/18560)\n",
      "Train Epoch: 0 | Loss: 2.051 | Acc: 23.298% (4354/18688)\n",
      "Train Epoch: 0 | Loss: 2.050 | Acc: 23.337% (4391/18816)\n",
      "Train Epoch: 0 | Loss: 2.049 | Acc: 23.348% (4423/18944)\n",
      "Train Epoch: 0 | Loss: 2.049 | Acc: 23.359% (4455/19072)\n",
      "Train Epoch: 0 | Loss: 2.047 | Acc: 23.411% (4495/19200)\n",
      "Train Epoch: 0 | Loss: 2.046 | Acc: 23.443% (4531/19328)\n",
      "Train Epoch: 0 | Loss: 2.045 | Acc: 23.473% (4567/19456)\n",
      "Train Epoch: 0 | Loss: 2.045 | Acc: 23.499% (4602/19584)\n",
      "Train Epoch: 0 | Loss: 2.043 | Acc: 23.564% (4645/19712)\n",
      "Train Epoch: 0 | Loss: 2.041 | Acc: 23.624% (4687/19840)\n",
      "Train Epoch: 0 | Loss: 2.039 | Acc: 23.733% (4739/19968)\n",
      "Train Epoch: 0 | Loss: 2.038 | Acc: 23.736% (4770/20096)\n",
      "Train Epoch: 0 | Loss: 2.037 | Acc: 23.818% (4817/20224)\n",
      "Train Epoch: 0 | Loss: 2.036 | Acc: 23.835% (4851/20352)\n",
      "Train Epoch: 0 | Loss: 2.035 | Acc: 23.887% (4892/20480)\n",
      "Train Epoch: 0 | Loss: 2.034 | Acc: 23.957% (4937/20608)\n",
      "Train Epoch: 0 | Loss: 2.032 | Acc: 23.978% (4972/20736)\n",
      "Train Epoch: 0 | Loss: 2.031 | Acc: 24.027% (5013/20864)\n",
      "Train Epoch: 0 | Loss: 2.030 | Acc: 24.085% (5056/20992)\n",
      "Train Epoch: 0 | Loss: 2.029 | Acc: 24.096% (5089/21120)\n",
      "Train Epoch: 0 | Loss: 2.028 | Acc: 24.176% (5137/21248)\n",
      "Train Epoch: 0 | Loss: 2.026 | Acc: 24.237% (5181/21376)\n",
      "Train Epoch: 0 | Loss: 2.024 | Acc: 24.284% (5222/21504)\n",
      "Train Epoch: 0 | Loss: 2.022 | Acc: 24.344% (5266/21632)\n",
      "Train Epoch: 0 | Loss: 2.021 | Acc: 24.370% (5303/21760)\n",
      "Train Epoch: 0 | Loss: 2.020 | Acc: 24.420% (5345/21888)\n",
      "Train Epoch: 0 | Loss: 2.018 | Acc: 24.487% (5391/22016)\n",
      "Train Epoch: 0 | Loss: 2.016 | Acc: 24.576% (5442/22144)\n",
      "Train Epoch: 0 | Loss: 2.016 | Acc: 24.600% (5479/22272)\n",
      "Train Epoch: 0 | Loss: 2.013 | Acc: 24.683% (5529/22400)\n",
      "Train Epoch: 0 | Loss: 2.012 | Acc: 24.711% (5567/22528)\n",
      "Train Epoch: 0 | Loss: 2.011 | Acc: 24.793% (5617/22656)\n",
      "Train Epoch: 0 | Loss: 2.010 | Acc: 24.846% (5661/22784)\n",
      "Train Epoch: 0 | Loss: 2.008 | Acc: 24.908% (5707/22912)\n",
      "Train Epoch: 0 | Loss: 2.006 | Acc: 24.983% (5756/23040)\n",
      "Train Epoch: 0 | Loss: 2.004 | Acc: 25.078% (5810/23168)\n",
      "Train Epoch: 0 | Loss: 2.004 | Acc: 25.103% (5848/23296)\n",
      "Train Epoch: 0 | Loss: 2.004 | Acc: 25.124% (5885/23424)\n",
      "Train Epoch: 0 | Loss: 2.003 | Acc: 25.157% (5925/23552)\n",
      "Train Epoch: 0 | Loss: 2.002 | Acc: 25.220% (5972/23680)\n",
      "Train Epoch: 0 | Loss: 2.001 | Acc: 25.265% (6015/23808)\n",
      "Train Epoch: 0 | Loss: 1.999 | Acc: 25.359% (6070/23936)\n",
      "Train Epoch: 0 | Loss: 1.998 | Acc: 25.411% (6115/24064)\n",
      "Train Epoch: 0 | Loss: 1.996 | Acc: 25.517% (6173/24192)\n",
      "Train Epoch: 0 | Loss: 1.994 | Acc: 25.596% (6225/24320)\n",
      "Train Epoch: 0 | Loss: 1.993 | Acc: 25.659% (6273/24448)\n",
      "Train Epoch: 0 | Loss: 1.992 | Acc: 25.684% (6312/24576)\n",
      "Train Epoch: 0 | Loss: 1.990 | Acc: 25.749% (6361/24704)\n",
      "Train Epoch: 0 | Loss: 1.989 | Acc: 25.793% (6405/24832)\n",
      "Train Epoch: 0 | Loss: 1.987 | Acc: 25.853% (6453/24960)\n",
      "Train Epoch: 0 | Loss: 1.986 | Acc: 25.929% (6505/25088)\n",
      "Train Epoch: 0 | Loss: 1.985 | Acc: 25.984% (6552/25216)\n",
      "Train Epoch: 0 | Loss: 1.985 | Acc: 26.022% (6595/25344)\n",
      "Train Epoch: 0 | Loss: 1.984 | Acc: 26.040% (6633/25472)\n",
      "Train Epoch: 0 | Loss: 1.983 | Acc: 26.086% (6678/25600)\n",
      "Train Epoch: 0 | Loss: 1.981 | Acc: 26.154% (6729/25728)\n",
      "Train Epoch: 0 | Loss: 1.980 | Acc: 26.180% (6769/25856)\n",
      "Train Epoch: 0 | Loss: 1.979 | Acc: 26.232% (6816/25984)\n",
      "Train Epoch: 0 | Loss: 1.978 | Acc: 26.275% (6861/26112)\n",
      "Train Epoch: 0 | Loss: 1.977 | Acc: 26.315% (6905/26240)\n",
      "Train Epoch: 0 | Loss: 1.975 | Acc: 26.365% (6952/26368)\n",
      "Train Epoch: 0 | Loss: 1.974 | Acc: 26.404% (6996/26496)\n",
      "Train Epoch: 0 | Loss: 1.973 | Acc: 26.461% (7045/26624)\n",
      "Train Epoch: 0 | Loss: 1.972 | Acc: 26.506% (7091/26752)\n",
      "Train Epoch: 0 | Loss: 1.971 | Acc: 26.510% (7126/26880)\n",
      "Train Epoch: 0 | Loss: 1.970 | Acc: 26.551% (7171/27008)\n",
      "Train Epoch: 0 | Loss: 1.968 | Acc: 26.610% (7221/27136)\n",
      "Train Epoch: 0 | Loss: 1.967 | Acc: 26.643% (7264/27264)\n",
      "Train Epoch: 0 | Loss: 1.966 | Acc: 26.690% (7311/27392)\n",
      "Train Epoch: 0 | Loss: 1.964 | Acc: 26.741% (7359/27520)\n",
      "Train Epoch: 0 | Loss: 1.963 | Acc: 26.758% (7398/27648)\n",
      "Train Epoch: 0 | Loss: 1.963 | Acc: 26.775% (7437/27776)\n",
      "Train Epoch: 0 | Loss: 1.962 | Acc: 26.799% (7478/27904)\n",
      "Train Epoch: 0 | Loss: 1.961 | Acc: 26.862% (7530/28032)\n",
      "Train Epoch: 0 | Loss: 1.960 | Acc: 26.875% (7568/28160)\n",
      "Train Epoch: 0 | Loss: 1.959 | Acc: 26.884% (7605/28288)\n",
      "Train Epoch: 0 | Loss: 1.958 | Acc: 26.897% (7643/28416)\n",
      "Train Epoch: 0 | Loss: 1.958 | Acc: 26.944% (7691/28544)\n",
      "Train Epoch: 0 | Loss: 1.956 | Acc: 27.019% (7747/28672)\n",
      "Train Epoch: 0 | Loss: 1.955 | Acc: 27.056% (7792/28800)\n",
      "Train Epoch: 0 | Loss: 1.955 | Acc: 27.084% (7835/28928)\n",
      "Train Epoch: 0 | Loss: 1.954 | Acc: 27.120% (7880/29056)\n",
      "Train Epoch: 0 | Loss: 1.953 | Acc: 27.155% (7925/29184)\n",
      "Train Epoch: 0 | Loss: 1.952 | Acc: 27.187% (7969/29312)\n",
      "Train Epoch: 0 | Loss: 1.951 | Acc: 27.225% (8015/29440)\n",
      "Train Epoch: 0 | Loss: 1.950 | Acc: 27.276% (8065/29568)\n",
      "Train Epoch: 0 | Loss: 1.949 | Acc: 27.334% (8117/29696)\n",
      "Train Epoch: 0 | Loss: 1.947 | Acc: 27.404% (8173/29824)\n",
      "Train Epoch: 0 | Loss: 1.946 | Acc: 27.441% (8219/29952)\n",
      "Train Epoch: 0 | Loss: 1.946 | Acc: 27.453% (8258/30080)\n",
      "Train Epoch: 0 | Loss: 1.944 | Acc: 27.513% (8311/30208)\n",
      "Train Epoch: 0 | Loss: 1.943 | Acc: 27.551% (8358/30336)\n",
      "Train Epoch: 0 | Loss: 1.943 | Acc: 27.590% (8405/30464)\n",
      "Train Epoch: 0 | Loss: 1.942 | Acc: 27.635% (8454/30592)\n",
      "Train Epoch: 0 | Loss: 1.941 | Acc: 27.692% (8507/30720)\n",
      "Train Epoch: 0 | Loss: 1.940 | Acc: 27.736% (8556/30848)\n",
      "Train Epoch: 0 | Loss: 1.939 | Acc: 27.780% (8605/30976)\n",
      "Train Epoch: 0 | Loss: 1.938 | Acc: 27.803% (8648/31104)\n",
      "Train Epoch: 0 | Loss: 1.937 | Acc: 27.827% (8691/31232)\n",
      "Train Epoch: 0 | Loss: 1.936 | Acc: 27.854% (8735/31360)\n",
      "Train Epoch: 0 | Loss: 1.935 | Acc: 27.880% (8779/31488)\n",
      "Train Epoch: 0 | Loss: 1.934 | Acc: 27.926% (8829/31616)\n",
      "Train Epoch: 0 | Loss: 1.933 | Acc: 27.967% (8878/31744)\n",
      "Train Epoch: 0 | Loss: 1.932 | Acc: 28.015% (8929/31872)\n",
      "Train Epoch: 0 | Loss: 1.931 | Acc: 28.075% (8984/32000)\n",
      "Train Epoch: 0 | Loss: 1.930 | Acc: 28.119% (9034/32128)\n",
      "Train Epoch: 0 | Loss: 1.929 | Acc: 28.159% (9083/32256)\n",
      "Train Epoch: 0 | Loss: 1.928 | Acc: 28.199% (9132/32384)\n",
      "Train Epoch: 0 | Loss: 1.927 | Acc: 28.230% (9178/32512)\n",
      "Train Epoch: 0 | Loss: 1.926 | Acc: 28.241% (9218/32640)\n",
      "Train Epoch: 0 | Loss: 1.926 | Acc: 28.241% (9254/32768)\n",
      "Train Epoch: 0 | Loss: 1.925 | Acc: 28.271% (9300/32896)\n",
      "Train Epoch: 0 | Loss: 1.924 | Acc: 28.322% (9353/33024)\n",
      "Train Epoch: 0 | Loss: 1.922 | Acc: 28.351% (9399/33152)\n",
      "Train Epoch: 0 | Loss: 1.922 | Acc: 28.356% (9437/33280)\n",
      "Train Epoch: 0 | Loss: 1.922 | Acc: 28.382% (9482/33408)\n",
      "Train Epoch: 0 | Loss: 1.921 | Acc: 28.405% (9526/33536)\n",
      "Train Epoch: 0 | Loss: 1.921 | Acc: 28.437% (9573/33664)\n",
      "Train Epoch: 0 | Loss: 1.920 | Acc: 28.483% (9625/33792)\n",
      "Train Epoch: 0 | Loss: 1.919 | Acc: 28.514% (9672/33920)\n",
      "Train Epoch: 0 | Loss: 1.918 | Acc: 28.583% (9732/34048)\n",
      "Train Epoch: 0 | Loss: 1.917 | Acc: 28.617% (9780/34176)\n",
      "Train Epoch: 0 | Loss: 1.916 | Acc: 28.650% (9828/34304)\n",
      "Train Epoch: 0 | Loss: 1.916 | Acc: 28.683% (9876/34432)\n",
      "Train Epoch: 0 | Loss: 1.915 | Acc: 28.695% (9917/34560)\n",
      "Train Epoch: 0 | Loss: 1.914 | Acc: 28.748% (9972/34688)\n",
      "Train Epoch: 0 | Loss: 1.913 | Acc: 28.766% (10015/34816)\n",
      "Train Epoch: 0 | Loss: 1.913 | Acc: 28.792% (10061/34944)\n",
      "Train Epoch: 0 | Loss: 1.912 | Acc: 28.826% (10110/35072)\n",
      "Train Epoch: 0 | Loss: 1.911 | Acc: 28.864% (10160/35200)\n",
      "Train Epoch: 0 | Loss: 1.911 | Acc: 28.901% (10210/35328)\n",
      "Train Epoch: 0 | Loss: 1.910 | Acc: 28.934% (10259/35456)\n",
      "Train Epoch: 0 | Loss: 1.909 | Acc: 28.965% (10307/35584)\n",
      "Train Epoch: 0 | Loss: 1.908 | Acc: 28.990% (10353/35712)\n",
      "Train Epoch: 0 | Loss: 1.907 | Acc: 29.043% (10409/35840)\n",
      "Train Epoch: 0 | Loss: 1.907 | Acc: 29.087% (10462/35968)\n",
      "Train Epoch: 0 | Loss: 1.906 | Acc: 29.128% (10514/36096)\n",
      "Train Epoch: 0 | Loss: 1.905 | Acc: 29.160% (10563/36224)\n",
      "Train Epoch: 0 | Loss: 1.904 | Acc: 29.192% (10612/36352)\n",
      "Train Epoch: 0 | Loss: 1.902 | Acc: 29.235% (10665/36480)\n",
      "Train Epoch: 0 | Loss: 1.902 | Acc: 29.264% (10713/36608)\n",
      "Train Epoch: 0 | Loss: 1.901 | Acc: 29.290% (10760/36736)\n",
      "Train Epoch: 0 | Loss: 1.900 | Acc: 29.327% (10811/36864)\n",
      "Train Epoch: 0 | Loss: 1.899 | Acc: 29.355% (10859/36992)\n",
      "Train Epoch: 0 | Loss: 1.899 | Acc: 29.364% (10900/37120)\n",
      "Train Epoch: 0 | Loss: 1.898 | Acc: 29.398% (10950/37248)\n",
      "Train Epoch: 0 | Loss: 1.898 | Acc: 29.444% (11005/37376)\n",
      "Train Epoch: 0 | Loss: 1.896 | Acc: 29.496% (11062/37504)\n",
      "Train Epoch: 0 | Loss: 1.895 | Acc: 29.528% (11112/37632)\n",
      "Train Epoch: 0 | Loss: 1.894 | Acc: 29.558% (11161/37760)\n",
      "Train Epoch: 0 | Loss: 1.893 | Acc: 29.587% (11210/37888)\n",
      "Train Epoch: 0 | Loss: 1.892 | Acc: 29.622% (11261/38016)\n",
      "Train Epoch: 0 | Loss: 1.891 | Acc: 29.677% (11320/38144)\n",
      "Train Epoch: 0 | Loss: 1.890 | Acc: 29.680% (11359/38272)\n",
      "Train Epoch: 0 | Loss: 1.890 | Acc: 29.706% (11407/38400)\n",
      "Train Epoch: 0 | Loss: 1.889 | Acc: 29.708% (11446/38528)\n",
      "Train Epoch: 0 | Loss: 1.888 | Acc: 29.765% (11506/38656)\n",
      "Train Epoch: 0 | Loss: 1.887 | Acc: 29.796% (11556/38784)\n",
      "Train Epoch: 0 | Loss: 1.887 | Acc: 29.811% (11600/38912)\n",
      "Train Epoch: 0 | Loss: 1.887 | Acc: 29.800% (11634/39040)\n",
      "Train Epoch: 0 | Loss: 1.886 | Acc: 29.820% (11680/39168)\n",
      "Train Epoch: 0 | Loss: 1.885 | Acc: 29.871% (11738/39296)\n",
      "Train Epoch: 0 | Loss: 1.884 | Acc: 29.928% (11799/39424)\n",
      "Train Epoch: 0 | Loss: 1.883 | Acc: 29.978% (11857/39552)\n",
      "Train Epoch: 0 | Loss: 1.882 | Acc: 30.018% (11911/39680)\n",
      "Train Epoch: 0 | Loss: 1.882 | Acc: 30.054% (11964/39808)\n",
      "Train Epoch: 0 | Loss: 1.880 | Acc: 30.106% (12023/39936)\n",
      "Train Epoch: 0 | Loss: 1.879 | Acc: 30.142% (12076/40064)\n",
      "Train Epoch: 0 | Loss: 1.878 | Acc: 30.183% (12131/40192)\n",
      "Train Epoch: 0 | Loss: 1.877 | Acc: 30.218% (12184/40320)\n",
      "Train Epoch: 0 | Loss: 1.876 | Acc: 30.264% (12241/40448)\n",
      "Train Epoch: 0 | Loss: 1.876 | Acc: 30.306% (12297/40576)\n",
      "Train Epoch: 0 | Loss: 1.875 | Acc: 30.351% (12354/40704)\n",
      "Train Epoch: 0 | Loss: 1.874 | Acc: 30.385% (12407/40832)\n",
      "Train Epoch: 0 | Loss: 1.873 | Acc: 30.427% (12463/40960)\n",
      "Train Epoch: 0 | Loss: 1.872 | Acc: 30.457% (12514/41088)\n",
      "Train Epoch: 0 | Loss: 1.871 | Acc: 30.503% (12572/41216)\n",
      "Train Epoch: 0 | Loss: 1.870 | Acc: 30.539% (12626/41344)\n",
      "Train Epoch: 0 | Loss: 1.868 | Acc: 30.601% (12691/41472)\n",
      "Train Epoch: 0 | Loss: 1.868 | Acc: 30.611% (12734/41600)\n",
      "Train Epoch: 0 | Loss: 1.868 | Acc: 30.632% (12782/41728)\n",
      "Train Epoch: 0 | Loss: 1.867 | Acc: 30.657% (12832/41856)\n",
      "Train Epoch: 0 | Loss: 1.866 | Acc: 30.700% (12889/41984)\n",
      "Train Epoch: 0 | Loss: 1.866 | Acc: 30.735% (12943/42112)\n",
      "Train Epoch: 0 | Loss: 1.865 | Acc: 30.753% (12990/42240)\n",
      "Train Epoch: 0 | Loss: 1.864 | Acc: 30.785% (13043/42368)\n",
      "Train Epoch: 0 | Loss: 1.863 | Acc: 30.801% (13089/42496)\n",
      "Train Epoch: 0 | Loss: 1.863 | Acc: 30.825% (13139/42624)\n",
      "Train Epoch: 0 | Loss: 1.862 | Acc: 30.864% (13195/42752)\n",
      "Train Epoch: 0 | Loss: 1.861 | Acc: 30.900% (13250/42880)\n",
      "Train Epoch: 0 | Loss: 1.861 | Acc: 30.920% (13298/43008)\n",
      "Train Epoch: 0 | Loss: 1.860 | Acc: 30.937% (13345/43136)\n",
      "Train Epoch: 0 | Loss: 1.859 | Acc: 30.991% (13408/43264)\n",
      "Train Epoch: 0 | Loss: 1.858 | Acc: 31.017% (13459/43392)\n",
      "Train Epoch: 0 | Loss: 1.857 | Acc: 31.039% (13508/43520)\n",
      "Train Epoch: 0 | Loss: 1.857 | Acc: 31.071% (13562/43648)\n",
      "Train Epoch: 0 | Loss: 1.856 | Acc: 31.108% (13618/43776)\n",
      "Train Epoch: 0 | Loss: 1.856 | Acc: 31.122% (13664/43904)\n",
      "Train Epoch: 0 | Loss: 1.855 | Acc: 31.146% (13714/44032)\n",
      "Train Epoch: 0 | Loss: 1.854 | Acc: 31.193% (13775/44160)\n",
      "Train Epoch: 0 | Loss: 1.853 | Acc: 31.243% (13837/44288)\n",
      "Train Epoch: 0 | Loss: 1.852 | Acc: 31.288% (13897/44416)\n",
      "Train Epoch: 0 | Loss: 1.852 | Acc: 31.317% (13950/44544)\n",
      "Train Epoch: 0 | Loss: 1.851 | Acc: 31.357% (14008/44672)\n",
      "Train Epoch: 0 | Loss: 1.850 | Acc: 31.386% (14061/44800)\n",
      "Train Epoch: 0 | Loss: 1.849 | Acc: 31.421% (14117/44928)\n",
      "Train Epoch: 0 | Loss: 1.848 | Acc: 31.456% (14173/45056)\n",
      "Train Epoch: 0 | Loss: 1.847 | Acc: 31.518% (14241/45184)\n",
      "Train Epoch: 0 | Loss: 1.846 | Acc: 31.544% (14293/45312)\n",
      "Train Epoch: 0 | Loss: 1.845 | Acc: 31.589% (14354/45440)\n",
      "Train Epoch: 0 | Loss: 1.844 | Acc: 31.621% (14409/45568)\n",
      "Train Epoch: 0 | Loss: 1.844 | Acc: 31.666% (14470/45696)\n",
      "Train Epoch: 0 | Loss: 1.843 | Acc: 31.702% (14527/45824)\n",
      "Train Epoch: 0 | Loss: 1.842 | Acc: 31.748% (14589/45952)\n",
      "Train Epoch: 0 | Loss: 1.841 | Acc: 31.780% (14644/46080)\n",
      "Train Epoch: 0 | Loss: 1.840 | Acc: 31.826% (14706/46208)\n",
      "Train Epoch: 0 | Loss: 1.839 | Acc: 31.872% (14768/46336)\n",
      "Train Epoch: 0 | Loss: 1.838 | Acc: 31.921% (14832/46464)\n",
      "Train Epoch: 0 | Loss: 1.837 | Acc: 31.984% (14902/46592)\n",
      "Train Epoch: 0 | Loss: 1.836 | Acc: 32.023% (14961/46720)\n",
      "Train Epoch: 0 | Loss: 1.836 | Acc: 32.053% (15016/46848)\n",
      "Train Epoch: 0 | Loss: 1.835 | Acc: 32.076% (15068/46976)\n",
      "Train Epoch: 0 | Loss: 1.834 | Acc: 32.118% (15129/47104)\n",
      "Train Epoch: 0 | Loss: 1.833 | Acc: 32.165% (15192/47232)\n",
      "Train Epoch: 0 | Loss: 1.833 | Acc: 32.190% (15245/47360)\n",
      "Train Epoch: 0 | Loss: 1.832 | Acc: 32.238% (15309/47488)\n",
      "Train Epoch: 0 | Loss: 1.831 | Acc: 32.285% (15373/47616)\n",
      "Train Epoch: 0 | Loss: 1.830 | Acc: 32.291% (15417/47744)\n",
      "Train Epoch: 0 | Loss: 1.830 | Acc: 32.328% (15476/47872)\n",
      "Train Epoch: 0 | Loss: 1.829 | Acc: 32.358% (15532/48000)\n",
      "Train Epoch: 0 | Loss: 1.828 | Acc: 32.376% (15582/48128)\n",
      "Train Epoch: 0 | Loss: 1.828 | Acc: 32.410% (15640/48256)\n",
      "Train Epoch: 0 | Loss: 1.827 | Acc: 32.459% (15705/48384)\n",
      "Train Epoch: 0 | Loss: 1.826 | Acc: 32.503% (15768/48512)\n",
      "Train Epoch: 0 | Loss: 1.825 | Acc: 32.547% (15831/48640)\n",
      "Train Epoch: 0 | Loss: 1.824 | Acc: 32.579% (15888/48768)\n",
      "Train Epoch: 0 | Loss: 1.824 | Acc: 32.612% (15946/48896)\n",
      "Train Epoch: 0 | Loss: 1.823 | Acc: 32.645% (16004/49024)\n",
      "Train Epoch: 0 | Loss: 1.823 | Acc: 32.672% (16059/49152)\n",
      "Train Epoch: 0 | Loss: 1.822 | Acc: 32.693% (16111/49280)\n",
      "Train Epoch: 0 | Loss: 1.821 | Acc: 32.725% (16169/49408)\n",
      "Train Epoch: 0 | Loss: 1.820 | Acc: 32.746% (16221/49536)\n",
      "Train Epoch: 0 | Loss: 1.820 | Acc: 32.784% (16282/49664)\n",
      "Train Epoch: 0 | Loss: 1.819 | Acc: 32.796% (16330/49792)\n",
      "Train Epoch: 0 | Loss: 1.818 | Acc: 32.847% (16397/49920)\n",
      "Train Epoch: 0 | Loss: 1.817 | Acc: 32.882% (16441/50000)\n",
      "Test Epoch: 0 | Loss: 1.339 | Acc: 54.000% (54/100)\n",
      "Test Epoch: 0 | Loss: 1.420 | Acc: 49.500% (99/200)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 50.000% (150/300)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.000% (200/400)\n",
      "Test Epoch: 0 | Loss: 1.378 | Acc: 50.200% (251/500)\n",
      "Test Epoch: 0 | Loss: 1.354 | Acc: 50.167% (301/600)\n",
      "Test Epoch: 0 | Loss: 1.348 | Acc: 50.714% (355/700)\n",
      "Test Epoch: 0 | Loss: 1.348 | Acc: 50.875% (407/800)\n",
      "Test Epoch: 0 | Loss: 1.346 | Acc: 50.889% (458/900)\n",
      "Test Epoch: 0 | Loss: 1.341 | Acc: 51.100% (511/1000)\n",
      "Test Epoch: 0 | Loss: 1.345 | Acc: 51.000% (561/1100)\n",
      "Test Epoch: 0 | Loss: 1.341 | Acc: 51.000% (612/1200)\n",
      "Test Epoch: 0 | Loss: 1.349 | Acc: 51.231% (666/1300)\n",
      "Test Epoch: 0 | Loss: 1.347 | Acc: 51.000% (714/1400)\n",
      "Test Epoch: 0 | Loss: 1.335 | Acc: 51.400% (771/1500)\n",
      "Test Epoch: 0 | Loss: 1.343 | Acc: 51.188% (819/1600)\n",
      "Test Epoch: 0 | Loss: 1.345 | Acc: 51.235% (871/1700)\n",
      "Test Epoch: 0 | Loss: 1.349 | Acc: 51.167% (921/1800)\n",
      "Test Epoch: 0 | Loss: 1.344 | Acc: 51.684% (982/1900)\n",
      "Test Epoch: 0 | Loss: 1.353 | Acc: 51.200% (1024/2000)\n",
      "Test Epoch: 0 | Loss: 1.350 | Acc: 51.333% (1078/2100)\n",
      "Test Epoch: 0 | Loss: 1.352 | Acc: 51.364% (1130/2200)\n",
      "Test Epoch: 0 | Loss: 1.353 | Acc: 51.304% (1180/2300)\n",
      "Test Epoch: 0 | Loss: 1.358 | Acc: 51.083% (1226/2400)\n",
      "Test Epoch: 0 | Loss: 1.354 | Acc: 51.360% (1284/2500)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.808% (1321/2600)\n",
      "Test Epoch: 0 | Loss: 1.372 | Acc: 50.704% (1369/2700)\n",
      "Test Epoch: 0 | Loss: 1.370 | Acc: 50.607% (1417/2800)\n",
      "Test Epoch: 0 | Loss: 1.375 | Acc: 50.483% (1464/2900)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.333% (1510/3000)\n",
      "Test Epoch: 0 | Loss: 1.370 | Acc: 50.484% (1565/3100)\n",
      "Test Epoch: 0 | Loss: 1.368 | Acc: 50.594% (1619/3200)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.667% (1672/3300)\n",
      "Test Epoch: 0 | Loss: 1.371 | Acc: 50.588% (1720/3400)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.486% (1767/3500)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.472% (1817/3600)\n",
      "Test Epoch: 0 | Loss: 1.377 | Acc: 50.324% (1862/3700)\n",
      "Test Epoch: 0 | Loss: 1.378 | Acc: 50.237% (1909/3800)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.359% (1964/3900)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.325% (2013/4000)\n",
      "Test Epoch: 0 | Loss: 1.377 | Acc: 50.293% (2062/4100)\n",
      "Test Epoch: 0 | Loss: 1.377 | Acc: 50.262% (2111/4200)\n",
      "Test Epoch: 0 | Loss: 1.373 | Acc: 50.465% (2170/4300)\n",
      "Test Epoch: 0 | Loss: 1.370 | Acc: 50.682% (2230/4400)\n",
      "Test Epoch: 0 | Loss: 1.372 | Acc: 50.756% (2284/4500)\n",
      "Test Epoch: 0 | Loss: 1.374 | Acc: 50.587% (2327/4600)\n",
      "Test Epoch: 0 | Loss: 1.372 | Acc: 50.638% (2380/4700)\n",
      "Test Epoch: 0 | Loss: 1.370 | Acc: 50.708% (2434/4800)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.673% (2483/4900)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.620% (2531/5000)\n",
      "Test Epoch: 0 | Loss: 1.369 | Acc: 50.706% (2586/5100)\n",
      "Test Epoch: 0 | Loss: 1.371 | Acc: 50.558% (2629/5200)\n",
      "Test Epoch: 0 | Loss: 1.372 | Acc: 50.491% (2676/5300)\n",
      "Test Epoch: 0 | Loss: 1.374 | Acc: 50.426% (2723/5400)\n",
      "Test Epoch: 0 | Loss: 1.376 | Acc: 50.364% (2770/5500)\n",
      "Test Epoch: 0 | Loss: 1.377 | Acc: 50.357% (2820/5600)\n",
      "Test Epoch: 0 | Loss: 1.378 | Acc: 50.421% (2874/5700)\n",
      "Test Epoch: 0 | Loss: 1.376 | Acc: 50.448% (2926/5800)\n",
      "Test Epoch: 0 | Loss: 1.377 | Acc: 50.390% (2973/5900)\n",
      "Test Epoch: 0 | Loss: 1.375 | Acc: 50.467% (3028/6000)\n",
      "Test Epoch: 0 | Loss: 1.378 | Acc: 50.311% (3069/6100)\n",
      "Test Epoch: 0 | Loss: 1.379 | Acc: 50.355% (3122/6200)\n",
      "Test Epoch: 0 | Loss: 1.380 | Acc: 50.333% (3171/6300)\n",
      "Test Epoch: 0 | Loss: 1.381 | Acc: 50.281% (3218/6400)\n",
      "Test Epoch: 0 | Loss: 1.383 | Acc: 50.215% (3264/6500)\n",
      "Test Epoch: 0 | Loss: 1.383 | Acc: 50.197% (3313/6600)\n",
      "Test Epoch: 0 | Loss: 1.384 | Acc: 50.090% (3356/6700)\n",
      "Test Epoch: 0 | Loss: 1.386 | Acc: 49.985% (3399/6800)\n",
      "Test Epoch: 0 | Loss: 1.388 | Acc: 49.884% (3442/6900)\n",
      "Test Epoch: 0 | Loss: 1.391 | Acc: 49.857% (3490/7000)\n",
      "Test Epoch: 0 | Loss: 1.391 | Acc: 49.789% (3535/7100)\n",
      "Test Epoch: 0 | Loss: 1.391 | Acc: 49.875% (3591/7200)\n",
      "Test Epoch: 0 | Loss: 1.388 | Acc: 49.904% (3643/7300)\n",
      "Test Epoch: 0 | Loss: 1.385 | Acc: 49.973% (3698/7400)\n",
      "Test Epoch: 0 | Loss: 1.386 | Acc: 50.013% (3751/7500)\n",
      "Test Epoch: 0 | Loss: 1.385 | Acc: 49.974% (3798/7600)\n",
      "Test Epoch: 0 | Loss: 1.386 | Acc: 49.870% (3840/7700)\n",
      "Test Epoch: 0 | Loss: 1.384 | Acc: 49.897% (3892/7800)\n",
      "Test Epoch: 0 | Loss: 1.385 | Acc: 49.835% (3937/7900)\n",
      "Test Epoch: 0 | Loss: 1.384 | Acc: 49.788% (3983/8000)\n",
      "Test Epoch: 0 | Loss: 1.384 | Acc: 49.901% (4042/8100)\n",
      "Test Epoch: 0 | Loss: 1.384 | Acc: 49.951% (4096/8200)\n",
      "Test Epoch: 0 | Loss: 1.386 | Acc: 49.880% (4140/8300)\n",
      "Test Epoch: 0 | Loss: 1.387 | Acc: 49.833% (4186/8400)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.718% (4226/8500)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.767% (4280/8600)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.747% (4328/8700)\n",
      "Test Epoch: 0 | Loss: 1.389 | Acc: 49.807% (4383/8800)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.809% (4433/8900)\n",
      "Test Epoch: 0 | Loss: 1.391 | Acc: 49.744% (4477/9000)\n",
      "Test Epoch: 0 | Loss: 1.392 | Acc: 49.615% (4515/9100)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.652% (4568/9200)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.731% (4625/9300)\n",
      "Test Epoch: 0 | Loss: 1.389 | Acc: 49.745% (4676/9400)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.663% (4718/9500)\n",
      "Test Epoch: 0 | Loss: 1.390 | Acc: 49.667% (4768/9600)\n",
      "Test Epoch: 0 | Loss: 1.389 | Acc: 49.660% (4817/9700)\n",
      "Test Epoch: 0 | Loss: 1.389 | Acc: 49.633% (4864/9800)\n",
      "Test Epoch: 0 | Loss: 1.388 | Acc: 49.626% (4913/9900)\n",
      "Test Epoch: 0 | Loss: 1.388 | Acc: 49.610% (4961/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Epoch: 1 | Loss: 1.406 | Acc: 46.875% (60/128)\n",
      "Train Epoch: 1 | Loss: 1.515 | Acc: 44.922% (115/256)\n",
      "Train Epoch: 1 | Loss: 1.535 | Acc: 44.271% (170/384)\n",
      "Train Epoch: 1 | Loss: 1.498 | Acc: 47.070% (241/512)\n",
      "Train Epoch: 1 | Loss: 1.508 | Acc: 44.844% (287/640)\n",
      "Train Epoch: 1 | Loss: 1.521 | Acc: 43.880% (337/768)\n",
      "Train Epoch: 1 | Loss: 1.521 | Acc: 43.973% (394/896)\n",
      "Train Epoch: 1 | Loss: 1.513 | Acc: 44.922% (460/1024)\n",
      "Train Epoch: 1 | Loss: 1.526 | Acc: 44.444% (512/1152)\n",
      "Train Epoch: 1 | Loss: 1.529 | Acc: 44.453% (569/1280)\n",
      "Train Epoch: 1 | Loss: 1.531 | Acc: 44.673% (629/1408)\n",
      "Train Epoch: 1 | Loss: 1.532 | Acc: 44.336% (681/1536)\n",
      "Train Epoch: 1 | Loss: 1.543 | Acc: 43.570% (725/1664)\n",
      "Train Epoch: 1 | Loss: 1.540 | Acc: 43.694% (783/1792)\n",
      "Train Epoch: 1 | Loss: 1.548 | Acc: 43.281% (831/1920)\n",
      "Train Epoch: 1 | Loss: 1.553 | Acc: 43.066% (882/2048)\n",
      "Train Epoch: 1 | Loss: 1.547 | Acc: 43.566% (948/2176)\n",
      "Train Epoch: 1 | Loss: 1.546 | Acc: 43.359% (999/2304)\n",
      "Train Epoch: 1 | Loss: 1.553 | Acc: 43.051% (1047/2432)\n",
      "Train Epoch: 1 | Loss: 1.546 | Acc: 43.477% (1113/2560)\n",
      "Train Epoch: 1 | Loss: 1.544 | Acc: 43.564% (1171/2688)\n",
      "Train Epoch: 1 | Loss: 1.538 | Acc: 43.643% (1229/2816)\n",
      "Train Epoch: 1 | Loss: 1.538 | Acc: 43.784% (1289/2944)\n",
      "Train Epoch: 1 | Loss: 1.541 | Acc: 43.685% (1342/3072)\n",
      "Train Epoch: 1 | Loss: 1.541 | Acc: 43.844% (1403/3200)\n",
      "Train Epoch: 1 | Loss: 1.537 | Acc: 44.020% (1465/3328)\n",
      "Train Epoch: 1 | Loss: 1.534 | Acc: 44.010% (1521/3456)\n",
      "Train Epoch: 1 | Loss: 1.530 | Acc: 44.141% (1582/3584)\n",
      "Train Epoch: 1 | Loss: 1.528 | Acc: 44.289% (1644/3712)\n",
      "Train Epoch: 1 | Loss: 1.524 | Acc: 44.427% (1706/3840)\n",
      "Train Epoch: 1 | Loss: 1.520 | Acc: 44.657% (1772/3968)\n",
      "Train Epoch: 1 | Loss: 1.519 | Acc: 44.751% (1833/4096)\n",
      "Train Epoch: 1 | Loss: 1.515 | Acc: 44.910% (1897/4224)\n",
      "Train Epoch: 1 | Loss: 1.511 | Acc: 45.014% (1959/4352)\n",
      "Train Epoch: 1 | Loss: 1.514 | Acc: 44.933% (2013/4480)\n",
      "Train Epoch: 1 | Loss: 1.514 | Acc: 45.030% (2075/4608)\n",
      "Train Epoch: 1 | Loss: 1.514 | Acc: 44.911% (2127/4736)\n",
      "Train Epoch: 1 | Loss: 1.515 | Acc: 44.922% (2185/4864)\n",
      "Train Epoch: 1 | Loss: 1.512 | Acc: 45.292% (2261/4992)\n",
      "Train Epoch: 1 | Loss: 1.513 | Acc: 45.117% (2310/5120)\n",
      "Train Epoch: 1 | Loss: 1.512 | Acc: 45.179% (2371/5248)\n",
      "Train Epoch: 1 | Loss: 1.510 | Acc: 45.238% (2432/5376)\n",
      "Train Epoch: 1 | Loss: 1.511 | Acc: 45.240% (2490/5504)\n",
      "Train Epoch: 1 | Loss: 1.510 | Acc: 45.170% (2544/5632)\n",
      "Train Epoch: 1 | Loss: 1.506 | Acc: 45.260% (2607/5760)\n",
      "Train Epoch: 1 | Loss: 1.502 | Acc: 45.465% (2677/5888)\n",
      "Train Epoch: 1 | Loss: 1.499 | Acc: 45.595% (2743/6016)\n",
      "Train Epoch: 1 | Loss: 1.498 | Acc: 45.638% (2804/6144)\n",
      "Train Epoch: 1 | Loss: 1.495 | Acc: 45.663% (2864/6272)\n",
      "Train Epoch: 1 | Loss: 1.494 | Acc: 45.719% (2926/6400)\n",
      "Train Epoch: 1 | Loss: 1.493 | Acc: 45.772% (2988/6528)\n",
      "Train Epoch: 1 | Loss: 1.497 | Acc: 45.703% (3042/6656)\n",
      "Train Epoch: 1 | Loss: 1.497 | Acc: 45.681% (3099/6784)\n",
      "Train Epoch: 1 | Loss: 1.499 | Acc: 45.587% (3151/6912)\n",
      "Train Epoch: 1 | Loss: 1.501 | Acc: 45.540% (3206/7040)\n",
      "Train Epoch: 1 | Loss: 1.500 | Acc: 45.536% (3264/7168)\n",
      "Train Epoch: 1 | Loss: 1.500 | Acc: 45.532% (3322/7296)\n",
      "Train Epoch: 1 | Loss: 1.497 | Acc: 45.555% (3382/7424)\n",
      "Train Epoch: 1 | Loss: 1.496 | Acc: 45.644% (3447/7552)\n",
      "Train Epoch: 1 | Loss: 1.494 | Acc: 45.638% (3505/7680)\n",
      "Train Epoch: 1 | Loss: 1.496 | Acc: 45.684% (3567/7808)\n",
      "Train Epoch: 1 | Loss: 1.495 | Acc: 45.766% (3632/7936)\n",
      "Train Epoch: 1 | Loss: 1.496 | Acc: 45.796% (3693/8064)\n",
      "Train Epoch: 1 | Loss: 1.494 | Acc: 45.825% (3754/8192)\n",
      "Train Epoch: 1 | Loss: 1.494 | Acc: 45.841% (3814/8320)\n",
      "Train Epoch: 1 | Loss: 1.490 | Acc: 45.904% (3878/8448)\n",
      "Train Epoch: 1 | Loss: 1.491 | Acc: 45.954% (3941/8576)\n",
      "Train Epoch: 1 | Loss: 1.494 | Acc: 45.852% (3991/8704)\n",
      "Train Epoch: 1 | Loss: 1.495 | Acc: 45.799% (4045/8832)\n",
      "Train Epoch: 1 | Loss: 1.495 | Acc: 45.837% (4107/8960)\n",
      "Train Epoch: 1 | Loss: 1.493 | Acc: 45.907% (4172/9088)\n",
      "Train Epoch: 1 | Loss: 1.489 | Acc: 46.126% (4251/9216)\n",
      "Train Epoch: 1 | Loss: 1.489 | Acc: 46.126% (4310/9344)\n",
      "Train Epoch: 1 | Loss: 1.487 | Acc: 46.115% (4368/9472)\n",
      "Train Epoch: 1 | Loss: 1.485 | Acc: 46.219% (4437/9600)\n",
      "Train Epoch: 1 | Loss: 1.483 | Acc: 46.289% (4503/9728)\n",
      "Train Epoch: 1 | Loss: 1.482 | Acc: 46.297% (4563/9856)\n",
      "Train Epoch: 1 | Loss: 1.479 | Acc: 46.414% (4634/9984)\n",
      "Train Epoch: 1 | Loss: 1.478 | Acc: 46.470% (4699/10112)\n",
      "Train Epoch: 1 | Loss: 1.477 | Acc: 46.484% (4760/10240)\n",
      "Train Epoch: 1 | Loss: 1.477 | Acc: 46.499% (4821/10368)\n",
      "Train Epoch: 1 | Loss: 1.478 | Acc: 46.399% (4870/10496)\n",
      "Train Epoch: 1 | Loss: 1.477 | Acc: 46.376% (4927/10624)\n",
      "Train Epoch: 1 | Loss: 1.476 | Acc: 46.466% (4996/10752)\n",
      "Train Epoch: 1 | Loss: 1.475 | Acc: 46.498% (5059/10880)\n",
      "Train Epoch: 1 | Loss: 1.474 | Acc: 46.521% (5121/11008)\n",
      "Train Epoch: 1 | Loss: 1.471 | Acc: 46.624% (5192/11136)\n",
      "Train Epoch: 1 | Loss: 1.472 | Acc: 46.644% (5254/11264)\n",
      "Train Epoch: 1 | Loss: 1.471 | Acc: 46.691% (5319/11392)\n",
      "Train Epoch: 1 | Loss: 1.470 | Acc: 46.675% (5377/11520)\n",
      "Train Epoch: 1 | Loss: 1.470 | Acc: 46.729% (5443/11648)\n",
      "Train Epoch: 1 | Loss: 1.471 | Acc: 46.714% (5501/11776)\n",
      "Train Epoch: 1 | Loss: 1.469 | Acc: 46.783% (5569/11904)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.784% (5629/12032)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.883% (5701/12160)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.899% (5763/12288)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.915% (5825/12416)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.947% (5889/12544)\n",
      "Train Epoch: 1 | Loss: 1.467 | Acc: 47.001% (5956/12672)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.930% (6007/12800)\n",
      "Train Epoch: 1 | Loss: 1.468 | Acc: 46.890% (6062/12928)\n",
      "Train Epoch: 1 | Loss: 1.467 | Acc: 46.921% (6126/13056)\n",
      "Train Epoch: 1 | Loss: 1.464 | Acc: 47.012% (6198/13184)\n",
      "Train Epoch: 1 | Loss: 1.463 | Acc: 47.040% (6262/13312)\n",
      "Train Epoch: 1 | Loss: 1.463 | Acc: 47.046% (6323/13440)\n",
      "Train Epoch: 1 | Loss: 1.463 | Acc: 47.067% (6386/13568)\n",
      "Train Epoch: 1 | Loss: 1.462 | Acc: 47.087% (6449/13696)\n",
      "Train Epoch: 1 | Loss: 1.461 | Acc: 47.143% (6517/13824)\n",
      "Train Epoch: 1 | Loss: 1.459 | Acc: 47.162% (6580/13952)\n",
      "Train Epoch: 1 | Loss: 1.459 | Acc: 47.180% (6643/14080)\n",
      "Train Epoch: 1 | Loss: 1.459 | Acc: 47.164% (6701/14208)\n",
      "Train Epoch: 1 | Loss: 1.460 | Acc: 47.119% (6755/14336)\n",
      "Train Epoch: 1 | Loss: 1.459 | Acc: 47.124% (6816/14464)\n",
      "Train Epoch: 1 | Loss: 1.460 | Acc: 47.129% (6877/14592)\n",
      "Train Epoch: 1 | Loss: 1.460 | Acc: 47.086% (6931/14720)\n",
      "Train Epoch: 1 | Loss: 1.458 | Acc: 47.151% (7001/14848)\n",
      "Train Epoch: 1 | Loss: 1.457 | Acc: 47.229% (7073/14976)\n",
      "Train Epoch: 1 | Loss: 1.457 | Acc: 47.239% (7135/15104)\n",
      "Train Epoch: 1 | Loss: 1.455 | Acc: 47.256% (7198/15232)\n",
      "Train Epoch: 1 | Loss: 1.456 | Acc: 47.194% (7249/15360)\n",
      "Train Epoch: 1 | Loss: 1.455 | Acc: 47.243% (7317/15488)\n",
      "Train Epoch: 1 | Loss: 1.455 | Acc: 47.227% (7375/15616)\n",
      "Train Epoch: 1 | Loss: 1.454 | Acc: 47.237% (7437/15744)\n",
      "Train Epoch: 1 | Loss: 1.453 | Acc: 47.266% (7502/15872)\n",
      "Train Epoch: 1 | Loss: 1.452 | Acc: 47.312% (7570/16000)\n",
      "Train Epoch: 1 | Loss: 1.452 | Acc: 47.284% (7626/16128)\n",
      "Train Epoch: 1 | Loss: 1.453 | Acc: 47.244% (7680/16256)\n",
      "Train Epoch: 1 | Loss: 1.453 | Acc: 47.229% (7738/16384)\n",
      "Train Epoch: 1 | Loss: 1.452 | Acc: 47.244% (7801/16512)\n",
      "Train Epoch: 1 | Loss: 1.451 | Acc: 47.278% (7867/16640)\n",
      "Train Epoch: 1 | Loss: 1.450 | Acc: 47.310% (7933/16768)\n",
      "Train Epoch: 1 | Loss: 1.450 | Acc: 47.319% (7995/16896)\n",
      "Train Epoch: 1 | Loss: 1.449 | Acc: 47.357% (8062/17024)\n",
      "Train Epoch: 1 | Loss: 1.449 | Acc: 47.336% (8119/17152)\n",
      "Train Epoch: 1 | Loss: 1.448 | Acc: 47.402% (8191/17280)\n",
      "Train Epoch: 1 | Loss: 1.447 | Acc: 47.455% (8261/17408)\n",
      "Train Epoch: 1 | Loss: 1.446 | Acc: 47.491% (8328/17536)\n",
      "Train Epoch: 1 | Loss: 1.445 | Acc: 47.543% (8398/17664)\n",
      "Train Epoch: 1 | Loss: 1.445 | Acc: 47.499% (8451/17792)\n",
      "Train Epoch: 1 | Loss: 1.445 | Acc: 47.483% (8509/17920)\n",
      "Train Epoch: 1 | Loss: 1.444 | Acc: 47.534% (8579/18048)\n",
      "Train Epoch: 1 | Loss: 1.445 | Acc: 47.508% (8635/18176)\n",
      "Train Epoch: 1 | Loss: 1.444 | Acc: 47.542% (8702/18304)\n",
      "Train Epoch: 1 | Loss: 1.443 | Acc: 47.586% (8771/18432)\n",
      "Train Epoch: 1 | Loss: 1.441 | Acc: 47.608% (8836/18560)\n",
      "Train Epoch: 1 | Loss: 1.441 | Acc: 47.635% (8902/18688)\n",
      "Train Epoch: 1 | Loss: 1.440 | Acc: 47.630% (8962/18816)\n",
      "Train Epoch: 1 | Loss: 1.440 | Acc: 47.630% (9023/18944)\n",
      "Train Epoch: 1 | Loss: 1.440 | Acc: 47.630% (9084/19072)\n",
      "Train Epoch: 1 | Loss: 1.439 | Acc: 47.661% (9151/19200)\n",
      "Train Epoch: 1 | Loss: 1.439 | Acc: 47.703% (9220/19328)\n",
      "Train Epoch: 1 | Loss: 1.438 | Acc: 47.744% (9289/19456)\n",
      "Train Epoch: 1 | Loss: 1.438 | Acc: 47.763% (9354/19584)\n",
      "Train Epoch: 1 | Loss: 1.439 | Acc: 47.783% (9419/19712)\n",
      "Train Epoch: 1 | Loss: 1.438 | Acc: 47.802% (9484/19840)\n",
      "Train Epoch: 1 | Loss: 1.438 | Acc: 47.827% (9550/19968)\n",
      "Train Epoch: 1 | Loss: 1.438 | Acc: 47.825% (9611/20096)\n",
      "Train Epoch: 1 | Loss: 1.437 | Acc: 47.879% (9683/20224)\n",
      "Train Epoch: 1 | Loss: 1.437 | Acc: 47.882% (9745/20352)\n",
      "Train Epoch: 1 | Loss: 1.437 | Acc: 47.920% (9814/20480)\n",
      "Train Epoch: 1 | Loss: 1.436 | Acc: 47.962% (9884/20608)\n",
      "Train Epoch: 1 | Loss: 1.436 | Acc: 47.984% (9950/20736)\n",
      "Train Epoch: 1 | Loss: 1.436 | Acc: 47.953% (10005/20864)\n",
      "Train Epoch: 1 | Loss: 1.435 | Acc: 47.975% (10071/20992)\n",
      "Train Epoch: 1 | Loss: 1.435 | Acc: 47.969% (10131/21120)\n",
      "Train Epoch: 1 | Loss: 1.435 | Acc: 47.981% (10195/21248)\n",
      "Train Epoch: 1 | Loss: 1.434 | Acc: 48.021% (10265/21376)\n",
      "Train Epoch: 1 | Loss: 1.433 | Acc: 48.056% (10334/21504)\n",
      "Train Epoch: 1 | Loss: 1.432 | Acc: 48.068% (10398/21632)\n",
      "Train Epoch: 1 | Loss: 1.431 | Acc: 48.120% (10471/21760)\n",
      "Train Epoch: 1 | Loss: 1.431 | Acc: 48.131% (10535/21888)\n",
      "Train Epoch: 1 | Loss: 1.430 | Acc: 48.160% (10603/22016)\n",
      "Train Epoch: 1 | Loss: 1.429 | Acc: 48.225% (10679/22144)\n",
      "Train Epoch: 1 | Loss: 1.429 | Acc: 48.217% (10739/22272)\n",
      "Train Epoch: 1 | Loss: 1.429 | Acc: 48.246% (10807/22400)\n",
      "Train Epoch: 1 | Loss: 1.428 | Acc: 48.256% (10871/22528)\n",
      "Train Epoch: 1 | Loss: 1.426 | Acc: 48.301% (10943/22656)\n",
      "Train Epoch: 1 | Loss: 1.426 | Acc: 48.328% (11011/22784)\n",
      "Train Epoch: 1 | Loss: 1.425 | Acc: 48.341% (11076/22912)\n",
      "Train Epoch: 1 | Loss: 1.425 | Acc: 48.325% (11134/23040)\n",
      "Train Epoch: 1 | Loss: 1.425 | Acc: 48.360% (11204/23168)\n",
      "Train Epoch: 1 | Loss: 1.424 | Acc: 48.386% (11272/23296)\n",
      "Train Epoch: 1 | Loss: 1.424 | Acc: 48.399% (11337/23424)\n",
      "Train Epoch: 1 | Loss: 1.424 | Acc: 48.442% (11409/23552)\n",
      "Train Epoch: 1 | Loss: 1.423 | Acc: 48.480% (11480/23680)\n",
      "Train Epoch: 1 | Loss: 1.423 | Acc: 48.505% (11548/23808)\n",
      "Train Epoch: 1 | Loss: 1.423 | Acc: 48.504% (11610/23936)\n",
      "Train Epoch: 1 | Loss: 1.423 | Acc: 48.487% (11668/24064)\n",
      "Train Epoch: 1 | Loss: 1.422 | Acc: 48.504% (11734/24192)\n",
      "Train Epoch: 1 | Loss: 1.421 | Acc: 48.536% (11804/24320)\n",
      "Train Epoch: 1 | Loss: 1.421 | Acc: 48.548% (11869/24448)\n",
      "Train Epoch: 1 | Loss: 1.421 | Acc: 48.576% (11938/24576)\n",
      "Train Epoch: 1 | Loss: 1.420 | Acc: 48.628% (12013/24704)\n",
      "Train Epoch: 1 | Loss: 1.420 | Acc: 48.655% (12082/24832)\n",
      "Train Epoch: 1 | Loss: 1.420 | Acc: 48.670% (12148/24960)\n",
      "Train Epoch: 1 | Loss: 1.419 | Acc: 48.705% (12219/25088)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.771% (12298/25216)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.793% (12366/25344)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.818% (12435/25472)\n",
      "Train Epoch: 1 | Loss: 1.419 | Acc: 48.816% (12497/25600)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.815% (12559/25728)\n",
      "Train Epoch: 1 | Loss: 1.419 | Acc: 48.805% (12619/25856)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.807% (12682/25984)\n",
      "Train Epoch: 1 | Loss: 1.418 | Acc: 48.843% (12754/26112)\n",
      "Train Epoch: 1 | Loss: 1.417 | Acc: 48.887% (12828/26240)\n",
      "Train Epoch: 1 | Loss: 1.417 | Acc: 48.881% (12889/26368)\n",
      "Train Epoch: 1 | Loss: 1.416 | Acc: 48.913% (12960/26496)\n",
      "Train Epoch: 1 | Loss: 1.415 | Acc: 48.907% (13021/26624)\n",
      "Train Epoch: 1 | Loss: 1.415 | Acc: 48.916% (13086/26752)\n",
      "Train Epoch: 1 | Loss: 1.414 | Acc: 48.951% (13158/26880)\n",
      "Train Epoch: 1 | Loss: 1.414 | Acc: 48.934% (13216/27008)\n",
      "Train Epoch: 1 | Loss: 1.415 | Acc: 48.924% (13276/27136)\n",
      "Train Epoch: 1 | Loss: 1.414 | Acc: 48.933% (13341/27264)\n",
      "Train Epoch: 1 | Loss: 1.414 | Acc: 48.963% (13412/27392)\n",
      "Train Epoch: 1 | Loss: 1.414 | Acc: 48.986% (13481/27520)\n",
      "Train Epoch: 1 | Loss: 1.413 | Acc: 49.013% (13551/27648)\n",
      "Train Epoch: 1 | Loss: 1.412 | Acc: 49.068% (13629/27776)\n",
      "Train Epoch: 1 | Loss: 1.411 | Acc: 49.079% (13695/27904)\n",
      "Train Epoch: 1 | Loss: 1.411 | Acc: 49.069% (13755/28032)\n",
      "Train Epoch: 1 | Loss: 1.410 | Acc: 49.116% (13831/28160)\n",
      "Train Epoch: 1 | Loss: 1.410 | Acc: 49.137% (13900/28288)\n",
      "Train Epoch: 1 | Loss: 1.409 | Acc: 49.159% (13969/28416)\n",
      "Train Epoch: 1 | Loss: 1.408 | Acc: 49.184% (14039/28544)\n",
      "Train Epoch: 1 | Loss: 1.408 | Acc: 49.184% (14102/28672)\n",
      "Train Epoch: 1 | Loss: 1.408 | Acc: 49.188% (14166/28800)\n",
      "Train Epoch: 1 | Loss: 1.408 | Acc: 49.174% (14225/28928)\n",
      "Train Epoch: 1 | Loss: 1.407 | Acc: 49.188% (14292/29056)\n",
      "Train Epoch: 1 | Loss: 1.406 | Acc: 49.232% (14368/29184)\n",
      "Train Epoch: 1 | Loss: 1.406 | Acc: 49.249% (14436/29312)\n",
      "Train Epoch: 1 | Loss: 1.406 | Acc: 49.266% (14504/29440)\n",
      "Train Epoch: 1 | Loss: 1.404 | Acc: 49.327% (14585/29568)\n",
      "Train Epoch: 1 | Loss: 1.404 | Acc: 49.350% (14655/29696)\n",
      "Train Epoch: 1 | Loss: 1.403 | Acc: 49.376% (14726/29824)\n",
      "Train Epoch: 1 | Loss: 1.402 | Acc: 49.412% (14800/29952)\n",
      "Train Epoch: 1 | Loss: 1.401 | Acc: 49.458% (14877/30080)\n",
      "Train Epoch: 1 | Loss: 1.401 | Acc: 49.484% (14948/30208)\n",
      "Train Epoch: 1 | Loss: 1.400 | Acc: 49.506% (15018/30336)\n",
      "Train Epoch: 1 | Loss: 1.400 | Acc: 49.537% (15091/30464)\n",
      "Train Epoch: 1 | Loss: 1.400 | Acc: 49.529% (15152/30592)\n",
      "Train Epoch: 1 | Loss: 1.400 | Acc: 49.521% (15213/30720)\n",
      "Train Epoch: 1 | Loss: 1.400 | Acc: 49.520% (15276/30848)\n",
      "Train Epoch: 1 | Loss: 1.399 | Acc: 49.574% (15356/30976)\n",
      "Train Epoch: 1 | Loss: 1.398 | Acc: 49.588% (15424/31104)\n",
      "Train Epoch: 1 | Loss: 1.398 | Acc: 49.616% (15496/31232)\n",
      "Train Epoch: 1 | Loss: 1.397 | Acc: 49.649% (15570/31360)\n",
      "Train Epoch: 1 | Loss: 1.396 | Acc: 49.695% (15648/31488)\n",
      "Train Epoch: 1 | Loss: 1.395 | Acc: 49.728% (15722/31616)\n",
      "Train Epoch: 1 | Loss: 1.395 | Acc: 49.776% (15801/31744)\n",
      "Train Epoch: 1 | Loss: 1.394 | Acc: 49.777% (15865/31872)\n",
      "Train Epoch: 1 | Loss: 1.394 | Acc: 49.816% (15941/32000)\n",
      "Train Epoch: 1 | Loss: 1.393 | Acc: 49.835% (16011/32128)\n",
      "Train Epoch: 1 | Loss: 1.393 | Acc: 49.833% (16074/32256)\n",
      "Train Epoch: 1 | Loss: 1.392 | Acc: 49.843% (16141/32384)\n",
      "Train Epoch: 1 | Loss: 1.392 | Acc: 49.862% (16211/32512)\n",
      "Train Epoch: 1 | Loss: 1.391 | Acc: 49.865% (16276/32640)\n",
      "Train Epoch: 1 | Loss: 1.391 | Acc: 49.869% (16341/32768)\n",
      "Train Epoch: 1 | Loss: 1.390 | Acc: 49.900% (16415/32896)\n",
      "Train Epoch: 1 | Loss: 1.390 | Acc: 49.930% (16489/33024)\n",
      "Train Epoch: 1 | Loss: 1.390 | Acc: 49.900% (16543/33152)\n",
      "Train Epoch: 1 | Loss: 1.389 | Acc: 49.946% (16622/33280)\n",
      "Train Epoch: 1 | Loss: 1.389 | Acc: 49.928% (16680/33408)\n",
      "Train Epoch: 1 | Loss: 1.389 | Acc: 49.946% (16750/33536)\n",
      "Train Epoch: 1 | Loss: 1.389 | Acc: 49.947% (16814/33664)\n",
      "Train Epoch: 1 | Loss: 1.389 | Acc: 49.973% (16887/33792)\n",
      "Train Epoch: 1 | Loss: 1.388 | Acc: 49.988% (16956/33920)\n",
      "Train Epoch: 1 | Loss: 1.387 | Acc: 50.012% (17028/34048)\n",
      "Train Epoch: 1 | Loss: 1.387 | Acc: 50.018% (17094/34176)\n",
      "Train Epoch: 1 | Loss: 1.387 | Acc: 50.050% (17169/34304)\n",
      "Train Epoch: 1 | Loss: 1.387 | Acc: 50.064% (17238/34432)\n",
      "Train Epoch: 1 | Loss: 1.386 | Acc: 50.078% (17307/34560)\n",
      "Train Epoch: 1 | Loss: 1.386 | Acc: 50.063% (17366/34688)\n",
      "Train Epoch: 1 | Loss: 1.385 | Acc: 50.115% (17448/34816)\n",
      "Train Epoch: 1 | Loss: 1.385 | Acc: 50.132% (17518/34944)\n",
      "Train Epoch: 1 | Loss: 1.384 | Acc: 50.145% (17587/35072)\n",
      "Train Epoch: 1 | Loss: 1.383 | Acc: 50.190% (17667/35200)\n",
      "Train Epoch: 1 | Loss: 1.383 | Acc: 50.175% (17726/35328)\n",
      "Train Epoch: 1 | Loss: 1.383 | Acc: 50.169% (17788/35456)\n",
      "Train Epoch: 1 | Loss: 1.383 | Acc: 50.174% (17854/35584)\n",
      "Train Epoch: 1 | Loss: 1.383 | Acc: 50.176% (17919/35712)\n",
      "Train Epoch: 1 | Loss: 1.382 | Acc: 50.209% (17995/35840)\n",
      "Train Epoch: 1 | Loss: 1.381 | Acc: 50.211% (18060/35968)\n",
      "Train Epoch: 1 | Loss: 1.381 | Acc: 50.235% (18133/36096)\n",
      "Train Epoch: 1 | Loss: 1.380 | Acc: 50.271% (18210/36224)\n",
      "Train Epoch: 1 | Loss: 1.380 | Acc: 50.267% (18273/36352)\n",
      "Train Epoch: 1 | Loss: 1.379 | Acc: 50.269% (18338/36480)\n",
      "Train Epoch: 1 | Loss: 1.379 | Acc: 50.279% (18406/36608)\n",
      "Train Epoch: 1 | Loss: 1.379 | Acc: 50.286% (18473/36736)\n",
      "Train Epoch: 1 | Loss: 1.378 | Acc: 50.304% (18544/36864)\n",
      "Train Epoch: 1 | Loss: 1.378 | Acc: 50.324% (18616/36992)\n",
      "Train Epoch: 1 | Loss: 1.377 | Acc: 50.353% (18691/37120)\n",
      "Train Epoch: 1 | Loss: 1.376 | Acc: 50.389% (18769/37248)\n",
      "Train Epoch: 1 | Loss: 1.376 | Acc: 50.412% (18842/37376)\n",
      "Train Epoch: 1 | Loss: 1.376 | Acc: 50.416% (18908/37504)\n",
      "Train Epoch: 1 | Loss: 1.376 | Acc: 50.438% (18981/37632)\n",
      "Train Epoch: 1 | Loss: 1.376 | Acc: 50.463% (19055/37760)\n",
      "Train Epoch: 1 | Loss: 1.375 | Acc: 50.515% (19139/37888)\n",
      "Train Epoch: 1 | Loss: 1.374 | Acc: 50.547% (19216/38016)\n",
      "Train Epoch: 1 | Loss: 1.374 | Acc: 50.574% (19291/38144)\n",
      "Train Epoch: 1 | Loss: 1.373 | Acc: 50.617% (19372/38272)\n",
      "Train Epoch: 1 | Loss: 1.373 | Acc: 50.659% (19453/38400)\n",
      "Train Epoch: 1 | Loss: 1.372 | Acc: 50.688% (19529/38528)\n",
      "Train Epoch: 1 | Loss: 1.372 | Acc: 50.696% (19597/38656)\n",
      "Train Epoch: 1 | Loss: 1.371 | Acc: 50.725% (19673/38784)\n",
      "Train Epoch: 1 | Loss: 1.370 | Acc: 50.750% (19748/38912)\n",
      "Train Epoch: 1 | Loss: 1.370 | Acc: 50.761% (19817/39040)\n",
      "Train Epoch: 1 | Loss: 1.370 | Acc: 50.779% (19889/39168)\n",
      "Train Epoch: 1 | Loss: 1.369 | Acc: 50.802% (19963/39296)\n",
      "Train Epoch: 1 | Loss: 1.369 | Acc: 50.829% (20039/39424)\n",
      "Train Epoch: 1 | Loss: 1.368 | Acc: 50.832% (20105/39552)\n",
      "Train Epoch: 1 | Loss: 1.368 | Acc: 50.837% (20172/39680)\n",
      "Train Epoch: 1 | Loss: 1.368 | Acc: 50.857% (20245/39808)\n",
      "Train Epoch: 1 | Loss: 1.368 | Acc: 50.856% (20310/39936)\n",
      "Train Epoch: 1 | Loss: 1.367 | Acc: 50.891% (20389/40064)\n",
      "Train Epoch: 1 | Loss: 1.367 | Acc: 50.906% (20460/40192)\n",
      "Train Epoch: 1 | Loss: 1.367 | Acc: 50.915% (20529/40320)\n",
      "Train Epoch: 1 | Loss: 1.366 | Acc: 50.927% (20599/40448)\n",
      "Train Epoch: 1 | Loss: 1.366 | Acc: 50.922% (20662/40576)\n",
      "Train Epoch: 1 | Loss: 1.367 | Acc: 50.934% (20732/40704)\n",
      "Train Epoch: 1 | Loss: 1.366 | Acc: 50.936% (20798/40832)\n",
      "Train Epoch: 1 | Loss: 1.366 | Acc: 50.967% (20876/40960)\n",
      "Train Epoch: 1 | Loss: 1.365 | Acc: 51.005% (20957/41088)\n",
      "Train Epoch: 1 | Loss: 1.365 | Acc: 51.007% (21023/41216)\n",
      "Train Epoch: 1 | Loss: 1.365 | Acc: 51.023% (21095/41344)\n",
      "Train Epoch: 1 | Loss: 1.364 | Acc: 51.049% (21171/41472)\n",
      "Train Epoch: 1 | Loss: 1.363 | Acc: 51.070% (21245/41600)\n",
      "Train Epoch: 1 | Loss: 1.363 | Acc: 51.083% (21316/41728)\n",
      "Train Epoch: 1 | Loss: 1.363 | Acc: 51.104% (21390/41856)\n",
      "Train Epoch: 1 | Loss: 1.363 | Acc: 51.112% (21459/41984)\n",
      "Train Epoch: 1 | Loss: 1.362 | Acc: 51.126% (21530/42112)\n",
      "Train Epoch: 1 | Loss: 1.362 | Acc: 51.139% (21601/42240)\n",
      "Train Epoch: 1 | Loss: 1.361 | Acc: 51.157% (21674/42368)\n",
      "Train Epoch: 1 | Loss: 1.360 | Acc: 51.184% (21751/42496)\n",
      "Train Epoch: 1 | Loss: 1.360 | Acc: 51.208% (21827/42624)\n",
      "Train Epoch: 1 | Loss: 1.359 | Acc: 51.223% (21899/42752)\n",
      "Train Epoch: 1 | Loss: 1.358 | Acc: 51.243% (21973/42880)\n",
      "Train Epoch: 1 | Loss: 1.358 | Acc: 51.265% (22048/43008)\n",
      "Train Epoch: 1 | Loss: 1.357 | Acc: 51.268% (22115/43136)\n",
      "Train Epoch: 1 | Loss: 1.357 | Acc: 51.274% (22183/43264)\n",
      "Train Epoch: 1 | Loss: 1.357 | Acc: 51.274% (22249/43392)\n",
      "Train Epoch: 1 | Loss: 1.356 | Acc: 51.294% (22323/43520)\n",
      "Train Epoch: 1 | Loss: 1.356 | Acc: 51.290% (22387/43648)\n",
      "Train Epoch: 1 | Loss: 1.355 | Acc: 51.316% (22464/43776)\n",
      "Train Epoch: 1 | Loss: 1.354 | Acc: 51.348% (22544/43904)\n",
      "Train Epoch: 1 | Loss: 1.354 | Acc: 51.372% (22620/44032)\n",
      "Train Epoch: 1 | Loss: 1.354 | Acc: 51.381% (22690/44160)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.395% (22762/44288)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.387% (22824/44416)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.401% (22896/44544)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.390% (22957/44672)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.388% (23022/44800)\n",
      "Train Epoch: 1 | Loss: 1.353 | Acc: 51.407% (23096/44928)\n",
      "Train Epoch: 1 | Loss: 1.352 | Acc: 51.425% (23170/45056)\n",
      "Train Epoch: 1 | Loss: 1.352 | Acc: 51.436% (23241/45184)\n",
      "Train Epoch: 1 | Loss: 1.351 | Acc: 51.463% (23319/45312)\n",
      "Train Epoch: 1 | Loss: 1.351 | Acc: 51.485% (23395/45440)\n",
      "Train Epoch: 1 | Loss: 1.350 | Acc: 51.512% (23473/45568)\n",
      "Train Epoch: 1 | Loss: 1.350 | Acc: 51.497% (23532/45696)\n",
      "Train Epoch: 1 | Loss: 1.350 | Acc: 51.504% (23601/45824)\n",
      "Train Epoch: 1 | Loss: 1.349 | Acc: 51.528% (23678/45952)\n",
      "Train Epoch: 1 | Loss: 1.349 | Acc: 51.532% (23746/46080)\n",
      "Train Epoch: 1 | Loss: 1.349 | Acc: 51.521% (23807/46208)\n",
      "Train Epoch: 1 | Loss: 1.349 | Acc: 51.537% (23880/46336)\n",
      "Train Epoch: 1 | Loss: 1.348 | Acc: 51.558% (23956/46464)\n",
      "Train Epoch: 1 | Loss: 1.348 | Acc: 51.580% (24032/46592)\n",
      "Train Epoch: 1 | Loss: 1.348 | Acc: 51.597% (24106/46720)\n",
      "Train Epoch: 1 | Loss: 1.347 | Acc: 51.603% (24175/46848)\n",
      "Train Epoch: 1 | Loss: 1.347 | Acc: 51.622% (24250/46976)\n",
      "Train Epoch: 1 | Loss: 1.346 | Acc: 51.645% (24327/47104)\n",
      "Train Epoch: 1 | Loss: 1.346 | Acc: 51.660% (24400/47232)\n",
      "Train Epoch: 1 | Loss: 1.345 | Acc: 51.670% (24471/47360)\n",
      "Train Epoch: 1 | Loss: 1.345 | Acc: 51.668% (24536/47488)\n",
      "Train Epoch: 1 | Loss: 1.345 | Acc: 51.670% (24603/47616)\n",
      "Train Epoch: 1 | Loss: 1.345 | Acc: 51.703% (24685/47744)\n",
      "Train Epoch: 1 | Loss: 1.344 | Acc: 51.725% (24762/47872)\n",
      "Train Epoch: 1 | Loss: 1.344 | Acc: 51.723% (24827/48000)\n",
      "Train Epoch: 1 | Loss: 1.344 | Acc: 51.733% (24898/48128)\n",
      "Train Epoch: 1 | Loss: 1.344 | Acc: 51.759% (24977/48256)\n",
      "Train Epoch: 1 | Loss: 1.343 | Acc: 51.765% (25046/48384)\n",
      "Train Epoch: 1 | Loss: 1.343 | Acc: 51.760% (25110/48512)\n",
      "Train Epoch: 1 | Loss: 1.343 | Acc: 51.791% (25191/48640)\n",
      "Train Epoch: 1 | Loss: 1.342 | Acc: 51.817% (25270/48768)\n",
      "Train Epoch: 1 | Loss: 1.341 | Acc: 51.841% (25348/48896)\n",
      "Train Epoch: 1 | Loss: 1.341 | Acc: 51.877% (25432/49024)\n",
      "Train Epoch: 1 | Loss: 1.340 | Acc: 51.904% (25512/49152)\n",
      "Train Epoch: 1 | Loss: 1.339 | Acc: 51.938% (25595/49280)\n",
      "Train Epoch: 1 | Loss: 1.339 | Acc: 51.955% (25670/49408)\n",
      "Train Epoch: 1 | Loss: 1.338 | Acc: 51.968% (25743/49536)\n",
      "Train Epoch: 1 | Loss: 1.338 | Acc: 51.983% (25817/49664)\n",
      "Train Epoch: 1 | Loss: 1.338 | Acc: 51.992% (25888/49792)\n",
      "Train Epoch: 1 | Loss: 1.337 | Acc: 52.011% (25964/49920)\n",
      "Train Epoch: 1 | Loss: 1.337 | Acc: 52.020% (26010/50000)\n",
      "Test Epoch: 1 | Loss: 1.063 | Acc: 60.000% (60/100)\n",
      "Test Epoch: 1 | Loss: 1.088 | Acc: 61.500% (123/200)\n",
      "Test Epoch: 1 | Loss: 1.125 | Acc: 61.667% (185/300)\n",
      "Test Epoch: 1 | Loss: 1.092 | Acc: 60.750% (243/400)\n",
      "Test Epoch: 1 | Loss: 1.082 | Acc: 61.200% (306/500)\n",
      "Test Epoch: 1 | Loss: 1.051 | Acc: 62.000% (372/600)\n",
      "Test Epoch: 1 | Loss: 1.065 | Acc: 61.143% (428/700)\n",
      "Test Epoch: 1 | Loss: 1.081 | Acc: 60.875% (487/800)\n",
      "Test Epoch: 1 | Loss: 1.085 | Acc: 60.889% (548/900)\n",
      "Test Epoch: 1 | Loss: 1.070 | Acc: 61.100% (611/1000)\n",
      "Test Epoch: 1 | Loss: 1.058 | Acc: 61.545% (677/1100)\n",
      "Test Epoch: 1 | Loss: 1.062 | Acc: 61.167% (734/1200)\n",
      "Test Epoch: 1 | Loss: 1.066 | Acc: 61.154% (795/1300)\n",
      "Test Epoch: 1 | Loss: 1.067 | Acc: 61.143% (856/1400)\n",
      "Test Epoch: 1 | Loss: 1.060 | Acc: 61.467% (922/1500)\n",
      "Test Epoch: 1 | Loss: 1.071 | Acc: 61.438% (983/1600)\n",
      "Test Epoch: 1 | Loss: 1.073 | Acc: 61.471% (1045/1700)\n",
      "Test Epoch: 1 | Loss: 1.072 | Acc: 61.611% (1109/1800)\n",
      "Test Epoch: 1 | Loss: 1.071 | Acc: 61.895% (1176/1900)\n",
      "Test Epoch: 1 | Loss: 1.078 | Acc: 61.650% (1233/2000)\n",
      "Test Epoch: 1 | Loss: 1.081 | Acc: 61.429% (1290/2100)\n",
      "Test Epoch: 1 | Loss: 1.081 | Acc: 61.455% (1352/2200)\n",
      "Test Epoch: 1 | Loss: 1.081 | Acc: 61.522% (1415/2300)\n",
      "Test Epoch: 1 | Loss: 1.081 | Acc: 61.542% (1477/2400)\n",
      "Test Epoch: 1 | Loss: 1.086 | Acc: 61.520% (1538/2500)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 61.192% (1591/2600)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 61.185% (1652/2700)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 61.071% (1710/2800)\n",
      "Test Epoch: 1 | Loss: 1.102 | Acc: 61.034% (1770/2900)\n",
      "Test Epoch: 1 | Loss: 1.104 | Acc: 60.967% (1829/3000)\n",
      "Test Epoch: 1 | Loss: 1.100 | Acc: 61.032% (1892/3100)\n",
      "Test Epoch: 1 | Loss: 1.097 | Acc: 61.156% (1957/3200)\n",
      "Test Epoch: 1 | Loss: 1.096 | Acc: 61.212% (2020/3300)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 61.000% (2074/3400)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.857% (2130/3500)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.833% (2190/3600)\n",
      "Test Epoch: 1 | Loss: 1.112 | Acc: 60.676% (2245/3700)\n",
      "Test Epoch: 1 | Loss: 1.113 | Acc: 60.579% (2302/3800)\n",
      "Test Epoch: 1 | Loss: 1.105 | Acc: 60.846% (2373/3900)\n",
      "Test Epoch: 1 | Loss: 1.104 | Acc: 60.875% (2435/4000)\n",
      "Test Epoch: 1 | Loss: 1.105 | Acc: 60.951% (2499/4100)\n",
      "Test Epoch: 1 | Loss: 1.102 | Acc: 61.143% (2568/4200)\n",
      "Test Epoch: 1 | Loss: 1.096 | Acc: 61.465% (2643/4300)\n",
      "Test Epoch: 1 | Loss: 1.095 | Acc: 61.568% (2709/4400)\n",
      "Test Epoch: 1 | Loss: 1.097 | Acc: 61.556% (2770/4500)\n",
      "Test Epoch: 1 | Loss: 1.098 | Acc: 61.348% (2822/4600)\n",
      "Test Epoch: 1 | Loss: 1.096 | Acc: 61.234% (2878/4700)\n",
      "Test Epoch: 1 | Loss: 1.097 | Acc: 61.229% (2939/4800)\n",
      "Test Epoch: 1 | Loss: 1.095 | Acc: 61.245% (3001/4900)\n",
      "Test Epoch: 1 | Loss: 1.096 | Acc: 61.280% (3064/5000)\n",
      "Test Epoch: 1 | Loss: 1.095 | Acc: 61.294% (3126/5100)\n",
      "Test Epoch: 1 | Loss: 1.095 | Acc: 61.250% (3185/5200)\n",
      "Test Epoch: 1 | Loss: 1.095 | Acc: 61.245% (3246/5300)\n",
      "Test Epoch: 1 | Loss: 1.098 | Acc: 61.111% (3300/5400)\n",
      "Test Epoch: 1 | Loss: 1.099 | Acc: 61.055% (3358/5500)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 61.000% (3416/5600)\n",
      "Test Epoch: 1 | Loss: 1.103 | Acc: 61.000% (3477/5700)\n",
      "Test Epoch: 1 | Loss: 1.101 | Acc: 60.966% (3536/5800)\n",
      "Test Epoch: 1 | Loss: 1.103 | Acc: 60.881% (3592/5900)\n",
      "Test Epoch: 1 | Loss: 1.103 | Acc: 60.917% (3655/6000)\n",
      "Test Epoch: 1 | Loss: 1.105 | Acc: 60.803% (3709/6100)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.710% (3764/6200)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.683% (3823/6300)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.562% (3876/6400)\n",
      "Test Epoch: 1 | Loss: 1.105 | Acc: 60.600% (3939/6500)\n",
      "Test Epoch: 1 | Loss: 1.104 | Acc: 60.606% (4000/6600)\n",
      "Test Epoch: 1 | Loss: 1.103 | Acc: 60.642% (4063/6700)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.559% (4118/6800)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.435% (4170/6900)\n",
      "Test Epoch: 1 | Loss: 1.110 | Acc: 60.400% (4228/7000)\n",
      "Test Epoch: 1 | Loss: 1.111 | Acc: 60.324% (4283/7100)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.431% (4351/7200)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.521% (4418/7300)\n",
      "Test Epoch: 1 | Loss: 1.103 | Acc: 60.514% (4478/7400)\n",
      "Test Epoch: 1 | Loss: 1.104 | Acc: 60.533% (4540/7500)\n",
      "Test Epoch: 1 | Loss: 1.105 | Acc: 60.487% (4597/7600)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.494% (4658/7700)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.462% (4716/7800)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.506% (4780/7900)\n",
      "Test Epoch: 1 | Loss: 1.109 | Acc: 60.462% (4837/8000)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.481% (4899/8100)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.476% (4959/8200)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.482% (5020/8300)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.452% (5078/8400)\n",
      "Test Epoch: 1 | Loss: 1.109 | Acc: 60.365% (5131/8500)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.430% (5197/8600)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.379% (5253/8700)\n",
      "Test Epoch: 1 | Loss: 1.109 | Acc: 60.330% (5309/8800)\n",
      "Test Epoch: 1 | Loss: 1.110 | Acc: 60.247% (5362/8900)\n",
      "Test Epoch: 1 | Loss: 1.111 | Acc: 60.200% (5418/9000)\n",
      "Test Epoch: 1 | Loss: 1.110 | Acc: 60.165% (5475/9100)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.304% (5548/9200)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.323% (5610/9300)\n",
      "Test Epoch: 1 | Loss: 1.107 | Acc: 60.298% (5668/9400)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.253% (5724/9500)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.292% (5788/9600)\n",
      "Test Epoch: 1 | Loss: 1.106 | Acc: 60.278% (5847/9700)\n",
      "Test Epoch: 1 | Loss: 1.109 | Acc: 60.224% (5902/9800)\n",
      "Test Epoch: 1 | Loss: 1.108 | Acc: 60.242% (5964/9900)\n",
      "Test Epoch: 1 | Loss: 1.109 | Acc: 60.230% (6023/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Epoch: 2 | Loss: 1.365 | Acc: 52.344% (67/128)\n",
      "Train Epoch: 2 | Loss: 1.306 | Acc: 55.469% (142/256)\n",
      "Train Epoch: 2 | Loss: 1.248 | Acc: 55.990% (215/384)\n",
      "Train Epoch: 2 | Loss: 1.225 | Acc: 58.398% (299/512)\n",
      "Train Epoch: 2 | Loss: 1.212 | Acc: 59.062% (378/640)\n",
      "Train Epoch: 2 | Loss: 1.217 | Acc: 58.464% (449/768)\n",
      "Train Epoch: 2 | Loss: 1.210 | Acc: 58.371% (523/896)\n",
      "Train Epoch: 2 | Loss: 1.196 | Acc: 58.398% (598/1024)\n",
      "Train Epoch: 2 | Loss: 1.202 | Acc: 58.073% (669/1152)\n",
      "Train Epoch: 2 | Loss: 1.200 | Acc: 57.656% (738/1280)\n",
      "Train Epoch: 2 | Loss: 1.205 | Acc: 57.031% (803/1408)\n",
      "Train Epoch: 2 | Loss: 1.204 | Acc: 57.031% (876/1536)\n",
      "Train Epoch: 2 | Loss: 1.189 | Acc: 56.971% (948/1664)\n",
      "Train Epoch: 2 | Loss: 1.181 | Acc: 57.310% (1027/1792)\n",
      "Train Epoch: 2 | Loss: 1.181 | Acc: 57.083% (1096/1920)\n",
      "Train Epoch: 2 | Loss: 1.170 | Acc: 57.812% (1184/2048)\n",
      "Train Epoch: 2 | Loss: 1.169 | Acc: 57.904% (1260/2176)\n",
      "Train Epoch: 2 | Loss: 1.166 | Acc: 58.247% (1342/2304)\n",
      "Train Epoch: 2 | Loss: 1.173 | Acc: 57.936% (1409/2432)\n",
      "Train Epoch: 2 | Loss: 1.170 | Acc: 58.047% (1486/2560)\n",
      "Train Epoch: 2 | Loss: 1.169 | Acc: 58.073% (1561/2688)\n",
      "Train Epoch: 2 | Loss: 1.169 | Acc: 58.274% (1641/2816)\n",
      "Train Epoch: 2 | Loss: 1.168 | Acc: 58.152% (1712/2944)\n",
      "Train Epoch: 2 | Loss: 1.173 | Acc: 57.910% (1779/3072)\n",
      "Train Epoch: 2 | Loss: 1.170 | Acc: 57.906% (1853/3200)\n",
      "Train Epoch: 2 | Loss: 1.168 | Acc: 57.843% (1925/3328)\n",
      "Train Epoch: 2 | Loss: 1.172 | Acc: 57.697% (1994/3456)\n",
      "Train Epoch: 2 | Loss: 1.174 | Acc: 57.617% (2065/3584)\n",
      "Train Epoch: 2 | Loss: 1.178 | Acc: 57.543% (2136/3712)\n",
      "Train Epoch: 2 | Loss: 1.178 | Acc: 57.578% (2211/3840)\n",
      "Train Epoch: 2 | Loss: 1.179 | Acc: 57.510% (2282/3968)\n",
      "Train Epoch: 2 | Loss: 1.179 | Acc: 57.446% (2353/4096)\n",
      "Train Epoch: 2 | Loss: 1.174 | Acc: 57.670% (2436/4224)\n",
      "Train Epoch: 2 | Loss: 1.171 | Acc: 57.721% (2512/4352)\n",
      "Train Epoch: 2 | Loss: 1.168 | Acc: 57.857% (2592/4480)\n",
      "Train Epoch: 2 | Loss: 1.167 | Acc: 57.834% (2665/4608)\n",
      "Train Epoch: 2 | Loss: 1.166 | Acc: 57.918% (2743/4736)\n",
      "Train Epoch: 2 | Loss: 1.162 | Acc: 58.121% (2827/4864)\n",
      "Train Epoch: 2 | Loss: 1.158 | Acc: 58.393% (2915/4992)\n",
      "Train Epoch: 2 | Loss: 1.162 | Acc: 58.281% (2984/5120)\n",
      "Train Epoch: 2 | Loss: 1.162 | Acc: 58.346% (3062/5248)\n",
      "Train Epoch: 2 | Loss: 1.161 | Acc: 58.371% (3138/5376)\n",
      "Train Epoch: 2 | Loss: 1.160 | Acc: 58.394% (3214/5504)\n",
      "Train Epoch: 2 | Loss: 1.164 | Acc: 58.345% (3286/5632)\n",
      "Train Epoch: 2 | Loss: 1.165 | Acc: 58.316% (3359/5760)\n",
      "Train Epoch: 2 | Loss: 1.164 | Acc: 58.356% (3436/5888)\n",
      "Train Epoch: 2 | Loss: 1.163 | Acc: 58.411% (3514/6016)\n",
      "Train Epoch: 2 | Loss: 1.163 | Acc: 58.382% (3587/6144)\n",
      "Train Epoch: 2 | Loss: 1.161 | Acc: 58.434% (3665/6272)\n",
      "Train Epoch: 2 | Loss: 1.158 | Acc: 58.469% (3742/6400)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.502% (3819/6528)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.594% (3900/6656)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.638% (3978/6784)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.536% (4046/6912)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.509% (4119/7040)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.566% (4198/7168)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.512% (4269/7296)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.621% (4352/7424)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.581% (4424/7552)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.451% (4489/7680)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.530% (4570/7808)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.619% (4652/7936)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 58.780% (4740/8064)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 58.777% (4815/8192)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.786% (4891/8320)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.736% (4962/8448)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.862% (5048/8576)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.812% (5119/8704)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.752% (5189/8832)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.739% (5263/8960)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.748% (5339/9088)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.811% (5420/9216)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.776% (5492/9344)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.784% (5568/9472)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.729% (5638/9600)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.799% (5720/9728)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 58.908% (5806/9856)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 58.924% (5883/9984)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 58.970% (5963/10112)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 59.043% (6046/10240)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.980% (6115/10368)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.032% (6196/10496)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.951% (6263/10624)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.966% (6340/10752)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.961% (6415/10880)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.903% (6484/11008)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.953% (6565/11136)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.958% (6641/11264)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.945% (6715/11392)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.898% (6785/11520)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.971% (6869/11648)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.942% (6941/11776)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.829% (7003/11904)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.793% (7074/12032)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.758% (7145/12160)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.740% (7218/12288)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.739% (7293/12416)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.745% (7369/12544)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.712% (7440/12672)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.672% (7510/12800)\n",
      "Train Epoch: 2 | Loss: 1.158 | Acc: 58.648% (7582/12928)\n",
      "Train Epoch: 2 | Loss: 1.157 | Acc: 58.686% (7662/13056)\n",
      "Train Epoch: 2 | Loss: 1.156 | Acc: 58.723% (7742/13184)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.767% (7823/13312)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.802% (7903/13440)\n",
      "Train Epoch: 2 | Loss: 1.155 | Acc: 58.800% (7978/13568)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.857% (8061/13696)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.854% (8136/13824)\n",
      "Train Epoch: 2 | Loss: 1.154 | Acc: 58.866% (8213/13952)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.892% (8292/14080)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.889% (8367/14208)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.887% (8442/14336)\n",
      "Train Epoch: 2 | Loss: 1.152 | Acc: 58.898% (8519/14464)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.943% (8601/14592)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.022% (8688/14720)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 59.025% (8764/14848)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.014% (8838/14976)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.958% (8905/15104)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.942% (8978/15232)\n",
      "Train Epoch: 2 | Loss: 1.153 | Acc: 58.919% (9050/15360)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.949% (9130/15488)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.991% (9212/15616)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.975% (9285/15744)\n",
      "Train Epoch: 2 | Loss: 1.151 | Acc: 58.997% (9364/15872)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.019% (9443/16000)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 59.034% (9521/16128)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.031% (9596/16256)\n",
      "Train Epoch: 2 | Loss: 1.150 | Acc: 59.052% (9675/16384)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 59.090% (9757/16512)\n",
      "Train Epoch: 2 | Loss: 1.149 | Acc: 59.123% (9838/16640)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.166% (9921/16768)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.186% (10000/16896)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.187% (10076/17024)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.188% (10152/17152)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.149% (10221/17280)\n",
      "Train Epoch: 2 | Loss: 1.148 | Acc: 59.162% (10299/17408)\n",
      "Train Epoch: 2 | Loss: 1.147 | Acc: 59.198% (10381/17536)\n",
      "Train Epoch: 2 | Loss: 1.147 | Acc: 59.222% (10461/17664)\n",
      "Train Epoch: 2 | Loss: 1.145 | Acc: 59.251% (10542/17792)\n",
      "Train Epoch: 2 | Loss: 1.144 | Acc: 59.325% (10631/17920)\n",
      "Train Epoch: 2 | Loss: 1.144 | Acc: 59.303% (10703/18048)\n",
      "Train Epoch: 2 | Loss: 1.143 | Acc: 59.314% (10781/18176)\n",
      "Train Epoch: 2 | Loss: 1.143 | Acc: 59.337% (10861/18304)\n",
      "Train Epoch: 2 | Loss: 1.142 | Acc: 59.348% (10939/18432)\n",
      "Train Epoch: 2 | Loss: 1.142 | Acc: 59.375% (11020/18560)\n",
      "Train Epoch: 2 | Loss: 1.141 | Acc: 59.396% (11100/18688)\n",
      "Train Epoch: 2 | Loss: 1.140 | Acc: 59.423% (11181/18816)\n",
      "Train Epoch: 2 | Loss: 1.139 | Acc: 59.459% (11264/18944)\n",
      "Train Epoch: 2 | Loss: 1.140 | Acc: 59.448% (11338/19072)\n",
      "Train Epoch: 2 | Loss: 1.139 | Acc: 59.464% (11417/19200)\n",
      "Train Epoch: 2 | Loss: 1.139 | Acc: 59.432% (11487/19328)\n",
      "Train Epoch: 2 | Loss: 1.139 | Acc: 59.457% (11568/19456)\n",
      "Train Epoch: 2 | Loss: 1.139 | Acc: 59.441% (11641/19584)\n",
      "Train Epoch: 2 | Loss: 1.138 | Acc: 59.502% (11729/19712)\n",
      "Train Epoch: 2 | Loss: 1.138 | Acc: 59.486% (11802/19840)\n",
      "Train Epoch: 2 | Loss: 1.137 | Acc: 59.525% (11886/19968)\n",
      "Train Epoch: 2 | Loss: 1.138 | Acc: 59.509% (11959/20096)\n",
      "Train Epoch: 2 | Loss: 1.137 | Acc: 59.548% (12043/20224)\n",
      "Train Epoch: 2 | Loss: 1.136 | Acc: 59.576% (12125/20352)\n",
      "Train Epoch: 2 | Loss: 1.136 | Acc: 59.600% (12206/20480)\n",
      "Train Epoch: 2 | Loss: 1.136 | Acc: 59.569% (12276/20608)\n",
      "Train Epoch: 2 | Loss: 1.136 | Acc: 59.549% (12348/20736)\n",
      "Train Epoch: 2 | Loss: 1.135 | Acc: 59.557% (12426/20864)\n",
      "Train Epoch: 2 | Loss: 1.134 | Acc: 59.585% (12508/20992)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.621% (12592/21120)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.596% (12663/21248)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.609% (12742/21376)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.584% (12813/21504)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.602% (12893/21632)\n",
      "Train Epoch: 2 | Loss: 1.134 | Acc: 59.568% (12962/21760)\n",
      "Train Epoch: 2 | Loss: 1.134 | Acc: 59.562% (13037/21888)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.611% (13124/22016)\n",
      "Train Epoch: 2 | Loss: 1.133 | Acc: 59.610% (13200/22144)\n",
      "Train Epoch: 2 | Loss: 1.132 | Acc: 59.604% (13275/22272)\n",
      "Train Epoch: 2 | Loss: 1.131 | Acc: 59.616% (13354/22400)\n",
      "Train Epoch: 2 | Loss: 1.132 | Acc: 59.601% (13427/22528)\n",
      "Train Epoch: 2 | Loss: 1.130 | Acc: 59.671% (13519/22656)\n",
      "Train Epoch: 2 | Loss: 1.130 | Acc: 59.652% (13591/22784)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.676% (13673/22912)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.696% (13754/23040)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.733% (13839/23168)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.740% (13917/23296)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.742% (13994/23424)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.740% (14070/23552)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.738% (14146/23680)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.753% (14226/23808)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.738% (14299/23936)\n",
      "Train Epoch: 2 | Loss: 1.129 | Acc: 59.720% (14371/24064)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.739% (14452/24192)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.733% (14527/24320)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.751% (14608/24448)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.774% (14690/24576)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.739% (14758/24704)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.737% (14834/24832)\n",
      "Train Epoch: 2 | Loss: 1.127 | Acc: 59.752% (14914/24960)\n",
      "Train Epoch: 2 | Loss: 1.128 | Acc: 59.734% (14986/25088)\n",
      "Train Epoch: 2 | Loss: 1.127 | Acc: 59.720% (15059/25216)\n",
      "Train Epoch: 2 | Loss: 1.127 | Acc: 59.722% (15136/25344)\n",
      "Train Epoch: 2 | Loss: 1.126 | Acc: 59.748% (15219/25472)\n",
      "Train Epoch: 2 | Loss: 1.126 | Acc: 59.777% (15303/25600)\n",
      "Train Epoch: 2 | Loss: 1.126 | Acc: 59.799% (15385/25728)\n",
      "Train Epoch: 2 | Loss: 1.126 | Acc: 59.789% (15459/25856)\n",
      "Train Epoch: 2 | Loss: 1.126 | Acc: 59.794% (15537/25984)\n",
      "Train Epoch: 2 | Loss: 1.125 | Acc: 59.819% (15620/26112)\n",
      "Train Epoch: 2 | Loss: 1.125 | Acc: 59.836% (15701/26240)\n",
      "Train Epoch: 2 | Loss: 1.124 | Acc: 59.857% (15783/26368)\n",
      "Train Epoch: 2 | Loss: 1.124 | Acc: 59.854% (15859/26496)\n",
      "Train Epoch: 2 | Loss: 1.123 | Acc: 59.878% (15942/26624)\n",
      "Train Epoch: 2 | Loss: 1.123 | Acc: 59.880% (16019/26752)\n",
      "Train Epoch: 2 | Loss: 1.122 | Acc: 59.907% (16103/26880)\n",
      "Train Epoch: 2 | Loss: 1.122 | Acc: 59.886% (16174/27008)\n",
      "Train Epoch: 2 | Loss: 1.122 | Acc: 59.865% (16245/27136)\n",
      "Train Epoch: 2 | Loss: 1.122 | Acc: 59.877% (16325/27264)\n",
      "Train Epoch: 2 | Loss: 1.122 | Acc: 59.893% (16406/27392)\n",
      "Train Epoch: 2 | Loss: 1.121 | Acc: 59.931% (16493/27520)\n",
      "Train Epoch: 2 | Loss: 1.120 | Acc: 59.975% (16582/27648)\n",
      "Train Epoch: 2 | Loss: 1.120 | Acc: 59.991% (16663/27776)\n",
      "Train Epoch: 2 | Loss: 1.119 | Acc: 60.002% (16743/27904)\n",
      "Train Epoch: 2 | Loss: 1.119 | Acc: 60.006% (16821/28032)\n",
      "Train Epoch: 2 | Loss: 1.119 | Acc: 60.014% (16900/28160)\n",
      "Train Epoch: 2 | Loss: 1.120 | Acc: 60.008% (16975/28288)\n",
      "Train Epoch: 2 | Loss: 1.120 | Acc: 59.991% (17047/28416)\n",
      "Train Epoch: 2 | Loss: 1.120 | Acc: 60.006% (17128/28544)\n",
      "Train Epoch: 2 | Loss: 1.119 | Acc: 60.038% (17214/28672)\n",
      "Train Epoch: 2 | Loss: 1.119 | Acc: 60.038% (17291/28800)\n",
      "Train Epoch: 2 | Loss: 1.118 | Acc: 60.053% (17372/28928)\n",
      "Train Epoch: 2 | Loss: 1.118 | Acc: 60.060% (17451/29056)\n",
      "Train Epoch: 2 | Loss: 1.118 | Acc: 60.033% (17520/29184)\n",
      "Train Epoch: 2 | Loss: 1.118 | Acc: 60.010% (17590/29312)\n",
      "Train Epoch: 2 | Loss: 1.118 | Acc: 60.051% (17679/29440)\n",
      "Train Epoch: 2 | Loss: 1.117 | Acc: 60.082% (17765/29568)\n",
      "Train Epoch: 2 | Loss: 1.117 | Acc: 60.079% (17841/29696)\n",
      "Train Epoch: 2 | Loss: 1.117 | Acc: 60.079% (17918/29824)\n",
      "Train Epoch: 2 | Loss: 1.117 | Acc: 60.106% (18003/29952)\n",
      "Train Epoch: 2 | Loss: 1.116 | Acc: 60.136% (18089/30080)\n",
      "Train Epoch: 2 | Loss: 1.115 | Acc: 60.160% (18173/30208)\n",
      "Train Epoch: 2 | Loss: 1.115 | Acc: 60.169% (18253/30336)\n",
      "Train Epoch: 2 | Loss: 1.115 | Acc: 60.166% (18329/30464)\n",
      "Train Epoch: 2 | Loss: 1.115 | Acc: 60.169% (18407/30592)\n",
      "Train Epoch: 2 | Loss: 1.115 | Acc: 60.173% (18485/30720)\n",
      "Train Epoch: 2 | Loss: 1.114 | Acc: 60.195% (18569/30848)\n",
      "Train Epoch: 2 | Loss: 1.114 | Acc: 60.211% (18651/30976)\n",
      "Train Epoch: 2 | Loss: 1.114 | Acc: 60.221% (18731/31104)\n",
      "Train Epoch: 2 | Loss: 1.114 | Acc: 60.239% (18814/31232)\n",
      "Train Epoch: 2 | Loss: 1.113 | Acc: 60.249% (18894/31360)\n",
      "Train Epoch: 2 | Loss: 1.112 | Acc: 60.299% (18987/31488)\n",
      "Train Epoch: 2 | Loss: 1.112 | Acc: 60.314% (19069/31616)\n",
      "Train Epoch: 2 | Loss: 1.112 | Acc: 60.330% (19151/31744)\n",
      "Train Epoch: 2 | Loss: 1.112 | Acc: 60.345% (19233/31872)\n",
      "Train Epoch: 2 | Loss: 1.112 | Acc: 60.341% (19309/32000)\n",
      "Train Epoch: 2 | Loss: 1.111 | Acc: 60.374% (19397/32128)\n",
      "Train Epoch: 2 | Loss: 1.111 | Acc: 60.404% (19484/32256)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.413% (19564/32384)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.439% (19650/32512)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.414% (19719/32640)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.431% (19802/32768)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.451% (19886/32896)\n",
      "Train Epoch: 2 | Loss: 1.110 | Acc: 60.453% (19964/33024)\n",
      "Train Epoch: 2 | Loss: 1.109 | Acc: 60.482% (20051/33152)\n",
      "Train Epoch: 2 | Loss: 1.109 | Acc: 60.499% (20134/33280)\n",
      "Train Epoch: 2 | Loss: 1.109 | Acc: 60.524% (20220/33408)\n",
      "Train Epoch: 2 | Loss: 1.108 | Acc: 60.568% (20312/33536)\n",
      "Train Epoch: 2 | Loss: 1.108 | Acc: 60.581% (20394/33664)\n",
      "Train Epoch: 2 | Loss: 1.108 | Acc: 60.588% (20474/33792)\n",
      "Train Epoch: 2 | Loss: 1.107 | Acc: 60.628% (20565/33920)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.647% (20649/34048)\n",
      "Train Epoch: 2 | Loss: 1.107 | Acc: 60.639% (20724/34176)\n",
      "Train Epoch: 2 | Loss: 1.107 | Acc: 60.643% (20803/34304)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.664% (20888/34432)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.657% (20963/34560)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.681% (21049/34688)\n",
      "Train Epoch: 2 | Loss: 1.107 | Acc: 60.659% (21119/34816)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.663% (21198/34944)\n",
      "Train Epoch: 2 | Loss: 1.106 | Acc: 60.689% (21285/35072)\n",
      "Train Epoch: 2 | Loss: 1.105 | Acc: 60.719% (21373/35200)\n",
      "Train Epoch: 2 | Loss: 1.105 | Acc: 60.737% (21457/35328)\n",
      "Train Epoch: 2 | Loss: 1.104 | Acc: 60.757% (21542/35456)\n",
      "Train Epoch: 2 | Loss: 1.104 | Acc: 60.766% (21623/35584)\n",
      "Train Epoch: 2 | Loss: 1.104 | Acc: 60.764% (21700/35712)\n",
      "Train Epoch: 2 | Loss: 1.104 | Acc: 60.778% (21783/35840)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.798% (21868/35968)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.816% (21952/36096)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.830% (22035/36224)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.830% (22113/36352)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.853% (22199/36480)\n",
      "Train Epoch: 2 | Loss: 1.103 | Acc: 60.847% (22275/36608)\n",
      "Train Epoch: 2 | Loss: 1.102 | Acc: 60.864% (22359/36736)\n",
      "Train Epoch: 2 | Loss: 1.101 | Acc: 60.875% (22441/36864)\n",
      "Train Epoch: 2 | Loss: 1.101 | Acc: 60.881% (22521/36992)\n",
      "Train Epoch: 2 | Loss: 1.101 | Acc: 60.900% (22606/37120)\n",
      "Train Epoch: 2 | Loss: 1.100 | Acc: 60.927% (22694/37248)\n",
      "Train Epoch: 2 | Loss: 1.100 | Acc: 60.943% (22778/37376)\n",
      "Train Epoch: 2 | Loss: 1.099 | Acc: 60.983% (22871/37504)\n",
      "Train Epoch: 2 | Loss: 1.098 | Acc: 61.001% (22956/37632)\n",
      "Train Epoch: 2 | Loss: 1.098 | Acc: 61.004% (23035/37760)\n",
      "Train Epoch: 2 | Loss: 1.098 | Acc: 61.027% (23122/37888)\n",
      "Train Epoch: 2 | Loss: 1.097 | Acc: 61.040% (23205/38016)\n",
      "Train Epoch: 2 | Loss: 1.097 | Acc: 61.029% (23279/38144)\n",
      "Train Epoch: 2 | Loss: 1.097 | Acc: 61.058% (23368/38272)\n",
      "Train Epoch: 2 | Loss: 1.097 | Acc: 61.047% (23442/38400)\n",
      "Train Epoch: 2 | Loss: 1.096 | Acc: 61.059% (23525/38528)\n",
      "Train Epoch: 2 | Loss: 1.096 | Acc: 61.049% (23599/38656)\n",
      "Train Epoch: 2 | Loss: 1.096 | Acc: 61.066% (23684/38784)\n",
      "Train Epoch: 2 | Loss: 1.096 | Acc: 61.069% (23763/38912)\n",
      "Train Epoch: 2 | Loss: 1.096 | Acc: 61.086% (23848/39040)\n",
      "Train Epoch: 2 | Loss: 1.095 | Acc: 61.083% (23925/39168)\n",
      "Train Epoch: 2 | Loss: 1.095 | Acc: 61.103% (24011/39296)\n",
      "Train Epoch: 2 | Loss: 1.095 | Acc: 61.097% (24087/39424)\n",
      "Train Epoch: 2 | Loss: 1.094 | Acc: 61.114% (24172/39552)\n",
      "Train Epoch: 2 | Loss: 1.094 | Acc: 61.124% (24254/39680)\n",
      "Train Epoch: 2 | Loss: 1.094 | Acc: 61.131% (24335/39808)\n",
      "Train Epoch: 2 | Loss: 1.094 | Acc: 61.140% (24417/39936)\n",
      "Train Epoch: 2 | Loss: 1.093 | Acc: 61.150% (24499/40064)\n",
      "Train Epoch: 2 | Loss: 1.093 | Acc: 61.161% (24582/40192)\n",
      "Train Epoch: 2 | Loss: 1.092 | Acc: 61.205% (24678/40320)\n",
      "Train Epoch: 2 | Loss: 1.092 | Acc: 61.207% (24757/40448)\n",
      "Train Epoch: 2 | Loss: 1.092 | Acc: 61.191% (24829/40576)\n",
      "Train Epoch: 2 | Loss: 1.092 | Acc: 61.191% (24907/40704)\n",
      "Train Epoch: 2 | Loss: 1.091 | Acc: 61.212% (24994/40832)\n",
      "Train Epoch: 2 | Loss: 1.091 | Acc: 61.221% (25076/40960)\n",
      "Train Epoch: 2 | Loss: 1.090 | Acc: 61.237% (25161/41088)\n",
      "Train Epoch: 2 | Loss: 1.090 | Acc: 61.236% (25239/41216)\n",
      "Train Epoch: 2 | Loss: 1.090 | Acc: 61.242% (25320/41344)\n",
      "Train Epoch: 2 | Loss: 1.090 | Acc: 61.241% (25398/41472)\n",
      "Train Epoch: 2 | Loss: 1.089 | Acc: 61.250% (25480/41600)\n",
      "Train Epoch: 2 | Loss: 1.089 | Acc: 61.261% (25563/41728)\n",
      "Train Epoch: 2 | Loss: 1.089 | Acc: 61.255% (25639/41856)\n",
      "Train Epoch: 2 | Loss: 1.089 | Acc: 61.259% (25719/41984)\n",
      "Train Epoch: 2 | Loss: 1.089 | Acc: 61.263% (25799/42112)\n",
      "Train Epoch: 2 | Loss: 1.088 | Acc: 61.278% (25884/42240)\n",
      "Train Epoch: 2 | Loss: 1.088 | Acc: 61.310% (25976/42368)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.333% (26064/42496)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.332% (26142/42624)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.340% (26224/42752)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.341% (26303/42880)\n",
      "Train Epoch: 2 | Loss: 1.088 | Acc: 61.356% (26388/43008)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.355% (26466/43136)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.388% (26559/43264)\n",
      "Train Epoch: 2 | Loss: 1.087 | Acc: 61.408% (26646/43392)\n",
      "Train Epoch: 2 | Loss: 1.086 | Acc: 61.441% (26739/43520)\n",
      "Train Epoch: 2 | Loss: 1.086 | Acc: 61.432% (26814/43648)\n",
      "Train Epoch: 2 | Loss: 1.086 | Acc: 61.410% (26883/43776)\n",
      "Train Epoch: 2 | Loss: 1.086 | Acc: 61.429% (26970/43904)\n",
      "Train Epoch: 2 | Loss: 1.085 | Acc: 61.460% (27062/44032)\n",
      "Train Epoch: 2 | Loss: 1.085 | Acc: 61.486% (27152/44160)\n",
      "Train Epoch: 2 | Loss: 1.085 | Acc: 61.491% (27233/44288)\n",
      "Train Epoch: 2 | Loss: 1.085 | Acc: 61.494% (27313/44416)\n",
      "Train Epoch: 2 | Loss: 1.085 | Acc: 61.499% (27394/44544)\n",
      "Train Epoch: 2 | Loss: 1.084 | Acc: 61.533% (27488/44672)\n",
      "Train Epoch: 2 | Loss: 1.084 | Acc: 61.556% (27577/44800)\n",
      "Train Epoch: 2 | Loss: 1.084 | Acc: 61.565% (27660/44928)\n",
      "Train Epoch: 2 | Loss: 1.083 | Acc: 61.583% (27747/45056)\n",
      "Train Epoch: 2 | Loss: 1.083 | Acc: 61.599% (27833/45184)\n",
      "Train Epoch: 2 | Loss: 1.083 | Acc: 61.606% (27915/45312)\n",
      "Train Epoch: 2 | Loss: 1.082 | Acc: 61.620% (28000/45440)\n",
      "Train Epoch: 2 | Loss: 1.082 | Acc: 61.605% (28072/45568)\n",
      "Train Epoch: 2 | Loss: 1.082 | Acc: 61.616% (28156/45696)\n",
      "Train Epoch: 2 | Loss: 1.082 | Acc: 61.616% (28235/45824)\n",
      "Train Epoch: 2 | Loss: 1.082 | Acc: 61.636% (28323/45952)\n",
      "Train Epoch: 2 | Loss: 1.081 | Acc: 61.669% (28417/46080)\n",
      "Train Epoch: 2 | Loss: 1.081 | Acc: 61.684% (28503/46208)\n",
      "Train Epoch: 2 | Loss: 1.081 | Acc: 61.682% (28581/46336)\n",
      "Train Epoch: 2 | Loss: 1.080 | Acc: 61.686% (28662/46464)\n",
      "Train Epoch: 2 | Loss: 1.080 | Acc: 61.706% (28750/46592)\n",
      "Train Epoch: 2 | Loss: 1.080 | Acc: 61.697% (28825/46720)\n",
      "Train Epoch: 2 | Loss: 1.081 | Acc: 61.685% (28898/46848)\n",
      "Train Epoch: 2 | Loss: 1.081 | Acc: 61.683% (28976/46976)\n",
      "Train Epoch: 2 | Loss: 1.080 | Acc: 61.704% (29065/47104)\n",
      "Train Epoch: 2 | Loss: 1.080 | Acc: 61.719% (29151/47232)\n",
      "Train Epoch: 2 | Loss: 1.079 | Acc: 61.725% (29233/47360)\n",
      "Train Epoch: 2 | Loss: 1.079 | Acc: 61.740% (29319/47488)\n",
      "Train Epoch: 2 | Loss: 1.078 | Acc: 61.754% (29405/47616)\n",
      "Train Epoch: 2 | Loss: 1.078 | Acc: 61.763% (29488/47744)\n",
      "Train Epoch: 2 | Loss: 1.078 | Acc: 61.767% (29569/47872)\n",
      "Train Epoch: 2 | Loss: 1.078 | Acc: 61.796% (29662/48000)\n",
      "Train Epoch: 2 | Loss: 1.077 | Acc: 61.804% (29745/48128)\n",
      "Train Epoch: 2 | Loss: 1.077 | Acc: 61.829% (29836/48256)\n",
      "Train Epoch: 2 | Loss: 1.077 | Acc: 61.837% (29919/48384)\n",
      "Train Epoch: 2 | Loss: 1.077 | Acc: 61.830% (29995/48512)\n",
      "Train Epoch: 2 | Loss: 1.076 | Acc: 61.840% (30079/48640)\n",
      "Train Epoch: 2 | Loss: 1.076 | Acc: 61.842% (30159/48768)\n",
      "Train Epoch: 2 | Loss: 1.076 | Acc: 61.846% (30240/48896)\n",
      "Train Epoch: 2 | Loss: 1.075 | Acc: 61.862% (30327/49024)\n",
      "Train Epoch: 2 | Loss: 1.075 | Acc: 61.869% (30410/49152)\n",
      "Train Epoch: 2 | Loss: 1.075 | Acc: 61.881% (30495/49280)\n",
      "Train Epoch: 2 | Loss: 1.075 | Acc: 61.895% (30581/49408)\n",
      "Train Epoch: 2 | Loss: 1.074 | Acc: 61.904% (30665/49536)\n",
      "Train Epoch: 2 | Loss: 1.074 | Acc: 61.930% (30757/49664)\n",
      "Train Epoch: 2 | Loss: 1.074 | Acc: 61.916% (30829/49792)\n",
      "Train Epoch: 2 | Loss: 1.074 | Acc: 61.921% (30911/49920)\n",
      "Train Epoch: 2 | Loss: 1.074 | Acc: 61.906% (30953/50000)\n",
      "Test Epoch: 2 | Loss: 0.924 | Acc: 68.000% (68/100)\n",
      "Test Epoch: 2 | Loss: 0.962 | Acc: 66.500% (133/200)\n",
      "Test Epoch: 2 | Loss: 0.984 | Acc: 67.333% (202/300)\n",
      "Test Epoch: 2 | Loss: 0.961 | Acc: 67.500% (270/400)\n",
      "Test Epoch: 2 | Loss: 0.968 | Acc: 67.800% (339/500)\n",
      "Test Epoch: 2 | Loss: 0.923 | Acc: 68.333% (410/600)\n",
      "Test Epoch: 2 | Loss: 0.939 | Acc: 67.429% (472/700)\n",
      "Test Epoch: 2 | Loss: 0.968 | Acc: 66.625% (533/800)\n",
      "Test Epoch: 2 | Loss: 0.955 | Acc: 67.111% (604/900)\n",
      "Test Epoch: 2 | Loss: 0.945 | Acc: 67.300% (673/1000)\n",
      "Test Epoch: 2 | Loss: 0.949 | Acc: 67.545% (743/1100)\n",
      "Test Epoch: 2 | Loss: 0.954 | Acc: 67.500% (810/1200)\n",
      "Test Epoch: 2 | Loss: 0.947 | Acc: 67.308% (875/1300)\n",
      "Test Epoch: 2 | Loss: 0.946 | Acc: 67.000% (938/1400)\n",
      "Test Epoch: 2 | Loss: 0.940 | Acc: 66.467% (997/1500)\n",
      "Test Epoch: 2 | Loss: 0.967 | Acc: 66.125% (1058/1600)\n",
      "Test Epoch: 2 | Loss: 0.960 | Acc: 66.647% (1133/1700)\n",
      "Test Epoch: 2 | Loss: 0.961 | Acc: 66.611% (1199/1800)\n",
      "Test Epoch: 2 | Loss: 0.960 | Acc: 67.000% (1273/1900)\n",
      "Test Epoch: 2 | Loss: 0.975 | Acc: 66.600% (1332/2000)\n",
      "Test Epoch: 2 | Loss: 0.972 | Acc: 66.524% (1397/2100)\n",
      "Test Epoch: 2 | Loss: 0.976 | Acc: 66.500% (1463/2200)\n",
      "Test Epoch: 2 | Loss: 0.974 | Acc: 66.783% (1536/2300)\n",
      "Test Epoch: 2 | Loss: 0.978 | Acc: 66.542% (1597/2400)\n",
      "Test Epoch: 2 | Loss: 0.976 | Acc: 66.600% (1665/2500)\n",
      "Test Epoch: 2 | Loss: 0.992 | Acc: 66.038% (1717/2600)\n",
      "Test Epoch: 2 | Loss: 0.995 | Acc: 65.852% (1778/2700)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.000% (1848/2800)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.207% (1920/2900)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.167% (1985/3000)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 66.161% (2051/3100)\n",
      "Test Epoch: 2 | Loss: 0.989 | Acc: 66.219% (2119/3200)\n",
      "Test Epoch: 2 | Loss: 0.989 | Acc: 66.333% (2189/3300)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 66.235% (2252/3400)\n",
      "Test Epoch: 2 | Loss: 0.994 | Acc: 66.171% (2316/3500)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 66.056% (2378/3600)\n",
      "Test Epoch: 2 | Loss: 1.004 | Acc: 65.892% (2438/3700)\n",
      "Test Epoch: 2 | Loss: 1.003 | Acc: 65.842% (2502/3800)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 66.051% (2576/3900)\n",
      "Test Epoch: 2 | Loss: 0.994 | Acc: 66.175% (2647/4000)\n",
      "Test Epoch: 2 | Loss: 0.995 | Acc: 66.244% (2716/4100)\n",
      "Test Epoch: 2 | Loss: 0.996 | Acc: 66.262% (2783/4200)\n",
      "Test Epoch: 2 | Loss: 0.991 | Acc: 66.465% (2858/4300)\n",
      "Test Epoch: 2 | Loss: 0.989 | Acc: 66.545% (2928/4400)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.400% (2988/4500)\n",
      "Test Epoch: 2 | Loss: 0.989 | Acc: 66.370% (3053/4600)\n",
      "Test Epoch: 2 | Loss: 0.986 | Acc: 66.383% (3120/4700)\n",
      "Test Epoch: 2 | Loss: 0.987 | Acc: 66.333% (3184/4800)\n",
      "Test Epoch: 2 | Loss: 0.986 | Acc: 66.327% (3250/4900)\n",
      "Test Epoch: 2 | Loss: 0.983 | Acc: 66.320% (3316/5000)\n",
      "Test Epoch: 2 | Loss: 0.982 | Acc: 66.392% (3386/5100)\n",
      "Test Epoch: 2 | Loss: 0.982 | Acc: 66.423% (3454/5200)\n",
      "Test Epoch: 2 | Loss: 0.983 | Acc: 66.358% (3517/5300)\n",
      "Test Epoch: 2 | Loss: 0.983 | Acc: 66.259% (3578/5400)\n",
      "Test Epoch: 2 | Loss: 0.985 | Acc: 66.109% (3636/5500)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.036% (3698/5600)\n",
      "Test Epoch: 2 | Loss: 0.992 | Acc: 65.965% (3760/5700)\n",
      "Test Epoch: 2 | Loss: 0.990 | Acc: 66.017% (3829/5800)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 65.932% (3890/5900)\n",
      "Test Epoch: 2 | Loss: 0.994 | Acc: 65.933% (3956/6000)\n",
      "Test Epoch: 2 | Loss: 0.994 | Acc: 65.869% (4018/6100)\n",
      "Test Epoch: 2 | Loss: 0.994 | Acc: 65.903% (4086/6200)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 65.873% (4150/6300)\n",
      "Test Epoch: 2 | Loss: 0.991 | Acc: 65.953% (4221/6400)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 65.877% (4282/6500)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 65.879% (4348/6600)\n",
      "Test Epoch: 2 | Loss: 0.993 | Acc: 65.851% (4412/6700)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.735% (4470/6800)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.739% (4536/6900)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.657% (4596/7000)\n",
      "Test Epoch: 2 | Loss: 1.000 | Acc: 65.620% (4659/7100)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.694% (4730/7200)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.699% (4796/7300)\n",
      "Test Epoch: 2 | Loss: 0.995 | Acc: 65.784% (4868/7400)\n",
      "Test Epoch: 2 | Loss: 0.995 | Acc: 65.813% (4936/7500)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.684% (4992/7600)\n",
      "Test Epoch: 2 | Loss: 0.999 | Acc: 65.597% (5051/7700)\n",
      "Test Epoch: 2 | Loss: 0.998 | Acc: 65.628% (5119/7800)\n",
      "Test Epoch: 2 | Loss: 0.999 | Acc: 65.633% (5185/7900)\n",
      "Test Epoch: 2 | Loss: 0.999 | Acc: 65.575% (5246/8000)\n",
      "Test Epoch: 2 | Loss: 0.996 | Acc: 65.654% (5318/8100)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.585% (5378/8200)\n",
      "Test Epoch: 2 | Loss: 0.997 | Acc: 65.590% (5444/8300)\n",
      "Test Epoch: 2 | Loss: 0.999 | Acc: 65.536% (5505/8400)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.482% (5566/8500)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.523% (5635/8600)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.540% (5702/8700)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.511% (5765/8800)\n",
      "Test Epoch: 2 | Loss: 1.004 | Acc: 65.438% (5824/8900)\n",
      "Test Epoch: 2 | Loss: 1.005 | Acc: 65.411% (5887/9000)\n",
      "Test Epoch: 2 | Loss: 1.006 | Acc: 65.385% (5950/9100)\n",
      "Test Epoch: 2 | Loss: 1.003 | Acc: 65.511% (6027/9200)\n",
      "Test Epoch: 2 | Loss: 1.003 | Acc: 65.516% (6093/9300)\n",
      "Test Epoch: 2 | Loss: 1.003 | Acc: 65.500% (6157/9400)\n",
      "Test Epoch: 2 | Loss: 1.003 | Acc: 65.432% (6216/9500)\n",
      "Test Epoch: 2 | Loss: 1.002 | Acc: 65.479% (6286/9600)\n",
      "Test Epoch: 2 | Loss: 1.001 | Acc: 65.464% (6350/9700)\n",
      "Test Epoch: 2 | Loss: 1.002 | Acc: 65.449% (6414/9800)\n",
      "Test Epoch: 2 | Loss: 1.002 | Acc: 65.475% (6482/9900)\n",
      "Test Epoch: 2 | Loss: 1.002 | Acc: 65.500% (6550/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Epoch: 3 | Loss: 1.002 | Acc: 64.062% (82/128)\n",
      "Train Epoch: 3 | Loss: 0.977 | Acc: 64.062% (164/256)\n",
      "Train Epoch: 3 | Loss: 0.980 | Acc: 63.802% (245/384)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 64.453% (330/512)\n",
      "Train Epoch: 3 | Loss: 0.963 | Acc: 65.156% (417/640)\n",
      "Train Epoch: 3 | Loss: 0.985 | Acc: 64.453% (495/768)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 65.625% (588/896)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 65.625% (672/1024)\n",
      "Train Epoch: 3 | Loss: 0.947 | Acc: 65.625% (756/1152)\n",
      "Train Epoch: 3 | Loss: 0.951 | Acc: 65.703% (841/1280)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 65.128% (917/1408)\n",
      "Train Epoch: 3 | Loss: 0.979 | Acc: 64.714% (994/1536)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.964% (1081/1664)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.844% (1162/1792)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.312% (1254/1920)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 65.430% (1340/2048)\n",
      "Train Epoch: 3 | Loss: 0.970 | Acc: 64.982% (1414/2176)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 64.931% (1496/2304)\n",
      "Train Epoch: 3 | Loss: 0.968 | Acc: 64.885% (1578/2432)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.000% (1664/2560)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 64.881% (1744/2688)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 64.773% (1824/2816)\n",
      "Train Epoch: 3 | Loss: 0.970 | Acc: 64.606% (1902/2944)\n",
      "Train Epoch: 3 | Loss: 0.975 | Acc: 64.388% (1978/3072)\n",
      "Train Epoch: 3 | Loss: 0.968 | Acc: 64.562% (2066/3200)\n",
      "Train Epoch: 3 | Loss: 0.968 | Acc: 64.603% (2150/3328)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 64.699% (2236/3456)\n",
      "Train Epoch: 3 | Loss: 0.962 | Acc: 65.039% (2331/3584)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 64.682% (2401/3712)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 64.609% (2481/3840)\n",
      "Train Epoch: 3 | Loss: 0.973 | Acc: 64.365% (2554/3968)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.331% (2635/4096)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.323% (2717/4224)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.246% (2796/4352)\n",
      "Train Epoch: 3 | Loss: 0.972 | Acc: 64.330% (2882/4480)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.345% (2965/4608)\n",
      "Train Epoch: 3 | Loss: 0.976 | Acc: 64.274% (3044/4736)\n",
      "Train Epoch: 3 | Loss: 0.975 | Acc: 64.289% (3127/4864)\n",
      "Train Epoch: 3 | Loss: 0.975 | Acc: 64.243% (3207/4992)\n",
      "Train Epoch: 3 | Loss: 0.976 | Acc: 64.258% (3290/5120)\n",
      "Train Epoch: 3 | Loss: 0.977 | Acc: 64.234% (3371/5248)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.435% (3464/5376)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.535% (3552/5504)\n",
      "Train Epoch: 3 | Loss: 0.974 | Acc: 64.595% (3638/5632)\n",
      "Train Epoch: 3 | Loss: 0.970 | Acc: 64.722% (3728/5760)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.606% (3804/5888)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.678% (3891/6016)\n",
      "Train Epoch: 3 | Loss: 0.970 | Acc: 64.779% (3980/6144)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.732% (4060/6272)\n",
      "Train Epoch: 3 | Loss: 0.971 | Acc: 64.797% (4147/6400)\n",
      "Train Epoch: 3 | Loss: 0.972 | Acc: 64.828% (4232/6528)\n",
      "Train Epoch: 3 | Loss: 0.972 | Acc: 64.919% (4321/6656)\n",
      "Train Epoch: 3 | Loss: 0.970 | Acc: 65.006% (4410/6784)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.191% (4506/6912)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.256% (4594/7040)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.095% (4666/7168)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.104% (4750/7296)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.221% (4842/7424)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.215% (4925/7552)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.195% (5007/7680)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.369% (5104/7808)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.348% (5186/7936)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.402% (5274/8064)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.576% (5372/8192)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.625% (5460/8320)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.625% (5544/8448)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.602% (5626/8576)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.636% (5713/8704)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.704% (5803/8832)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.714% (5888/8960)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.757% (5976/9088)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.777% (6062/9216)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.764% (6145/9344)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.720% (6225/9472)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.750% (6312/9600)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.718% (6393/9728)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.767% (6482/9856)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.855% (6575/9984)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.823% (6656/10112)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.830% (6741/10240)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.789% (6821/10368)\n",
      "Train Epoch: 3 | Loss: 0.966 | Acc: 65.796% (6906/10496)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.776% (6988/10624)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.783% (7073/10752)\n",
      "Train Epoch: 3 | Loss: 0.967 | Acc: 65.818% (7161/10880)\n",
      "Train Epoch: 3 | Loss: 0.968 | Acc: 65.870% (7251/11008)\n",
      "Train Epoch: 3 | Loss: 0.968 | Acc: 65.858% (7334/11136)\n",
      "Train Epoch: 3 | Loss: 0.965 | Acc: 65.900% (7423/11264)\n",
      "Train Epoch: 3 | Loss: 0.964 | Acc: 65.959% (7514/11392)\n",
      "Train Epoch: 3 | Loss: 0.963 | Acc: 65.990% (7602/11520)\n",
      "Train Epoch: 3 | Loss: 0.963 | Acc: 65.968% (7684/11648)\n",
      "Train Epoch: 3 | Loss: 0.962 | Acc: 65.939% (7765/11776)\n",
      "Train Epoch: 3 | Loss: 0.962 | Acc: 65.936% (7849/11904)\n",
      "Train Epoch: 3 | Loss: 0.962 | Acc: 65.982% (7939/12032)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 65.987% (8024/12160)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 65.983% (8108/12288)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 65.995% (8194/12416)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.040% (8284/12544)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.091% (8375/12672)\n",
      "Train Epoch: 3 | Loss: 0.959 | Acc: 66.094% (8460/12800)\n",
      "Train Epoch: 3 | Loss: 0.961 | Acc: 66.019% (8535/12928)\n",
      "Train Epoch: 3 | Loss: 0.959 | Acc: 66.085% (8628/13056)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.148% (8721/13184)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.166% (8808/13312)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.272% (8907/13440)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.244% (8988/13568)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.304% (9081/13696)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.247% (9158/13824)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.256% (9244/13952)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.250% (9328/14080)\n",
      "Train Epoch: 3 | Loss: 0.959 | Acc: 66.251% (9413/14208)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.309% (9506/14336)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.261% (9584/14464)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.276% (9671/14592)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.168% (9740/14720)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.130% (9819/14848)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.119% (9902/14976)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.148% (9991/15104)\n",
      "Train Epoch: 3 | Loss: 0.960 | Acc: 66.144% (10075/15232)\n",
      "Train Epoch: 3 | Loss: 0.959 | Acc: 66.185% (10166/15360)\n",
      "Train Epoch: 3 | Loss: 0.959 | Acc: 66.219% (10256/15488)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.253% (10346/15616)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.292% (10437/15744)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.249% (10515/15872)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.300% (10608/16000)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.319% (10696/16128)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.419% (10797/16256)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.400% (10879/16384)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.388% (10962/16512)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.418% (11052/16640)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.454% (11143/16768)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.495% (11235/16896)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.518% (11324/17024)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.453% (11398/17152)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.412% (11476/17280)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.383% (11556/17408)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.406% (11645/17536)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.463% (11740/17664)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.502% (11832/17792)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.523% (11921/17920)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.478% (11998/18048)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.439% (12076/18176)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.444% (12162/18304)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.450% (12248/18432)\n",
      "Train Epoch: 3 | Loss: 0.958 | Acc: 66.460% (12335/18560)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.460% (12420/18688)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.481% (12509/18816)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.512% (12600/18944)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.495% (12682/19072)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.464% (12761/19200)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.463% (12846/19328)\n",
      "Train Epoch: 3 | Loss: 0.957 | Acc: 66.473% (12933/19456)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.473% (13018/19584)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.457% (13100/19712)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.472% (13188/19840)\n",
      "Train Epoch: 3 | Loss: 0.956 | Acc: 66.471% (13273/19968)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.481% (13360/20096)\n",
      "Train Epoch: 3 | Loss: 0.954 | Acc: 66.520% (13453/20224)\n",
      "Train Epoch: 3 | Loss: 0.954 | Acc: 66.534% (13541/20352)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.504% (13620/20480)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.484% (13701/20608)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.479% (13785/20736)\n",
      "Train Epoch: 3 | Loss: 0.955 | Acc: 66.493% (13873/20864)\n",
      "Train Epoch: 3 | Loss: 0.954 | Acc: 66.497% (13959/20992)\n",
      "Train Epoch: 3 | Loss: 0.954 | Acc: 66.515% (14048/21120)\n",
      "Train Epoch: 3 | Loss: 0.954 | Acc: 66.519% (14134/21248)\n",
      "Train Epoch: 3 | Loss: 0.952 | Acc: 66.570% (14230/21376)\n",
      "Train Epoch: 3 | Loss: 0.952 | Acc: 66.588% (14319/21504)\n",
      "Train Epoch: 3 | Loss: 0.951 | Acc: 66.591% (14405/21632)\n",
      "Train Epoch: 3 | Loss: 0.951 | Acc: 66.636% (14500/21760)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.676% (14594/21888)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.706% (14686/22016)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.686% (14767/22144)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.707% (14857/22272)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.710% (14943/22400)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.721% (15031/22528)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.728% (15118/22656)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.727% (15203/22784)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.729% (15289/22912)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.727% (15374/23040)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.670% (15446/23168)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.685% (15535/23296)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.658% (15614/23424)\n",
      "Train Epoch: 3 | Loss: 0.950 | Acc: 66.648% (15697/23552)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.643% (15781/23680)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.658% (15870/23808)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.682% (15961/23936)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.664% (16042/24064)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.658% (16126/24192)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.645% (16208/24320)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.643% (16293/24448)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.618% (16372/24576)\n",
      "Train Epoch: 3 | Loss: 0.949 | Acc: 66.605% (16454/24704)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.608% (16540/24832)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.635% (16632/24960)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.633% (16717/25088)\n",
      "Train Epoch: 3 | Loss: 0.948 | Acc: 66.636% (16803/25216)\n",
      "Train Epoch: 3 | Loss: 0.947 | Acc: 66.698% (16904/25344)\n",
      "Train Epoch: 3 | Loss: 0.947 | Acc: 66.724% (16996/25472)\n",
      "Train Epoch: 3 | Loss: 0.947 | Acc: 66.723% (17081/25600)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.733% (17169/25728)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.731% (17254/25856)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.699% (17331/25984)\n",
      "Train Epoch: 3 | Loss: 0.947 | Acc: 66.690% (17414/26112)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.726% (17509/26240)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.751% (17601/26368)\n",
      "Train Epoch: 3 | Loss: 0.945 | Acc: 66.761% (17689/26496)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.741% (17769/26624)\n",
      "Train Epoch: 3 | Loss: 0.946 | Acc: 66.758% (17859/26752)\n",
      "Train Epoch: 3 | Loss: 0.945 | Acc: 66.786% (17952/26880)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.799% (18041/27008)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.764% (18117/27136)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.777% (18206/27264)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.779% (18292/27392)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.777% (18377/27520)\n",
      "Train Epoch: 3 | Loss: 0.944 | Acc: 66.826% (18476/27648)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.860% (18571/27776)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.872% (18660/27904)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.845% (18738/28032)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.889% (18836/28160)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.891% (18922/28288)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.874% (19003/28416)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.869% (19087/28544)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.895% (19180/28672)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.896% (19266/28800)\n",
      "Train Epoch: 3 | Loss: 0.943 | Acc: 66.883% (19348/28928)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.909% (19441/29056)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.900% (19524/29184)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.925% (19617/29312)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.923% (19702/29440)\n",
      "Train Epoch: 3 | Loss: 0.942 | Acc: 66.954% (19797/29568)\n",
      "Train Epoch: 3 | Loss: 0.941 | Acc: 66.985% (19892/29696)\n",
      "Train Epoch: 3 | Loss: 0.941 | Acc: 67.003% (19983/29824)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.037% (20079/29952)\n",
      "Train Epoch: 3 | Loss: 0.940 | Acc: 67.021% (20160/30080)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.015% (20244/30208)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 66.996% (20324/30336)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.030% (20420/30464)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.034% (20507/30592)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.025% (20590/30720)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.032% (20678/30848)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.026% (20762/30976)\n",
      "Train Epoch: 3 | Loss: 0.939 | Acc: 67.027% (20848/31104)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.043% (20939/31232)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.073% (21034/31360)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.070% (21119/31488)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.042% (21196/31616)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.068% (21290/31744)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.087% (21382/31872)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.106% (21474/32000)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.125% (21566/32128)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.116% (21649/32256)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.141% (21743/32384)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.123% (21823/32512)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.126% (21910/32640)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.123% (21995/32768)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.102% (22074/32896)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.106% (22161/33024)\n",
      "Train Epoch: 3 | Loss: 0.938 | Acc: 67.094% (22243/33152)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.097% (22330/33280)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.098% (22416/33408)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.122% (22510/33536)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.125% (22597/33664)\n",
      "Train Epoch: 3 | Loss: 0.937 | Acc: 67.140% (22688/33792)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.182% (22788/33920)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.176% (22872/34048)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.190% (22963/34176)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.188% (23048/34304)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.202% (23139/34432)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.205% (23226/34560)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.196% (23309/34688)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.210% (23400/34816)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.222% (23490/34944)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.236% (23581/35072)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.239% (23668/35200)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.219% (23747/35328)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.244% (23842/35456)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.249% (23930/35584)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.244% (24014/35712)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.218% (24091/35840)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.213% (24175/35968)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.235% (24269/36096)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.237% (24356/36224)\n",
      "Train Epoch: 3 | Loss: 0.936 | Acc: 67.232% (24440/36352)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.253% (24534/36480)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.267% (24625/36608)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.253% (24706/36736)\n",
      "Train Epoch: 3 | Loss: 0.935 | Acc: 67.266% (24797/36864)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.296% (24894/36992)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.295% (24980/37120)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.311% (25072/37248)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.308% (25157/37376)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.313% (25245/37504)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.307% (25329/37632)\n",
      "Train Epoch: 3 | Loss: 0.934 | Acc: 67.312% (25417/37760)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.330% (25510/37888)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.340% (25600/38016)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.332% (25683/38144)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.323% (25766/38272)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.328% (25854/38400)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.325% (25939/38528)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.340% (26031/38656)\n",
      "Train Epoch: 3 | Loss: 0.933 | Acc: 67.337% (26116/38784)\n",
      "Train Epoch: 3 | Loss: 0.932 | Acc: 67.349% (26207/38912)\n",
      "Train Epoch: 3 | Loss: 0.932 | Acc: 67.364% (26299/39040)\n",
      "Train Epoch: 3 | Loss: 0.931 | Acc: 67.382% (26392/39168)\n",
      "Train Epoch: 3 | Loss: 0.931 | Acc: 67.383% (26479/39296)\n",
      "Train Epoch: 3 | Loss: 0.931 | Acc: 67.398% (26571/39424)\n",
      "Train Epoch: 3 | Loss: 0.931 | Acc: 67.418% (26665/39552)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.450% (26764/39680)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.461% (26855/39808)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.455% (26939/39936)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.472% (27032/40064)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.489% (27125/40192)\n",
      "Train Epoch: 3 | Loss: 0.929 | Acc: 67.502% (27217/40320)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.487% (27297/40448)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.498% (27388/40576)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.497% (27474/40704)\n",
      "Train Epoch: 3 | Loss: 0.930 | Acc: 67.508% (27565/40832)\n",
      "Train Epoch: 3 | Loss: 0.929 | Acc: 67.546% (27667/40960)\n",
      "Train Epoch: 3 | Loss: 0.929 | Acc: 67.560% (27759/41088)\n",
      "Train Epoch: 3 | Loss: 0.929 | Acc: 67.554% (27843/41216)\n",
      "Train Epoch: 3 | Loss: 0.929 | Acc: 67.558% (27931/41344)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.568% (28022/41472)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.584% (28115/41600)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.590% (28204/41728)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.601% (28295/41856)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.597% (28380/41984)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.582% (28460/42112)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.592% (28551/42240)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.586% (28635/42368)\n",
      "Train Epoch: 3 | Loss: 0.928 | Acc: 67.595% (28725/42496)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.607% (28817/42624)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.599% (28900/42752)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.607% (28990/42880)\n",
      "Train Epoch: 3 | Loss: 0.927 | Acc: 67.615% (29080/43008)\n",
      "Train Epoch: 3 | Loss: 0.926 | Acc: 67.623% (29170/43136)\n",
      "Train Epoch: 3 | Loss: 0.926 | Acc: 67.631% (29260/43264)\n",
      "Train Epoch: 3 | Loss: 0.926 | Acc: 67.616% (29340/43392)\n",
      "Train Epoch: 3 | Loss: 0.926 | Acc: 67.631% (29433/43520)\n",
      "Train Epoch: 3 | Loss: 0.925 | Acc: 67.630% (29519/43648)\n",
      "Train Epoch: 3 | Loss: 0.925 | Acc: 67.626% (29604/43776)\n",
      "Train Epoch: 3 | Loss: 0.925 | Acc: 67.645% (29699/43904)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.687% (29804/44032)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.692% (29893/44160)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.677% (29973/44288)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.678% (30060/44416)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.684% (30149/44544)\n",
      "Train Epoch: 3 | Loss: 0.923 | Acc: 67.700% (30243/44672)\n",
      "Train Epoch: 3 | Loss: 0.924 | Acc: 67.676% (30319/44800)\n",
      "Train Epoch: 3 | Loss: 0.923 | Acc: 67.682% (30408/44928)\n",
      "Train Epoch: 3 | Loss: 0.923 | Acc: 67.689% (30498/45056)\n",
      "Train Epoch: 3 | Loss: 0.923 | Acc: 67.710% (30594/45184)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.746% (30697/45312)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.753% (30787/45440)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.751% (30873/45568)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.743% (30956/45696)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.753% (31047/45824)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.755% (31135/45952)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.752% (31220/46080)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.785% (31322/46208)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.792% (31412/46336)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.777% (31492/46464)\n",
      "Train Epoch: 3 | Loss: 0.922 | Acc: 67.758% (31570/46592)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.770% (31662/46720)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.796% (31761/46848)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.794% (31847/46976)\n",
      "Train Epoch: 3 | Loss: 0.921 | Acc: 67.801% (31937/47104)\n",
      "Train Epoch: 3 | Loss: 0.920 | Acc: 67.814% (32030/47232)\n",
      "Train Epoch: 3 | Loss: 0.920 | Acc: 67.823% (32121/47360)\n",
      "Train Epoch: 3 | Loss: 0.920 | Acc: 67.821% (32207/47488)\n",
      "Train Epoch: 3 | Loss: 0.920 | Acc: 67.830% (32298/47616)\n",
      "Train Epoch: 3 | Loss: 0.919 | Acc: 67.835% (32387/47744)\n",
      "Train Epoch: 3 | Loss: 0.919 | Acc: 67.831% (32472/47872)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.858% (32572/48000)\n",
      "Train Epoch: 3 | Loss: 0.919 | Acc: 67.863% (32661/48128)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.880% (32756/48256)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.886% (32846/48384)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.874% (32927/48512)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.889% (33021/48640)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.874% (33101/48768)\n",
      "Train Epoch: 3 | Loss: 0.918 | Acc: 67.877% (33189/48896)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.889% (33282/49024)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.902% (33375/49152)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.910% (33466/49280)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.910% (33553/49408)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.930% (33650/49536)\n",
      "Train Epoch: 3 | Loss: 0.917 | Acc: 67.943% (33743/49664)\n",
      "Train Epoch: 3 | Loss: 0.916 | Acc: 67.961% (33839/49792)\n",
      "Train Epoch: 3 | Loss: 0.916 | Acc: 67.965% (33928/49920)\n",
      "Train Epoch: 3 | Loss: 0.916 | Acc: 67.966% (33983/50000)\n",
      "Test Epoch: 3 | Loss: 0.901 | Acc: 71.000% (71/100)\n",
      "Test Epoch: 3 | Loss: 0.917 | Acc: 69.500% (139/200)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.333% (208/300)\n",
      "Test Epoch: 3 | Loss: 0.869 | Acc: 70.750% (283/400)\n",
      "Test Epoch: 3 | Loss: 0.877 | Acc: 70.400% (352/500)\n",
      "Test Epoch: 3 | Loss: 0.833 | Acc: 71.500% (429/600)\n",
      "Test Epoch: 3 | Loss: 0.852 | Acc: 71.429% (500/700)\n",
      "Test Epoch: 3 | Loss: 0.872 | Acc: 70.250% (562/800)\n",
      "Test Epoch: 3 | Loss: 0.870 | Acc: 70.778% (637/900)\n",
      "Test Epoch: 3 | Loss: 0.862 | Acc: 71.100% (711/1000)\n",
      "Test Epoch: 3 | Loss: 0.862 | Acc: 71.364% (785/1100)\n",
      "Test Epoch: 3 | Loss: 0.867 | Acc: 71.417% (857/1200)\n",
      "Test Epoch: 3 | Loss: 0.864 | Acc: 71.077% (924/1300)\n",
      "Test Epoch: 3 | Loss: 0.865 | Acc: 70.714% (990/1400)\n",
      "Test Epoch: 3 | Loss: 0.861 | Acc: 70.533% (1058/1500)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 70.125% (1122/1600)\n",
      "Test Epoch: 3 | Loss: 0.879 | Acc: 70.235% (1194/1700)\n",
      "Test Epoch: 3 | Loss: 0.875 | Acc: 70.333% (1266/1800)\n",
      "Test Epoch: 3 | Loss: 0.874 | Acc: 70.579% (1341/1900)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 70.450% (1409/2000)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 70.000% (1470/2100)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 70.000% (1540/2200)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 70.174% (1614/2300)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.792% (1675/2400)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.680% (1742/2500)\n",
      "Test Epoch: 3 | Loss: 0.904 | Acc: 69.269% (1801/2600)\n",
      "Test Epoch: 3 | Loss: 0.903 | Acc: 69.111% (1866/2700)\n",
      "Test Epoch: 3 | Loss: 0.900 | Acc: 69.321% (1941/2800)\n",
      "Test Epoch: 3 | Loss: 0.897 | Acc: 69.483% (2015/2900)\n",
      "Test Epoch: 3 | Loss: 0.893 | Acc: 69.567% (2087/3000)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.452% (2153/3100)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.688% (2230/3200)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.636% (2298/3300)\n",
      "Test Epoch: 3 | Loss: 0.893 | Acc: 69.412% (2360/3400)\n",
      "Test Epoch: 3 | Loss: 0.899 | Acc: 69.229% (2423/3500)\n",
      "Test Epoch: 3 | Loss: 0.898 | Acc: 69.389% (2498/3600)\n",
      "Test Epoch: 3 | Loss: 0.903 | Acc: 69.297% (2564/3700)\n",
      "Test Epoch: 3 | Loss: 0.900 | Acc: 69.395% (2637/3800)\n",
      "Test Epoch: 3 | Loss: 0.897 | Acc: 69.462% (2709/3900)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.550% (2782/4000)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.512% (2850/4100)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.643% (2925/4200)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.907% (3006/4300)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.909% (3076/4400)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.822% (3142/4500)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.739% (3208/4600)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.830% (3282/4700)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.854% (3353/4800)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.776% (3419/4900)\n",
      "Test Epoch: 3 | Loss: 0.883 | Acc: 69.880% (3494/5000)\n",
      "Test Epoch: 3 | Loss: 0.880 | Acc: 69.902% (3565/5100)\n",
      "Test Epoch: 3 | Loss: 0.881 | Acc: 69.788% (3629/5200)\n",
      "Test Epoch: 3 | Loss: 0.882 | Acc: 69.698% (3694/5300)\n",
      "Test Epoch: 3 | Loss: 0.883 | Acc: 69.722% (3765/5400)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.636% (3830/5500)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.625% (3899/5600)\n",
      "Test Epoch: 3 | Loss: 0.887 | Acc: 69.579% (3966/5700)\n",
      "Test Epoch: 3 | Loss: 0.883 | Acc: 69.741% (4045/5800)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 69.644% (4109/5900)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.633% (4178/6000)\n",
      "Test Epoch: 3 | Loss: 0.890 | Acc: 69.574% (4244/6100)\n",
      "Test Epoch: 3 | Loss: 0.890 | Acc: 69.613% (4316/6200)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.619% (4386/6300)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.734% (4463/6400)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.692% (4530/6500)\n",
      "Test Epoch: 3 | Loss: 0.887 | Acc: 69.727% (4602/6600)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.776% (4675/6700)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.765% (4744/6800)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.841% (4819/6900)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 69.743% (4882/7000)\n",
      "Test Epoch: 3 | Loss: 0.887 | Acc: 69.789% (4955/7100)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.875% (5031/7200)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.959% (5107/7300)\n",
      "Test Epoch: 3 | Loss: 0.883 | Acc: 69.986% (5179/7400)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 70.040% (5253/7500)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.987% (5319/7600)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.935% (5385/7700)\n",
      "Test Epoch: 3 | Loss: 0.885 | Acc: 69.936% (5455/7800)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.975% (5528/7900)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.950% (5596/8000)\n",
      "Test Epoch: 3 | Loss: 0.883 | Acc: 70.049% (5674/8100)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.976% (5738/8200)\n",
      "Test Epoch: 3 | Loss: 0.884 | Acc: 69.988% (5809/8300)\n",
      "Test Epoch: 3 | Loss: 0.886 | Acc: 69.893% (5871/8400)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 69.835% (5936/8500)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 69.849% (6007/8600)\n",
      "Test Epoch: 3 | Loss: 0.888 | Acc: 69.828% (6075/8700)\n",
      "Test Epoch: 3 | Loss: 0.890 | Acc: 69.784% (6141/8800)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.753% (6208/8900)\n",
      "Test Epoch: 3 | Loss: 0.894 | Acc: 69.733% (6276/9000)\n",
      "Test Epoch: 3 | Loss: 0.895 | Acc: 69.714% (6344/9100)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.870% (6428/9200)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.892% (6500/9300)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.883% (6569/9400)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.832% (6634/9500)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.865% (6707/9600)\n",
      "Test Epoch: 3 | Loss: 0.890 | Acc: 69.918% (6782/9700)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.847% (6845/9800)\n",
      "Test Epoch: 3 | Loss: 0.891 | Acc: 69.889% (6919/9900)\n",
      "Test Epoch: 3 | Loss: 0.892 | Acc: 69.850% (6985/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Train Epoch: 4 | Loss: 0.873 | Acc: 68.750% (88/128)\n",
      "Train Epoch: 4 | Loss: 0.907 | Acc: 67.578% (173/256)\n",
      "Train Epoch: 4 | Loss: 0.863 | Acc: 69.271% (266/384)\n",
      "Train Epoch: 4 | Loss: 0.848 | Acc: 71.094% (364/512)\n",
      "Train Epoch: 4 | Loss: 0.835 | Acc: 71.250% (456/640)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.875% (552/768)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.429% (640/896)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.094% (728/1024)\n",
      "Train Epoch: 4 | Loss: 0.835 | Acc: 70.573% (813/1152)\n",
      "Train Epoch: 4 | Loss: 0.832 | Acc: 70.938% (908/1280)\n",
      "Train Epoch: 4 | Loss: 0.835 | Acc: 70.881% (998/1408)\n",
      "Train Epoch: 4 | Loss: 0.829 | Acc: 71.224% (1094/1536)\n",
      "Train Epoch: 4 | Loss: 0.839 | Acc: 70.974% (1181/1664)\n",
      "Train Epoch: 4 | Loss: 0.840 | Acc: 70.647% (1266/1792)\n",
      "Train Epoch: 4 | Loss: 0.845 | Acc: 70.260% (1349/1920)\n",
      "Train Epoch: 4 | Loss: 0.835 | Acc: 70.703% (1448/2048)\n",
      "Train Epoch: 4 | Loss: 0.832 | Acc: 70.818% (1541/2176)\n",
      "Train Epoch: 4 | Loss: 0.831 | Acc: 70.660% (1628/2304)\n",
      "Train Epoch: 4 | Loss: 0.842 | Acc: 70.148% (1706/2432)\n",
      "Train Epoch: 4 | Loss: 0.852 | Acc: 69.844% (1788/2560)\n",
      "Train Epoch: 4 | Loss: 0.851 | Acc: 69.792% (1876/2688)\n",
      "Train Epoch: 4 | Loss: 0.847 | Acc: 69.993% (1971/2816)\n",
      "Train Epoch: 4 | Loss: 0.845 | Acc: 70.177% (2066/2944)\n",
      "Train Epoch: 4 | Loss: 0.847 | Acc: 69.987% (2150/3072)\n",
      "Train Epoch: 4 | Loss: 0.847 | Acc: 69.938% (2238/3200)\n",
      "Train Epoch: 4 | Loss: 0.852 | Acc: 69.802% (2323/3328)\n",
      "Train Epoch: 4 | Loss: 0.853 | Acc: 69.705% (2409/3456)\n",
      "Train Epoch: 4 | Loss: 0.855 | Acc: 69.559% (2493/3584)\n",
      "Train Epoch: 4 | Loss: 0.855 | Acc: 69.693% (2587/3712)\n",
      "Train Epoch: 4 | Loss: 0.851 | Acc: 69.922% (2685/3840)\n",
      "Train Epoch: 4 | Loss: 0.848 | Acc: 69.934% (2775/3968)\n",
      "Train Epoch: 4 | Loss: 0.849 | Acc: 70.068% (2870/4096)\n",
      "Train Epoch: 4 | Loss: 0.847 | Acc: 70.076% (2960/4224)\n",
      "Train Epoch: 4 | Loss: 0.850 | Acc: 69.922% (3043/4352)\n",
      "Train Epoch: 4 | Loss: 0.848 | Acc: 69.911% (3132/4480)\n",
      "Train Epoch: 4 | Loss: 0.844 | Acc: 70.095% (3230/4608)\n",
      "Train Epoch: 4 | Loss: 0.839 | Acc: 70.312% (3330/4736)\n",
      "Train Epoch: 4 | Loss: 0.837 | Acc: 70.498% (3429/4864)\n",
      "Train Epoch: 4 | Loss: 0.840 | Acc: 70.373% (3513/4992)\n",
      "Train Epoch: 4 | Loss: 0.848 | Acc: 70.020% (3585/5120)\n",
      "Train Epoch: 4 | Loss: 0.847 | Acc: 70.103% (3679/5248)\n",
      "Train Epoch: 4 | Loss: 0.844 | Acc: 70.257% (3777/5376)\n",
      "Train Epoch: 4 | Loss: 0.841 | Acc: 70.422% (3876/5504)\n",
      "Train Epoch: 4 | Loss: 0.840 | Acc: 70.508% (3971/5632)\n",
      "Train Epoch: 4 | Loss: 0.840 | Acc: 70.521% (4062/5760)\n",
      "Train Epoch: 4 | Loss: 0.841 | Acc: 70.431% (4147/5888)\n",
      "Train Epoch: 4 | Loss: 0.842 | Acc: 70.412% (4236/6016)\n",
      "Train Epoch: 4 | Loss: 0.841 | Acc: 70.475% (4330/6144)\n",
      "Train Epoch: 4 | Loss: 0.837 | Acc: 70.599% (4428/6272)\n",
      "Train Epoch: 4 | Loss: 0.838 | Acc: 70.484% (4511/6400)\n",
      "Train Epoch: 4 | Loss: 0.836 | Acc: 70.512% (4603/6528)\n",
      "Train Epoch: 4 | Loss: 0.833 | Acc: 70.703% (4706/6656)\n",
      "Train Epoch: 4 | Loss: 0.832 | Acc: 70.637% (4792/6784)\n",
      "Train Epoch: 4 | Loss: 0.831 | Acc: 70.703% (4887/6912)\n",
      "Train Epoch: 4 | Loss: 0.831 | Acc: 70.696% (4977/7040)\n",
      "Train Epoch: 4 | Loss: 0.830 | Acc: 70.745% (5071/7168)\n",
      "Train Epoch: 4 | Loss: 0.829 | Acc: 70.874% (5171/7296)\n",
      "Train Epoch: 4 | Loss: 0.827 | Acc: 70.932% (5266/7424)\n",
      "Train Epoch: 4 | Loss: 0.827 | Acc: 70.882% (5353/7552)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.016% (5454/7680)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.055% (5548/7808)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.031% (5637/7936)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.032% (5728/8064)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.021% (5818/8192)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 70.998% (5907/8320)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 70.975% (5996/8448)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 70.977% (6087/8576)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 70.875% (6169/8704)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 70.913% (6263/8832)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.016% (6363/8960)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 70.962% (6449/9088)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 70.898% (6534/9216)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.008% (6635/9344)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.041% (6729/9472)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 70.990% (6815/9600)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.073% (6914/9728)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.175% (7015/9856)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.154% (7104/9984)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.025% (7182/10112)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.133% (7284/10240)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.181% (7380/10368)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.170% (7470/10496)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.160% (7560/10624)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.177% (7653/10752)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.057% (7731/10880)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.012% (7817/11008)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.058% (7913/11136)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 70.978% (7995/11264)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 70.945% (8082/11392)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 70.981% (8177/11520)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.068% (8278/11648)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.068% (8369/11776)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.136% (8468/11904)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.119% (8557/12032)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.135% (8650/12160)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.175% (8746/12288)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.198% (8840/12416)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.158% (8926/12544)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.157% (9017/12672)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.133% (9105/12800)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.187% (9203/12928)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.216% (9298/13056)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.245% (9393/13184)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.274% (9488/13312)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.324% (9586/13440)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.300% (9674/13568)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.379% (9776/13696)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.448% (9877/13824)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.416% (9964/13952)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.435% (10058/14080)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.516% (10161/14208)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.547% (10257/14336)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.592% (10355/14464)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.560% (10442/14592)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.556% (10533/14720)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.532% (10621/14848)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.521% (10711/14976)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.498% (10799/15104)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.442% (10882/15232)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.393% (10966/15360)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.333% (11048/15488)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.350% (11142/15616)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.361% (11235/15744)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.333% (11322/15872)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.344% (11415/16000)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.342% (11506/16128)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.371% (11602/16256)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.381% (11695/16384)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.391% (11788/16512)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.358% (11874/16640)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.416% (11975/16768)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.407% (12065/16896)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.393% (12154/17024)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.368% (12241/17152)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.360% (12331/17280)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.341% (12419/17408)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.350% (12512/17536)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.264% (12588/17664)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.319% (12689/17792)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.317% (12780/17920)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.310% (12870/18048)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.319% (12963/18176)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.307% (13052/18304)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.294% (13141/18432)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.298% (13233/18560)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.302% (13325/18688)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.301% (13416/18816)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.326% (13512/18944)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.356% (13609/19072)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.333% (13696/19200)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.342% (13789/19328)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.320% (13876/19456)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.308% (13965/19584)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.281% (14051/19712)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.270% (14140/19840)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.299% (14237/19968)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.318% (14332/20096)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.267% (14413/20224)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.256% (14502/20352)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.230% (14588/20480)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.249% (14683/20608)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.291% (14783/20736)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.285% (14873/20864)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.241% (14955/20992)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.222% (15042/21120)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.197% (15128/21248)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.187% (15217/21376)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.168% (15304/21504)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.172% (15396/21632)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.172% (15487/21760)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.181% (15580/21888)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.157% (15666/22016)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.121% (15749/22144)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.125% (15841/22272)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.152% (15938/22400)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.125% (16023/22528)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.142% (16118/22656)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.146% (16210/22784)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.124% (16296/22912)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.124% (16387/23040)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.154% (16485/23168)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.180% (16582/23296)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.179% (16673/23424)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.200% (16769/23552)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.208% (16862/23680)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.178% (16946/23808)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.161% (17033/23936)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.131% (17117/24064)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.131% (17208/24192)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.094% (17290/24320)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.098% (17382/24448)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.110% (17476/24576)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.114% (17568/24704)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.130% (17663/24832)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.106% (17748/24960)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.122% (17843/25088)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.102% (17929/25216)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.086% (18016/25344)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.082% (18106/25472)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.086% (18198/25600)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.074% (18286/25728)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.078% (18378/25856)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.075% (18468/25984)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.101% (18566/26112)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.109% (18659/26240)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.109% (18750/26368)\n",
      "Train Epoch: 4 | Loss: 0.826 | Acc: 71.105% (18840/26496)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.113% (18933/26624)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.131% (19029/26752)\n",
      "Train Epoch: 4 | Loss: 0.825 | Acc: 71.161% (19128/26880)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.186% (19226/27008)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.193% (19319/27136)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.193% (19410/27264)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.236% (19513/27392)\n",
      "Train Epoch: 4 | Loss: 0.824 | Acc: 71.214% (19598/27520)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.231% (19694/27648)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.241% (19788/27776)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.241% (19879/27904)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.254% (19974/28032)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.218% (20055/28160)\n",
      "Train Epoch: 4 | Loss: 0.823 | Acc: 71.253% (20156/28288)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.266% (20251/28416)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.276% (20345/28544)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.289% (20440/28672)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.302% (20535/28800)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.315% (20630/28928)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.328% (20725/29056)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.354% (20824/29184)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.353% (20915/29312)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.382% (21015/29440)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.381% (21106/29568)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.383% (21198/29696)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.402% (21295/29824)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.401% (21386/29952)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.383% (21472/30080)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.372% (21560/30208)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.367% (21650/30336)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.366% (21741/30464)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.378% (21836/30592)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.393% (21932/30720)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.369% (22016/30848)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.413% (22121/30976)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.412% (22212/31104)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.417% (22305/31232)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.384% (22386/31360)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.361% (22470/31488)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.385% (22569/31616)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.339% (22646/31744)\n",
      "Train Epoch: 4 | Loss: 0.822 | Acc: 71.332% (22735/31872)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.369% (22838/32000)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.368% (22929/32128)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.367% (23020/32256)\n",
      "Train Epoch: 4 | Loss: 0.821 | Acc: 71.359% (23109/32384)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.386% (23209/32512)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.400% (23305/32640)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.417% (23402/32768)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.416% (23493/32896)\n",
      "Train Epoch: 4 | Loss: 0.820 | Acc: 71.403% (23580/33024)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.413% (23675/33152)\n",
      "Train Epoch: 4 | Loss: 0.819 | Acc: 71.442% (23776/33280)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.435% (23865/33408)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.455% (23963/33536)\n",
      "Train Epoch: 4 | Loss: 0.818 | Acc: 71.465% (24058/33664)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.467% (24150/33792)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.471% (24243/33920)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.461% (24331/34048)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.474% (24427/34176)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.458% (24513/34304)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.457% (24604/34432)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.453% (24694/34560)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.480% (24795/34688)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.484% (24888/34816)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.471% (24975/34944)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.462% (25063/35072)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.472% (25158/35200)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.479% (25252/35328)\n",
      "Train Epoch: 4 | Loss: 0.817 | Acc: 71.463% (25338/35456)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.487% (25438/35584)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.480% (25527/35712)\n",
      "Train Epoch: 4 | Loss: 0.816 | Acc: 71.490% (25622/35840)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.508% (25720/35968)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.504% (25810/36096)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.505% (25902/36224)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.506% (25994/36352)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.543% (26099/36480)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.542% (26190/36608)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.524% (26275/36736)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.525% (26367/36864)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.513% (26454/36992)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.517% (26547/37120)\n",
      "Train Epoch: 4 | Loss: 0.815 | Acc: 71.521% (26640/37248)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.511% (26728/37376)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.523% (26824/37504)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.524% (26916/37632)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.528% (27009/37760)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.529% (27101/37888)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.538% (27196/38016)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.558% (27295/38144)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.580% (27395/38272)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.576% (27485/38400)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.571% (27575/38528)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.562% (27663/38656)\n",
      "Train Epoch: 4 | Loss: 0.814 | Acc: 71.545% (27748/38784)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.556% (27844/38912)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.568% (27940/39040)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.558% (28028/39168)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.562% (28121/39296)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.555% (28210/39424)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.541% (28296/39552)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.540% (28387/39680)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.541% (28479/39808)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.527% (28565/39936)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.546% (28664/40064)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.549% (28757/40192)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.577% (28860/40320)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.571% (28949/40448)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.567% (29039/40576)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.565% (29130/40704)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.554% (29217/40832)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.562% (29312/40960)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.568% (29406/41088)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.564% (29496/41216)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.546% (29580/41344)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.545% (29671/41472)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.546% (29763/41600)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.551% (29857/41728)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.548% (29947/41856)\n",
      "Train Epoch: 4 | Loss: 0.813 | Acc: 71.563% (30045/41984)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.566% (30138/42112)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.572% (30232/42240)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.592% (30332/42368)\n",
      "Train Epoch: 4 | Loss: 0.812 | Acc: 71.593% (30424/42496)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.617% (30526/42624)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.643% (30629/42752)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.625% (30713/42880)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.612% (30799/43008)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.613% (30891/43136)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.621% (30986/43264)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.640% (31086/43392)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.668% (31190/43520)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.641% (31270/43648)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.640% (31361/43776)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.645% (31455/43904)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.646% (31547/44032)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.642% (31637/44160)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.670% (31741/44288)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.657% (31827/44416)\n",
      "Train Epoch: 4 | Loss: 0.811 | Acc: 71.655% (31918/44544)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.674% (32018/44672)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.690% (32117/44800)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.699% (32213/44928)\n",
      "Train Epoch: 4 | Loss: 0.810 | Acc: 71.691% (32301/45056)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.709% (32401/45184)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.729% (32502/45312)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.745% (32601/45440)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.739% (32690/45568)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.724% (32775/45696)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.720% (32865/45824)\n",
      "Train Epoch: 4 | Loss: 0.809 | Acc: 71.703% (32949/45952)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.723% (33050/46080)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.741% (33150/46208)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.739% (33241/46336)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.754% (33340/46464)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.772% (33440/46592)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.779% (33535/46720)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.787% (33631/46848)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.781% (33720/46976)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.782% (33812/47104)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.778% (33902/47232)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.776% (33993/47360)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.789% (34091/47488)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.772% (34175/47616)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.772% (34267/47744)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.773% (34359/47872)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.787% (34458/48000)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.800% (34556/48128)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.784% (34640/48256)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.772% (34726/48384)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.770% (34817/48512)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.774% (34911/48640)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.799% (35015/48768)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.808% (35111/48896)\n",
      "Train Epoch: 4 | Loss: 0.808 | Acc: 71.800% (35199/49024)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.826% (35304/49152)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.826% (35396/49280)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.835% (35492/49408)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.837% (35585/49536)\n",
      "Train Epoch: 4 | Loss: 0.807 | Acc: 71.859% (35688/49664)\n",
      "Train Epoch: 4 | Loss: 0.806 | Acc: 71.871% (35786/49792)\n",
      "Train Epoch: 4 | Loss: 0.806 | Acc: 71.877% (35881/49920)\n",
      "Train Epoch: 4 | Loss: 0.806 | Acc: 71.874% (35937/50000)\n",
      "Test Epoch: 4 | Loss: 0.761 | Acc: 75.000% (75/100)\n",
      "Test Epoch: 4 | Loss: 0.807 | Acc: 71.500% (143/200)\n",
      "Test Epoch: 4 | Loss: 0.882 | Acc: 71.667% (215/300)\n",
      "Test Epoch: 4 | Loss: 0.886 | Acc: 71.250% (285/400)\n",
      "Test Epoch: 4 | Loss: 0.889 | Acc: 71.200% (356/500)\n",
      "Test Epoch: 4 | Loss: 0.842 | Acc: 72.667% (436/600)\n",
      "Test Epoch: 4 | Loss: 0.862 | Acc: 72.143% (505/700)\n",
      "Test Epoch: 4 | Loss: 0.897 | Acc: 71.000% (568/800)\n",
      "Test Epoch: 4 | Loss: 0.922 | Acc: 70.333% (633/900)\n",
      "Test Epoch: 4 | Loss: 0.914 | Acc: 70.500% (705/1000)\n",
      "Test Epoch: 4 | Loss: 0.904 | Acc: 71.000% (781/1100)\n",
      "Test Epoch: 4 | Loss: 0.915 | Acc: 70.917% (851/1200)\n",
      "Test Epoch: 4 | Loss: 0.914 | Acc: 70.462% (916/1300)\n",
      "Test Epoch: 4 | Loss: 0.914 | Acc: 70.429% (986/1400)\n",
      "Test Epoch: 4 | Loss: 0.920 | Acc: 70.200% (1053/1500)\n",
      "Test Epoch: 4 | Loss: 0.946 | Acc: 69.688% (1115/1600)\n",
      "Test Epoch: 4 | Loss: 0.945 | Acc: 69.588% (1183/1700)\n",
      "Test Epoch: 4 | Loss: 0.951 | Acc: 69.278% (1247/1800)\n",
      "Test Epoch: 4 | Loss: 0.942 | Acc: 69.684% (1324/1900)\n",
      "Test Epoch: 4 | Loss: 0.952 | Acc: 69.550% (1391/2000)\n",
      "Test Epoch: 4 | Loss: 0.954 | Acc: 69.429% (1458/2100)\n",
      "Test Epoch: 4 | Loss: 0.953 | Acc: 69.273% (1524/2200)\n",
      "Test Epoch: 4 | Loss: 0.953 | Acc: 69.435% (1597/2300)\n",
      "Test Epoch: 4 | Loss: 0.956 | Acc: 69.250% (1662/2400)\n",
      "Test Epoch: 4 | Loss: 0.953 | Acc: 69.200% (1730/2500)\n",
      "Test Epoch: 4 | Loss: 0.970 | Acc: 69.038% (1795/2600)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.889% (1860/2700)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.893% (1929/2800)\n",
      "Test Epoch: 4 | Loss: 0.961 | Acc: 69.069% (2003/2900)\n",
      "Test Epoch: 4 | Loss: 0.956 | Acc: 69.167% (2075/3000)\n",
      "Test Epoch: 4 | Loss: 0.957 | Acc: 69.129% (2143/3100)\n",
      "Test Epoch: 4 | Loss: 0.959 | Acc: 69.031% (2209/3200)\n",
      "Test Epoch: 4 | Loss: 0.960 | Acc: 69.030% (2278/3300)\n",
      "Test Epoch: 4 | Loss: 0.963 | Acc: 68.735% (2337/3400)\n",
      "Test Epoch: 4 | Loss: 0.971 | Acc: 68.571% (2400/3500)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.583% (2469/3600)\n",
      "Test Epoch: 4 | Loss: 0.971 | Acc: 68.324% (2528/3700)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.474% (2602/3800)\n",
      "Test Epoch: 4 | Loss: 0.964 | Acc: 68.538% (2673/3900)\n",
      "Test Epoch: 4 | Loss: 0.959 | Acc: 68.675% (2747/4000)\n",
      "Test Epoch: 4 | Loss: 0.958 | Acc: 68.707% (2817/4100)\n",
      "Test Epoch: 4 | Loss: 0.959 | Acc: 68.714% (2886/4200)\n",
      "Test Epoch: 4 | Loss: 0.955 | Acc: 68.814% (2959/4300)\n",
      "Test Epoch: 4 | Loss: 0.954 | Acc: 68.977% (3035/4400)\n",
      "Test Epoch: 4 | Loss: 0.954 | Acc: 68.822% (3097/4500)\n",
      "Test Epoch: 4 | Loss: 0.956 | Acc: 68.630% (3157/4600)\n",
      "Test Epoch: 4 | Loss: 0.958 | Acc: 68.638% (3226/4700)\n",
      "Test Epoch: 4 | Loss: 0.959 | Acc: 68.667% (3296/4800)\n",
      "Test Epoch: 4 | Loss: 0.958 | Acc: 68.816% (3372/4900)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.740% (3437/5000)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.667% (3502/5100)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.577% (3566/5200)\n",
      "Test Epoch: 4 | Loss: 0.969 | Acc: 68.528% (3632/5300)\n",
      "Test Epoch: 4 | Loss: 0.970 | Acc: 68.611% (3705/5400)\n",
      "Test Epoch: 4 | Loss: 0.970 | Acc: 68.564% (3771/5500)\n",
      "Test Epoch: 4 | Loss: 0.972 | Acc: 68.589% (3841/5600)\n",
      "Test Epoch: 4 | Loss: 0.971 | Acc: 68.684% (3915/5700)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.724% (3986/5800)\n",
      "Test Epoch: 4 | Loss: 0.973 | Acc: 68.542% (4044/5900)\n",
      "Test Epoch: 4 | Loss: 0.974 | Acc: 68.467% (4108/6000)\n",
      "Test Epoch: 4 | Loss: 0.975 | Acc: 68.393% (4172/6100)\n",
      "Test Epoch: 4 | Loss: 0.976 | Acc: 68.419% (4242/6200)\n",
      "Test Epoch: 4 | Loss: 0.973 | Acc: 68.444% (4312/6300)\n",
      "Test Epoch: 4 | Loss: 0.972 | Acc: 68.500% (4384/6400)\n",
      "Test Epoch: 4 | Loss: 0.974 | Acc: 68.446% (4449/6500)\n",
      "Test Epoch: 4 | Loss: 0.971 | Acc: 68.515% (4522/6600)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.522% (4591/6700)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.588% (4664/6800)\n",
      "Test Epoch: 4 | Loss: 0.969 | Acc: 68.594% (4733/6900)\n",
      "Test Epoch: 4 | Loss: 0.972 | Acc: 68.486% (4794/7000)\n",
      "Test Epoch: 4 | Loss: 0.970 | Acc: 68.535% (4866/7100)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.583% (4938/7200)\n",
      "Test Epoch: 4 | Loss: 0.966 | Acc: 68.575% (5006/7300)\n",
      "Test Epoch: 4 | Loss: 0.964 | Acc: 68.649% (5080/7400)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.627% (5147/7500)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.553% (5210/7600)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.558% (5279/7700)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.551% (5347/7800)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.532% (5414/7900)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.525% (5482/8000)\n",
      "Test Epoch: 4 | Loss: 0.964 | Acc: 68.593% (5556/8100)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.549% (5621/8200)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.542% (5689/8300)\n",
      "Test Epoch: 4 | Loss: 0.969 | Acc: 68.476% (5752/8400)\n",
      "Test Epoch: 4 | Loss: 0.970 | Acc: 68.412% (5815/8500)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.477% (5889/8600)\n",
      "Test Epoch: 4 | Loss: 0.969 | Acc: 68.368% (5948/8700)\n",
      "Test Epoch: 4 | Loss: 0.967 | Acc: 68.443% (6023/8800)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.427% (6090/8900)\n",
      "Test Epoch: 4 | Loss: 0.969 | Acc: 68.322% (6149/9000)\n",
      "Test Epoch: 4 | Loss: 0.968 | Acc: 68.352% (6220/9100)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.435% (6296/9200)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.484% (6369/9300)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.500% (6439/9400)\n",
      "Test Epoch: 4 | Loss: 0.965 | Acc: 68.505% (6508/9500)\n",
      "Test Epoch: 4 | Loss: 0.962 | Acc: 68.604% (6586/9600)\n",
      "Test Epoch: 4 | Loss: 0.959 | Acc: 68.691% (6663/9700)\n",
      "Test Epoch: 4 | Loss: 0.960 | Acc: 68.633% (6726/9800)\n",
      "Test Epoch: 4 | Loss: 0.960 | Acc: 68.667% (6798/9900)\n",
      "Test Epoch: 4 | Loss: 0.961 | Acc: 68.610% (6861/10000)\n",
      "\n",
      "Epoch: 5\n",
      "Train Epoch: 5 | Loss: 0.753 | Acc: 75.000% (96/128)\n",
      "Train Epoch: 5 | Loss: 0.807 | Acc: 72.656% (186/256)\n",
      "Train Epoch: 5 | Loss: 0.780 | Acc: 72.396% (278/384)\n",
      "Train Epoch: 5 | Loss: 0.828 | Acc: 70.312% (360/512)\n",
      "Train Epoch: 5 | Loss: 0.826 | Acc: 70.156% (449/640)\n",
      "Train Epoch: 5 | Loss: 0.852 | Acc: 69.661% (535/768)\n",
      "Train Epoch: 5 | Loss: 0.838 | Acc: 70.312% (630/896)\n",
      "Train Epoch: 5 | Loss: 0.857 | Acc: 70.020% (717/1024)\n",
      "Train Epoch: 5 | Loss: 0.854 | Acc: 69.618% (802/1152)\n",
      "Train Epoch: 5 | Loss: 0.843 | Acc: 70.312% (900/1280)\n",
      "Train Epoch: 5 | Loss: 0.815 | Acc: 71.165% (1002/1408)\n",
      "Train Epoch: 5 | Loss: 0.800 | Acc: 71.745% (1102/1536)\n",
      "Train Epoch: 5 | Loss: 0.796 | Acc: 71.935% (1197/1664)\n",
      "Train Epoch: 5 | Loss: 0.793 | Acc: 71.763% (1286/1792)\n",
      "Train Epoch: 5 | Loss: 0.791 | Acc: 72.031% (1383/1920)\n",
      "Train Epoch: 5 | Loss: 0.795 | Acc: 72.119% (1477/2048)\n",
      "Train Epoch: 5 | Loss: 0.793 | Acc: 72.289% (1573/2176)\n",
      "Train Epoch: 5 | Loss: 0.783 | Acc: 72.569% (1672/2304)\n",
      "Train Epoch: 5 | Loss: 0.788 | Acc: 72.492% (1763/2432)\n",
      "Train Epoch: 5 | Loss: 0.783 | Acc: 72.734% (1862/2560)\n",
      "Train Epoch: 5 | Loss: 0.788 | Acc: 72.359% (1945/2688)\n",
      "Train Epoch: 5 | Loss: 0.783 | Acc: 72.763% (2049/2816)\n",
      "Train Epoch: 5 | Loss: 0.775 | Acc: 72.996% (2149/2944)\n",
      "Train Epoch: 5 | Loss: 0.771 | Acc: 73.112% (2246/3072)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.094% (2339/3200)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.017% (2430/3328)\n",
      "Train Epoch: 5 | Loss: 0.767 | Acc: 73.148% (2528/3456)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.465% (2633/3584)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.276% (2720/3712)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.411% (2819/3840)\n",
      "Train Epoch: 5 | Loss: 0.763 | Acc: 73.412% (2913/3968)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.560% (3013/4096)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.556% (3107/4224)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.529% (3200/4352)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.638% (3299/4480)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.676% (3395/4608)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.501% (3481/4736)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 73.540% (3577/4864)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.518% (3670/4992)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.418% (3759/5120)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.476% (3856/5248)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.438% (3948/5376)\n",
      "Train Epoch: 5 | Loss: 0.770 | Acc: 73.347% (4037/5504)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.455% (4137/5632)\n",
      "Train Epoch: 5 | Loss: 0.767 | Acc: 73.403% (4228/5760)\n",
      "Train Epoch: 5 | Loss: 0.767 | Acc: 73.438% (4324/5888)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.471% (4420/6016)\n",
      "Train Epoch: 5 | Loss: 0.769 | Acc: 73.307% (4504/6144)\n",
      "Train Epoch: 5 | Loss: 0.769 | Acc: 73.310% (4598/6272)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.453% (4701/6400)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.361% (4789/6528)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.407% (4886/6656)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.349% (4976/6784)\n",
      "Train Epoch: 5 | Loss: 0.771 | Acc: 73.278% (5065/6912)\n",
      "Train Epoch: 5 | Loss: 0.769 | Acc: 73.310% (5161/7040)\n",
      "Train Epoch: 5 | Loss: 0.769 | Acc: 73.284% (5253/7168)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.300% (5348/7296)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.330% (5444/7424)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.252% (5532/7552)\n",
      "Train Epoch: 5 | Loss: 0.768 | Acc: 73.216% (5623/7680)\n",
      "Train Epoch: 5 | Loss: 0.767 | Acc: 73.258% (5720/7808)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.324% (5819/7936)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.363% (5916/8064)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.450% (6017/8192)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.365% (6104/8320)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.366% (6198/8448)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.426% (6297/8576)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.449% (6393/8704)\n",
      "Train Epoch: 5 | Loss: 0.757 | Acc: 73.494% (6491/8832)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.382% (6575/8960)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.371% (6668/9088)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.438% (6768/9216)\n",
      "Train Epoch: 5 | Loss: 0.757 | Acc: 73.480% (6866/9344)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.480% (6960/9472)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.458% (7052/9600)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.489% (7149/9728)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.509% (7245/9856)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.427% (7331/9984)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.348% (7417/10112)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.369% (7513/10240)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.380% (7608/10368)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.323% (7696/10496)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.287% (7786/10624)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.205% (7871/10752)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.162% (7960/10880)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.138% (8051/11008)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.168% (8148/11136)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.162% (8241/11264)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.165% (8335/11392)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.238% (8437/11520)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.257% (8533/11648)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.268% (8628/11776)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.253% (8720/11904)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.205% (8808/12032)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.207% (8902/12160)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.193% (8994/12288)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.139% (9081/12416)\n",
      "Train Epoch: 5 | Loss: 0.763 | Acc: 73.063% (9165/12544)\n",
      "Train Epoch: 5 | Loss: 0.763 | Acc: 73.067% (9259/12672)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 73.031% (9348/12800)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 73.012% (9439/12928)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.009% (9532/13056)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 73.005% (9625/13184)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 73.009% (9719/13312)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.006% (9812/13440)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.010% (9906/13568)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 73.029% (10002/13696)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.982% (10089/13824)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.950% (10178/13952)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.962% (10273/14080)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.966% (10367/14208)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.977% (10462/14336)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.954% (10552/14464)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.999% (10652/14592)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 73.010% (10747/14720)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.932% (10829/14848)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.917% (10920/14976)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.881% (11008/15104)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.899% (11104/15232)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.910% (11199/15360)\n",
      "Train Epoch: 5 | Loss: 0.766 | Acc: 72.818% (11278/15488)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.880% (11381/15616)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.879% (11474/15744)\n",
      "Train Epoch: 5 | Loss: 0.765 | Acc: 72.889% (11569/15872)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.894% (11663/16000)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.910% (11759/16128)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.865% (11845/16256)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.913% (11946/16384)\n",
      "Train Epoch: 5 | Loss: 0.764 | Acc: 72.935% (12043/16512)\n",
      "Train Epoch: 5 | Loss: 0.763 | Acc: 72.951% (12139/16640)\n",
      "Train Epoch: 5 | Loss: 0.763 | Acc: 72.937% (12230/16768)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 72.994% (12333/16896)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 73.015% (12430/17024)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.024% (12525/17152)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.027% (12619/17280)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.053% (12717/17408)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.050% (12810/17536)\n",
      "Train Epoch: 5 | Loss: 0.760 | Acc: 73.030% (12900/17664)\n",
      "Train Epoch: 5 | Loss: 0.762 | Acc: 72.988% (12986/17792)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 72.991% (13080/17920)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.000% (13175/18048)\n",
      "Train Epoch: 5 | Loss: 0.761 | Acc: 73.019% (13272/18176)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.121% (13384/18304)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.117% (13477/18432)\n",
      "Train Epoch: 5 | Loss: 0.759 | Acc: 73.136% (13574/18560)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.170% (13674/18688)\n",
      "Train Epoch: 5 | Loss: 0.758 | Acc: 73.230% (13779/18816)\n",
      "Train Epoch: 5 | Loss: 0.756 | Acc: 73.290% (13884/18944)\n",
      "Train Epoch: 5 | Loss: 0.756 | Acc: 73.291% (13978/19072)\n",
      "Train Epoch: 5 | Loss: 0.756 | Acc: 73.276% (14069/19200)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.308% (14169/19328)\n",
      "Train Epoch: 5 | Loss: 0.756 | Acc: 73.288% (14259/19456)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.340% (14363/19584)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.372% (14463/19712)\n",
      "Train Epoch: 5 | Loss: 0.754 | Acc: 73.392% (14561/19840)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.372% (14651/19968)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.368% (14744/20096)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.373% (14839/20224)\n",
      "Train Epoch: 5 | Loss: 0.755 | Acc: 73.423% (14943/20352)\n",
      "Train Epoch: 5 | Loss: 0.754 | Acc: 73.428% (15038/20480)\n",
      "Train Epoch: 5 | Loss: 0.753 | Acc: 73.467% (15140/20608)\n",
      "Train Epoch: 5 | Loss: 0.753 | Acc: 73.491% (15239/20736)\n",
      "Train Epoch: 5 | Loss: 0.752 | Acc: 73.481% (15331/20864)\n",
      "Train Epoch: 5 | Loss: 0.752 | Acc: 73.480% (15425/20992)\n",
      "Train Epoch: 5 | Loss: 0.751 | Acc: 73.527% (15529/21120)\n",
      "Train Epoch: 5 | Loss: 0.752 | Acc: 73.536% (15625/21248)\n",
      "Train Epoch: 5 | Loss: 0.751 | Acc: 73.559% (15724/21376)\n",
      "Train Epoch: 5 | Loss: 0.751 | Acc: 73.582% (15823/21504)\n",
      "Train Epoch: 5 | Loss: 0.750 | Acc: 73.599% (15921/21632)\n",
      "Train Epoch: 5 | Loss: 0.750 | Acc: 73.603% (16016/21760)\n",
      "Train Epoch: 5 | Loss: 0.750 | Acc: 73.597% (16109/21888)\n",
      "Train Epoch: 5 | Loss: 0.750 | Acc: 73.587% (16201/22016)\n",
      "Train Epoch: 5 | Loss: 0.750 | Acc: 73.596% (16297/22144)\n",
      "Train Epoch: 5 | Loss: 0.749 | Acc: 73.617% (16396/22272)\n",
      "Train Epoch: 5 | Loss: 0.749 | Acc: 73.634% (16494/22400)\n",
      "Train Epoch: 5 | Loss: 0.749 | Acc: 73.624% (16586/22528)\n",
      "Train Epoch: 5 | Loss: 0.749 | Acc: 73.649% (16686/22656)\n",
      "Train Epoch: 5 | Loss: 0.748 | Acc: 73.683% (16788/22784)\n",
      "Train Epoch: 5 | Loss: 0.748 | Acc: 73.704% (16887/22912)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.737% (16989/23040)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.757% (17088/23168)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.794% (17191/23296)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.796% (17286/23424)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.803% (17382/23552)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.830% (17483/23680)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.824% (17576/23808)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.839% (17674/23936)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.791% (17757/24064)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.772% (17847/24192)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.795% (17947/24320)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.806% (18044/24448)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.812% (18140/24576)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.769% (18224/24704)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.736% (18310/24832)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.742% (18406/24960)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.732% (18498/25088)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.779% (18604/25216)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.777% (18698/25344)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.767% (18790/25472)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.773% (18886/25600)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.752% (18975/25728)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.747% (19068/25856)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.734% (19159/25984)\n",
      "Train Epoch: 5 | Loss: 0.747 | Acc: 73.736% (19254/26112)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.765% (19356/26240)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.802% (19460/26368)\n",
      "Train Epoch: 5 | Loss: 0.746 | Acc: 73.804% (19555/26496)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.806% (19650/26624)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.819% (19748/26752)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.802% (19838/26880)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.823% (19938/27008)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.788% (20023/27136)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.797% (20120/27264)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.810% (20218/27392)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.805% (20311/27520)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.810% (20407/27648)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.830% (20507/27776)\n",
      "Train Epoch: 5 | Loss: 0.745 | Acc: 73.799% (20593/27904)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.816% (20692/28032)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.807% (20784/28160)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.848% (20890/28288)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.842% (20983/28416)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.858% (21082/28544)\n",
      "Train Epoch: 5 | Loss: 0.743 | Acc: 73.873% (21181/28672)\n",
      "Train Epoch: 5 | Loss: 0.743 | Acc: 73.868% (21274/28800)\n",
      "Train Epoch: 5 | Loss: 0.743 | Acc: 73.883% (21373/28928)\n",
      "Train Epoch: 5 | Loss: 0.743 | Acc: 73.878% (21466/29056)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.876% (21560/29184)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.891% (21659/29312)\n",
      "Train Epoch: 5 | Loss: 0.744 | Acc: 73.882% (21751/29440)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.928% (21859/29568)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.922% (21952/29696)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.937% (22051/29824)\n",
      "Train Epoch: 5 | Loss: 0.743 | Acc: 73.935% (22145/29952)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.959% (22247/30080)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.957% (22341/30208)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.981% (22443/30336)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.979% (22537/30464)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.987% (22634/30592)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 74.004% (22734/30720)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.998% (22827/30848)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.996% (22921/30976)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 74.019% (23023/31104)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.027% (23120/31232)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 74.008% (23209/31360)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.022% (23308/31488)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.001% (23396/31616)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.001% (23491/31744)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.983% (23580/31872)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.978% (23673/32000)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.985% (23770/32128)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.955% (23855/32256)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.938% (23944/32384)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.933% (24037/32512)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.931% (24131/32640)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.950% (24232/32768)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.957% (24329/32896)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.946% (24420/33024)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.974% (24524/33152)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.963% (24615/33280)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.961% (24709/33408)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.962% (24804/33536)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.978% (24904/33664)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.982% (25000/33792)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.989% (25097/33920)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.004% (25197/34048)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.008% (25293/34176)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.003% (25386/34304)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.010% (25483/34432)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.999% (25574/34560)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.994% (25667/34688)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.975% (25755/34816)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.967% (25847/34944)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.971% (25943/35072)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.960% (26034/35200)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.967% (26131/35328)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.971% (26227/35456)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.971% (26322/35584)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.972% (26417/35712)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.984% (26516/35840)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.988% (26612/35968)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.992% (26708/36096)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.979% (26798/36224)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.993% (26898/36352)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.983% (26989/36480)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.003% (27091/36608)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.017% (27191/36736)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.045% (27296/36864)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.038% (27388/36992)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.025% (27478/37120)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.023% (27572/37248)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.007% (27661/37376)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.981% (27746/37504)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.958% (27832/37632)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.962% (27928/37760)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.963% (28023/37888)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.937% (28108/38016)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.946% (28206/38144)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.965% (28308/38272)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.945% (28395/38400)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.962% (28496/38528)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.947% (28585/38656)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.961% (28685/38784)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.949% (28775/38912)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.950% (28870/39040)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.948% (28964/39168)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.939% (29055/39296)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.922% (29143/39424)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.923% (29238/39552)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.919% (29331/39680)\n",
      "Train Epoch: 5 | Loss: 0.742 | Acc: 73.920% (29426/39808)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.928% (29524/39936)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.932% (29620/40064)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.945% (29720/40192)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.953% (29818/40320)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.962% (29916/40448)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.975% (30016/40576)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.956% (30103/40704)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.966% (30202/40832)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.950% (30290/40960)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.951% (30385/41088)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.952% (30480/41216)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.965% (30580/41344)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.968% (30676/41472)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.954% (30765/41600)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.965% (30864/41728)\n",
      "Train Epoch: 5 | Loss: 0.741 | Acc: 73.963% (30958/41856)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.985% (31062/41984)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.986% (31157/42112)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.994% (31255/42240)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.018% (31360/42368)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.016% (31454/42496)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.019% (31550/42624)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.029% (31649/42752)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.025% (31742/42880)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.021% (31835/43008)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.005% (31923/43136)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.001% (32016/43264)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 73.995% (32108/43392)\n",
      "Train Epoch: 5 | Loss: 0.740 | Acc: 74.003% (32206/43520)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.017% (32307/43648)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.022% (32404/43776)\n",
      "Train Epoch: 5 | Loss: 0.739 | Acc: 74.055% (32513/43904)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.062% (32611/44032)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.081% (32714/44160)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.088% (32812/44288)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.093% (32909/44416)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.089% (33002/44544)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.105% (33104/44672)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.107% (33200/44800)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.105% (33294/44928)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.103% (33388/45056)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.108% (33485/45184)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.106% (33579/45312)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.113% (33677/45440)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.127% (33778/45568)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.112% (33866/45696)\n",
      "Train Epoch: 5 | Loss: 0.738 | Acc: 74.112% (33961/45824)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.125% (34062/45952)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.134% (34161/46080)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.134% (34256/46208)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.135% (34351/46336)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.139% (34448/46464)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.146% (34546/46592)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.150% (34643/46720)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.155% (34740/46848)\n",
      "Train Epoch: 5 | Loss: 0.737 | Acc: 74.155% (34835/46976)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.151% (34928/47104)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.162% (35028/47232)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.158% (35121/47360)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.160% (35217/47488)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.175% (35319/47616)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.158% (35406/47744)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.169% (35506/47872)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.173% (35603/48000)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.183% (35703/48128)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.192% (35802/48256)\n",
      "Train Epoch: 5 | Loss: 0.736 | Acc: 74.186% (35894/48384)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.200% (35996/48512)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.217% (36099/48640)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.223% (36197/48768)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.247% (36304/48896)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.251% (36401/49024)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.251% (36496/49152)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.243% (36587/49280)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.243% (36682/49408)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.239% (36775/49536)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.231% (36866/49664)\n",
      "Train Epoch: 5 | Loss: 0.735 | Acc: 74.243% (36967/49792)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.249% (37065/49920)\n",
      "Train Epoch: 5 | Loss: 0.734 | Acc: 74.244% (37122/50000)\n",
      "Test Epoch: 5 | Loss: 0.523 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 5 | Loss: 0.565 | Acc: 83.000% (166/200)\n",
      "Test Epoch: 5 | Loss: 0.600 | Acc: 80.333% (241/300)\n",
      "Test Epoch: 5 | Loss: 0.585 | Acc: 79.750% (319/400)\n",
      "Test Epoch: 5 | Loss: 0.597 | Acc: 79.200% (396/500)\n",
      "Test Epoch: 5 | Loss: 0.562 | Acc: 79.833% (479/600)\n",
      "Test Epoch: 5 | Loss: 0.591 | Acc: 79.714% (558/700)\n",
      "Test Epoch: 5 | Loss: 0.623 | Acc: 78.250% (626/800)\n",
      "Test Epoch: 5 | Loss: 0.645 | Acc: 77.667% (699/900)\n",
      "Test Epoch: 5 | Loss: 0.647 | Acc: 77.500% (775/1000)\n",
      "Test Epoch: 5 | Loss: 0.650 | Acc: 77.273% (850/1100)\n",
      "Test Epoch: 5 | Loss: 0.658 | Acc: 76.833% (922/1200)\n",
      "Test Epoch: 5 | Loss: 0.653 | Acc: 76.462% (994/1300)\n",
      "Test Epoch: 5 | Loss: 0.650 | Acc: 76.286% (1068/1400)\n",
      "Test Epoch: 5 | Loss: 0.643 | Acc: 76.467% (1147/1500)\n",
      "Test Epoch: 5 | Loss: 0.653 | Acc: 76.312% (1221/1600)\n",
      "Test Epoch: 5 | Loss: 0.648 | Acc: 76.706% (1304/1700)\n",
      "Test Epoch: 5 | Loss: 0.650 | Acc: 76.611% (1379/1800)\n",
      "Test Epoch: 5 | Loss: 0.649 | Acc: 76.842% (1460/1900)\n",
      "Test Epoch: 5 | Loss: 0.664 | Acc: 76.700% (1534/2000)\n",
      "Test Epoch: 5 | Loss: 0.669 | Acc: 76.286% (1602/2100)\n",
      "Test Epoch: 5 | Loss: 0.670 | Acc: 76.318% (1679/2200)\n",
      "Test Epoch: 5 | Loss: 0.672 | Acc: 76.348% (1756/2300)\n",
      "Test Epoch: 5 | Loss: 0.673 | Acc: 76.292% (1831/2400)\n",
      "Test Epoch: 5 | Loss: 0.673 | Acc: 76.200% (1905/2500)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.308% (1984/2600)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.074% (2054/2700)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.179% (2133/2800)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.276% (2212/2900)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.467% (2294/3000)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.452% (2370/3100)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.406% (2445/3200)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.303% (2518/3300)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.147% (2589/3400)\n",
      "Test Epoch: 5 | Loss: 0.686 | Acc: 76.114% (2664/3500)\n",
      "Test Epoch: 5 | Loss: 0.686 | Acc: 76.250% (2745/3600)\n",
      "Test Epoch: 5 | Loss: 0.688 | Acc: 76.216% (2820/3700)\n",
      "Test Epoch: 5 | Loss: 0.685 | Acc: 76.211% (2896/3800)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.333% (2977/3900)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.500% (3060/4000)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.512% (3137/4100)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.524% (3214/4200)\n",
      "Test Epoch: 5 | Loss: 0.675 | Acc: 76.698% (3298/4300)\n",
      "Test Epoch: 5 | Loss: 0.676 | Acc: 76.705% (3375/4400)\n",
      "Test Epoch: 5 | Loss: 0.675 | Acc: 76.711% (3452/4500)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.696% (3528/4600)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.638% (3602/4700)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.688% (3681/4800)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.735% (3760/4900)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.660% (3833/5000)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.784% (3916/5100)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.673% (3987/5200)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.566% (4058/5300)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.519% (4132/5400)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.473% (4206/5500)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.518% (4285/5600)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.439% (4357/5700)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.603% (4443/5800)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.407% (4508/5900)\n",
      "Test Epoch: 5 | Loss: 0.683 | Acc: 76.383% (4583/6000)\n",
      "Test Epoch: 5 | Loss: 0.683 | Acc: 76.361% (4658/6100)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.355% (4734/6200)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.381% (4812/6300)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.531% (4898/6400)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.492% (4972/6500)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.485% (5048/6600)\n",
      "Test Epoch: 5 | Loss: 0.676 | Acc: 76.552% (5129/6700)\n",
      "Test Epoch: 5 | Loss: 0.676 | Acc: 76.618% (5210/6800)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.623% (5287/6900)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.557% (5359/7000)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.521% (5433/7100)\n",
      "Test Epoch: 5 | Loss: 0.675 | Acc: 76.639% (5518/7200)\n",
      "Test Epoch: 5 | Loss: 0.675 | Acc: 76.740% (5602/7300)\n",
      "Test Epoch: 5 | Loss: 0.674 | Acc: 76.824% (5685/7400)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.773% (5758/7500)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.724% (5831/7600)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.675% (5904/7700)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.641% (5978/7800)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.608% (6052/7900)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.575% (6126/8000)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.556% (6201/8100)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.585% (6280/8200)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.602% (6358/8300)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.583% (6433/8400)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.494% (6502/8500)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.547% (6583/8600)\n",
      "Test Epoch: 5 | Loss: 0.681 | Acc: 76.529% (6658/8700)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.523% (6734/8800)\n",
      "Test Epoch: 5 | Loss: 0.683 | Acc: 76.517% (6810/8900)\n",
      "Test Epoch: 5 | Loss: 0.684 | Acc: 76.489% (6884/9000)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.527% (6964/9100)\n",
      "Test Epoch: 5 | Loss: 0.679 | Acc: 76.641% (7051/9200)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.645% (7128/9300)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.596% (7200/9400)\n",
      "Test Epoch: 5 | Loss: 0.680 | Acc: 76.589% (7276/9500)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.615% (7355/9600)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.639% (7434/9700)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.643% (7511/9800)\n",
      "Test Epoch: 5 | Loss: 0.676 | Acc: 76.646% (7588/9900)\n",
      "Test Epoch: 5 | Loss: 0.677 | Acc: 76.670% (7667/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Train Epoch: 6 | Loss: 0.754 | Acc: 73.438% (94/128)\n",
      "Train Epoch: 6 | Loss: 0.834 | Acc: 70.703% (181/256)\n",
      "Train Epoch: 6 | Loss: 0.798 | Acc: 71.354% (274/384)\n",
      "Train Epoch: 6 | Loss: 0.782 | Acc: 71.680% (367/512)\n",
      "Train Epoch: 6 | Loss: 0.754 | Acc: 72.031% (461/640)\n",
      "Train Epoch: 6 | Loss: 0.786 | Acc: 71.484% (549/768)\n",
      "Train Epoch: 6 | Loss: 0.777 | Acc: 71.875% (644/896)\n",
      "Train Epoch: 6 | Loss: 0.757 | Acc: 73.145% (749/1024)\n",
      "Train Epoch: 6 | Loss: 0.756 | Acc: 73.264% (844/1152)\n",
      "Train Epoch: 6 | Loss: 0.755 | Acc: 73.359% (939/1280)\n",
      "Train Epoch: 6 | Loss: 0.739 | Acc: 74.006% (1042/1408)\n",
      "Train Epoch: 6 | Loss: 0.733 | Acc: 74.219% (1140/1536)\n",
      "Train Epoch: 6 | Loss: 0.721 | Acc: 74.519% (1240/1664)\n",
      "Train Epoch: 6 | Loss: 0.712 | Acc: 74.833% (1341/1792)\n",
      "Train Epoch: 6 | Loss: 0.722 | Acc: 74.219% (1425/1920)\n",
      "Train Epoch: 6 | Loss: 0.709 | Acc: 74.658% (1529/2048)\n",
      "Train Epoch: 6 | Loss: 0.707 | Acc: 74.586% (1623/2176)\n",
      "Train Epoch: 6 | Loss: 0.706 | Acc: 74.609% (1719/2304)\n",
      "Train Epoch: 6 | Loss: 0.704 | Acc: 74.630% (1815/2432)\n",
      "Train Epoch: 6 | Loss: 0.701 | Acc: 74.766% (1914/2560)\n",
      "Train Epoch: 6 | Loss: 0.700 | Acc: 75.000% (2016/2688)\n",
      "Train Epoch: 6 | Loss: 0.699 | Acc: 75.107% (2115/2816)\n",
      "Train Epoch: 6 | Loss: 0.691 | Acc: 75.306% (2217/2944)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 75.260% (2312/3072)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 75.500% (2416/3200)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 75.601% (2516/3328)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 75.521% (2610/3456)\n",
      "Train Epoch: 6 | Loss: 0.683 | Acc: 75.837% (2718/3584)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 75.862% (2816/3712)\n",
      "Train Epoch: 6 | Loss: 0.693 | Acc: 75.625% (2904/3840)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 75.756% (3006/3968)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 75.952% (3111/4096)\n",
      "Train Epoch: 6 | Loss: 0.679 | Acc: 76.136% (3216/4224)\n",
      "Train Epoch: 6 | Loss: 0.681 | Acc: 76.034% (3309/4352)\n",
      "Train Epoch: 6 | Loss: 0.682 | Acc: 76.027% (3406/4480)\n",
      "Train Epoch: 6 | Loss: 0.681 | Acc: 76.128% (3508/4608)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 75.992% (3599/4736)\n",
      "Train Epoch: 6 | Loss: 0.683 | Acc: 76.131% (3703/4864)\n",
      "Train Epoch: 6 | Loss: 0.683 | Acc: 76.162% (3802/4992)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.113% (3897/5120)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.162% (3997/5248)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.172% (4095/5376)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 75.999% (4183/5504)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 75.994% (4280/5632)\n",
      "Train Epoch: 6 | Loss: 0.693 | Acc: 75.938% (4374/5760)\n",
      "Train Epoch: 6 | Loss: 0.695 | Acc: 75.917% (4470/5888)\n",
      "Train Epoch: 6 | Loss: 0.695 | Acc: 75.964% (4570/6016)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.123% (4677/6144)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.148% (4776/6272)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.281% (4882/6400)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.302% (4981/6528)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.247% (5075/6656)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.135% (5165/6784)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.114% (5261/6912)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.179% (5363/7040)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.172% (5460/7168)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.124% (5554/7296)\n",
      "Train Epoch: 6 | Loss: 0.691 | Acc: 76.118% (5651/7424)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.126% (5749/7552)\n",
      "Train Epoch: 6 | Loss: 0.691 | Acc: 76.068% (5842/7680)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.050% (5938/7808)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.046% (6035/7936)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.079% (6135/8064)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.111% (6235/8192)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.094% (6331/8320)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.160% (6434/8448)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.166% (6532/8576)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.149% (6628/8704)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.212% (6731/8832)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.239% (6831/8960)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.243% (6929/9088)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.118% (7015/9216)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.102% (7111/9344)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.130% (7211/9472)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.125% (7308/9600)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.059% (7399/9728)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.075% (7498/9856)\n",
      "Train Epoch: 6 | Loss: 0.690 | Acc: 76.052% (7593/9984)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.048% (7690/10112)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.152% (7798/10240)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.206% (7901/10368)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.258% (8004/10496)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.252% (8101/10624)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.228% (8196/10752)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.268% (8298/10880)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.290% (8398/11008)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.239% (8490/11136)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.216% (8585/11264)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.264% (8688/11392)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.250% (8784/11520)\n",
      "Train Epoch: 6 | Loss: 0.683 | Acc: 76.322% (8890/11648)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.257% (8980/11776)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.235% (9075/11904)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.222% (9171/12032)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.201% (9266/12160)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.221% (9366/12288)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.208% (9462/12416)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.188% (9557/12544)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.128% (9647/12672)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.141% (9746/12800)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.153% (9845/12928)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.210% (9950/13056)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.198% (10046/13184)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.247% (10150/13312)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.235% (10246/13440)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.275% (10349/13568)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.270% (10446/13696)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.223% (10537/13824)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.218% (10634/13952)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.200% (10729/14080)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.154% (10820/14208)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.116% (10912/14336)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.092% (11006/14464)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.144% (11111/14592)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.107% (11203/14720)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.105% (11300/14848)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.095% (11396/14976)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.099% (11494/15104)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.096% (11591/15232)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.094% (11688/15360)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.091% (11785/15488)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 76.082% (11881/15616)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.067% (11976/15744)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.090% (12077/15872)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.062% (12170/16000)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.035% (12263/16128)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 75.990% (12353/16256)\n",
      "Train Epoch: 6 | Loss: 0.689 | Acc: 75.995% (12451/16384)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 76.030% (12554/16512)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.010% (12648/16640)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.038% (12750/16768)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 76.012% (12843/16896)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.022% (12942/17024)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 75.997% (13035/17152)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.013% (13135/17280)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.017% (13233/17408)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 75.998% (13327/17536)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 75.996% (13424/17664)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 75.950% (13513/17792)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 75.938% (13608/17920)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 75.942% (13706/18048)\n",
      "Train Epoch: 6 | Loss: 0.688 | Acc: 75.930% (13801/18176)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 75.951% (13902/18304)\n",
      "Train Epoch: 6 | Loss: 0.687 | Acc: 75.960% (14001/18432)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 75.986% (14103/18560)\n",
      "Train Epoch: 6 | Loss: 0.686 | Acc: 76.001% (14203/18688)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.026% (14305/18816)\n",
      "Train Epoch: 6 | Loss: 0.685 | Acc: 76.019% (14401/18944)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.033% (14501/19072)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.057% (14603/19200)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.061% (14701/19328)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.079% (14802/19456)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.067% (14897/19584)\n",
      "Train Epoch: 6 | Loss: 0.684 | Acc: 76.065% (14994/19712)\n",
      "Train Epoch: 6 | Loss: 0.683 | Acc: 76.109% (15100/19840)\n",
      "Train Epoch: 6 | Loss: 0.682 | Acc: 76.132% (15202/19968)\n",
      "Train Epoch: 6 | Loss: 0.682 | Acc: 76.145% (15302/20096)\n",
      "Train Epoch: 6 | Loss: 0.681 | Acc: 76.162% (15403/20224)\n",
      "Train Epoch: 6 | Loss: 0.681 | Acc: 76.160% (15500/20352)\n",
      "Train Epoch: 6 | Loss: 0.680 | Acc: 76.157% (15597/20480)\n",
      "Train Epoch: 6 | Loss: 0.679 | Acc: 76.218% (15707/20608)\n",
      "Train Epoch: 6 | Loss: 0.678 | Acc: 76.239% (15809/20736)\n",
      "Train Epoch: 6 | Loss: 0.678 | Acc: 76.256% (15910/20864)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.277% (16012/20992)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.269% (16108/21120)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.257% (16203/21248)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.230% (16295/21376)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.228% (16392/21504)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.230% (16490/21632)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.250% (16592/21760)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.252% (16690/21888)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.249% (16787/22016)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.237% (16882/22144)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.235% (16979/22272)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.246% (17079/22400)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.234% (17174/22528)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.258% (17277/22656)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.255% (17374/22784)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.270% (17475/22912)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.289% (17577/23040)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.282% (17673/23168)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.271% (17768/23296)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.272% (17866/23424)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.270% (17963/23552)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.275% (18062/23680)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.302% (18166/23808)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.299% (18263/23936)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.292% (18359/24064)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.286% (18455/24192)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.275% (18550/24320)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.268% (18646/24448)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.290% (18749/24576)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.267% (18841/24704)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.260% (18937/24832)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.278% (19039/24960)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.315% (19146/25088)\n",
      "Train Epoch: 6 | Loss: 0.677 | Acc: 76.273% (19233/25216)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.294% (19336/25344)\n",
      "Train Epoch: 6 | Loss: 0.676 | Acc: 76.288% (19432/25472)\n",
      "Train Epoch: 6 | Loss: 0.675 | Acc: 76.309% (19535/25600)\n",
      "Train Epoch: 6 | Loss: 0.674 | Acc: 76.353% (19644/25728)\n",
      "Train Epoch: 6 | Loss: 0.674 | Acc: 76.338% (19738/25856)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.382% (19847/25984)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.421% (19955/26112)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.421% (20053/26240)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.426% (20152/26368)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.396% (20242/26496)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.416% (20345/26624)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.391% (20436/26752)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.384% (20532/26880)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.388% (20631/27008)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.393% (20730/27136)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.419% (20835/27264)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.420% (20933/27392)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.417% (21030/27520)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.425% (21130/27648)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.426% (21228/27776)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.390% (21316/27904)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.413% (21420/28032)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.445% (21527/28160)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.449% (21626/28288)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.492% (21736/28416)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.510% (21839/28544)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.521% (21940/28672)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.538% (22043/28800)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.528% (22138/28928)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.535% (22238/29056)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.497% (22325/29184)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.501% (22424/29312)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.505% (22523/29440)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.529% (22628/29568)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.519% (22723/29696)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.529% (22824/29824)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.539% (22925/29952)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.523% (23018/30080)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.490% (23106/30208)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.473% (23199/30336)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.471% (23296/30464)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.487% (23399/30592)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.497% (23500/30720)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.498% (23598/30848)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.472% (23688/30976)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.492% (23792/31104)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.511% (23896/31232)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.508% (23993/31360)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.502% (24089/31488)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.464% (24175/31616)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.474% (24276/31744)\n",
      "Train Epoch: 6 | Loss: 0.673 | Acc: 76.478% (24375/31872)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.503% (24481/32000)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.485% (24573/32128)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.473% (24667/32256)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.482% (24768/32384)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.504% (24873/32512)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.538% (24982/32640)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.553% (25085/32768)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.566% (25187/32896)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.541% (25277/33024)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.550% (25378/33152)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.547% (25475/33280)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.554% (25575/33408)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.554% (25673/33536)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.545% (25768/33664)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.557% (25870/33792)\n",
      "Train Epoch: 6 | Loss: 0.672 | Acc: 76.560% (25969/33920)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.560% (26067/34048)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.568% (26168/34176)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.580% (26270/34304)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.589% (26371/34432)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.594% (26471/34560)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.603% (26572/34688)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.608% (26672/34816)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.603% (26768/34944)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.605% (26867/35072)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.602% (26964/35200)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.636% (27074/35328)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.605% (27161/35456)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.610% (27261/35584)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.627% (27365/35712)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.627% (27463/35840)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.626% (27561/35968)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.612% (27654/36096)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.604% (27749/36224)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.626% (27855/36352)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.617% (27950/36480)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.609% (28045/36608)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.620% (28147/36736)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.619% (28245/36864)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.627% (28346/36992)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.659% (28456/37120)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.646% (28549/37248)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.629% (28641/37376)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.621% (28736/37504)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.621% (28834/37632)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.621% (28932/37760)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.642% (29038/37888)\n",
      "Train Epoch: 6 | Loss: 0.671 | Acc: 76.649% (29139/38016)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.660% (29241/38144)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.659% (29339/38272)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.669% (29441/38400)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.674% (29541/38528)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.679% (29641/38656)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.694% (29745/38784)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.704% (29847/38912)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.711% (29948/39040)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.718% (30049/39168)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.720% (30148/39296)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.740% (30254/39424)\n",
      "Train Epoch: 6 | Loss: 0.670 | Acc: 76.724% (30346/39552)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.736% (30449/39680)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.741% (30549/39808)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.770% (30659/39936)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.757% (30752/40064)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.771% (30856/40192)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.763% (30951/40320)\n",
      "Train Epoch: 6 | Loss: 0.669 | Acc: 76.768% (31051/40448)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.777% (31153/40576)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.784% (31254/40704)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.785% (31353/40832)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.775% (31447/40960)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.767% (31542/41088)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.769% (31641/41216)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.773% (31741/41344)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.772% (31839/41472)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.760% (31932/41600)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.735% (32020/41728)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.730% (32116/41856)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.715% (32208/41984)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.714% (32306/42112)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.721% (32407/42240)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.725% (32507/42368)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.711% (32599/42496)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.715% (32699/42624)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.724% (32801/42752)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.728% (32901/42880)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.739% (33004/43008)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.732% (33099/43136)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.724% (33194/43264)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.712% (33287/43392)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.723% (33390/43520)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.711% (33483/43648)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.713% (33582/43776)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.717% (33682/43904)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.740% (33790/44032)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.723% (33881/44160)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.723% (33979/44288)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.727% (34079/44416)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.731% (34179/44544)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.726% (34275/44672)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.730% (34375/44800)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.741% (34478/44928)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.733% (34573/45056)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.733% (34671/45184)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.724% (34765/45312)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.721% (34862/45440)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.707% (34954/45568)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.705% (35051/45696)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.715% (35154/45824)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.726% (35257/45952)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.734% (35359/46080)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.738% (35459/46208)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.718% (35548/46336)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.720% (35647/46464)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.715% (35743/46592)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.719% (35843/46720)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.718% (35941/46848)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.733% (36046/46976)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.726% (36141/47104)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.723% (36238/47232)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.723% (36336/47360)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.731% (36438/47488)\n",
      "Train Epoch: 6 | Loss: 0.668 | Acc: 76.731% (36536/47616)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.741% (36639/47744)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.744% (36739/47872)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.763% (36846/48000)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.774% (36950/48128)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.774% (37048/48256)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.767% (37143/48384)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.760% (37238/48512)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.754% (37333/48640)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.743% (37426/48768)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.755% (37530/48896)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.742% (37622/49024)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.756% (37727/49152)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.759% (37827/49280)\n",
      "Train Epoch: 6 | Loss: 0.666 | Acc: 76.771% (37931/49408)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.768% (38028/49536)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.760% (38122/49664)\n",
      "Train Epoch: 6 | Loss: 0.667 | Acc: 76.755% (38218/49792)\n",
      "Train Epoch: 6 | Loss: 0.666 | Acc: 76.771% (38324/49920)\n",
      "Train Epoch: 6 | Loss: 0.666 | Acc: 76.782% (38391/50000)\n",
      "Test Epoch: 6 | Loss: 0.542 | Acc: 80.000% (80/100)\n",
      "Test Epoch: 6 | Loss: 0.570 | Acc: 80.500% (161/200)\n",
      "Test Epoch: 6 | Loss: 0.536 | Acc: 81.000% (243/300)\n",
      "Test Epoch: 6 | Loss: 0.541 | Acc: 80.000% (320/400)\n",
      "Test Epoch: 6 | Loss: 0.561 | Acc: 79.200% (396/500)\n",
      "Test Epoch: 6 | Loss: 0.516 | Acc: 81.167% (487/600)\n",
      "Test Epoch: 6 | Loss: 0.540 | Acc: 80.571% (564/700)\n",
      "Test Epoch: 6 | Loss: 0.560 | Acc: 80.000% (640/800)\n",
      "Test Epoch: 6 | Loss: 0.584 | Acc: 79.222% (713/900)\n",
      "Test Epoch: 6 | Loss: 0.585 | Acc: 79.200% (792/1000)\n",
      "Test Epoch: 6 | Loss: 0.588 | Acc: 78.909% (868/1100)\n",
      "Test Epoch: 6 | Loss: 0.600 | Acc: 78.833% (946/1200)\n",
      "Test Epoch: 6 | Loss: 0.595 | Acc: 78.846% (1025/1300)\n",
      "Test Epoch: 6 | Loss: 0.603 | Acc: 78.643% (1101/1400)\n",
      "Test Epoch: 6 | Loss: 0.594 | Acc: 78.800% (1182/1500)\n",
      "Test Epoch: 6 | Loss: 0.615 | Acc: 78.312% (1253/1600)\n",
      "Test Epoch: 6 | Loss: 0.616 | Acc: 78.294% (1331/1700)\n",
      "Test Epoch: 6 | Loss: 0.617 | Acc: 78.111% (1406/1800)\n",
      "Test Epoch: 6 | Loss: 0.613 | Acc: 78.316% (1488/1900)\n",
      "Test Epoch: 6 | Loss: 0.624 | Acc: 77.950% (1559/2000)\n",
      "Test Epoch: 6 | Loss: 0.626 | Acc: 77.714% (1632/2100)\n",
      "Test Epoch: 6 | Loss: 0.627 | Acc: 77.909% (1714/2200)\n",
      "Test Epoch: 6 | Loss: 0.628 | Acc: 77.826% (1790/2300)\n",
      "Test Epoch: 6 | Loss: 0.633 | Acc: 77.750% (1866/2400)\n",
      "Test Epoch: 6 | Loss: 0.633 | Acc: 78.040% (1951/2500)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.808% (2023/2600)\n",
      "Test Epoch: 6 | Loss: 0.640 | Acc: 77.778% (2100/2700)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.786% (2178/2800)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.897% (2259/2900)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.967% (2339/3000)\n",
      "Test Epoch: 6 | Loss: 0.644 | Acc: 77.903% (2415/3100)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.812% (2490/3200)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.818% (2568/3300)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.676% (2641/3400)\n",
      "Test Epoch: 6 | Loss: 0.649 | Acc: 77.514% (2713/3500)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.583% (2793/3600)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 77.432% (2865/3700)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.553% (2947/3800)\n",
      "Test Epoch: 6 | Loss: 0.644 | Acc: 77.615% (3027/3900)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 77.850% (3114/4000)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.829% (3191/4100)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.714% (3264/4200)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.907% (3350/4300)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.977% (3431/4400)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 78.089% (3514/4500)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.957% (3586/4600)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.872% (3660/4700)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 77.938% (3741/4800)\n",
      "Test Epoch: 6 | Loss: 0.639 | Acc: 77.959% (3820/4900)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.840% (3892/5000)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 77.941% (3975/5100)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.865% (4049/5200)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.830% (4125/5300)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.907% (4207/5400)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.909% (4285/5500)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.804% (4357/5600)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.825% (4436/5700)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.931% (4520/5800)\n",
      "Test Epoch: 6 | Loss: 0.644 | Acc: 77.898% (4596/5900)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.800% (4668/6000)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.787% (4745/6100)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.742% (4820/6200)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.778% (4900/6300)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.844% (4982/6400)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.877% (5062/6500)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.818% (5136/6600)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.851% (5216/6700)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.868% (5295/6800)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.826% (5370/6900)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.814% (5447/7000)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.789% (5523/7100)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.833% (5604/7200)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.890% (5686/7300)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.892% (5764/7400)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.867% (5840/7500)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.882% (5919/7600)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.909% (5999/7700)\n",
      "Test Epoch: 6 | Loss: 0.646 | Acc: 77.833% (6071/7800)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.810% (6147/7900)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.800% (6224/8000)\n",
      "Test Epoch: 6 | Loss: 0.644 | Acc: 77.827% (6304/8100)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.854% (6384/8200)\n",
      "Test Epoch: 6 | Loss: 0.644 | Acc: 77.831% (6460/8300)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.774% (6533/8400)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.718% (6606/8500)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 77.709% (6683/8600)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.701% (6760/8700)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 77.739% (6841/8800)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 77.685% (6914/8900)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 77.722% (6995/9000)\n",
      "Test Epoch: 6 | Loss: 0.647 | Acc: 77.747% (7075/9100)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.848% (7162/9200)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.860% (7241/9300)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.872% (7320/9400)\n",
      "Test Epoch: 6 | Loss: 0.645 | Acc: 77.842% (7395/9500)\n",
      "Test Epoch: 6 | Loss: 0.643 | Acc: 77.917% (7480/9600)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 77.907% (7557/9700)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.857% (7630/9800)\n",
      "Test Epoch: 6 | Loss: 0.641 | Acc: 77.909% (7713/9900)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 77.860% (7786/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Epoch: 7 | Loss: 0.699 | Acc: 76.562% (98/128)\n",
      "Train Epoch: 7 | Loss: 0.681 | Acc: 76.172% (195/256)\n",
      "Train Epoch: 7 | Loss: 0.678 | Acc: 77.604% (298/384)\n",
      "Train Epoch: 7 | Loss: 0.656 | Acc: 77.734% (398/512)\n",
      "Train Epoch: 7 | Loss: 0.659 | Acc: 77.344% (495/640)\n",
      "Train Epoch: 7 | Loss: 0.657 | Acc: 76.823% (590/768)\n",
      "Train Epoch: 7 | Loss: 0.663 | Acc: 76.451% (685/896)\n",
      "Train Epoch: 7 | Loss: 0.667 | Acc: 76.660% (785/1024)\n",
      "Train Epoch: 7 | Loss: 0.661 | Acc: 76.736% (884/1152)\n",
      "Train Epoch: 7 | Loss: 0.666 | Acc: 76.562% (980/1280)\n",
      "Train Epoch: 7 | Loss: 0.675 | Acc: 76.491% (1077/1408)\n",
      "Train Epoch: 7 | Loss: 0.675 | Acc: 76.497% (1175/1536)\n",
      "Train Epoch: 7 | Loss: 0.665 | Acc: 76.683% (1276/1664)\n",
      "Train Epoch: 7 | Loss: 0.660 | Acc: 76.842% (1377/1792)\n",
      "Train Epoch: 7 | Loss: 0.663 | Acc: 76.615% (1471/1920)\n",
      "Train Epoch: 7 | Loss: 0.665 | Acc: 76.758% (1572/2048)\n",
      "Train Epoch: 7 | Loss: 0.660 | Acc: 77.022% (1676/2176)\n",
      "Train Epoch: 7 | Loss: 0.659 | Acc: 77.214% (1779/2304)\n",
      "Train Epoch: 7 | Loss: 0.661 | Acc: 76.933% (1871/2432)\n",
      "Train Epoch: 7 | Loss: 0.654 | Acc: 77.227% (1977/2560)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 77.530% (2084/2688)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.663% (2187/2816)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.683% (2287/2944)\n",
      "Train Epoch: 7 | Loss: 0.647 | Acc: 77.507% (2381/3072)\n",
      "Train Epoch: 7 | Loss: 0.647 | Acc: 77.344% (2475/3200)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 77.073% (2565/3328)\n",
      "Train Epoch: 7 | Loss: 0.647 | Acc: 77.286% (2671/3456)\n",
      "Train Epoch: 7 | Loss: 0.652 | Acc: 76.897% (2756/3584)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 76.940% (2856/3712)\n",
      "Train Epoch: 7 | Loss: 0.649 | Acc: 77.188% (2964/3840)\n",
      "Train Epoch: 7 | Loss: 0.648 | Acc: 77.243% (3065/3968)\n",
      "Train Epoch: 7 | Loss: 0.648 | Acc: 77.246% (3164/4096)\n",
      "Train Epoch: 7 | Loss: 0.652 | Acc: 77.060% (3255/4224)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 77.091% (3355/4352)\n",
      "Train Epoch: 7 | Loss: 0.647 | Acc: 77.232% (3460/4480)\n",
      "Train Epoch: 7 | Loss: 0.646 | Acc: 77.214% (3558/4608)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.259% (3659/4736)\n",
      "Train Epoch: 7 | Loss: 0.652 | Acc: 77.035% (3747/4864)\n",
      "Train Epoch: 7 | Loss: 0.649 | Acc: 77.163% (3852/4992)\n",
      "Train Epoch: 7 | Loss: 0.651 | Acc: 77.070% (3946/5120)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 77.058% (4044/5248)\n",
      "Train Epoch: 7 | Loss: 0.648 | Acc: 77.176% (4149/5376)\n",
      "Train Epoch: 7 | Loss: 0.646 | Acc: 77.326% (4256/5504)\n",
      "Train Epoch: 7 | Loss: 0.651 | Acc: 77.148% (4345/5632)\n",
      "Train Epoch: 7 | Loss: 0.655 | Acc: 76.910% (4430/5760)\n",
      "Train Epoch: 7 | Loss: 0.653 | Acc: 77.021% (4535/5888)\n",
      "Train Epoch: 7 | Loss: 0.650 | Acc: 77.094% (4638/6016)\n",
      "Train Epoch: 7 | Loss: 0.649 | Acc: 77.181% (4742/6144)\n",
      "Train Epoch: 7 | Loss: 0.649 | Acc: 77.105% (4836/6272)\n",
      "Train Epoch: 7 | Loss: 0.649 | Acc: 77.141% (4937/6400)\n",
      "Train Epoch: 7 | Loss: 0.648 | Acc: 77.129% (5035/6528)\n",
      "Train Epoch: 7 | Loss: 0.648 | Acc: 77.013% (5126/6656)\n",
      "Train Epoch: 7 | Loss: 0.646 | Acc: 77.108% (5231/6784)\n",
      "Train Epoch: 7 | Loss: 0.643 | Acc: 77.286% (5342/6912)\n",
      "Train Epoch: 7 | Loss: 0.643 | Acc: 77.301% (5442/7040)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.288% (5540/7168)\n",
      "Train Epoch: 7 | Loss: 0.645 | Acc: 77.289% (5639/7296)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.344% (5742/7424)\n",
      "Train Epoch: 7 | Loss: 0.643 | Acc: 77.423% (5847/7552)\n",
      "Train Epoch: 7 | Loss: 0.644 | Acc: 77.422% (5946/7680)\n",
      "Train Epoch: 7 | Loss: 0.643 | Acc: 77.433% (6046/7808)\n",
      "Train Epoch: 7 | Loss: 0.642 | Acc: 77.457% (6147/7936)\n",
      "Train Epoch: 7 | Loss: 0.641 | Acc: 77.455% (6246/8064)\n",
      "Train Epoch: 7 | Loss: 0.645 | Acc: 77.319% (6334/8192)\n",
      "Train Epoch: 7 | Loss: 0.643 | Acc: 77.320% (6433/8320)\n",
      "Train Epoch: 7 | Loss: 0.641 | Acc: 77.391% (6538/8448)\n",
      "Train Epoch: 7 | Loss: 0.641 | Acc: 77.414% (6639/8576)\n",
      "Train Epoch: 7 | Loss: 0.640 | Acc: 77.482% (6744/8704)\n",
      "Train Epoch: 7 | Loss: 0.639 | Acc: 77.491% (6844/8832)\n",
      "Train Epoch: 7 | Loss: 0.638 | Acc: 77.500% (6944/8960)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.520% (7045/9088)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.582% (7150/9216)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.568% (7248/9344)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.629% (7353/9472)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.667% (7456/9600)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.693% (7558/9728)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.628% (7651/9856)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.634% (7751/9984)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.670% (7854/10112)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.656% (7952/10240)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.672% (8053/10368)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.734% (8159/10496)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.673% (8252/10624)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.660% (8350/10752)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.656% (8449/10880)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.671% (8550/11008)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.667% (8649/11136)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.725% (8755/11264)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.765% (8859/11392)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.769% (8959/11520)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.782% (9060/11648)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.751% (9156/11776)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.747% (9255/11904)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.734% (9353/12032)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.763% (9456/12160)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.808% (9561/12288)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.827% (9663/12416)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.766% (9755/12544)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.786% (9857/12672)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.789% (9957/12800)\n",
      "Train Epoch: 7 | Loss: 0.638 | Acc: 77.731% (10049/12928)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.765% (10153/13056)\n",
      "Train Epoch: 7 | Loss: 0.639 | Acc: 77.700% (10244/13184)\n",
      "Train Epoch: 7 | Loss: 0.639 | Acc: 77.689% (10342/13312)\n",
      "Train Epoch: 7 | Loss: 0.639 | Acc: 77.679% (10440/13440)\n",
      "Train Epoch: 7 | Loss: 0.639 | Acc: 77.675% (10539/13568)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.760% (10650/13696)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.792% (10754/13824)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.759% (10849/13952)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.749% (10947/14080)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.759% (11048/14208)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.762% (11148/14336)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.793% (11252/14464)\n",
      "Train Epoch: 7 | Loss: 0.637 | Acc: 77.755% (11346/14592)\n",
      "Train Epoch: 7 | Loss: 0.636 | Acc: 77.772% (11448/14720)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.829% (11556/14848)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.831% (11656/14976)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.854% (11759/15104)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.869% (11861/15232)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.884% (11963/15360)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.912% (12067/15488)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.920% (12168/15616)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.890% (12263/15744)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.898% (12364/15872)\n",
      "Train Epoch: 7 | Loss: 0.632 | Acc: 77.925% (12468/16000)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.908% (12565/16128)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.824% (12651/16256)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.844% (12754/16384)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.889% (12861/16512)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.915% (12965/16640)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.916% (13065/16768)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.930% (13167/16896)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.943% (13269/17024)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.927% (13366/17152)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.957% (13471/17280)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.918% (13564/17408)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.891% (13659/17536)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.882% (13757/17664)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.895% (13859/17792)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.896% (13959/17920)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.887% (14057/18048)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.927% (14164/18176)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.923% (14263/18304)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.930% (14364/18432)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.926% (14463/18560)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.900% (14558/18688)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 77.928% (14663/18816)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.893% (14756/18944)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.863% (14850/19072)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.880% (14953/19200)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.882% (15053/19328)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.899% (15156/19456)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.900% (15256/19584)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.897% (15355/19712)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.893% (15454/19840)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.895% (15554/19968)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.911% (15657/20096)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.937% (15762/20224)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.909% (15856/20352)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.920% (15958/20480)\n",
      "Train Epoch: 7 | Loss: 0.635 | Acc: 77.921% (16058/20608)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.956% (16165/20736)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 77.976% (16269/20864)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 78.025% (16379/20992)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 78.026% (16479/21120)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.045% (16583/21248)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.074% (16689/21376)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 78.041% (16782/21504)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.083% (16891/21632)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.084% (16991/21760)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.093% (17093/21888)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.089% (17192/22016)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.084% (17291/22144)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 78.085% (17391/22272)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.121% (17499/22400)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.107% (17596/22528)\n",
      "Train Epoch: 7 | Loss: 0.634 | Acc: 78.094% (17693/22656)\n",
      "Train Epoch: 7 | Loss: 0.633 | Acc: 78.121% (17799/22784)\n",
      "Train Epoch: 7 | Loss: 0.632 | Acc: 78.142% (17904/22912)\n",
      "Train Epoch: 7 | Loss: 0.632 | Acc: 78.142% (18004/23040)\n",
      "Train Epoch: 7 | Loss: 0.632 | Acc: 78.181% (18113/23168)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.189% (18215/23296)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.198% (18317/23424)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.227% (18424/23552)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.235% (18526/23680)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.238% (18627/23808)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.225% (18724/23936)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.191% (18816/24064)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.199% (18918/24192)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.195% (19017/24320)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.170% (19111/24448)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.153% (19207/24576)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.157% (19308/24704)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.157% (19408/24832)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.165% (19510/24960)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.161% (19609/25088)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.157% (19708/25216)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.161% (19809/25344)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.172% (19912/25472)\n",
      "Train Epoch: 7 | Loss: 0.631 | Acc: 78.176% (20013/25600)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.218% (20124/25728)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.206% (20221/25856)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.225% (20326/25984)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.225% (20426/26112)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.197% (20519/26240)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.189% (20617/26368)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.193% (20718/26496)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.204% (20821/26624)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.203% (20921/26752)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.229% (21028/26880)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.236% (21130/27008)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.236% (21230/27136)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.235% (21330/27264)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.256% (21436/27392)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.278% (21542/27520)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.284% (21644/27648)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.309% (21751/27776)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.301% (21849/27904)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.328% (21957/28032)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.338% (22060/28160)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.334% (22159/28288)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.326% (22257/28416)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.314% (22354/28544)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.313% (22454/28672)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.292% (22548/28800)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.260% (22639/28928)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.242% (22734/29056)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.245% (22835/29184)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.261% (22940/29312)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.271% (23043/29440)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.291% (23149/29568)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.290% (23249/29696)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.279% (23346/29824)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.262% (23441/29952)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.275% (23545/30080)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.274% (23645/30208)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.270% (23744/30336)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.263% (23842/30464)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.249% (23938/30592)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.245% (24037/30720)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.261% (24142/30848)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.254% (24240/30976)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.254% (24340/31104)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.291% (24452/31232)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.288% (24551/31360)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.274% (24647/31488)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.258% (24742/31616)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.248% (24839/31744)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.276% (24948/31872)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.281% (25050/32000)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.287% (25152/32128)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.274% (25248/32256)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.252% (25341/32384)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.236% (25436/32512)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.251% (25541/32640)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.241% (25638/32768)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.222% (25732/32896)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.210% (25828/33024)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.209% (25928/33152)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.188% (26021/33280)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.197% (26124/33408)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.170% (26215/33536)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.161% (26312/33664)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.175% (26417/33792)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.172% (26516/33920)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.193% (26623/34048)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.201% (26726/34176)\n",
      "Train Epoch: 7 | Loss: 0.630 | Acc: 78.218% (26832/34304)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.224% (26934/34432)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.220% (27033/34560)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.229% (27136/34688)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.251% (27244/34816)\n",
      "Train Epoch: 7 | Loss: 0.629 | Acc: 78.231% (27337/34944)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.236% (27439/35072)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.253% (27545/35200)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.244% (27642/35328)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.221% (27734/35456)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.229% (27837/35584)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.229% (27937/35712)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.214% (28032/35840)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.206% (28129/35968)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.216% (28233/36096)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.200% (28327/36224)\n",
      "Train Epoch: 7 | Loss: 0.628 | Acc: 78.208% (28430/36352)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.237% (28541/36480)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.229% (28638/36608)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.237% (28741/36736)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.209% (28831/36864)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.214% (28933/36992)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.214% (29033/37120)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.230% (29139/37248)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.253% (29248/37376)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.253% (29348/37504)\n",
      "Train Epoch: 7 | Loss: 0.627 | Acc: 78.245% (29445/37632)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.263% (29552/37760)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.265% (29653/37888)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.264% (29753/38016)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.274% (29857/38144)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.271% (29956/38272)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.286% (30062/38400)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.294% (30165/38528)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.296% (30266/38656)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.305% (30370/38784)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.300% (30468/38912)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.307% (30571/39040)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.322% (30677/39168)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.321% (30777/39296)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.305% (30871/39424)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.312% (30974/39552)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.304% (31071/39680)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.313% (31175/39808)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.293% (31267/39936)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.282% (31363/40064)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.294% (31468/40192)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.299% (31570/40320)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.298% (31670/40448)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.300% (31771/40576)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.275% (31861/40704)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.274% (31961/40832)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.293% (32069/40960)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.295% (32170/41088)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.302% (32273/41216)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.294% (32370/41344)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.303% (32474/41472)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.303% (32574/41600)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.298% (32672/41728)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.307% (32776/41856)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.287% (32868/41984)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.282% (32966/42112)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.295% (33072/42240)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.283% (33167/42368)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.301% (33275/42496)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.308% (33378/42624)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.317% (33482/42752)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.323% (33585/42880)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.306% (33678/43008)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.306% (33778/43136)\n",
      "Train Epoch: 7 | Loss: 0.626 | Acc: 78.303% (33877/43264)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.312% (33981/43392)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.302% (34077/43520)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.315% (34183/43648)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.321% (34286/43776)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.321% (34386/43904)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.329% (34490/44032)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.333% (34592/44160)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.333% (34692/44288)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.319% (34786/44416)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.314% (34884/44544)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.313% (34984/44672)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.319% (35087/44800)\n",
      "Train Epoch: 7 | Loss: 0.625 | Acc: 78.341% (35197/44928)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.362% (35307/45056)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.371% (35411/45184)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.377% (35514/45312)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.371% (35612/45440)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.382% (35717/45568)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.405% (35828/45696)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.420% (35935/45824)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.410% (36031/45952)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.416% (36134/46080)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.400% (36227/46208)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.416% (36335/46336)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.407% (36431/46464)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.404% (36530/46592)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.420% (36638/46720)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.430% (36743/46848)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.432% (36844/46976)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.441% (36949/47104)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.436% (37047/47232)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.433% (37146/47360)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.430% (37245/47488)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.430% (37345/47616)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.429% (37445/47744)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.424% (37543/47872)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.429% (37646/48000)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.424% (37744/48128)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.407% (37836/48256)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.412% (37939/48384)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.414% (38040/48512)\n",
      "Train Epoch: 7 | Loss: 0.624 | Acc: 78.413% (38140/48640)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.420% (38244/48768)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.426% (38347/48896)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.419% (38444/49024)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.426% (38548/49152)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.442% (38656/49280)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.431% (38751/49408)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.424% (38848/49536)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.421% (38947/49664)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.420% (39047/49792)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.429% (39152/49920)\n",
      "Train Epoch: 7 | Loss: 0.623 | Acc: 78.424% (39212/50000)\n",
      "Test Epoch: 7 | Loss: 0.533 | Acc: 82.000% (82/100)\n",
      "Test Epoch: 7 | Loss: 0.563 | Acc: 80.500% (161/200)\n",
      "Test Epoch: 7 | Loss: 0.546 | Acc: 81.000% (243/300)\n",
      "Test Epoch: 7 | Loss: 0.552 | Acc: 81.500% (326/400)\n",
      "Test Epoch: 7 | Loss: 0.581 | Acc: 81.000% (405/500)\n",
      "Test Epoch: 7 | Loss: 0.541 | Acc: 82.000% (492/600)\n",
      "Test Epoch: 7 | Loss: 0.547 | Acc: 81.000% (567/700)\n",
      "Test Epoch: 7 | Loss: 0.556 | Acc: 80.500% (644/800)\n",
      "Test Epoch: 7 | Loss: 0.583 | Acc: 79.111% (712/900)\n",
      "Test Epoch: 7 | Loss: 0.580 | Acc: 79.500% (795/1000)\n",
      "Test Epoch: 7 | Loss: 0.580 | Acc: 79.545% (875/1100)\n",
      "Test Epoch: 7 | Loss: 0.585 | Acc: 79.417% (953/1200)\n",
      "Test Epoch: 7 | Loss: 0.577 | Acc: 79.154% (1029/1300)\n",
      "Test Epoch: 7 | Loss: 0.578 | Acc: 79.071% (1107/1400)\n",
      "Test Epoch: 7 | Loss: 0.579 | Acc: 79.067% (1186/1500)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 78.688% (1259/1600)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 78.882% (1341/1700)\n",
      "Test Epoch: 7 | Loss: 0.596 | Acc: 78.889% (1420/1800)\n",
      "Test Epoch: 7 | Loss: 0.595 | Acc: 78.842% (1498/1900)\n",
      "Test Epoch: 7 | Loss: 0.607 | Acc: 78.650% (1573/2000)\n",
      "Test Epoch: 7 | Loss: 0.613 | Acc: 78.429% (1647/2100)\n",
      "Test Epoch: 7 | Loss: 0.613 | Acc: 78.545% (1728/2200)\n",
      "Test Epoch: 7 | Loss: 0.614 | Acc: 78.478% (1805/2300)\n",
      "Test Epoch: 7 | Loss: 0.619 | Acc: 78.333% (1880/2400)\n",
      "Test Epoch: 7 | Loss: 0.623 | Acc: 78.280% (1957/2500)\n",
      "Test Epoch: 7 | Loss: 0.630 | Acc: 78.308% (2036/2600)\n",
      "Test Epoch: 7 | Loss: 0.626 | Acc: 78.370% (2116/2700)\n",
      "Test Epoch: 7 | Loss: 0.626 | Acc: 78.429% (2196/2800)\n",
      "Test Epoch: 7 | Loss: 0.632 | Acc: 78.345% (2272/2900)\n",
      "Test Epoch: 7 | Loss: 0.629 | Acc: 78.500% (2355/3000)\n",
      "Test Epoch: 7 | Loss: 0.630 | Acc: 78.484% (2433/3100)\n",
      "Test Epoch: 7 | Loss: 0.629 | Acc: 78.469% (2511/3200)\n",
      "Test Epoch: 7 | Loss: 0.627 | Acc: 78.606% (2594/3300)\n",
      "Test Epoch: 7 | Loss: 0.627 | Acc: 78.529% (2670/3400)\n",
      "Test Epoch: 7 | Loss: 0.631 | Acc: 78.371% (2743/3500)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.306% (2819/3600)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.189% (2893/3700)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.289% (2975/3800)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.436% (3059/3900)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.450% (3138/4000)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.463% (3217/4100)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.452% (3295/4200)\n",
      "Test Epoch: 7 | Loss: 0.634 | Acc: 78.581% (3379/4300)\n",
      "Test Epoch: 7 | Loss: 0.634 | Acc: 78.682% (3462/4400)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.644% (3539/4500)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.652% (3618/4600)\n",
      "Test Epoch: 7 | Loss: 0.634 | Acc: 78.723% (3700/4700)\n",
      "Test Epoch: 7 | Loss: 0.636 | Acc: 78.729% (3779/4800)\n",
      "Test Epoch: 7 | Loss: 0.635 | Acc: 78.776% (3860/4900)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.740% (3937/5000)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.765% (4017/5100)\n",
      "Test Epoch: 7 | Loss: 0.639 | Acc: 78.712% (4093/5200)\n",
      "Test Epoch: 7 | Loss: 0.639 | Acc: 78.679% (4170/5300)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.667% (4248/5400)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.727% (4330/5500)\n",
      "Test Epoch: 7 | Loss: 0.642 | Acc: 78.732% (4409/5600)\n",
      "Test Epoch: 7 | Loss: 0.642 | Acc: 78.772% (4490/5700)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.845% (4573/5800)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.780% (4648/5900)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.767% (4726/6000)\n",
      "Test Epoch: 7 | Loss: 0.639 | Acc: 78.770% (4805/6100)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.661% (4877/6200)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.683% (4957/6300)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.734% (5039/6400)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.708% (5116/6500)\n",
      "Test Epoch: 7 | Loss: 0.638 | Acc: 78.652% (5191/6600)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.672% (5271/6700)\n",
      "Test Epoch: 7 | Loss: 0.639 | Acc: 78.618% (5346/6800)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.536% (5419/6900)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.443% (5491/7000)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.408% (5567/7100)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.417% (5646/7200)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.384% (5722/7300)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.392% (5801/7400)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.333% (5875/7500)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.382% (5957/7600)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.377% (6035/7700)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.359% (6112/7800)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.367% (6191/7900)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.375% (6270/8000)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.432% (6353/8100)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.427% (6431/8200)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.458% (6512/8300)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.417% (6587/8400)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.365% (6661/8500)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.395% (6742/8600)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.391% (6820/8700)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.386% (6898/8800)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.371% (6975/8900)\n",
      "Test Epoch: 7 | Loss: 0.644 | Acc: 78.389% (7055/9000)\n",
      "Test Epoch: 7 | Loss: 0.643 | Acc: 78.418% (7136/9100)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.511% (7223/9200)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.495% (7300/9300)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.521% (7381/9400)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.516% (7459/9500)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.552% (7541/9600)\n",
      "Test Epoch: 7 | Loss: 0.637 | Acc: 78.608% (7625/9700)\n",
      "Test Epoch: 7 | Loss: 0.639 | Acc: 78.561% (7699/9800)\n",
      "Test Epoch: 7 | Loss: 0.640 | Acc: 78.556% (7777/9900)\n",
      "Test Epoch: 7 | Loss: 0.641 | Acc: 78.560% (7856/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Epoch: 8 | Loss: 0.503 | Acc: 83.594% (107/128)\n",
      "Train Epoch: 8 | Loss: 0.552 | Acc: 79.297% (203/256)\n",
      "Train Epoch: 8 | Loss: 0.525 | Acc: 80.990% (311/384)\n",
      "Train Epoch: 8 | Loss: 0.531 | Acc: 80.859% (414/512)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 80.469% (515/640)\n",
      "Train Epoch: 8 | Loss: 0.552 | Acc: 80.469% (618/768)\n",
      "Train Epoch: 8 | Loss: 0.559 | Acc: 80.580% (722/896)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 80.957% (829/1024)\n",
      "Train Epoch: 8 | Loss: 0.577 | Acc: 79.948% (921/1152)\n",
      "Train Epoch: 8 | Loss: 0.575 | Acc: 79.922% (1023/1280)\n",
      "Train Epoch: 8 | Loss: 0.577 | Acc: 79.688% (1122/1408)\n",
      "Train Epoch: 8 | Loss: 0.573 | Acc: 79.688% (1224/1536)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.627% (1325/1664)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.632% (1427/1792)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.479% (1526/1920)\n",
      "Train Epoch: 8 | Loss: 0.590 | Acc: 79.590% (1630/2048)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.871% (1738/2176)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.644% (1835/2304)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.729% (1939/2432)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.766% (2042/2560)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.799% (2145/2688)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.688% (2244/2816)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.620% (2344/2944)\n",
      "Train Epoch: 8 | Loss: 0.589 | Acc: 79.427% (2440/3072)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.438% (2542/3200)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.507% (2646/3328)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.456% (2746/3456)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.381% (2845/3584)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 79.176% (2939/3712)\n",
      "Train Epoch: 8 | Loss: 0.597 | Acc: 79.089% (3037/3840)\n",
      "Train Epoch: 8 | Loss: 0.597 | Acc: 79.083% (3138/3968)\n",
      "Train Epoch: 8 | Loss: 0.595 | Acc: 79.126% (3241/4096)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.261% (3348/4224)\n",
      "Train Epoch: 8 | Loss: 0.590 | Acc: 79.366% (3454/4352)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.420% (3558/4480)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.470% (3662/4608)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.455% (3763/4736)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 79.317% (3858/4864)\n",
      "Train Epoch: 8 | Loss: 0.594 | Acc: 79.327% (3960/4992)\n",
      "Train Epoch: 8 | Loss: 0.595 | Acc: 79.219% (4056/5120)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.211% (4157/5248)\n",
      "Train Epoch: 8 | Loss: 0.595 | Acc: 79.167% (4256/5376)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 79.179% (4358/5504)\n",
      "Train Epoch: 8 | Loss: 0.594 | Acc: 79.084% (4454/5632)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.045% (4553/5760)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.025% (4653/5888)\n",
      "Train Epoch: 8 | Loss: 0.589 | Acc: 79.106% (4759/6016)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 79.004% (4854/6144)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.018% (4956/6272)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.078% (5061/6400)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.013% (5158/6528)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 78.951% (5255/6656)\n",
      "Train Epoch: 8 | Loss: 0.594 | Acc: 78.906% (5353/6784)\n",
      "Train Epoch: 8 | Loss: 0.594 | Acc: 78.863% (5451/6912)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 78.892% (5554/7040)\n",
      "Train Epoch: 8 | Loss: 0.594 | Acc: 78.878% (5654/7168)\n",
      "Train Epoch: 8 | Loss: 0.596 | Acc: 78.810% (5750/7296)\n",
      "Train Epoch: 8 | Loss: 0.595 | Acc: 78.852% (5854/7424)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 78.893% (5958/7552)\n",
      "Train Epoch: 8 | Loss: 0.592 | Acc: 78.919% (6061/7680)\n",
      "Train Epoch: 8 | Loss: 0.593 | Acc: 78.983% (6167/7808)\n",
      "Train Epoch: 8 | Loss: 0.591 | Acc: 79.057% (6274/7936)\n",
      "Train Epoch: 8 | Loss: 0.590 | Acc: 79.105% (6379/8064)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.138% (6483/8192)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.159% (6586/8320)\n",
      "Train Epoch: 8 | Loss: 0.589 | Acc: 79.119% (6684/8448)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.174% (6790/8576)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.205% (6894/8704)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.246% (6999/8832)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.196% (7096/8960)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.126% (7191/9088)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.199% (7299/9216)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.206% (7401/9344)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.170% (7499/9472)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.250% (7608/9600)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.245% (7709/9728)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.221% (7808/9856)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.237% (7911/9984)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.272% (8016/10112)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.258% (8116/10240)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.196% (8211/10368)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.192% (8312/10496)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.217% (8416/10624)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.213% (8517/10752)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.173% (8614/10880)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.142% (8712/11008)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.149% (8814/11136)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.190% (8920/11264)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.213% (9024/11392)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.236% (9128/11520)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.190% (9224/11648)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.186% (9325/11776)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.217% (9430/11904)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.222% (9532/12032)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.235% (9635/12160)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.191% (9731/12288)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.228% (9837/12416)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.209% (9936/12544)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.190% (10035/12672)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.234% (10142/12800)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.301% (10252/12928)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.251% (10347/13056)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.293% (10454/13184)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.304% (10557/13312)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.323% (10661/13440)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.304% (10760/13568)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.264% (10856/13696)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.239% (10954/13824)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.229% (11054/13952)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.247% (11158/14080)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.237% (11258/14208)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.276% (11365/14336)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.328% (11474/14464)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.359% (11580/14592)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.368% (11683/14720)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.351% (11782/14848)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.334% (11881/14976)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.350% (11985/15104)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.379% (12091/15232)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.362% (12190/15360)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.397% (12297/15488)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.438% (12405/15616)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.414% (12503/15744)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.448% (12610/15872)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.425% (12708/16000)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.427% (12810/16128)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.411% (12909/16256)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.425% (13013/16384)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.433% (13116/16512)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.423% (13216/16640)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.431% (13319/16768)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.433% (13421/16896)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.447% (13525/17024)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.443% (13626/17152)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.450% (13729/17280)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.463% (13833/17408)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.465% (13935/17536)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.467% (14037/17664)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.451% (14136/17792)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.487% (14244/17920)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.466% (14342/18048)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.456% (14442/18176)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.447% (14542/18304)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.460% (14646/18432)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.504% (14756/18560)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.490% (14855/18688)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.486% (14956/18816)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.503% (15061/18944)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.514% (15165/19072)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.510% (15266/19200)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.517% (15369/19328)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.559% (15479/19456)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.555% (15580/19584)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.566% (15684/19712)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.536% (15780/19840)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.557% (15886/19968)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.533% (15983/20096)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.524% (16083/20224)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.574% (16195/20352)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.575% (16297/20480)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.566% (16397/20608)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.601% (16506/20736)\n",
      "Train Epoch: 8 | Loss: 0.579 | Acc: 79.616% (16611/20864)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.587% (16707/20992)\n",
      "Train Epoch: 8 | Loss: 0.580 | Acc: 79.560% (16803/21120)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.509% (16894/21248)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.514% (16997/21376)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.483% (17092/21504)\n",
      "Train Epoch: 8 | Loss: 0.581 | Acc: 79.498% (17197/21632)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.481% (17295/21760)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.459% (17392/21888)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.469% (17496/22016)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.462% (17596/22144)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.450% (17695/22272)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.433% (17793/22400)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.466% (17902/22528)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.484% (18008/22656)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.486% (18110/22784)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.469% (18208/22912)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.470% (18310/23040)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.472% (18412/23168)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.473% (18514/23296)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.466% (18614/23424)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.458% (18714/23552)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.502% (18826/23680)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.507% (18929/23808)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.466% (19021/23936)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.455% (19120/24064)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.477% (19227/24192)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.482% (19330/24320)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.426% (19418/24448)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.443% (19524/24576)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.453% (19628/24704)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.462% (19732/24832)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.487% (19840/24960)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.504% (19946/25088)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.485% (20043/25216)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.490% (20146/25344)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.468% (20242/25472)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.492% (20350/25600)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.485% (20450/25728)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.502% (20556/25856)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.514% (20661/25984)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.500% (20759/26112)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.478% (20855/26240)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.505% (20964/26368)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.525% (21071/26496)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.522% (21172/26624)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.504% (21269/26752)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.513% (21373/26880)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.506% (21473/27008)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.489% (21570/27136)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.515% (21679/27264)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.512% (21780/27392)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.524% (21885/27520)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.546% (21993/27648)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.543% (22094/27776)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.548% (22197/27904)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.563% (22303/28032)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.567% (22406/28160)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.546% (22502/28288)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.522% (22597/28416)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.533% (22702/28544)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.545% (22807/28672)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.521% (22902/28800)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.532% (23007/28928)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.546% (23113/29056)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.547% (23215/29184)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.565% (23322/29312)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.586% (23430/29440)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.593% (23534/29568)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.553% (23624/29696)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.567% (23730/29824)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.597% (23841/29952)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.598% (23943/30080)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.578% (24039/30208)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.589% (24144/30336)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.609% (24252/30464)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.625% (24359/30592)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.632% (24463/30720)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.603% (24556/30848)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.610% (24660/30976)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.610% (24762/31104)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.604% (24862/31232)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.598% (24962/31360)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.595% (25063/31488)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.599% (25166/31616)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.606% (25270/31744)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.597% (25369/31872)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.581% (25466/32000)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.600% (25574/32128)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.585% (25671/32256)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.598% (25777/32384)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.580% (25873/32512)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.599% (25981/32640)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.590% (26080/32768)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.578% (26178/32896)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.588% (26283/33024)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.603% (26390/33152)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.624% (26499/33280)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.631% (26603/33408)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.640% (26708/33536)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.670% (26820/33664)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.673% (26923/33792)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.649% (27017/33920)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.620% (27109/34048)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.608% (27207/34176)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.618% (27312/34304)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.621% (27415/34432)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.647% (27526/34560)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.662% (27633/34688)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.659% (27734/34816)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.679% (27843/34944)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.668% (27941/35072)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.673% (28045/35200)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.690% (28153/35328)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.690% (28255/35456)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.685% (28355/35584)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.682% (28456/35712)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.693% (28562/35840)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.693% (28664/35968)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.674% (28759/36096)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.671% (28860/36224)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.688% (28968/36352)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.707% (29077/36480)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.682% (29170/36608)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.682% (29272/36736)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.679% (29373/36864)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.660% (29468/36992)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.671% (29574/37120)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.669% (29675/37248)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.698% (29788/37376)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.690% (29887/37504)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.706% (29995/37632)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.706% (30097/37760)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.706% (30199/37888)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.693% (30296/38016)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.669% (30389/38144)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.648% (30483/38272)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.654% (30587/38400)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.659% (30691/38528)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.651% (30790/38656)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.667% (30898/38784)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.654% (30995/38912)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.662% (31100/39040)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.654% (31199/39168)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.657% (31302/39296)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.647% (31400/39424)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.652% (31504/39552)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.662% (31610/39680)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.660% (31711/39808)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.672% (31818/39936)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.673% (31920/40064)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.663% (32018/40192)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.655% (32117/40320)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.648% (32216/40448)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.646% (32317/40576)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.629% (32412/40704)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.634% (32516/40832)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.629% (32616/40960)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.627% (32717/41088)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.632% (32821/41216)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.613% (32915/41344)\n",
      "Train Epoch: 8 | Loss: 0.589 | Acc: 79.591% (33008/41472)\n",
      "Train Epoch: 8 | Loss: 0.589 | Acc: 79.603% (33115/41600)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.630% (33228/41728)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.609% (33321/41856)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.611% (33424/41984)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.619% (33529/42112)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.633% (33637/42240)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.628% (33737/42368)\n",
      "Train Epoch: 8 | Loss: 0.588 | Acc: 79.626% (33838/42496)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.655% (33952/42624)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.659% (34056/42752)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.650% (34154/42880)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.660% (34260/43008)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.662% (34363/43136)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.669% (34468/43264)\n",
      "Train Epoch: 8 | Loss: 0.587 | Acc: 79.685% (34577/43392)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.708% (34689/43520)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.720% (34796/43648)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.722% (34899/43776)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.724% (35002/43904)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.740% (35111/44032)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.744% (35215/44160)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.751% (35320/44288)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.757% (35425/44416)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.757% (35527/44544)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.755% (35628/44672)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.748% (35727/44800)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.743% (35827/44928)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.739% (35927/45056)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.734% (36027/45184)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.727% (36126/45312)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.723% (36226/45440)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.738% (36335/45568)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.729% (36433/45696)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.725% (36533/45824)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.720% (36633/45952)\n",
      "Train Epoch: 8 | Loss: 0.586 | Acc: 79.731% (36740/46080)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.744% (36848/46208)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.750% (36953/46336)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.759% (37059/46464)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.769% (37166/46592)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.782% (37274/46720)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.792% (37381/46848)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.773% (37474/46976)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.772% (37576/47104)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.779% (37681/47232)\n",
      "Train Epoch: 8 | Loss: 0.585 | Acc: 79.787% (37787/47360)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.791% (37891/47488)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.788% (37992/47616)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.809% (38104/47744)\n",
      "Train Epoch: 8 | Loss: 0.584 | Acc: 79.807% (38205/47872)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.812% (38310/48000)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.810% (38411/48128)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.833% (38524/48256)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.832% (38626/48384)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.830% (38727/48512)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.829% (38829/48640)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.829% (38931/48768)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.845% (39041/48896)\n",
      "Train Epoch: 8 | Loss: 0.582 | Acc: 79.843% (39142/49024)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.820% (39233/49152)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.823% (39337/49280)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.819% (39437/49408)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.831% (39545/49536)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.828% (39646/49664)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.824% (39746/49792)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.814% (39843/49920)\n",
      "Train Epoch: 8 | Loss: 0.583 | Acc: 79.808% (39904/50000)\n",
      "Test Epoch: 8 | Loss: 0.498 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 8 | Loss: 0.580 | Acc: 83.500% (167/200)\n",
      "Test Epoch: 8 | Loss: 0.567 | Acc: 82.333% (247/300)\n",
      "Test Epoch: 8 | Loss: 0.588 | Acc: 81.000% (324/400)\n",
      "Test Epoch: 8 | Loss: 0.590 | Acc: 81.000% (405/500)\n",
      "Test Epoch: 8 | Loss: 0.550 | Acc: 82.000% (492/600)\n",
      "Test Epoch: 8 | Loss: 0.561 | Acc: 81.857% (573/700)\n",
      "Test Epoch: 8 | Loss: 0.586 | Acc: 81.125% (649/800)\n",
      "Test Epoch: 8 | Loss: 0.607 | Acc: 80.111% (721/900)\n",
      "Test Epoch: 8 | Loss: 0.621 | Acc: 80.000% (800/1000)\n",
      "Test Epoch: 8 | Loss: 0.621 | Acc: 79.909% (879/1100)\n",
      "Test Epoch: 8 | Loss: 0.619 | Acc: 80.000% (960/1200)\n",
      "Test Epoch: 8 | Loss: 0.609 | Acc: 79.846% (1038/1300)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.929% (1119/1400)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.600% (1194/1500)\n",
      "Test Epoch: 8 | Loss: 0.614 | Acc: 79.500% (1272/1600)\n",
      "Test Epoch: 8 | Loss: 0.611 | Acc: 79.588% (1353/1700)\n",
      "Test Epoch: 8 | Loss: 0.617 | Acc: 79.278% (1427/1800)\n",
      "Test Epoch: 8 | Loss: 0.615 | Acc: 79.368% (1508/1900)\n",
      "Test Epoch: 8 | Loss: 0.623 | Acc: 79.100% (1582/2000)\n",
      "Test Epoch: 8 | Loss: 0.621 | Acc: 78.952% (1658/2100)\n",
      "Test Epoch: 8 | Loss: 0.628 | Acc: 78.591% (1729/2200)\n",
      "Test Epoch: 8 | Loss: 0.634 | Acc: 78.478% (1805/2300)\n",
      "Test Epoch: 8 | Loss: 0.641 | Acc: 78.250% (1878/2400)\n",
      "Test Epoch: 8 | Loss: 0.644 | Acc: 78.280% (1957/2500)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.077% (2030/2600)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.000% (2106/2700)\n",
      "Test Epoch: 8 | Loss: 0.658 | Acc: 78.143% (2188/2800)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.345% (2272/2900)\n",
      "Test Epoch: 8 | Loss: 0.654 | Acc: 78.433% (2353/3000)\n",
      "Test Epoch: 8 | Loss: 0.654 | Acc: 78.452% (2432/3100)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.406% (2509/3200)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.455% (2589/3300)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.265% (2661/3400)\n",
      "Test Epoch: 8 | Loss: 0.666 | Acc: 78.171% (2736/3500)\n",
      "Test Epoch: 8 | Loss: 0.667 | Acc: 78.194% (2815/3600)\n",
      "Test Epoch: 8 | Loss: 0.667 | Acc: 78.108% (2890/3700)\n",
      "Test Epoch: 8 | Loss: 0.664 | Acc: 78.184% (2971/3800)\n",
      "Test Epoch: 8 | Loss: 0.660 | Acc: 78.282% (3053/3900)\n",
      "Test Epoch: 8 | Loss: 0.660 | Acc: 78.300% (3132/4000)\n",
      "Test Epoch: 8 | Loss: 0.660 | Acc: 78.220% (3207/4100)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.310% (3289/4200)\n",
      "Test Epoch: 8 | Loss: 0.657 | Acc: 78.512% (3376/4300)\n",
      "Test Epoch: 8 | Loss: 0.658 | Acc: 78.568% (3457/4400)\n",
      "Test Epoch: 8 | Loss: 0.657 | Acc: 78.622% (3538/4500)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.674% (3619/4600)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.638% (3696/4700)\n",
      "Test Epoch: 8 | Loss: 0.657 | Acc: 78.688% (3777/4800)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.735% (3858/4900)\n",
      "Test Epoch: 8 | Loss: 0.658 | Acc: 78.600% (3930/5000)\n",
      "Test Epoch: 8 | Loss: 0.657 | Acc: 78.588% (4008/5100)\n",
      "Test Epoch: 8 | Loss: 0.661 | Acc: 78.423% (4078/5200)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.340% (4152/5300)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.333% (4230/5400)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.309% (4307/5500)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.321% (4386/5600)\n",
      "Test Epoch: 8 | Loss: 0.662 | Acc: 78.281% (4462/5700)\n",
      "Test Epoch: 8 | Loss: 0.661 | Acc: 78.328% (4543/5800)\n",
      "Test Epoch: 8 | Loss: 0.663 | Acc: 78.237% (4616/5900)\n",
      "Test Epoch: 8 | Loss: 0.663 | Acc: 78.167% (4690/6000)\n",
      "Test Epoch: 8 | Loss: 0.664 | Acc: 78.082% (4763/6100)\n",
      "Test Epoch: 8 | Loss: 0.664 | Acc: 78.081% (4841/6200)\n",
      "Test Epoch: 8 | Loss: 0.661 | Acc: 78.127% (4922/6300)\n",
      "Test Epoch: 8 | Loss: 0.659 | Acc: 78.219% (5006/6400)\n",
      "Test Epoch: 8 | Loss: 0.660 | Acc: 78.185% (5082/6500)\n",
      "Test Epoch: 8 | Loss: 0.658 | Acc: 78.227% (5163/6600)\n",
      "Test Epoch: 8 | Loss: 0.654 | Acc: 78.418% (5254/6700)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.426% (5333/6800)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.435% (5412/6900)\n",
      "Test Epoch: 8 | Loss: 0.657 | Acc: 78.400% (5488/7000)\n",
      "Test Epoch: 8 | Loss: 0.656 | Acc: 78.465% (5571/7100)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.542% (5655/7200)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.644% (5741/7300)\n",
      "Test Epoch: 8 | Loss: 0.650 | Acc: 78.662% (5821/7400)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.613% (5896/7500)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.632% (5976/7600)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.584% (6051/7700)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.577% (6129/7800)\n",
      "Test Epoch: 8 | Loss: 0.654 | Acc: 78.582% (6208/7900)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.575% (6286/8000)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.630% (6369/8100)\n",
      "Test Epoch: 8 | Loss: 0.651 | Acc: 78.683% (6452/8200)\n",
      "Test Epoch: 8 | Loss: 0.651 | Acc: 78.639% (6527/8300)\n",
      "Test Epoch: 8 | Loss: 0.651 | Acc: 78.667% (6608/8400)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.588% (6680/8500)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.605% (6760/8600)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.586% (6837/8700)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.614% (6918/8800)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.652% (7000/8900)\n",
      "Test Epoch: 8 | Loss: 0.653 | Acc: 78.656% (7079/9000)\n",
      "Test Epoch: 8 | Loss: 0.655 | Acc: 78.637% (7156/9100)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.707% (7241/9200)\n",
      "Test Epoch: 8 | Loss: 0.652 | Acc: 78.699% (7319/9300)\n",
      "Test Epoch: 8 | Loss: 0.650 | Acc: 78.734% (7401/9400)\n",
      "Test Epoch: 8 | Loss: 0.650 | Acc: 78.705% (7477/9500)\n",
      "Test Epoch: 8 | Loss: 0.647 | Acc: 78.771% (7562/9600)\n",
      "Test Epoch: 8 | Loss: 0.645 | Acc: 78.835% (7647/9700)\n",
      "Test Epoch: 8 | Loss: 0.648 | Acc: 78.786% (7721/9800)\n",
      "Test Epoch: 8 | Loss: 0.647 | Acc: 78.788% (7800/9900)\n",
      "Test Epoch: 8 | Loss: 0.648 | Acc: 78.760% (7876/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Train Epoch: 9 | Loss: 0.655 | Acc: 78.906% (101/128)\n",
      "Train Epoch: 9 | Loss: 0.598 | Acc: 81.250% (208/256)\n",
      "Train Epoch: 9 | Loss: 0.562 | Acc: 81.250% (312/384)\n",
      "Train Epoch: 9 | Loss: 0.526 | Acc: 82.227% (421/512)\n",
      "Train Epoch: 9 | Loss: 0.502 | Acc: 82.344% (527/640)\n",
      "Train Epoch: 9 | Loss: 0.519 | Acc: 81.771% (628/768)\n",
      "Train Epoch: 9 | Loss: 0.523 | Acc: 81.696% (732/896)\n",
      "Train Epoch: 9 | Loss: 0.541 | Acc: 81.250% (832/1024)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.990% (933/1152)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.859% (1035/1280)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.682% (1136/1408)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.924% (1243/1536)\n",
      "Train Epoch: 9 | Loss: 0.570 | Acc: 80.409% (1338/1664)\n",
      "Train Epoch: 9 | Loss: 0.576 | Acc: 80.078% (1435/1792)\n",
      "Train Epoch: 9 | Loss: 0.571 | Acc: 80.365% (1543/1920)\n",
      "Train Epoch: 9 | Loss: 0.573 | Acc: 80.273% (1644/2048)\n",
      "Train Epoch: 9 | Loss: 0.570 | Acc: 80.377% (1749/2176)\n",
      "Train Epoch: 9 | Loss: 0.564 | Acc: 80.642% (1858/2304)\n",
      "Train Epoch: 9 | Loss: 0.564 | Acc: 80.798% (1965/2432)\n",
      "Train Epoch: 9 | Loss: 0.560 | Acc: 80.977% (2073/2560)\n",
      "Train Epoch: 9 | Loss: 0.563 | Acc: 80.804% (2172/2688)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 81.072% (2283/2816)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.284% (2393/2944)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 81.380% (2500/3072)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.250% (2600/3200)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.100% (2699/3328)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 81.047% (2801/3456)\n",
      "Train Epoch: 9 | Loss: 0.550 | Acc: 81.166% (2909/3584)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.115% (3011/3712)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.964% (3109/3840)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 81.225% (3223/3968)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 81.055% (3320/4096)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 81.108% (3426/4224)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.882% (3520/4352)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.027% (3630/4480)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.011% (3733/4608)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 81.018% (3837/4736)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.942% (3937/4864)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.990% (4043/4992)\n",
      "Train Epoch: 9 | Loss: 0.560 | Acc: 80.957% (4145/5120)\n",
      "Train Epoch: 9 | Loss: 0.558 | Acc: 80.983% (4250/5248)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 81.027% (4356/5376)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.996% (4458/5504)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 81.037% (4564/5632)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.990% (4665/5760)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.978% (4768/5888)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.868% (4865/6016)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.859% (4968/6144)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.756% (5065/6272)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.734% (5167/6400)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.806% (5275/6528)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.784% (5377/6656)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.734% (5477/6784)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.773% (5583/6912)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.710% (5682/7040)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.748% (5788/7168)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.811% (5896/7296)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.873% (6004/7424)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.707% (6095/7552)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.703% (6198/7680)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.635% (6296/7808)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.645% (6400/7936)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.692% (6507/8064)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.762% (6616/8192)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.709% (6715/8320)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 80.694% (6817/8448)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.702% (6921/8576)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.699% (7024/8704)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.684% (7126/8832)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 80.770% (7237/8960)\n",
      "Train Epoch: 9 | Loss: 0.550 | Acc: 80.843% (7347/9088)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.935% (7459/9216)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.993% (7568/9344)\n",
      "Train Epoch: 9 | Loss: 0.549 | Acc: 80.986% (7671/9472)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.062% (7782/9600)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.065% (7886/9728)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.996% (7983/9856)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 81.000% (8087/9984)\n",
      "Train Epoch: 9 | Loss: 0.550 | Acc: 80.934% (8184/10112)\n",
      "Train Epoch: 9 | Loss: 0.550 | Acc: 80.986% (8293/10240)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.903% (8388/10368)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.907% (8492/10496)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.855% (8590/10624)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.794% (8687/10752)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.772% (8788/10880)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.759% (8890/11008)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.756% (8993/11136)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.735% (9094/11264)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.706% (9194/11392)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.634% (9289/11520)\n",
      "Train Epoch: 9 | Loss: 0.557 | Acc: 80.658% (9395/11648)\n",
      "Train Epoch: 9 | Loss: 0.556 | Acc: 80.707% (9504/11776)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.771% (9615/11904)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.751% (9716/12032)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.740% (9818/12160)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.754% (9923/12288)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.743% (10025/12416)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.748% (10129/12544)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.769% (10235/12672)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.719% (10332/12800)\n",
      "Train Epoch: 9 | Loss: 0.555 | Acc: 80.709% (10434/12928)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.806% (10550/13056)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.765% (10648/13184)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.807% (10757/13312)\n",
      "Train Epoch: 9 | Loss: 0.554 | Acc: 80.722% (10849/13440)\n",
      "Train Epoch: 9 | Loss: 0.553 | Acc: 80.756% (10957/13568)\n",
      "Train Epoch: 9 | Loss: 0.552 | Acc: 80.827% (11070/13696)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.867% (11179/13824)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.892% (11286/13952)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.888% (11389/14080)\n",
      "Train Epoch: 9 | Loss: 0.551 | Acc: 80.891% (11493/14208)\n",
      "Train Epoch: 9 | Loss: 0.550 | Acc: 80.894% (11597/14336)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.973% (11712/14464)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.976% (11816/14592)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.985% (11921/14720)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.987% (12025/14848)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.036% (12136/14976)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.038% (12240/15104)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.040% (12344/15232)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.035% (12447/15360)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.024% (12549/15488)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 80.994% (12648/15616)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.958% (12746/15744)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.979% (12853/15872)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.938% (12950/16000)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.952% (13056/16128)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.912% (13153/16256)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.933% (13260/16384)\n",
      "Train Epoch: 9 | Loss: 0.549 | Acc: 80.887% (13356/16512)\n",
      "Train Epoch: 9 | Loss: 0.549 | Acc: 80.883% (13459/16640)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.880% (13562/16768)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.859% (13662/16896)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.856% (13765/17024)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.859% (13869/17152)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.891% (13978/17280)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.900% (14083/17408)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.919% (14190/17536)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.922% (14294/17664)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.907% (14395/17792)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.932% (14503/17920)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.934% (14607/18048)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.942% (14712/18176)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.971% (14821/18304)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.952% (14921/18432)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.948% (15024/18560)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.924% (15123/18688)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.936% (15229/18816)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.960% (15337/18944)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.977% (15444/19072)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.026% (15557/19200)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.017% (15659/19328)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.039% (15767/19456)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.010% (15865/19584)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.052% (15977/19712)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.064% (16083/19840)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.085% (16191/19968)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.086% (16295/20096)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.072% (16396/20224)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.053% (16496/20352)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.030% (16595/20480)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.041% (16701/20608)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.076% (16812/20736)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.030% (16906/20864)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.050% (17014/20992)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.061% (17120/21120)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.081% (17228/21248)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.039% (17323/21376)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.073% (17434/21504)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.056% (17534/21632)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.034% (17633/21760)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.063% (17743/21888)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.073% (17849/22016)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.096% (17958/22144)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.133% (18070/22272)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.116% (18170/22400)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.130% (18277/22528)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.140% (18383/22656)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.136% (18486/22784)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.097% (18581/22912)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.128% (18692/23040)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.121% (18794/23168)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.168% (18909/23296)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.152% (19009/23424)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.178% (19119/23552)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.182% (19224/23680)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.166% (19324/23808)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.166% (19428/23936)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.159% (19530/24064)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.143% (19630/24192)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.139% (19733/24320)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.127% (19834/24448)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.095% (19930/24576)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.096% (20034/24704)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.097% (20138/24832)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.090% (20240/24960)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.118% (20351/25088)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.135% (20459/25216)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.179% (20574/25344)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.195% (20682/25472)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.211% (20790/25600)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.242% (20902/25728)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.231% (21003/25856)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.246% (21111/25984)\n",
      "Train Epoch: 9 | Loss: 0.542 | Acc: 81.258% (21218/26112)\n",
      "Train Epoch: 9 | Loss: 0.542 | Acc: 81.265% (21324/26240)\n",
      "Train Epoch: 9 | Loss: 0.542 | Acc: 81.258% (21426/26368)\n",
      "Train Epoch: 9 | Loss: 0.541 | Acc: 81.288% (21538/26496)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.265% (21636/26624)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.243% (21734/26752)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.231% (21835/26880)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.231% (21939/27008)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.250% (22048/27136)\n",
      "Train Epoch: 9 | Loss: 0.542 | Acc: 81.254% (22153/27264)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.199% (22242/27392)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.188% (22343/27520)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.199% (22450/27648)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.178% (22548/27776)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.157% (22646/27904)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.118% (22739/28032)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.101% (22838/28160)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.077% (22935/28288)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.106% (23047/28416)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.106% (23151/28544)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.114% (23257/28672)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.108% (23359/28800)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.108% (23463/28928)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.112% (23568/29056)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.110% (23671/29184)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.107% (23774/29312)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.135% (23886/29440)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.145% (23993/29568)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.152% (24099/29696)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.166% (24207/29824)\n",
      "Train Epoch: 9 | Loss: 0.543 | Acc: 81.167% (24311/29952)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.157% (24412/30080)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.161% (24517/30208)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.161% (24621/30336)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.155% (24723/30464)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.158% (24828/30592)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.156% (24931/30720)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.153% (25034/30848)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.147% (25136/30976)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.125% (25233/31104)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.112% (25333/31232)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.100% (25433/31360)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.088% (25533/31488)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.063% (25629/31616)\n",
      "Train Epoch: 9 | Loss: 0.545 | Acc: 81.052% (25729/31744)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.049% (25832/31872)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.053% (25937/32000)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.045% (26038/32128)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.045% (26142/32256)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.059% (26250/32384)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.062% (26355/32512)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.048% (26454/32640)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.030% (26552/32768)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.040% (26659/32896)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.026% (26758/33024)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.042% (26867/33152)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.049% (26973/33280)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.026% (27069/33408)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.041% (27178/33536)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.054% (27286/33664)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.022% (27379/33792)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.029% (27485/33920)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.009% (27582/34048)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.007% (27685/34176)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.011% (27790/34304)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.032% (27901/34432)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.027% (28003/34560)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.034% (28109/34688)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.023% (28209/34816)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.998% (28304/34944)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.996% (28407/35072)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.003% (28513/35200)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.981% (28609/35328)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.979% (28712/35456)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.966% (28811/35584)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.967% (28915/35712)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.951% (29013/35840)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.958% (29119/35968)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.976% (29229/36096)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.946% (29322/36224)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.964% (29432/36352)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.948% (29530/36480)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.955% (29636/36608)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.934% (29732/36736)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.930% (29834/36864)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.939% (29941/36992)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.938% (30044/37120)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.957% (30155/37248)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.948% (30255/37376)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.951% (30360/37504)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.960% (30467/37632)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.935% (30561/37760)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.925% (30661/37888)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.916% (30761/38016)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.907% (30861/38144)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.897% (30961/38272)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.911% (31070/38400)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.913% (31174/38528)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.893% (31270/38656)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.899% (31376/38784)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.908% (31483/38912)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.925% (31593/39040)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.928% (31698/39168)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.945% (31808/39296)\n",
      "Train Epoch: 9 | Loss: 0.549 | Acc: 80.908% (31897/39424)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.914% (32003/39552)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.915% (32107/39680)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.923% (32214/39808)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.917% (32315/39936)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.936% (32426/40064)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.949% (32535/40192)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.957% (32642/40320)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.953% (32744/40448)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.939% (32842/40576)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.950% (32950/40704)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.966% (33060/40832)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.964% (33163/40960)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.977% (33272/41088)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.973% (33374/41216)\n",
      "Train Epoch: 9 | Loss: 0.548 | Acc: 80.950% (33468/41344)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.970% (33580/41472)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.959% (33679/41600)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.967% (33786/41728)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.978% (33894/41856)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.971% (33995/41984)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.956% (34092/42112)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.956% (34196/42240)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.974% (34307/42368)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.982% (34414/42496)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.990% (34521/42624)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.993% (34626/42752)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.996% (34731/42880)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.983% (34829/43008)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.969% (34927/43136)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.975% (35033/43264)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.969% (35134/43392)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.958% (35233/43520)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.961% (35338/43648)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.964% (35443/43776)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.972% (35550/43904)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.964% (35650/44032)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.976% (35759/44160)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.956% (35854/44288)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.960% (35959/44416)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.954% (36060/44544)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.946% (36160/44672)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.951% (36266/44800)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.958% (36373/44928)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.959% (36477/45056)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.958% (36580/45184)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.965% (36687/45312)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.977% (36796/45440)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.978% (36900/45568)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.985% (37007/45696)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.986% (37111/45824)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.980% (37212/45952)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.974% (37313/46080)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.969% (37414/46208)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.972% (37519/46336)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.977% (37625/46464)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.986% (37733/46592)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.991% (37839/46720)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.996% (37945/46848)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.995% (38048/46976)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.989% (38149/47104)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.983% (38250/47232)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 80.990% (38357/47360)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.004% (38467/47488)\n",
      "Train Epoch: 9 | Loss: 0.547 | Acc: 81.006% (38572/47616)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.005% (38675/47744)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.001% (38777/47872)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.013% (38886/48000)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.982% (38975/48128)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.989% (39082/48256)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.988% (39185/48384)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.001% (39295/48512)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.007% (39402/48640)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.004% (39504/48768)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.007% (39609/48896)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.003% (39711/49024)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.992% (39809/49152)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.998% (39916/49280)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 81.013% (40027/49408)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.992% (40120/49536)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.990% (40223/49664)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.983% (40323/49792)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.976% (40423/49920)\n",
      "Train Epoch: 9 | Loss: 0.546 | Acc: 80.980% (40490/50000)\n",
      "Test Epoch: 9 | Loss: 0.457 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 9 | Loss: 0.554 | Acc: 83.500% (167/200)\n",
      "Test Epoch: 9 | Loss: 0.522 | Acc: 84.667% (254/300)\n",
      "Test Epoch: 9 | Loss: 0.512 | Acc: 83.500% (334/400)\n",
      "Test Epoch: 9 | Loss: 0.526 | Acc: 82.400% (412/500)\n",
      "Test Epoch: 9 | Loss: 0.481 | Acc: 83.667% (502/600)\n",
      "Test Epoch: 9 | Loss: 0.507 | Acc: 83.143% (582/700)\n",
      "Test Epoch: 9 | Loss: 0.543 | Acc: 82.125% (657/800)\n",
      "Test Epoch: 9 | Loss: 0.562 | Acc: 81.556% (734/900)\n",
      "Test Epoch: 9 | Loss: 0.578 | Acc: 81.700% (817/1000)\n",
      "Test Epoch: 9 | Loss: 0.589 | Acc: 81.182% (893/1100)\n",
      "Test Epoch: 9 | Loss: 0.590 | Acc: 80.917% (971/1200)\n",
      "Test Epoch: 9 | Loss: 0.583 | Acc: 80.769% (1050/1300)\n",
      "Test Epoch: 9 | Loss: 0.574 | Acc: 80.643% (1129/1400)\n",
      "Test Epoch: 9 | Loss: 0.569 | Acc: 80.667% (1210/1500)\n",
      "Test Epoch: 9 | Loss: 0.583 | Acc: 80.625% (1290/1600)\n",
      "Test Epoch: 9 | Loss: 0.582 | Acc: 80.706% (1372/1700)\n",
      "Test Epoch: 9 | Loss: 0.585 | Acc: 80.500% (1449/1800)\n",
      "Test Epoch: 9 | Loss: 0.585 | Acc: 80.474% (1529/1900)\n",
      "Test Epoch: 9 | Loss: 0.604 | Acc: 80.050% (1601/2000)\n",
      "Test Epoch: 9 | Loss: 0.611 | Acc: 79.762% (1675/2100)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.500% (1749/2200)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.478% (1828/2300)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.458% (1907/2400)\n",
      "Test Epoch: 9 | Loss: 0.626 | Acc: 79.440% (1986/2500)\n",
      "Test Epoch: 9 | Loss: 0.634 | Acc: 79.192% (2059/2600)\n",
      "Test Epoch: 9 | Loss: 0.631 | Acc: 79.370% (2143/2700)\n",
      "Test Epoch: 9 | Loss: 0.633 | Acc: 79.429% (2224/2800)\n",
      "Test Epoch: 9 | Loss: 0.636 | Acc: 79.310% (2300/2900)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 79.300% (2379/3000)\n",
      "Test Epoch: 9 | Loss: 0.636 | Acc: 79.419% (2462/3100)\n",
      "Test Epoch: 9 | Loss: 0.636 | Acc: 79.438% (2542/3200)\n",
      "Test Epoch: 9 | Loss: 0.633 | Acc: 79.636% (2628/3300)\n",
      "Test Epoch: 9 | Loss: 0.636 | Acc: 79.471% (2702/3400)\n",
      "Test Epoch: 9 | Loss: 0.641 | Acc: 79.286% (2775/3500)\n",
      "Test Epoch: 9 | Loss: 0.641 | Acc: 79.278% (2854/3600)\n",
      "Test Epoch: 9 | Loss: 0.640 | Acc: 79.270% (2933/3700)\n",
      "Test Epoch: 9 | Loss: 0.642 | Acc: 79.184% (3009/3800)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 79.333% (3094/3900)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 79.400% (3176/4000)\n",
      "Test Epoch: 9 | Loss: 0.641 | Acc: 79.341% (3253/4100)\n",
      "Test Epoch: 9 | Loss: 0.642 | Acc: 79.238% (3328/4200)\n",
      "Test Epoch: 9 | Loss: 0.637 | Acc: 79.349% (3412/4300)\n",
      "Test Epoch: 9 | Loss: 0.639 | Acc: 79.364% (3492/4400)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 79.378% (3572/4500)\n",
      "Test Epoch: 9 | Loss: 0.639 | Acc: 79.435% (3654/4600)\n",
      "Test Epoch: 9 | Loss: 0.637 | Acc: 79.489% (3736/4700)\n",
      "Test Epoch: 9 | Loss: 0.639 | Acc: 79.458% (3814/4800)\n",
      "Test Epoch: 9 | Loss: 0.636 | Acc: 79.571% (3899/4900)\n",
      "Test Epoch: 9 | Loss: 0.637 | Acc: 79.560% (3978/5000)\n",
      "Test Epoch: 9 | Loss: 0.637 | Acc: 79.588% (4059/5100)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 79.558% (4137/5200)\n",
      "Test Epoch: 9 | Loss: 0.635 | Acc: 79.547% (4216/5300)\n",
      "Test Epoch: 9 | Loss: 0.635 | Acc: 79.556% (4296/5400)\n",
      "Test Epoch: 9 | Loss: 0.633 | Acc: 79.582% (4377/5500)\n",
      "Test Epoch: 9 | Loss: 0.633 | Acc: 79.589% (4457/5600)\n",
      "Test Epoch: 9 | Loss: 0.632 | Acc: 79.544% (4534/5700)\n",
      "Test Epoch: 9 | Loss: 0.630 | Acc: 79.603% (4617/5800)\n",
      "Test Epoch: 9 | Loss: 0.630 | Acc: 79.627% (4698/5900)\n",
      "Test Epoch: 9 | Loss: 0.629 | Acc: 79.683% (4781/6000)\n",
      "Test Epoch: 9 | Loss: 0.629 | Acc: 79.689% (4861/6100)\n",
      "Test Epoch: 9 | Loss: 0.628 | Acc: 79.742% (4944/6200)\n",
      "Test Epoch: 9 | Loss: 0.626 | Acc: 79.794% (5027/6300)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.875% (5112/6400)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.862% (5191/6500)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.818% (5268/6600)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.896% (5353/6700)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.779% (5425/6800)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.739% (5502/6900)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.743% (5582/7000)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.789% (5665/7100)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.847% (5749/7200)\n",
      "Test Epoch: 9 | Loss: 0.616 | Acc: 79.918% (5834/7300)\n",
      "Test Epoch: 9 | Loss: 0.615 | Acc: 79.905% (5913/7400)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.813% (5986/7500)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.803% (6065/7600)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.805% (6145/7700)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.769% (6222/7800)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.772% (6302/7900)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.763% (6381/8000)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.765% (6461/8100)\n",
      "Test Epoch: 9 | Loss: 0.618 | Acc: 79.805% (6544/8200)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.807% (6624/8300)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.690% (6694/8400)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.624% (6768/8500)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.686% (6853/8600)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.678% (6932/8700)\n",
      "Test Epoch: 9 | Loss: 0.623 | Acc: 79.659% (7010/8800)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.652% (7089/8900)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.633% (7167/9000)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.659% (7249/9100)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.761% (7338/9200)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.710% (7413/9300)\n",
      "Test Epoch: 9 | Loss: 0.621 | Acc: 79.702% (7492/9400)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.684% (7570/9500)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.708% (7652/9600)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.742% (7735/9700)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 79.684% (7809/9800)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.737% (7894/9900)\n",
      "Test Epoch: 9 | Loss: 0.620 | Acc: 79.720% (7972/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "Train Epoch: 10 | Loss: 0.564 | Acc: 78.906% (101/128)\n",
      "Train Epoch: 10 | Loss: 0.526 | Acc: 80.078% (205/256)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 80.469% (309/384)\n",
      "Train Epoch: 10 | Loss: 0.546 | Acc: 80.273% (411/512)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 80.938% (518/640)\n",
      "Train Epoch: 10 | Loss: 0.536 | Acc: 80.990% (622/768)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.027% (726/896)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.348% (833/1024)\n",
      "Train Epoch: 10 | Loss: 0.538 | Acc: 81.250% (936/1152)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.859% (1035/1280)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 81.037% (1141/1408)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.534% (1237/1536)\n",
      "Train Epoch: 10 | Loss: 0.561 | Acc: 80.168% (1334/1664)\n",
      "Train Epoch: 10 | Loss: 0.554 | Acc: 80.469% (1442/1792)\n",
      "Train Epoch: 10 | Loss: 0.551 | Acc: 80.521% (1546/1920)\n",
      "Train Epoch: 10 | Loss: 0.550 | Acc: 80.615% (1651/2048)\n",
      "Train Epoch: 10 | Loss: 0.553 | Acc: 80.561% (1753/2176)\n",
      "Train Epoch: 10 | Loss: 0.551 | Acc: 80.512% (1855/2304)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 80.839% (1966/2432)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.703% (2066/2560)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 80.766% (2171/2688)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 80.753% (2274/2816)\n",
      "Train Epoch: 10 | Loss: 0.552 | Acc: 80.571% (2372/2944)\n",
      "Train Epoch: 10 | Loss: 0.551 | Acc: 80.469% (2472/3072)\n",
      "Train Epoch: 10 | Loss: 0.550 | Acc: 80.531% (2577/3200)\n",
      "Train Epoch: 10 | Loss: 0.552 | Acc: 80.469% (2678/3328)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.787% (2792/3456)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.748% (2894/3584)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.846% (3001/3712)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 80.833% (3104/3840)\n",
      "Train Epoch: 10 | Loss: 0.540 | Acc: 80.973% (3213/3968)\n",
      "Train Epoch: 10 | Loss: 0.542 | Acc: 81.055% (3320/4096)\n",
      "Train Epoch: 10 | Loss: 0.541 | Acc: 81.132% (3427/4224)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 81.066% (3528/4352)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.848% (3622/4480)\n",
      "Train Epoch: 10 | Loss: 0.551 | Acc: 80.794% (3723/4608)\n",
      "Train Epoch: 10 | Loss: 0.546 | Acc: 80.997% (3836/4736)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 80.962% (3938/4864)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 80.990% (4043/4992)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.074% (4151/5120)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 80.983% (4250/5248)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.952% (4352/5376)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.159% (4467/5504)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.143% (4570/5632)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.146% (4674/5760)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.961% (4767/5888)\n",
      "Train Epoch: 10 | Loss: 0.550 | Acc: 80.818% (4862/6016)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.973% (4975/6144)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.867% (5072/6272)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.828% (5173/6400)\n",
      "Train Epoch: 10 | Loss: 0.550 | Acc: 80.790% (5274/6528)\n",
      "Train Epoch: 10 | Loss: 0.550 | Acc: 80.829% (5380/6656)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.896% (5488/6784)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.961% (5596/6912)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.909% (5696/7040)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.845% (5795/7168)\n",
      "Train Epoch: 10 | Loss: 0.549 | Acc: 80.811% (5896/7296)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.886% (6005/7424)\n",
      "Train Epoch: 10 | Loss: 0.548 | Acc: 80.866% (6107/7552)\n",
      "Train Epoch: 10 | Loss: 0.546 | Acc: 80.964% (6218/7680)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.891% (6316/7808)\n",
      "Train Epoch: 10 | Loss: 0.546 | Acc: 80.922% (6422/7936)\n",
      "Train Epoch: 10 | Loss: 0.547 | Acc: 80.890% (6523/8064)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 80.994% (6635/8192)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 81.010% (6740/8320)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.061% (6848/8448)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.110% (6956/8576)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.124% (7061/8704)\n",
      "Train Epoch: 10 | Loss: 0.544 | Acc: 81.148% (7167/8832)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.161% (7272/8960)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.140% (7374/9088)\n",
      "Train Epoch: 10 | Loss: 0.545 | Acc: 81.098% (7474/9216)\n",
      "Train Epoch: 10 | Loss: 0.543 | Acc: 81.154% (7583/9344)\n",
      "Train Epoch: 10 | Loss: 0.541 | Acc: 81.187% (7690/9472)\n",
      "Train Epoch: 10 | Loss: 0.540 | Acc: 81.198% (7795/9600)\n",
      "Train Epoch: 10 | Loss: 0.540 | Acc: 81.219% (7901/9728)\n",
      "Train Epoch: 10 | Loss: 0.539 | Acc: 81.250% (8008/9856)\n",
      "Train Epoch: 10 | Loss: 0.538 | Acc: 81.340% (8121/9984)\n",
      "Train Epoch: 10 | Loss: 0.538 | Acc: 81.309% (8222/10112)\n",
      "Train Epoch: 10 | Loss: 0.536 | Acc: 81.367% (8332/10240)\n",
      "Train Epoch: 10 | Loss: 0.534 | Acc: 81.443% (8444/10368)\n",
      "Train Epoch: 10 | Loss: 0.534 | Acc: 81.402% (8544/10496)\n",
      "Train Epoch: 10 | Loss: 0.534 | Acc: 81.419% (8650/10624)\n",
      "Train Epoch: 10 | Loss: 0.535 | Acc: 81.390% (8751/10752)\n",
      "Train Epoch: 10 | Loss: 0.535 | Acc: 81.388% (8855/10880)\n",
      "Train Epoch: 10 | Loss: 0.536 | Acc: 81.386% (8959/11008)\n",
      "Train Epoch: 10 | Loss: 0.535 | Acc: 81.448% (9070/11136)\n",
      "Train Epoch: 10 | Loss: 0.535 | Acc: 81.472% (9177/11264)\n",
      "Train Epoch: 10 | Loss: 0.533 | Acc: 81.540% (9289/11392)\n",
      "Train Epoch: 10 | Loss: 0.532 | Acc: 81.632% (9404/11520)\n",
      "Train Epoch: 10 | Loss: 0.532 | Acc: 81.619% (9507/11648)\n",
      "Train Epoch: 10 | Loss: 0.531 | Acc: 81.641% (9614/11776)\n",
      "Train Epoch: 10 | Loss: 0.530 | Acc: 81.704% (9726/11904)\n",
      "Train Epoch: 10 | Loss: 0.529 | Acc: 81.749% (9836/12032)\n",
      "Train Epoch: 10 | Loss: 0.529 | Acc: 81.760% (9942/12160)\n",
      "Train Epoch: 10 | Loss: 0.529 | Acc: 81.779% (10049/12288)\n",
      "Train Epoch: 10 | Loss: 0.527 | Acc: 81.822% (10159/12416)\n",
      "Train Epoch: 10 | Loss: 0.526 | Acc: 81.880% (10271/12544)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.937% (10383/12672)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.969% (10492/12800)\n",
      "Train Epoch: 10 | Loss: 0.524 | Acc: 82.000% (10601/12928)\n",
      "Train Epoch: 10 | Loss: 0.524 | Acc: 81.962% (10701/13056)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.940% (10803/13184)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.919% (10905/13312)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.890% (11006/13440)\n",
      "Train Epoch: 10 | Loss: 0.526 | Acc: 81.906% (11113/13568)\n",
      "Train Epoch: 10 | Loss: 0.527 | Acc: 81.900% (11217/13696)\n",
      "Train Epoch: 10 | Loss: 0.526 | Acc: 81.937% (11327/13824)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.995% (11440/13952)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.974% (11542/14080)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.975% (11647/14208)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.982% (11753/14336)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.983% (11858/14464)\n",
      "Train Epoch: 10 | Loss: 0.525 | Acc: 81.949% (11958/14592)\n",
      "Train Epoch: 10 | Loss: 0.524 | Acc: 81.984% (12068/14720)\n",
      "Train Epoch: 10 | Loss: 0.524 | Acc: 81.984% (12173/14848)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 81.998% (12280/14976)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.011% (12387/15104)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.018% (12493/15232)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.018% (12598/15360)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.031% (12705/15488)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.076% (12817/15616)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.050% (12918/15744)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.012% (13017/15872)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.025% (13124/16000)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.037% (13231/16128)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.037% (13336/16256)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 81.995% (13434/16384)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 81.977% (13536/16512)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.025% (13649/16640)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.073% (13762/16768)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.090% (13870/16896)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.072% (13972/17024)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.125% (14086/17152)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.159% (14197/17280)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.163% (14303/17408)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.185% (14412/17536)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.161% (14513/17664)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.183% (14622/17792)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.182% (14727/17920)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.159% (14828/18048)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.185% (14938/18176)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.179% (15042/18304)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.172% (15146/18432)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.188% (15254/18560)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.186% (15359/18688)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.217% (15470/18816)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.237% (15579/18944)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.199% (15677/19072)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.203% (15783/19200)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.181% (15884/19328)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.191% (15991/19456)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.184% (16095/19584)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.158% (16195/19712)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.167% (16302/19840)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.207% (16415/19968)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.210% (16521/20096)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.199% (16624/20224)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.193% (16728/20352)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.217% (16838/20480)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.182% (16936/20608)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.186% (17042/20736)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.156% (17141/20864)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.131% (17241/20992)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.135% (17347/21120)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.144% (17454/21248)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.129% (17556/21376)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.115% (17658/21504)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.105% (17761/21632)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.119% (17869/21760)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.123% (17975/21888)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.095% (18074/22016)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.090% (18178/22144)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.063% (18277/22272)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.049% (18379/22400)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.071% (18489/22528)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.040% (18587/22656)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.031% (18690/22784)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.044% (18798/22912)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.075% (18910/23040)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.066% (19013/23168)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.087% (19123/23296)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.087% (19228/23424)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.082% (19332/23552)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.082% (19437/23680)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.048% (19534/23808)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.052% (19640/23936)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.031% (19740/24064)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.011% (19840/24192)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.007% (19944/24320)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.027% (20054/24448)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.052% (20165/24576)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.056% (20271/24704)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.051% (20375/24832)\n",
      "Train Epoch: 10 | Loss: 0.523 | Acc: 82.043% (20478/24960)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.039% (20582/25088)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.063% (20693/25216)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.071% (20800/25344)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.090% (20910/25472)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.098% (21017/25600)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.078% (21117/25728)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.066% (21219/25856)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.050% (21320/25984)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.077% (21432/26112)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.088% (21540/26240)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.077% (21642/26368)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.114% (21757/26496)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.129% (21866/26624)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.143% (21975/26752)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.113% (22072/26880)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.102% (22174/27008)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.120% (22284/27136)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.123% (22390/27264)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.115% (22493/27392)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.104% (22595/27520)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.093% (22697/27648)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.100% (22804/27776)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.096% (22908/27904)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.099% (23014/28032)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.113% (23123/28160)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.077% (23218/28288)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.066% (23320/28416)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.101% (23435/28544)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.104% (23541/28672)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.101% (23645/28800)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.104% (23751/28928)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.100% (23855/29056)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.110% (23963/29184)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.134% (24075/29312)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.126% (24178/29440)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.126% (24283/29568)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.112% (24384/29696)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.118% (24491/29824)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.108% (24593/29952)\n",
      "Train Epoch: 10 | Loss: 0.522 | Acc: 82.101% (24696/30080)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.131% (24810/30208)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.120% (24912/30336)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.126% (25019/30464)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.116% (25121/30592)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.122% (25228/30720)\n",
      "Train Epoch: 10 | Loss: 0.521 | Acc: 82.132% (25336/30848)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.138% (25443/30976)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.150% (25552/31104)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.153% (25658/31232)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.162% (25766/31360)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.187% (25879/31488)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.199% (25988/31616)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.208% (26096/31744)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.207% (26201/31872)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.209% (26307/32000)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.187% (26405/32128)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.158% (26501/32256)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.155% (26605/32384)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.160% (26712/32512)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.166% (26819/32640)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.162% (26923/32768)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.159% (27027/32896)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.158% (27132/33024)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.176% (27243/33152)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.160% (27343/33280)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.151% (27445/33408)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.159% (27553/33536)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.168% (27661/33664)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.144% (27758/33792)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.129% (27858/33920)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.131% (27964/34048)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.128% (28068/34176)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.127% (28173/34304)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.113% (28273/34432)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.138% (28387/34560)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.144% (28494/34688)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.143% (28599/34816)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.157% (28709/34944)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.160% (28815/35072)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.156% (28919/35200)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.142% (29019/35328)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.138% (29123/35456)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.138% (29228/35584)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.140% (29334/35712)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.134% (29437/35840)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.134% (29542/35968)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.123% (29643/36096)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.128% (29750/36224)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.117% (29851/36352)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.122% (29958/36480)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.132% (30067/36608)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.173% (30187/36736)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.164% (30289/36864)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.145% (30387/36992)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.155% (30496/37120)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.157% (30602/37248)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.149% (30704/37376)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.146% (30808/37504)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.164% (30920/37632)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.164% (31025/37760)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.190% (31140/37888)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.186% (31244/38016)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 82.183% (31348/38144)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.201% (31460/38272)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.208% (31568/38400)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.200% (31670/38528)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.199% (31775/38656)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.201% (31881/38784)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.203% (31987/38912)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.205% (32093/39040)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.202% (32197/39168)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.186% (32296/39296)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.194% (32404/39424)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.226% (32522/39552)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.225% (32627/39680)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.232% (32735/39808)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.224% (32837/39936)\n",
      "Train Epoch: 10 | Loss: 0.519 | Acc: 82.201% (32933/40064)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.215% (33044/40192)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.205% (33145/40320)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.202% (33249/40448)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.226% (33364/40576)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 82.208% (33462/40704)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.208% (33567/40832)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.219% (33677/40960)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.226% (33785/41088)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.206% (33882/41216)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.201% (33985/41344)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.212% (34095/41472)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.214% (34201/41600)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.230% (34313/41728)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.222% (34415/41856)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.229% (34523/41984)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.233% (34630/42112)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.221% (34730/42240)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.227% (34838/42368)\n",
      "Train Epoch: 10 | Loss: 0.517 | Acc: 82.231% (34945/42496)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.224% (35047/42624)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.237% (35158/42752)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.229% (35260/42880)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.243% (35371/43008)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.240% (35475/43136)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.228% (35575/43264)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.227% (35680/43392)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.233% (35788/43520)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.244% (35898/43648)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.253% (36007/43776)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.257% (36114/43904)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.263% (36222/44032)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.271% (36331/44160)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.286% (36443/44288)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.279% (36545/44416)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.283% (36652/44544)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 82.284% (36758/44672)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.288% (36865/44800)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.278% (36966/44928)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.280% (37072/45056)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.277% (37176/45184)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.285% (37285/45312)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 82.287% (37391/45440)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.270% (37489/45568)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.272% (37595/45696)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.276% (37702/45824)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 82.292% (37815/45952)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 82.294% (37921/46080)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.287% (38023/46208)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 82.292% (38131/46336)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.272% (38227/46464)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.269% (38331/46592)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.260% (38432/46720)\n",
      "Train Epoch: 10 | Loss: 0.515 | Acc: 82.253% (38534/46848)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.246% (38636/46976)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.233% (38735/47104)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.211% (38830/47232)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.211% (38935/47360)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.219% (39044/47488)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.208% (39144/47616)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.197% (39244/47744)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.207% (39354/47872)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.204% (39458/48000)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.204% (39563/48128)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.201% (39667/48256)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.205% (39774/48384)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.229% (39891/48512)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.222% (39993/48640)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.216% (40095/48768)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.217% (40201/48896)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.217% (40306/49024)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.231% (40418/49152)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.238% (40527/49280)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.248% (40637/49408)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.247% (40742/49536)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.245% (40846/49664)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.224% (40941/49792)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.240% (41054/49920)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 82.246% (41123/50000)\n",
      "Test Epoch: 10 | Loss: 0.546 | Acc: 81.000% (81/100)\n",
      "Test Epoch: 10 | Loss: 0.520 | Acc: 81.500% (163/200)\n",
      "Test Epoch: 10 | Loss: 0.491 | Acc: 83.000% (249/300)\n",
      "Test Epoch: 10 | Loss: 0.510 | Acc: 82.500% (330/400)\n",
      "Test Epoch: 10 | Loss: 0.505 | Acc: 82.000% (410/500)\n",
      "Test Epoch: 10 | Loss: 0.468 | Acc: 82.833% (497/600)\n",
      "Test Epoch: 10 | Loss: 0.492 | Acc: 82.286% (576/700)\n",
      "Test Epoch: 10 | Loss: 0.500 | Acc: 81.750% (654/800)\n",
      "Test Epoch: 10 | Loss: 0.520 | Acc: 81.444% (733/900)\n",
      "Test Epoch: 10 | Loss: 0.532 | Acc: 81.200% (812/1000)\n",
      "Test Epoch: 10 | Loss: 0.549 | Acc: 80.727% (888/1100)\n",
      "Test Epoch: 10 | Loss: 0.558 | Acc: 80.583% (967/1200)\n",
      "Test Epoch: 10 | Loss: 0.546 | Acc: 80.846% (1051/1300)\n",
      "Test Epoch: 10 | Loss: 0.540 | Acc: 81.143% (1136/1400)\n",
      "Test Epoch: 10 | Loss: 0.538 | Acc: 81.067% (1216/1500)\n",
      "Test Epoch: 10 | Loss: 0.546 | Acc: 80.938% (1295/1600)\n",
      "Test Epoch: 10 | Loss: 0.543 | Acc: 81.059% (1378/1700)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.722% (1453/1800)\n",
      "Test Epoch: 10 | Loss: 0.549 | Acc: 80.947% (1538/1900)\n",
      "Test Epoch: 10 | Loss: 0.564 | Acc: 80.650% (1613/2000)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.476% (1690/2100)\n",
      "Test Epoch: 10 | Loss: 0.565 | Acc: 80.364% (1768/2200)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.261% (1846/2300)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.375% (1929/2400)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.200% (2005/2500)\n",
      "Test Epoch: 10 | Loss: 0.588 | Acc: 79.808% (2075/2600)\n",
      "Test Epoch: 10 | Loss: 0.581 | Acc: 80.074% (2162/2700)\n",
      "Test Epoch: 10 | Loss: 0.584 | Acc: 79.857% (2236/2800)\n",
      "Test Epoch: 10 | Loss: 0.582 | Acc: 79.966% (2319/2900)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.067% (2402/3000)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.097% (2483/3100)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.031% (2561/3200)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.061% (2642/3300)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 79.971% (2719/3400)\n",
      "Test Epoch: 10 | Loss: 0.585 | Acc: 79.829% (2794/3500)\n",
      "Test Epoch: 10 | Loss: 0.584 | Acc: 79.944% (2878/3600)\n",
      "Test Epoch: 10 | Loss: 0.586 | Acc: 79.919% (2957/3700)\n",
      "Test Epoch: 10 | Loss: 0.582 | Acc: 80.184% (3047/3800)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.359% (3134/3900)\n",
      "Test Epoch: 10 | Loss: 0.576 | Acc: 80.500% (3220/4000)\n",
      "Test Epoch: 10 | Loss: 0.581 | Acc: 80.341% (3294/4100)\n",
      "Test Epoch: 10 | Loss: 0.584 | Acc: 80.286% (3372/4200)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.488% (3461/4300)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.523% (3543/4400)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.556% (3625/4500)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.565% (3706/4600)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.511% (3784/4700)\n",
      "Test Epoch: 10 | Loss: 0.580 | Acc: 80.521% (3865/4800)\n",
      "Test Epoch: 10 | Loss: 0.576 | Acc: 80.633% (3951/4900)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.540% (4027/5000)\n",
      "Test Epoch: 10 | Loss: 0.576 | Acc: 80.588% (4110/5100)\n",
      "Test Epoch: 10 | Loss: 0.581 | Acc: 80.500% (4186/5200)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.528% (4268/5300)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.593% (4352/5400)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.636% (4435/5500)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.661% (4517/5600)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.632% (4596/5700)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.793% (4686/5800)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.797% (4767/5900)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.733% (4844/6000)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.770% (4927/6100)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.823% (5011/6200)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.841% (5093/6300)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.922% (5179/6400)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.908% (5259/6500)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.894% (5339/6600)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.985% (5426/6700)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 81.000% (5508/6800)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.957% (5586/6900)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.943% (5666/7000)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.944% (5747/7100)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.917% (5826/7200)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 81.000% (5913/7300)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 81.000% (5994/7400)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 80.960% (6072/7500)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.961% (6153/7600)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.987% (6236/7700)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 81.026% (6320/7800)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.987% (6398/7900)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.987% (6479/8000)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 80.988% (6560/8100)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.976% (6640/8200)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 81.024% (6725/8300)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 81.024% (6806/8400)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.988% (6884/8500)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.942% (6961/8600)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.931% (7041/8700)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.909% (7120/8800)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.854% (7196/8900)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.811% (7273/9000)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.857% (7358/9100)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.924% (7445/9200)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.903% (7524/9300)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.926% (7607/9400)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.884% (7684/9500)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.885% (7765/9600)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 80.948% (7852/9700)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.918% (7930/9800)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.899% (8009/9900)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.880% (8088/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Train Epoch: 11 | Loss: 0.396 | Acc: 85.938% (110/128)\n",
      "Train Epoch: 11 | Loss: 0.453 | Acc: 85.547% (219/256)\n",
      "Train Epoch: 11 | Loss: 0.405 | Acc: 86.979% (334/384)\n",
      "Train Epoch: 11 | Loss: 0.402 | Acc: 86.328% (442/512)\n",
      "Train Epoch: 11 | Loss: 0.403 | Acc: 86.250% (552/640)\n",
      "Train Epoch: 11 | Loss: 0.420 | Acc: 86.068% (661/768)\n",
      "Train Epoch: 11 | Loss: 0.439 | Acc: 85.379% (765/896)\n",
      "Train Epoch: 11 | Loss: 0.444 | Acc: 85.059% (871/1024)\n",
      "Train Epoch: 11 | Loss: 0.437 | Acc: 85.417% (984/1152)\n",
      "Train Epoch: 11 | Loss: 0.446 | Acc: 85.078% (1089/1280)\n",
      "Train Epoch: 11 | Loss: 0.447 | Acc: 84.872% (1195/1408)\n",
      "Train Epoch: 11 | Loss: 0.446 | Acc: 84.766% (1302/1536)\n",
      "Train Epoch: 11 | Loss: 0.453 | Acc: 84.555% (1407/1664)\n",
      "Train Epoch: 11 | Loss: 0.456 | Acc: 84.542% (1515/1792)\n",
      "Train Epoch: 11 | Loss: 0.462 | Acc: 84.010% (1613/1920)\n",
      "Train Epoch: 11 | Loss: 0.457 | Acc: 84.229% (1725/2048)\n",
      "Train Epoch: 11 | Loss: 0.463 | Acc: 84.099% (1830/2176)\n",
      "Train Epoch: 11 | Loss: 0.463 | Acc: 84.071% (1937/2304)\n",
      "Train Epoch: 11 | Loss: 0.466 | Acc: 83.923% (2041/2432)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.750% (2144/2560)\n",
      "Train Epoch: 11 | Loss: 0.463 | Acc: 83.966% (2257/2688)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.807% (2360/2816)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.730% (2465/2944)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.822% (2575/3072)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.750% (2680/3200)\n",
      "Train Epoch: 11 | Loss: 0.465 | Acc: 83.804% (2789/3328)\n",
      "Train Epoch: 11 | Loss: 0.464 | Acc: 83.854% (2898/3456)\n",
      "Train Epoch: 11 | Loss: 0.466 | Acc: 83.873% (3006/3584)\n",
      "Train Epoch: 11 | Loss: 0.461 | Acc: 84.025% (3119/3712)\n",
      "Train Epoch: 11 | Loss: 0.461 | Acc: 84.062% (3228/3840)\n",
      "Train Epoch: 11 | Loss: 0.463 | Acc: 83.947% (3331/3968)\n",
      "Train Epoch: 11 | Loss: 0.463 | Acc: 83.960% (3439/4096)\n",
      "Train Epoch: 11 | Loss: 0.465 | Acc: 83.902% (3544/4224)\n",
      "Train Epoch: 11 | Loss: 0.464 | Acc: 83.915% (3652/4352)\n",
      "Train Epoch: 11 | Loss: 0.466 | Acc: 83.906% (3759/4480)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.746% (3859/4608)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.636% (3961/4736)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.553% (4064/4864)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.614% (4174/4992)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.574% (4279/5120)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.575% (4386/5248)\n",
      "Train Epoch: 11 | Loss: 0.465 | Acc: 83.594% (4494/5376)\n",
      "Train Epoch: 11 | Loss: 0.464 | Acc: 83.648% (4604/5504)\n",
      "Train Epoch: 11 | Loss: 0.464 | Acc: 83.647% (4711/5632)\n",
      "Train Epoch: 11 | Loss: 0.461 | Acc: 83.733% (4823/5760)\n",
      "Train Epoch: 11 | Loss: 0.460 | Acc: 83.713% (4929/5888)\n",
      "Train Epoch: 11 | Loss: 0.465 | Acc: 83.594% (5029/6016)\n",
      "Train Epoch: 11 | Loss: 0.465 | Acc: 83.594% (5136/6144)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.626% (5245/6272)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.500% (5344/6400)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.456% (5448/6528)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.474% (5556/6656)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.402% (5658/6784)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.449% (5768/6912)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.494% (5878/7040)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.580% (5991/7168)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.635% (6102/7296)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.688% (6213/7424)\n",
      "Train Epoch: 11 | Loss: 0.467 | Acc: 83.660% (6318/7552)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.685% (6427/7680)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.632% (6530/7808)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.556% (6631/7936)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.532% (6736/8064)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.594% (6848/8192)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.570% (6953/8320)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.594% (7062/8448)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.617% (7171/8576)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.548% (7272/8704)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.481% (7373/8832)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.471% (7479/8960)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.440% (7583/9088)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.431% (7689/9216)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.283% (7782/9344)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.351% (7895/9472)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.396% (8006/9600)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.429% (8116/9728)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.421% (8222/9856)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.474% (8334/9984)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.445% (8438/10112)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.467% (8547/10240)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.401% (8647/10368)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.413% (8755/10496)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.415% (8862/10624)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.398% (8967/10752)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.419% (9076/10880)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.403% (9181/11008)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.441% (9292/11136)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.407% (9395/11264)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.374% (9498/11392)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.359% (9603/11520)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.345% (9708/11648)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.373% (9818/11776)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.392% (9927/11904)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.419% (10037/12032)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.347% (10135/12160)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.366% (10244/12288)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.368% (10351/12416)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.355% (10456/12544)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.396% (10568/12672)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.414% (10677/12800)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.408% (10783/12928)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.379% (10886/13056)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.298% (10982/13184)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.226% (11079/13312)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.237% (11187/13440)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.225% (11292/13568)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.287% (11407/13696)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.283% (11513/13824)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.271% (11618/13952)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.253% (11722/14080)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.242% (11827/14208)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.217% (11930/14336)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.200% (12034/14464)\n",
      "Train Epoch: 11 | Loss: 0.482 | Acc: 83.169% (12136/14592)\n",
      "Train Epoch: 11 | Loss: 0.484 | Acc: 83.098% (12232/14720)\n",
      "Train Epoch: 11 | Loss: 0.485 | Acc: 83.055% (12332/14848)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 83.040% (12436/14976)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 83.024% (12540/15104)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 83.042% (12649/15232)\n",
      "Train Epoch: 11 | Loss: 0.487 | Acc: 83.014% (12751/15360)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 82.980% (12852/15488)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.017% (12964/15616)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 82.984% (13065/15744)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 82.989% (13172/15872)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.000% (13280/16000)\n",
      "Train Epoch: 11 | Loss: 0.487 | Acc: 83.048% (13394/16128)\n",
      "Train Epoch: 11 | Loss: 0.487 | Acc: 83.046% (13500/16256)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 82.996% (13598/16384)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.000% (13705/16512)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 82.987% (13809/16640)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 82.956% (13910/16768)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 82.937% (14013/16896)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 82.959% (14123/17024)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 82.970% (14231/17152)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 82.934% (14331/17280)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 82.933% (14437/17408)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 82.932% (14543/17536)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 82.982% (14658/17664)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 82.964% (14761/17792)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 82.985% (14871/17920)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.006% (14981/18048)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.044% (15094/18176)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.031% (15198/18304)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.019% (15302/18432)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.077% (15419/18560)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.096% (15529/18688)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.073% (15631/18816)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.082% (15739/18944)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.085% (15846/19072)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.083% (15952/19200)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.071% (16056/19328)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.095% (16167/19456)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.083% (16271/19584)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.061% (16373/19712)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.009% (16469/19840)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.033% (16580/19968)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.051% (16690/20096)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.065% (16799/20224)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.063% (16905/20352)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.071% (17013/20480)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.050% (17115/20608)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.034% (17218/20736)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.999% (17317/20864)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.970% (17417/20992)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.969% (17523/21120)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.968% (17629/21248)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.986% (17739/21376)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.008% (17850/21504)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.002% (17955/21632)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.015% (18064/21760)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.004% (18168/21888)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.999% (18273/22016)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.038% (18388/22144)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.037% (18494/22272)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.049% (18603/22400)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.012% (18701/22528)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.029% (18811/22656)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.014% (18914/22784)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.005% (19018/22912)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.995% (19122/23040)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.994% (19228/23168)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.993% (19334/23296)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.992% (19440/23424)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.982% (19544/23552)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.990% (19652/23680)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.972% (19754/23808)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.959% (19857/23936)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 82.991% (19971/24064)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.994% (20078/24192)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 83.002% (20186/24320)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.021% (20297/24448)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.032% (20406/24576)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.031% (20512/24704)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.002% (20611/24832)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.017% (20721/24960)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.024% (20829/25088)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.019% (20934/25216)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.022% (21041/25344)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.021% (21147/25472)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.027% (21255/25600)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.015% (21358/25728)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.010% (21463/25856)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.997% (21566/25984)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.985% (21669/26112)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.988% (21776/26240)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.006% (21887/26368)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.016% (21996/26496)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.023% (22104/26624)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.044% (22216/26752)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.999% (22310/26880)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.005% (22418/27008)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.023% (22529/27136)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.036% (22639/27264)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.061% (22752/27392)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.056% (22857/27520)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.069% (22967/27648)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.086% (23078/27776)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.088% (23185/27904)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.073% (23287/28032)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.058% (23389/28160)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.063% (23497/28288)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.069% (23605/28416)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.093% (23718/28544)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.105% (23828/28672)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.111% (23936/28800)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.110% (24042/28928)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.102% (24146/29056)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.107% (24254/29184)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.116% (24363/29312)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.125% (24472/29440)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.130% (24580/29568)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.146% (24691/29696)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.151% (24799/29824)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.153% (24906/29952)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.145% (25010/30080)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.134% (25113/30208)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.119% (25215/30336)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.111% (25319/30464)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.120% (25428/30592)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.112% (25532/30720)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.107% (25637/30848)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.080% (25735/30976)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.086% (25843/31104)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.075% (25946/31232)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.084% (26055/31360)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.054% (26152/31488)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.066% (26262/31616)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.046% (26362/31744)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.038% (26466/31872)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.025% (26568/32000)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.043% (26680/32128)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.036% (26784/32256)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.035% (26890/32384)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.059% (27004/32512)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.061% (27111/32640)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.081% (27224/32768)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.080% (27330/32896)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.058% (27429/33024)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.066% (27538/33152)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.074% (27647/33280)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.070% (27752/33408)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.063% (27856/33536)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.059% (27961/33664)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.064% (28069/33792)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.066% (28176/33920)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.050% (28277/34048)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.041% (28380/34176)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.022% (28480/34304)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.030% (28589/34432)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.015% (28690/34560)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.034% (28803/34688)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.048% (28914/34816)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.053% (29022/34944)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.046% (29126/35072)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.040% (29230/35200)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.025% (29331/35328)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.024% (29437/35456)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.037% (29548/35584)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.031% (29652/35712)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.039% (29761/35840)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.040% (29868/35968)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.040% (29974/36096)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.031% (30077/36224)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.027% (30182/36352)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.007% (30281/36480)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.990% (30381/36608)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.998% (30490/36736)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.994% (30595/36864)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.007% (30706/36992)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.004% (30811/37120)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.990% (30912/37248)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.992% (31019/37376)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.988% (31124/37504)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.980% (31227/37632)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.979% (31333/37760)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.981% (31440/37888)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.997% (31552/38016)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.999% (31659/38144)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.988% (31761/38272)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.992% (31869/38400)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.984% (31972/38528)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.970% (32073/38656)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.985% (32185/38784)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.995% (32295/38912)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.992% (32400/39040)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.999% (32509/39168)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.993% (32613/39296)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.015% (32728/39424)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.020% (32836/39552)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.034% (32948/39680)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.046% (33059/39808)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.035% (33161/39936)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.025% (33263/40064)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.026% (33370/40192)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.018% (33473/40320)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.020% (33580/40448)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.005% (33680/40576)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 82.987% (33779/40704)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 82.999% (33890/40832)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.000% (33997/40960)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.012% (34108/41088)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.011% (34214/41216)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.033% (34329/41344)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.037% (34437/41472)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.031% (34541/41600)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.038% (34650/41728)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.044% (34759/41856)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.044% (34865/41984)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.040% (34970/42112)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.054% (35082/42240)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.063% (35192/42368)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.081% (35306/42496)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.087% (35415/42624)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.098% (35526/42752)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.102% (35634/42880)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.115% (35746/43008)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.107% (35849/43136)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.111% (35957/43264)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.091% (36055/43392)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.086% (36159/43520)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.081% (36263/43648)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.064% (36362/43776)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.058% (36466/43904)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.046% (36567/44032)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.050% (36675/44160)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.041% (36777/44288)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.042% (36884/44416)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.050% (36994/44544)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.050% (37100/44672)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.042% (37203/44800)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.040% (37308/44928)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.030% (37410/45056)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.023% (37513/45184)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.024% (37620/45312)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.033% (37730/45440)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.036% (37838/45568)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.040% (37946/45696)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.024% (38045/45824)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.034% (38156/45952)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.027% (38259/46080)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.033% (38368/46208)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.041% (38478/46336)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.034% (38581/46464)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.036% (38688/46592)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.046% (38799/46720)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.032% (38899/46848)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.032% (39005/46976)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.046% (39118/47104)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.041% (39222/47232)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.049% (39332/47360)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.061% (39444/47488)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.073% (39556/47616)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.072% (39662/47744)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.065% (39765/47872)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.071% (39874/48000)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.076% (39983/48128)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.086% (40094/48256)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.087% (40201/48384)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.085% (40306/48512)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.092% (40416/48640)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.087% (40520/48768)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.091% (40628/48896)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.084% (40731/49024)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.079% (40835/49152)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.068% (40936/49280)\n",
      "Train Epoch: 11 | Loss: 0.491 | Acc: 83.059% (41038/49408)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.049% (41139/49536)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.050% (41246/49664)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.029% (41342/49792)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.017% (41442/49920)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.020% (41510/50000)\n",
      "Test Epoch: 11 | Loss: 0.435 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 11 | Loss: 0.447 | Acc: 84.000% (168/200)\n",
      "Test Epoch: 11 | Loss: 0.490 | Acc: 83.667% (251/300)\n",
      "Test Epoch: 11 | Loss: 0.494 | Acc: 83.500% (334/400)\n",
      "Test Epoch: 11 | Loss: 0.506 | Acc: 83.000% (415/500)\n",
      "Test Epoch: 11 | Loss: 0.473 | Acc: 84.000% (504/600)\n",
      "Test Epoch: 11 | Loss: 0.480 | Acc: 83.857% (587/700)\n",
      "Test Epoch: 11 | Loss: 0.491 | Acc: 83.625% (669/800)\n",
      "Test Epoch: 11 | Loss: 0.533 | Acc: 82.444% (742/900)\n",
      "Test Epoch: 11 | Loss: 0.526 | Acc: 82.700% (827/1000)\n",
      "Test Epoch: 11 | Loss: 0.529 | Acc: 82.455% (907/1100)\n",
      "Test Epoch: 11 | Loss: 0.539 | Acc: 82.250% (987/1200)\n",
      "Test Epoch: 11 | Loss: 0.531 | Acc: 82.385% (1071/1300)\n",
      "Test Epoch: 11 | Loss: 0.530 | Acc: 82.143% (1150/1400)\n",
      "Test Epoch: 11 | Loss: 0.531 | Acc: 82.000% (1230/1500)\n",
      "Test Epoch: 11 | Loss: 0.539 | Acc: 81.938% (1311/1600)\n",
      "Test Epoch: 11 | Loss: 0.535 | Acc: 82.294% (1399/1700)\n",
      "Test Epoch: 11 | Loss: 0.538 | Acc: 82.167% (1479/1800)\n",
      "Test Epoch: 11 | Loss: 0.535 | Acc: 82.474% (1567/1900)\n",
      "Test Epoch: 11 | Loss: 0.538 | Acc: 82.250% (1645/2000)\n",
      "Test Epoch: 11 | Loss: 0.547 | Acc: 81.952% (1721/2100)\n",
      "Test Epoch: 11 | Loss: 0.548 | Acc: 81.909% (1802/2200)\n",
      "Test Epoch: 11 | Loss: 0.548 | Acc: 81.870% (1883/2300)\n",
      "Test Epoch: 11 | Loss: 0.550 | Acc: 81.833% (1964/2400)\n",
      "Test Epoch: 11 | Loss: 0.556 | Acc: 81.760% (2044/2500)\n",
      "Test Epoch: 11 | Loss: 0.567 | Acc: 81.577% (2121/2600)\n",
      "Test Epoch: 11 | Loss: 0.567 | Acc: 81.556% (2202/2700)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.536% (2283/2800)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.483% (2363/2900)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.433% (2443/3000)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.581% (2529/3100)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.469% (2607/3200)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.455% (2688/3300)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.382% (2767/3400)\n",
      "Test Epoch: 11 | Loss: 0.580 | Acc: 81.286% (2845/3500)\n",
      "Test Epoch: 11 | Loss: 0.580 | Acc: 81.278% (2926/3600)\n",
      "Test Epoch: 11 | Loss: 0.578 | Acc: 81.351% (3010/3700)\n",
      "Test Epoch: 11 | Loss: 0.575 | Acc: 81.289% (3089/3800)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.436% (3176/3900)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.525% (3261/4000)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.390% (3337/4100)\n",
      "Test Epoch: 11 | Loss: 0.575 | Acc: 81.357% (3417/4200)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.558% (3507/4300)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.659% (3593/4400)\n",
      "Test Epoch: 11 | Loss: 0.568 | Acc: 81.733% (3678/4500)\n",
      "Test Epoch: 11 | Loss: 0.568 | Acc: 81.696% (3758/4600)\n",
      "Test Epoch: 11 | Loss: 0.567 | Acc: 81.681% (3839/4700)\n",
      "Test Epoch: 11 | Loss: 0.567 | Acc: 81.667% (3920/4800)\n",
      "Test Epoch: 11 | Loss: 0.566 | Acc: 81.735% (4005/4900)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.620% (4081/5000)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.706% (4167/5100)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.673% (4247/5200)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.566% (4323/5300)\n",
      "Test Epoch: 11 | Loss: 0.575 | Acc: 81.574% (4405/5400)\n",
      "Test Epoch: 11 | Loss: 0.574 | Acc: 81.509% (4483/5500)\n",
      "Test Epoch: 11 | Loss: 0.576 | Acc: 81.482% (4563/5600)\n",
      "Test Epoch: 11 | Loss: 0.576 | Acc: 81.544% (4648/5700)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.672% (4737/5800)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.627% (4816/5900)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.583% (4895/6000)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.508% (4972/6100)\n",
      "Test Epoch: 11 | Loss: 0.574 | Acc: 81.500% (5053/6200)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.524% (5136/6300)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.562% (5220/6400)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.554% (5301/6500)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.485% (5378/6600)\n",
      "Test Epoch: 11 | Loss: 0.567 | Acc: 81.567% (5465/6700)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.500% (5542/6800)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.522% (5625/6900)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.457% (5702/7000)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.451% (5783/7100)\n",
      "Test Epoch: 11 | Loss: 0.574 | Acc: 81.375% (5859/7200)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.452% (5946/7300)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.459% (6028/7400)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.427% (6107/7500)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.461% (6191/7600)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.455% (6272/7700)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.423% (6351/7800)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.418% (6432/7900)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.388% (6511/8000)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.420% (6595/8100)\n",
      "Test Epoch: 11 | Loss: 0.569 | Acc: 81.451% (6679/8200)\n",
      "Test Epoch: 11 | Loss: 0.568 | Acc: 81.458% (6761/8300)\n",
      "Test Epoch: 11 | Loss: 0.568 | Acc: 81.464% (6843/8400)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.388% (6918/8500)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.407% (7001/8600)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.356% (7078/8700)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.341% (7158/8800)\n",
      "Test Epoch: 11 | Loss: 0.574 | Acc: 81.303% (7236/8900)\n",
      "Test Epoch: 11 | Loss: 0.575 | Acc: 81.289% (7316/9000)\n",
      "Test Epoch: 11 | Loss: 0.575 | Acc: 81.319% (7400/9100)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.380% (7487/9200)\n",
      "Test Epoch: 11 | Loss: 0.574 | Acc: 81.409% (7571/9300)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.404% (7652/9400)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.400% (7733/9500)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.427% (7817/9600)\n",
      "Test Epoch: 11 | Loss: 0.570 | Acc: 81.485% (7904/9700)\n",
      "Test Epoch: 11 | Loss: 0.571 | Acc: 81.449% (7982/9800)\n",
      "Test Epoch: 11 | Loss: 0.572 | Acc: 81.465% (8065/9900)\n",
      "Test Epoch: 11 | Loss: 0.573 | Acc: 81.430% (8143/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      "Train Epoch: 12 | Loss: 0.403 | Acc: 87.500% (112/128)\n",
      "Train Epoch: 12 | Loss: 0.479 | Acc: 85.156% (218/256)\n",
      "Train Epoch: 12 | Loss: 0.511 | Acc: 82.552% (317/384)\n",
      "Train Epoch: 12 | Loss: 0.482 | Acc: 83.008% (425/512)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.062% (538/640)\n",
      "Train Epoch: 12 | Loss: 0.470 | Acc: 83.724% (643/768)\n",
      "Train Epoch: 12 | Loss: 0.471 | Acc: 83.817% (751/896)\n",
      "Train Epoch: 12 | Loss: 0.476 | Acc: 83.789% (858/1024)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.767% (965/1152)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.297% (1079/1280)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.588% (1191/1408)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.505% (1298/1536)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.555% (1407/1664)\n",
      "Train Epoch: 12 | Loss: 0.449 | Acc: 84.766% (1519/1792)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.635% (1625/1920)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.180% (1724/2048)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.007% (1828/2176)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.158% (1939/2304)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.046% (2044/2432)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.141% (2154/2560)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.891% (2255/2688)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.126% (2369/2816)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.069% (2475/2944)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.115% (2584/3072)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.312% (2698/3200)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.315% (2806/3328)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.086% (2906/3456)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.235% (3019/3584)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.240% (3127/3712)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.219% (3234/3840)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.350% (3347/3968)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.277% (3452/4096)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.304% (3561/4224)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.214% (3665/4352)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.085% (3767/4480)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.158% (3878/4608)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.206% (3988/4736)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.087% (4090/4864)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.115% (4199/4992)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.141% (4308/5120)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.165% (4417/5248)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.282% (4531/5376)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.211% (4635/5504)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.197% (4742/5632)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.219% (4851/5760)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.035% (4948/5888)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.860% (5045/6016)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.870% (5153/6144)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.849% (5259/6272)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.781% (5362/6400)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.716% (5465/6528)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.789% (5577/6656)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.800% (5685/6784)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.825% (5794/6912)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 83.920% (5908/7040)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.040% (6024/7168)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 83.950% (6125/7296)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.836% (6224/7424)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.792% (6328/7552)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.685% (6427/7680)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.747% (6539/7808)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 83.770% (6648/7936)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.780% (6756/8064)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.813% (6866/8192)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 83.762% (6969/8320)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.819% (7081/8448)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.862% (7192/8576)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 83.812% (7295/8704)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.911% (7411/8832)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.884% (7516/8960)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 83.880% (7623/9088)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 83.865% (7729/9216)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.947% (7844/9344)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.932% (7950/9472)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 83.958% (8060/9600)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 83.861% (8158/9728)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 83.847% (8264/9856)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.784% (8365/9984)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.792% (8473/10112)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.799% (8581/10240)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.825% (8691/10368)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.889% (8805/10496)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.933% (8917/10624)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.873% (9018/10752)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.906% (9129/10880)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.903% (9236/11008)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.890% (9342/11136)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.869% (9447/11264)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.919% (9560/11392)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.915% (9667/11520)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.946% (9778/11648)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.959% (9887/11776)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.947% (9993/11904)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.918% (10097/12032)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.906% (10203/12160)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.895% (10309/12288)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.860% (10412/12416)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.897% (10524/12544)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.862% (10627/12672)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.844% (10732/12800)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.826% (10837/12928)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.824% (10944/13056)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.859% (11056/13184)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.759% (11150/13312)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.713% (11251/13440)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.778% (11367/13568)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.762% (11472/13696)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.767% (11580/13824)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.802% (11692/13952)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.771% (11795/14080)\n",
      "Train Epoch: 12 | Loss: 0.469 | Acc: 83.713% (11894/14208)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.705% (12000/14336)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.767% (12116/14464)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.772% (12224/14592)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.798% (12335/14720)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.843% (12449/14848)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.807% (12551/14976)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.779% (12654/15104)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.817% (12767/15232)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.809% (12873/15360)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.858% (12988/15488)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.856% (13095/15616)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.803% (13194/15744)\n",
      "Train Epoch: 12 | Loss: 0.467 | Acc: 83.833% (13306/15872)\n",
      "Train Epoch: 12 | Loss: 0.468 | Acc: 83.775% (13404/16000)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.829% (13520/16128)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.864% (13633/16256)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.844% (13737/16384)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.897% (13853/16512)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.912% (13963/16640)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.904% (14069/16768)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.902% (14176/16896)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.846% (14274/17024)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.879% (14387/17152)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.872% (14493/17280)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.829% (14593/17408)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.867% (14707/17536)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.871% (14815/17664)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.869% (14922/17792)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.878% (15031/17920)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.887% (15140/18048)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.891% (15248/18176)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.883% (15354/18304)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.914% (15467/18432)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.922% (15576/18560)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.888% (15677/18688)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.886% (15784/18816)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.858% (15886/18944)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.856% (15993/19072)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.854% (16100/19200)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.858% (16208/19328)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.887% (16321/19456)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.859% (16423/19584)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.873% (16533/19712)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.851% (16636/19840)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.849% (16743/19968)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.857% (16852/20096)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.846% (16957/20224)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.825% (17060/20352)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.818% (17166/20480)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.788% (17267/20608)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.787% (17374/20736)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.819% (17488/20864)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.808% (17593/20992)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.830% (17705/21120)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.867% (17820/21248)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.903% (17935/21376)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.905% (18043/21504)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.894% (18148/21632)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.888% (18254/21760)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.850% (18353/21888)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.853% (18461/22016)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.851% (18568/22144)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.859% (18677/22272)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.857% (18784/22400)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.856% (18891/22528)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.819% (18990/22656)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.800% (19093/22784)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.799% (19200/22912)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.785% (19304/23040)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.775% (19409/23168)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.770% (19515/23296)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.777% (19624/23424)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.789% (19734/23552)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.822% (19849/23680)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.858% (19965/23808)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.869% (20075/23936)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.905% (20191/24064)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.937% (20306/24192)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.939% (20414/24320)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.933% (20520/24448)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 83.940% (20629/24576)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.934% (20735/24704)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.916% (20838/24832)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.914% (20945/24960)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.929% (21056/25088)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.919% (21161/25216)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.909% (21266/25344)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.884% (21367/25472)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.895% (21477/25600)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.881% (21581/25728)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.895% (21692/25856)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.886% (21797/25984)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 83.889% (21905/26112)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.864% (22006/26240)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.878% (22117/26368)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.881% (22225/26496)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.883% (22333/26624)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.911% (22448/26752)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.917% (22557/26880)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.897% (22659/27008)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.907% (22769/27136)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.920% (22880/27264)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.919% (22987/27392)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.903% (23090/27520)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.908% (23199/27648)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.929% (23312/27776)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.927% (23419/27904)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.936% (23529/28032)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.928% (23634/28160)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.944% (23746/28288)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.946% (23854/28416)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.937% (23959/28544)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.939% (24067/28672)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.920% (24169/28800)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.894% (24269/28928)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.900% (24378/29056)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.919% (24491/29184)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.949% (24607/29312)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.964% (24719/29440)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.945% (24821/29568)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.944% (24928/29696)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.949% (25037/29824)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.951% (25145/29952)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.936% (25248/30080)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.928% (25353/30208)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.923% (25459/30336)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.919% (25565/30464)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.921% (25673/30592)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.929% (25783/30720)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.931% (25891/30848)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.929% (25998/30976)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.922% (26103/31104)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.911% (26207/31232)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.919% (26317/31360)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.918% (26424/31488)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.907% (26528/31616)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.915% (26638/31744)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.914% (26745/31872)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.931% (26858/32000)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.927% (26964/32128)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.941% (27076/32256)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.940% (27183/32384)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.932% (27288/32512)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.943% (27399/32640)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.963% (27513/32768)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.968% (27622/32896)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.963% (27728/33024)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.992% (27845/33152)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.987% (27951/33280)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.980% (28056/33408)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.993% (28168/33536)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.986% (28273/33664)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.973% (28376/33792)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.001% (28493/33920)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.981% (28594/34048)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.995% (28706/34176)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.002% (28816/34304)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.003% (28924/34432)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 83.999% (29030/34560)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.994% (29136/34688)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.976% (29237/34816)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.966% (29341/34944)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.967% (29449/35072)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.974% (29559/35200)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.982% (29669/35328)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.980% (29776/35456)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.979% (29883/35584)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.969% (29987/35712)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.965% (30093/35840)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.977% (30205/35968)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.971% (30310/36096)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.975% (30419/36224)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.971% (30525/36352)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.991% (30640/36480)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.990% (30747/36608)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.991% (30855/36736)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.984% (30960/36864)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.986% (31068/36992)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.995% (31179/37120)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.002% (31289/37248)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.998% (31395/37376)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.991% (31500/37504)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.984% (31605/37632)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.965% (31705/37760)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.969% (31814/37888)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.978% (31925/38016)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.971% (32030/38144)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.967% (32136/38272)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.964% (32242/38400)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.975% (32354/38528)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.977% (32462/38656)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.988% (32574/38784)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.992% (32683/38912)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.996% (32792/39040)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.989% (32897/39168)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.978% (33000/39296)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.989% (33112/39424)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.981% (33216/39552)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 83.984% (33325/39680)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.006% (33441/39808)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.009% (33550/39936)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.011% (33658/40064)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.009% (33765/40192)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.018% (33876/40320)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.026% (33987/40448)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.032% (34097/40576)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.016% (34198/40704)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.015% (34305/40832)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.023% (34416/40960)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.032% (34527/41088)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.023% (34631/41216)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.027% (34740/41344)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.035% (34851/41472)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.034% (34958/41600)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.035% (35066/41728)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.026% (35170/41856)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.020% (35275/41984)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.026% (35385/42112)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.027% (35493/42240)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.030% (35602/42368)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.031% (35710/42496)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.040% (35821/42624)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.048% (35932/42752)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.039% (36036/42880)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.033% (36141/43008)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.037% (36250/43136)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.044% (36361/43264)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.041% (36467/43392)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.026% (36568/43520)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.036% (36680/43648)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.019% (36780/43776)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.011% (36884/43904)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.007% (36990/44032)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.008% (37098/44160)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.018% (37210/44288)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.008% (37313/44416)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.018% (37425/44544)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.019% (37533/44672)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.996% (37630/44800)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 83.992% (37736/44928)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.002% (37848/45056)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.010% (37959/45184)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.004% (38064/45312)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.010% (38174/45440)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.009% (38281/45568)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.023% (38395/45696)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.035% (38508/45824)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.029% (38613/45952)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.028% (38720/46080)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.020% (38824/46208)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.025% (38934/46336)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.020% (39039/46464)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.014% (39144/46592)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.026% (39257/46720)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.019% (39361/46848)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.019% (39469/46976)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.018% (39576/47104)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.028% (39688/47232)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.029% (39796/47360)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.023% (39901/47488)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.020% (40007/47616)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.013% (40111/47744)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.018% (40221/47872)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.023% (40331/48000)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.001% (40428/48128)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.014% (40542/48256)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.020% (40652/48384)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.027% (40763/48512)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.025% (40870/48640)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.033% (40981/48768)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.042% (41093/48896)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.043% (41201/49024)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.037% (41306/49152)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.032% (41411/49280)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.025% (41515/49408)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.022% (41621/49536)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.019% (41727/49664)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.024% (41837/49792)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.026% (41946/49920)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.026% (42013/50000)\n",
      "Test Epoch: 12 | Loss: 0.441 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 12 | Loss: 0.462 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 12 | Loss: 0.431 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 12 | Loss: 0.474 | Acc: 84.250% (337/400)\n",
      "Test Epoch: 12 | Loss: 0.481 | Acc: 83.400% (417/500)\n",
      "Test Epoch: 12 | Loss: 0.438 | Acc: 85.000% (510/600)\n",
      "Test Epoch: 12 | Loss: 0.456 | Acc: 84.429% (591/700)\n",
      "Test Epoch: 12 | Loss: 0.476 | Acc: 83.500% (668/800)\n",
      "Test Epoch: 12 | Loss: 0.507 | Acc: 82.778% (745/900)\n",
      "Test Epoch: 12 | Loss: 0.512 | Acc: 82.600% (826/1000)\n",
      "Test Epoch: 12 | Loss: 0.531 | Acc: 82.091% (903/1100)\n",
      "Test Epoch: 12 | Loss: 0.541 | Acc: 82.000% (984/1200)\n",
      "Test Epoch: 12 | Loss: 0.537 | Acc: 81.923% (1065/1300)\n",
      "Test Epoch: 12 | Loss: 0.531 | Acc: 82.000% (1148/1400)\n",
      "Test Epoch: 12 | Loss: 0.530 | Acc: 82.000% (1230/1500)\n",
      "Test Epoch: 12 | Loss: 0.537 | Acc: 81.688% (1307/1600)\n",
      "Test Epoch: 12 | Loss: 0.538 | Acc: 81.941% (1393/1700)\n",
      "Test Epoch: 12 | Loss: 0.549 | Acc: 81.611% (1469/1800)\n",
      "Test Epoch: 12 | Loss: 0.545 | Acc: 81.737% (1553/1900)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.400% (1628/2000)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.429% (1710/2100)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.364% (1790/2200)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.261% (1869/2300)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.208% (1949/2400)\n",
      "Test Epoch: 12 | Loss: 0.568 | Acc: 81.080% (2027/2500)\n",
      "Test Epoch: 12 | Loss: 0.581 | Acc: 80.808% (2101/2600)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.741% (2180/2700)\n",
      "Test Epoch: 12 | Loss: 0.579 | Acc: 80.714% (2260/2800)\n",
      "Test Epoch: 12 | Loss: 0.578 | Acc: 80.793% (2343/2900)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.733% (2422/3000)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.710% (2502/3100)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.562% (2578/3200)\n",
      "Test Epoch: 12 | Loss: 0.578 | Acc: 80.364% (2652/3300)\n",
      "Test Epoch: 12 | Loss: 0.577 | Acc: 80.382% (2733/3400)\n",
      "Test Epoch: 12 | Loss: 0.581 | Acc: 80.371% (2813/3500)\n",
      "Test Epoch: 12 | Loss: 0.579 | Acc: 80.444% (2896/3600)\n",
      "Test Epoch: 12 | Loss: 0.579 | Acc: 80.514% (2979/3700)\n",
      "Test Epoch: 12 | Loss: 0.577 | Acc: 80.553% (3061/3800)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.667% (3146/3900)\n",
      "Test Epoch: 12 | Loss: 0.572 | Acc: 80.775% (3231/4000)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.756% (3311/4100)\n",
      "Test Epoch: 12 | Loss: 0.581 | Acc: 80.667% (3388/4200)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.744% (3472/4300)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.773% (3554/4400)\n",
      "Test Epoch: 12 | Loss: 0.574 | Acc: 80.800% (3636/4500)\n",
      "Test Epoch: 12 | Loss: 0.574 | Acc: 80.761% (3715/4600)\n",
      "Test Epoch: 12 | Loss: 0.574 | Acc: 80.660% (3791/4700)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.667% (3872/4800)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.714% (3955/4900)\n",
      "Test Epoch: 12 | Loss: 0.578 | Acc: 80.600% (4030/5000)\n",
      "Test Epoch: 12 | Loss: 0.574 | Acc: 80.725% (4117/5100)\n",
      "Test Epoch: 12 | Loss: 0.579 | Acc: 80.635% (4193/5200)\n",
      "Test Epoch: 12 | Loss: 0.577 | Acc: 80.698% (4277/5300)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.741% (4360/5400)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.745% (4441/5500)\n",
      "Test Epoch: 12 | Loss: 0.575 | Acc: 80.750% (4522/5600)\n",
      "Test Epoch: 12 | Loss: 0.576 | Acc: 80.842% (4608/5700)\n",
      "Test Epoch: 12 | Loss: 0.572 | Acc: 80.948% (4695/5800)\n",
      "Test Epoch: 12 | Loss: 0.573 | Acc: 80.881% (4772/5900)\n",
      "Test Epoch: 12 | Loss: 0.574 | Acc: 80.867% (4852/6000)\n",
      "Test Epoch: 12 | Loss: 0.571 | Acc: 80.869% (4933/6100)\n",
      "Test Epoch: 12 | Loss: 0.570 | Acc: 80.871% (5014/6200)\n",
      "Test Epoch: 12 | Loss: 0.568 | Acc: 80.905% (5097/6300)\n",
      "Test Epoch: 12 | Loss: 0.567 | Acc: 80.969% (5182/6400)\n",
      "Test Epoch: 12 | Loss: 0.568 | Acc: 80.862% (5256/6500)\n",
      "Test Epoch: 12 | Loss: 0.567 | Acc: 80.939% (5342/6600)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.000% (5427/6700)\n",
      "Test Epoch: 12 | Loss: 0.566 | Acc: 81.015% (5509/6800)\n",
      "Test Epoch: 12 | Loss: 0.566 | Acc: 80.957% (5586/6900)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.029% (5672/7000)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.056% (5755/7100)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.069% (5837/7200)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.137% (5923/7300)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.095% (6001/7400)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.067% (6080/7500)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.066% (6161/7600)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.065% (6242/7700)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.064% (6323/7800)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.063% (6404/7900)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.050% (6484/8000)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.086% (6568/8100)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.061% (6647/8200)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.072% (6729/8300)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.036% (6807/8400)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.035% (6888/8500)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.012% (6967/8600)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.000% (7047/8700)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.023% (7130/8800)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.011% (7210/8900)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.044% (7294/9000)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.066% (7377/9100)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.152% (7466/9200)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.161% (7548/9300)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.202% (7633/9400)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.158% (7710/9500)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.208% (7796/9600)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.289% (7885/9700)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.255% (7963/9800)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.263% (8045/9900)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.280% (8128/10000)\n",
      "\n",
      "Epoch: 13\n",
      "Train Epoch: 13 | Loss: 0.388 | Acc: 85.938% (110/128)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 85.547% (219/256)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.115% (323/384)\n",
      "Train Epoch: 13 | Loss: 0.443 | Acc: 84.180% (431/512)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.688% (542/640)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.026% (653/768)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.491% (766/896)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.840% (879/1024)\n",
      "Train Epoch: 13 | Loss: 0.414 | Acc: 85.938% (990/1152)\n",
      "Train Epoch: 13 | Loss: 0.410 | Acc: 86.484% (1107/1280)\n",
      "Train Epoch: 13 | Loss: 0.419 | Acc: 86.293% (1215/1408)\n",
      "Train Epoch: 13 | Loss: 0.425 | Acc: 86.133% (1323/1536)\n",
      "Train Epoch: 13 | Loss: 0.419 | Acc: 86.058% (1432/1664)\n",
      "Train Epoch: 13 | Loss: 0.420 | Acc: 85.993% (1541/1792)\n",
      "Train Epoch: 13 | Loss: 0.419 | Acc: 85.990% (1651/1920)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.693% (1755/2048)\n",
      "Train Epoch: 13 | Loss: 0.419 | Acc: 85.800% (1867/2176)\n",
      "Train Epoch: 13 | Loss: 0.419 | Acc: 85.720% (1975/2304)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.650% (2083/2432)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.703% (2194/2560)\n",
      "Train Epoch: 13 | Loss: 0.421 | Acc: 85.714% (2304/2688)\n",
      "Train Epoch: 13 | Loss: 0.413 | Acc: 86.044% (2423/2816)\n",
      "Train Epoch: 13 | Loss: 0.413 | Acc: 86.005% (2532/2944)\n",
      "Train Epoch: 13 | Loss: 0.413 | Acc: 85.938% (2640/3072)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 86.031% (2753/3200)\n",
      "Train Epoch: 13 | Loss: 0.409 | Acc: 86.088% (2865/3328)\n",
      "Train Epoch: 13 | Loss: 0.408 | Acc: 86.111% (2976/3456)\n",
      "Train Epoch: 13 | Loss: 0.410 | Acc: 86.049% (3084/3584)\n",
      "Train Epoch: 13 | Loss: 0.409 | Acc: 86.180% (3199/3712)\n",
      "Train Epoch: 13 | Loss: 0.418 | Acc: 85.911% (3299/3840)\n",
      "Train Epoch: 13 | Loss: 0.418 | Acc: 85.988% (3412/3968)\n",
      "Train Epoch: 13 | Loss: 0.418 | Acc: 85.913% (3519/4096)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.914% (3629/4224)\n",
      "Train Epoch: 13 | Loss: 0.421 | Acc: 85.754% (3732/4352)\n",
      "Train Epoch: 13 | Loss: 0.418 | Acc: 85.893% (3848/4480)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.851% (3956/4608)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.747% (4061/4736)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.814% (4174/4864)\n",
      "Train Epoch: 13 | Loss: 0.414 | Acc: 85.857% (4286/4992)\n",
      "Train Epoch: 13 | Loss: 0.415 | Acc: 85.840% (4395/5120)\n",
      "Train Epoch: 13 | Loss: 0.414 | Acc: 85.880% (4507/5248)\n",
      "Train Epoch: 13 | Loss: 0.413 | Acc: 85.919% (4619/5376)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 86.010% (4734/5504)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 86.009% (4844/5632)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 85.955% (4951/5760)\n",
      "Train Epoch: 13 | Loss: 0.414 | Acc: 85.887% (5057/5888)\n",
      "Train Epoch: 13 | Loss: 0.415 | Acc: 85.888% (5167/6016)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.872% (5276/6144)\n",
      "Train Epoch: 13 | Loss: 0.414 | Acc: 85.906% (5388/6272)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.828% (5493/6400)\n",
      "Train Epoch: 13 | Loss: 0.418 | Acc: 85.769% (5599/6528)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.877% (5716/6656)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.834% (5823/6784)\n",
      "Train Epoch: 13 | Loss: 0.415 | Acc: 85.865% (5935/6912)\n",
      "Train Epoch: 13 | Loss: 0.415 | Acc: 85.881% (6046/7040)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.938% (6160/7168)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.855% (6264/7296)\n",
      "Train Epoch: 13 | Loss: 0.417 | Acc: 85.897% (6377/7424)\n",
      "Train Epoch: 13 | Loss: 0.420 | Acc: 85.765% (6477/7552)\n",
      "Train Epoch: 13 | Loss: 0.420 | Acc: 85.768% (6587/7680)\n",
      "Train Epoch: 13 | Loss: 0.421 | Acc: 85.745% (6695/7808)\n",
      "Train Epoch: 13 | Loss: 0.425 | Acc: 85.648% (6797/7936)\n",
      "Train Epoch: 13 | Loss: 0.426 | Acc: 85.627% (6905/8064)\n",
      "Train Epoch: 13 | Loss: 0.424 | Acc: 85.669% (7018/8192)\n",
      "Train Epoch: 13 | Loss: 0.425 | Acc: 85.613% (7123/8320)\n",
      "Train Epoch: 13 | Loss: 0.426 | Acc: 85.618% (7233/8448)\n",
      "Train Epoch: 13 | Loss: 0.425 | Acc: 85.693% (7349/8576)\n",
      "Train Epoch: 13 | Loss: 0.427 | Acc: 85.650% (7455/8704)\n",
      "Train Epoch: 13 | Loss: 0.426 | Acc: 85.609% (7561/8832)\n",
      "Train Epoch: 13 | Loss: 0.424 | Acc: 85.703% (7679/8960)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.695% (7788/9088)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.677% (7896/9216)\n",
      "Train Epoch: 13 | Loss: 0.422 | Acc: 85.659% (8004/9344)\n",
      "Train Epoch: 13 | Loss: 0.423 | Acc: 85.621% (8110/9472)\n",
      "Train Epoch: 13 | Loss: 0.424 | Acc: 85.573% (8215/9600)\n",
      "Train Epoch: 13 | Loss: 0.426 | Acc: 85.516% (8319/9728)\n",
      "Train Epoch: 13 | Loss: 0.427 | Acc: 85.522% (8429/9856)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.487% (8535/9984)\n",
      "Train Epoch: 13 | Loss: 0.427 | Acc: 85.492% (8645/10112)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.498% (8755/10240)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.436% (8858/10368)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.366% (8960/10496)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.410% (9074/10624)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.407% (9183/10752)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.414% (9293/10880)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.356% (9396/11008)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.345% (9504/11136)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.316% (9610/11264)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.323% (9720/11392)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.321% (9829/11520)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.379% (9945/11648)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.403% (10057/11776)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.417% (10168/11904)\n",
      "Train Epoch: 13 | Loss: 0.428 | Acc: 85.447% (10281/12032)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.403% (10385/12160)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.400% (10494/12288)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.390% (10602/12416)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.356% (10707/12544)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.283% (10807/12672)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.281% (10916/12800)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.265% (11023/12928)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.263% (11132/13056)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.202% (11233/13184)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.179% (11339/13312)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.201% (11451/13440)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.208% (11561/13568)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.185% (11667/13696)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.250% (11785/13824)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.278% (11898/13952)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.284% (12008/14080)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.283% (12117/14208)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.324% (12232/14336)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.329% (12342/14464)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.328% (12451/14592)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.326% (12560/14720)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.358% (12674/14848)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.330% (12779/14976)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.342% (12890/15104)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.366% (13003/15232)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.345% (13109/15360)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.331% (13216/15488)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.278% (13317/15616)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.290% (13428/15744)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.270% (13534/15872)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.294% (13647/16000)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.286% (13755/16128)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.322% (13870/16256)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.333% (13981/16384)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.326% (14089/16512)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.270% (14189/16640)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.293% (14302/16768)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.239% (14402/16896)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.227% (14509/17024)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.244% (14621/17152)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.214% (14725/17280)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.219% (14835/17408)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.225% (14945/17536)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.236% (15056/17664)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.224% (15163/17792)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.246% (15276/17920)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.256% (15387/18048)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.266% (15498/18176)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.282% (15610/18304)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.248% (15713/18432)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.269% (15826/18560)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.247% (15931/18688)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.247% (16040/18816)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.246% (16149/18944)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.235% (16256/19072)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.240% (16366/19200)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.208% (16469/19328)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.208% (16578/19456)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.197% (16685/19584)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.177% (16790/19712)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.176% (16899/19840)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.176% (17008/19968)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.196% (17121/20096)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.201% (17231/20224)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.161% (17332/20352)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.142% (17437/20480)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.151% (17548/20608)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 85.147% (17656/20736)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.118% (17759/20864)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.132% (17871/20992)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.123% (17978/21120)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.081% (18078/21248)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.095% (18190/21376)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.091% (18298/21504)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.101% (18409/21632)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.110% (18520/21760)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.120% (18631/21888)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.129% (18742/22016)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.107% (18846/22144)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.080% (18949/22272)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.040% (19049/22400)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.054% (19161/22528)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.050% (19269/22656)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.064% (19381/22784)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.052% (19487/22912)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.052% (19596/23040)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.061% (19707/23168)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.027% (19808/23296)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.003% (19911/23424)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.012% (20022/23552)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.013% (20131/23680)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.013% (20240/23808)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.010% (20348/23936)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.032% (20462/24064)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.032% (20571/24192)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.033% (20680/24320)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.034% (20789/24448)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.038% (20899/24576)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.043% (21009/24704)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.048% (21119/24832)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.052% (21229/24960)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.057% (21339/25088)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.061% (21449/25216)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.038% (21552/25344)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.027% (21658/25472)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.035% (21769/25600)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.044% (21880/25728)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.048% (21990/25856)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.029% (22094/25984)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.015% (22199/26112)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.015% (22308/26240)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 85.001% (22413/26368)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.998% (22521/26496)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.965% (22621/26624)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.969% (22731/26752)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.993% (22846/26880)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.001% (22957/27008)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.013% (23069/27136)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.010% (23177/27264)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.018% (23288/27392)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.007% (23394/27520)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.008% (23503/27648)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.991% (23607/27776)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.981% (23713/27904)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.967% (23818/28032)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.950% (23922/28160)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.955% (24032/28288)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.970% (24145/28416)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.974% (24255/28544)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.982% (24366/28672)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.986% (24476/28800)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.001% (24589/28928)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.991% (24695/29056)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.995% (24805/29184)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.003% (24916/29312)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.017% (25029/29440)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.004% (25134/29568)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 85.011% (25245/29696)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.982% (25345/29824)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.969% (25450/29952)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.953% (25554/30080)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.961% (25665/30208)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.955% (25772/30336)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.936% (25875/30464)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.924% (25980/30592)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.932% (26091/30720)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.936% (26201/30848)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.950% (26314/30976)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.938% (26419/31104)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.929% (26525/31232)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.933% (26635/31360)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.924% (26741/31488)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.932% (26852/31616)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.936% (26962/31744)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.927% (27068/31872)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.938% (27180/32000)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.932% (27287/32128)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.933% (27396/32256)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.918% (27500/32384)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.932% (27613/32512)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.939% (27724/32640)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.940% (27833/32768)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.934% (27940/32896)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.932% (28048/33024)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.909% (28149/33152)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.913% (28259/33280)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.878% (28356/33408)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.873% (28463/33536)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.859% (28567/33664)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.869% (28679/33792)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.873% (28789/33920)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.877% (28899/34048)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.887% (29011/34176)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.888% (29120/34304)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.889% (29229/34432)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.873% (29332/34560)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.862% (29437/34688)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.878% (29551/34816)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.870% (29657/34944)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.874% (29767/35072)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.861% (29871/35200)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.851% (29976/35328)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.843% (30082/35456)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.853% (30194/35584)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.845% (30300/35712)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.874% (30419/35840)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.864% (30524/35968)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.871% (30635/36096)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.880% (30747/36224)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.900% (30863/36352)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.888% (30967/36480)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.910% (31084/36608)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.922% (31197/36736)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.926% (31307/36864)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.924% (31415/36992)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.930% (31526/37120)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.941% (31639/37248)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.945% (31749/37376)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.922% (31849/37504)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.914% (31955/37632)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.913% (32063/37760)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.903% (32168/37888)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.922% (32284/38016)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.920% (32392/38144)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.905% (32495/38272)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.901% (32602/38400)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.902% (32711/38528)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.890% (32815/38656)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.891% (32924/38784)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.904% (33038/38912)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.921% (33153/39040)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.914% (33259/39168)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.917% (33369/39296)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.918% (33478/39424)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.916% (33586/39552)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.934% (33702/39680)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.943% (33814/39808)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.958% (33929/39936)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.972% (34043/40064)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.985% (34157/40192)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.980% (34264/40320)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.968% (34368/40448)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.947% (34468/40576)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.947% (34577/40704)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.951% (34687/40832)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.937% (34790/40960)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.918% (34891/41088)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.904% (34994/41216)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.914% (35107/41344)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.910% (35214/41472)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.911% (35323/41600)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.900% (35427/41728)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.901% (35536/41856)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.906% (35647/41984)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.928% (35765/42112)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.931% (35875/42240)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.930% (35983/42368)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.921% (36088/42496)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.924% (36198/42624)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.913% (36302/42752)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.918% (36413/42880)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.907% (36517/43008)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.901% (36623/43136)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.916% (36738/43264)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.900% (36840/43392)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.901% (36949/43520)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.913% (37063/43648)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.923% (37176/43776)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.915% (37281/43904)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.897% (37382/44032)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.912% (37497/44160)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.908% (37604/44288)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.909% (37713/44416)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.894% (37815/44544)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.901% (37927/44672)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.904% (38037/44800)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.916% (38151/44928)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.912% (38258/45056)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.904% (38363/45184)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.907% (38473/45312)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.903% (38580/45440)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.904% (38689/45568)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.894% (38793/45696)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.881% (38896/45824)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.889% (39008/45952)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.909% (39126/46080)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.907% (39234/46208)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.910% (39344/46336)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.922% (39458/46464)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.933% (39572/46592)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.942% (39685/46720)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.939% (39792/46848)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.943% (39903/46976)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.955% (40017/47104)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.951% (40124/47232)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.960% (40237/47360)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.958% (40345/47488)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.948% (40449/47616)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.949% (40558/47744)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.949% (40667/47872)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.938% (40770/48000)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.946% (40883/48128)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.941% (40989/48256)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.931% (41093/48384)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.923% (41198/48512)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.918% (41304/48640)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.904% (41406/48768)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.905% (41515/48896)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.909% (41626/49024)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.914% (41737/49152)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.907% (41842/49280)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.923% (41959/49408)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.920% (42066/49536)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.919% (42174/49664)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.935% (42291/49792)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.930% (42397/49920)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.936% (42468/50000)\n",
      "Test Epoch: 13 | Loss: 0.430 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 13 | Loss: 0.479 | Acc: 85.500% (171/200)\n",
      "Test Epoch: 13 | Loss: 0.422 | Acc: 87.000% (261/300)\n",
      "Test Epoch: 13 | Loss: 0.446 | Acc: 85.750% (343/400)\n",
      "Test Epoch: 13 | Loss: 0.465 | Acc: 85.000% (425/500)\n",
      "Test Epoch: 13 | Loss: 0.439 | Acc: 85.667% (514/600)\n",
      "Test Epoch: 13 | Loss: 0.466 | Acc: 85.000% (595/700)\n",
      "Test Epoch: 13 | Loss: 0.495 | Acc: 83.750% (670/800)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.333% (750/900)\n",
      "Test Epoch: 13 | Loss: 0.528 | Acc: 83.100% (831/1000)\n",
      "Test Epoch: 13 | Loss: 0.544 | Acc: 82.545% (908/1100)\n",
      "Test Epoch: 13 | Loss: 0.542 | Acc: 82.417% (989/1200)\n",
      "Test Epoch: 13 | Loss: 0.535 | Acc: 82.538% (1073/1300)\n",
      "Test Epoch: 13 | Loss: 0.530 | Acc: 82.714% (1158/1400)\n",
      "Test Epoch: 13 | Loss: 0.527 | Acc: 82.800% (1242/1500)\n",
      "Test Epoch: 13 | Loss: 0.534 | Acc: 82.750% (1324/1600)\n",
      "Test Epoch: 13 | Loss: 0.535 | Acc: 82.882% (1409/1700)\n",
      "Test Epoch: 13 | Loss: 0.538 | Acc: 82.667% (1488/1800)\n",
      "Test Epoch: 13 | Loss: 0.535 | Acc: 82.895% (1575/1900)\n",
      "Test Epoch: 13 | Loss: 0.550 | Acc: 82.500% (1650/2000)\n",
      "Test Epoch: 13 | Loss: 0.551 | Acc: 82.333% (1729/2100)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.227% (1809/2200)\n",
      "Test Epoch: 13 | Loss: 0.547 | Acc: 82.217% (1891/2300)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.250% (1974/2400)\n",
      "Test Epoch: 13 | Loss: 0.551 | Acc: 82.160% (2054/2500)\n",
      "Test Epoch: 13 | Loss: 0.561 | Acc: 82.038% (2133/2600)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.111% (2217/2700)\n",
      "Test Epoch: 13 | Loss: 0.558 | Acc: 82.179% (2301/2800)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.241% (2385/2900)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.233% (2467/3000)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.194% (2548/3100)\n",
      "Test Epoch: 13 | Loss: 0.554 | Acc: 82.156% (2629/3200)\n",
      "Test Epoch: 13 | Loss: 0.553 | Acc: 82.121% (2710/3300)\n",
      "Test Epoch: 13 | Loss: 0.555 | Acc: 81.912% (2785/3400)\n",
      "Test Epoch: 13 | Loss: 0.559 | Acc: 81.743% (2861/3500)\n",
      "Test Epoch: 13 | Loss: 0.559 | Acc: 81.778% (2944/3600)\n",
      "Test Epoch: 13 | Loss: 0.562 | Acc: 81.703% (3023/3700)\n",
      "Test Epoch: 13 | Loss: 0.561 | Acc: 81.816% (3109/3800)\n",
      "Test Epoch: 13 | Loss: 0.558 | Acc: 81.949% (3196/3900)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.000% (3280/4000)\n",
      "Test Epoch: 13 | Loss: 0.558 | Acc: 81.976% (3361/4100)\n",
      "Test Epoch: 13 | Loss: 0.560 | Acc: 82.024% (3445/4200)\n",
      "Test Epoch: 13 | Loss: 0.555 | Acc: 82.140% (3532/4300)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.182% (3616/4400)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.311% (3704/4500)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.261% (3784/4600)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.191% (3863/4700)\n",
      "Test Epoch: 13 | Loss: 0.559 | Acc: 82.083% (3940/4800)\n",
      "Test Epoch: 13 | Loss: 0.555 | Acc: 82.184% (4027/4900)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.120% (4106/5000)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.216% (4193/5100)\n",
      "Test Epoch: 13 | Loss: 0.557 | Acc: 82.135% (4271/5200)\n",
      "Test Epoch: 13 | Loss: 0.556 | Acc: 82.132% (4353/5300)\n",
      "Test Epoch: 13 | Loss: 0.554 | Acc: 82.204% (4439/5400)\n",
      "Test Epoch: 13 | Loss: 0.554 | Acc: 82.164% (4519/5500)\n",
      "Test Epoch: 13 | Loss: 0.553 | Acc: 82.179% (4602/5600)\n",
      "Test Epoch: 13 | Loss: 0.553 | Acc: 82.123% (4681/5700)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.293% (4773/5800)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.271% (4854/5900)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.217% (4933/6000)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.197% (5014/6100)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.258% (5100/6200)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.222% (5180/6300)\n",
      "Test Epoch: 13 | Loss: 0.545 | Acc: 82.281% (5266/6400)\n",
      "Test Epoch: 13 | Loss: 0.545 | Acc: 82.262% (5347/6500)\n",
      "Test Epoch: 13 | Loss: 0.544 | Acc: 82.288% (5431/6600)\n",
      "Test Epoch: 13 | Loss: 0.541 | Acc: 82.313% (5515/6700)\n",
      "Test Epoch: 13 | Loss: 0.544 | Acc: 82.206% (5590/6800)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.275% (5677/6900)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.314% (5762/7000)\n",
      "Test Epoch: 13 | Loss: 0.542 | Acc: 82.296% (5843/7100)\n",
      "Test Epoch: 13 | Loss: 0.541 | Acc: 82.375% (5931/7200)\n",
      "Test Epoch: 13 | Loss: 0.540 | Acc: 82.479% (6021/7300)\n",
      "Test Epoch: 13 | Loss: 0.540 | Acc: 82.446% (6101/7400)\n",
      "Test Epoch: 13 | Loss: 0.541 | Acc: 82.440% (6183/7500)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.447% (6266/7600)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.481% (6351/7700)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.462% (6432/7800)\n",
      "Test Epoch: 13 | Loss: 0.545 | Acc: 82.405% (6510/7900)\n",
      "Test Epoch: 13 | Loss: 0.545 | Acc: 82.412% (6593/8000)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.444% (6678/8100)\n",
      "Test Epoch: 13 | Loss: 0.542 | Acc: 82.415% (6758/8200)\n",
      "Test Epoch: 13 | Loss: 0.542 | Acc: 82.434% (6842/8300)\n",
      "Test Epoch: 13 | Loss: 0.542 | Acc: 82.452% (6926/8400)\n",
      "Test Epoch: 13 | Loss: 0.543 | Acc: 82.400% (7004/8500)\n",
      "Test Epoch: 13 | Loss: 0.545 | Acc: 82.360% (7083/8600)\n",
      "Test Epoch: 13 | Loss: 0.547 | Acc: 82.333% (7163/8700)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.330% (7245/8800)\n",
      "Test Epoch: 13 | Loss: 0.548 | Acc: 82.303% (7325/8900)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.289% (7406/9000)\n",
      "Test Epoch: 13 | Loss: 0.549 | Acc: 82.308% (7490/9100)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.391% (7580/9200)\n",
      "Test Epoch: 13 | Loss: 0.547 | Acc: 82.344% (7658/9300)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.372% (7743/9400)\n",
      "Test Epoch: 13 | Loss: 0.547 | Acc: 82.326% (7821/9500)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.365% (7907/9600)\n",
      "Test Epoch: 13 | Loss: 0.544 | Acc: 82.423% (7995/9700)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.327% (8068/9800)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.333% (8151/9900)\n",
      "Test Epoch: 13 | Loss: 0.546 | Acc: 82.340% (8234/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Train Epoch: 14 | Loss: 0.396 | Acc: 85.938% (110/128)\n",
      "Train Epoch: 14 | Loss: 0.468 | Acc: 84.766% (217/256)\n",
      "Train Epoch: 14 | Loss: 0.462 | Acc: 84.896% (326/384)\n",
      "Train Epoch: 14 | Loss: 0.423 | Acc: 86.328% (442/512)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 86.406% (553/640)\n",
      "Train Epoch: 14 | Loss: 0.448 | Acc: 85.807% (659/768)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 86.384% (774/896)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 85.742% (878/1024)\n",
      "Train Epoch: 14 | Loss: 0.440 | Acc: 85.851% (989/1152)\n",
      "Train Epoch: 14 | Loss: 0.456 | Acc: 85.547% (1095/1280)\n",
      "Train Epoch: 14 | Loss: 0.453 | Acc: 85.724% (1207/1408)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 85.872% (1319/1536)\n",
      "Train Epoch: 14 | Loss: 0.441 | Acc: 85.757% (1427/1664)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 85.714% (1536/1792)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 85.573% (1643/1920)\n",
      "Train Epoch: 14 | Loss: 0.449 | Acc: 85.498% (1751/2048)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 85.616% (1863/2176)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 85.634% (1973/2304)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 85.691% (2084/2432)\n",
      "Train Epoch: 14 | Loss: 0.440 | Acc: 85.859% (2198/2560)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.900% (2309/2688)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 86.009% (2422/2816)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 86.039% (2533/2944)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 86.100% (2645/3072)\n",
      "Train Epoch: 14 | Loss: 0.424 | Acc: 86.188% (2758/3200)\n",
      "Train Epoch: 14 | Loss: 0.428 | Acc: 86.118% (2866/3328)\n",
      "Train Epoch: 14 | Loss: 0.425 | Acc: 86.227% (2980/3456)\n",
      "Train Epoch: 14 | Loss: 0.426 | Acc: 86.077% (3085/3584)\n",
      "Train Epoch: 14 | Loss: 0.424 | Acc: 86.153% (3198/3712)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 86.250% (3312/3840)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 86.391% (3428/3968)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 86.401% (3539/4096)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 86.458% (3652/4224)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 86.328% (3757/4352)\n",
      "Train Epoch: 14 | Loss: 0.423 | Acc: 86.228% (3863/4480)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 86.220% (3973/4608)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 86.296% (4087/4736)\n",
      "Train Epoch: 14 | Loss: 0.422 | Acc: 86.225% (4194/4864)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 86.318% (4309/4992)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 86.230% (4415/5120)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 86.223% (4525/5248)\n",
      "Train Epoch: 14 | Loss: 0.423 | Acc: 86.161% (4632/5376)\n",
      "Train Epoch: 14 | Loss: 0.422 | Acc: 86.156% (4742/5504)\n",
      "Train Epoch: 14 | Loss: 0.422 | Acc: 86.097% (4849/5632)\n",
      "Train Epoch: 14 | Loss: 0.422 | Acc: 86.024% (4955/5760)\n",
      "Train Epoch: 14 | Loss: 0.424 | Acc: 85.954% (5061/5888)\n",
      "Train Epoch: 14 | Loss: 0.425 | Acc: 85.971% (5172/6016)\n",
      "Train Epoch: 14 | Loss: 0.423 | Acc: 86.019% (5285/6144)\n",
      "Train Epoch: 14 | Loss: 0.424 | Acc: 85.922% (5389/6272)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 85.953% (5501/6400)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 86.045% (5617/6528)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.983% (5723/6656)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.967% (5832/6784)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.981% (5943/6912)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 86.037% (6057/7040)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.063% (6169/7168)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.033% (6277/7296)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 86.045% (6388/7424)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.083% (6501/7552)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.081% (6611/7680)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 86.078% (6721/7808)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 86.190% (6840/7936)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.260% (6956/8064)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.279% (7068/8192)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 86.154% (7168/8320)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.091% (7273/8448)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 86.007% (7376/8576)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.995% (7485/8704)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.039% (7599/8832)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.049% (7710/8960)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 86.015% (7817/9088)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 86.024% (7928/9216)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 86.002% (8036/9344)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 86.011% (8147/9472)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.969% (8253/9600)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.958% (8362/9728)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.978% (8474/9856)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.978% (8584/9984)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.967% (8693/10112)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.918% (8798/10240)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.957% (8912/10368)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.985% (9025/10496)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.956% (9132/10624)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.919% (9238/10752)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.901% (9346/10880)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.883% (9454/11008)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.893% (9565/11136)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.893% (9675/11264)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.902% (9786/11392)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.885% (9894/11520)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.843% (9999/11648)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.836% (10108/11776)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.870% (10222/11904)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.888% (10334/12032)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.896% (10445/12160)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.913% (10557/12288)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.897% (10665/12416)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.914% (10777/12544)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.890% (10884/12672)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.930% (10999/12800)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.914% (11107/12928)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.907% (11216/13056)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.930% (11329/13184)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 85.960% (11443/13312)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 85.967% (11554/13440)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.019% (11671/13568)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.047% (11785/13696)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.082% (11900/13824)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.052% (12006/13952)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.037% (12114/14080)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.043% (12225/14208)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.035% (12334/14336)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.055% (12447/14464)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.061% (12558/14592)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.067% (12669/14720)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.072% (12780/14848)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.078% (12891/14976)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.050% (12997/15104)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.075% (13111/15232)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.087% (13223/15360)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.073% (13331/15488)\n",
      "Train Epoch: 14 | Loss: 0.410 | Acc: 86.085% (13443/15616)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.071% (13551/15744)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.026% (13654/15872)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.050% (13768/16000)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.043% (13877/16128)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.024% (13984/16256)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.035% (14096/16384)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.016% (14203/16512)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.016% (14313/16640)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.973% (14416/16768)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.003% (14531/16896)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.014% (14643/17024)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 85.996% (14750/17152)\n",
      "Train Epoch: 14 | Loss: 0.411 | Acc: 86.024% (14865/17280)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.001% (14971/17408)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.029% (15086/17536)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.028% (15196/17664)\n",
      "Train Epoch: 14 | Loss: 0.412 | Acc: 86.011% (15303/17792)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.943% (15401/17920)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.932% (15509/18048)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.921% (15617/18176)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.916% (15726/18304)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.905% (15834/18432)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.857% (15935/18560)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.841% (16042/18688)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.837% (16151/18816)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.806% (16255/18944)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.785% (16361/19072)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.776% (16469/19200)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.746% (16573/19328)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.788% (16691/19456)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.774% (16798/19584)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.770% (16907/19712)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.796% (17022/19840)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.787% (17130/19968)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.788% (17240/20096)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.799% (17352/20224)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.795% (17461/20352)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.835% (17579/20480)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.845% (17691/20608)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.831% (17798/20736)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.851% (17912/20864)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.847% (18021/20992)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.862% (18134/21120)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.890% (18250/21248)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.886% (18359/21376)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.896% (18471/21504)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.864% (18574/21632)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.873% (18686/21760)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.864% (18794/21888)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.856% (18902/22016)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.838% (19008/22144)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.839% (19118/22272)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.839% (19228/22400)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.844% (19339/22528)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.818% (19443/22656)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.823% (19554/22784)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.837% (19667/22912)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.842% (19778/23040)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.868% (19894/23168)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.865% (20003/23296)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.844% (20108/23424)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.874% (20225/23552)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.857% (20331/23680)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.862% (20442/23808)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.858% (20551/23936)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.888% (20668/24064)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.896% (20780/24192)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.880% (20886/24320)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.901% (21001/24448)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.893% (21109/24576)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.897% (21220/24704)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.897% (21330/24832)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.893% (21439/24960)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.878% (21545/25088)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.890% (21658/25216)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.882% (21766/25344)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.867% (21872/25472)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.859% (21980/25600)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.840% (22085/25728)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.852% (22198/25856)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.864% (22311/25984)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.853% (22418/26112)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.808% (22516/26240)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.793% (22622/26368)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.783% (22729/26496)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.791% (22841/26624)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.792% (22951/26752)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.815% (23067/26880)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.797% (23172/27008)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.812% (23286/27136)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.802% (23393/27264)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.813% (23506/27392)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.810% (23615/27520)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.800% (23722/27648)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.797% (23831/27776)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.801% (23942/27904)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.813% (24055/28032)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.831% (24170/28160)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.824% (24278/28288)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.814% (24385/28416)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.804% (24492/28544)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.812% (24604/28672)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.823% (24717/28800)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.827% (24828/28928)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.827% (24938/29056)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.824% (25047/29184)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.808% (25152/29312)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.788% (25256/29440)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.785% (25365/29568)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.779% (25473/29696)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.780% (25583/29824)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.774% (25691/29952)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.778% (25802/30080)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.775% (25911/30208)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.789% (26025/30336)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.806% (26140/30464)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.800% (26248/30592)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.811% (26361/30720)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.808% (26470/30848)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.802% (26578/30976)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.802% (26688/31104)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.797% (26796/31232)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.807% (26909/31360)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.782% (27011/31488)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.779% (27120/31616)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.783% (27231/31744)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.765% (27335/31872)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.753% (27441/32000)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.751% (27550/32128)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.764% (27664/32256)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.777% (27778/32384)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.774% (27887/32512)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.781% (27999/32640)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.803% (28116/32768)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.798% (28224/32896)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.801% (28335/33024)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.766% (28433/33152)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.778% (28547/33280)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.782% (28658/33408)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.788% (28770/33536)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.810% (28887/33664)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.807% (28996/33792)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.799% (29103/33920)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.811% (29217/34048)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.829% (29333/34176)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.821% (29440/34304)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.818% (29549/34432)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.822% (29660/34560)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.819% (29769/34688)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.831% (29883/34816)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.794% (29980/34944)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.812% (30096/35072)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.815% (30207/35200)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.804% (30313/35328)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.819% (30428/35456)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.822% (30539/35584)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.837% (30654/35712)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.845% (30767/35840)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.840% (30875/35968)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.843% (30986/36096)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.855% (31100/36224)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.855% (31210/36352)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.853% (31319/36480)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.858% (31431/36608)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.856% (31540/36736)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.837% (31643/36864)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.846% (31756/36992)\n",
      "Train Epoch: 14 | Loss: 0.413 | Acc: 85.843% (31865/37120)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.819% (31966/37248)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.809% (32072/37376)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.812% (32183/37504)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.797% (32287/37632)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.816% (32404/37760)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.808% (32511/37888)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.814% (32623/38016)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.799% (32727/38144)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.794% (32835/38272)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.807% (32950/38400)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.803% (33058/38528)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.824% (33176/38656)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.829% (33288/38784)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.830% (33398/38912)\n",
      "Train Epoch: 14 | Loss: 0.414 | Acc: 85.827% (33507/39040)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.812% (33611/39168)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.805% (33718/39296)\n",
      "Train Epoch: 14 | Loss: 0.415 | Acc: 85.783% (33819/39424)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.766% (33922/39552)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.771% (34034/39680)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.757% (34138/39808)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.752% (34246/39936)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.755% (34357/40064)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.748% (34464/40192)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.742% (34571/40320)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.730% (34676/40448)\n",
      "Train Epoch: 14 | Loss: 0.416 | Acc: 85.748% (34793/40576)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.743% (34901/40704)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.727% (35004/40832)\n",
      "Train Epoch: 14 | Loss: 0.417 | Acc: 85.723% (35112/40960)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.721% (35221/41088)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.722% (35331/41216)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.710% (35436/41344)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.706% (35544/41472)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.707% (35654/41600)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.693% (35758/41728)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.682% (35863/41856)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.675% (35970/41984)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.662% (36074/42112)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.661% (36183/42240)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.652% (36289/42368)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.643% (36395/42496)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.642% (36504/42624)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.624% (36606/42752)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.632% (36719/42880)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.635% (36830/43008)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.645% (36944/43136)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.635% (37049/43264)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.615% (37150/43392)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.595% (37251/43520)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.589% (37358/43648)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.570% (37459/43776)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.562% (37565/43904)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.579% (37682/44032)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.596% (37799/44160)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.590% (37906/44288)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.595% (38018/44416)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.599% (38129/44544)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.602% (38240/44672)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.605% (38351/44800)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.604% (38460/44928)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.607% (38571/45056)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.590% (38673/45184)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.571% (38774/45312)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.572% (38884/45440)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.567% (38991/45568)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.565% (39100/45696)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.569% (39211/45824)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.565% (39319/45952)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.553% (39423/46080)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.557% (39534/46208)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.571% (39650/46336)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.557% (39753/46464)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.555% (39862/46592)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.539% (39964/46720)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 85.528% (40068/46848)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 85.525% (40176/46976)\n",
      "Train Epoch: 14 | Loss: 0.421 | Acc: 85.524% (40285/47104)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.533% (40399/47232)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.541% (40512/47360)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.542% (40622/47488)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.543% (40732/47616)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.552% (40846/47744)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.564% (40961/47872)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.565% (41071/48000)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.574% (41185/48128)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.583% (41299/48256)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.580% (41407/48384)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.575% (41514/48512)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.559% (41616/48640)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.554% (41723/48768)\n",
      "Train Epoch: 14 | Loss: 0.420 | Acc: 85.553% (41832/48896)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.554% (41942/49024)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.563% (42056/49152)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.564% (42166/49280)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.565% (42276/49408)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.576% (42391/49536)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.583% (42504/49664)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.584% (42614/49792)\n",
      "Train Epoch: 14 | Loss: 0.418 | Acc: 85.595% (42729/49920)\n",
      "Train Epoch: 14 | Loss: 0.419 | Acc: 85.586% (42793/50000)\n",
      "Test Epoch: 14 | Loss: 0.360 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 14 | Loss: 0.418 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 14 | Loss: 0.427 | Acc: 85.667% (257/300)\n",
      "Test Epoch: 14 | Loss: 0.438 | Acc: 85.000% (340/400)\n",
      "Test Epoch: 14 | Loss: 0.431 | Acc: 85.600% (428/500)\n",
      "Test Epoch: 14 | Loss: 0.394 | Acc: 87.167% (523/600)\n",
      "Test Epoch: 14 | Loss: 0.400 | Acc: 86.286% (604/700)\n",
      "Test Epoch: 14 | Loss: 0.409 | Acc: 86.000% (688/800)\n",
      "Test Epoch: 14 | Loss: 0.431 | Acc: 84.889% (764/900)\n",
      "Test Epoch: 14 | Loss: 0.444 | Acc: 84.500% (845/1000)\n",
      "Test Epoch: 14 | Loss: 0.453 | Acc: 84.364% (928/1100)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.250% (1011/1200)\n",
      "Test Epoch: 14 | Loss: 0.448 | Acc: 84.308% (1096/1300)\n",
      "Test Epoch: 14 | Loss: 0.447 | Acc: 84.357% (1181/1400)\n",
      "Test Epoch: 14 | Loss: 0.446 | Acc: 84.200% (1263/1500)\n",
      "Test Epoch: 14 | Loss: 0.453 | Acc: 84.125% (1346/1600)\n",
      "Test Epoch: 14 | Loss: 0.454 | Acc: 84.235% (1432/1700)\n",
      "Test Epoch: 14 | Loss: 0.462 | Acc: 84.056% (1513/1800)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.421% (1604/1900)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.400% (1688/2000)\n",
      "Test Epoch: 14 | Loss: 0.472 | Acc: 84.095% (1766/2100)\n",
      "Test Epoch: 14 | Loss: 0.475 | Acc: 83.955% (1847/2200)\n",
      "Test Epoch: 14 | Loss: 0.479 | Acc: 83.739% (1926/2300)\n",
      "Test Epoch: 14 | Loss: 0.478 | Acc: 83.792% (2011/2400)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 83.840% (2096/2500)\n",
      "Test Epoch: 14 | Loss: 0.494 | Acc: 83.808% (2179/2600)\n",
      "Test Epoch: 14 | Loss: 0.491 | Acc: 83.926% (2266/2700)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 84.000% (2352/2800)\n",
      "Test Epoch: 14 | Loss: 0.491 | Acc: 84.103% (2439/2900)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 84.133% (2524/3000)\n",
      "Test Epoch: 14 | Loss: 0.487 | Acc: 84.161% (2609/3100)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 84.094% (2691/3200)\n",
      "Test Epoch: 14 | Loss: 0.490 | Acc: 84.091% (2775/3300)\n",
      "Test Epoch: 14 | Loss: 0.490 | Acc: 84.000% (2856/3400)\n",
      "Test Epoch: 14 | Loss: 0.500 | Acc: 83.857% (2935/3500)\n",
      "Test Epoch: 14 | Loss: 0.499 | Acc: 83.833% (3018/3600)\n",
      "Test Epoch: 14 | Loss: 0.500 | Acc: 83.946% (3106/3700)\n",
      "Test Epoch: 14 | Loss: 0.497 | Acc: 84.000% (3192/3800)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.154% (3282/3900)\n",
      "Test Epoch: 14 | Loss: 0.492 | Acc: 84.200% (3368/4000)\n",
      "Test Epoch: 14 | Loss: 0.496 | Acc: 84.049% (3446/4100)\n",
      "Test Epoch: 14 | Loss: 0.499 | Acc: 84.000% (3528/4200)\n",
      "Test Epoch: 14 | Loss: 0.494 | Acc: 84.093% (3616/4300)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.114% (3701/4400)\n",
      "Test Epoch: 14 | Loss: 0.490 | Acc: 84.244% (3791/4500)\n",
      "Test Epoch: 14 | Loss: 0.490 | Acc: 84.261% (3876/4600)\n",
      "Test Epoch: 14 | Loss: 0.491 | Acc: 84.149% (3955/4700)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.062% (4035/4800)\n",
      "Test Epoch: 14 | Loss: 0.490 | Acc: 84.143% (4123/4900)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.080% (4204/5000)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.118% (4290/5100)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 84.135% (4375/5200)\n",
      "Test Epoch: 14 | Loss: 0.491 | Acc: 84.057% (4455/5300)\n",
      "Test Epoch: 14 | Loss: 0.492 | Acc: 83.981% (4535/5400)\n",
      "Test Epoch: 14 | Loss: 0.493 | Acc: 83.945% (4617/5500)\n",
      "Test Epoch: 14 | Loss: 0.492 | Acc: 83.946% (4701/5600)\n",
      "Test Epoch: 14 | Loss: 0.492 | Acc: 83.930% (4784/5700)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 83.983% (4871/5800)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 84.017% (4957/5900)\n",
      "Test Epoch: 14 | Loss: 0.489 | Acc: 84.067% (5044/6000)\n",
      "Test Epoch: 14 | Loss: 0.488 | Acc: 84.049% (5127/6100)\n",
      "Test Epoch: 14 | Loss: 0.486 | Acc: 84.161% (5218/6200)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.254% (5308/6300)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.328% (5397/6400)\n",
      "Test Epoch: 14 | Loss: 0.486 | Acc: 84.215% (5474/6500)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.288% (5563/6600)\n",
      "Test Epoch: 14 | Loss: 0.483 | Acc: 84.328% (5650/6700)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.324% (5734/6800)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.246% (5813/6900)\n",
      "Test Epoch: 14 | Loss: 0.487 | Acc: 84.214% (5895/7000)\n",
      "Test Epoch: 14 | Loss: 0.486 | Acc: 84.211% (5979/7100)\n",
      "Test Epoch: 14 | Loss: 0.487 | Acc: 84.208% (6063/7200)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.288% (6153/7300)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.284% (6237/7400)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.253% (6319/7500)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.250% (6403/7600)\n",
      "Test Epoch: 14 | Loss: 0.483 | Acc: 84.273% (6489/7700)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.244% (6571/7800)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.228% (6654/7900)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.200% (6736/8000)\n",
      "Test Epoch: 14 | Loss: 0.482 | Acc: 84.247% (6824/8100)\n",
      "Test Epoch: 14 | Loss: 0.481 | Acc: 84.244% (6908/8200)\n",
      "Test Epoch: 14 | Loss: 0.482 | Acc: 84.205% (6989/8300)\n",
      "Test Epoch: 14 | Loss: 0.482 | Acc: 84.214% (7074/8400)\n",
      "Test Epoch: 14 | Loss: 0.484 | Acc: 84.200% (7157/8500)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.221% (7243/8600)\n",
      "Test Epoch: 14 | Loss: 0.485 | Acc: 84.241% (7329/8700)\n",
      "Test Epoch: 14 | Loss: 0.486 | Acc: 84.193% (7409/8800)\n",
      "Test Epoch: 14 | Loss: 0.487 | Acc: 84.146% (7489/8900)\n",
      "Test Epoch: 14 | Loss: 0.487 | Acc: 84.144% (7573/9000)\n",
      "Test Epoch: 14 | Loss: 0.486 | Acc: 84.154% (7658/9100)\n",
      "Test Epoch: 14 | Loss: 0.483 | Acc: 84.196% (7746/9200)\n",
      "Test Epoch: 14 | Loss: 0.483 | Acc: 84.204% (7831/9300)\n",
      "Test Epoch: 14 | Loss: 0.482 | Acc: 84.223% (7917/9400)\n",
      "Test Epoch: 14 | Loss: 0.482 | Acc: 84.263% (8005/9500)\n",
      "Test Epoch: 14 | Loss: 0.481 | Acc: 84.281% (8091/9600)\n",
      "Test Epoch: 14 | Loss: 0.478 | Acc: 84.392% (8186/9700)\n",
      "Test Epoch: 14 | Loss: 0.478 | Acc: 84.408% (8272/9800)\n",
      "Test Epoch: 14 | Loss: 0.479 | Acc: 84.404% (8356/9900)\n",
      "Test Epoch: 14 | Loss: 0.480 | Acc: 84.390% (8439/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 84.375% (108/128)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 82.812% (212/256)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 84.896% (326/384)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 84.570% (433/512)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.781% (549/640)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 86.328% (663/768)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 86.607% (776/896)\n",
      "Train Epoch: 15 | Loss: 0.392 | Acc: 87.207% (893/1024)\n",
      "Train Epoch: 15 | Loss: 0.379 | Acc: 87.760% (1011/1152)\n",
      "Train Epoch: 15 | Loss: 0.376 | Acc: 87.578% (1121/1280)\n",
      "Train Epoch: 15 | Loss: 0.376 | Acc: 87.500% (1232/1408)\n",
      "Train Epoch: 15 | Loss: 0.386 | Acc: 87.435% (1343/1536)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.959% (1447/1664)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.830% (1556/1792)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.719% (1665/1920)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.768% (1777/2048)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 86.673% (1886/2176)\n",
      "Train Epoch: 15 | Loss: 0.397 | Acc: 86.632% (1996/2304)\n",
      "Train Epoch: 15 | Loss: 0.393 | Acc: 86.842% (2112/2432)\n",
      "Train Epoch: 15 | Loss: 0.391 | Acc: 86.758% (2221/2560)\n",
      "Train Epoch: 15 | Loss: 0.388 | Acc: 86.793% (2333/2688)\n",
      "Train Epoch: 15 | Loss: 0.394 | Acc: 86.648% (2440/2816)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.311% (2541/2944)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 86.361% (2653/3072)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.250% (2760/3200)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.118% (2866/3328)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.053% (2974/3456)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.910% (3079/3584)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.830% (3186/3712)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.755% (3293/3840)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.635% (3398/3968)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.645% (3508/4096)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.535% (3613/4224)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.662% (3728/4352)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.536% (3832/4480)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.655% (3947/4608)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.663% (4057/4736)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.794% (4173/4864)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 85.797% (4283/4992)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.879% (4397/5120)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.861% (4506/5248)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.900% (4618/5376)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.901% (4728/5504)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.902% (4838/5632)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.920% (4949/5760)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 85.819% (5053/5888)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 85.771% (5160/6016)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 85.791% (5271/6144)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 85.842% (5384/6272)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.781% (5490/6400)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 85.815% (5602/6528)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 85.907% (5718/6656)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.908% (5828/6784)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.966% (5942/6912)\n",
      "Train Epoch: 15 | Loss: 0.397 | Acc: 85.980% (6053/7040)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.993% (6164/7168)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.979% (6273/7296)\n",
      "Train Epoch: 15 | Loss: 0.397 | Acc: 86.005% (6385/7424)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 85.990% (6494/7552)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 86.016% (6606/7680)\n",
      "Train Epoch: 15 | Loss: 0.397 | Acc: 86.040% (6718/7808)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.988% (6824/7936)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 86.062% (6940/8064)\n",
      "Train Epoch: 15 | Loss: 0.398 | Acc: 86.035% (7048/8192)\n",
      "Train Epoch: 15 | Loss: 0.399 | Acc: 85.962% (7152/8320)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.878% (7255/8448)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.844% (7362/8576)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.949% (7481/8704)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.971% (7593/8832)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.960% (7702/8960)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 86.004% (7816/9088)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.959% (7922/9216)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.023% (8038/9344)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.001% (8146/9472)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.062% (8262/9600)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.009% (8367/9728)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.059% (8482/9856)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.998% (8586/9984)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.947% (8691/10112)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.957% (8802/10240)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.938% (8910/10368)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.938% (9020/10496)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.928% (9129/10624)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.882% (9234/10752)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.892% (9345/10880)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.856% (9451/11008)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.839% (9559/11136)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.884% (9674/11264)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.911% (9787/11392)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.885% (9894/11520)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.929% (10009/11648)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.912% (10117/11776)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.963% (10233/11904)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.938% (10340/12032)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.913% (10447/12160)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.905% (10556/12288)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.881% (10663/12416)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.866% (10771/12544)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.811% (10874/12672)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.859% (10990/12800)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.899% (11105/12928)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.876% (11212/13056)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.824% (11315/13184)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.840% (11427/13312)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.789% (11530/13440)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.849% (11648/13568)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.857% (11759/13696)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.901% (11875/13824)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.866% (11980/13952)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.859% (12089/14080)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.825% (12194/14208)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.819% (12303/14336)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.820% (12413/14464)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.848% (12527/14592)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.897% (12644/14720)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.917% (12757/14848)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.958% (12873/14976)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 85.997% (12989/15104)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.016% (13102/15232)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.009% (13211/15360)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.002% (13320/15488)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.014% (13432/15616)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.039% (13546/15744)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.045% (13657/15872)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.088% (13774/16000)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 86.080% (13883/16128)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.054% (13989/16256)\n",
      "Train Epoch: 15 | Loss: 0.401 | Acc: 86.078% (14103/16384)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.119% (14220/16512)\n",
      "Train Epoch: 15 | Loss: 0.400 | Acc: 86.058% (14320/16640)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.997% (14420/16768)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.973% (14526/16896)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.949% (14632/17024)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.967% (14745/17152)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.001% (14861/17280)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.006% (14972/17408)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.000% (15081/17536)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.994% (15190/17664)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.022% (15305/17792)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.016% (15414/17920)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.004% (15522/18048)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.998% (15631/18176)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.992% (15740/18304)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.959% (15844/18432)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.975% (15957/18560)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.986% (16069/18688)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.007% (16183/18816)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.006% (16293/18944)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.016% (16405/19072)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.026% (16517/19200)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.020% (16626/19328)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.009% (16734/19456)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.019% (16846/19584)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.009% (16954/19712)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.013% (17065/19840)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.038% (17180/19968)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.012% (17285/20096)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.036% (17400/20224)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.021% (17507/20352)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.035% (17620/20480)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.044% (17732/20608)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.053% (17844/20736)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.029% (17949/20864)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.033% (18060/20992)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.990% (18161/21120)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.980% (18269/21248)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.956% (18374/21376)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.942% (18481/21504)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.951% (18593/21632)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.960% (18705/21760)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.956% (18814/21888)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.965% (18926/22016)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.983% (19040/22144)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.991% (19152/22272)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.969% (19257/22400)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.973% (19368/22528)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.004% (19485/22656)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.981% (19590/22784)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.990% (19702/22912)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 85.998% (19814/23040)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.015% (19928/23168)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.028% (20041/23296)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.006% (20146/23424)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.005% (20256/23552)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.988% (20362/23680)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.946% (20462/23808)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.963% (20576/23936)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.942% (20681/24064)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.958% (20795/24192)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.975% (20909/24320)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.999% (21025/24448)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 85.974% (21129/24576)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.002% (21246/24704)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.014% (21359/24832)\n",
      "Train Epoch: 15 | Loss: 0.402 | Acc: 86.038% (21475/24960)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.017% (21580/25088)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.013% (21689/25216)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.009% (21798/25344)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.008% (21908/25472)\n",
      "Train Epoch: 15 | Loss: 0.403 | Acc: 86.008% (22018/25600)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 85.976% (22120/25728)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.965% (22227/25856)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.945% (22332/25984)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.941% (22441/26112)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.938% (22550/26240)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.934% (22659/26368)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.915% (22764/26496)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.915% (22874/26624)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.919% (22985/26752)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.919% (23095/26880)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.930% (23208/27008)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.930% (23318/27136)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.926% (23427/27264)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.916% (23534/27392)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.901% (23640/27520)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.894% (23748/27648)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.883% (23855/27776)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.884% (23965/27904)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.888% (24076/28032)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.874% (24182/28160)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.881% (24294/28288)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.878% (24403/28416)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.892% (24517/28544)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.885% (24625/28672)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.899% (24739/28800)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.899% (24849/28928)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.907% (24961/29056)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.890% (25066/29184)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.873% (25171/29312)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.870% (25280/29440)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.866% (25389/29568)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.847% (25493/29696)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.857% (25606/29824)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.857% (25716/29952)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.851% (25824/30080)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.845% (25932/30208)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.835% (26039/30336)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.819% (26144/30464)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.807% (26250/30592)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.814% (26362/30720)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.798% (26467/30848)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.789% (26574/30976)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.802% (26688/31104)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.790% (26794/31232)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.775% (26899/31360)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.747% (27000/31488)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.767% (27116/31616)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.780% (27230/31744)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.752% (27331/31872)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.763% (27444/32000)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.782% (27560/32128)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.770% (27666/32256)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.780% (27779/32384)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.784% (27890/32512)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.794% (28003/32640)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.800% (28115/32768)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.816% (28230/32896)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.822% (28342/33024)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.832% (28455/33152)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.859% (28574/33280)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.863% (28685/33408)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.845% (28789/33536)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.842% (28898/33664)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.852% (29011/33792)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.864% (29125/33920)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.861% (29234/34048)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.853% (29341/34176)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.841% (29447/34304)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.842% (29557/34432)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.854% (29671/34560)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.857% (29782/34688)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.854% (29891/34816)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.832% (29993/34944)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.821% (30099/35072)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.804% (30203/35200)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.821% (30319/35328)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 85.828% (30431/35456)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.839% (30545/35584)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.845% (30657/35712)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.857% (30771/35840)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.851% (30879/35968)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.852% (30989/36096)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.852% (31099/36224)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.836% (31203/36352)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.836% (31313/36480)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.828% (31420/36608)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.820% (31527/36736)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.826% (31639/36864)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.840% (31754/36992)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.838% (31863/37120)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.849% (31977/37248)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.855% (32089/37376)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.847% (32196/37504)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.866% (32313/37632)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.866% (32423/37760)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.856% (32529/37888)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.845% (32635/38016)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.848% (32746/38144)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.854% (32858/38272)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.878% (32977/38400)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.878% (33087/38528)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.862% (33191/38656)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.845% (33294/38784)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.842% (33403/38912)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.850% (33516/39040)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.861% (33630/39168)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.879% (33747/39296)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.866% (33852/39424)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.867% (33962/39552)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.872% (34074/39680)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.882% (34188/39808)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.890% (34301/39936)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.880% (34407/40064)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.893% (34522/40192)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.888% (34630/40320)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.886% (34739/40448)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.878% (34846/40576)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.883% (34958/40704)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.869% (35062/40832)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.879% (35176/40960)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.903% (35296/41088)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.911% (35409/41216)\n",
      "Train Epoch: 15 | Loss: 0.407 | Acc: 85.911% (35519/41344)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.913% (35630/41472)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.925% (35745/41600)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.916% (35851/41728)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.926% (35965/41856)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.928% (36076/41984)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.928% (36186/42112)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.935% (36299/42240)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.947% (36414/42368)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.928% (36516/42496)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.942% (36632/42624)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.949% (36745/42752)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.928% (36846/42880)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.944% (36963/43008)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.961% (37080/43136)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.958% (37189/43264)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.954% (37297/43392)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.960% (37410/43520)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.958% (37519/43648)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.951% (37626/43776)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.940% (37731/43904)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.938% (37840/44032)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.942% (37952/44160)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.942% (38062/44288)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.931% (38167/44416)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.933% (38278/44544)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.926% (38385/44672)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.938% (38500/44800)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.944% (38613/44928)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.951% (38726/45056)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.960% (38840/45184)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.964% (38952/45312)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.944% (39053/45440)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.944% (39163/45568)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.938% (39270/45696)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.944% (39383/45824)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.944% (39493/45952)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.955% (39608/46080)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.966% (39723/46208)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.963% (39832/46336)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.968% (39944/46464)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.965% (40053/46592)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.965% (40163/46720)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.972% (40276/46848)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.965% (40383/46976)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.965% (40493/47104)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.980% (40610/47232)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 85.980% (40720/47360)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.986% (40833/47488)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.990% (40945/47616)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.992% (41056/47744)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.002% (41171/47872)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.992% (41276/48000)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.004% (41392/48128)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.996% (41498/48256)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.006% (41613/48384)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.995% (41718/48512)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 85.997% (41829/48640)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.011% (41946/48768)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.005% (42053/48896)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.017% (42169/49024)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.019% (42280/49152)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.027% (42394/49280)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.023% (42502/49408)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.022% (42612/49536)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 86.034% (42728/49664)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.028% (42835/49792)\n",
      "Train Epoch: 15 | Loss: 0.404 | Acc: 86.038% (42950/49920)\n",
      "Train Epoch: 15 | Loss: 0.405 | Acc: 86.028% (43014/50000)\n",
      "Test Epoch: 15 | Loss: 0.457 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 15 | Loss: 0.466 | Acc: 85.000% (170/200)\n",
      "Test Epoch: 15 | Loss: 0.432 | Acc: 86.667% (260/300)\n",
      "Test Epoch: 15 | Loss: 0.425 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 15 | Loss: 0.446 | Acc: 86.400% (432/500)\n",
      "Test Epoch: 15 | Loss: 0.421 | Acc: 86.833% (521/600)\n",
      "Test Epoch: 15 | Loss: 0.435 | Acc: 85.714% (600/700)\n",
      "Test Epoch: 15 | Loss: 0.454 | Acc: 84.750% (678/800)\n",
      "Test Epoch: 15 | Loss: 0.478 | Acc: 84.000% (756/900)\n",
      "Test Epoch: 15 | Loss: 0.499 | Acc: 83.500% (835/1000)\n",
      "Test Epoch: 15 | Loss: 0.507 | Acc: 83.364% (917/1100)\n",
      "Test Epoch: 15 | Loss: 0.514 | Acc: 83.500% (1002/1200)\n",
      "Test Epoch: 15 | Loss: 0.509 | Acc: 83.462% (1085/1300)\n",
      "Test Epoch: 15 | Loss: 0.506 | Acc: 83.571% (1170/1400)\n",
      "Test Epoch: 15 | Loss: 0.500 | Acc: 83.800% (1257/1500)\n",
      "Test Epoch: 15 | Loss: 0.506 | Acc: 83.562% (1337/1600)\n",
      "Test Epoch: 15 | Loss: 0.511 | Acc: 83.647% (1422/1700)\n",
      "Test Epoch: 15 | Loss: 0.514 | Acc: 83.444% (1502/1800)\n",
      "Test Epoch: 15 | Loss: 0.510 | Acc: 83.789% (1592/1900)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.550% (1671/2000)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.476% (1753/2100)\n",
      "Test Epoch: 15 | Loss: 0.531 | Acc: 83.409% (1835/2200)\n",
      "Test Epoch: 15 | Loss: 0.535 | Acc: 83.261% (1915/2300)\n",
      "Test Epoch: 15 | Loss: 0.532 | Acc: 83.417% (2002/2400)\n",
      "Test Epoch: 15 | Loss: 0.535 | Acc: 83.440% (2086/2500)\n",
      "Test Epoch: 15 | Loss: 0.546 | Acc: 83.346% (2167/2600)\n",
      "Test Epoch: 15 | Loss: 0.542 | Acc: 83.407% (2252/2700)\n",
      "Test Epoch: 15 | Loss: 0.541 | Acc: 83.393% (2335/2800)\n",
      "Test Epoch: 15 | Loss: 0.539 | Acc: 83.448% (2420/2900)\n",
      "Test Epoch: 15 | Loss: 0.540 | Acc: 83.333% (2500/3000)\n",
      "Test Epoch: 15 | Loss: 0.544 | Acc: 83.290% (2582/3100)\n",
      "Test Epoch: 15 | Loss: 0.540 | Acc: 83.344% (2667/3200)\n",
      "Test Epoch: 15 | Loss: 0.541 | Acc: 83.212% (2746/3300)\n",
      "Test Epoch: 15 | Loss: 0.540 | Acc: 83.176% (2828/3400)\n",
      "Test Epoch: 15 | Loss: 0.548 | Acc: 83.029% (2906/3500)\n",
      "Test Epoch: 15 | Loss: 0.548 | Acc: 83.139% (2993/3600)\n",
      "Test Epoch: 15 | Loss: 0.546 | Acc: 83.324% (3083/3700)\n",
      "Test Epoch: 15 | Loss: 0.545 | Acc: 83.368% (3168/3800)\n",
      "Test Epoch: 15 | Loss: 0.543 | Acc: 83.487% (3256/3900)\n",
      "Test Epoch: 15 | Loss: 0.541 | Acc: 83.550% (3342/4000)\n",
      "Test Epoch: 15 | Loss: 0.541 | Acc: 83.439% (3421/4100)\n",
      "Test Epoch: 15 | Loss: 0.546 | Acc: 83.452% (3505/4200)\n",
      "Test Epoch: 15 | Loss: 0.540 | Acc: 83.558% (3593/4300)\n",
      "Test Epoch: 15 | Loss: 0.540 | Acc: 83.545% (3676/4400)\n",
      "Test Epoch: 15 | Loss: 0.538 | Acc: 83.533% (3759/4500)\n",
      "Test Epoch: 15 | Loss: 0.538 | Acc: 83.543% (3843/4600)\n",
      "Test Epoch: 15 | Loss: 0.537 | Acc: 83.489% (3924/4700)\n",
      "Test Epoch: 15 | Loss: 0.538 | Acc: 83.479% (4007/4800)\n",
      "Test Epoch: 15 | Loss: 0.536 | Acc: 83.429% (4088/4900)\n",
      "Test Epoch: 15 | Loss: 0.538 | Acc: 83.300% (4165/5000)\n",
      "Test Epoch: 15 | Loss: 0.535 | Acc: 83.353% (4251/5100)\n",
      "Test Epoch: 15 | Loss: 0.537 | Acc: 83.288% (4331/5200)\n",
      "Test Epoch: 15 | Loss: 0.537 | Acc: 83.245% (4412/5300)\n",
      "Test Epoch: 15 | Loss: 0.536 | Acc: 83.278% (4497/5400)\n",
      "Test Epoch: 15 | Loss: 0.536 | Acc: 83.255% (4579/5500)\n",
      "Test Epoch: 15 | Loss: 0.536 | Acc: 83.250% (4662/5600)\n",
      "Test Epoch: 15 | Loss: 0.537 | Acc: 83.211% (4743/5700)\n",
      "Test Epoch: 15 | Loss: 0.533 | Acc: 83.310% (4832/5800)\n",
      "Test Epoch: 15 | Loss: 0.533 | Acc: 83.288% (4914/5900)\n",
      "Test Epoch: 15 | Loss: 0.534 | Acc: 83.217% (4993/6000)\n",
      "Test Epoch: 15 | Loss: 0.534 | Acc: 83.197% (5075/6100)\n",
      "Test Epoch: 15 | Loss: 0.532 | Acc: 83.226% (5160/6200)\n",
      "Test Epoch: 15 | Loss: 0.532 | Acc: 83.238% (5244/6300)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.328% (5333/6400)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.292% (5414/6500)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.303% (5498/6600)\n",
      "Test Epoch: 15 | Loss: 0.528 | Acc: 83.284% (5580/6700)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.279% (5663/6800)\n",
      "Test Epoch: 15 | Loss: 0.531 | Acc: 83.246% (5744/6900)\n",
      "Test Epoch: 15 | Loss: 0.532 | Acc: 83.200% (5824/7000)\n",
      "Test Epoch: 15 | Loss: 0.532 | Acc: 83.169% (5905/7100)\n",
      "Test Epoch: 15 | Loss: 0.531 | Acc: 83.125% (5985/7200)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.178% (6072/7300)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.216% (6158/7400)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.213% (6241/7500)\n",
      "Test Epoch: 15 | Loss: 0.528 | Acc: 83.158% (6320/7600)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.182% (6405/7700)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.128% (6484/7800)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.114% (6566/7900)\n",
      "Test Epoch: 15 | Loss: 0.528 | Acc: 83.062% (6645/8000)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.148% (6735/8100)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.134% (6817/8200)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.145% (6901/8300)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.167% (6986/8400)\n",
      "Test Epoch: 15 | Loss: 0.528 | Acc: 83.129% (7066/8500)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.116% (7148/8600)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.103% (7230/8700)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.125% (7315/8800)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.112% (7397/8900)\n",
      "Test Epoch: 15 | Loss: 0.530 | Acc: 83.100% (7479/9000)\n",
      "Test Epoch: 15 | Loss: 0.529 | Acc: 83.088% (7561/9100)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.185% (7653/9200)\n",
      "Test Epoch: 15 | Loss: 0.528 | Acc: 83.194% (7737/9300)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.191% (7820/9400)\n",
      "Test Epoch: 15 | Loss: 0.527 | Acc: 83.179% (7902/9500)\n",
      "Test Epoch: 15 | Loss: 0.525 | Acc: 83.188% (7986/9600)\n",
      "Test Epoch: 15 | Loss: 0.524 | Acc: 83.216% (8072/9700)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.173% (8151/9800)\n",
      "Test Epoch: 15 | Loss: 0.526 | Acc: 83.202% (8237/9900)\n",
      "Test Epoch: 15 | Loss: 0.525 | Acc: 83.210% (8321/10000)\n",
      "\n",
      "Epoch: 16\n",
      "Train Epoch: 16 | Loss: 0.542 | Acc: 84.375% (108/128)\n",
      "Train Epoch: 16 | Loss: 0.456 | Acc: 85.547% (219/256)\n",
      "Train Epoch: 16 | Loss: 0.416 | Acc: 86.198% (331/384)\n",
      "Train Epoch: 16 | Loss: 0.452 | Acc: 85.156% (436/512)\n",
      "Train Epoch: 16 | Loss: 0.414 | Acc: 86.406% (553/640)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 86.328% (663/768)\n",
      "Train Epoch: 16 | Loss: 0.413 | Acc: 86.161% (772/896)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.523% (886/1024)\n",
      "Train Epoch: 16 | Loss: 0.419 | Acc: 86.111% (992/1152)\n",
      "Train Epoch: 16 | Loss: 0.414 | Acc: 86.328% (1105/1280)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.293% (1215/1408)\n",
      "Train Epoch: 16 | Loss: 0.415 | Acc: 86.263% (1325/1536)\n",
      "Train Epoch: 16 | Loss: 0.416 | Acc: 86.238% (1435/1664)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.551% (1551/1792)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.458% (1660/1920)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 86.084% (1763/2048)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.938% (1870/2176)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.981% (1981/2304)\n",
      "Train Epoch: 16 | Loss: 0.413 | Acc: 85.855% (2088/2432)\n",
      "Train Epoch: 16 | Loss: 0.415 | Acc: 85.781% (2196/2560)\n",
      "Train Epoch: 16 | Loss: 0.417 | Acc: 85.789% (2306/2688)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.151% (2426/2816)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.175% (2537/2944)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.426% (2655/3072)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.375% (2764/3200)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.418% (2876/3328)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.314% (2983/3456)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.272% (3092/3584)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.288% (3203/3712)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.198% (3310/3840)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.190% (3420/3968)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.328% (3536/4096)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.245% (3643/4224)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.305% (3756/4352)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.295% (3866/4480)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.241% (3974/4608)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.254% (4085/4736)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.266% (4196/4864)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.378% (4312/4992)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.289% (4418/5120)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.280% (4528/5248)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.254% (4637/5376)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.283% (4749/5504)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.222% (4856/5632)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.198% (4965/5760)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.226% (5077/5888)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.370% (5196/6016)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.442% (5311/6144)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.480% (5424/6272)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.578% (5541/6400)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.642% (5656/6528)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.779% (5776/6656)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.822% (5890/6784)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.748% (5996/6912)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.747% (6107/7040)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.719% (6216/7168)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.815% (6334/7296)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.840% (6447/7424)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.798% (6555/7552)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.797% (6666/7680)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.744% (6773/7808)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.694% (6880/7936)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.632% (6986/8064)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.633% (7097/8192)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.647% (7209/8320)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.707% (7325/8448)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.707% (7436/8576)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.707% (7547/8704)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.696% (7657/8832)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.674% (7766/8960)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.675% (7877/9088)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.534% (7975/9216)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.494% (8082/9344)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.571% (8200/9472)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.552% (8309/9600)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.626% (8427/9728)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.617% (8537/9856)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.659% (8652/9984)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.650% (8762/10112)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.572% (8865/10240)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.603% (8979/10368)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.604% (9090/10496)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.606% (9201/10624)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.551% (9306/10752)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.590% (9421/10880)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.628% (9536/11008)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.665% (9651/11136)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.657% (9761/11264)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.657% (9872/11392)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.649% (9982/11520)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.667% (10095/11648)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.668% (10206/11776)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.677% (10318/11904)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.694% (10431/12032)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.694% (10542/12160)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.678% (10651/12288)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.646% (10758/12416)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.623% (10866/12544)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.600% (10974/12672)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.562% (11080/12800)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.634% (11200/12928)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.573% (11303/13056)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.590% (11416/13184)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.621% (11531/13312)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.644% (11645/13440)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.608% (11751/13568)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.573% (11857/13696)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.523% (11961/13824)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.511% (12070/13952)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.520% (12182/14080)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.522% (12293/14208)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.544% (12407/14336)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.511% (12513/14464)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.520% (12625/14592)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.549% (12740/14720)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.550% (12851/14848)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.538% (12960/14976)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.494% (13064/15104)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.489% (13174/15232)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.478% (13283/15360)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.532% (13402/15488)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.507% (13509/15616)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.477% (13615/15744)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.442% (13720/15872)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.463% (13834/16000)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.508% (13952/16128)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.503% (14062/16256)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.523% (14176/16384)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.537% (14289/16512)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.562% (14404/16640)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.582% (14518/16768)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.600% (14632/16896)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.595% (14742/17024)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.590% (14852/17152)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.609% (14966/17280)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.598% (15075/17408)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.605% (15187/17536)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.611% (15299/17664)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.595% (15407/17792)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.596% (15518/17920)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.597% (15629/18048)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.587% (15738/18176)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.582% (15848/18304)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.578% (15958/18432)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.552% (16064/18560)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.548% (16174/18688)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.543% (16284/18816)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.560% (16398/18944)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.582% (16513/19072)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.589% (16625/19200)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.636% (16745/19328)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.657% (16860/19456)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.652% (16970/19584)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.658% (17082/19712)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.648% (17191/19840)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.654% (17303/19968)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.669% (17417/20096)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.659% (17526/20224)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.660% (17637/20352)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.641% (17744/20480)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.670% (17861/20608)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.680% (17974/20736)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.709% (18091/20864)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.719% (18204/20992)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.723% (18316/21120)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.733% (18429/21248)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.728% (18539/21376)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.737% (18652/21504)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.728% (18761/21632)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.719% (18870/21760)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.723% (18982/21888)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.737% (19096/22016)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.723% (19204/22144)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.723% (19315/22272)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.732% (19428/22400)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.754% (19544/22528)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.750% (19654/22656)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.754% (19766/22784)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.758% (19878/22912)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.745% (19986/23040)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.732% (20094/23168)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.732% (20205/23296)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.727% (20315/23424)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.706% (20421/23552)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.736% (20539/23680)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.757% (20655/23808)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.740% (20762/23936)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.731% (20871/24064)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.748% (20986/24192)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.727% (21092/24320)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.715% (21200/24448)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.719% (21312/24576)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.715% (21422/24704)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.699% (21529/24832)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.675% (21634/24960)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.667% (21743/25088)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.675% (21856/25216)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.671% (21966/25344)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.660% (22074/25472)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.648% (22182/25600)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.664% (22297/25728)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.653% (22405/25856)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.669% (22520/25984)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.677% (22633/26112)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.688% (22747/26240)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.707% (22863/26368)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.685% (22968/26496)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.700% (23083/26624)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.737% (23204/26752)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.741% (23316/26880)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.782% (23438/27008)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.770% (23546/27136)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.770% (23657/27264)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.781% (23771/27392)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.781% (23882/27520)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.773% (23991/27648)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.766% (24100/27776)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.751% (24207/27904)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.751% (24318/28032)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.722% (24421/28160)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.758% (24542/28288)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.761% (24654/28416)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.761% (24765/28544)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.764% (24877/28672)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.771% (24990/28800)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.795% (25108/28928)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.777% (25214/29056)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.780% (25326/29184)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.760% (25431/29312)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.766% (25544/29440)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.776% (25658/29568)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.776% (25769/29696)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.749% (25872/29824)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.762% (25987/29952)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.745% (26093/30080)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.749% (26205/30208)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.748% (26316/30336)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.745% (26426/30464)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.765% (26543/30592)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.774% (26657/30720)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.774% (26768/30848)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.790% (26884/30976)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.773% (26990/31104)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.770% (27100/31232)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.770% (27211/31360)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.763% (27320/31488)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.773% (27434/31616)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.757% (27540/31744)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.772% (27656/31872)\n",
      "Train Epoch: 16 | Loss: 0.379 | Acc: 86.797% (27775/32000)\n",
      "Train Epoch: 16 | Loss: 0.379 | Acc: 86.787% (27883/32128)\n",
      "Train Epoch: 16 | Loss: 0.379 | Acc: 86.793% (27996/32256)\n",
      "Train Epoch: 16 | Loss: 0.379 | Acc: 86.777% (28102/32384)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.771% (28211/32512)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.765% (28320/32640)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.761% (28430/32768)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.743% (28535/32896)\n",
      "Train Epoch: 16 | Loss: 0.380 | Acc: 86.725% (28640/33024)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.716% (28748/33152)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.698% (28853/33280)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.689% (28961/33408)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.683% (29070/33536)\n",
      "Train Epoch: 16 | Loss: 0.381 | Acc: 86.701% (29187/33664)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.680% (29291/33792)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.686% (29404/33920)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.689% (29516/34048)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.687% (29626/34176)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.666% (29730/34304)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.672% (29843/34432)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.670% (29953/34560)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.664% (30062/34688)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.670% (30175/34816)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.690% (30293/34944)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.696% (30406/35072)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.707% (30521/35200)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.707% (30632/35328)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.713% (30745/35456)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.705% (30853/35584)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.677% (30954/35712)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.680% (31066/35840)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.680% (31177/35968)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.683% (31289/36096)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.680% (31399/36224)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.669% (31506/36352)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.658% (31613/36480)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.653% (31722/36608)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.651% (31832/36736)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.656% (31945/36864)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.670% (32061/36992)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.689% (32179/37120)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.695% (32292/37248)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.681% (32398/37376)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.665% (32503/37504)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.674% (32617/37632)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.690% (32734/37760)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.687% (32844/37888)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.692% (32957/38016)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.687% (33066/38144)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.680% (33174/38272)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.682% (33286/38400)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.685% (33398/38528)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.677% (33506/38656)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.683% (33619/38784)\n",
      "Train Epoch: 16 | Loss: 0.382 | Acc: 86.690% (33733/38912)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.673% (33837/39040)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.668% (33946/39168)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.675% (34060/39296)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.683% (34174/39424)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.673% (34281/39552)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.676% (34393/39680)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.666% (34500/39808)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.679% (34616/39936)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.671% (34724/40064)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.657% (34829/40192)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.649% (34937/40320)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.652% (35049/40448)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.660% (35163/40576)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.675% (35280/40704)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.665% (35387/40832)\n",
      "Train Epoch: 16 | Loss: 0.383 | Acc: 86.660% (35496/40960)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.653% (35604/41088)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.656% (35716/41216)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.663% (35830/41344)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.654% (35937/41472)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.649% (36046/41600)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.640% (36153/41728)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.626% (36258/41856)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.626% (36369/41984)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.638% (36485/42112)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.634% (36594/42240)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.629% (36703/42368)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.620% (36810/42496)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.611% (36917/42624)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.604% (37025/42752)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.614% (37140/42880)\n",
      "Train Epoch: 16 | Loss: 0.384 | Acc: 86.614% (37251/43008)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.610% (37360/43136)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.610% (37471/43264)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.601% (37578/43392)\n",
      "Train Epoch: 16 | Loss: 0.385 | Acc: 86.588% (37683/43520)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.572% (37787/43648)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.557% (37891/43776)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.552% (38000/43904)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.544% (38107/44032)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.542% (38217/44160)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.522% (38319/44288)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.523% (38430/44416)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.519% (38539/44544)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.522% (38651/44672)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.527% (38764/44800)\n",
      "Train Epoch: 16 | Loss: 0.386 | Acc: 86.523% (38873/44928)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.510% (38978/45056)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.486% (39078/45184)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.485% (39188/45312)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.483% (39298/45440)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.488% (39411/45568)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.480% (39518/45696)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.479% (39628/45824)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.484% (39741/45952)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.469% (39845/46080)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.466% (39954/46208)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.468% (40066/46336)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.465% (40175/46464)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.465% (40286/46592)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.464% (40396/46720)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.460% (40505/46848)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.457% (40614/46976)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.458% (40725/47104)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.469% (40841/47232)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.463% (40949/47360)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.456% (41056/47488)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.456% (41167/47616)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.465% (41282/47744)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.466% (41393/47872)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.460% (41501/48000)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.463% (41613/48128)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.456% (41720/48256)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.444% (41825/48384)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.461% (41944/48512)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.476% (42062/48640)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.471% (42170/48768)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.473% (42282/48896)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.478% (42395/49024)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.469% (42501/49152)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.481% (42618/49280)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.480% (42728/49408)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.472% (42835/49536)\n",
      "Train Epoch: 16 | Loss: 0.387 | Acc: 86.459% (42939/49664)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.458% (43049/49792)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.448% (43155/49920)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.438% (43219/50000)\n",
      "Test Epoch: 16 | Loss: 0.472 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 16 | Loss: 0.439 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 16 | Loss: 0.440 | Acc: 85.250% (341/400)\n",
      "Test Epoch: 16 | Loss: 0.457 | Acc: 84.600% (423/500)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 85.000% (510/600)\n",
      "Test Epoch: 16 | Loss: 0.439 | Acc: 85.429% (598/700)\n",
      "Test Epoch: 16 | Loss: 0.449 | Acc: 85.125% (681/800)\n",
      "Test Epoch: 16 | Loss: 0.466 | Acc: 84.111% (757/900)\n",
      "Test Epoch: 16 | Loss: 0.473 | Acc: 84.200% (842/1000)\n",
      "Test Epoch: 16 | Loss: 0.482 | Acc: 83.909% (923/1100)\n",
      "Test Epoch: 16 | Loss: 0.487 | Acc: 83.667% (1004/1200)\n",
      "Test Epoch: 16 | Loss: 0.486 | Acc: 83.615% (1087/1300)\n",
      "Test Epoch: 16 | Loss: 0.484 | Acc: 83.643% (1171/1400)\n",
      "Test Epoch: 16 | Loss: 0.487 | Acc: 83.600% (1254/1500)\n",
      "Test Epoch: 16 | Loss: 0.498 | Acc: 83.562% (1337/1600)\n",
      "Test Epoch: 16 | Loss: 0.491 | Acc: 83.824% (1425/1700)\n",
      "Test Epoch: 16 | Loss: 0.489 | Acc: 83.667% (1506/1800)\n",
      "Test Epoch: 16 | Loss: 0.495 | Acc: 83.632% (1589/1900)\n",
      "Test Epoch: 16 | Loss: 0.500 | Acc: 83.450% (1669/2000)\n",
      "Test Epoch: 16 | Loss: 0.506 | Acc: 83.381% (1751/2100)\n",
      "Test Epoch: 16 | Loss: 0.514 | Acc: 83.273% (1832/2200)\n",
      "Test Epoch: 16 | Loss: 0.516 | Acc: 83.348% (1917/2300)\n",
      "Test Epoch: 16 | Loss: 0.518 | Acc: 83.250% (1998/2400)\n",
      "Test Epoch: 16 | Loss: 0.523 | Acc: 83.080% (2077/2500)\n",
      "Test Epoch: 16 | Loss: 0.532 | Acc: 83.038% (2159/2600)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 83.185% (2246/2700)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.250% (2331/2800)\n",
      "Test Epoch: 16 | Loss: 0.532 | Acc: 83.138% (2411/2900)\n",
      "Test Epoch: 16 | Loss: 0.532 | Acc: 83.133% (2494/3000)\n",
      "Test Epoch: 16 | Loss: 0.533 | Acc: 83.194% (2579/3100)\n",
      "Test Epoch: 16 | Loss: 0.531 | Acc: 83.156% (2661/3200)\n",
      "Test Epoch: 16 | Loss: 0.531 | Acc: 83.061% (2741/3300)\n",
      "Test Epoch: 16 | Loss: 0.532 | Acc: 83.029% (2823/3400)\n",
      "Test Epoch: 16 | Loss: 0.538 | Acc: 82.800% (2898/3500)\n",
      "Test Epoch: 16 | Loss: 0.538 | Acc: 82.806% (2981/3600)\n",
      "Test Epoch: 16 | Loss: 0.539 | Acc: 82.838% (3065/3700)\n",
      "Test Epoch: 16 | Loss: 0.537 | Acc: 82.842% (3148/3800)\n",
      "Test Epoch: 16 | Loss: 0.534 | Acc: 82.974% (3236/3900)\n",
      "Test Epoch: 16 | Loss: 0.535 | Acc: 82.975% (3319/4000)\n",
      "Test Epoch: 16 | Loss: 0.533 | Acc: 82.951% (3401/4100)\n",
      "Test Epoch: 16 | Loss: 0.534 | Acc: 82.857% (3480/4200)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 82.953% (3567/4300)\n",
      "Test Epoch: 16 | Loss: 0.531 | Acc: 82.977% (3651/4400)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.111% (3740/4500)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.087% (3822/4600)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.128% (3907/4700)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.062% (3987/4800)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.163% (4075/4900)\n",
      "Test Epoch: 16 | Loss: 0.530 | Acc: 83.000% (4150/5000)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.118% (4239/5100)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.096% (4321/5200)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.075% (4403/5300)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.130% (4489/5400)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.109% (4571/5500)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.143% (4656/5600)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.193% (4742/5700)\n",
      "Test Epoch: 16 | Loss: 0.523 | Acc: 83.259% (4829/5800)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.237% (4911/5900)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.217% (4993/6000)\n",
      "Test Epoch: 16 | Loss: 0.525 | Acc: 83.230% (5077/6100)\n",
      "Test Epoch: 16 | Loss: 0.524 | Acc: 83.274% (5163/6200)\n",
      "Test Epoch: 16 | Loss: 0.522 | Acc: 83.302% (5248/6300)\n",
      "Test Epoch: 16 | Loss: 0.520 | Acc: 83.328% (5333/6400)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.308% (5415/6500)\n",
      "Test Epoch: 16 | Loss: 0.520 | Acc: 83.288% (5497/6600)\n",
      "Test Epoch: 16 | Loss: 0.519 | Acc: 83.328% (5583/6700)\n",
      "Test Epoch: 16 | Loss: 0.520 | Acc: 83.309% (5665/6800)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.304% (5748/6900)\n",
      "Test Epoch: 16 | Loss: 0.523 | Acc: 83.271% (5829/7000)\n",
      "Test Epoch: 16 | Loss: 0.522 | Acc: 83.324% (5916/7100)\n",
      "Test Epoch: 16 | Loss: 0.523 | Acc: 83.319% (5999/7200)\n",
      "Test Epoch: 16 | Loss: 0.522 | Acc: 83.411% (6089/7300)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.446% (6175/7400)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.413% (6256/7500)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.382% (6337/7600)\n",
      "Test Epoch: 16 | Loss: 0.522 | Acc: 83.377% (6420/7700)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.397% (6505/7800)\n",
      "Test Epoch: 16 | Loss: 0.522 | Acc: 83.392% (6588/7900)\n",
      "Test Epoch: 16 | Loss: 0.521 | Acc: 83.412% (6673/8000)\n",
      "Test Epoch: 16 | Loss: 0.519 | Acc: 83.420% (6757/8100)\n",
      "Test Epoch: 16 | Loss: 0.519 | Acc: 83.402% (6839/8200)\n",
      "Test Epoch: 16 | Loss: 0.518 | Acc: 83.434% (6925/8300)\n",
      "Test Epoch: 16 | Loss: 0.520 | Acc: 83.369% (7003/8400)\n",
      "Test Epoch: 16 | Loss: 0.523 | Acc: 83.306% (7081/8500)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.256% (7160/8600)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.184% (7237/8700)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 83.159% (7318/8800)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.213% (7406/8900)\n",
      "Test Epoch: 16 | Loss: 0.530 | Acc: 83.222% (7490/9000)\n",
      "Test Epoch: 16 | Loss: 0.530 | Acc: 83.209% (7572/9100)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.283% (7662/9200)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 83.247% (7742/9300)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 83.245% (7825/9400)\n",
      "Test Epoch: 16 | Loss: 0.529 | Acc: 83.211% (7905/9500)\n",
      "Test Epoch: 16 | Loss: 0.528 | Acc: 83.229% (7990/9600)\n",
      "Test Epoch: 16 | Loss: 0.526 | Acc: 83.309% (8081/9700)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.327% (8166/9800)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.293% (8246/9900)\n",
      "Test Epoch: 16 | Loss: 0.527 | Acc: 83.270% (8327/10000)\n",
      "\n",
      "Epoch: 17\n",
      "Train Epoch: 17 | Loss: 0.515 | Acc: 80.469% (103/128)\n",
      "Train Epoch: 17 | Loss: 0.423 | Acc: 84.766% (217/256)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 85.417% (328/384)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.156% (436/512)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 85.938% (550/640)\n",
      "Train Epoch: 17 | Loss: 0.386 | Acc: 86.198% (662/768)\n",
      "Train Epoch: 17 | Loss: 0.385 | Acc: 86.384% (774/896)\n",
      "Train Epoch: 17 | Loss: 0.388 | Acc: 86.426% (885/1024)\n",
      "Train Epoch: 17 | Loss: 0.375 | Acc: 86.806% (1000/1152)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 86.797% (1111/1280)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 86.364% (1216/1408)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 86.458% (1328/1536)\n",
      "Train Epoch: 17 | Loss: 0.374 | Acc: 85.998% (1431/1664)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 86.440% (1549/1792)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 86.719% (1665/1920)\n",
      "Train Epoch: 17 | Loss: 0.357 | Acc: 87.158% (1785/2048)\n",
      "Train Epoch: 17 | Loss: 0.362 | Acc: 87.178% (1897/2176)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.023% (2005/2304)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 86.924% (2114/2432)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 86.914% (2225/2560)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 86.905% (2336/2688)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 86.825% (2445/2816)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 86.923% (2559/2944)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 86.979% (2672/3072)\n",
      "Train Epoch: 17 | Loss: 0.363 | Acc: 87.125% (2788/3200)\n",
      "Train Epoch: 17 | Loss: 0.363 | Acc: 87.139% (2900/3328)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 86.979% (3006/3456)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 86.886% (3114/3584)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.015% (3230/3712)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.031% (3342/3840)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.046% (3454/3968)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.036% (3565/4096)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.240% (3685/4224)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.247% (3797/4352)\n",
      "Train Epoch: 17 | Loss: 0.363 | Acc: 87.232% (3908/4480)\n",
      "Train Epoch: 17 | Loss: 0.362 | Acc: 87.370% (4026/4608)\n",
      "Train Epoch: 17 | Loss: 0.359 | Acc: 87.479% (4143/4736)\n",
      "Train Epoch: 17 | Loss: 0.358 | Acc: 87.623% (4262/4864)\n",
      "Train Epoch: 17 | Loss: 0.357 | Acc: 87.660% (4376/4992)\n",
      "Train Epoch: 17 | Loss: 0.358 | Acc: 87.598% (4485/5120)\n",
      "Train Epoch: 17 | Loss: 0.358 | Acc: 87.595% (4597/5248)\n",
      "Train Epoch: 17 | Loss: 0.355 | Acc: 87.705% (4715/5376)\n",
      "Train Epoch: 17 | Loss: 0.355 | Acc: 87.718% (4828/5504)\n",
      "Train Epoch: 17 | Loss: 0.357 | Acc: 87.660% (4937/5632)\n",
      "Train Epoch: 17 | Loss: 0.357 | Acc: 87.587% (5045/5760)\n",
      "Train Epoch: 17 | Loss: 0.359 | Acc: 87.585% (5157/5888)\n",
      "Train Epoch: 17 | Loss: 0.360 | Acc: 87.533% (5266/6016)\n",
      "Train Epoch: 17 | Loss: 0.358 | Acc: 87.549% (5379/6144)\n",
      "Train Epoch: 17 | Loss: 0.360 | Acc: 87.500% (5488/6272)\n",
      "Train Epoch: 17 | Loss: 0.359 | Acc: 87.516% (5601/6400)\n",
      "Train Epoch: 17 | Loss: 0.361 | Acc: 87.423% (5707/6528)\n",
      "Train Epoch: 17 | Loss: 0.361 | Acc: 87.365% (5815/6656)\n",
      "Train Epoch: 17 | Loss: 0.363 | Acc: 87.294% (5922/6784)\n",
      "Train Epoch: 17 | Loss: 0.362 | Acc: 87.283% (6033/6912)\n",
      "Train Epoch: 17 | Loss: 0.362 | Acc: 87.273% (6144/7040)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.235% (6253/7168)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.226% (6364/7296)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 87.190% (6473/7424)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 87.209% (6586/7552)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.318% (6706/7680)\n",
      "Train Epoch: 17 | Loss: 0.362 | Acc: 87.346% (6820/7808)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.261% (6925/7936)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.289% (7039/8064)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.244% (7147/8192)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.212% (7256/8320)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 87.228% (7369/8448)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.174% (7476/8576)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.109% (7582/8704)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.092% (7692/8832)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.132% (7807/8960)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.170% (7922/9088)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.164% (8033/9216)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.168% (8145/9344)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.183% (8258/9472)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.229% (8374/9600)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.243% (8487/9728)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.226% (8597/9856)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.220% (8708/9984)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.164% (8814/10112)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.168% (8926/10240)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.153% (9036/10368)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.176% (9150/10496)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.255% (9270/10624)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.230% (9379/10752)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.252% (9493/10880)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.282% (9608/11008)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.311% (9723/11136)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.331% (9837/11264)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.351% (9951/11392)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.274% (10054/11520)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.200% (10157/11648)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.245% (10274/11776)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.214% (10382/11904)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.209% (10493/12032)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.278% (10613/12160)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.272% (10724/12288)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 87.299% (10839/12416)\n",
      "Train Epoch: 17 | Loss: 0.364 | Acc: 87.341% (10956/12544)\n",
      "Train Epoch: 17 | Loss: 0.365 | Acc: 87.287% (11061/12672)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.273% (11171/12800)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.291% (11285/12928)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.309% (11399/13056)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.227% (11500/13184)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.200% (11608/13312)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.240% (11725/13440)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.205% (11832/13568)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.274% (11953/13696)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.269% (12064/13824)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.249% (12173/13952)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.216% (12280/14080)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.240% (12395/14208)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.263% (12510/14336)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.265% (12622/14464)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.267% (12734/14592)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.283% (12848/14720)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.271% (12958/14848)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.266% (13069/14976)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.275% (13182/15104)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.290% (13296/15232)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.292% (13408/15360)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.326% (13525/15488)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.314% (13635/15616)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.348% (13752/15744)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.317% (13859/15872)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.306% (13969/16000)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.308% (14081/16128)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.291% (14190/16256)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.286% (14301/16384)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.300% (14415/16512)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.296% (14526/16640)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.273% (14634/16768)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.299% (14750/16896)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.259% (14855/17024)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.243% (14964/17152)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.274% (15081/17280)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.299% (15197/17408)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.278% (15305/17536)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.245% (15411/17664)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.230% (15520/17792)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.199% (15626/17920)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.201% (15738/18048)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.236% (15856/18176)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.243% (15969/18304)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.240% (16080/18432)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.231% (16190/18560)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.222% (16300/18688)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.202% (16408/18816)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.178% (16515/18944)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.180% (16627/19072)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.193% (16741/19200)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.169% (16848/19328)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.192% (16964/19456)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.178% (17073/19584)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.191% (17187/19712)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.193% (17299/19840)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.195% (17411/19968)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.191% (17522/20096)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.198% (17635/20224)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.190% (17745/20352)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.202% (17859/20480)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.219% (17974/20608)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.240% (18090/20736)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.232% (18200/20864)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.195% (18304/20992)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.183% (18413/21120)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.175% (18523/21248)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.163% (18632/21376)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.188% (18749/21504)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.204% (18864/21632)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.224% (18980/21760)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.240% (19095/21888)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.250% (19209/22016)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.274% (19326/22144)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.280% (19439/22272)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.281% (19551/22400)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.287% (19664/22528)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.284% (19775/22656)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.289% (19888/22784)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.304% (20003/22912)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.296% (20113/23040)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.306% (20227/23168)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.290% (20335/23296)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.304% (20450/23424)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.305% (20562/23552)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.272% (20666/23680)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.256% (20774/23808)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.233% (20880/23936)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.234% (20992/24064)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.244% (21106/24192)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.262% (21222/24320)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.267% (21335/24448)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.264% (21446/24576)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.269% (21559/24704)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.283% (21674/24832)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.280% (21785/24960)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.289% (21899/25088)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.286% (22010/25216)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.299% (22125/25344)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.315% (22241/25472)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.293% (22347/25600)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.298% (22460/25728)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.272% (22565/25856)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.273% (22677/25984)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.270% (22788/26112)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.260% (22897/26240)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.269% (23011/26368)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.262% (23121/26496)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.267% (23234/26624)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.279% (23349/26752)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.273% (23459/26880)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.293% (23576/27008)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.312% (23693/27136)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.302% (23802/27264)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.307% (23915/27392)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.293% (24023/27520)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.308% (24139/27648)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.302% (24249/27776)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.299% (24360/27904)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.282% (24467/28032)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.276% (24577/28160)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.281% (24690/28288)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.271% (24799/28416)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.262% (24908/28544)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.287% (25027/28672)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.285% (25138/28800)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.261% (25243/28928)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.263% (25355/29056)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.257% (25465/29184)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.251% (25575/29312)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.262% (25690/29440)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.250% (25798/29568)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.244% (25908/29696)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.249% (26021/29824)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.260% (26136/29952)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.284% (26255/30080)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.285% (26367/30208)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.269% (26474/30336)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.264% (26584/30464)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.271% (26698/30592)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.288% (26815/30720)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.260% (26918/30848)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.268% (27032/30976)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.269% (27144/31104)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.276% (27258/31232)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.277% (27370/31360)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.246% (27472/31488)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.260% (27588/31616)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.257% (27699/31744)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.280% (27818/31872)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.284% (27931/32000)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.257% (28034/32128)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.230% (28137/32256)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.238% (28251/32384)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.254% (28368/32512)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.249% (28478/32640)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.238% (28586/32768)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.232% (28696/32896)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.240% (28810/33024)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.250% (28925/33152)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.254% (29038/33280)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.255% (29150/33408)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.258% (29263/33536)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.277% (29381/33664)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.266% (29489/33792)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.267% (29601/33920)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.262% (29711/34048)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.257% (29821/34176)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.261% (29934/34304)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.239% (30038/34432)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.248% (30153/34560)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.246% (30264/34688)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.239% (30373/34816)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.257% (30491/34944)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.260% (30604/35072)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.267% (30718/35200)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.262% (30828/35328)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.263% (30940/35456)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.250% (31047/35584)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.245% (31157/35712)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.232% (31264/35840)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.225% (31373/35968)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.226% (31485/36096)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.229% (31598/36224)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.241% (31714/36352)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.231% (31822/36480)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.235% (31935/36608)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.247% (32051/36736)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.248% (32163/36864)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.249% (32275/36992)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.228% (32379/37120)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.240% (32495/37248)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.238% (32606/37376)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.212% (32708/37504)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.189% (32811/37632)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.174% (32917/37760)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.173% (33028/37888)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.190% (33146/38016)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.193% (33259/38144)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.173% (33363/38272)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.182% (33478/38400)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.178% (33588/38528)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.187% (33703/38656)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.173% (33809/38784)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.166% (33918/38912)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.167% (34030/39040)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.178% (34146/39168)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.195% (34264/39296)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.196% (34376/39424)\n",
      "Train Epoch: 17 | Loss: 0.369 | Acc: 87.194% (34487/39552)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.195% (34599/39680)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.171% (34701/39808)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.172% (34813/39936)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.168% (34923/40064)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.154% (35029/40192)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.145% (35137/40320)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.142% (35247/40448)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.148% (35361/40576)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.129% (35465/40704)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.130% (35577/40832)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.126% (35687/40960)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.130% (35800/41088)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.146% (35918/41216)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.137% (36026/41344)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.131% (36135/41472)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.132% (36247/41600)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.143% (36363/41728)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.134% (36471/41856)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.126% (36579/41984)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.137% (36695/42112)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.126% (36802/42240)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.127% (36914/42368)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.114% (37020/42496)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.125% (37136/42624)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.107% (37240/42752)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.101% (37349/42880)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.098% (37459/43008)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.087% (37566/43136)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.084% (37676/43264)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.083% (37787/43392)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.084% (37899/43520)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.101% (38018/43648)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.087% (38123/43776)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.090% (38236/43904)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.093% (38349/44032)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.081% (38455/44160)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.082% (38567/44288)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.065% (38671/44416)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.071% (38785/44544)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.081% (38901/44672)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.078% (39011/44800)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.079% (39123/44928)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.078% (39234/45056)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.084% (39348/45184)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.078% (39457/45312)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.086% (39572/45440)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.090% (39685/45568)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.093% (39798/45696)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.098% (39912/45824)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.089% (40019/45952)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.096% (40134/46080)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.091% (40243/46208)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.099% (40358/46336)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.098% (40469/46464)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.088% (40576/46592)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.087% (40687/46720)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.079% (40795/46848)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.081% (40907/46976)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.071% (41014/47104)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.079% (41129/47232)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.071% (41237/47360)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.073% (41349/47488)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.074% (41461/47616)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.075% (41573/47744)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.072% (41683/47872)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.073% (41795/48000)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.076% (41908/48128)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.063% (42013/48256)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.072% (42129/48384)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.073% (42241/48512)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.066% (42349/48640)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.071% (42463/48768)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.073% (42575/48896)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.074% (42687/49024)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.085% (42804/49152)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.084% (42915/49280)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.069% (43019/49408)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.052% (43122/49536)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.049% (43232/49664)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.052% (43345/49792)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.055% (43458/49920)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.058% (43529/50000)\n",
      "Test Epoch: 17 | Loss: 0.359 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 17 | Loss: 0.395 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 17 | Loss: 0.372 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 17 | Loss: 0.407 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 17 | Loss: 0.412 | Acc: 86.400% (432/500)\n",
      "Test Epoch: 17 | Loss: 0.384 | Acc: 86.667% (520/600)\n",
      "Test Epoch: 17 | Loss: 0.393 | Acc: 86.286% (604/700)\n",
      "Test Epoch: 17 | Loss: 0.416 | Acc: 85.375% (683/800)\n",
      "Test Epoch: 17 | Loss: 0.437 | Acc: 84.667% (762/900)\n",
      "Test Epoch: 17 | Loss: 0.450 | Acc: 84.500% (845/1000)\n",
      "Test Epoch: 17 | Loss: 0.467 | Acc: 84.182% (926/1100)\n",
      "Test Epoch: 17 | Loss: 0.473 | Acc: 83.917% (1007/1200)\n",
      "Test Epoch: 17 | Loss: 0.472 | Acc: 83.923% (1091/1300)\n",
      "Test Epoch: 17 | Loss: 0.472 | Acc: 84.071% (1177/1400)\n",
      "Test Epoch: 17 | Loss: 0.476 | Acc: 83.867% (1258/1500)\n",
      "Test Epoch: 17 | Loss: 0.480 | Acc: 83.688% (1339/1600)\n",
      "Test Epoch: 17 | Loss: 0.482 | Acc: 83.647% (1422/1700)\n",
      "Test Epoch: 17 | Loss: 0.480 | Acc: 83.667% (1506/1800)\n",
      "Test Epoch: 17 | Loss: 0.478 | Acc: 83.789% (1592/1900)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.700% (1674/2000)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.476% (1753/2100)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.455% (1836/2200)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.435% (1919/2300)\n",
      "Test Epoch: 17 | Loss: 0.481 | Acc: 83.667% (2008/2400)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.640% (2091/2500)\n",
      "Test Epoch: 17 | Loss: 0.495 | Acc: 83.385% (2168/2600)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.593% (2257/2700)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.464% (2337/2800)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.448% (2420/2900)\n",
      "Test Epoch: 17 | Loss: 0.481 | Acc: 83.567% (2507/3000)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.516% (2589/3100)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.469% (2671/3200)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.455% (2754/3300)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.471% (2838/3400)\n",
      "Test Epoch: 17 | Loss: 0.496 | Acc: 83.371% (2918/3500)\n",
      "Test Epoch: 17 | Loss: 0.493 | Acc: 83.444% (3004/3600)\n",
      "Test Epoch: 17 | Loss: 0.495 | Acc: 83.541% (3091/3700)\n",
      "Test Epoch: 17 | Loss: 0.494 | Acc: 83.605% (3177/3800)\n",
      "Test Epoch: 17 | Loss: 0.493 | Acc: 83.641% (3262/3900)\n",
      "Test Epoch: 17 | Loss: 0.490 | Acc: 83.725% (3349/4000)\n",
      "Test Epoch: 17 | Loss: 0.495 | Acc: 83.659% (3430/4100)\n",
      "Test Epoch: 17 | Loss: 0.497 | Acc: 83.643% (3513/4200)\n",
      "Test Epoch: 17 | Loss: 0.491 | Acc: 83.884% (3607/4300)\n",
      "Test Epoch: 17 | Loss: 0.490 | Acc: 83.886% (3691/4400)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.911% (3776/4500)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.935% (3861/4600)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.936% (3945/4700)\n",
      "Test Epoch: 17 | Loss: 0.491 | Acc: 83.875% (4026/4800)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 84.000% (4116/4900)\n",
      "Test Epoch: 17 | Loss: 0.490 | Acc: 83.880% (4194/5000)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.902% (4279/5100)\n",
      "Test Epoch: 17 | Loss: 0.493 | Acc: 83.769% (4356/5200)\n",
      "Test Epoch: 17 | Loss: 0.492 | Acc: 83.774% (4440/5300)\n",
      "Test Epoch: 17 | Loss: 0.492 | Acc: 83.778% (4524/5400)\n",
      "Test Epoch: 17 | Loss: 0.492 | Acc: 83.745% (4606/5500)\n",
      "Test Epoch: 17 | Loss: 0.491 | Acc: 83.821% (4694/5600)\n",
      "Test Epoch: 17 | Loss: 0.491 | Acc: 83.807% (4777/5700)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.879% (4865/5800)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.881% (4949/5900)\n",
      "Test Epoch: 17 | Loss: 0.490 | Acc: 83.750% (5025/6000)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.738% (5108/6100)\n",
      "Test Epoch: 17 | Loss: 0.489 | Acc: 83.758% (5193/6200)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.794% (5279/6300)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.797% (5363/6400)\n",
      "Test Epoch: 17 | Loss: 0.490 | Acc: 83.754% (5444/6500)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.788% (5530/6600)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.836% (5617/6700)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.853% (5702/6800)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.855% (5786/6900)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.757% (5863/7000)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.789% (5949/7100)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.778% (6032/7200)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.836% (6120/7300)\n",
      "Test Epoch: 17 | Loss: 0.482 | Acc: 83.878% (6207/7400)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.800% (6285/7500)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.803% (6369/7600)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.779% (6451/7700)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.808% (6537/7800)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.835% (6623/7900)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.812% (6705/8000)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 83.852% (6792/8100)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 83.841% (6875/8200)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 83.855% (6960/8300)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 83.821% (7041/8400)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.824% (7125/8500)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.837% (7210/8600)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.851% (7295/8700)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.830% (7377/8800)\n",
      "Test Epoch: 17 | Loss: 0.487 | Acc: 83.831% (7461/8900)\n",
      "Test Epoch: 17 | Loss: 0.488 | Acc: 83.778% (7540/9000)\n",
      "Test Epoch: 17 | Loss: 0.486 | Acc: 83.857% (7631/9100)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.935% (7722/9200)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.925% (7805/9300)\n",
      "Test Epoch: 17 | Loss: 0.485 | Acc: 83.926% (7889/9400)\n",
      "Test Epoch: 17 | Loss: 0.484 | Acc: 83.968% (7977/9500)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 84.042% (8068/9600)\n",
      "Test Epoch: 17 | Loss: 0.481 | Acc: 84.103% (8158/9700)\n",
      "Test Epoch: 17 | Loss: 0.483 | Acc: 84.020% (8234/9800)\n",
      "Test Epoch: 17 | Loss: 0.482 | Acc: 84.071% (8323/9900)\n",
      "Test Epoch: 17 | Loss: 0.482 | Acc: 84.070% (8407/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Train Epoch: 18 | Loss: 0.261 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 18 | Loss: 0.235 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 18 | Loss: 0.289 | Acc: 90.885% (349/384)\n",
      "Train Epoch: 18 | Loss: 0.294 | Acc: 90.430% (463/512)\n",
      "Train Epoch: 18 | Loss: 0.302 | Acc: 89.688% (574/640)\n",
      "Train Epoch: 18 | Loss: 0.318 | Acc: 89.193% (685/768)\n",
      "Train Epoch: 18 | Loss: 0.325 | Acc: 88.951% (797/896)\n",
      "Train Epoch: 18 | Loss: 0.326 | Acc: 88.770% (909/1024)\n",
      "Train Epoch: 18 | Loss: 0.331 | Acc: 88.715% (1022/1152)\n",
      "Train Epoch: 18 | Loss: 0.333 | Acc: 88.750% (1136/1280)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.494% (1246/1408)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 88.216% (1355/1536)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 88.341% (1470/1664)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.504% (1586/1792)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.438% (1698/1920)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.477% (1812/2048)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 88.649% (1929/2176)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.889% (2048/2304)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 88.405% (2150/2432)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 88.242% (2259/2560)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.356% (2375/2688)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.210% (2484/2816)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.281% (2599/2944)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 88.118% (2707/3072)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 88.000% (2816/3200)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.951% (2927/3328)\n",
      "Train Epoch: 18 | Loss: 0.341 | Acc: 88.108% (3045/3456)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.198% (3161/3584)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.254% (3276/3712)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.333% (3392/3840)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.256% (3502/3968)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.086% (3608/4096)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.092% (3721/4224)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 88.006% (3830/4352)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 87.879% (3937/4480)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 87.934% (4052/4608)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.943% (4165/4736)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 87.993% (4280/4864)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 87.901% (4388/4992)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 87.930% (4502/5120)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.957% (4616/5248)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.021% (4732/5376)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.063% (4847/5504)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.033% (4958/5632)\n",
      "Train Epoch: 18 | Loss: 0.335 | Acc: 88.142% (5077/5760)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.060% (5185/5888)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.082% (5299/6016)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.037% (5409/6144)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 88.026% (5521/6272)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.000% (5632/6400)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.051% (5748/6528)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.041% (5860/6656)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.075% (5975/6784)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.079% (6088/6912)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 87.983% (6194/7040)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.030% (6310/7168)\n",
      "Train Epoch: 18 | Loss: 0.335 | Acc: 88.076% (6426/7296)\n",
      "Train Epoch: 18 | Loss: 0.334 | Acc: 88.147% (6544/7424)\n",
      "Train Epoch: 18 | Loss: 0.334 | Acc: 88.122% (6655/7552)\n",
      "Train Epoch: 18 | Loss: 0.333 | Acc: 88.164% (6771/7680)\n",
      "Train Epoch: 18 | Loss: 0.331 | Acc: 88.256% (6891/7808)\n",
      "Train Epoch: 18 | Loss: 0.330 | Acc: 88.281% (7006/7936)\n",
      "Train Epoch: 18 | Loss: 0.331 | Acc: 88.219% (7114/8064)\n",
      "Train Epoch: 18 | Loss: 0.333 | Acc: 88.159% (7222/8192)\n",
      "Train Epoch: 18 | Loss: 0.334 | Acc: 88.053% (7326/8320)\n",
      "Train Epoch: 18 | Loss: 0.335 | Acc: 88.045% (7438/8448)\n",
      "Train Epoch: 18 | Loss: 0.335 | Acc: 88.083% (7554/8576)\n",
      "Train Epoch: 18 | Loss: 0.334 | Acc: 88.143% (7672/8704)\n",
      "Train Epoch: 18 | Loss: 0.335 | Acc: 88.055% (7777/8832)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.025% (7887/8960)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.039% (8001/9088)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 88.043% (8114/9216)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.078% (8230/9344)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 87.933% (8329/9472)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.979% (8446/9600)\n",
      "Train Epoch: 18 | Loss: 0.337 | Acc: 88.024% (8563/9728)\n",
      "Train Epoch: 18 | Loss: 0.336 | Acc: 88.078% (8681/9856)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.951% (8781/9984)\n",
      "Train Epoch: 18 | Loss: 0.339 | Acc: 87.945% (8893/10112)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.959% (9007/10240)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.963% (9120/10368)\n",
      "Train Epoch: 18 | Loss: 0.338 | Acc: 87.986% (9235/10496)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 87.971% (9346/10624)\n",
      "Train Epoch: 18 | Loss: 0.341 | Acc: 87.919% (9453/10752)\n",
      "Train Epoch: 18 | Loss: 0.340 | Acc: 87.950% (9569/10880)\n",
      "Train Epoch: 18 | Loss: 0.341 | Acc: 87.918% (9678/11008)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.913% (9790/11136)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.926% (9904/11264)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.921% (10016/11392)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.856% (10121/11520)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.886% (10237/11648)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.840% (10344/11776)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.828% (10455/11904)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.849% (10570/12032)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.870% (10685/12160)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.891% (10800/12288)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.846% (10907/12416)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.851% (11020/12544)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.808% (11127/12672)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.797% (11238/12800)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.771% (11347/12928)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.760% (11458/13056)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.765% (11571/13184)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.763% (11683/13312)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.798% (11800/13440)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.802% (11913/13568)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.792% (12024/13696)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.782% (12135/13824)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.780% (12247/13952)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.805% (12363/14080)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.753% (12468/14208)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.702% (12573/14336)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.707% (12686/14464)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.740% (12803/14592)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.717% (12912/14720)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.709% (13023/14848)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.747% (13141/14976)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.758% (13255/15104)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.795% (13373/15232)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.786% (13484/15360)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.791% (13597/15488)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.846% (13718/15616)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.824% (13827/15744)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.821% (13939/15872)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.819% (14051/16000)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.816% (14163/16128)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.820% (14276/16256)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.805% (14386/16384)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.779% (14494/16512)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.788% (14608/16640)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.745% (14713/16768)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.743% (14825/16896)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.770% (14942/17024)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.780% (15056/17152)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.778% (15168/17280)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.776% (15280/17408)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.774% (15392/17536)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.760% (15502/17664)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.781% (15618/17792)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.785% (15731/17920)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.771% (15841/18048)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.803% (15959/18176)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.800% (16071/18304)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.798% (16183/18432)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.780% (16292/18560)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.778% (16404/18688)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.787% (16518/18816)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.817% (16636/18944)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.841% (16753/19072)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.828% (16863/19200)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.873% (16984/19328)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.875% (17097/19456)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.857% (17206/19584)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.886% (17324/19712)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.878% (17435/19840)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.896% (17551/19968)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.873% (17659/20096)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.856% (17768/20224)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.873% (17884/20352)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.891% (18000/20480)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.912% (18117/20608)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.900% (18227/20736)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.941% (18348/20864)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.943% (18461/20992)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.936% (18572/21120)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.942% (18686/21248)\n",
      "Train Epoch: 18 | Loss: 0.342 | Acc: 87.926% (18795/21376)\n",
      "Train Epoch: 18 | Loss: 0.343 | Acc: 87.900% (18902/21504)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.884% (19011/21632)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.858% (19118/21760)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.834% (19225/21888)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.863% (19344/22016)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.852% (19454/22144)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.850% (19566/22272)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.830% (19674/22400)\n",
      "Train Epoch: 18 | Loss: 0.344 | Acc: 87.846% (19790/22528)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.818% (19896/22656)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.798% (20004/22784)\n",
      "Train Epoch: 18 | Loss: 0.345 | Acc: 87.814% (20120/22912)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.773% (20223/23040)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.772% (20335/23168)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.770% (20447/23296)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.786% (20563/23424)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.755% (20668/23552)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.745% (20778/23680)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.752% (20892/23808)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.734% (21000/23936)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.729% (21111/24064)\n",
      "Train Epoch: 18 | Loss: 0.346 | Acc: 87.756% (21230/24192)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.730% (21336/24320)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.709% (21443/24448)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.736% (21562/24576)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.731% (21673/24704)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.738% (21787/24832)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.720% (21895/24960)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.727% (22009/25088)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.722% (22120/25216)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.749% (22239/25344)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.739% (22349/25472)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.762% (22467/25600)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.760% (22579/25728)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.736% (22685/25856)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.739% (22798/25984)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.753% (22914/26112)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.755% (23027/26240)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.747% (23137/26368)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.768% (23255/26496)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.763% (23366/26624)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.769% (23480/26752)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.779% (23595/26880)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.759% (23702/27008)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.769% (23817/27136)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.779% (23932/27264)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.770% (24042/27392)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.754% (24150/27520)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.768% (24266/27648)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.766% (24378/27776)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.780% (24494/27904)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.782% (24607/28032)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.788% (24721/28160)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.811% (24840/28288)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.789% (24946/28416)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.798% (25061/28544)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.814% (25178/28672)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.802% (25287/28800)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.811% (25402/28928)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.789% (25508/29056)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.798% (25623/29184)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.810% (25739/29312)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.812% (25852/29440)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.835% (25971/29568)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.840% (26085/29696)\n",
      "Train Epoch: 18 | Loss: 0.347 | Acc: 87.859% (26203/29824)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.851% (26313/29952)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.836% (26421/30080)\n",
      "Train Epoch: 18 | Loss: 0.348 | Acc: 87.824% (26530/30208)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.813% (26639/30336)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.828% (26756/30464)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.814% (26864/30592)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.803% (26973/30720)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.805% (27086/30848)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.807% (27199/30976)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.818% (27315/31104)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.807% (27424/31232)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.797% (27533/31360)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.789% (27643/31488)\n",
      "Train Epoch: 18 | Loss: 0.349 | Acc: 87.804% (27760/31616)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.806% (27873/31744)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.814% (27988/31872)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.806% (28098/32000)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.796% (28207/32128)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.807% (28323/32256)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.790% (28430/32384)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.795% (28544/32512)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.800% (28658/32640)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.805% (28772/32768)\n",
      "Train Epoch: 18 | Loss: 0.350 | Acc: 87.795% (28881/32896)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.763% (28983/33024)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.762% (29095/33152)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.746% (29202/33280)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.754% (29317/33408)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.759% (29431/33536)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.773% (29548/33664)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.778% (29662/33792)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.768% (29771/33920)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.779% (29887/34048)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.778% (29999/34176)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.777% (30111/34304)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.776% (30223/34432)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.784% (30338/34560)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.780% (30449/34688)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.770% (30558/34816)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.755% (30665/34944)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.722% (30766/35072)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.724% (30879/35200)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.715% (30988/35328)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.714% (31100/35456)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.711% (31211/35584)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.702% (31320/35712)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.681% (31425/35840)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.692% (31541/35968)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.691% (31653/36096)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.690% (31765/36224)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.701% (31881/36352)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.689% (31989/36480)\n",
      "Train Epoch: 18 | Loss: 0.351 | Acc: 87.691% (32102/36608)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.693% (32215/36736)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.674% (32320/36864)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.670% (32431/36992)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.656% (32538/37120)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.658% (32651/37248)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.644% (32758/37376)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.641% (32869/37504)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.641% (32981/37632)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.632% (33090/37760)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.643% (33206/37888)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.645% (33319/38016)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.634% (33427/38144)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.638% (33541/38272)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.646% (33656/38400)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.635% (33764/38528)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.632% (33875/38656)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.639% (33990/38784)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.657% (34109/38912)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.656% (34221/39040)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.663% (34336/39168)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.658% (34446/39296)\n",
      "Train Epoch: 18 | Loss: 0.352 | Acc: 87.667% (34562/39424)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.659% (34671/39552)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.641% (34776/39680)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.643% (34889/39808)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.650% (35004/39936)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.650% (35116/40064)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.659% (35232/40192)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.659% (35344/40320)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.666% (35459/40448)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.658% (35568/40576)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.657% (35680/40704)\n",
      "Train Epoch: 18 | Loss: 0.353 | Acc: 87.654% (35791/40832)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.642% (35898/40960)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.639% (36009/41088)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.629% (36117/41216)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.628% (36229/41344)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.606% (36332/41472)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.599% (36441/41600)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.596% (36552/41728)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.591% (36662/41856)\n",
      "Train Epoch: 18 | Loss: 0.354 | Acc: 87.586% (36772/41984)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.578% (36881/42112)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.585% (36996/42240)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.580% (37106/42368)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.564% (37211/42496)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.552% (37318/42624)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.544% (37427/42752)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.530% (37533/42880)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.523% (37642/43008)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.509% (37748/43136)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.518% (37864/43264)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.523% (37978/43392)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.525% (38091/43520)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.523% (38202/43648)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.516% (38311/43776)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.518% (38424/43904)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.523% (38538/44032)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.505% (38642/44160)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.486% (38746/44288)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.475% (38853/44416)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.464% (38960/44544)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.466% (39073/44672)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.469% (39186/44800)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.464% (39296/44928)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.469% (39410/45056)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.467% (39521/45184)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.462% (39631/45312)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.471% (39747/45440)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.476% (39861/45568)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.461% (39966/45696)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.461% (40078/45824)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.437% (40179/45952)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.431% (40288/46080)\n",
      "Train Epoch: 18 | Loss: 0.358 | Acc: 87.435% (40402/46208)\n",
      "Train Epoch: 18 | Loss: 0.358 | Acc: 87.444% (40518/46336)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.440% (40628/46464)\n",
      "Train Epoch: 18 | Loss: 0.358 | Acc: 87.436% (40738/46592)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.440% (40852/46720)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.442% (40965/46848)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.440% (41076/46976)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.445% (41190/47104)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.453% (41306/47232)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.447% (41415/47360)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.452% (41529/47488)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.462% (41646/47616)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.471% (41762/47744)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.479% (41878/47872)\n",
      "Train Epoch: 18 | Loss: 0.357 | Acc: 87.479% (41990/48000)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.492% (42108/48128)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.498% (42223/48256)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.496% (42334/48384)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.510% (42453/48512)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.512% (42566/48640)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.523% (42683/48768)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.533% (42800/48896)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.524% (42908/49024)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.533% (43024/49152)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.539% (43139/49280)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.530% (43247/49408)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.530% (43359/49536)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.530% (43471/49664)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.540% (43588/49792)\n",
      "Train Epoch: 18 | Loss: 0.356 | Acc: 87.534% (43697/49920)\n",
      "Train Epoch: 18 | Loss: 0.355 | Acc: 87.532% (43766/50000)\n",
      "Test Epoch: 18 | Loss: 0.384 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 18 | Loss: 0.398 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 18 | Loss: 0.359 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 18 | Loss: 0.376 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 18 | Loss: 0.376 | Acc: 87.600% (438/500)\n",
      "Test Epoch: 18 | Loss: 0.340 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 18 | Loss: 0.359 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 18 | Loss: 0.400 | Acc: 87.125% (697/800)\n",
      "Test Epoch: 18 | Loss: 0.420 | Acc: 86.333% (777/900)\n",
      "Test Epoch: 18 | Loss: 0.429 | Acc: 86.100% (861/1000)\n",
      "Test Epoch: 18 | Loss: 0.443 | Acc: 85.727% (943/1100)\n",
      "Test Epoch: 18 | Loss: 0.447 | Acc: 85.667% (1028/1200)\n",
      "Test Epoch: 18 | Loss: 0.445 | Acc: 85.615% (1113/1300)\n",
      "Test Epoch: 18 | Loss: 0.440 | Acc: 85.500% (1197/1400)\n",
      "Test Epoch: 18 | Loss: 0.439 | Acc: 85.400% (1281/1500)\n",
      "Test Epoch: 18 | Loss: 0.439 | Acc: 85.250% (1364/1600)\n",
      "Test Epoch: 18 | Loss: 0.438 | Acc: 85.471% (1453/1700)\n",
      "Test Epoch: 18 | Loss: 0.442 | Acc: 85.500% (1539/1800)\n",
      "Test Epoch: 18 | Loss: 0.441 | Acc: 85.579% (1626/1900)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 85.150% (1703/2000)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 85.048% (1786/2100)\n",
      "Test Epoch: 18 | Loss: 0.460 | Acc: 84.818% (1866/2200)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.913% (1953/2300)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 85.000% (2040/2400)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 85.000% (2125/2500)\n",
      "Test Epoch: 18 | Loss: 0.467 | Acc: 84.923% (2208/2600)\n",
      "Test Epoch: 18 | Loss: 0.462 | Acc: 85.111% (2298/2700)\n",
      "Test Epoch: 18 | Loss: 0.460 | Acc: 85.071% (2382/2800)\n",
      "Test Epoch: 18 | Loss: 0.460 | Acc: 85.172% (2470/2900)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 85.133% (2554/3000)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 85.000% (2635/3100)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 85.062% (2722/3200)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 85.152% (2810/3300)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 85.059% (2892/3400)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.857% (2970/3500)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.889% (3056/3600)\n",
      "Test Epoch: 18 | Loss: 0.462 | Acc: 84.757% (3136/3700)\n",
      "Test Epoch: 18 | Loss: 0.463 | Acc: 84.737% (3220/3800)\n",
      "Test Epoch: 18 | Loss: 0.463 | Acc: 84.872% (3310/3900)\n",
      "Test Epoch: 18 | Loss: 0.462 | Acc: 84.900% (3396/4000)\n",
      "Test Epoch: 18 | Loss: 0.467 | Acc: 84.829% (3478/4100)\n",
      "Test Epoch: 18 | Loss: 0.471 | Acc: 84.762% (3560/4200)\n",
      "Test Epoch: 18 | Loss: 0.469 | Acc: 84.791% (3646/4300)\n",
      "Test Epoch: 18 | Loss: 0.471 | Acc: 84.795% (3731/4400)\n",
      "Test Epoch: 18 | Loss: 0.468 | Acc: 84.889% (3820/4500)\n",
      "Test Epoch: 18 | Loss: 0.469 | Acc: 84.826% (3902/4600)\n",
      "Test Epoch: 18 | Loss: 0.468 | Acc: 84.830% (3987/4700)\n",
      "Test Epoch: 18 | Loss: 0.469 | Acc: 84.792% (4070/4800)\n",
      "Test Epoch: 18 | Loss: 0.468 | Acc: 84.837% (4157/4900)\n",
      "Test Epoch: 18 | Loss: 0.469 | Acc: 84.780% (4239/5000)\n",
      "Test Epoch: 18 | Loss: 0.465 | Acc: 84.941% (4332/5100)\n",
      "Test Epoch: 18 | Loss: 0.464 | Acc: 84.923% (4416/5200)\n",
      "Test Epoch: 18 | Loss: 0.465 | Acc: 84.849% (4497/5300)\n",
      "Test Epoch: 18 | Loss: 0.462 | Acc: 84.870% (4583/5400)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 84.855% (4667/5500)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 84.857% (4752/5600)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 84.895% (4839/5700)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 85.000% (4930/5800)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.915% (5010/5900)\n",
      "Test Epoch: 18 | Loss: 0.461 | Acc: 84.800% (5088/6000)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.754% (5170/6100)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 84.790% (5257/6200)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 84.810% (5343/6300)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 84.875% (5432/6400)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.831% (5514/6500)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.833% (5599/6600)\n",
      "Test Epoch: 18 | Loss: 0.453 | Acc: 84.896% (5688/6700)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 84.824% (5768/6800)\n",
      "Test Epoch: 18 | Loss: 0.453 | Acc: 84.884% (5857/6900)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 84.900% (5943/7000)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.887% (6027/7100)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 84.903% (6113/7200)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.959% (6202/7300)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.932% (6285/7400)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 84.907% (6368/7500)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.882% (6451/7600)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.909% (6538/7700)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 84.936% (6625/7800)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.975% (6713/7900)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.975% (6798/8000)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.938% (6880/8100)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 84.976% (6968/8200)\n",
      "Test Epoch: 18 | Loss: 0.453 | Acc: 84.976% (7053/8300)\n",
      "Test Epoch: 18 | Loss: 0.453 | Acc: 84.917% (7133/8400)\n",
      "Test Epoch: 18 | Loss: 0.454 | Acc: 84.929% (7219/8500)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.895% (7301/8600)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.862% (7383/8700)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 84.852% (7467/8800)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 84.831% (7550/8900)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.844% (7636/9000)\n",
      "Test Epoch: 18 | Loss: 0.459 | Acc: 84.857% (7722/9100)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.891% (7810/9200)\n",
      "Test Epoch: 18 | Loss: 0.458 | Acc: 84.892% (7895/9300)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.915% (7982/9400)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.874% (8063/9500)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 84.917% (8152/9600)\n",
      "Test Epoch: 18 | Loss: 0.455 | Acc: 84.979% (8243/9700)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.939% (8324/9800)\n",
      "Test Epoch: 18 | Loss: 0.457 | Acc: 84.970% (8412/9900)\n",
      "Test Epoch: 18 | Loss: 0.456 | Acc: 85.020% (8502/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Train Epoch: 19 | Loss: 0.326 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 19 | Loss: 0.298 | Acc: 89.453% (229/256)\n",
      "Train Epoch: 19 | Loss: 0.282 | Acc: 90.365% (347/384)\n",
      "Train Epoch: 19 | Loss: 0.286 | Acc: 90.039% (461/512)\n",
      "Train Epoch: 19 | Loss: 0.294 | Acc: 89.062% (570/640)\n",
      "Train Epoch: 19 | Loss: 0.311 | Acc: 88.932% (683/768)\n",
      "Train Epoch: 19 | Loss: 0.313 | Acc: 89.062% (798/896)\n",
      "Train Epoch: 19 | Loss: 0.302 | Acc: 89.453% (916/1024)\n",
      "Train Epoch: 19 | Loss: 0.298 | Acc: 89.497% (1031/1152)\n",
      "Train Epoch: 19 | Loss: 0.289 | Acc: 89.922% (1151/1280)\n",
      "Train Epoch: 19 | Loss: 0.294 | Acc: 89.631% (1262/1408)\n",
      "Train Epoch: 19 | Loss: 0.299 | Acc: 89.583% (1376/1536)\n",
      "Train Epoch: 19 | Loss: 0.304 | Acc: 89.784% (1494/1664)\n",
      "Train Epoch: 19 | Loss: 0.305 | Acc: 89.732% (1608/1792)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.375% (1716/1920)\n",
      "Train Epoch: 19 | Loss: 0.317 | Acc: 89.307% (1829/2048)\n",
      "Train Epoch: 19 | Loss: 0.315 | Acc: 89.430% (1946/2176)\n",
      "Train Epoch: 19 | Loss: 0.318 | Acc: 89.366% (2059/2304)\n",
      "Train Epoch: 19 | Loss: 0.315 | Acc: 89.515% (2177/2432)\n",
      "Train Epoch: 19 | Loss: 0.314 | Acc: 89.609% (2294/2560)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.583% (2408/2688)\n",
      "Train Epoch: 19 | Loss: 0.311 | Acc: 89.702% (2526/2816)\n",
      "Train Epoch: 19 | Loss: 0.314 | Acc: 89.674% (2640/2944)\n",
      "Train Epoch: 19 | Loss: 0.315 | Acc: 89.681% (2755/3072)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.594% (2867/3200)\n",
      "Train Epoch: 19 | Loss: 0.317 | Acc: 89.603% (2982/3328)\n",
      "Train Epoch: 19 | Loss: 0.315 | Acc: 89.641% (3098/3456)\n",
      "Train Epoch: 19 | Loss: 0.314 | Acc: 89.621% (3212/3584)\n",
      "Train Epoch: 19 | Loss: 0.313 | Acc: 89.682% (3329/3712)\n",
      "Train Epoch: 19 | Loss: 0.310 | Acc: 89.818% (3449/3840)\n",
      "Train Epoch: 19 | Loss: 0.314 | Acc: 89.667% (3558/3968)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.600% (3670/4096)\n",
      "Train Epoch: 19 | Loss: 0.317 | Acc: 89.583% (3784/4224)\n",
      "Train Epoch: 19 | Loss: 0.317 | Acc: 89.591% (3899/4352)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.643% (4016/4480)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.714% (4134/4608)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.738% (4250/4736)\n",
      "Train Epoch: 19 | Loss: 0.318 | Acc: 89.720% (4364/4864)\n",
      "Train Epoch: 19 | Loss: 0.319 | Acc: 89.663% (4476/4992)\n",
      "Train Epoch: 19 | Loss: 0.315 | Acc: 89.766% (4596/5120)\n",
      "Train Epoch: 19 | Loss: 0.316 | Acc: 89.653% (4705/5248)\n",
      "Train Epoch: 19 | Loss: 0.317 | Acc: 89.639% (4819/5376)\n",
      "Train Epoch: 19 | Loss: 0.322 | Acc: 89.426% (4922/5504)\n",
      "Train Epoch: 19 | Loss: 0.322 | Acc: 89.506% (5041/5632)\n",
      "Train Epoch: 19 | Loss: 0.321 | Acc: 89.549% (5158/5760)\n",
      "Train Epoch: 19 | Loss: 0.321 | Acc: 89.589% (5275/5888)\n",
      "Train Epoch: 19 | Loss: 0.320 | Acc: 89.644% (5393/6016)\n",
      "Train Epoch: 19 | Loss: 0.320 | Acc: 89.632% (5507/6144)\n",
      "Train Epoch: 19 | Loss: 0.319 | Acc: 89.684% (5625/6272)\n",
      "Train Epoch: 19 | Loss: 0.320 | Acc: 89.656% (5738/6400)\n",
      "Train Epoch: 19 | Loss: 0.324 | Acc: 89.553% (5846/6528)\n",
      "Train Epoch: 19 | Loss: 0.324 | Acc: 89.513% (5958/6656)\n",
      "Train Epoch: 19 | Loss: 0.324 | Acc: 89.460% (6069/6784)\n",
      "Train Epoch: 19 | Loss: 0.324 | Acc: 89.453% (6183/6912)\n",
      "Train Epoch: 19 | Loss: 0.324 | Acc: 89.403% (6294/7040)\n",
      "Train Epoch: 19 | Loss: 0.328 | Acc: 89.300% (6401/7168)\n",
      "Train Epoch: 19 | Loss: 0.327 | Acc: 89.282% (6514/7296)\n",
      "Train Epoch: 19 | Loss: 0.328 | Acc: 89.211% (6623/7424)\n",
      "Train Epoch: 19 | Loss: 0.328 | Acc: 89.168% (6734/7552)\n",
      "Train Epoch: 19 | Loss: 0.329 | Acc: 89.089% (6842/7680)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 89.011% (6950/7808)\n",
      "Train Epoch: 19 | Loss: 0.330 | Acc: 89.025% (7065/7936)\n",
      "Train Epoch: 19 | Loss: 0.332 | Acc: 88.976% (7175/8064)\n",
      "Train Epoch: 19 | Loss: 0.330 | Acc: 89.026% (7293/8192)\n",
      "Train Epoch: 19 | Loss: 0.330 | Acc: 89.050% (7409/8320)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 89.003% (7519/8448)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 88.981% (7631/8576)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 88.994% (7746/8704)\n",
      "Train Epoch: 19 | Loss: 0.332 | Acc: 88.904% (7852/8832)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 88.929% (7968/8960)\n",
      "Train Epoch: 19 | Loss: 0.331 | Acc: 88.908% (8080/9088)\n",
      "Train Epoch: 19 | Loss: 0.332 | Acc: 88.889% (8192/9216)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.848% (8302/9344)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.851% (8416/9472)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.823% (8527/9600)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.795% (8638/9728)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.819% (8754/9856)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.822% (8868/9984)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.786% (8978/10112)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.809% (9094/10240)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.792% (9206/10368)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.815% (9322/10496)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.846% (9439/10624)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.849% (9553/10752)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.851% (9667/10880)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.808% (9776/11008)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.793% (9888/11136)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.841% (10007/11264)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.799% (10116/11392)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.793% (10229/11520)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.745% (10337/11648)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.740% (10450/11776)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.743% (10564/11904)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.688% (10671/12032)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.717% (10788/12160)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.737% (10904/12288)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.700% (11013/12416)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.736% (11131/12544)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.699% (11240/12672)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.734% (11358/12800)\n",
      "Train Epoch: 19 | Loss: 0.333 | Acc: 88.769% (11476/12928)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.710% (11582/13056)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.714% (11696/13184)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.687% (11806/13312)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.705% (11922/13440)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.694% (12034/13568)\n",
      "Train Epoch: 19 | Loss: 0.334 | Acc: 88.690% (12147/13696)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.628% (12252/13824)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.618% (12364/13952)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.594% (12474/14080)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.584% (12586/14208)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.581% (12699/14336)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.599% (12815/14464)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.583% (12926/14592)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.580% (13039/14720)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.564% (13150/14848)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.595% (13268/14976)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.626% (13386/15104)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.629% (13500/15232)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.626% (13613/15360)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.656% (13731/15488)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.659% (13845/15616)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.662% (13959/15744)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.628% (14067/15872)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.631% (14181/16000)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.616% (14292/16128)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.595% (14402/16256)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.574% (14512/16384)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.596% (14629/16512)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.594% (14742/16640)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.597% (14856/16768)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.583% (14967/16896)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.587% (15081/17024)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.538% (15186/17152)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.507% (15294/17280)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.534% (15412/17408)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.515% (15522/17536)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.513% (15635/17664)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.495% (15745/17792)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.516% (15862/17920)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.525% (15977/18048)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.529% (16091/18176)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.522% (16203/18304)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.515% (16315/18432)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.508% (16427/18560)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.495% (16538/18688)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.483% (16649/18816)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.477% (16761/18944)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.486% (16876/19072)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.495% (16991/19200)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.509% (17107/19328)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.538% (17226/19456)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.552% (17342/19584)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.555% (17456/19712)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.569% (17572/19840)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.557% (17683/19968)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.560% (17797/20096)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.558% (17910/20224)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.566% (18025/20352)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.569% (18139/20480)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.543% (18247/20608)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.546% (18361/20736)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.540% (18473/20864)\n",
      "Train Epoch: 19 | Loss: 0.335 | Acc: 88.558% (18590/20992)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.532% (18698/21120)\n",
      "Train Epoch: 19 | Loss: 0.336 | Acc: 88.545% (18814/21248)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.520% (18922/21376)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.491% (19029/21504)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.462% (19136/21632)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.442% (19245/21760)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.450% (19360/21888)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.454% (19474/22016)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.448% (19586/22144)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.447% (19699/22272)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.464% (19816/22400)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.437% (19923/22528)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.445% (20038/22656)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.430% (20148/22784)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.443% (20264/22912)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.442% (20377/23040)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.450% (20492/23168)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.457% (20607/23296)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.456% (20720/23424)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.468% (20836/23552)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.467% (20949/23680)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.458% (21060/23808)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.448% (21171/23936)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.427% (21279/24064)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.414% (21389/24192)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.417% (21503/24320)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.408% (21614/24448)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.407% (21727/24576)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.382% (21834/24704)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.406% (21953/24832)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.417% (22069/24960)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.425% (22184/25088)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.404% (22292/25216)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.419% (22409/25344)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.419% (22522/25472)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.418% (22635/25600)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.413% (22747/25728)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.417% (22861/25856)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.385% (22966/25984)\n",
      "Train Epoch: 19 | Loss: 0.337 | Acc: 88.366% (23074/26112)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.335% (23179/26240)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.342% (23294/26368)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.338% (23406/26496)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.341% (23520/26624)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.345% (23634/26752)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.352% (23749/26880)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.381% (23870/27008)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.377% (23982/27136)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.373% (24094/27264)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.369% (24206/27392)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.368% (24319/27520)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.364% (24431/27648)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.371% (24546/27776)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.324% (24646/27904)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.335% (24762/28032)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.327% (24873/28160)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.345% (24991/28288)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.345% (25104/28416)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.337% (25215/28544)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.337% (25328/28672)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.347% (25444/28800)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.340% (25555/28928)\n",
      "Train Epoch: 19 | Loss: 0.338 | Acc: 88.323% (25663/29056)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.309% (25772/29184)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.295% (25881/29312)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.295% (25994/29440)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.298% (26108/29568)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.291% (26219/29696)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.291% (26332/29824)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.278% (26441/29952)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.278% (26554/30080)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.281% (26668/30208)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.281% (26781/30336)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.281% (26894/30464)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.278% (27006/30592)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.278% (27119/30720)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.259% (27226/30848)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.226% (27329/30976)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.227% (27442/31104)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.214% (27551/31232)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.230% (27669/31360)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.208% (27775/31488)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.221% (27892/31616)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.231% (28008/31744)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.228% (28120/31872)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.231% (28234/32000)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.213% (28341/32128)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.232% (28460/32256)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.235% (28574/32384)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.247% (28691/32512)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.257% (28807/32640)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.266% (28923/32768)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.269% (29037/32896)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.269% (29150/33024)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.257% (29259/33152)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.257% (29372/33280)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.245% (29481/33408)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.245% (29594/33536)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.260% (29712/33664)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.255% (29823/33792)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.267% (29940/33920)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.264% (30052/34048)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.258% (30163/34176)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.258% (30276/34304)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.264% (30391/34432)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.261% (30503/34560)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.252% (30613/34688)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.241% (30722/34816)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.233% (30832/34944)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.244% (30949/35072)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.241% (31061/35200)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.222% (31167/35328)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.214% (31277/35456)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.217% (31391/35584)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.211% (31502/35712)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.228% (31621/35840)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.215% (31729/35968)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.218% (31843/36096)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.229% (31960/36224)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.245% (32079/36352)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.262% (32198/36480)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.276% (32316/36608)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.268% (32426/36736)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.273% (32541/36864)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.276% (32655/36992)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.265% (32764/37120)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.257% (32874/37248)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.271% (32992/37376)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.281% (33109/37504)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.281% (33222/37632)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.294% (33340/37760)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.300% (33455/37888)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.297% (33567/38016)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.305% (33683/38144)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.310% (33798/38272)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.297% (33906/38400)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.286% (34015/38528)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.294% (34131/38656)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.294% (34244/38784)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.302% (34360/38912)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.307% (34475/39040)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.307% (34588/39168)\n",
      "Train Epoch: 19 | Loss: 0.339 | Acc: 88.286% (34693/39296)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.279% (34803/39424)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.261% (34909/39552)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.248% (35017/39680)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.266% (35137/39808)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.259% (35247/39936)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.274% (35366/40064)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.269% (35477/40192)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.276% (35593/40320)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.266% (35702/40448)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.286% (35823/40576)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.284% (35935/40704)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.289% (36050/40832)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.291% (36164/40960)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.262% (36265/41088)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.264% (36379/41216)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.264% (36492/41344)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.245% (36597/41472)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.252% (36713/41600)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.260% (36829/41728)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.253% (36939/41856)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.255% (37053/41984)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.262% (37169/42112)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.260% (37281/42240)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.267% (37397/42368)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.269% (37511/42496)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.281% (37629/42624)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.291% (37746/42752)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.288% (37858/42880)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.291% (37972/43008)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.279% (38080/43136)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.286% (38196/43264)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.284% (38308/43392)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.279% (38419/43520)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.288% (38536/43648)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.288% (38649/43776)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.288% (38762/43904)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.295% (38878/44032)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.297% (38992/44160)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.293% (39103/44288)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.284% (39212/44416)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.263% (39316/44544)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.259% (39427/44672)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.250% (39536/44800)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.243% (39646/44928)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.244% (39759/45056)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.241% (39871/45184)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.224% (39976/45312)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.206% (40081/45440)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.196% (40189/45568)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.202% (40305/45696)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.216% (40424/45824)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.220% (40539/45952)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.225% (40654/46080)\n",
      "Train Epoch: 19 | Loss: 0.342 | Acc: 88.244% (40776/46208)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.242% (40888/46336)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.249% (41004/46464)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.249% (41117/46592)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.260% (41235/46720)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.256% (41346/46848)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.266% (41464/46976)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.256% (41572/47104)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.258% (41686/47232)\n",
      "Train Epoch: 19 | Loss: 0.341 | Acc: 88.273% (41806/47360)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.290% (41927/47488)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.304% (42047/47616)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.308% (42162/47744)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.308% (42275/47872)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.310% (42389/48000)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.302% (42498/48128)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.296% (42608/48256)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.292% (42719/48384)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.304% (42838/48512)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.302% (42950/48640)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.298% (43061/48768)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.294% (43172/48896)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.296% (43286/49024)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.302% (43402/49152)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.306% (43517/49280)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.301% (43628/49408)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.305% (43743/49536)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.313% (43860/49664)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.313% (43973/49792)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.315% (44087/49920)\n",
      "Train Epoch: 19 | Loss: 0.340 | Acc: 88.322% (44161/50000)\n",
      "Test Epoch: 19 | Loss: 0.341 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 19 | Loss: 0.353 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 19 | Loss: 0.317 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 19 | Loss: 0.343 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 19 | Loss: 0.342 | Acc: 88.400% (442/500)\n",
      "Test Epoch: 19 | Loss: 0.323 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 19 | Loss: 0.338 | Acc: 89.000% (623/700)\n",
      "Test Epoch: 19 | Loss: 0.361 | Acc: 88.000% (704/800)\n",
      "Test Epoch: 19 | Loss: 0.370 | Acc: 87.556% (788/900)\n",
      "Test Epoch: 19 | Loss: 0.371 | Acc: 87.900% (879/1000)\n",
      "Test Epoch: 19 | Loss: 0.389 | Acc: 87.182% (959/1100)\n",
      "Test Epoch: 19 | Loss: 0.396 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 19 | Loss: 0.392 | Acc: 87.077% (1132/1300)\n",
      "Test Epoch: 19 | Loss: 0.386 | Acc: 87.286% (1222/1400)\n",
      "Test Epoch: 19 | Loss: 0.384 | Acc: 87.200% (1308/1500)\n",
      "Test Epoch: 19 | Loss: 0.388 | Acc: 86.812% (1389/1600)\n",
      "Test Epoch: 19 | Loss: 0.385 | Acc: 87.118% (1481/1700)\n",
      "Test Epoch: 19 | Loss: 0.392 | Acc: 87.000% (1566/1800)\n",
      "Test Epoch: 19 | Loss: 0.396 | Acc: 87.000% (1653/1900)\n",
      "Test Epoch: 19 | Loss: 0.401 | Acc: 86.950% (1739/2000)\n",
      "Test Epoch: 19 | Loss: 0.409 | Acc: 86.619% (1819/2100)\n",
      "Test Epoch: 19 | Loss: 0.411 | Acc: 86.409% (1901/2200)\n",
      "Test Epoch: 19 | Loss: 0.408 | Acc: 86.522% (1990/2300)\n",
      "Test Epoch: 19 | Loss: 0.409 | Acc: 86.542% (2077/2400)\n",
      "Test Epoch: 19 | Loss: 0.417 | Acc: 86.400% (2160/2500)\n",
      "Test Epoch: 19 | Loss: 0.426 | Acc: 86.154% (2240/2600)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 86.222% (2328/2700)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.214% (2414/2800)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.276% (2502/2900)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.167% (2585/3000)\n",
      "Test Epoch: 19 | Loss: 0.426 | Acc: 86.065% (2668/3100)\n",
      "Test Epoch: 19 | Loss: 0.427 | Acc: 86.062% (2754/3200)\n",
      "Test Epoch: 19 | Loss: 0.426 | Acc: 86.061% (2840/3300)\n",
      "Test Epoch: 19 | Loss: 0.426 | Acc: 85.971% (2923/3400)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 85.886% (3006/3500)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.028% (3097/3600)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 86.081% (3185/3700)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 86.184% (3275/3800)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.205% (3362/3900)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.175% (3447/4000)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 86.098% (3530/4100)\n",
      "Test Epoch: 19 | Loss: 0.438 | Acc: 86.024% (3613/4200)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.163% (3705/4300)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 86.273% (3796/4400)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 86.244% (3881/4500)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 86.152% (3963/4600)\n",
      "Test Epoch: 19 | Loss: 0.430 | Acc: 86.128% (4048/4700)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 86.042% (4130/4800)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.082% (4218/4900)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.980% (4299/5000)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.059% (4389/5100)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 86.038% (4474/5200)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.943% (4555/5300)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 86.037% (4646/5400)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 86.036% (4732/5500)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 86.054% (4819/5600)\n",
      "Test Epoch: 19 | Loss: 0.430 | Acc: 86.053% (4905/5700)\n",
      "Test Epoch: 19 | Loss: 0.426 | Acc: 86.103% (4994/5800)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.153% (5083/5900)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.100% (5166/6000)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.180% (5257/6100)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.258% (5348/6200)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 86.286% (5436/6300)\n",
      "Test Epoch: 19 | Loss: 0.419 | Acc: 86.359% (5527/6400)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 86.231% (5605/6500)\n",
      "Test Epoch: 19 | Loss: 0.421 | Acc: 86.258% (5693/6600)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.328% (5784/6700)\n",
      "Test Epoch: 19 | Loss: 0.419 | Acc: 86.250% (5865/6800)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.174% (5946/6900)\n",
      "Test Epoch: 19 | Loss: 0.421 | Acc: 86.171% (6032/7000)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.169% (6118/7100)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.167% (6204/7200)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.192% (6292/7300)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.189% (6378/7400)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.147% (6461/7500)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.105% (6544/7600)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.078% (6628/7700)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.090% (6715/7800)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.051% (6798/7900)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.075% (6886/8000)\n",
      "Test Epoch: 19 | Loss: 0.421 | Acc: 86.086% (6973/8100)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.110% (7061/8200)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.133% (7149/8300)\n",
      "Test Epoch: 19 | Loss: 0.420 | Acc: 86.083% (7231/8400)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 86.012% (7311/8500)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 85.977% (7394/8600)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 85.977% (7480/8700)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 85.977% (7566/8800)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.022% (7656/8900)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.022% (7742/9000)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.044% (7830/9100)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.087% (7920/9200)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.086% (8006/9300)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.074% (8091/9400)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.063% (8176/9500)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 86.031% (8259/9600)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.072% (8349/9700)\n",
      "Test Epoch: 19 | Loss: 0.424 | Acc: 86.051% (8433/9800)\n",
      "Test Epoch: 19 | Loss: 0.423 | Acc: 86.081% (8522/9900)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 86.100% (8610/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 87.500% (112/128)\n",
      "Train Epoch: 20 | Loss: 0.394 | Acc: 86.328% (221/256)\n",
      "Train Epoch: 20 | Loss: 0.385 | Acc: 85.677% (329/384)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 86.719% (444/512)\n",
      "Train Epoch: 20 | Loss: 0.355 | Acc: 87.031% (557/640)\n",
      "Train Epoch: 20 | Loss: 0.353 | Acc: 86.849% (667/768)\n",
      "Train Epoch: 20 | Loss: 0.346 | Acc: 87.277% (782/896)\n",
      "Train Epoch: 20 | Loss: 0.340 | Acc: 87.598% (897/1024)\n",
      "Train Epoch: 20 | Loss: 0.330 | Acc: 87.934% (1013/1152)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.438% (1132/1280)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.778% (1250/1408)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.062% (1368/1536)\n",
      "Train Epoch: 20 | Loss: 0.306 | Acc: 89.183% (1484/1664)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.118% (1597/1792)\n",
      "Train Epoch: 20 | Loss: 0.307 | Acc: 89.167% (1712/1920)\n",
      "Train Epoch: 20 | Loss: 0.307 | Acc: 89.307% (1829/2048)\n",
      "Train Epoch: 20 | Loss: 0.306 | Acc: 89.292% (1943/2176)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.280% (2057/2304)\n",
      "Train Epoch: 20 | Loss: 0.311 | Acc: 89.227% (2170/2432)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.219% (2284/2560)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.286% (2400/2688)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.418% (2518/2816)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.198% (2626/2944)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.193% (2740/3072)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 89.125% (2852/3200)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.243% (2970/3328)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.178% (3082/3456)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.202% (3197/3584)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 89.089% (3307/3712)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.297% (3429/3840)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.340% (3545/3968)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.331% (3659/4096)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.323% (3773/4224)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.315% (3887/4352)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.286% (4000/4480)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.345% (4117/4608)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.295% (4229/4736)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.268% (4342/4864)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.283% (4457/4992)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 89.160% (4565/5120)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.196% (4681/5248)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.249% (4798/5376)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.281% (4914/5504)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.382% (5034/5632)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.392% (5149/5760)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.317% (5259/5888)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.262% (5370/6016)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.339% (5489/6144)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.349% (5604/6272)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.391% (5721/6400)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.323% (5831/6528)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.303% (5944/6656)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.284% (6057/6784)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.265% (6170/6912)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.290% (6286/7040)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.328% (6403/7168)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.350% (6519/7296)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.372% (6635/7424)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.447% (6755/7552)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.453% (6870/7680)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.447% (6984/7808)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.466% (7100/7936)\n",
      "Train Epoch: 20 | Loss: 0.311 | Acc: 89.509% (7218/8064)\n",
      "Train Epoch: 20 | Loss: 0.311 | Acc: 89.514% (7333/8192)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.495% (7446/8320)\n",
      "Train Epoch: 20 | Loss: 0.311 | Acc: 89.524% (7563/8448)\n",
      "Train Epoch: 20 | Loss: 0.311 | Acc: 89.517% (7677/8576)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.545% (7794/8704)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.538% (7908/8832)\n",
      "Train Epoch: 20 | Loss: 0.310 | Acc: 89.520% (8021/8960)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.415% (8126/9088)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.366% (8236/9216)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.362% (8350/9344)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.358% (8464/9472)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.365% (8579/9600)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.381% (8695/9728)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.326% (8804/9856)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.363% (8922/9984)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.379% (9038/10112)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.316% (9146/10240)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.275% (9256/10368)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.291% (9372/10496)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.307% (9488/10624)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.304% (9602/10752)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.292% (9715/10880)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.326% (9833/11008)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.305% (9945/11136)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.355% (10065/11264)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.326% (10176/11392)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.323% (10290/11520)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.294% (10401/11648)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.283% (10514/11776)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.289% (10629/11904)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.279% (10742/12032)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.326% (10862/12160)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.307% (10974/12288)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.304% (11088/12416)\n",
      "Train Epoch: 20 | Loss: 0.312 | Acc: 89.318% (11204/12544)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.283% (11314/12672)\n",
      "Train Epoch: 20 | Loss: 0.313 | Acc: 89.242% (11423/12800)\n",
      "Train Epoch: 20 | Loss: 0.314 | Acc: 89.202% (11532/12928)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.162% (11641/13056)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.154% (11754/13184)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.130% (11865/13312)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.152% (11982/13440)\n",
      "Train Epoch: 20 | Loss: 0.315 | Acc: 89.151% (12096/13568)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.121% (12206/13696)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.077% (12314/13824)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.077% (12428/13952)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.062% (12540/14080)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.070% (12655/14208)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.111% (12775/14336)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.111% (12889/14464)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.104% (13002/14592)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.103% (13116/14720)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.083% (13227/14848)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.089% (13342/14976)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.102% (13458/15104)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.095% (13571/15232)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.069% (13681/15360)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.037% (13790/15488)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.050% (13906/15616)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.043% (14019/15744)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.006% (14127/15872)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.019% (14243/16000)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.007% (14355/16128)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.001% (14468/16256)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.038% (14588/16384)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.044% (14703/16512)\n",
      "Train Epoch: 20 | Loss: 0.316 | Acc: 89.032% (14815/16640)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.985% (14921/16768)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.986% (15035/16896)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.986% (15149/17024)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.993% (15264/17152)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.976% (15375/17280)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.994% (15492/17408)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.005% (15608/17536)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.972% (15716/17664)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.967% (15829/17792)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.984% (15946/17920)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.952% (16054/18048)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.941% (16166/18176)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.959% (16283/18304)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.992% (16403/18432)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.966% (16512/18560)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 88.988% (16630/18688)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.972% (16741/18816)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.983% (16857/18944)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.989% (16972/19072)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.990% (17086/19200)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.959% (17194/19328)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.955% (17307/19456)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.950% (17420/19584)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.936% (17531/19712)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.962% (17650/19840)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.942% (17760/19968)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.958% (17877/20096)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.988% (17997/20224)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.974% (18108/20352)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.004% (18228/20480)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.995% (18340/20608)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.014% (18458/20736)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.010% (18571/20864)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.029% (18689/20992)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.025% (18802/21120)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.011% (18913/21248)\n",
      "Train Epoch: 20 | Loss: 0.317 | Acc: 89.011% (19027/21376)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.969% (19132/21504)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.961% (19244/21632)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.943% (19354/21760)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.935% (19466/21888)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.917% (19576/22016)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.909% (19688/22144)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.905% (19801/22272)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.942% (19923/22400)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.934% (20035/22528)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.948% (20152/22656)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.935% (20263/22784)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.940% (20378/22912)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.958% (20496/23040)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.959% (20610/23168)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.959% (20724/23296)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.956% (20837/23424)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.948% (20949/23552)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.953% (21064/23680)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.936% (21174/23808)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.933% (21287/23936)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.925% (21399/24064)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.930% (21514/24192)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.931% (21628/24320)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.952% (21747/24448)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.949% (21860/24576)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.941% (21972/24704)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.934% (22084/24832)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.938% (22199/24960)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.927% (22310/25088)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.944% (22428/25216)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.920% (22536/25344)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.933% (22653/25472)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.938% (22768/25600)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.954% (22886/25728)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.954% (23000/25856)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.966% (23117/25984)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.959% (23229/26112)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.952% (23341/26240)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.926% (23448/26368)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.927% (23562/26496)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.946% (23681/26624)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.977% (23803/26752)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.977% (23917/26880)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.981% (24032/27008)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.992% (24149/27136)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 89.007% (24267/27264)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.982% (24374/27392)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.975% (24486/27520)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.976% (24600/27648)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.990% (24718/27776)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.980% (24829/27904)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.973% (24941/28032)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.952% (25049/28160)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.949% (25162/28288)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.964% (25280/28416)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.947% (25389/28544)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.951% (25504/28672)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.951% (25618/28800)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.955% (25733/28928)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.970% (25851/29056)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.973% (25966/29184)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.960% (26076/29312)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.954% (26188/29440)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.958% (26303/29568)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.945% (26413/29696)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.935% (26524/29824)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.922% (26634/29952)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.926% (26749/30080)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.947% (26869/30208)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.931% (26978/30336)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.915% (27087/30464)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.912% (27200/30592)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.929% (27319/30720)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.930% (27433/30848)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.920% (27544/30976)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.921% (27658/31104)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.918% (27771/31232)\n",
      "Train Epoch: 20 | Loss: 0.318 | Acc: 88.913% (27883/31360)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.904% (27994/31488)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.901% (28107/31616)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.908% (28223/31744)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.893% (28332/31872)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.897% (28447/32000)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.898% (28561/32128)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.895% (28674/32256)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.896% (28788/32384)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.903% (28904/32512)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.888% (29013/32640)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.879% (29124/32768)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.877% (29237/32896)\n",
      "Train Epoch: 20 | Loss: 0.319 | Acc: 88.881% (29352/33024)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.878% (29465/33152)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.882% (29580/33280)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.874% (29691/33408)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.869% (29803/33536)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.866% (29916/33664)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.885% (30036/33792)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.880% (30148/33920)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.875% (30260/34048)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.887% (30378/34176)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.882% (30490/34304)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.862% (30597/34432)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.854% (30708/34560)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.841% (30817/34688)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.844% (30932/34816)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.828% (31040/34944)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.829% (31154/35072)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.835% (31270/35200)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.833% (31383/35328)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.837% (31498/35456)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.857% (31619/35584)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.850% (31730/35712)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.850% (31844/35840)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.846% (31956/35968)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.835% (32066/36096)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.847% (32184/36224)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.851% (32299/36352)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.843% (32410/36480)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.849% (32526/36608)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.847% (32639/36736)\n",
      "Train Epoch: 20 | Loss: 0.320 | Acc: 88.851% (32754/36864)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.841% (32864/36992)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.847% (32980/37120)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.832% (33088/37248)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.843% (33206/37376)\n",
      "Train Epoch: 20 | Loss: 0.321 | Acc: 88.828% (33314/37504)\n",
      "Train Epoch: 20 | Loss: 0.322 | Acc: 88.810% (33421/37632)\n",
      "Train Epoch: 20 | Loss: 0.322 | Acc: 88.806% (33533/37760)\n",
      "Train Epoch: 20 | Loss: 0.322 | Acc: 88.793% (33642/37888)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.776% (33749/38016)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.766% (33859/38144)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.759% (33970/38272)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.771% (34088/38400)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.772% (34202/38528)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.778% (34318/38656)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.776% (34431/38784)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.775% (34544/38912)\n",
      "Train Epoch: 20 | Loss: 0.322 | Acc: 88.783% (34661/39040)\n",
      "Train Epoch: 20 | Loss: 0.322 | Acc: 88.779% (34773/39168)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.770% (34883/39296)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.778% (35000/39424)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.777% (35113/39552)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.775% (35226/39680)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.779% (35341/39808)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.772% (35452/39936)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.765% (35563/40064)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.759% (35674/40192)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.755% (35786/40320)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.736% (35892/40448)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.742% (36008/40576)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.731% (36117/40704)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.725% (36228/40832)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.721% (36340/40960)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.719% (36453/41088)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.720% (36567/41216)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.724% (36682/41344)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.730% (36798/41472)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.736% (36914/41600)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.739% (37029/41728)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.742% (37144/41856)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.746% (37259/41984)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.730% (37366/42112)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.714% (37473/42240)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.716% (37587/42368)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.719% (37702/42496)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.732% (37821/42624)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.742% (37939/42752)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.748% (38055/42880)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.760% (38174/43008)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.766% (38290/43136)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.769% (38405/43264)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.761% (38515/43392)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.766% (38631/43520)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.774% (38748/43648)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.777% (38863/43776)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.782% (38979/43904)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.788% (39095/44032)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.786% (39208/44160)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.789% (39323/44288)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.783% (39434/44416)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.775% (39544/44544)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.778% (39659/44672)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.781% (39774/44800)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.784% (39889/44928)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.776% (39999/45056)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.768% (40109/45184)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.776% (40226/45312)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.779% (40341/45440)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.771% (40451/45568)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.778% (40568/45696)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.764% (40675/45824)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.767% (40790/45952)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.757% (40899/46080)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.751% (41010/46208)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.737% (41117/46336)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.729% (41227/46464)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.717% (41335/46592)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.735% (41457/46720)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.740% (41573/46848)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.747% (41690/46976)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.744% (41802/47104)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.760% (41923/47232)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.765% (42039/47360)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.757% (42149/47488)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.758% (42263/47616)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.765% (42380/47744)\n",
      "Train Epoch: 20 | Loss: 0.323 | Acc: 88.766% (42494/47872)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.758% (42604/48000)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.747% (42712/48128)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.745% (42825/48256)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.748% (42940/48384)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.749% (43054/48512)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.746% (43166/48640)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.730% (43272/48768)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.719% (43380/48896)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.712% (43490/49024)\n",
      "Train Epoch: 20 | Loss: 0.325 | Acc: 88.700% (43598/49152)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.711% (43717/49280)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.712% (43831/49408)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.721% (43949/49536)\n",
      "Train Epoch: 20 | Loss: 0.324 | Acc: 88.718% (44061/49664)\n",
      "Train Epoch: 20 | Loss: 0.325 | Acc: 88.717% (44174/49792)\n",
      "Train Epoch: 20 | Loss: 0.325 | Acc: 88.722% (44290/49920)\n",
      "Train Epoch: 20 | Loss: 0.325 | Acc: 88.718% (44359/50000)\n",
      "Test Epoch: 20 | Loss: 0.366 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 20 | Loss: 0.413 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 20 | Loss: 0.378 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 20 | Loss: 0.383 | Acc: 86.500% (346/400)\n",
      "Test Epoch: 20 | Loss: 0.387 | Acc: 86.600% (433/500)\n",
      "Test Epoch: 20 | Loss: 0.362 | Acc: 87.500% (525/600)\n",
      "Test Epoch: 20 | Loss: 0.366 | Acc: 87.143% (610/700)\n",
      "Test Epoch: 20 | Loss: 0.391 | Acc: 86.250% (690/800)\n",
      "Test Epoch: 20 | Loss: 0.398 | Acc: 85.667% (771/900)\n",
      "Test Epoch: 20 | Loss: 0.417 | Acc: 85.500% (855/1000)\n",
      "Test Epoch: 20 | Loss: 0.433 | Acc: 84.818% (933/1100)\n",
      "Test Epoch: 20 | Loss: 0.445 | Acc: 84.583% (1015/1200)\n",
      "Test Epoch: 20 | Loss: 0.445 | Acc: 84.692% (1101/1300)\n",
      "Test Epoch: 20 | Loss: 0.445 | Acc: 84.643% (1185/1400)\n",
      "Test Epoch: 20 | Loss: 0.444 | Acc: 84.533% (1268/1500)\n",
      "Test Epoch: 20 | Loss: 0.449 | Acc: 84.312% (1349/1600)\n",
      "Test Epoch: 20 | Loss: 0.441 | Acc: 84.824% (1442/1700)\n",
      "Test Epoch: 20 | Loss: 0.451 | Acc: 84.556% (1522/1800)\n",
      "Test Epoch: 20 | Loss: 0.457 | Acc: 84.474% (1605/1900)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.600% (1692/2000)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.571% (1776/2100)\n",
      "Test Epoch: 20 | Loss: 0.468 | Acc: 84.500% (1859/2200)\n",
      "Test Epoch: 20 | Loss: 0.474 | Acc: 84.391% (1941/2300)\n",
      "Test Epoch: 20 | Loss: 0.475 | Acc: 84.292% (2023/2400)\n",
      "Test Epoch: 20 | Loss: 0.483 | Acc: 84.280% (2107/2500)\n",
      "Test Epoch: 20 | Loss: 0.494 | Acc: 84.192% (2189/2600)\n",
      "Test Epoch: 20 | Loss: 0.493 | Acc: 84.296% (2276/2700)\n",
      "Test Epoch: 20 | Loss: 0.490 | Acc: 84.286% (2360/2800)\n",
      "Test Epoch: 20 | Loss: 0.491 | Acc: 84.241% (2443/2900)\n",
      "Test Epoch: 20 | Loss: 0.487 | Acc: 84.367% (2531/3000)\n",
      "Test Epoch: 20 | Loss: 0.491 | Acc: 84.290% (2613/3100)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.375% (2700/3200)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.333% (2783/3300)\n",
      "Test Epoch: 20 | Loss: 0.490 | Acc: 84.206% (2863/3400)\n",
      "Test Epoch: 20 | Loss: 0.497 | Acc: 84.114% (2944/3500)\n",
      "Test Epoch: 20 | Loss: 0.498 | Acc: 84.111% (3028/3600)\n",
      "Test Epoch: 20 | Loss: 0.499 | Acc: 84.108% (3112/3700)\n",
      "Test Epoch: 20 | Loss: 0.499 | Acc: 84.105% (3196/3800)\n",
      "Test Epoch: 20 | Loss: 0.499 | Acc: 84.128% (3281/3900)\n",
      "Test Epoch: 20 | Loss: 0.500 | Acc: 84.100% (3364/4000)\n",
      "Test Epoch: 20 | Loss: 0.499 | Acc: 84.122% (3449/4100)\n",
      "Test Epoch: 20 | Loss: 0.500 | Acc: 84.048% (3530/4200)\n",
      "Test Epoch: 20 | Loss: 0.495 | Acc: 84.163% (3619/4300)\n",
      "Test Epoch: 20 | Loss: 0.496 | Acc: 84.182% (3704/4400)\n",
      "Test Epoch: 20 | Loss: 0.494 | Acc: 84.244% (3791/4500)\n",
      "Test Epoch: 20 | Loss: 0.493 | Acc: 84.239% (3875/4600)\n",
      "Test Epoch: 20 | Loss: 0.492 | Acc: 84.191% (3957/4700)\n",
      "Test Epoch: 20 | Loss: 0.492 | Acc: 84.188% (4041/4800)\n",
      "Test Epoch: 20 | Loss: 0.491 | Acc: 84.224% (4127/4900)\n",
      "Test Epoch: 20 | Loss: 0.494 | Acc: 84.140% (4207/5000)\n",
      "Test Epoch: 20 | Loss: 0.492 | Acc: 84.255% (4297/5100)\n",
      "Test Epoch: 20 | Loss: 0.494 | Acc: 84.212% (4379/5200)\n",
      "Test Epoch: 20 | Loss: 0.493 | Acc: 84.245% (4465/5300)\n",
      "Test Epoch: 20 | Loss: 0.491 | Acc: 84.296% (4552/5400)\n",
      "Test Epoch: 20 | Loss: 0.492 | Acc: 84.218% (4632/5500)\n",
      "Test Epoch: 20 | Loss: 0.490 | Acc: 84.268% (4719/5600)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.263% (4803/5700)\n",
      "Test Epoch: 20 | Loss: 0.486 | Acc: 84.362% (4893/5800)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.373% (4978/5900)\n",
      "Test Epoch: 20 | Loss: 0.487 | Acc: 84.350% (5061/6000)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.344% (5145/6100)\n",
      "Test Epoch: 20 | Loss: 0.486 | Acc: 84.371% (5231/6200)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.397% (5317/6300)\n",
      "Test Epoch: 20 | Loss: 0.483 | Acc: 84.406% (5402/6400)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.354% (5483/6500)\n",
      "Test Epoch: 20 | Loss: 0.483 | Acc: 84.409% (5571/6600)\n",
      "Test Epoch: 20 | Loss: 0.481 | Acc: 84.433% (5657/6700)\n",
      "Test Epoch: 20 | Loss: 0.480 | Acc: 84.441% (5742/6800)\n",
      "Test Epoch: 20 | Loss: 0.480 | Acc: 84.435% (5826/6900)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.386% (5907/7000)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.338% (5988/7100)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.361% (6074/7200)\n",
      "Test Epoch: 20 | Loss: 0.483 | Acc: 84.438% (6164/7300)\n",
      "Test Epoch: 20 | Loss: 0.481 | Acc: 84.500% (6253/7400)\n",
      "Test Epoch: 20 | Loss: 0.482 | Acc: 84.453% (6334/7500)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.434% (6417/7600)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.416% (6500/7700)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.462% (6588/7800)\n",
      "Test Epoch: 20 | Loss: 0.486 | Acc: 84.481% (6674/7900)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.500% (6760/8000)\n",
      "Test Epoch: 20 | Loss: 0.483 | Acc: 84.543% (6848/8100)\n",
      "Test Epoch: 20 | Loss: 0.482 | Acc: 84.573% (6935/8200)\n",
      "Test Epoch: 20 | Loss: 0.481 | Acc: 84.578% (7020/8300)\n",
      "Test Epoch: 20 | Loss: 0.482 | Acc: 84.571% (7104/8400)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.506% (7183/8500)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.453% (7263/8600)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.402% (7343/8700)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.386% (7426/8800)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.416% (7513/8900)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.456% (7601/9000)\n",
      "Test Epoch: 20 | Loss: 0.489 | Acc: 84.440% (7684/9100)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.467% (7771/9200)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.484% (7857/9300)\n",
      "Test Epoch: 20 | Loss: 0.488 | Acc: 84.457% (7939/9400)\n",
      "Test Epoch: 20 | Loss: 0.487 | Acc: 84.421% (8020/9500)\n",
      "Test Epoch: 20 | Loss: 0.486 | Acc: 84.438% (8106/9600)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.515% (8198/9700)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 84.459% (8277/9800)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.455% (8361/9900)\n",
      "Test Epoch: 20 | Loss: 0.484 | Acc: 84.440% (8444/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Epoch: 21 | Loss: 0.201 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 21 | Loss: 0.209 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 21 | Loss: 0.237 | Acc: 93.229% (358/384)\n",
      "Train Epoch: 21 | Loss: 0.242 | Acc: 92.969% (476/512)\n",
      "Train Epoch: 21 | Loss: 0.254 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 21 | Loss: 0.267 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 21 | Loss: 0.257 | Acc: 91.295% (818/896)\n",
      "Train Epoch: 21 | Loss: 0.270 | Acc: 90.723% (929/1024)\n",
      "Train Epoch: 21 | Loss: 0.269 | Acc: 90.712% (1045/1152)\n",
      "Train Epoch: 21 | Loss: 0.265 | Acc: 90.703% (1161/1280)\n",
      "Train Epoch: 21 | Loss: 0.270 | Acc: 90.554% (1275/1408)\n",
      "Train Epoch: 21 | Loss: 0.275 | Acc: 90.495% (1390/1536)\n",
      "Train Epoch: 21 | Loss: 0.269 | Acc: 90.685% (1509/1664)\n",
      "Train Epoch: 21 | Loss: 0.267 | Acc: 90.737% (1626/1792)\n",
      "Train Epoch: 21 | Loss: 0.271 | Acc: 90.417% (1736/1920)\n",
      "Train Epoch: 21 | Loss: 0.275 | Acc: 90.234% (1848/2048)\n",
      "Train Epoch: 21 | Loss: 0.275 | Acc: 90.165% (1962/2176)\n",
      "Train Epoch: 21 | Loss: 0.279 | Acc: 90.061% (2075/2304)\n",
      "Train Epoch: 21 | Loss: 0.281 | Acc: 89.967% (2188/2432)\n",
      "Train Epoch: 21 | Loss: 0.279 | Acc: 90.039% (2305/2560)\n",
      "Train Epoch: 21 | Loss: 0.282 | Acc: 89.993% (2419/2688)\n",
      "Train Epoch: 21 | Loss: 0.282 | Acc: 90.057% (2536/2816)\n",
      "Train Epoch: 21 | Loss: 0.287 | Acc: 89.946% (2648/2944)\n",
      "Train Epoch: 21 | Loss: 0.288 | Acc: 90.007% (2765/3072)\n",
      "Train Epoch: 21 | Loss: 0.289 | Acc: 89.906% (2877/3200)\n",
      "Train Epoch: 21 | Loss: 0.283 | Acc: 90.084% (2998/3328)\n",
      "Train Epoch: 21 | Loss: 0.287 | Acc: 90.046% (3112/3456)\n",
      "Train Epoch: 21 | Loss: 0.286 | Acc: 90.095% (3229/3584)\n",
      "Train Epoch: 21 | Loss: 0.292 | Acc: 89.898% (3337/3712)\n",
      "Train Epoch: 21 | Loss: 0.291 | Acc: 89.870% (3451/3840)\n",
      "Train Epoch: 21 | Loss: 0.290 | Acc: 89.844% (3565/3968)\n",
      "Train Epoch: 21 | Loss: 0.288 | Acc: 89.893% (3682/4096)\n",
      "Train Epoch: 21 | Loss: 0.290 | Acc: 89.867% (3796/4224)\n",
      "Train Epoch: 21 | Loss: 0.288 | Acc: 89.913% (3913/4352)\n",
      "Train Epoch: 21 | Loss: 0.290 | Acc: 89.955% (4030/4480)\n",
      "Train Epoch: 21 | Loss: 0.289 | Acc: 89.952% (4145/4608)\n",
      "Train Epoch: 21 | Loss: 0.288 | Acc: 89.949% (4260/4736)\n",
      "Train Epoch: 21 | Loss: 0.290 | Acc: 89.905% (4373/4864)\n",
      "Train Epoch: 21 | Loss: 0.290 | Acc: 89.984% (4492/4992)\n",
      "Train Epoch: 21 | Loss: 0.291 | Acc: 89.902% (4603/5120)\n",
      "Train Epoch: 21 | Loss: 0.291 | Acc: 89.844% (4715/5248)\n",
      "Train Epoch: 21 | Loss: 0.293 | Acc: 89.695% (4822/5376)\n",
      "Train Epoch: 21 | Loss: 0.294 | Acc: 89.626% (4933/5504)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.542% (5043/5632)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.514% (5156/5760)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.538% (5272/5888)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.478% (5383/6016)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.535% (5501/6144)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.509% (5614/6272)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.531% (5730/6400)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.614% (5850/6528)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.618% (5965/6656)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.549% (6075/6784)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.540% (6189/6912)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.588% (6307/7040)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.579% (6421/7168)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.570% (6535/7296)\n",
      "Train Epoch: 21 | Loss: 0.296 | Acc: 89.601% (6652/7424)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.579% (6765/7552)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.518% (6875/7680)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.524% (6990/7808)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.504% (7103/7936)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.484% (7216/8064)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.514% (7333/8192)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.519% (7448/8320)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.441% (7556/8448)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.471% (7673/8576)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.534% (7793/8704)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.538% (7908/8832)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.531% (8022/8960)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.492% (8133/9088)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.518% (8250/9216)\n",
      "Train Epoch: 21 | Loss: 0.297 | Acc: 89.512% (8364/9344)\n",
      "Train Epoch: 21 | Loss: 0.298 | Acc: 89.495% (8477/9472)\n",
      "Train Epoch: 21 | Loss: 0.300 | Acc: 89.469% (8589/9600)\n",
      "Train Epoch: 21 | Loss: 0.301 | Acc: 89.412% (8698/9728)\n",
      "Train Epoch: 21 | Loss: 0.301 | Acc: 89.428% (8814/9856)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.373% (8923/9984)\n",
      "Train Epoch: 21 | Loss: 0.301 | Acc: 89.409% (9041/10112)\n",
      "Train Epoch: 21 | Loss: 0.301 | Acc: 89.453% (9160/10240)\n",
      "Train Epoch: 21 | Loss: 0.300 | Acc: 89.497% (9279/10368)\n",
      "Train Epoch: 21 | Loss: 0.299 | Acc: 89.548% (9399/10496)\n",
      "Train Epoch: 21 | Loss: 0.299 | Acc: 89.533% (9512/10624)\n",
      "Train Epoch: 21 | Loss: 0.300 | Acc: 89.546% (9628/10752)\n",
      "Train Epoch: 21 | Loss: 0.300 | Acc: 89.513% (9739/10880)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.471% (9849/11008)\n",
      "Train Epoch: 21 | Loss: 0.301 | Acc: 89.476% (9964/11136)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.471% (10078/11264)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.466% (10192/11392)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.488% (10309/11520)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.457% (10420/11648)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.479% (10537/11776)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.499% (10654/11904)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.503% (10769/12032)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.556% (10890/12160)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.518% (11000/12288)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.554% (11119/12416)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.533% (11231/12544)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.489% (11340/12672)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.477% (11453/12800)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.472% (11567/12928)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.476% (11682/13056)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.427% (11790/13184)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.363% (11896/13312)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.368% (12011/13440)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.402% (12130/13568)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.428% (12248/13696)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.446% (12365/13824)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.471% (12483/13952)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.474% (12598/14080)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.450% (12709/14208)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.481% (12828/14336)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.491% (12944/14464)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.481% (13057/14592)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.504% (13175/14720)\n",
      "Train Epoch: 21 | Loss: 0.302 | Acc: 89.514% (13291/14848)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.456% (13397/14976)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.486% (13516/15104)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.489% (13631/15232)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.460% (13741/15360)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.437% (13852/15488)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.434% (13966/15616)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.425% (14079/15744)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.434% (14195/15872)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.444% (14311/16000)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.453% (14427/16128)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.444% (14540/16256)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.447% (14655/16384)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.456% (14771/16512)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.399% (14876/16640)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.391% (14989/16768)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.364% (15099/16896)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.368% (15214/17024)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.389% (15332/17152)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.387% (15446/17280)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.373% (15558/17408)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.376% (15673/17536)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.363% (15785/17664)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.355% (15898/17792)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.347% (16011/17920)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.345% (16125/18048)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.343% (16239/18176)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.358% (16356/18304)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.377% (16474/18432)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.397% (16592/18560)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.405% (16708/18688)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.371% (16816/18816)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.390% (16934/18944)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.398% (17050/19072)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.401% (17165/19200)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.435% (17286/19328)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.443% (17402/19456)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.451% (17518/19584)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.443% (17631/19712)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.441% (17745/19840)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.413% (17854/19968)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.421% (17970/20096)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.423% (18085/20224)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.426% (18200/20352)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.414% (18312/20480)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.431% (18430/20608)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.429% (18544/20736)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.446% (18662/20864)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.463% (18780/20992)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.479% (18898/21120)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.448% (19006/21248)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.437% (19118/21376)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.453% (19236/21504)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.460% (19352/21632)\n",
      "Train Epoch: 21 | Loss: 0.303 | Acc: 89.462% (19467/21760)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.442% (19577/21888)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.444% (19692/22016)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.428% (19803/22144)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.413% (19914/22272)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.402% (20026/22400)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.391% (20138/22528)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.402% (20255/22656)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.374% (20363/22784)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.364% (20475/22912)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.345% (20585/23040)\n",
      "Train Epoch: 21 | Loss: 0.306 | Acc: 89.360% (20703/23168)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.363% (20818/23296)\n",
      "Train Epoch: 21 | Loss: 0.306 | Acc: 89.361% (20932/23424)\n",
      "Train Epoch: 21 | Loss: 0.306 | Acc: 89.355% (21045/23552)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.392% (21168/23680)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.424% (21290/23808)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.405% (21400/23936)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.399% (21513/24064)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.410% (21630/24192)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.441% (21752/24320)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.447% (21868/24448)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.445% (21982/24576)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.459% (22100/24704)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.457% (22214/24832)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.459% (22329/24960)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.429% (22436/25088)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.455% (22557/25216)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.465% (22674/25344)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.471% (22790/25472)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.453% (22900/25600)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.455% (23015/25728)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.442% (23126/25856)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.436% (23239/25984)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.430% (23352/26112)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.436% (23468/26240)\n",
      "Train Epoch: 21 | Loss: 0.304 | Acc: 89.434% (23582/26368)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.421% (23693/26496)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.427% (23809/26624)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.429% (23924/26752)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.416% (24035/26880)\n",
      "Train Epoch: 21 | Loss: 0.305 | Acc: 89.414% (24149/27008)\n",
      "Train Epoch: 21 | Loss: 0.306 | Acc: 89.376% (24253/27136)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.356% (24362/27264)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.340% (24472/27392)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.328% (24583/27520)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.348% (24703/27648)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.347% (24817/27776)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.342% (24930/27904)\n",
      "Train Epoch: 21 | Loss: 0.306 | Acc: 89.355% (25048/28032)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.343% (25159/28160)\n",
      "Train Epoch: 21 | Loss: 0.307 | Acc: 89.331% (25270/28288)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.326% (25383/28416)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.336% (25500/28544)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.331% (25613/28672)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.299% (25718/28800)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.325% (25840/28928)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.314% (25951/29056)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.330% (26070/29184)\n",
      "Train Epoch: 21 | Loss: 0.308 | Acc: 89.339% (26187/29312)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.334% (26300/29440)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.330% (26413/29568)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.315% (26523/29696)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.311% (26636/29824)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.320% (26753/29952)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.318% (26867/30080)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.304% (26977/30208)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.297% (27089/30336)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.312% (27208/30464)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.298% (27318/30592)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.277% (27426/30720)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.260% (27535/30848)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.259% (27649/30976)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.255% (27762/31104)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.245% (27873/31232)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.270% (27995/31360)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.275% (28111/31488)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.268% (28223/31616)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.277% (28340/31744)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.270% (28452/31872)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.281% (28570/32000)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.277% (28683/32128)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.261% (28792/32256)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.260% (28906/32384)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.272% (29024/32512)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.277% (29140/32640)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.267% (29251/32768)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.266% (29365/32896)\n",
      "Train Epoch: 21 | Loss: 0.309 | Acc: 89.250% (29474/33024)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.250% (29588/33152)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.249% (29702/33280)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.248% (29816/33408)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.247% (29930/33536)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.247% (30044/33664)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.237% (30155/33792)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.242% (30271/33920)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.239% (30384/34048)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.253% (30503/34176)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.252% (30617/34304)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.260% (30734/34432)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.253% (30846/34560)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.233% (30953/34688)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.220% (31063/34816)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.226% (31179/34944)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.239% (31298/35072)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.230% (31409/35200)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.235% (31525/35328)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.243% (31642/35456)\n",
      "Train Epoch: 21 | Loss: 0.310 | Acc: 89.242% (31756/35584)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.228% (31865/35712)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.210% (31973/35840)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.196% (32082/35968)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.190% (32194/36096)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.187% (32307/36224)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.192% (32423/36352)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.183% (32534/36480)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.196% (32653/36608)\n",
      "Train Epoch: 21 | Loss: 0.311 | Acc: 89.196% (32767/36736)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.190% (32879/36864)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.187% (32992/36992)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.186% (33106/37120)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.189% (33221/37248)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.172% (33329/37376)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.164% (33440/37504)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.169% (33556/37632)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.176% (33673/37760)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.168% (33784/37888)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.170% (33899/38016)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.175% (34015/38144)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.180% (34131/38272)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.169% (34241/38400)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.164% (34353/38528)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.145% (34460/38656)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.137% (34571/38784)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.142% (34687/38912)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.132% (34797/39040)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.139% (34914/39168)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.141% (35029/39296)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.131% (35139/39424)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.128% (35252/39552)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.110% (35359/39680)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.123% (35478/39808)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.115% (35589/39936)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.122% (35706/40064)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.130% (35823/40192)\n",
      "Train Epoch: 21 | Loss: 0.312 | Acc: 89.127% (35936/40320)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.119% (36047/40448)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.117% (36160/40576)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.114% (36273/40704)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.109% (36385/40832)\n",
      "Train Epoch: 21 | Loss: 0.313 | Acc: 89.084% (36489/40960)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.067% (36596/41088)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.060% (36707/41216)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.070% (36825/41344)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.060% (36935/41472)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.065% (37051/41600)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (37162/41728)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.048% (37272/41856)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.055% (37389/41984)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (37504/42112)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.062% (37620/42240)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.051% (37729/42368)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.041% (37839/42496)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.053% (37958/42624)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.051% (38071/42752)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.051% (38185/42880)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.062% (38304/43008)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.049% (38412/43136)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.051% (38527/43264)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (38644/43392)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.042% (38751/43520)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.037% (38863/43648)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.049% (38982/43776)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.060% (39101/43904)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.053% (39212/44032)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.056% (39327/44160)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.047% (39437/44288)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.062% (39558/44416)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.049% (39666/44544)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.038% (39775/44672)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.029% (39885/44800)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.034% (40001/44928)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.038% (40117/45056)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.047% (40235/45184)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.049% (40350/45312)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (40468/45440)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (40582/45568)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.058% (40696/45696)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.056% (40809/45824)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.071% (40930/45952)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.071% (41044/46080)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.073% (41159/46208)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.075% (41274/46336)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.080% (41390/46464)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.086% (41507/46592)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.090% (41623/46720)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.088% (41736/46848)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.090% (41851/46976)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.079% (41960/47104)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.079% (42074/47232)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.073% (42185/47360)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.065% (42295/47488)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.073% (42413/47616)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.073% (42527/47744)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.077% (42643/47872)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.092% (42764/48000)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.092% (42878/48128)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.083% (42988/48256)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.067% (43094/48384)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.062% (43206/48512)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.058% (43318/48640)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.056% (43431/48768)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.052% (43543/48896)\n",
      "Train Epoch: 21 | Loss: 0.315 | Acc: 89.056% (43659/49024)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.056% (43773/49152)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.050% (43884/49280)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.056% (44001/49408)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.067% (44120/49536)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.079% (44240/49664)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.079% (44354/49792)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.077% (44467/49920)\n",
      "Train Epoch: 21 | Loss: 0.314 | Acc: 89.080% (44540/50000)\n",
      "Test Epoch: 21 | Loss: 0.401 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 21 | Loss: 0.363 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 21 | Loss: 0.337 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 21 | Loss: 0.365 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 21 | Loss: 0.363 | Acc: 88.400% (442/500)\n",
      "Test Epoch: 21 | Loss: 0.336 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 21 | Loss: 0.349 | Acc: 89.286% (625/700)\n",
      "Test Epoch: 21 | Loss: 0.367 | Acc: 88.250% (706/800)\n",
      "Test Epoch: 21 | Loss: 0.375 | Acc: 87.889% (791/900)\n",
      "Test Epoch: 21 | Loss: 0.395 | Acc: 87.600% (876/1000)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.727% (954/1100)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.750% (1041/1200)\n",
      "Test Epoch: 21 | Loss: 0.412 | Acc: 86.846% (1129/1300)\n",
      "Test Epoch: 21 | Loss: 0.406 | Acc: 86.929% (1217/1400)\n",
      "Test Epoch: 21 | Loss: 0.403 | Acc: 86.867% (1303/1500)\n",
      "Test Epoch: 21 | Loss: 0.401 | Acc: 86.938% (1391/1600)\n",
      "Test Epoch: 21 | Loss: 0.404 | Acc: 87.176% (1482/1700)\n",
      "Test Epoch: 21 | Loss: 0.409 | Acc: 87.000% (1566/1800)\n",
      "Test Epoch: 21 | Loss: 0.409 | Acc: 87.105% (1655/1900)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.850% (1737/2000)\n",
      "Test Epoch: 21 | Loss: 0.420 | Acc: 86.810% (1823/2100)\n",
      "Test Epoch: 21 | Loss: 0.419 | Acc: 86.682% (1907/2200)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.696% (1994/2300)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.667% (2080/2400)\n",
      "Test Epoch: 21 | Loss: 0.422 | Acc: 86.640% (2166/2500)\n",
      "Test Epoch: 21 | Loss: 0.430 | Acc: 86.577% (2251/2600)\n",
      "Test Epoch: 21 | Loss: 0.428 | Acc: 86.556% (2337/2700)\n",
      "Test Epoch: 21 | Loss: 0.428 | Acc: 86.536% (2423/2800)\n",
      "Test Epoch: 21 | Loss: 0.428 | Acc: 86.586% (2511/2900)\n",
      "Test Epoch: 21 | Loss: 0.429 | Acc: 86.533% (2596/3000)\n",
      "Test Epoch: 21 | Loss: 0.430 | Acc: 86.516% (2682/3100)\n",
      "Test Epoch: 21 | Loss: 0.426 | Acc: 86.594% (2771/3200)\n",
      "Test Epoch: 21 | Loss: 0.425 | Acc: 86.576% (2857/3300)\n",
      "Test Epoch: 21 | Loss: 0.422 | Acc: 86.618% (2945/3400)\n",
      "Test Epoch: 21 | Loss: 0.427 | Acc: 86.514% (3028/3500)\n",
      "Test Epoch: 21 | Loss: 0.432 | Acc: 86.500% (3114/3600)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 86.541% (3202/3700)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 86.579% (3290/3800)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 86.564% (3376/3900)\n",
      "Test Epoch: 21 | Loss: 0.431 | Acc: 86.600% (3464/4000)\n",
      "Test Epoch: 21 | Loss: 0.431 | Acc: 86.585% (3550/4100)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 86.476% (3632/4200)\n",
      "Test Epoch: 21 | Loss: 0.428 | Acc: 86.628% (3725/4300)\n",
      "Test Epoch: 21 | Loss: 0.427 | Acc: 86.659% (3813/4400)\n",
      "Test Epoch: 21 | Loss: 0.425 | Acc: 86.667% (3900/4500)\n",
      "Test Epoch: 21 | Loss: 0.424 | Acc: 86.652% (3986/4600)\n",
      "Test Epoch: 21 | Loss: 0.421 | Acc: 86.787% (4079/4700)\n",
      "Test Epoch: 21 | Loss: 0.423 | Acc: 86.688% (4161/4800)\n",
      "Test Epoch: 21 | Loss: 0.421 | Acc: 86.735% (4250/4900)\n",
      "Test Epoch: 21 | Loss: 0.422 | Acc: 86.700% (4335/5000)\n",
      "Test Epoch: 21 | Loss: 0.421 | Acc: 86.784% (4426/5100)\n",
      "Test Epoch: 21 | Loss: 0.421 | Acc: 86.750% (4511/5200)\n",
      "Test Epoch: 21 | Loss: 0.420 | Acc: 86.717% (4596/5300)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.778% (4686/5400)\n",
      "Test Epoch: 21 | Loss: 0.420 | Acc: 86.691% (4768/5500)\n",
      "Test Epoch: 21 | Loss: 0.420 | Acc: 86.696% (4855/5600)\n",
      "Test Epoch: 21 | Loss: 0.419 | Acc: 86.667% (4940/5700)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.707% (5029/5800)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.678% (5114/5900)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.617% (5197/6000)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.639% (5285/6100)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.694% (5375/6200)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.730% (5464/6300)\n",
      "Test Epoch: 21 | Loss: 0.411 | Acc: 86.750% (5552/6400)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 86.800% (5642/6500)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 86.773% (5727/6600)\n",
      "Test Epoch: 21 | Loss: 0.407 | Acc: 86.836% (5818/6700)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 86.765% (5900/6800)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 86.710% (5983/6900)\n",
      "Test Epoch: 21 | Loss: 0.411 | Acc: 86.686% (6068/7000)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.634% (6151/7100)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.611% (6236/7200)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.671% (6327/7300)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.676% (6414/7400)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.680% (6501/7500)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.645% (6585/7600)\n",
      "Test Epoch: 21 | Loss: 0.415 | Acc: 86.649% (6672/7700)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.628% (6757/7800)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.633% (6844/7900)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.588% (6927/8000)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.593% (7014/8100)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.646% (7105/8200)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.639% (7191/8300)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 86.667% (7280/8400)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.600% (7361/8500)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.570% (7445/8600)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.540% (7529/8700)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.568% (7618/8800)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.562% (7704/8900)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.567% (7791/9000)\n",
      "Test Epoch: 21 | Loss: 0.419 | Acc: 86.560% (7877/9100)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.609% (7968/9200)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.591% (8053/9300)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.617% (8142/9400)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 86.611% (8228/9500)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 86.635% (8317/9600)\n",
      "Test Epoch: 21 | Loss: 0.414 | Acc: 86.660% (8406/9700)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.643% (8491/9800)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 86.636% (8577/9900)\n",
      "Test Epoch: 21 | Loss: 0.415 | Acc: 86.680% (8668/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 22\n",
      "Train Epoch: 22 | Loss: 0.223 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 22 | Loss: 0.352 | Acc: 88.281% (226/256)\n",
      "Train Epoch: 22 | Loss: 0.308 | Acc: 89.844% (345/384)\n",
      "Train Epoch: 22 | Loss: 0.282 | Acc: 90.625% (464/512)\n",
      "Train Epoch: 22 | Loss: 0.283 | Acc: 90.469% (579/640)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.844% (690/768)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.067% (807/896)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.137% (923/1024)\n",
      "Train Epoch: 22 | Loss: 0.268 | Acc: 90.451% (1042/1152)\n",
      "Train Epoch: 22 | Loss: 0.265 | Acc: 90.547% (1159/1280)\n",
      "Train Epoch: 22 | Loss: 0.267 | Acc: 90.483% (1274/1408)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.430% (1389/1536)\n",
      "Train Epoch: 22 | Loss: 0.270 | Acc: 90.445% (1505/1664)\n",
      "Train Epoch: 22 | Loss: 0.267 | Acc: 90.681% (1625/1792)\n",
      "Train Epoch: 22 | Loss: 0.261 | Acc: 90.938% (1746/1920)\n",
      "Train Epoch: 22 | Loss: 0.263 | Acc: 90.723% (1858/2048)\n",
      "Train Epoch: 22 | Loss: 0.269 | Acc: 90.579% (1971/2176)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.321% (2081/2304)\n",
      "Train Epoch: 22 | Loss: 0.271 | Acc: 90.419% (2199/2432)\n",
      "Train Epoch: 22 | Loss: 0.270 | Acc: 90.352% (2313/2560)\n",
      "Train Epoch: 22 | Loss: 0.269 | Acc: 90.327% (2428/2688)\n",
      "Train Epoch: 22 | Loss: 0.273 | Acc: 90.163% (2539/2816)\n",
      "Train Epoch: 22 | Loss: 0.273 | Acc: 90.217% (2656/2944)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.039% (2766/3072)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.000% (2880/3200)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.054% (2997/3328)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 89.988% (3110/3456)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 89.983% (3225/3584)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 89.978% (3340/3712)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.026% (3457/3840)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.020% (3572/3968)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.015% (3687/4096)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.175% (3809/4224)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.211% (3926/4352)\n",
      "Train Epoch: 22 | Loss: 0.274 | Acc: 90.268% (4044/4480)\n",
      "Train Epoch: 22 | Loss: 0.273 | Acc: 90.278% (4160/4608)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.245% (4274/4736)\n",
      "Train Epoch: 22 | Loss: 0.274 | Acc: 90.214% (4388/4864)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.184% (4502/4992)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.215% (4619/5120)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.263% (4737/5248)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.420% (4861/5376)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.480% (4980/5504)\n",
      "Train Epoch: 22 | Loss: 0.271 | Acc: 90.501% (5097/5632)\n",
      "Train Epoch: 22 | Loss: 0.270 | Acc: 90.556% (5216/5760)\n",
      "Train Epoch: 22 | Loss: 0.270 | Acc: 90.574% (5333/5888)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.542% (5447/6016)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.511% (5561/6144)\n",
      "Train Epoch: 22 | Loss: 0.271 | Acc: 90.593% (5682/6272)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.516% (5793/6400)\n",
      "Train Epoch: 22 | Loss: 0.274 | Acc: 90.426% (5903/6528)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.415% (6018/6656)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.374% (6131/6784)\n",
      "Train Epoch: 22 | Loss: 0.274 | Acc: 90.451% (6252/6912)\n",
      "Train Epoch: 22 | Loss: 0.273 | Acc: 90.440% (6367/7040)\n",
      "Train Epoch: 22 | Loss: 0.272 | Acc: 90.472% (6485/7168)\n",
      "Train Epoch: 22 | Loss: 0.273 | Acc: 90.447% (6599/7296)\n",
      "Train Epoch: 22 | Loss: 0.274 | Acc: 90.383% (6710/7424)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.347% (6823/7552)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.286% (6934/7680)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.292% (7050/7808)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.310% (7167/7936)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.315% (7283/8064)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.308% (7398/8192)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.300% (7513/8320)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.258% (7625/8448)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.287% (7743/8576)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.315% (7861/8704)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.353% (7980/8832)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.290% (8090/8960)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.273% (8204/9088)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.375% (8329/9216)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.400% (8447/9344)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.424% (8565/9472)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.375% (8676/9600)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.296% (8784/9728)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.331% (8903/9856)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.365% (9022/9984)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.378% (9139/10112)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.352% (9252/10240)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.307% (9363/10368)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.301% (9478/10496)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.277% (9591/10624)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.299% (9709/10752)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.285% (9823/10880)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.307% (9941/11008)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.302% (10056/11136)\n",
      "Train Epoch: 22 | Loss: 0.275 | Acc: 90.323% (10174/11264)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.300% (10287/11392)\n",
      "Train Epoch: 22 | Loss: 0.276 | Acc: 90.278% (10400/11520)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.230% (10510/11648)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.200% (10622/11776)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.205% (10738/11904)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.218% (10855/12032)\n",
      "Train Epoch: 22 | Loss: 0.277 | Acc: 90.222% (10971/12160)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.169% (11080/12288)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.118% (11189/12416)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.202% (11315/12544)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.144% (11423/12672)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.141% (11538/12800)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.176% (11658/12928)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.142% (11769/13056)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.147% (11885/13184)\n",
      "Train Epoch: 22 | Loss: 0.278 | Acc: 90.167% (12003/13312)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.134% (12114/13440)\n",
      "Train Epoch: 22 | Loss: 0.279 | Acc: 90.139% (12230/13568)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.158% (12348/13696)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.119% (12458/13824)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.130% (12575/13952)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.092% (12685/14080)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.083% (12799/14208)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.081% (12914/14336)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.093% (13031/14464)\n",
      "Train Epoch: 22 | Loss: 0.280 | Acc: 90.104% (13148/14592)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.054% (13256/14720)\n",
      "Train Epoch: 22 | Loss: 0.281 | Acc: 90.046% (13370/14848)\n",
      "Train Epoch: 22 | Loss: 0.282 | Acc: 90.017% (13481/14976)\n",
      "Train Epoch: 22 | Loss: 0.282 | Acc: 90.023% (13597/15104)\n",
      "Train Epoch: 22 | Loss: 0.282 | Acc: 90.021% (13712/15232)\n",
      "Train Epoch: 22 | Loss: 0.283 | Acc: 90.007% (13825/15360)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.979% (13936/15488)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.959% (14048/15616)\n",
      "Train Epoch: 22 | Loss: 0.285 | Acc: 89.933% (14159/15744)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.957% (14278/15872)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.938% (14390/16000)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.968% (14510/16128)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.973% (14626/16256)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.996% (14745/16384)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.983% (14858/16512)\n",
      "Train Epoch: 22 | Loss: 0.284 | Acc: 89.988% (14974/16640)\n",
      "Train Epoch: 22 | Loss: 0.285 | Acc: 89.957% (15084/16768)\n",
      "Train Epoch: 22 | Loss: 0.285 | Acc: 89.962% (15200/16896)\n",
      "Train Epoch: 22 | Loss: 0.286 | Acc: 89.926% (15309/17024)\n",
      "Train Epoch: 22 | Loss: 0.286 | Acc: 89.908% (15421/17152)\n",
      "Train Epoch: 22 | Loss: 0.287 | Acc: 89.913% (15537/17280)\n",
      "Train Epoch: 22 | Loss: 0.287 | Acc: 89.901% (15650/17408)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.895% (15764/17536)\n",
      "Train Epoch: 22 | Loss: 0.287 | Acc: 89.900% (15880/17664)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.889% (15993/17792)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.888% (16108/17920)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.905% (16226/18048)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.915% (16343/18176)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.904% (16456/18304)\n",
      "Train Epoch: 22 | Loss: 0.288 | Acc: 89.903% (16571/18432)\n",
      "Train Epoch: 22 | Loss: 0.289 | Acc: 89.860% (16678/18560)\n",
      "Train Epoch: 22 | Loss: 0.289 | Acc: 89.822% (16786/18688)\n",
      "Train Epoch: 22 | Loss: 0.290 | Acc: 89.822% (16901/18816)\n",
      "Train Epoch: 22 | Loss: 0.290 | Acc: 89.791% (17010/18944)\n",
      "Train Epoch: 22 | Loss: 0.289 | Acc: 89.797% (17126/19072)\n",
      "Train Epoch: 22 | Loss: 0.289 | Acc: 89.807% (17243/19200)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.776% (17352/19328)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.762% (17464/19456)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.747% (17576/19584)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.747% (17691/19712)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.753% (17807/19840)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.734% (17918/19968)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.719% (18030/20096)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.740% (18149/20224)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.755% (18267/20352)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.756% (18382/20480)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.761% (18498/20608)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.767% (18614/20736)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.786% (18733/20864)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.787% (18848/20992)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.768% (18959/21120)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.754% (19071/21248)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.755% (19186/21376)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.760% (19302/21504)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.751% (19415/21632)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.761% (19532/21760)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.784% (19652/21888)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.780% (19766/22016)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.790% (19883/22144)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.803% (20001/22272)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.799% (20115/22400)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.808% (20232/22528)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.804% (20346/22656)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.787% (20457/22784)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.778% (20570/22912)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.787% (20687/23040)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.788% (20802/23168)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.775% (20914/23296)\n",
      "Train Epoch: 22 | Loss: 0.291 | Acc: 89.801% (21035/23424)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.784% (21146/23552)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.738% (21250/23680)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.722% (21361/23808)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.706% (21472/23936)\n",
      "Train Epoch: 22 | Loss: 0.292 | Acc: 89.723% (21591/24064)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.695% (21699/24192)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.696% (21814/24320)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.676% (21924/24448)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.673% (22038/24576)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.649% (22147/24704)\n",
      "Train Epoch: 22 | Loss: 0.293 | Acc: 89.663% (22265/24832)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.639% (22374/24960)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.636% (22488/25088)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.653% (22607/25216)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.662% (22724/25344)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.651% (22836/25472)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.621% (22943/25600)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.634% (23061/25728)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.647% (23179/25856)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.659% (23297/25984)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.671% (23415/26112)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.657% (23526/26240)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.654% (23640/26368)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.663% (23757/26496)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.660% (23871/26624)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.646% (23982/26752)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.639% (24095/26880)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.648% (24212/27008)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.648% (24327/27136)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.635% (24438/27264)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.647% (24556/27392)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.644% (24670/27520)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.638% (24783/27648)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.635% (24897/27776)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.647% (25015/27904)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.648% (25130/28032)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.656% (25247/28160)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.653% (25361/28288)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.647% (25474/28416)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.634% (25585/28544)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.621% (25696/28672)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.628% (25813/28800)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.619% (25925/28928)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.613% (26038/29056)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.597% (26148/29184)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.602% (26264/29312)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.586% (26374/29440)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.587% (26489/29568)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.581% (26602/29696)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.586% (26718/29824)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.577% (26830/29952)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.584% (26947/30080)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.586% (27062/30208)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.600% (27181/30336)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.607% (27298/30464)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.621% (27417/30592)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.635% (27536/30720)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.646% (27654/30848)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.657% (27772/30976)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.664% (27889/31104)\n",
      "Train Epoch: 22 | Loss: 0.294 | Acc: 89.652% (28000/31232)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.636% (28110/31360)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.644% (28227/31488)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.638% (28340/31616)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.639% (28455/31744)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.630% (28567/31872)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.628% (28681/32000)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.623% (28794/32128)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.617% (28907/32256)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.618% (29022/32384)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.622% (29138/32512)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.602% (29246/32640)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.609% (29363/32768)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.616% (29480/32896)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.623% (29597/33024)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.618% (29710/33152)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.609% (29822/33280)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.607% (29936/33408)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.617% (30054/33536)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.630% (30173/33664)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.622% (30285/33792)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.631% (30403/33920)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.621% (30514/34048)\n",
      "Train Epoch: 22 | Loss: 0.295 | Acc: 89.630% (30632/34176)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.613% (30741/34304)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.632% (30862/34432)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.633% (30977/34560)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.616% (31086/34688)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.623% (31203/34816)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.621% (31317/34944)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.627% (31434/35072)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.619% (31546/35200)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.589% (31650/35328)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.584% (31763/35456)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.602% (31884/35584)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.609% (32001/35712)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.604% (32114/35840)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.585% (32222/35968)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.583% (32336/36096)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.595% (32455/36224)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.607% (32574/36352)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.589% (32682/36480)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.598% (32800/36608)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.596% (32914/36736)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.610% (33034/36864)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.611% (33149/36992)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.612% (33264/37120)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.616% (33380/37248)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.622% (33497/37376)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.612% (33608/37504)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.599% (33718/37632)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.603% (33834/37760)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.596% (33946/37888)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.591% (34059/38016)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.610% (34181/38144)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.606% (34294/38272)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.599% (34406/38400)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.610% (34525/38528)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.598% (34635/38656)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.596% (34749/38784)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.592% (34862/38912)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.593% (34977/39040)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.601% (35095/39168)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.607% (35212/39296)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.628% (35335/39424)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.629% (35450/39552)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.622% (35562/39680)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.623% (35677/39808)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.608% (35786/39936)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.609% (35901/40064)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.612% (36017/40192)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.616% (36133/40320)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.619% (36249/40448)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.629% (36368/40576)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.630% (36483/40704)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.631% (36598/40832)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.634% (36714/40960)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.634% (36829/41088)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.628% (36941/41216)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.633% (37058/41344)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.624% (37169/41472)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.625% (37284/41600)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.633% (37402/41728)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.638% (37519/41856)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.648% (37638/41984)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.659% (37757/42112)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.669% (37876/42240)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.679% (37995/42368)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.674% (38108/42496)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.677% (38224/42624)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.666% (38334/42752)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.676% (38453/42880)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.667% (38564/43008)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.661% (38676/43136)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.666% (38793/43264)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.664% (38907/43392)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.658% (39019/43520)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.649% (39130/43648)\n",
      "Train Epoch: 22 | Loss: 0.296 | Acc: 89.666% (39252/43776)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.655% (39362/43904)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.653% (39476/44032)\n",
      "Train Epoch: 22 | Loss: 0.297 | Acc: 89.640% (39585/44160)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.632% (39696/44288)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.616% (39804/44416)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.626% (39923/44544)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.631% (40040/44672)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.621% (40150/44800)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.612% (40261/44928)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.608% (40374/45056)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.618% (40493/45184)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.608% (40603/45312)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.599% (40714/45440)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.589% (40824/45568)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.579% (40934/45696)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.584% (41051/45824)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.583% (41165/45952)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.579% (41278/46080)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.584% (41395/46208)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.583% (41509/46336)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.594% (41629/46464)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.582% (41738/46592)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.583% (41853/46720)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.571% (41962/46848)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.576% (42079/46976)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.566% (42189/47104)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.571% (42306/47232)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.569% (42420/47360)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.581% (42540/47488)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.575% (42652/47616)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.574% (42766/47744)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.574% (42881/47872)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.575% (42996/48000)\n",
      "Train Epoch: 22 | Loss: 0.298 | Acc: 89.582% (43114/48128)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.578% (43227/48256)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.579% (43342/48384)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.572% (43453/48512)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.566% (43565/48640)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.563% (43678/48768)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.557% (43790/48896)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.550% (43901/49024)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.537% (44009/49152)\n",
      "Train Epoch: 22 | Loss: 0.300 | Acc: 89.529% (44120/49280)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.530% (44235/49408)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.521% (44345/49536)\n",
      "Train Epoch: 22 | Loss: 0.300 | Acc: 89.524% (44461/49664)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.530% (44579/49792)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.533% (44695/49920)\n",
      "Train Epoch: 22 | Loss: 0.299 | Acc: 89.542% (44771/50000)\n",
      "Test Epoch: 22 | Loss: 0.495 | Acc: 83.000% (83/100)\n",
      "Test Epoch: 22 | Loss: 0.490 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 22 | Loss: 0.482 | Acc: 84.750% (339/400)\n",
      "Test Epoch: 22 | Loss: 0.468 | Acc: 84.000% (420/500)\n",
      "Test Epoch: 22 | Loss: 0.432 | Acc: 85.333% (512/600)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 85.000% (595/700)\n",
      "Test Epoch: 22 | Loss: 0.468 | Acc: 84.250% (674/800)\n",
      "Test Epoch: 22 | Loss: 0.486 | Acc: 83.667% (753/900)\n",
      "Test Epoch: 22 | Loss: 0.502 | Acc: 83.500% (835/1000)\n",
      "Test Epoch: 22 | Loss: 0.523 | Acc: 82.909% (912/1100)\n",
      "Test Epoch: 22 | Loss: 0.536 | Acc: 82.583% (991/1200)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.000% (1079/1300)\n",
      "Test Epoch: 22 | Loss: 0.516 | Acc: 83.357% (1167/1400)\n",
      "Test Epoch: 22 | Loss: 0.514 | Acc: 83.467% (1252/1500)\n",
      "Test Epoch: 22 | Loss: 0.520 | Acc: 83.438% (1335/1600)\n",
      "Test Epoch: 22 | Loss: 0.514 | Acc: 83.765% (1424/1700)\n",
      "Test Epoch: 22 | Loss: 0.516 | Acc: 83.444% (1502/1800)\n",
      "Test Epoch: 22 | Loss: 0.517 | Acc: 83.579% (1588/1900)\n",
      "Test Epoch: 22 | Loss: 0.518 | Acc: 83.700% (1674/2000)\n",
      "Test Epoch: 22 | Loss: 0.519 | Acc: 83.619% (1756/2100)\n",
      "Test Epoch: 22 | Loss: 0.524 | Acc: 83.500% (1837/2200)\n",
      "Test Epoch: 22 | Loss: 0.526 | Acc: 83.565% (1922/2300)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.500% (2004/2400)\n",
      "Test Epoch: 22 | Loss: 0.539 | Acc: 83.400% (2085/2500)\n",
      "Test Epoch: 22 | Loss: 0.550 | Acc: 83.269% (2165/2600)\n",
      "Test Epoch: 22 | Loss: 0.549 | Acc: 83.259% (2248/2700)\n",
      "Test Epoch: 22 | Loss: 0.546 | Acc: 83.321% (2333/2800)\n",
      "Test Epoch: 22 | Loss: 0.548 | Acc: 83.310% (2416/2900)\n",
      "Test Epoch: 22 | Loss: 0.549 | Acc: 83.333% (2500/3000)\n",
      "Test Epoch: 22 | Loss: 0.547 | Acc: 83.290% (2582/3100)\n",
      "Test Epoch: 22 | Loss: 0.544 | Acc: 83.375% (2668/3200)\n",
      "Test Epoch: 22 | Loss: 0.540 | Acc: 83.394% (2752/3300)\n",
      "Test Epoch: 22 | Loss: 0.543 | Acc: 83.353% (2834/3400)\n",
      "Test Epoch: 22 | Loss: 0.548 | Acc: 83.257% (2914/3500)\n",
      "Test Epoch: 22 | Loss: 0.549 | Acc: 83.250% (2997/3600)\n",
      "Test Epoch: 22 | Loss: 0.551 | Acc: 83.216% (3079/3700)\n",
      "Test Epoch: 22 | Loss: 0.550 | Acc: 83.316% (3166/3800)\n",
      "Test Epoch: 22 | Loss: 0.549 | Acc: 83.333% (3250/3900)\n",
      "Test Epoch: 22 | Loss: 0.549 | Acc: 83.375% (3335/4000)\n",
      "Test Epoch: 22 | Loss: 0.547 | Acc: 83.390% (3419/4100)\n",
      "Test Epoch: 22 | Loss: 0.548 | Acc: 83.333% (3500/4200)\n",
      "Test Epoch: 22 | Loss: 0.543 | Acc: 83.488% (3590/4300)\n",
      "Test Epoch: 22 | Loss: 0.544 | Acc: 83.591% (3678/4400)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.578% (3761/4500)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.478% (3840/4600)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.426% (3921/4700)\n",
      "Test Epoch: 22 | Loss: 0.543 | Acc: 83.396% (4003/4800)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.429% (4088/4900)\n",
      "Test Epoch: 22 | Loss: 0.543 | Acc: 83.360% (4168/5000)\n",
      "Test Epoch: 22 | Loss: 0.540 | Acc: 83.490% (4258/5100)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.404% (4337/5200)\n",
      "Test Epoch: 22 | Loss: 0.542 | Acc: 83.302% (4415/5300)\n",
      "Test Epoch: 22 | Loss: 0.539 | Acc: 83.407% (4504/5400)\n",
      "Test Epoch: 22 | Loss: 0.540 | Acc: 83.364% (4585/5500)\n",
      "Test Epoch: 22 | Loss: 0.541 | Acc: 83.357% (4668/5600)\n",
      "Test Epoch: 22 | Loss: 0.538 | Acc: 83.386% (4753/5700)\n",
      "Test Epoch: 22 | Loss: 0.535 | Acc: 83.483% (4842/5800)\n",
      "Test Epoch: 22 | Loss: 0.538 | Acc: 83.390% (4920/5900)\n",
      "Test Epoch: 22 | Loss: 0.537 | Acc: 83.400% (5004/6000)\n",
      "Test Epoch: 22 | Loss: 0.535 | Acc: 83.410% (5088/6100)\n",
      "Test Epoch: 22 | Loss: 0.536 | Acc: 83.468% (5175/6200)\n",
      "Test Epoch: 22 | Loss: 0.535 | Acc: 83.492% (5260/6300)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.531% (5346/6400)\n",
      "Test Epoch: 22 | Loss: 0.532 | Acc: 83.477% (5426/6500)\n",
      "Test Epoch: 22 | Loss: 0.531 | Acc: 83.470% (5509/6600)\n",
      "Test Epoch: 22 | Loss: 0.528 | Acc: 83.567% (5599/6700)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.529% (5680/6800)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.551% (5765/6900)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.543% (5848/7000)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.507% (5929/7100)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.514% (6013/7200)\n",
      "Test Epoch: 22 | Loss: 0.528 | Acc: 83.603% (6103/7300)\n",
      "Test Epoch: 22 | Loss: 0.528 | Acc: 83.635% (6189/7400)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.653% (6274/7500)\n",
      "Test Epoch: 22 | Loss: 0.531 | Acc: 83.618% (6355/7600)\n",
      "Test Epoch: 22 | Loss: 0.531 | Acc: 83.675% (6443/7700)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.667% (6526/7800)\n",
      "Test Epoch: 22 | Loss: 0.531 | Acc: 83.658% (6609/7900)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.650% (6692/8000)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.605% (6772/8100)\n",
      "Test Epoch: 22 | Loss: 0.528 | Acc: 83.671% (6861/8200)\n",
      "Test Epoch: 22 | Loss: 0.527 | Acc: 83.675% (6945/8300)\n",
      "Test Epoch: 22 | Loss: 0.527 | Acc: 83.702% (7031/8400)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.624% (7108/8500)\n",
      "Test Epoch: 22 | Loss: 0.532 | Acc: 83.605% (7190/8600)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.575% (7271/8700)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.557% (7353/8800)\n",
      "Test Epoch: 22 | Loss: 0.532 | Acc: 83.562% (7437/8900)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.533% (7518/9000)\n",
      "Test Epoch: 22 | Loss: 0.535 | Acc: 83.527% (7601/9100)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.565% (7688/9200)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.527% (7768/9300)\n",
      "Test Epoch: 22 | Loss: 0.532 | Acc: 83.564% (7855/9400)\n",
      "Test Epoch: 22 | Loss: 0.533 | Acc: 83.600% (7942/9500)\n",
      "Test Epoch: 22 | Loss: 0.532 | Acc: 83.635% (8029/9600)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.711% (8120/9700)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.724% (8205/9800)\n",
      "Test Epoch: 22 | Loss: 0.530 | Acc: 83.758% (8292/9900)\n",
      "Test Epoch: 22 | Loss: 0.529 | Acc: 83.820% (8382/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Train Epoch: 23 | Loss: 0.320 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 23 | Loss: 0.327 | Acc: 89.844% (230/256)\n",
      "Train Epoch: 23 | Loss: 0.329 | Acc: 89.323% (343/384)\n",
      "Train Epoch: 23 | Loss: 0.338 | Acc: 89.453% (458/512)\n",
      "Train Epoch: 23 | Loss: 0.326 | Acc: 89.531% (573/640)\n",
      "Train Epoch: 23 | Loss: 0.333 | Acc: 88.932% (683/768)\n",
      "Train Epoch: 23 | Loss: 0.328 | Acc: 89.062% (798/896)\n",
      "Train Epoch: 23 | Loss: 0.315 | Acc: 89.355% (915/1024)\n",
      "Train Epoch: 23 | Loss: 0.311 | Acc: 89.062% (1026/1152)\n",
      "Train Epoch: 23 | Loss: 0.312 | Acc: 88.906% (1138/1280)\n",
      "Train Epoch: 23 | Loss: 0.305 | Acc: 89.062% (1254/1408)\n",
      "Train Epoch: 23 | Loss: 0.306 | Acc: 89.062% (1368/1536)\n",
      "Train Epoch: 23 | Loss: 0.310 | Acc: 88.942% (1480/1664)\n",
      "Train Epoch: 23 | Loss: 0.315 | Acc: 88.839% (1592/1792)\n",
      "Train Epoch: 23 | Loss: 0.316 | Acc: 88.958% (1708/1920)\n",
      "Train Epoch: 23 | Loss: 0.315 | Acc: 89.062% (1824/2048)\n",
      "Train Epoch: 23 | Loss: 0.313 | Acc: 89.246% (1942/2176)\n",
      "Train Epoch: 23 | Loss: 0.307 | Acc: 89.453% (2061/2304)\n",
      "Train Epoch: 23 | Loss: 0.311 | Acc: 89.391% (2174/2432)\n",
      "Train Epoch: 23 | Loss: 0.307 | Acc: 89.375% (2288/2560)\n",
      "Train Epoch: 23 | Loss: 0.305 | Acc: 89.323% (2401/2688)\n",
      "Train Epoch: 23 | Loss: 0.301 | Acc: 89.489% (2520/2816)\n",
      "Train Epoch: 23 | Loss: 0.301 | Acc: 89.504% (2635/2944)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.811% (2759/3072)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.875% (2876/3200)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.904% (2992/3328)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.988% (3110/3456)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.927% (3223/3584)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.871% (3336/3712)\n",
      "Train Epoch: 23 | Loss: 0.291 | Acc: 90.000% (3456/3840)\n",
      "Train Epoch: 23 | Loss: 0.291 | Acc: 90.020% (3572/3968)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.063% (3689/4096)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.152% (3808/4224)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.097% (3921/4352)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.112% (4037/4480)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.191% (4156/4608)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.224% (4273/4736)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.234% (4389/4864)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.224% (4504/4992)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.156% (4616/5120)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.187% (4733/5248)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.030% (4840/5376)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.062% (4957/5504)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.217% (5081/5632)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.295% (5201/5760)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.353% (5320/5888)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.376% (5437/6016)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.348% (5551/6144)\n",
      "Train Epoch: 23 | Loss: 0.279 | Acc: 90.466% (5674/6272)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.453% (5789/6400)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.472% (5906/6528)\n",
      "Train Epoch: 23 | Loss: 0.277 | Acc: 90.490% (6023/6656)\n",
      "Train Epoch: 23 | Loss: 0.277 | Acc: 90.433% (6135/6784)\n",
      "Train Epoch: 23 | Loss: 0.277 | Acc: 90.394% (6248/6912)\n",
      "Train Epoch: 23 | Loss: 0.277 | Acc: 90.341% (6360/7040)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.304% (6473/7168)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.255% (6585/7296)\n",
      "Train Epoch: 23 | Loss: 0.279 | Acc: 90.234% (6699/7424)\n",
      "Train Epoch: 23 | Loss: 0.279 | Acc: 90.228% (6814/7552)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.260% (6932/7680)\n",
      "Train Epoch: 23 | Loss: 0.279 | Acc: 90.254% (7047/7808)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.247% (7162/7936)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.265% (7279/8064)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.271% (7395/8192)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.264% (7510/8320)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.317% (7630/8448)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.322% (7746/8576)\n",
      "Train Epoch: 23 | Loss: 0.278 | Acc: 90.292% (7859/8704)\n",
      "Train Epoch: 23 | Loss: 0.279 | Acc: 90.217% (7968/8832)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.145% (8077/8960)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.163% (8194/9088)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.050% (8299/9216)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.026% (8412/9344)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.076% (8532/9472)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.031% (8643/9600)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.039% (8759/9728)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.037% (8874/9856)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.074% (8993/9984)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.131% (9114/10112)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.107% (9227/10240)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.104% (9342/10368)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.139% (9461/10496)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.145% (9577/10624)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.151% (9693/10752)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.119% (9805/10880)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.162% (9925/11008)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.086% (10032/11136)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.066% (10145/11264)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.046% (10258/11392)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.035% (10372/11520)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.990% (10482/11648)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.971% (10595/11776)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.987% (10712/11904)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.993% (10828/12032)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.959% (10939/12160)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.990% (11058/12288)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.981% (11172/12416)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.971% (11286/12544)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.962% (11400/12672)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 89.984% (11518/12800)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.006% (11636/12928)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.005% (11751/13056)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.003% (11866/13184)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.986% (11979/13312)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.970% (12092/13440)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 89.991% (12210/13568)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.034% (12331/13696)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.046% (12448/13824)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.073% (12567/13952)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.078% (12683/14080)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.062% (12796/14208)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.046% (12909/14336)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.024% (13021/14464)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.036% (13138/14592)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.014% (13250/14720)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.032% (13368/14848)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.057% (13487/14976)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.062% (13603/15104)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.074% (13720/15232)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.091% (13838/15360)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.089% (13953/15488)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.106% (14071/15616)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.111% (14187/15744)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.108% (14302/15872)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.106% (14417/16000)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.086% (14529/16128)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.102% (14647/16256)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.076% (14758/16384)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.056% (14870/16512)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.072% (14988/16640)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.070% (15103/16768)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.027% (15211/16896)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.020% (15325/17024)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.048% (15445/17152)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.052% (15561/17280)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.068% (15679/17408)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.032% (15788/17536)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.065% (15909/17664)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.085% (16028/17792)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.078% (16142/17920)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.099% (16261/18048)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.102% (16377/18176)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.133% (16498/18304)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.148% (16616/18432)\n",
      "Train Epoch: 23 | Loss: 0.280 | Acc: 90.194% (16740/18560)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.181% (16853/18688)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.136% (16960/18816)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.124% (17073/18944)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.074% (17179/19072)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.073% (17294/19200)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.102% (17415/19328)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.121% (17534/19456)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.140% (17653/19584)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.168% (17774/19712)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.171% (17890/19840)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.159% (18003/19968)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.177% (18122/20096)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.145% (18231/20224)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.153% (18348/20352)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.142% (18461/20480)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.140% (18576/20608)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.133% (18690/20736)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.146% (18808/20864)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.172% (18929/20992)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.189% (19048/21120)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.211% (19168/21248)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.223% (19286/21376)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.239% (19405/21504)\n",
      "Train Epoch: 23 | Loss: 0.281 | Acc: 90.264% (19526/21632)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.248% (19638/21760)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.218% (19747/21888)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.225% (19864/22016)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.205% (19975/22144)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.221% (20094/22272)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.214% (20208/22400)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.203% (20321/22528)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.201% (20436/22656)\n",
      "Train Epoch: 23 | Loss: 0.282 | Acc: 90.212% (20554/22784)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.189% (20664/22912)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.161% (20773/23040)\n",
      "Train Epoch: 23 | Loss: 0.283 | Acc: 90.167% (20890/23168)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.153% (21002/23296)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.104% (21106/23424)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.124% (21226/23552)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.135% (21344/23680)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.150% (21463/23808)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.132% (21574/23936)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.135% (21690/24064)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.141% (21807/24192)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.160% (21927/24320)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.142% (22038/24448)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.157% (22157/24576)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.139% (22268/24704)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.142% (22384/24832)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.124% (22495/24960)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.127% (22611/25088)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.133% (22728/25216)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.144% (22846/25344)\n",
      "Train Epoch: 23 | Loss: 0.284 | Acc: 90.162% (22966/25472)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.148% (23078/25600)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.155% (23195/25728)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.145% (23308/25856)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.148% (23424/25984)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.146% (23539/26112)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.149% (23655/26240)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.151% (23771/26368)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.153% (23887/26496)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.159% (24004/26624)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.135% (24113/26752)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.134% (24228/26880)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.133% (24343/27008)\n",
      "Train Epoch: 23 | Loss: 0.285 | Acc: 90.131% (24458/27136)\n",
      "Train Epoch: 23 | Loss: 0.286 | Acc: 90.134% (24574/27264)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.096% (24679/27392)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.098% (24795/27520)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.079% (24905/27648)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.074% (25019/27776)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.048% (25127/27904)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.047% (25242/28032)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.032% (25353/28160)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.049% (25473/28288)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.037% (25585/28416)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.033% (25699/28544)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.036% (25815/28672)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.042% (25932/28800)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.044% (26048/28928)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.040% (26162/29056)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.049% (26280/29184)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.055% (26397/29312)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.054% (26512/29440)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.047% (26625/29568)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.056% (26743/29696)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.048% (26856/29824)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.041% (26969/29952)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.060% (27090/30080)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.066% (27207/30208)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.058% (27320/30336)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.060% (27436/30464)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.069% (27554/30592)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.055% (27665/30720)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.038% (27775/30848)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.047% (27893/30976)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.066% (28014/31104)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.065% (28129/31232)\n",
      "Train Epoch: 23 | Loss: 0.287 | Acc: 90.057% (28242/31360)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.041% (28352/31488)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.027% (28463/31616)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.014% (28574/31744)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.007% (28687/31872)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 89.997% (28799/32000)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.002% (28916/32128)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.014% (29035/32256)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 90.001% (29146/32384)\n",
      "Train Epoch: 23 | Loss: 0.288 | Acc: 89.998% (29260/32512)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.994% (29374/32640)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.978% (29484/32768)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.984% (29601/32896)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.983% (29716/33024)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.976% (29829/33152)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.967% (29941/33280)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.952% (30051/33408)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.930% (30159/33536)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.939% (30277/33664)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.962% (30400/33792)\n",
      "Train Epoch: 23 | Loss: 0.289 | Acc: 89.965% (30516/33920)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.947% (30625/34048)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.940% (30738/34176)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.937% (30852/34304)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.931% (30965/34432)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.910% (31073/34560)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.922% (31192/34688)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.913% (31304/34816)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.927% (31424/34944)\n",
      "Train Epoch: 23 | Loss: 0.290 | Acc: 89.912% (31534/35072)\n",
      "Train Epoch: 23 | Loss: 0.291 | Acc: 89.884% (31639/35200)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.881% (31753/35328)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.886% (31870/35456)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.877% (31982/35584)\n",
      "Train Epoch: 23 | Loss: 0.291 | Acc: 89.883% (32099/35712)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.883% (32214/35840)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.880% (32328/35968)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.866% (32438/36096)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.866% (32553/36224)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.866% (32668/36352)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.844% (32775/36480)\n",
      "Train Epoch: 23 | Loss: 0.292 | Acc: 89.838% (32888/36608)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.827% (32999/36736)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.817% (33110/36864)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.825% (33228/36992)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.822% (33342/37120)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.817% (33455/37248)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.817% (33570/37376)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.817% (33685/37504)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.817% (33800/37632)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.828% (33919/37760)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.833% (34036/37888)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.825% (34148/38016)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.825% (34263/38144)\n",
      "Train Epoch: 23 | Loss: 0.293 | Acc: 89.818% (34375/38272)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.799% (34483/38400)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.805% (34600/38528)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.805% (34715/38656)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.795% (34826/38784)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.797% (34942/38912)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.813% (35063/39040)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.821% (35181/39168)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.816% (35294/39296)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.823% (35412/39424)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.829% (35529/39552)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.821% (35641/39680)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.819% (35755/39808)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.829% (35874/39936)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.836% (35992/40064)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.824% (36102/40192)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.816% (36214/40320)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.821% (36331/40448)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.817% (36444/40576)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.807% (36555/40704)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.814% (36673/40832)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.822% (36791/40960)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.819% (36905/41088)\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 89.829% (37024/41216)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.820% (37135/41344)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.815% (37248/41472)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.815% (37363/41600)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.808% (37475/41728)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.810% (37591/41856)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.810% (37706/41984)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.818% (37824/42112)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.820% (37940/42240)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.808% (38050/42368)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.804% (38163/42496)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.806% (38279/42624)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.809% (38395/42752)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.811% (38511/42880)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.802% (38622/43008)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.800% (38736/43136)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.800% (38851/43264)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.802% (38967/43392)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.789% (39076/43520)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.789% (39191/43648)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.775% (39300/43776)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.785% (39419/43904)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.787% (39535/44032)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.796% (39654/44160)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.792% (39767/44288)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.774% (39874/44416)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.772% (39988/44544)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.759% (40097/44672)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.757% (40211/44800)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.764% (40329/44928)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.771% (40447/45056)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.766% (40560/45184)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.758% (40671/45312)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.758% (40786/45440)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.756% (40900/45568)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.761% (41017/45696)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.767% (41135/45824)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.774% (41253/45952)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.763% (41363/46080)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.762% (41477/46208)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.753% (41588/46336)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.758% (41705/46464)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.758% (41820/46592)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.747% (41930/46720)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.752% (42047/46848)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.767% (42169/46976)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.772% (42286/47104)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.763% (42397/47232)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.759% (42510/47360)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.762% (42626/47488)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.749% (42735/47616)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.749% (42850/47744)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.750% (42965/47872)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.756% (43083/48000)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.759% (43199/48128)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.761% (43315/48256)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.751% (43425/48384)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.753% (43541/48512)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.753% (43656/48640)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.749% (43769/48768)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.754% (43886/48896)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.754% (44001/49024)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.762% (44120/49152)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.775% (44241/49280)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.769% (44353/49408)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.773% (44470/49536)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.787% (44592/49664)\n",
      "Train Epoch: 23 | Loss: 0.296 | Acc: 89.788% (44707/49792)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.804% (44830/49920)\n",
      "Train Epoch: 23 | Loss: 0.295 | Acc: 89.808% (44904/50000)\n",
      "Test Epoch: 23 | Loss: 0.319 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 23 | Loss: 0.332 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 23 | Loss: 0.329 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 23 | Loss: 0.361 | Acc: 87.750% (351/400)\n",
      "Test Epoch: 23 | Loss: 0.357 | Acc: 87.800% (439/500)\n",
      "Test Epoch: 23 | Loss: 0.326 | Acc: 88.833% (533/600)\n",
      "Test Epoch: 23 | Loss: 0.335 | Acc: 89.000% (623/700)\n",
      "Test Epoch: 23 | Loss: 0.356 | Acc: 88.250% (706/800)\n",
      "Test Epoch: 23 | Loss: 0.388 | Acc: 87.222% (785/900)\n",
      "Test Epoch: 23 | Loss: 0.400 | Acc: 87.000% (870/1000)\n",
      "Test Epoch: 23 | Loss: 0.417 | Acc: 86.455% (951/1100)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.333% (1036/1200)\n",
      "Test Epoch: 23 | Loss: 0.416 | Acc: 86.462% (1124/1300)\n",
      "Test Epoch: 23 | Loss: 0.409 | Acc: 86.643% (1213/1400)\n",
      "Test Epoch: 23 | Loss: 0.404 | Acc: 86.533% (1298/1500)\n",
      "Test Epoch: 23 | Loss: 0.405 | Acc: 86.062% (1377/1600)\n",
      "Test Epoch: 23 | Loss: 0.396 | Acc: 86.588% (1472/1700)\n",
      "Test Epoch: 23 | Loss: 0.401 | Acc: 86.444% (1556/1800)\n",
      "Test Epoch: 23 | Loss: 0.406 | Acc: 86.474% (1643/1900)\n",
      "Test Epoch: 23 | Loss: 0.407 | Acc: 86.600% (1732/2000)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.524% (1817/2100)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.227% (1897/2200)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.304% (1985/2300)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.333% (2072/2400)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.240% (2156/2500)\n",
      "Test Epoch: 23 | Loss: 0.429 | Acc: 86.115% (2239/2600)\n",
      "Test Epoch: 23 | Loss: 0.425 | Acc: 86.259% (2329/2700)\n",
      "Test Epoch: 23 | Loss: 0.422 | Acc: 86.393% (2419/2800)\n",
      "Test Epoch: 23 | Loss: 0.422 | Acc: 86.448% (2507/2900)\n",
      "Test Epoch: 23 | Loss: 0.422 | Acc: 86.367% (2591/3000)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.387% (2678/3100)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.406% (2765/3200)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.455% (2853/3300)\n",
      "Test Epoch: 23 | Loss: 0.417 | Acc: 86.529% (2942/3400)\n",
      "Test Epoch: 23 | Loss: 0.423 | Acc: 86.371% (3023/3500)\n",
      "Test Epoch: 23 | Loss: 0.428 | Acc: 86.389% (3110/3600)\n",
      "Test Epoch: 23 | Loss: 0.428 | Acc: 86.432% (3198/3700)\n",
      "Test Epoch: 23 | Loss: 0.429 | Acc: 86.447% (3285/3800)\n",
      "Test Epoch: 23 | Loss: 0.428 | Acc: 86.513% (3374/3900)\n",
      "Test Epoch: 23 | Loss: 0.428 | Acc: 86.500% (3460/4000)\n",
      "Test Epoch: 23 | Loss: 0.429 | Acc: 86.415% (3543/4100)\n",
      "Test Epoch: 23 | Loss: 0.430 | Acc: 86.381% (3628/4200)\n",
      "Test Epoch: 23 | Loss: 0.424 | Acc: 86.488% (3719/4300)\n",
      "Test Epoch: 23 | Loss: 0.426 | Acc: 86.500% (3806/4400)\n",
      "Test Epoch: 23 | Loss: 0.423 | Acc: 86.556% (3895/4500)\n",
      "Test Epoch: 23 | Loss: 0.423 | Acc: 86.543% (3981/4600)\n",
      "Test Epoch: 23 | Loss: 0.422 | Acc: 86.532% (4067/4700)\n",
      "Test Epoch: 23 | Loss: 0.425 | Acc: 86.438% (4149/4800)\n",
      "Test Epoch: 23 | Loss: 0.425 | Acc: 86.510% (4239/4900)\n",
      "Test Epoch: 23 | Loss: 0.426 | Acc: 86.480% (4324/5000)\n",
      "Test Epoch: 23 | Loss: 0.421 | Acc: 86.647% (4419/5100)\n",
      "Test Epoch: 23 | Loss: 0.421 | Acc: 86.654% (4506/5200)\n",
      "Test Epoch: 23 | Loss: 0.422 | Acc: 86.604% (4590/5300)\n",
      "Test Epoch: 23 | Loss: 0.419 | Acc: 86.704% (4682/5400)\n",
      "Test Epoch: 23 | Loss: 0.418 | Acc: 86.655% (4766/5500)\n",
      "Test Epoch: 23 | Loss: 0.418 | Acc: 86.679% (4854/5600)\n",
      "Test Epoch: 23 | Loss: 0.418 | Acc: 86.684% (4941/5700)\n",
      "Test Epoch: 23 | Loss: 0.416 | Acc: 86.724% (5030/5800)\n",
      "Test Epoch: 23 | Loss: 0.416 | Acc: 86.746% (5118/5900)\n",
      "Test Epoch: 23 | Loss: 0.416 | Acc: 86.767% (5206/6000)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.787% (5294/6100)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.774% (5380/6200)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.810% (5469/6300)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.859% (5559/6400)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.862% (5646/6500)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.909% (5736/6600)\n",
      "Test Epoch: 23 | Loss: 0.408 | Acc: 87.000% (5829/6700)\n",
      "Test Epoch: 23 | Loss: 0.408 | Acc: 87.000% (5916/6800)\n",
      "Test Epoch: 23 | Loss: 0.408 | Acc: 87.000% (6003/6900)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.900% (6083/7000)\n",
      "Test Epoch: 23 | Loss: 0.412 | Acc: 86.845% (6166/7100)\n",
      "Test Epoch: 23 | Loss: 0.412 | Acc: 86.806% (6250/7200)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.877% (6342/7300)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.892% (6430/7400)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.840% (6513/7500)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.803% (6597/7600)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.753% (6680/7700)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.782% (6769/7800)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.785% (6856/7900)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.775% (6942/8000)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.815% (7032/8100)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.805% (7118/8200)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.819% (7206/8300)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.869% (7297/8400)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.812% (7379/8500)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.744% (7460/8600)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.701% (7543/8700)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.648% (7625/8800)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.674% (7714/8900)\n",
      "Test Epoch: 23 | Loss: 0.416 | Acc: 86.700% (7803/9000)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.692% (7889/9100)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.717% (7978/9200)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.742% (8067/9300)\n",
      "Test Epoch: 23 | Loss: 0.413 | Acc: 86.766% (8156/9400)\n",
      "Test Epoch: 23 | Loss: 0.412 | Acc: 86.800% (8246/9500)\n",
      "Test Epoch: 23 | Loss: 0.412 | Acc: 86.812% (8334/9600)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.866% (8426/9700)\n",
      "Test Epoch: 23 | Loss: 0.411 | Acc: 86.857% (8512/9800)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.879% (8601/9900)\n",
      "Test Epoch: 23 | Loss: 0.410 | Acc: 86.850% (8685/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 24 | Loss: 0.326 | Acc: 89.453% (229/256)\n",
      "Train Epoch: 24 | Loss: 0.298 | Acc: 90.885% (349/384)\n",
      "Train Epoch: 24 | Loss: 0.285 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 24 | Loss: 0.287 | Acc: 91.562% (586/640)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.927% (706/768)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 91.295% (818/896)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 91.406% (936/1024)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 91.406% (1053/1152)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.562% (1172/1280)\n",
      "Train Epoch: 24 | Loss: 0.265 | Acc: 91.548% (1289/1408)\n",
      "Train Epoch: 24 | Loss: 0.265 | Acc: 91.276% (1402/1536)\n",
      "Train Epoch: 24 | Loss: 0.258 | Acc: 91.647% (1525/1664)\n",
      "Train Epoch: 24 | Loss: 0.257 | Acc: 91.629% (1642/1792)\n",
      "Train Epoch: 24 | Loss: 0.260 | Acc: 91.406% (1755/1920)\n",
      "Train Epoch: 24 | Loss: 0.262 | Acc: 91.211% (1868/2048)\n",
      "Train Epoch: 24 | Loss: 0.266 | Acc: 90.947% (1979/2176)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.016% (2097/2304)\n",
      "Train Epoch: 24 | Loss: 0.267 | Acc: 91.036% (2214/2432)\n",
      "Train Epoch: 24 | Loss: 0.264 | Acc: 91.133% (2333/2560)\n",
      "Train Epoch: 24 | Loss: 0.266 | Acc: 91.109% (2449/2688)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.016% (2563/2816)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 90.965% (2678/2944)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.016% (2796/3072)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.031% (2913/3200)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.106% (3032/3328)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.001% (3145/3456)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.016% (3262/3584)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.083% (3381/3712)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.964% (3493/3840)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.053% (3613/3968)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 90.967% (3726/4096)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.027% (3845/4224)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.039% (3962/4352)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.027% (4078/4480)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 90.994% (4193/4608)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.047% (4312/4736)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.118% (4432/4864)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 91.026% (4544/4992)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.055% (4662/5120)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 91.025% (4777/5248)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.090% (4897/5376)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.097% (5014/5504)\n",
      "Train Epoch: 24 | Loss: 0.268 | Acc: 91.087% (5130/5632)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.007% (5242/5760)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 90.999% (5358/5888)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 90.974% (5473/6016)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 91.016% (5592/6144)\n",
      "Train Epoch: 24 | Loss: 0.270 | Acc: 91.071% (5712/6272)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.000% (5824/6400)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 90.993% (5940/6528)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.001% (6057/6656)\n",
      "Train Epoch: 24 | Loss: 0.269 | Acc: 91.067% (6178/6784)\n",
      "Train Epoch: 24 | Loss: 0.271 | Acc: 91.030% (6292/6912)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.994% (6406/7040)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.890% (6515/7168)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.954% (6636/7296)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.921% (6750/7424)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.983% (6871/7552)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.964% (6986/7680)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.984% (7104/7808)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.965% (7219/7936)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.935% (7333/8064)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.906% (7447/8192)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.889% (7562/8320)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.897% (7679/8448)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.823% (7789/8576)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.855% (7908/8704)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.863% (8025/8832)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.826% (8138/8960)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.735% (8246/9088)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.755% (8364/9216)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.786% (8483/9344)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.773% (8598/9472)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.688% (8706/9600)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.697% (8823/9728)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.645% (8934/9856)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.635% (9049/9984)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.655% (9167/10112)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.654% (9283/10240)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.596% (9393/10368)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.606% (9510/10496)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.559% (9621/10624)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.541% (9735/10752)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.570% (9854/10880)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.616% (9975/11008)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.661% (10096/11136)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.669% (10213/11264)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.678% (10330/11392)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.686% (10447/11520)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.711% (10566/11648)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.727% (10684/11776)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.743% (10802/11904)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.783% (10923/12032)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.765% (11037/12160)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.771% (11154/12288)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.746% (11267/12416)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.729% (11381/12544)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.704% (11494/12672)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.688% (11608/12800)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.695% (11725/12928)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.633% (11833/13056)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.655% (11952/13184)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.685% (12072/13312)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.707% (12191/13440)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.699% (12306/13568)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.683% (12420/13696)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.661% (12533/13824)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.668% (12650/13952)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.682% (12768/14080)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.709% (12888/14208)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.737% (13008/14336)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.763% (13128/14464)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.776% (13246/14592)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.734% (13356/14720)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.773% (13478/14848)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.759% (13592/14976)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.791% (13713/15104)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.783% (13828/15232)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.742% (13938/15360)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.735% (14053/15488)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.747% (14171/15616)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.777% (14292/15744)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.770% (14407/15872)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.756% (14521/16000)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.749% (14636/16128)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.773% (14756/16256)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.710% (14862/16384)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.716% (14979/16512)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.721% (15096/16640)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.732% (15214/16768)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.732% (15330/16896)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.748% (15449/17024)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.771% (15569/17152)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.758% (15683/17280)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.740% (15796/17408)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.768% (15917/17536)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.750% (16030/17664)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.732% (16143/17792)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.731% (16259/17920)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.708% (16371/18048)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.702% (16486/18176)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.691% (16600/18304)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.668% (16712/18432)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.679% (16830/18560)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.641% (16939/18688)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.641% (17055/18816)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.625% (17168/18944)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.635% (17286/19072)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.656% (17406/19200)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.672% (17525/19328)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.666% (17640/19456)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.691% (17761/19584)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.686% (17876/19712)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.691% (17993/19840)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.665% (18104/19968)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.665% (18220/20096)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.650% (18333/20224)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.650% (18449/20352)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.640% (18563/20480)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.649% (18681/20608)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.639% (18795/20736)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.644% (18912/20864)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.654% (19030/20992)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.663% (19148/21120)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.677% (19267/21248)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.672% (19382/21376)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.667% (19497/21504)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.648% (19609/21632)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.666% (19729/21760)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.643% (19840/21888)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.652% (19958/22016)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.657% (20075/22144)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.670% (20194/22272)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.665% (20309/22400)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.665% (20425/22528)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.674% (20543/22656)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.691% (20663/22784)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.690% (20779/22912)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.673% (20891/23040)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.651% (21002/23168)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.646% (21117/23296)\n",
      "Train Epoch: 24 | Loss: 0.272 | Acc: 90.655% (21235/23424)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.646% (21349/23552)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.629% (21461/23680)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.621% (21575/23808)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.625% (21692/23936)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.613% (21805/24064)\n",
      "Train Epoch: 24 | Loss: 0.273 | Acc: 90.625% (21924/24192)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.604% (22035/24320)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.605% (22151/24448)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.560% (22256/24576)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.568% (22374/24704)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.565% (22489/24832)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.577% (22608/24960)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.569% (22722/25088)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.573% (22839/25216)\n",
      "Train Epoch: 24 | Loss: 0.274 | Acc: 90.582% (22957/25344)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.558% (23067/25472)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.539% (23178/25600)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.536% (23293/25728)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.528% (23407/25856)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.533% (23524/25984)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.529% (23639/26112)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.537% (23757/26240)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.534% (23872/26368)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.531% (23987/26496)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.535% (24104/26624)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.539% (24221/26752)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.517% (24331/26880)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.518% (24447/27008)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.511% (24561/27136)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.515% (24678/27264)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.519% (24795/27392)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.512% (24909/27520)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.516% (25026/27648)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.492% (25135/27776)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.503% (25254/27904)\n",
      "Train Epoch: 24 | Loss: 0.275 | Acc: 90.507% (25371/28032)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.504% (25486/28160)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.487% (25597/28288)\n",
      "Train Epoch: 24 | Loss: 0.276 | Acc: 90.460% (25705/28416)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.467% (25823/28544)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.454% (25935/28672)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.441% (26047/28800)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.431% (26160/28928)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.439% (26278/29056)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.437% (26393/29184)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.431% (26507/29312)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.421% (26620/29440)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.425% (26737/29568)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.426% (26853/29696)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.431% (26970/29824)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.438% (27088/29952)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.439% (27204/30080)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.446% (27322/30208)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.454% (27440/30336)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.454% (27556/30464)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.442% (27668/30592)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.436% (27782/30720)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.456% (27904/30848)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.431% (28012/30976)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.422% (28125/31104)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.391% (28231/31232)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.386% (28345/31360)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.368% (28455/31488)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.378% (28574/31616)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.386% (28692/31744)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.396% (28811/31872)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.403% (28929/32000)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.388% (29040/32128)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.402% (29160/32256)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.418% (29281/32384)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.419% (29397/32512)\n",
      "Train Epoch: 24 | Loss: 0.277 | Acc: 90.407% (29509/32640)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.393% (29620/32768)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.373% (29729/32896)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.362% (29841/33024)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.369% (29959/33152)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.358% (30071/33280)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.341% (30181/33408)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.351% (30300/33536)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.367% (30421/33664)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.365% (30536/33792)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.363% (30651/33920)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.358% (30765/34048)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.356% (30880/34176)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.357% (30996/34304)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.355% (31111/34432)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.350% (31225/34560)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.354% (31342/34688)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.352% (31457/34816)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.359% (31575/34944)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.351% (31688/35072)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.352% (31804/35200)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.348% (31918/35328)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.334% (32029/35456)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.327% (32142/35584)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.334% (32260/35712)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.338% (32377/35840)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.314% (32484/35968)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.309% (32598/36096)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.294% (32708/36224)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.298% (32825/36352)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.285% (32936/36480)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.273% (33047/36608)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.277% (33164/36736)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.278% (33280/36864)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.287% (33399/36992)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.291% (33516/37120)\n",
      "Train Epoch: 24 | Loss: 0.282 | Acc: 90.273% (33625/37248)\n",
      "Train Epoch: 24 | Loss: 0.282 | Acc: 90.275% (33741/37376)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.276% (33857/37504)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.272% (33971/37632)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.273% (34087/37760)\n",
      "Train Epoch: 24 | Loss: 0.282 | Acc: 90.258% (34197/37888)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.273% (34318/38016)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.263% (34430/38144)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.267% (34547/38272)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.268% (34663/38400)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.280% (34783/38528)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.271% (34895/38656)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.272% (35011/38784)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.258% (35121/38912)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.269% (35241/39040)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.257% (35352/39168)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.256% (35467/39296)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.262% (35585/39424)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.261% (35700/39552)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.275% (35821/39680)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.266% (35933/39808)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.262% (36047/39936)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.266% (36164/40064)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.262% (36278/40192)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.268% (36396/40320)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.271% (36513/40448)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.273% (36629/40576)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.274% (36745/40704)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.282% (36864/40832)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.278% (36978/40960)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.287% (37097/41088)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.285% (37212/41216)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.282% (37326/41344)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.287% (37444/41472)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.296% (37563/41600)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.299% (37680/41728)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.310% (37800/41856)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.289% (37907/41984)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.285% (38021/42112)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.277% (38133/42240)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.283% (38251/42368)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.300% (38374/42496)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.301% (38490/42624)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.286% (38599/42752)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.287% (38715/42880)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.297% (38835/43008)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.305% (38954/43136)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.299% (39067/43264)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.298% (39182/43392)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.299% (39298/43520)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.307% (39417/43648)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.305% (39532/43776)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.302% (39646/43904)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.309% (39765/44032)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.294% (39874/44160)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.293% (39989/44288)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.292% (40104/44416)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.293% (40220/44544)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.289% (40334/44672)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.290% (40450/44800)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.293% (40567/44928)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.292% (40682/45056)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.289% (40796/45184)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.283% (40909/45312)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.288% (41027/45440)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.274% (41136/45568)\n",
      "Train Epoch: 24 | Loss: 0.281 | Acc: 90.281% (41255/45696)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.285% (41372/45824)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.290% (41490/45952)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.291% (41606/46080)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.290% (41721/46208)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.293% (41838/46336)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.296% (41955/46464)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.294% (42070/46592)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.300% (42188/46720)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.298% (42303/46848)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.297% (42418/46976)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.302% (42536/47104)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.299% (42650/47232)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.310% (42771/47360)\n",
      "Train Epoch: 24 | Loss: 0.280 | Acc: 90.311% (42887/47488)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.320% (43007/47616)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.334% (43129/47744)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.339% (43247/47872)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.331% (43359/48000)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.340% (43479/48128)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.345% (43597/48256)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.344% (43712/48384)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.351% (43831/48512)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.350% (43946/48640)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.354% (44064/48768)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.367% (44186/48896)\n",
      "Train Epoch: 24 | Loss: 0.278 | Acc: 90.370% (44303/49024)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.369% (44418/49152)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.367% (44533/49280)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.360% (44645/49408)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.348% (44755/49536)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.349% (44871/49664)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.340% (44982/49792)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.343% (45099/49920)\n",
      "Train Epoch: 24 | Loss: 0.279 | Acc: 90.346% (45173/50000)\n",
      "Test Epoch: 24 | Loss: 0.295 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 24 | Loss: 0.348 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 24 | Loss: 0.362 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 24 | Loss: 0.374 | Acc: 87.250% (349/400)\n",
      "Test Epoch: 24 | Loss: 0.352 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 24 | Loss: 0.323 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 24 | Loss: 0.331 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 24 | Loss: 0.352 | Acc: 87.250% (698/800)\n",
      "Test Epoch: 24 | Loss: 0.373 | Acc: 86.889% (782/900)\n",
      "Test Epoch: 24 | Loss: 0.382 | Acc: 86.600% (866/1000)\n",
      "Test Epoch: 24 | Loss: 0.376 | Acc: 86.909% (956/1100)\n",
      "Test Epoch: 24 | Loss: 0.395 | Acc: 86.583% (1039/1200)\n",
      "Test Epoch: 24 | Loss: 0.388 | Acc: 86.769% (1128/1300)\n",
      "Test Epoch: 24 | Loss: 0.388 | Acc: 86.857% (1216/1400)\n",
      "Test Epoch: 24 | Loss: 0.393 | Acc: 86.467% (1297/1500)\n",
      "Test Epoch: 24 | Loss: 0.399 | Acc: 86.375% (1382/1600)\n",
      "Test Epoch: 24 | Loss: 0.401 | Acc: 86.588% (1472/1700)\n",
      "Test Epoch: 24 | Loss: 0.408 | Acc: 86.444% (1556/1800)\n",
      "Test Epoch: 24 | Loss: 0.410 | Acc: 86.368% (1641/1900)\n",
      "Test Epoch: 24 | Loss: 0.411 | Acc: 86.350% (1727/2000)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.333% (1813/2100)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.273% (1898/2200)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.304% (1985/2300)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.333% (2072/2400)\n",
      "Test Epoch: 24 | Loss: 0.421 | Acc: 86.280% (2157/2500)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 86.192% (2241/2600)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 86.222% (2328/2700)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 86.214% (2414/2800)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 86.207% (2500/2900)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 86.300% (2589/3000)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.258% (2674/3100)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 86.281% (2761/3200)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.212% (2845/3300)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.176% (2930/3400)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 86.114% (3014/3500)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 86.111% (3100/3600)\n",
      "Test Epoch: 24 | Loss: 0.448 | Acc: 86.027% (3183/3700)\n",
      "Test Epoch: 24 | Loss: 0.447 | Acc: 85.974% (3267/3800)\n",
      "Test Epoch: 24 | Loss: 0.448 | Acc: 85.923% (3351/3900)\n",
      "Test Epoch: 24 | Loss: 0.444 | Acc: 86.000% (3440/4000)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 85.976% (3525/4100)\n",
      "Test Epoch: 24 | Loss: 0.449 | Acc: 85.952% (3610/4200)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 86.070% (3701/4300)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 86.114% (3789/4400)\n",
      "Test Epoch: 24 | Loss: 0.441 | Acc: 86.178% (3878/4500)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 86.261% (3968/4600)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.255% (4054/4700)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 86.229% (4139/4800)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.265% (4227/4900)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 86.180% (4309/5000)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 86.275% (4400/5100)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 86.250% (4485/5200)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 86.151% (4566/5300)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.185% (4654/5400)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 86.127% (4737/5500)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 86.214% (4828/5600)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 86.193% (4913/5700)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 86.293% (5005/5800)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 86.322% (5093/5900)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 86.267% (5176/6000)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 86.246% (5261/6100)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 86.242% (5347/6200)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 86.286% (5436/6300)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 86.391% (5529/6400)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 86.323% (5611/6500)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 86.379% (5701/6600)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.463% (5793/6700)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.456% (5879/6800)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.449% (5965/6900)\n",
      "Test Epoch: 24 | Loss: 0.429 | Acc: 86.414% (6049/7000)\n",
      "Test Epoch: 24 | Loss: 0.429 | Acc: 86.451% (6138/7100)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 86.417% (6222/7200)\n",
      "Test Epoch: 24 | Loss: 0.429 | Acc: 86.466% (6312/7300)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.527% (6403/7400)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.520% (6489/7500)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.539% (6577/7600)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.506% (6661/7700)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.474% (6745/7800)\n",
      "Test Epoch: 24 | Loss: 0.425 | Acc: 86.506% (6834/7900)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 86.550% (6924/8000)\n",
      "Test Epoch: 24 | Loss: 0.422 | Acc: 86.580% (7013/8100)\n",
      "Test Epoch: 24 | Loss: 0.423 | Acc: 86.512% (7094/8200)\n",
      "Test Epoch: 24 | Loss: 0.423 | Acc: 86.494% (7179/8300)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 86.476% (7264/8400)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.400% (7344/8500)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.395% (7430/8600)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.368% (7514/8700)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 86.398% (7603/8800)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.382% (7688/8900)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.400% (7776/9000)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.407% (7863/9100)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.457% (7954/9200)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.495% (8044/9300)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 86.479% (8129/9400)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 86.453% (8213/9500)\n",
      "Test Epoch: 24 | Loss: 0.425 | Acc: 86.479% (8302/9600)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 86.536% (8394/9700)\n",
      "Test Epoch: 24 | Loss: 0.425 | Acc: 86.531% (8480/9800)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 86.535% (8567/9900)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 86.560% (8656/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 25 | Loss: 0.322 | Acc: 89.844% (230/256)\n",
      "Train Epoch: 25 | Loss: 0.311 | Acc: 90.885% (349/384)\n",
      "Train Epoch: 25 | Loss: 0.299 | Acc: 90.820% (465/512)\n",
      "Train Epoch: 25 | Loss: 0.290 | Acc: 90.781% (581/640)\n",
      "Train Epoch: 25 | Loss: 0.278 | Acc: 90.755% (697/768)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 91.071% (816/896)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 91.309% (935/1024)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 91.233% (1051/1152)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.250% (1168/1280)\n",
      "Train Epoch: 25 | Loss: 0.259 | Acc: 91.193% (1284/1408)\n",
      "Train Epoch: 25 | Loss: 0.256 | Acc: 91.471% (1405/1536)\n",
      "Train Epoch: 25 | Loss: 0.258 | Acc: 91.406% (1521/1664)\n",
      "Train Epoch: 25 | Loss: 0.261 | Acc: 91.071% (1632/1792)\n",
      "Train Epoch: 25 | Loss: 0.258 | Acc: 91.302% (1753/1920)\n",
      "Train Epoch: 25 | Loss: 0.252 | Acc: 91.455% (1873/2048)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 91.085% (1982/2176)\n",
      "Train Epoch: 25 | Loss: 0.261 | Acc: 91.146% (2100/2304)\n",
      "Train Epoch: 25 | Loss: 0.261 | Acc: 91.036% (2214/2432)\n",
      "Train Epoch: 25 | Loss: 0.260 | Acc: 91.055% (2331/2560)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.071% (2448/2688)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.945% (2561/2816)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.931% (2677/2944)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 91.016% (2796/3072)\n",
      "Train Epoch: 25 | Loss: 0.272 | Acc: 90.812% (2906/3200)\n",
      "Train Epoch: 25 | Loss: 0.272 | Acc: 90.865% (3024/3328)\n",
      "Train Epoch: 25 | Loss: 0.274 | Acc: 90.856% (3140/3456)\n",
      "Train Epoch: 25 | Loss: 0.273 | Acc: 90.932% (3259/3584)\n",
      "Train Epoch: 25 | Loss: 0.271 | Acc: 90.894% (3374/3712)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 90.938% (3492/3840)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.927% (3608/3968)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.894% (3723/4096)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.933% (3841/4224)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.970% (3959/4352)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.915% (4073/4480)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.994% (4193/4608)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.921% (4306/4736)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.933% (4423/4864)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.946% (4540/4992)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 91.035% (4661/5120)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.101% (4781/5248)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.164% (4901/5376)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.134% (5016/5504)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 91.033% (5127/5632)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 91.094% (5247/5760)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.135% (5366/5888)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.090% (5480/6016)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.146% (5600/6144)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 91.040% (5710/6272)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.125% (5832/6400)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.161% (5951/6528)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.166% (6068/6656)\n",
      "Train Epoch: 25 | Loss: 0.261 | Acc: 91.215% (6188/6784)\n",
      "Train Epoch: 25 | Loss: 0.261 | Acc: 91.233% (6306/6912)\n",
      "Train Epoch: 25 | Loss: 0.262 | Acc: 91.108% (6414/7040)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.071% (6528/7168)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.064% (6644/7296)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 91.016% (6757/7424)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.088% (6879/7552)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.081% (6995/7680)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.060% (7110/7808)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.978% (7220/7936)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.935% (7333/8064)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.942% (7450/8192)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.950% (7567/8320)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.921% (7681/8448)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.882% (7794/8576)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.855% (7908/8704)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.795% (8019/8832)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.792% (8135/8960)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.746% (8247/9088)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.788% (8367/9216)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.860% (8490/9344)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.857% (8606/9472)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.875% (8724/9600)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.882% (8841/9728)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.869% (8956/9856)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.845% (9070/9984)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.823% (9184/10112)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.811% (9299/10240)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.799% (9414/10368)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.806% (9531/10496)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.776% (9644/10624)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.802% (9763/10752)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.827% (9882/10880)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.852% (10001/11008)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.841% (10116/11136)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.803% (10228/11264)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.783% (10342/11392)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.807% (10461/11520)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.797% (10576/11648)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.795% (10692/11776)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.810% (10810/11904)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.841% (10930/12032)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.855% (11048/12160)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.845% (11163/12288)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.842% (11279/12416)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.864% (11398/12544)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.854% (11513/12672)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.875% (11632/12800)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.888% (11750/12928)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.901% (11868/13056)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.928% (11988/13184)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.941% (12106/13312)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.952% (12224/13440)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.986% (12345/13568)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 91.027% (12467/13696)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.994% (12579/13824)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.955% (12690/13952)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.973% (12809/14080)\n",
      "Train Epoch: 25 | Loss: 0.263 | Acc: 90.970% (12925/14208)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.932% (13036/14336)\n",
      "Train Epoch: 25 | Loss: 0.264 | Acc: 90.929% (13152/14464)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.899% (13264/14592)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.883% (13378/14720)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.894% (13496/14848)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.839% (13604/14976)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.863% (13724/15104)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.868% (13841/15232)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.866% (13957/15360)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.851% (14071/15488)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.836% (14185/15616)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.847% (14303/15744)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.858% (14421/15872)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.850% (14536/16000)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.848% (14652/16128)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.853% (14769/16256)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.863% (14887/16384)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.849% (15001/16512)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.835% (15115/16640)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.840% (15232/16768)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.856% (15351/16896)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.872% (15470/17024)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.852% (15583/17152)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.862% (15701/17280)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.832% (15812/17408)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.836% (15929/17536)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.834% (16045/17664)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.833% (16161/17792)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.859% (16282/17920)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.847% (16396/18048)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.867% (16516/18176)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.860% (16631/18304)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.831% (16742/18432)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.835% (16859/18560)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.855% (16979/18688)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.843% (17093/18816)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.820% (17205/18944)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.803% (17318/19072)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.786% (17431/19200)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.822% (17554/19328)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.841% (17674/19456)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.860% (17794/19584)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.889% (17916/19712)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.897% (18034/19840)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.860% (18143/19968)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.839% (18255/20096)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.848% (18373/20224)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.836% (18487/20352)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.835% (18603/20480)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.843% (18721/20608)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.832% (18835/20736)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.865% (18958/20864)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.873% (19076/20992)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.895% (19197/21120)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.893% (19313/21248)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.882% (19427/21376)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.871% (19541/21504)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.870% (19657/21632)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.864% (19772/21760)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.863% (19888/21888)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (20002/22016)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.869% (20122/22144)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.876% (20240/22272)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.884% (20358/22400)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.891% (20476/22528)\n",
      "Train Epoch: 25 | Loss: 0.265 | Acc: 90.894% (20593/22656)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.871% (20704/22784)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (20816/22912)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.851% (20932/23040)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.862% (21051/23168)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.865% (21168/23296)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.868% (21285/23424)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.859% (21399/23552)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.836% (21510/23680)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (21630/23808)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.846% (21745/23936)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.849% (21862/24064)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (21979/24192)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.868% (22099/24320)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.879% (22218/24448)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.857% (22329/24576)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (22444/24704)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.822% (22553/24832)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.809% (22666/24960)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.820% (22785/25088)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.835% (22905/25216)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.850% (23025/25344)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.849% (23141/25472)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.855% (23259/25600)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.854% (23375/25728)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.849% (23490/25856)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.841% (23604/25984)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.813% (23713/26112)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.819% (23831/26240)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.834% (23951/26368)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.810% (24061/26496)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.824% (24181/26624)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.808% (24293/26752)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.811% (24410/26880)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.821% (24529/27008)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.828% (24647/27136)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.801% (24756/27264)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.815% (24876/27392)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.836% (24998/27520)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.846% (25117/27648)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.819% (25226/27776)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.790% (25334/27904)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.796% (25452/28032)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.788% (25566/28160)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.788% (25682/28288)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.769% (25793/28416)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.786% (25914/28544)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.778% (26028/28672)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.781% (26145/28800)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.784% (26262/28928)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.787% (26379/29056)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.765% (26489/29184)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.761% (26604/29312)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.764% (26721/29440)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.764% (26837/29568)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.763% (26953/29696)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.762% (27069/29824)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.759% (27184/29952)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.745% (27296/30080)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.757% (27416/30208)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.747% (27529/30336)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.750% (27646/30464)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.746% (27761/30592)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.736% (27874/30720)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 90.725% (27987/30848)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 90.728% (28104/30976)\n",
      "Train Epoch: 25 | Loss: 0.270 | Acc: 90.731% (28221/31104)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.731% (28337/31232)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.753% (28460/31360)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.765% (28580/31488)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.767% (28697/31616)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.767% (28813/31744)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.776% (28932/31872)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.772% (29047/32000)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.774% (29164/32128)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.780% (29282/32256)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.792% (29402/32384)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.810% (29524/32512)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.824% (29645/32640)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.823% (29761/32768)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.838% (29882/32896)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.840% (29999/33024)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.860% (30122/33152)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.847% (30234/33280)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.838% (30347/33408)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.843% (30465/33536)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.842% (30581/33664)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.850% (30700/33792)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.825% (30808/33920)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.825% (30924/34048)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.830% (31042/34176)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.841% (31162/34304)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.852% (31282/34432)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.839% (31394/34560)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.838% (31510/34688)\n",
      "Train Epoch: 25 | Loss: 0.266 | Acc: 90.843% (31628/34816)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.837% (31742/34944)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.825% (31854/35072)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.824% (31970/35200)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.826% (32087/35328)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.828% (32204/35456)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.833% (32322/35584)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.832% (32438/35712)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.831% (32554/35840)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.817% (32665/35968)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.805% (32777/36096)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.802% (32892/36224)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.804% (33009/36352)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.814% (33129/36480)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.811% (33244/36608)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.813% (33361/36736)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.799% (33472/36864)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.790% (33585/36992)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.800% (33705/37120)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.802% (33822/37248)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.804% (33939/37376)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.798% (34053/37504)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.784% (34164/37632)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.773% (34276/37760)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.778% (34394/37888)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.783% (34512/38016)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.788% (34630/38144)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.797% (34750/38272)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.802% (34868/38400)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.807% (34986/38528)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.806% (35102/38656)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.803% (35217/38784)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.813% (35337/38912)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.817% (35455/39040)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.816% (35571/39168)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.821% (35689/39296)\n",
      "Train Epoch: 25 | Loss: 0.267 | Acc: 90.825% (35807/39424)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.812% (35918/39552)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.811% (36034/39680)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.816% (36152/39808)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.818% (36269/39936)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.817% (36385/40064)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.817% (36501/40192)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.809% (36614/40320)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.818% (36734/40448)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.798% (36842/40576)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.797% (36958/40704)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.796% (37074/40832)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.789% (37187/40960)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.803% (37309/41088)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.792% (37421/41216)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.789% (37536/41344)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.784% (37650/41472)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.788% (37768/41600)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.795% (37887/41728)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.799% (38005/41856)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.804% (38123/41984)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.796% (38236/42112)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.786% (38348/42240)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.774% (38459/42368)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (38577/42496)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.773% (38691/42624)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.782% (38811/42752)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.784% (38928/42880)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (39042/43008)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.773% (39156/43136)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (39274/43264)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.786% (39394/43392)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.781% (39508/43520)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.783% (39625/43648)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.792% (39745/43776)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.796% (39863/43904)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.800% (39981/44032)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.788% (40092/44160)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.781% (40205/44288)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.794% (40327/44416)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.798% (40445/44544)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.795% (40560/44672)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.790% (40674/44800)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.787% (40789/44928)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.789% (40906/45056)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.789% (41022/45184)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.799% (41143/45312)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.792% (41256/45440)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.790% (41371/45568)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.798% (41491/45696)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.797% (41607/45824)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.812% (41730/45952)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.818% (41849/46080)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.811% (41962/46208)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.808% (42077/46336)\n",
      "Train Epoch: 25 | Loss: 0.268 | Acc: 90.799% (42189/46464)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.790% (42301/46592)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.788% (42416/46720)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.783% (42530/46848)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.780% (42645/46976)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (42760/47104)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.777% (42876/47232)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.775% (42991/47360)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.766% (43103/47488)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (43225/47616)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.776% (43340/47744)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.773% (43455/47872)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.775% (43572/48000)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.775% (43688/48128)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.770% (43802/48256)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.772% (43919/48384)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (44038/48512)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.779% (44155/48640)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.771% (44267/48768)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.776% (44386/48896)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (44503/49024)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.782% (44621/49152)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.785% (44739/49280)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.785% (44855/49408)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.782% (44970/49536)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.778% (45084/49664)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.772% (45197/49792)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.769% (45312/49920)\n",
      "Train Epoch: 25 | Loss: 0.269 | Acc: 90.766% (45383/50000)\n",
      "Test Epoch: 25 | Loss: 0.312 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 25 | Loss: 0.388 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 25 | Loss: 0.409 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 25 | Loss: 0.379 | Acc: 87.600% (438/500)\n",
      "Test Epoch: 25 | Loss: 0.361 | Acc: 88.000% (528/600)\n",
      "Test Epoch: 25 | Loss: 0.374 | Acc: 88.143% (617/700)\n",
      "Test Epoch: 25 | Loss: 0.401 | Acc: 87.125% (697/800)\n",
      "Test Epoch: 25 | Loss: 0.420 | Acc: 86.778% (781/900)\n",
      "Test Epoch: 25 | Loss: 0.433 | Acc: 86.500% (865/1000)\n",
      "Test Epoch: 25 | Loss: 0.464 | Acc: 85.727% (943/1100)\n",
      "Test Epoch: 25 | Loss: 0.485 | Acc: 85.333% (1024/1200)\n",
      "Test Epoch: 25 | Loss: 0.489 | Acc: 85.077% (1106/1300)\n",
      "Test Epoch: 25 | Loss: 0.482 | Acc: 85.214% (1193/1400)\n",
      "Test Epoch: 25 | Loss: 0.482 | Acc: 85.133% (1277/1500)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.188% (1363/1600)\n",
      "Test Epoch: 25 | Loss: 0.473 | Acc: 85.353% (1451/1700)\n",
      "Test Epoch: 25 | Loss: 0.488 | Acc: 85.222% (1534/1800)\n",
      "Test Epoch: 25 | Loss: 0.489 | Acc: 85.316% (1621/1900)\n",
      "Test Epoch: 25 | Loss: 0.493 | Acc: 85.350% (1707/2000)\n",
      "Test Epoch: 25 | Loss: 0.490 | Acc: 85.381% (1793/2100)\n",
      "Test Epoch: 25 | Loss: 0.498 | Acc: 85.091% (1872/2200)\n",
      "Test Epoch: 25 | Loss: 0.499 | Acc: 85.130% (1958/2300)\n",
      "Test Epoch: 25 | Loss: 0.496 | Acc: 85.167% (2044/2400)\n",
      "Test Epoch: 25 | Loss: 0.497 | Acc: 85.360% (2134/2500)\n",
      "Test Epoch: 25 | Loss: 0.507 | Acc: 85.154% (2214/2600)\n",
      "Test Epoch: 25 | Loss: 0.498 | Acc: 85.370% (2305/2700)\n",
      "Test Epoch: 25 | Loss: 0.494 | Acc: 85.286% (2388/2800)\n",
      "Test Epoch: 25 | Loss: 0.493 | Acc: 85.414% (2477/2900)\n",
      "Test Epoch: 25 | Loss: 0.491 | Acc: 85.500% (2565/3000)\n",
      "Test Epoch: 25 | Loss: 0.492 | Acc: 85.387% (2647/3100)\n",
      "Test Epoch: 25 | Loss: 0.490 | Acc: 85.344% (2731/3200)\n",
      "Test Epoch: 25 | Loss: 0.492 | Acc: 85.273% (2814/3300)\n",
      "Test Epoch: 25 | Loss: 0.494 | Acc: 85.118% (2894/3400)\n",
      "Test Epoch: 25 | Loss: 0.502 | Acc: 85.029% (2976/3500)\n",
      "Test Epoch: 25 | Loss: 0.503 | Acc: 85.028% (3061/3600)\n",
      "Test Epoch: 25 | Loss: 0.502 | Acc: 85.000% (3145/3700)\n",
      "Test Epoch: 25 | Loss: 0.505 | Acc: 84.895% (3226/3800)\n",
      "Test Epoch: 25 | Loss: 0.504 | Acc: 84.923% (3312/3900)\n",
      "Test Epoch: 25 | Loss: 0.503 | Acc: 85.000% (3400/4000)\n",
      "Test Epoch: 25 | Loss: 0.501 | Acc: 85.024% (3486/4100)\n",
      "Test Epoch: 25 | Loss: 0.502 | Acc: 84.905% (3566/4200)\n",
      "Test Epoch: 25 | Loss: 0.498 | Acc: 85.023% (3656/4300)\n",
      "Test Epoch: 25 | Loss: 0.498 | Acc: 85.114% (3745/4400)\n",
      "Test Epoch: 25 | Loss: 0.496 | Acc: 85.133% (3831/4500)\n",
      "Test Epoch: 25 | Loss: 0.495 | Acc: 85.087% (3914/4600)\n",
      "Test Epoch: 25 | Loss: 0.495 | Acc: 85.043% (3997/4700)\n",
      "Test Epoch: 25 | Loss: 0.498 | Acc: 84.958% (4078/4800)\n",
      "Test Epoch: 25 | Loss: 0.495 | Acc: 85.122% (4171/4900)\n",
      "Test Epoch: 25 | Loss: 0.497 | Acc: 85.080% (4254/5000)\n",
      "Test Epoch: 25 | Loss: 0.494 | Acc: 85.137% (4342/5100)\n",
      "Test Epoch: 25 | Loss: 0.493 | Acc: 85.173% (4429/5200)\n",
      "Test Epoch: 25 | Loss: 0.491 | Acc: 85.189% (4515/5300)\n",
      "Test Epoch: 25 | Loss: 0.492 | Acc: 85.167% (4599/5400)\n",
      "Test Epoch: 25 | Loss: 0.494 | Acc: 85.182% (4685/5500)\n",
      "Test Epoch: 25 | Loss: 0.495 | Acc: 85.196% (4771/5600)\n",
      "Test Epoch: 25 | Loss: 0.492 | Acc: 85.228% (4858/5700)\n",
      "Test Epoch: 25 | Loss: 0.488 | Acc: 85.345% (4950/5800)\n",
      "Test Epoch: 25 | Loss: 0.488 | Acc: 85.305% (5033/5900)\n",
      "Test Epoch: 25 | Loss: 0.487 | Acc: 85.283% (5117/6000)\n",
      "Test Epoch: 25 | Loss: 0.485 | Acc: 85.393% (5209/6100)\n",
      "Test Epoch: 25 | Loss: 0.484 | Acc: 85.403% (5295/6200)\n",
      "Test Epoch: 25 | Loss: 0.482 | Acc: 85.397% (5380/6300)\n",
      "Test Epoch: 25 | Loss: 0.482 | Acc: 85.484% (5471/6400)\n",
      "Test Epoch: 25 | Loss: 0.482 | Acc: 85.431% (5553/6500)\n",
      "Test Epoch: 25 | Loss: 0.481 | Acc: 85.485% (5642/6600)\n",
      "Test Epoch: 25 | Loss: 0.479 | Acc: 85.552% (5732/6700)\n",
      "Test Epoch: 25 | Loss: 0.479 | Acc: 85.529% (5816/6800)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.507% (5900/6900)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.471% (5983/7000)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.521% (6072/7100)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.514% (6157/7200)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.616% (6250/7300)\n",
      "Test Epoch: 25 | Loss: 0.473 | Acc: 85.649% (6338/7400)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.547% (6416/7500)\n",
      "Test Epoch: 25 | Loss: 0.474 | Acc: 85.579% (6504/7600)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.584% (6590/7700)\n",
      "Test Epoch: 25 | Loss: 0.476 | Acc: 85.551% (6673/7800)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.506% (6755/7900)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.537% (6843/8000)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.543% (6929/8100)\n",
      "Test Epoch: 25 | Loss: 0.474 | Acc: 85.524% (7013/8200)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.506% (7097/8300)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.512% (7183/8400)\n",
      "Test Epoch: 25 | Loss: 0.479 | Acc: 85.424% (7261/8500)\n",
      "Test Epoch: 25 | Loss: 0.480 | Acc: 85.407% (7345/8600)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.425% (7432/8700)\n",
      "Test Epoch: 25 | Loss: 0.478 | Acc: 85.420% (7517/8800)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.427% (7603/8900)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.433% (7689/9000)\n",
      "Test Epoch: 25 | Loss: 0.477 | Acc: 85.418% (7773/9100)\n",
      "Test Epoch: 25 | Loss: 0.476 | Acc: 85.446% (7861/9200)\n",
      "Test Epoch: 25 | Loss: 0.476 | Acc: 85.419% (7944/9300)\n",
      "Test Epoch: 25 | Loss: 0.475 | Acc: 85.415% (8029/9400)\n",
      "Test Epoch: 25 | Loss: 0.474 | Acc: 85.389% (8112/9500)\n",
      "Test Epoch: 25 | Loss: 0.473 | Acc: 85.427% (8201/9600)\n",
      "Test Epoch: 25 | Loss: 0.470 | Acc: 85.485% (8292/9700)\n",
      "Test Epoch: 25 | Loss: 0.471 | Acc: 85.480% (8377/9800)\n",
      "Test Epoch: 25 | Loss: 0.471 | Acc: 85.505% (8465/9900)\n",
      "Test Epoch: 25 | Loss: 0.469 | Acc: 85.530% (8553/10000)\n",
      "\n",
      "Epoch: 26\n",
      "Train Epoch: 26 | Loss: 0.231 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 26 | Loss: 0.240 | Acc: 93.359% (239/256)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 91.667% (352/384)\n",
      "Train Epoch: 26 | Loss: 0.253 | Acc: 91.797% (470/512)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.875% (588/640)\n",
      "Train Epoch: 26 | Loss: 0.238 | Acc: 92.448% (710/768)\n",
      "Train Epoch: 26 | Loss: 0.232 | Acc: 92.411% (828/896)\n",
      "Train Epoch: 26 | Loss: 0.233 | Acc: 92.480% (947/1024)\n",
      "Train Epoch: 26 | Loss: 0.241 | Acc: 92.014% (1060/1152)\n",
      "Train Epoch: 26 | Loss: 0.234 | Acc: 92.188% (1180/1280)\n",
      "Train Epoch: 26 | Loss: 0.229 | Acc: 92.401% (1301/1408)\n",
      "Train Epoch: 26 | Loss: 0.229 | Acc: 92.318% (1418/1536)\n",
      "Train Epoch: 26 | Loss: 0.234 | Acc: 92.067% (1532/1664)\n",
      "Train Epoch: 26 | Loss: 0.240 | Acc: 92.076% (1650/1792)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 92.031% (1767/1920)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 92.041% (1885/2048)\n",
      "Train Epoch: 26 | Loss: 0.250 | Acc: 91.958% (2001/2176)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 92.014% (2120/2304)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 92.023% (2238/2432)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.875% (2352/2560)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.815% (2468/2688)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.832% (2586/2816)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.712% (2700/2944)\n",
      "Train Epoch: 26 | Loss: 0.251 | Acc: 91.829% (2821/3072)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.906% (2941/3200)\n",
      "Train Epoch: 26 | Loss: 0.250 | Acc: 91.857% (3057/3328)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.985% (3179/3456)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 92.104% (3301/3584)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 92.134% (3420/3712)\n",
      "Train Epoch: 26 | Loss: 0.241 | Acc: 92.161% (3539/3840)\n",
      "Train Epoch: 26 | Loss: 0.240 | Acc: 92.137% (3656/3968)\n",
      "Train Epoch: 26 | Loss: 0.239 | Acc: 92.188% (3776/4096)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 92.045% (3888/4224)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 92.004% (4004/4352)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.920% (4118/4480)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.927% (4236/4608)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.871% (4351/4736)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.838% (4467/4864)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.847% (4585/4992)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.816% (4701/5120)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.749% (4815/5248)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 91.797% (4935/5376)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.661% (5045/5504)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.708% (5165/5632)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.701% (5282/5760)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.695% (5399/5888)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.672% (5515/6016)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.699% (5634/6144)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.693% (5751/6272)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 91.719% (5870/6400)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 91.743% (5989/6528)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 91.752% (6107/6656)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 91.701% (6221/6784)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 91.681% (6337/6912)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 91.705% (6456/7040)\n",
      "Train Epoch: 26 | Loss: 0.242 | Acc: 91.713% (6574/7168)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.626% (6685/7296)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.608% (6801/7424)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.631% (6920/7552)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.667% (7040/7680)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.650% (7156/7808)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.646% (7273/7936)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.667% (7392/8064)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.663% (7509/8192)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.659% (7626/8320)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.667% (7744/8448)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 91.709% (7865/8576)\n",
      "Train Epoch: 26 | Loss: 0.243 | Acc: 91.716% (7983/8704)\n",
      "Train Epoch: 26 | Loss: 0.244 | Acc: 91.723% (8101/8832)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.663% (8213/8960)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.670% (8331/9088)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.710% (8452/9216)\n",
      "Train Epoch: 26 | Loss: 0.245 | Acc: 91.738% (8572/9344)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.670% (8683/9472)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.719% (8805/9600)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.704% (8921/9728)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.670% (9035/9856)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.677% (9153/9984)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.663% (9269/10112)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.650% (9385/10240)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.676% (9505/10368)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.663% (9621/10496)\n",
      "Train Epoch: 26 | Loss: 0.246 | Acc: 91.632% (9735/10624)\n",
      "Train Epoch: 26 | Loss: 0.247 | Acc: 91.611% (9850/10752)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.535% (9959/10880)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.506% (10073/11008)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.523% (10192/11136)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.495% (10306/11264)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.494% (10423/11392)\n",
      "Train Epoch: 26 | Loss: 0.248 | Acc: 91.493% (10540/11520)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.484% (10656/11648)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.483% (10773/11776)\n",
      "Train Epoch: 26 | Loss: 0.250 | Acc: 91.448% (10886/11904)\n",
      "Train Epoch: 26 | Loss: 0.249 | Acc: 91.473% (11006/12032)\n",
      "Train Epoch: 26 | Loss: 0.251 | Acc: 91.398% (11114/12160)\n",
      "Train Epoch: 26 | Loss: 0.251 | Acc: 91.406% (11232/12288)\n",
      "Train Epoch: 26 | Loss: 0.251 | Acc: 91.366% (11344/12416)\n",
      "Train Epoch: 26 | Loss: 0.251 | Acc: 91.319% (11455/12544)\n",
      "Train Epoch: 26 | Loss: 0.252 | Acc: 91.288% (11568/12672)\n",
      "Train Epoch: 26 | Loss: 0.253 | Acc: 91.273% (11683/12800)\n",
      "Train Epoch: 26 | Loss: 0.253 | Acc: 91.259% (11798/12928)\n",
      "Train Epoch: 26 | Loss: 0.253 | Acc: 91.299% (11920/13056)\n",
      "Train Epoch: 26 | Loss: 0.253 | Acc: 91.308% (12038/13184)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.256% (12148/13312)\n",
      "Train Epoch: 26 | Loss: 0.254 | Acc: 91.280% (12268/13440)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.244% (12380/13568)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.224% (12494/13696)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.218% (12610/13824)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.220% (12727/13952)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.236% (12846/14080)\n",
      "Train Epoch: 26 | Loss: 0.255 | Acc: 91.216% (12960/14208)\n",
      "Train Epoch: 26 | Loss: 0.256 | Acc: 91.169% (13070/14336)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.157% (13185/14464)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.139% (13299/14592)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.094% (13409/14720)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.083% (13524/14848)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.032% (13633/14976)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.049% (13752/15104)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.032% (13866/15232)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.035% (13983/15360)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.006% (14095/15488)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 90.990% (14209/15616)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 90.993% (14326/15744)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 90.978% (14440/15872)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 90.969% (14555/16000)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 90.997% (14676/16128)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 90.988% (14791/16256)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 90.997% (14909/16384)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 90.994% (15025/16512)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.022% (15146/16640)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.031% (15264/16768)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.033% (15381/16896)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.024% (15496/17024)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.027% (15613/17152)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.024% (15729/17280)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.039% (15848/17408)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.076% (15971/17536)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.118% (16095/17664)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.125% (16213/17792)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.116% (16328/17920)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.107% (16443/18048)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.115% (16561/18176)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.073% (16670/18304)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.064% (16785/18432)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.061% (16901/18560)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.080% (17021/18688)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.071% (17136/18816)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.068% (17252/18944)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.060% (17367/19072)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.094% (17490/19200)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.085% (17605/19328)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.118% (17728/19456)\n",
      "Train Epoch: 26 | Loss: 0.256 | Acc: 91.131% (17847/19584)\n",
      "Train Epoch: 26 | Loss: 0.256 | Acc: 91.132% (17964/19712)\n",
      "Train Epoch: 26 | Loss: 0.256 | Acc: 91.129% (18080/19840)\n",
      "Train Epoch: 26 | Loss: 0.256 | Acc: 91.101% (18191/19968)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.098% (18307/20096)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.065% (18417/20224)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.057% (18532/20352)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.064% (18650/20480)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.067% (18767/20608)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.078% (18886/20736)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.071% (19001/20864)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.073% (19118/20992)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.094% (19239/21120)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.077% (19352/21248)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.069% (19467/21376)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.081% (19586/21504)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.087% (19704/21632)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.094% (19822/21760)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.082% (19936/21888)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.061% (20048/22016)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.068% (20166/22144)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.056% (20280/22272)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.058% (20397/22400)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.064% (20515/22528)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.084% (20636/22656)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.086% (20753/22784)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.070% (20866/22912)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.068% (20982/23040)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.061% (21097/23168)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.054% (21212/23296)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.056% (21329/23424)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.045% (21443/23552)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.026% (21555/23680)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.011% (21668/23808)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.018% (21786/23936)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.020% (21903/24064)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.014% (22018/24192)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.003% (22132/24320)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.018% (22252/24448)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 90.999% (22364/24576)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.010% (22483/24704)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.004% (22598/24832)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.002% (22714/24960)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.032% (22838/25088)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.026% (22953/25216)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.024% (23069/25344)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.033% (23188/25472)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.055% (23310/25600)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.029% (23420/25728)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.035% (23538/25856)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.052% (23659/25984)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.054% (23776/26112)\n",
      "Train Epoch: 26 | Loss: 0.257 | Acc: 91.059% (23894/26240)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.038% (24005/26368)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.048% (24124/26496)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.049% (24241/26624)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.036% (24354/26752)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.031% (24469/26880)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.021% (24583/27008)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.034% (24703/27136)\n",
      "Train Epoch: 26 | Loss: 0.258 | Acc: 91.050% (24824/27264)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.063% (24944/27392)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.054% (25058/27520)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.063% (25177/27648)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.043% (25288/27776)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.044% (25405/27904)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.035% (25519/28032)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.048% (25639/28160)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.032% (25751/28288)\n",
      "Train Epoch: 26 | Loss: 0.259 | Acc: 91.040% (25870/28416)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.031% (25984/28544)\n",
      "Train Epoch: 26 | Loss: 0.260 | Acc: 91.030% (26100/28672)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 91.007% (26210/28800)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 91.009% (26327/28928)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 91.007% (26443/29056)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 91.009% (26560/29184)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 90.997% (26673/29312)\n",
      "Train Epoch: 26 | Loss: 0.261 | Acc: 90.992% (26788/29440)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.977% (26900/29568)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.982% (27018/29696)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.957% (27127/29824)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.959% (27244/29952)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.957% (27360/30080)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.963% (27478/30208)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.971% (27597/30336)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.957% (27709/30464)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.945% (27822/30592)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.941% (27937/30720)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.949% (28056/30848)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.948% (28172/30976)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.959% (28292/31104)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.958% (28408/31232)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.941% (28519/31360)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.939% (28635/31488)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.941% (28752/31616)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.927% (28864/31744)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.914% (28976/31872)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.916% (29093/32000)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.905% (29206/32128)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.901% (29321/32256)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.900% (29437/32384)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.883% (29548/32512)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.879% (29663/32640)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.887% (29782/32768)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.868% (29892/32896)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.873% (30010/33024)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.860% (30122/33152)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.877% (30244/33280)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.870% (30358/33408)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.881% (30478/33536)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.875% (30592/33664)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.874% (30708/33792)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.881% (30827/33920)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.881% (30943/34048)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.885% (31061/34176)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.884% (31177/34304)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.869% (31288/34432)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.883% (31409/34560)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.882% (31525/34688)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.884% (31642/34816)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.877% (31756/34944)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.867% (31869/35072)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.872% (31987/35200)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.854% (32097/35328)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.856% (32214/35456)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.855% (32330/35584)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.857% (32447/35712)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.859% (32564/35840)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.856% (32679/35968)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.869% (32800/36096)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.865% (32915/36224)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.864% (33031/36352)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.880% (33153/36480)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.876% (33268/36608)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.875% (33384/36736)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.883% (33503/36864)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.885% (33620/36992)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.881% (33735/37120)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.867% (33846/37248)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.874% (33965/37376)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.870% (34080/37504)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.872% (34197/37632)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.877% (34315/37760)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.886% (34435/37888)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.888% (34552/38016)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.879% (34665/38144)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.889% (34785/38272)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.885% (34900/38400)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.885% (35016/38528)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.889% (35134/38656)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.891% (35251/38784)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.885% (35365/38912)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.863% (35473/39040)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.873% (35593/39168)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.877% (35711/39296)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.889% (35832/39424)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.888% (35948/39552)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.895% (36067/39680)\n",
      "Train Epoch: 26 | Loss: 0.265 | Acc: 90.886% (36180/39808)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.895% (36300/39936)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.900% (36418/40064)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.909% (36538/40192)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.913% (36656/40320)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.924% (36777/40448)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.921% (36892/40576)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.922% (37009/40704)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.929% (37128/40832)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.935% (37247/40960)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.941% (37366/41088)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.936% (37480/41216)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.944% (37600/41344)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.941% (37715/41472)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.933% (37828/41600)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.939% (37947/41728)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.928% (38059/41856)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.932% (38177/41984)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.946% (38299/42112)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.952% (38418/42240)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.960% (38538/42368)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.969% (38658/42496)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.963% (38772/42624)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.948% (38882/42752)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.924% (38988/42880)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.920% (39103/43008)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.917% (39218/43136)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.919% (39335/43264)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.920% (39452/43392)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.905% (39562/43520)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.909% (39680/43648)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.906% (39795/43776)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.903% (39910/43904)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.902% (40026/44032)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.906% (40144/44160)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.900% (40258/44288)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.897% (40373/44416)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.903% (40492/44544)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.903% (40608/44672)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.906% (40726/44800)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.912% (40845/44928)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.916% (40963/45056)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.924% (41083/45184)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.927% (41201/45312)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.911% (41310/45440)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.915% (41428/45568)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.912% (41543/45696)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.911% (41659/45824)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.919% (41779/45952)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.911% (41892/46080)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.904% (42005/46208)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.901% (42120/46336)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.892% (42232/46464)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.885% (42345/46592)\n",
      "Train Epoch: 26 | Loss: 0.262 | Acc: 90.893% (42465/46720)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.885% (42578/46848)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.876% (42690/46976)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.882% (42809/47104)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.888% (42928/47232)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.878% (43040/47360)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.878% (43156/47488)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.871% (43269/47616)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.866% (43383/47744)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.865% (43499/47872)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.871% (43618/48000)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.872% (43735/48128)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.867% (43849/48256)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.863% (43963/48384)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.856% (44076/48512)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.853% (44191/48640)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.857% (44309/48768)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.856% (44425/48896)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.851% (44539/49024)\n",
      "Train Epoch: 26 | Loss: 0.263 | Acc: 90.849% (44654/49152)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.834% (44763/49280)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.829% (44877/49408)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.827% (44992/49536)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.832% (45111/49664)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.838% (45230/49792)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.829% (45342/49920)\n",
      "Train Epoch: 26 | Loss: 0.264 | Acc: 90.828% (45414/50000)\n",
      "Test Epoch: 26 | Loss: 0.387 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 26 | Loss: 0.385 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 26 | Loss: 0.332 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 26 | Loss: 0.352 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 26 | Loss: 0.342 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 26 | Loss: 0.315 | Acc: 89.000% (534/600)\n",
      "Test Epoch: 26 | Loss: 0.342 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.500% (700/800)\n",
      "Test Epoch: 26 | Loss: 0.406 | Acc: 86.556% (779/900)\n",
      "Test Epoch: 26 | Loss: 0.402 | Acc: 86.700% (867/1000)\n",
      "Test Epoch: 26 | Loss: 0.419 | Acc: 86.455% (951/1100)\n",
      "Test Epoch: 26 | Loss: 0.430 | Acc: 86.333% (1036/1200)\n",
      "Test Epoch: 26 | Loss: 0.434 | Acc: 85.846% (1116/1300)\n",
      "Test Epoch: 26 | Loss: 0.431 | Acc: 86.143% (1206/1400)\n",
      "Test Epoch: 26 | Loss: 0.432 | Acc: 85.867% (1288/1500)\n",
      "Test Epoch: 26 | Loss: 0.441 | Acc: 85.688% (1371/1600)\n",
      "Test Epoch: 26 | Loss: 0.442 | Acc: 85.824% (1459/1700)\n",
      "Test Epoch: 26 | Loss: 0.446 | Acc: 85.889% (1546/1800)\n",
      "Test Epoch: 26 | Loss: 0.445 | Acc: 86.000% (1634/1900)\n",
      "Test Epoch: 26 | Loss: 0.462 | Acc: 85.800% (1716/2000)\n",
      "Test Epoch: 26 | Loss: 0.461 | Acc: 85.762% (1801/2100)\n",
      "Test Epoch: 26 | Loss: 0.463 | Acc: 85.636% (1884/2200)\n",
      "Test Epoch: 26 | Loss: 0.463 | Acc: 85.522% (1967/2300)\n",
      "Test Epoch: 26 | Loss: 0.463 | Acc: 85.375% (2049/2400)\n",
      "Test Epoch: 26 | Loss: 0.466 | Acc: 85.560% (2139/2500)\n",
      "Test Epoch: 26 | Loss: 0.480 | Acc: 85.346% (2219/2600)\n",
      "Test Epoch: 26 | Loss: 0.477 | Acc: 85.370% (2305/2700)\n",
      "Test Epoch: 26 | Loss: 0.478 | Acc: 85.357% (2390/2800)\n",
      "Test Epoch: 26 | Loss: 0.479 | Acc: 85.414% (2477/2900)\n",
      "Test Epoch: 26 | Loss: 0.479 | Acc: 85.367% (2561/3000)\n",
      "Test Epoch: 26 | Loss: 0.481 | Acc: 85.387% (2647/3100)\n",
      "Test Epoch: 26 | Loss: 0.475 | Acc: 85.500% (2736/3200)\n",
      "Test Epoch: 26 | Loss: 0.476 | Acc: 85.455% (2820/3300)\n",
      "Test Epoch: 26 | Loss: 0.478 | Acc: 85.441% (2905/3400)\n",
      "Test Epoch: 26 | Loss: 0.486 | Acc: 85.314% (2986/3500)\n",
      "Test Epoch: 26 | Loss: 0.486 | Acc: 85.417% (3075/3600)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.432% (3161/3700)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.447% (3247/3800)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.359% (3329/3900)\n",
      "Test Epoch: 26 | Loss: 0.488 | Acc: 85.325% (3413/4000)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.244% (3495/4100)\n",
      "Test Epoch: 26 | Loss: 0.500 | Acc: 85.119% (3575/4200)\n",
      "Test Epoch: 26 | Loss: 0.495 | Acc: 85.233% (3665/4300)\n",
      "Test Epoch: 26 | Loss: 0.496 | Acc: 85.205% (3749/4400)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.311% (3839/4500)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.239% (3921/4600)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.128% (4001/4700)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.083% (4084/4800)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.184% (4174/4900)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.060% (4253/5000)\n",
      "Test Epoch: 26 | Loss: 0.488 | Acc: 85.118% (4341/5100)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.115% (4426/5200)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.019% (4506/5300)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.037% (4592/5400)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.018% (4676/5500)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.054% (4763/5600)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.070% (4849/5700)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.121% (4937/5800)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.136% (5023/5900)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.083% (5105/6000)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.098% (5191/6100)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.113% (5277/6200)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.143% (5364/6300)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.219% (5454/6400)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.215% (5539/6500)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.197% (5623/6600)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.269% (5713/6700)\n",
      "Test Epoch: 26 | Loss: 0.489 | Acc: 85.221% (5795/6800)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.174% (5877/6900)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.200% (5964/7000)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.169% (6047/7100)\n",
      "Test Epoch: 26 | Loss: 0.496 | Acc: 85.083% (6126/7200)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.137% (6215/7300)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.176% (6303/7400)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.173% (6388/7500)\n",
      "Test Epoch: 26 | Loss: 0.496 | Acc: 85.158% (6472/7600)\n",
      "Test Epoch: 26 | Loss: 0.495 | Acc: 85.195% (6560/7700)\n",
      "Test Epoch: 26 | Loss: 0.495 | Acc: 85.179% (6644/7800)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.253% (6735/7900)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.275% (6822/8000)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.321% (6911/8100)\n",
      "Test Epoch: 26 | Loss: 0.491 | Acc: 85.293% (6994/8200)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.277% (7078/8300)\n",
      "Test Epoch: 26 | Loss: 0.492 | Acc: 85.274% (7163/8400)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.259% (7247/8500)\n",
      "Test Epoch: 26 | Loss: 0.497 | Acc: 85.198% (7327/8600)\n",
      "Test Epoch: 26 | Loss: 0.498 | Acc: 85.149% (7408/8700)\n",
      "Test Epoch: 26 | Loss: 0.498 | Acc: 85.170% (7495/8800)\n",
      "Test Epoch: 26 | Loss: 0.498 | Acc: 85.169% (7580/8900)\n",
      "Test Epoch: 26 | Loss: 0.497 | Acc: 85.189% (7667/9000)\n",
      "Test Epoch: 26 | Loss: 0.497 | Acc: 85.231% (7756/9100)\n",
      "Test Epoch: 26 | Loss: 0.495 | Acc: 85.272% (7845/9200)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.290% (7932/9300)\n",
      "Test Epoch: 26 | Loss: 0.494 | Acc: 85.298% (8018/9400)\n",
      "Test Epoch: 26 | Loss: 0.493 | Acc: 85.347% (8108/9500)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.406% (8199/9600)\n",
      "Test Epoch: 26 | Loss: 0.488 | Acc: 85.464% (8290/9700)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.439% (8373/9800)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.424% (8457/9900)\n",
      "Test Epoch: 26 | Loss: 0.490 | Acc: 85.430% (8543/10000)\n",
      "\n",
      "Epoch: 27\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 27 | Loss: 0.235 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 27 | Loss: 0.287 | Acc: 89.844% (345/384)\n",
      "Train Epoch: 27 | Loss: 0.265 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 27 | Loss: 0.269 | Acc: 91.250% (584/640)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.797% (705/768)\n",
      "Train Epoch: 27 | Loss: 0.261 | Acc: 91.518% (820/896)\n",
      "Train Epoch: 27 | Loss: 0.253 | Acc: 91.797% (940/1024)\n",
      "Train Epoch: 27 | Loss: 0.268 | Acc: 91.059% (1049/1152)\n",
      "Train Epoch: 27 | Loss: 0.268 | Acc: 90.938% (1164/1280)\n",
      "Train Epoch: 27 | Loss: 0.274 | Acc: 90.412% (1273/1408)\n",
      "Train Epoch: 27 | Loss: 0.268 | Acc: 90.560% (1391/1536)\n",
      "Train Epoch: 27 | Loss: 0.266 | Acc: 90.445% (1505/1664)\n",
      "Train Epoch: 27 | Loss: 0.265 | Acc: 90.513% (1622/1792)\n",
      "Train Epoch: 27 | Loss: 0.267 | Acc: 90.521% (1738/1920)\n",
      "Train Epoch: 27 | Loss: 0.260 | Acc: 90.820% (1860/2048)\n",
      "Train Epoch: 27 | Loss: 0.260 | Acc: 90.855% (1977/2176)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 90.799% (2092/2304)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 90.872% (2210/2432)\n",
      "Train Epoch: 27 | Loss: 0.252 | Acc: 91.016% (2330/2560)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.183% (2451/2688)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.122% (2566/2816)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 90.965% (2678/2944)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.048% (2797/3072)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 90.844% (2907/3200)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 90.835% (3023/3328)\n",
      "Train Epoch: 27 | Loss: 0.257 | Acc: 90.856% (3140/3456)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 90.960% (3260/3584)\n",
      "Train Epoch: 27 | Loss: 0.261 | Acc: 90.921% (3375/3712)\n",
      "Train Epoch: 27 | Loss: 0.261 | Acc: 90.964% (3493/3840)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.079% (3614/3968)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.089% (3731/4096)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.122% (3849/4224)\n",
      "Train Epoch: 27 | Loss: 0.260 | Acc: 91.131% (3966/4352)\n",
      "Train Epoch: 27 | Loss: 0.260 | Acc: 91.161% (4084/4480)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.233% (4204/4608)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.174% (4318/4736)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.242% (4438/4864)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.146% (4550/4992)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.172% (4668/5120)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.159% (4784/5248)\n",
      "Train Epoch: 27 | Loss: 0.257 | Acc: 91.220% (4904/5376)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.225% (5021/5504)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.140% (5133/5632)\n",
      "Train Epoch: 27 | Loss: 0.259 | Acc: 91.146% (5250/5760)\n",
      "Train Epoch: 27 | Loss: 0.261 | Acc: 90.999% (5358/5888)\n",
      "Train Epoch: 27 | Loss: 0.260 | Acc: 91.090% (5480/6016)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.162% (5601/6144)\n",
      "Train Epoch: 27 | Loss: 0.257 | Acc: 91.215% (5721/6272)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 91.234% (5839/6400)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.253% (5957/6528)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.286% (6076/6656)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.288% (6193/6784)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.262% (6308/6912)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 91.250% (6424/7040)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.323% (6546/7168)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 91.297% (6661/7296)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.231% (6773/7424)\n",
      "Train Epoch: 27 | Loss: 0.258 | Acc: 91.247% (6891/7552)\n",
      "Train Epoch: 27 | Loss: 0.257 | Acc: 91.250% (7008/7680)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 91.291% (7128/7808)\n",
      "Train Epoch: 27 | Loss: 0.257 | Acc: 91.318% (7247/7936)\n",
      "Train Epoch: 27 | Loss: 0.256 | Acc: 91.295% (7362/8064)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.309% (7480/8192)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.334% (7599/8320)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.359% (7718/8448)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.336% (7833/8576)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.337% (7950/8704)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.395% (8072/8832)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.384% (8188/8960)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.406% (8307/9088)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.406% (8424/9216)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.396% (8540/9344)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.417% (8659/9472)\n",
      "Train Epoch: 27 | Loss: 0.255 | Acc: 91.375% (8772/9600)\n",
      "Train Epoch: 27 | Loss: 0.254 | Acc: 91.417% (8893/9728)\n",
      "Train Epoch: 27 | Loss: 0.253 | Acc: 91.437% (9012/9856)\n",
      "Train Epoch: 27 | Loss: 0.252 | Acc: 91.466% (9132/9984)\n",
      "Train Epoch: 27 | Loss: 0.252 | Acc: 91.505% (9253/10112)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.553% (9375/10240)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.532% (9490/10368)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.540% (9608/10496)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.500% (9721/10624)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.471% (9835/10752)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.434% (9948/10880)\n",
      "Train Epoch: 27 | Loss: 0.252 | Acc: 91.388% (10060/11008)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.424% (10181/11136)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.406% (10296/11264)\n",
      "Train Epoch: 27 | Loss: 0.251 | Acc: 91.433% (10416/11392)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.441% (10534/11520)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.475% (10655/11648)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.500% (10775/11776)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.507% (10893/11904)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.531% (11013/12032)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.530% (11130/12160)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.536% (11248/12288)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.527% (11364/12416)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.566% (11486/12544)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.533% (11599/12672)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.531% (11716/12800)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.545% (11835/12928)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.552% (11953/13056)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.550% (12070/13184)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.541% (12186/13312)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.555% (12305/13440)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.554% (12422/13568)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.538% (12537/13696)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.536% (12654/13824)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.550% (12773/13952)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.534% (12888/14080)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.561% (13009/14208)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.560% (13126/14336)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.531% (13239/14464)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.530% (13356/14592)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.522% (13472/14720)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.514% (13588/14848)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.480% (13700/14976)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.446% (13812/15104)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.465% (13932/15232)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.471% (14050/15360)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.471% (14167/15488)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.464% (14283/15616)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.444% (14397/15744)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.450% (14515/15872)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.475% (14636/16000)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.481% (14754/16128)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.492% (14873/16256)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.504% (14992/16384)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.497% (15108/16512)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.502% (15226/16640)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.531% (15348/16768)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.548% (15468/16896)\n",
      "Train Epoch: 27 | Loss: 0.245 | Acc: 91.535% (15583/17024)\n",
      "Train Epoch: 27 | Loss: 0.245 | Acc: 91.546% (15702/17152)\n",
      "Train Epoch: 27 | Loss: 0.245 | Acc: 91.545% (15819/17280)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.504% (15929/17408)\n",
      "Train Epoch: 27 | Loss: 0.246 | Acc: 91.480% (16042/17536)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.480% (16159/17664)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.451% (16271/17792)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.451% (16388/17920)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.456% (16506/18048)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.461% (16624/18176)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.483% (16745/18304)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.471% (16860/18432)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.487% (16980/18560)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.476% (17095/18688)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.465% (17210/18816)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.464% (17327/18944)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.480% (17447/19072)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.458% (17560/19200)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (17671/19328)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.411% (17785/19456)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (17905/19584)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.421% (18021/19712)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.431% (18140/19840)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.426% (18256/19968)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.446% (18377/20096)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.436% (18492/20224)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.431% (18608/20352)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.436% (18726/20480)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.426% (18841/20608)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.445% (18962/20736)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.445% (19079/20864)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.449% (19197/20992)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.444% (19313/21120)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.444% (19430/21248)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.453% (19549/21376)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.434% (19662/21504)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.420% (19776/21632)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.434% (19896/21760)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.429% (20012/21888)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.402% (20123/22016)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.411% (20242/22144)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.397% (20356/22272)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.402% (20474/22400)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.397% (20590/22528)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.419% (20712/22656)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.419% (20829/22784)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.437% (20950/22912)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.437% (21067/23040)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.454% (21188/23168)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.453% (21305/23296)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.436% (21418/23424)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (21533/23552)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (21650/23680)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (21767/23808)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.435% (21886/23936)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (22001/24064)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.402% (22112/24192)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.414% (22232/24320)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.414% (22349/24448)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.439% (22472/24576)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.443% (22590/24704)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.459% (22711/24832)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.422% (22819/24960)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.438% (22940/25088)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.434% (23056/25216)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.454% (23178/25344)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.438% (23291/25472)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.441% (23409/25600)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.433% (23524/25728)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.433% (23641/25856)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.425% (23756/25984)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.437% (23876/26112)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.410% (23986/26240)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.410% (24103/26368)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.421% (24223/26496)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.436% (24344/26624)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.444% (24463/26752)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.440% (24579/26880)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.465% (24703/27008)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.465% (24820/27136)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.458% (24935/27264)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.472% (25056/27392)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.464% (25171/27520)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.475% (25291/27648)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.475% (25408/27776)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.456% (25520/27904)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.449% (25635/28032)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.445% (25751/28160)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.442% (25867/28288)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.438% (25983/28416)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.431% (26098/28544)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.431% (26215/28672)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.448% (26337/28800)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.441% (26452/28928)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.437% (26568/29056)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.423% (26681/29184)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.434% (26801/29312)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.430% (26917/29440)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.427% (27033/29568)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.410% (27145/29696)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.423% (27266/29824)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.433% (27386/29952)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.400% (27493/30080)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.380% (27604/30208)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.377% (27720/30336)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.383% (27839/30464)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.390% (27958/30592)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.396% (28077/30720)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.384% (28190/30848)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.371% (28303/30976)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.364% (28418/31104)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.349% (28530/31232)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.358% (28650/31360)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.349% (28764/31488)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.343% (28879/31616)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.334% (28993/31744)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.337% (29111/31872)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.334% (29227/32000)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.316% (29338/32128)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.310% (29453/32256)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.311% (29570/32384)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.314% (29688/32512)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.311% (29804/32640)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.306% (29919/32768)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.321% (30041/32896)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.334% (30162/33024)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.331% (30278/33152)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.343% (30399/33280)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.352% (30519/33408)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.344% (30633/33536)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.350% (30752/33664)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.350% (30869/33792)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.353% (30987/33920)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.353% (31104/34048)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.359% (31223/34176)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.357% (31339/34304)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.357% (31456/34432)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.366% (31576/34560)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.366% (31693/34688)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.380% (31815/34816)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.372% (31929/34944)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.378% (32048/35072)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.372% (32163/35200)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.386% (32285/35328)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.384% (32401/35456)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.381% (32517/35584)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.381% (32634/35712)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.381% (32751/35840)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.398% (32874/35968)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.392% (32989/36096)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.381% (33102/36224)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.368% (33214/36352)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.357% (33327/36480)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.365% (33447/36608)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.371% (33566/36736)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.379% (33686/36864)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.352% (33793/36992)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.371% (33917/37120)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.371% (34034/37248)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.385% (34156/37376)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.377% (34270/37504)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.366% (34383/37632)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.353% (34495/37760)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.346% (34609/37888)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.356% (34730/38016)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.370% (34852/38144)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.372% (34970/38272)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.388% (35093/38400)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.378% (35206/38528)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.378% (35323/38656)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.380% (35441/38784)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.365% (35552/38912)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.360% (35667/39040)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.348% (35779/39168)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.348% (35896/39296)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.348% (36013/39424)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.348% (36130/39552)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.351% (36248/39680)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.356% (36367/39808)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.364% (36487/39936)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.369% (36606/40064)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.371% (36724/40192)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.376% (36843/40320)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.382% (36962/40448)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.379% (37078/40576)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.374% (37193/40704)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.372% (37309/40832)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.375% (37427/40960)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.372% (37543/41088)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.377% (37662/41216)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.372% (37777/41344)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.365% (37891/41472)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.370% (38010/41600)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.373% (38128/41728)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.370% (38244/41856)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.375% (38363/41984)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.383% (38483/42112)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.375% (38597/42240)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.380% (38716/42368)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.385% (38835/42496)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.380% (38950/42624)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.381% (39067/42752)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.376% (39182/42880)\n",
      "Train Epoch: 27 | Loss: 0.247 | Acc: 91.385% (39303/43008)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.371% (39414/43136)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.367% (39529/43264)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.367% (39646/43392)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.360% (39760/43520)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.351% (39873/43648)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.342% (39986/43776)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.336% (40100/43904)\n",
      "Train Epoch: 27 | Loss: 0.248 | Acc: 91.338% (40218/44032)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.322% (40328/44160)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.305% (40437/44288)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.307% (40555/44416)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.307% (40672/44544)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.301% (40786/44672)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.310% (40907/44800)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.322% (41029/44928)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.315% (41143/45056)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.318% (41261/45184)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.314% (41376/45312)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.303% (41488/45440)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.303% (41605/45568)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.297% (41719/45696)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.308% (41841/45824)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.295% (41952/45952)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.309% (42075/46080)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.309% (42192/46208)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.307% (42308/46336)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.303% (42423/46464)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.305% (42541/46592)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.304% (42657/46720)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.293% (42769/46848)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.296% (42887/46976)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.300% (43006/47104)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.300% (43123/47232)\n",
      "Train Epoch: 27 | Loss: 0.250 | Acc: 91.290% (43235/47360)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.301% (43357/47488)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.305% (43476/47616)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.312% (43596/47744)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.316% (43715/47872)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.323% (43835/48000)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.325% (43953/48128)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.325% (44070/48256)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.319% (44184/48384)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.316% (44299/48512)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.314% (44415/48640)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.316% (44533/48768)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.324% (44654/48896)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.314% (44766/49024)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.323% (44887/49152)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.315% (45000/49280)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.327% (45123/49408)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.330% (45241/49536)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.332% (45359/49664)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.332% (45476/49792)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.324% (45589/49920)\n",
      "Train Epoch: 27 | Loss: 0.249 | Acc: 91.330% (45665/50000)\n",
      "Test Epoch: 27 | Loss: 0.478 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 27 | Loss: 0.382 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 27 | Loss: 0.368 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 27 | Loss: 0.376 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 27 | Loss: 0.393 | Acc: 87.200% (436/500)\n",
      "Test Epoch: 27 | Loss: 0.355 | Acc: 88.833% (533/600)\n",
      "Test Epoch: 27 | Loss: 0.382 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 27 | Loss: 0.393 | Acc: 87.625% (701/800)\n",
      "Test Epoch: 27 | Loss: 0.410 | Acc: 86.778% (781/900)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.700% (867/1000)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.182% (948/1100)\n",
      "Test Epoch: 27 | Loss: 0.426 | Acc: 86.083% (1033/1200)\n",
      "Test Epoch: 27 | Loss: 0.421 | Acc: 86.231% (1121/1300)\n",
      "Test Epoch: 27 | Loss: 0.418 | Acc: 86.429% (1210/1400)\n",
      "Test Epoch: 27 | Loss: 0.421 | Acc: 86.200% (1293/1500)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.125% (1378/1600)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.353% (1468/1700)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.389% (1555/1800)\n",
      "Test Epoch: 27 | Loss: 0.422 | Acc: 86.368% (1641/1900)\n",
      "Test Epoch: 27 | Loss: 0.434 | Acc: 86.200% (1724/2000)\n",
      "Test Epoch: 27 | Loss: 0.440 | Acc: 85.952% (1805/2100)\n",
      "Test Epoch: 27 | Loss: 0.436 | Acc: 86.136% (1895/2200)\n",
      "Test Epoch: 27 | Loss: 0.428 | Acc: 86.261% (1984/2300)\n",
      "Test Epoch: 27 | Loss: 0.426 | Acc: 86.292% (2071/2400)\n",
      "Test Epoch: 27 | Loss: 0.433 | Acc: 86.080% (2152/2500)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.000% (2236/2600)\n",
      "Test Epoch: 27 | Loss: 0.434 | Acc: 86.148% (2326/2700)\n",
      "Test Epoch: 27 | Loss: 0.429 | Acc: 86.250% (2415/2800)\n",
      "Test Epoch: 27 | Loss: 0.431 | Acc: 86.276% (2502/2900)\n",
      "Test Epoch: 27 | Loss: 0.429 | Acc: 86.233% (2587/3000)\n",
      "Test Epoch: 27 | Loss: 0.429 | Acc: 86.129% (2670/3100)\n",
      "Test Epoch: 27 | Loss: 0.426 | Acc: 86.219% (2759/3200)\n",
      "Test Epoch: 27 | Loss: 0.427 | Acc: 86.182% (2844/3300)\n",
      "Test Epoch: 27 | Loss: 0.426 | Acc: 86.176% (2930/3400)\n",
      "Test Epoch: 27 | Loss: 0.432 | Acc: 86.086% (3013/3500)\n",
      "Test Epoch: 27 | Loss: 0.436 | Acc: 86.167% (3102/3600)\n",
      "Test Epoch: 27 | Loss: 0.437 | Acc: 86.189% (3189/3700)\n",
      "Test Epoch: 27 | Loss: 0.438 | Acc: 86.132% (3273/3800)\n",
      "Test Epoch: 27 | Loss: 0.437 | Acc: 86.205% (3362/3900)\n",
      "Test Epoch: 27 | Loss: 0.441 | Acc: 86.275% (3451/4000)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.146% (3532/4100)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.095% (3616/4200)\n",
      "Test Epoch: 27 | Loss: 0.441 | Acc: 86.256% (3709/4300)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.295% (3797/4400)\n",
      "Test Epoch: 27 | Loss: 0.439 | Acc: 86.378% (3887/4500)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.304% (3970/4600)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.362% (4059/4700)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.375% (4146/4800)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.449% (4236/4900)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.400% (4320/5000)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.451% (4409/5100)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.462% (4496/5200)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.415% (4580/5300)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.407% (4666/5400)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.382% (4751/5500)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.304% (4833/5600)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.316% (4920/5700)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.379% (5010/5800)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.356% (5095/5900)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.350% (5181/6000)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.393% (5270/6100)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.355% (5354/6200)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.381% (5442/6300)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.406% (5530/6400)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.308% (5610/6500)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.394% (5702/6600)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.463% (5793/6700)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.471% (5880/6800)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.507% (5969/6900)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.486% (6054/7000)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.437% (6137/7100)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.472% (6226/7200)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.534% (6317/7300)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.486% (6400/7400)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.480% (6486/7500)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.487% (6573/7600)\n",
      "Test Epoch: 27 | Loss: 0.444 | Acc: 86.506% (6661/7700)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.526% (6749/7800)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.557% (6838/7900)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.537% (6923/8000)\n",
      "Test Epoch: 27 | Loss: 0.441 | Acc: 86.556% (7011/8100)\n",
      "Test Epoch: 27 | Loss: 0.441 | Acc: 86.549% (7097/8200)\n",
      "Test Epoch: 27 | Loss: 0.442 | Acc: 86.530% (7182/8300)\n",
      "Test Epoch: 27 | Loss: 0.443 | Acc: 86.524% (7268/8400)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.494% (7352/8500)\n",
      "Test Epoch: 27 | Loss: 0.450 | Acc: 86.442% (7434/8600)\n",
      "Test Epoch: 27 | Loss: 0.449 | Acc: 86.402% (7517/8700)\n",
      "Test Epoch: 27 | Loss: 0.449 | Acc: 86.386% (7602/8800)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.393% (7689/8900)\n",
      "Test Epoch: 27 | Loss: 0.451 | Acc: 86.356% (7772/9000)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.429% (7865/9100)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.402% (7949/9200)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.419% (8037/9300)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.436% (8125/9400)\n",
      "Test Epoch: 27 | Loss: 0.448 | Acc: 86.463% (8214/9500)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.490% (8303/9600)\n",
      "Test Epoch: 27 | Loss: 0.445 | Acc: 86.526% (8393/9700)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.520% (8479/9800)\n",
      "Test Epoch: 27 | Loss: 0.447 | Acc: 86.475% (8561/9900)\n",
      "Test Epoch: 27 | Loss: 0.446 | Acc: 86.490% (8649/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 28 | Loss: 0.247 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 28 | Loss: 0.301 | Acc: 89.844% (345/384)\n",
      "Train Epoch: 28 | Loss: 0.267 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 28 | Loss: 0.251 | Acc: 91.562% (586/640)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.448% (710/768)\n",
      "Train Epoch: 28 | Loss: 0.245 | Acc: 92.076% (825/896)\n",
      "Train Epoch: 28 | Loss: 0.248 | Acc: 92.188% (944/1024)\n",
      "Train Epoch: 28 | Loss: 0.244 | Acc: 92.101% (1061/1152)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.472% (1302/1408)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.383% (1419/1536)\n",
      "Train Epoch: 28 | Loss: 0.225 | Acc: 92.608% (1541/1664)\n",
      "Train Epoch: 28 | Loss: 0.225 | Acc: 92.690% (1661/1792)\n",
      "Train Epoch: 28 | Loss: 0.228 | Acc: 92.604% (1778/1920)\n",
      "Train Epoch: 28 | Loss: 0.225 | Acc: 92.676% (1898/2048)\n",
      "Train Epoch: 28 | Loss: 0.226 | Acc: 92.601% (2015/2176)\n",
      "Train Epoch: 28 | Loss: 0.228 | Acc: 92.578% (2133/2304)\n",
      "Train Epoch: 28 | Loss: 0.227 | Acc: 92.516% (2250/2432)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.266% (2362/2560)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.113% (2476/2688)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.045% (2592/2816)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.221% (2715/2944)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.253% (2834/3072)\n",
      "Train Epoch: 28 | Loss: 0.229 | Acc: 92.281% (2953/3200)\n",
      "Train Epoch: 28 | Loss: 0.229 | Acc: 92.248% (3070/3328)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.130% (3184/3456)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.160% (3303/3584)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.188% (3422/3712)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.979% (3532/3840)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.036% (3652/3968)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.017% (3769/4096)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.116% (3891/4224)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.119% (4009/4352)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.076% (4125/4480)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.014% (4240/4608)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.040% (4359/4736)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.105% (4480/4864)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.027% (4594/4992)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.992% (4710/5120)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.035% (4830/5248)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.039% (4948/5376)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 92.060% (5067/5504)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.099% (5187/5632)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.153% (5308/5760)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.120% (5424/5888)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.088% (5540/6016)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.122% (5660/6144)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.172% (5781/6272)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.078% (5893/6400)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.065% (6010/6528)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.142% (6133/6656)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.055% (6245/6784)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.072% (6364/6912)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.116% (6485/7040)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.104% (6602/7168)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.119% (6721/7296)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.174% (6843/7424)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.135% (6958/7552)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.174% (7079/7680)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.162% (7196/7808)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.200% (7317/7936)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.138% (7430/8064)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.163% (7550/8192)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.163% (7668/8320)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.164% (7786/8448)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.176% (7905/8576)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.176% (8023/8704)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.210% (8144/8832)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.121% (8254/8960)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.165% (8376/9088)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.133% (8491/9216)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.102% (8606/9344)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.124% (8726/9472)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.146% (8846/9600)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.116% (8961/9728)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.086% (9076/9856)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.057% (9191/9984)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.049% (9308/10112)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.021% (9423/10240)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 92.014% (9540/10368)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.064% (9663/10496)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.065% (9781/10624)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.029% (9895/10752)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.994% (10009/10880)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.015% (10129/11008)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.017% (10247/11136)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.019% (10365/11264)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.038% (10485/11392)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.005% (10599/11520)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.042% (10721/11648)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.035% (10838/11776)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.061% (10959/11904)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.088% (11080/12032)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.081% (11197/12160)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.090% (11316/12288)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.075% (11432/12416)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.084% (11551/12544)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.085% (11669/12672)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.055% (11783/12800)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.056% (11901/12928)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.050% (12018/13056)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.028% (12133/13184)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.015% (12249/13312)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.031% (12369/13440)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.070% (12492/13568)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.100% (12614/13696)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.093% (12731/13824)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.109% (12851/13952)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.109% (12969/14080)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.138% (13091/14208)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.139% (13209/14336)\n",
      "Train Epoch: 28 | Loss: 0.230 | Acc: 92.118% (13324/14464)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.085% (13437/14592)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.092% (13556/14720)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.066% (13670/14848)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.067% (13788/14976)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.035% (13901/15104)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.997% (14013/15232)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.031% (14136/15360)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.000% (14249/15488)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.002% (14367/15616)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.022% (14488/15744)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.017% (14605/15872)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.031% (14725/16000)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.039% (14844/16128)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.034% (14961/16256)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.035% (15079/16384)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.048% (15199/16512)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.037% (15315/16640)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.021% (15430/16768)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.010% (15546/16896)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.047% (15670/17024)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.065% (15791/17152)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.060% (15908/17280)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.027% (16020/17408)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.034% (16139/17536)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.052% (16260/17664)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.047% (16377/17792)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.031% (16492/17920)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.038% (16611/18048)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.039% (16729/18176)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.002% (16840/18304)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.014% (16960/18432)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.031% (17081/18560)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.038% (17200/18688)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.007% (17312/18816)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 92.019% (17432/18944)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.051% (17556/19072)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.052% (17674/19200)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.074% (17796/19328)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.090% (17917/19456)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.090% (18035/19584)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.071% (18149/19712)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.072% (18267/19840)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.087% (18388/19968)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.073% (18503/20096)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.054% (18617/20224)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.060% (18736/20352)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.080% (18858/20480)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.061% (18972/20608)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.052% (19088/20736)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.058% (19207/20864)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.078% (19329/20992)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.069% (19445/21120)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.075% (19564/21248)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.085% (19684/21376)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.090% (19803/21504)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.100% (19923/21632)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.119% (20045/21760)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.105% (20160/21888)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.101% (20277/22016)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.088% (20392/22144)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.084% (20509/22272)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.089% (20628/22400)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.085% (20745/22528)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.068% (20859/22656)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.056% (20974/22784)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.052% (21091/22912)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.040% (21206/23040)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.032% (21322/23168)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.020% (21437/23296)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 92.025% (21556/23424)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.030% (21675/23552)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.035% (21794/23680)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.032% (21911/23808)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.029% (22028/23936)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.017% (22143/24064)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.026% (22263/24192)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.035% (22383/24320)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.016% (22496/24448)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.004% (22611/24576)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.985% (22724/24704)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.002% (22846/24832)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.999% (22963/24960)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.008% (23083/25088)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.013% (23202/25216)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.038% (23326/25344)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.038% (23444/25472)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.027% (23559/25600)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.032% (23678/25728)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.044% (23799/25856)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.041% (23916/25984)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.042% (24034/26112)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.050% (24154/26240)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.043% (24270/26368)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.052% (24390/26496)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.026% (24501/26624)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.019% (24617/26752)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.024% (24736/26880)\n",
      "Train Epoch: 28 | Loss: 0.231 | Acc: 92.043% (24859/27008)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.018% (24970/27136)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.011% (25086/27264)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.020% (25206/27392)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.028% (25326/27520)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.043% (25448/27648)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.043% (25566/27776)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.037% (25682/27904)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.041% (25801/28032)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.021% (25913/28160)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.021% (26031/28288)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.019% (26148/28416)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.012% (26264/28544)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.027% (26386/28672)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.031% (26505/28800)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.028% (26622/28928)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.991% (26729/29056)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.989% (26846/29184)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.993% (26965/29312)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.987% (27081/29440)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.991% (27200/29568)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.992% (27318/29696)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.990% (27435/29824)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.004% (27557/29952)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.005% (27675/30080)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.005% (27793/30208)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.996% (27908/30336)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 92.000% (28027/30464)\n",
      "Train Epoch: 28 | Loss: 0.232 | Acc: 91.988% (28141/30592)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.960% (28250/30720)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.961% (28368/30848)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.955% (28484/30976)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.962% (28604/31104)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.967% (28723/31232)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.964% (28840/31360)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.962% (28957/31488)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.966% (29076/31616)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.958% (29191/31744)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.949% (29306/31872)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.950% (29424/32000)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.960% (29545/32128)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.974% (29667/32256)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.987% (29789/32384)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.978% (29904/32512)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.961% (30016/32640)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.974% (30138/32768)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.956% (30250/32896)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.957% (30368/33024)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.970% (30490/33152)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.965% (30606/33280)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.972% (30726/33408)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.970% (30843/33536)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.965% (30959/33664)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.969% (31078/33792)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.969% (31196/33920)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.958% (31310/34048)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.956% (31427/34176)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.948% (31542/34304)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.949% (31660/34432)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.936% (31773/34560)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.922% (31886/34688)\n",
      "Train Epoch: 28 | Loss: 0.233 | Acc: 91.926% (32005/34816)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.913% (32118/34944)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.908% (32234/35072)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.895% (32347/35200)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.896% (32465/35328)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.911% (32588/35456)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.921% (32709/35584)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.927% (32829/35712)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.900% (32937/35840)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.898% (33054/35968)\n",
      "Train Epoch: 28 | Loss: 0.234 | Acc: 91.894% (33170/36096)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.881% (33283/36224)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.882% (33401/36352)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.872% (33515/36480)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.868% (33631/36608)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.877% (33752/36736)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.865% (33865/36864)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.860% (33981/36992)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.864% (34100/37120)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.865% (34218/37248)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.872% (34338/37376)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.868% (34454/37504)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.869% (34572/37632)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.859% (34686/37760)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.855% (34802/37888)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.848% (34917/38016)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.852% (35036/38144)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.850% (35153/38272)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.846% (35269/38400)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.860% (35392/38528)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.867% (35512/38656)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.860% (35627/38784)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.859% (35744/38912)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.867% (35865/39040)\n",
      "Train Epoch: 28 | Loss: 0.235 | Acc: 91.858% (35979/39168)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.852% (36094/39296)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.850% (36211/39424)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.851% (36329/39552)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.860% (36450/39680)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.858% (36567/39808)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.849% (36681/39936)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.851% (36799/40064)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.862% (36921/40192)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.868% (37041/40320)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.874% (37161/40448)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.884% (37283/40576)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.883% (37400/40704)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.872% (37513/40832)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.870% (37630/40960)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.859% (37743/41088)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.867% (37864/41216)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.875% (37985/41344)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.862% (38097/41472)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.865% (38216/41600)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.859% (38331/41728)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.860% (38449/41856)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.854% (38564/41984)\n",
      "Train Epoch: 28 | Loss: 0.236 | Acc: 91.841% (38676/42112)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.837% (38792/42240)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.829% (38906/42368)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.823% (39021/42496)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.826% (39140/42624)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.816% (39253/42752)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.805% (39366/42880)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.799% (39481/43008)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.798% (39598/43136)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.795% (39714/43264)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.793% (39831/43392)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.804% (39953/43520)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.793% (40066/43648)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.792% (40183/43776)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.800% (40304/43904)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.792% (40418/44032)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.789% (40534/44160)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.783% (40649/44288)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.791% (40770/44416)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.799% (40891/44544)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.809% (41013/44672)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.806% (41129/44800)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.809% (41248/44928)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.819% (41370/45056)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.829% (41492/45184)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.821% (41606/45312)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.824% (41725/45440)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.830% (41845/45568)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.811% (41954/45696)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.810% (42071/45824)\n",
      "Train Epoch: 28 | Loss: 0.237 | Acc: 91.818% (42192/45952)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.803% (42303/46080)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.802% (42420/46208)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.797% (42535/46336)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.800% (42654/46464)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.788% (42766/46592)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.785% (42882/46720)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.782% (42998/46848)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.787% (43118/46976)\n",
      "Train Epoch: 28 | Loss: 0.238 | Acc: 91.786% (43235/47104)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.789% (43354/47232)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.791% (43472/47360)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.783% (43586/47488)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.786% (43705/47616)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.779% (43819/47744)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.770% (43932/47872)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.773% (44051/48000)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.778% (44171/48128)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.777% (44288/48256)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.760% (44397/48384)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.746% (44508/48512)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.739% (44622/48640)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.745% (44742/48768)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.748% (44861/48896)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.743% (44976/49024)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.744% (45094/49152)\n",
      "Train Epoch: 28 | Loss: 0.239 | Acc: 91.745% (45212/49280)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.736% (45325/49408)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.737% (45443/49536)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.740% (45562/49664)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.744% (45681/49792)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.737% (45795/49920)\n",
      "Train Epoch: 28 | Loss: 0.240 | Acc: 91.738% (45869/50000)\n",
      "Test Epoch: 28 | Loss: 0.394 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 28 | Loss: 0.376 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 28 | Loss: 0.381 | Acc: 87.000% (261/300)\n",
      "Test Epoch: 28 | Loss: 0.418 | Acc: 86.500% (346/400)\n",
      "Test Epoch: 28 | Loss: 0.408 | Acc: 86.800% (434/500)\n",
      "Test Epoch: 28 | Loss: 0.367 | Acc: 88.167% (529/600)\n",
      "Test Epoch: 28 | Loss: 0.371 | Acc: 88.000% (616/700)\n",
      "Test Epoch: 28 | Loss: 0.398 | Acc: 86.875% (695/800)\n",
      "Test Epoch: 28 | Loss: 0.432 | Acc: 86.444% (778/900)\n",
      "Test Epoch: 28 | Loss: 0.432 | Acc: 86.600% (866/1000)\n",
      "Test Epoch: 28 | Loss: 0.441 | Acc: 86.455% (951/1100)\n",
      "Test Epoch: 28 | Loss: 0.454 | Acc: 85.917% (1031/1200)\n",
      "Test Epoch: 28 | Loss: 0.458 | Acc: 85.923% (1117/1300)\n",
      "Test Epoch: 28 | Loss: 0.456 | Acc: 86.000% (1204/1400)\n",
      "Test Epoch: 28 | Loss: 0.461 | Acc: 85.933% (1289/1500)\n",
      "Test Epoch: 28 | Loss: 0.466 | Acc: 85.812% (1373/1600)\n",
      "Test Epoch: 28 | Loss: 0.461 | Acc: 86.176% (1465/1700)\n",
      "Test Epoch: 28 | Loss: 0.469 | Acc: 86.111% (1550/1800)\n",
      "Test Epoch: 28 | Loss: 0.470 | Acc: 86.000% (1634/1900)\n",
      "Test Epoch: 28 | Loss: 0.476 | Acc: 85.950% (1719/2000)\n",
      "Test Epoch: 28 | Loss: 0.477 | Acc: 85.905% (1804/2100)\n",
      "Test Epoch: 28 | Loss: 0.472 | Acc: 86.000% (1892/2200)\n",
      "Test Epoch: 28 | Loss: 0.470 | Acc: 86.087% (1980/2300)\n",
      "Test Epoch: 28 | Loss: 0.473 | Acc: 86.042% (2065/2400)\n",
      "Test Epoch: 28 | Loss: 0.477 | Acc: 86.040% (2151/2500)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.885% (2233/2600)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 85.889% (2319/2700)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 85.964% (2407/2800)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 86.138% (2498/2900)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 86.200% (2586/3000)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 86.065% (2668/3100)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 86.156% (2757/3200)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 86.121% (2842/3300)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 86.059% (2926/3400)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.971% (3009/3500)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 86.028% (3097/3600)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 86.027% (3183/3700)\n",
      "Test Epoch: 28 | Loss: 0.491 | Acc: 85.974% (3267/3800)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 86.077% (3357/3900)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 86.075% (3443/4000)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.976% (3525/4100)\n",
      "Test Epoch: 28 | Loss: 0.492 | Acc: 85.905% (3608/4200)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 86.000% (3698/4300)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 86.068% (3787/4400)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 86.111% (3875/4500)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 86.087% (3960/4600)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 86.043% (4044/4700)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 85.958% (4126/4800)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 86.000% (4214/4900)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.880% (4294/5000)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 86.078% (4390/5100)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 86.077% (4476/5200)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 86.057% (4561/5300)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 86.056% (4647/5400)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.982% (4729/5500)\n",
      "Test Epoch: 28 | Loss: 0.492 | Acc: 85.946% (4813/5600)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.965% (4900/5700)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 86.000% (4988/5800)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 85.983% (5073/5900)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 85.950% (5157/6000)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 86.016% (5247/6100)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 85.952% (5329/6200)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 85.968% (5416/6300)\n",
      "Test Epoch: 28 | Loss: 0.479 | Acc: 86.000% (5504/6400)\n",
      "Test Epoch: 28 | Loss: 0.480 | Acc: 85.938% (5586/6500)\n",
      "Test Epoch: 28 | Loss: 0.478 | Acc: 85.985% (5675/6600)\n",
      "Test Epoch: 28 | Loss: 0.478 | Acc: 85.985% (5761/6700)\n",
      "Test Epoch: 28 | Loss: 0.479 | Acc: 85.956% (5845/6800)\n",
      "Test Epoch: 28 | Loss: 0.478 | Acc: 86.029% (5936/6900)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 85.914% (6014/7000)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.873% (6097/7100)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 85.875% (6183/7200)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.959% (6275/7300)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.973% (6362/7400)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.907% (6443/7500)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.908% (6529/7600)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.896% (6614/7700)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 85.923% (6702/7800)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 85.937% (6789/7900)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 85.925% (6874/8000)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 85.951% (6962/8100)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 85.866% (7041/8200)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 85.855% (7126/8300)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 85.857% (7212/8400)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 85.835% (7296/8500)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.791% (7378/8600)\n",
      "Test Epoch: 28 | Loss: 0.491 | Acc: 85.747% (7460/8700)\n",
      "Test Epoch: 28 | Loss: 0.492 | Acc: 85.705% (7542/8800)\n",
      "Test Epoch: 28 | Loss: 0.491 | Acc: 85.753% (7632/8900)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.789% (7721/9000)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.802% (7808/9100)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.793% (7893/9200)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.796% (7979/9300)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 85.787% (8064/9400)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.811% (8152/9500)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 85.865% (8243/9600)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 85.938% (8336/9700)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 85.918% (8420/9800)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 85.889% (8503/9900)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 85.880% (8588/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Epoch: 29 | Loss: 0.214 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 29 | Loss: 0.171 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 29 | Loss: 0.188 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 29 | Loss: 0.217 | Acc: 91.602% (469/512)\n",
      "Train Epoch: 29 | Loss: 0.217 | Acc: 91.875% (588/640)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.183% (817/896)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 90.918% (931/1024)\n",
      "Train Epoch: 29 | Loss: 0.245 | Acc: 90.625% (1044/1152)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.094% (1166/1280)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.264% (1285/1408)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.471% (1405/1536)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.526% (1523/1664)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.239% (1635/1792)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.510% (1757/1920)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.602% (1876/2048)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.498% (1991/2176)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.536% (2109/2304)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.612% (2228/2432)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.523% (2343/2560)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.629% (2463/2688)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.655% (2581/2816)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.644% (2698/2944)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.602% (2814/3072)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.625% (2932/3200)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.647% (3050/3328)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.638% (3167/3456)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.546% (3281/3584)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.595% (3400/3712)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.693% (3521/3840)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.709% (3639/3968)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.724% (3757/4096)\n",
      "Train Epoch: 29 | Loss: 0.223 | Acc: 91.856% (3880/4224)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 91.820% (3996/4352)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.786% (4112/4480)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 91.819% (4231/4608)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.786% (4347/4736)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 91.838% (4467/4864)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.747% (4580/4992)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.758% (4698/5120)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.749% (4815/5248)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.778% (4934/5376)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.697% (5047/5504)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.602% (5159/5632)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.632% (5278/5760)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.661% (5397/5888)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.656% (5514/6016)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.667% (5632/6144)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.629% (5747/6272)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.688% (5868/6400)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.697% (5986/6528)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.692% (6103/6656)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.745% (6224/6784)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.797% (6345/6912)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.747% (6459/7040)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.783% (6579/7168)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.776% (6696/7296)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.810% (6816/7424)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.843% (6936/7552)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.823% (7052/7680)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.931% (7178/7808)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.948% (7297/7936)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.952% (7415/8064)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.956% (7533/8192)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.959% (7651/8320)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.927% (7766/8448)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 91.966% (7887/8576)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.969% (8005/8704)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 92.029% (8128/8832)\n",
      "Train Epoch: 29 | Loss: 0.224 | Acc: 92.031% (8246/8960)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.978% (8359/9088)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.992% (8478/9216)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.006% (8597/9344)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 92.019% (8716/9472)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.969% (8829/9600)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.951% (8945/9728)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.954% (9063/9856)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.927% (9178/9984)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.920% (9295/10112)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.895% (9410/10240)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.869% (9525/10368)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.892% (9645/10496)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.886% (9762/10624)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.862% (9877/10752)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.847% (9993/10880)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.870% (10113/11008)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.855% (10229/11136)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.832% (10344/11264)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.836% (10462/11392)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.858% (10582/11520)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 91.870% (10701/11648)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.916% (10824/11776)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.919% (10942/11904)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.980% (11067/12032)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.007% (11188/12160)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 92.057% (11312/12288)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.034% (11427/12416)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.020% (11543/12544)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.045% (11664/12672)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 92.047% (11782/12800)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 92.025% (11897/12928)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.050% (12018/13056)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.021% (12132/13184)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.992% (12246/13312)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.987% (12363/13440)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.966% (12478/13568)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.976% (12597/13696)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.942% (12710/13824)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.944% (12828/13952)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.939% (12945/14080)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 91.955% (13065/14208)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.999% (13189/14336)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.994% (13306/14464)\n",
      "Train Epoch: 29 | Loss: 0.225 | Acc: 91.996% (13424/14592)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.977% (13539/14720)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.006% (13661/14848)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.001% (13778/14976)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.015% (13898/15104)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.010% (14015/15232)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.012% (14133/15360)\n",
      "Train Epoch: 29 | Loss: 0.226 | Acc: 92.007% (14250/15488)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.989% (14365/15616)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.978% (14481/15744)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.986% (14600/15872)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.987% (14718/16000)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.977% (14834/16128)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.960% (14949/16256)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.968% (15068/16384)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.982% (15188/16512)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.001% (15309/16640)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.973% (15422/16768)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 91.974% (15540/16896)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.958% (15655/17024)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.966% (15774/17152)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.985% (15895/17280)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 91.981% (16012/17408)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.011% (16135/17536)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.029% (16256/17664)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.053% (16378/17792)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.054% (16496/17920)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.082% (16619/18048)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.061% (16733/18176)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.051% (16849/18304)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.041% (16965/18432)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.053% (17085/18560)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.038% (17200/18688)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.023% (17315/18816)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.003% (17429/18944)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.009% (17548/19072)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.010% (17666/19200)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.032% (17788/19328)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.038% (17907/19456)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.034% (18024/19584)\n",
      "Train Epoch: 29 | Loss: 0.227 | Acc: 92.040% (18143/19712)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.041% (18261/19840)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.042% (18379/19968)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.033% (18495/20096)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.069% (18620/20224)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.079% (18740/20352)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.075% (18857/20480)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.056% (18971/20608)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.052% (19088/20736)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.049% (19205/20864)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.054% (19324/20992)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.050% (19441/21120)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.060% (19561/21248)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.085% (19684/21376)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.067% (19798/21504)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.058% (19914/21632)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.045% (20029/21760)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.023% (20142/21888)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.024% (20260/22016)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.025% (20378/22144)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.039% (20499/22272)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.045% (20618/22400)\n",
      "Train Epoch: 29 | Loss: 0.228 | Acc: 92.063% (20740/22528)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.046% (20854/22656)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.038% (20970/22784)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.039% (21088/22912)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.049% (21208/23040)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.036% (21323/23168)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.029% (21439/23296)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.012% (21553/23424)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.009% (21670/23552)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.014% (21789/23680)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.003% (21904/23808)\n",
      "Train Epoch: 29 | Loss: 0.229 | Acc: 92.008% (22023/23936)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.000% (22139/24064)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.001% (22257/24192)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 92.002% (22375/24320)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.995% (22491/24448)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.968% (22602/24576)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.981% (22723/24704)\n",
      "Train Epoch: 29 | Loss: 0.230 | Acc: 91.974% (22839/24832)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.951% (22951/24960)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.924% (23062/25088)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.942% (23184/25216)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.919% (23296/25344)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.901% (23409/25472)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.910% (23529/25600)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.896% (23643/25728)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.909% (23764/25856)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.918% (23884/25984)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.916% (24001/26112)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.925% (24121/26240)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.937% (24242/26368)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.935% (24359/26496)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.932% (24476/26624)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.922% (24591/26752)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.916% (24707/26880)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.928% (24828/27008)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.911% (24941/27136)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.901% (25056/27264)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.914% (25177/27392)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.911% (25294/27520)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.905% (25410/27648)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.899% (25526/27776)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.912% (25647/27904)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.913% (25765/28032)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.914% (25883/28160)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.905% (25998/28288)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.913% (26118/28416)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.900% (26232/28544)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.905% (26351/28672)\n",
      "Train Epoch: 29 | Loss: 0.231 | Acc: 91.910% (26470/28800)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.904% (26586/28928)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.898% (26702/29056)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.896% (26819/29184)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.891% (26935/29312)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.889% (27052/29440)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.897% (27172/29568)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.868% (27281/29696)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.869% (27399/29824)\n",
      "Train Epoch: 29 | Loss: 0.232 | Acc: 91.867% (27516/29952)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.865% (27633/30080)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.850% (27746/30208)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.822% (27855/30336)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.807% (27968/30464)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.805% (28085/30592)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.803% (28202/30720)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.792% (28316/30848)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.797% (28435/30976)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.802% (28554/31104)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.784% (28666/31232)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.776% (28781/31360)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.771% (28897/31488)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.783% (29018/31616)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.784% (29136/31744)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.789% (29255/31872)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.763% (29364/32000)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.761% (29481/32128)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.753% (29596/32256)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.764% (29717/32384)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.769% (29836/32512)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.768% (29953/32640)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.782% (30075/32768)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.786% (30194/32896)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.797% (30315/33024)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.801% (30434/33152)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.806% (30553/33280)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.813% (30673/33408)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.821% (30793/33536)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.819% (30910/33664)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.806% (31023/33792)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.813% (31143/33920)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.809% (31259/34048)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.795% (31372/34176)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.806% (31493/34304)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.807% (31611/34432)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.817% (31732/34560)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.798% (31843/34688)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.800% (31961/34816)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.798% (32078/34944)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.803% (32197/35072)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.795% (32312/35200)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.794% (32429/35328)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.779% (32541/35456)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.760% (32652/35584)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.756% (32768/35712)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.761% (32887/35840)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.751% (33001/35968)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.755% (33120/36096)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.754% (33237/36224)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.756% (33355/36352)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.743% (33468/36480)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.731% (33581/36608)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.714% (33692/36736)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.715% (33810/36864)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.725% (33931/36992)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.740% (34054/37120)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.742% (34172/37248)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.738% (34288/37376)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.737% (34405/37504)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.733% (34521/37632)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.743% (34642/37760)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.749% (34762/37888)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.753% (34881/38016)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.763% (35002/38144)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.756% (35117/38272)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.750% (35232/38400)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.754% (35351/38528)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.758% (35470/38656)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.757% (35587/38784)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.756% (35704/38912)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.762% (35824/39040)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.771% (35945/39168)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.773% (36063/39296)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.782% (36184/39424)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.785% (36303/39552)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.764% (36412/39680)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.765% (36530/39808)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.757% (36644/39936)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.758% (36762/40064)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.767% (36883/40192)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.771% (37002/40320)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.770% (37119/40448)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.766% (37235/40576)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.767% (37353/40704)\n",
      "Train Epoch: 29 | Loss: 0.236 | Acc: 91.761% (37468/40832)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.760% (37585/40960)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.769% (37706/41088)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.758% (37819/41216)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.764% (37939/41344)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.763% (38056/41472)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.752% (38169/41600)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.759% (38289/41728)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.760% (38407/41856)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.761% (38525/41984)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.774% (38648/42112)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.776% (38766/42240)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.777% (38884/42368)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.764% (38996/42496)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.756% (39110/42624)\n",
      "Train Epoch: 29 | Loss: 0.235 | Acc: 91.769% (39233/42752)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.784% (39357/42880)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.783% (39474/43008)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.784% (39592/43136)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.785% (39710/43264)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.782% (39826/43392)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.797% (39950/43520)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.800% (40069/43648)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.801% (40187/43776)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.807% (40307/43904)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.813% (40427/44032)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.816% (40546/44160)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.817% (40664/44288)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.814% (40780/44416)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.808% (40895/44544)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.807% (41012/44672)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.806% (41129/44800)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.807% (41247/44928)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.806% (41364/45056)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.796% (41477/45184)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.801% (41597/45312)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.805% (41716/45440)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.795% (41829/45568)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.800% (41949/45696)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.790% (42062/45824)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.791% (42180/45952)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.784% (42294/46080)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.770% (42405/46208)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.775% (42525/46336)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.768% (42639/46464)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.756% (42751/46592)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.753% (42867/46720)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.758% (42987/46848)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.766% (43108/46976)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.765% (43225/47104)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.773% (43346/47232)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.774% (43464/47360)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.783% (43586/47488)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.767% (43696/47616)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.764% (43812/47744)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.755% (43925/47872)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.754% (44042/48000)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.753% (44159/48128)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.765% (44282/48256)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.760% (44397/48384)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.753% (44511/48512)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.754% (44629/48640)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.757% (44748/48768)\n",
      "Train Epoch: 29 | Loss: 0.234 | Acc: 91.758% (44866/48896)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.765% (44987/49024)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.760% (45102/49152)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.765% (45222/49280)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.777% (45345/49408)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.772% (45460/49536)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.773% (45578/49664)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.774% (45696/49792)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.775% (45814/49920)\n",
      "Train Epoch: 29 | Loss: 0.233 | Acc: 91.776% (45888/50000)\n",
      "Test Epoch: 29 | Loss: 0.316 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 29 | Loss: 0.335 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 29 | Loss: 0.341 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 29 | Loss: 0.337 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 29 | Loss: 0.351 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 29 | Loss: 0.318 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 29 | Loss: 0.334 | Acc: 89.571% (627/700)\n",
      "Test Epoch: 29 | Loss: 0.354 | Acc: 88.625% (709/800)\n",
      "Test Epoch: 29 | Loss: 0.365 | Acc: 88.444% (796/900)\n",
      "Test Epoch: 29 | Loss: 0.372 | Acc: 88.300% (883/1000)\n",
      "Test Epoch: 29 | Loss: 0.373 | Acc: 88.273% (971/1100)\n",
      "Test Epoch: 29 | Loss: 0.388 | Acc: 87.667% (1052/1200)\n",
      "Test Epoch: 29 | Loss: 0.385 | Acc: 87.692% (1140/1300)\n",
      "Test Epoch: 29 | Loss: 0.383 | Acc: 87.929% (1231/1400)\n",
      "Test Epoch: 29 | Loss: 0.388 | Acc: 87.600% (1314/1500)\n",
      "Test Epoch: 29 | Loss: 0.393 | Acc: 87.500% (1400/1600)\n",
      "Test Epoch: 29 | Loss: 0.397 | Acc: 87.647% (1490/1700)\n",
      "Test Epoch: 29 | Loss: 0.401 | Acc: 87.611% (1577/1800)\n",
      "Test Epoch: 29 | Loss: 0.400 | Acc: 87.632% (1665/1900)\n",
      "Test Epoch: 29 | Loss: 0.408 | Acc: 87.400% (1748/2000)\n",
      "Test Epoch: 29 | Loss: 0.411 | Acc: 87.333% (1834/2100)\n",
      "Test Epoch: 29 | Loss: 0.418 | Acc: 87.136% (1917/2200)\n",
      "Test Epoch: 29 | Loss: 0.416 | Acc: 87.087% (2003/2300)\n",
      "Test Epoch: 29 | Loss: 0.414 | Acc: 87.083% (2090/2400)\n",
      "Test Epoch: 29 | Loss: 0.421 | Acc: 87.040% (2176/2500)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.962% (2261/2600)\n",
      "Test Epoch: 29 | Loss: 0.426 | Acc: 87.111% (2352/2700)\n",
      "Test Epoch: 29 | Loss: 0.422 | Acc: 87.143% (2440/2800)\n",
      "Test Epoch: 29 | Loss: 0.422 | Acc: 87.241% (2530/2900)\n",
      "Test Epoch: 29 | Loss: 0.418 | Acc: 87.400% (2622/3000)\n",
      "Test Epoch: 29 | Loss: 0.420 | Acc: 87.258% (2705/3100)\n",
      "Test Epoch: 29 | Loss: 0.417 | Acc: 87.250% (2792/3200)\n",
      "Test Epoch: 29 | Loss: 0.419 | Acc: 87.152% (2876/3300)\n",
      "Test Epoch: 29 | Loss: 0.418 | Acc: 87.176% (2964/3400)\n",
      "Test Epoch: 29 | Loss: 0.427 | Acc: 87.114% (3049/3500)\n",
      "Test Epoch: 29 | Loss: 0.425 | Acc: 87.139% (3137/3600)\n",
      "Test Epoch: 29 | Loss: 0.425 | Acc: 87.189% (3226/3700)\n",
      "Test Epoch: 29 | Loss: 0.426 | Acc: 87.158% (3312/3800)\n",
      "Test Epoch: 29 | Loss: 0.425 | Acc: 87.103% (3397/3900)\n",
      "Test Epoch: 29 | Loss: 0.428 | Acc: 87.025% (3481/4000)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.902% (3563/4100)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.857% (3648/4200)\n",
      "Test Epoch: 29 | Loss: 0.426 | Acc: 87.023% (3742/4300)\n",
      "Test Epoch: 29 | Loss: 0.425 | Acc: 87.091% (3832/4400)\n",
      "Test Epoch: 29 | Loss: 0.423 | Acc: 87.111% (3920/4500)\n",
      "Test Epoch: 29 | Loss: 0.428 | Acc: 86.935% (3999/4600)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.894% (4084/4700)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.833% (4168/4800)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.959% (4261/4900)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.860% (4343/5000)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.941% (4434/5100)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.885% (4518/5200)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.811% (4601/5300)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.833% (4689/5400)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.745% (4771/5500)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.768% (4859/5600)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.772% (4946/5700)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.845% (5037/5800)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.780% (5120/5900)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.750% (5205/6000)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.754% (5292/6100)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.726% (5377/6200)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.746% (5465/6300)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.797% (5555/6400)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.785% (5641/6500)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.803% (5729/6600)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.806% (5816/6700)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.750% (5899/6800)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.841% (5992/6900)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.814% (6077/7000)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.803% (6163/7100)\n",
      "Test Epoch: 29 | Loss: 0.435 | Acc: 86.778% (6248/7200)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.822% (6338/7300)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.797% (6423/7400)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.720% (6504/7500)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.684% (6588/7600)\n",
      "Test Epoch: 29 | Loss: 0.433 | Acc: 86.649% (6672/7700)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.641% (6758/7800)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.658% (6846/7900)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.662% (6933/8000)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.716% (7024/8100)\n",
      "Test Epoch: 29 | Loss: 0.428 | Acc: 86.744% (7113/8200)\n",
      "Test Epoch: 29 | Loss: 0.428 | Acc: 86.711% (7197/8300)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.679% (7281/8400)\n",
      "Test Epoch: 29 | Loss: 0.432 | Acc: 86.624% (7363/8500)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.581% (7446/8600)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.575% (7532/8700)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.580% (7619/8800)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.562% (7704/8900)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 86.578% (7792/9000)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.659% (7886/9100)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.674% (7974/9200)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.667% (8060/9300)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.649% (8145/9400)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.674% (8234/9500)\n",
      "Test Epoch: 29 | Loss: 0.431 | Acc: 86.688% (8322/9600)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.753% (8415/9700)\n",
      "Test Epoch: 29 | Loss: 0.429 | Acc: 86.765% (8503/9800)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.747% (8588/9900)\n",
      "Test Epoch: 29 | Loss: 0.430 | Acc: 86.750% (8675/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 30 | Loss: 0.231 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 30 | Loss: 0.240 | Acc: 91.992% (471/512)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.812% (594/640)\n",
      "Train Epoch: 30 | Loss: 0.235 | Acc: 92.188% (708/768)\n",
      "Train Epoch: 30 | Loss: 0.243 | Acc: 91.629% (821/896)\n",
      "Train Epoch: 30 | Loss: 0.239 | Acc: 91.699% (939/1024)\n",
      "Train Epoch: 30 | Loss: 0.231 | Acc: 92.188% (1062/1152)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.500% (1184/1280)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.330% (1300/1408)\n",
      "Train Epoch: 30 | Loss: 0.213 | Acc: 92.708% (1424/1536)\n",
      "Train Epoch: 30 | Loss: 0.213 | Acc: 92.849% (1545/1664)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.746% (1662/1792)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.552% (1777/1920)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.432% (1893/2048)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.417% (2011/2176)\n",
      "Train Epoch: 30 | Loss: 0.232 | Acc: 92.318% (2127/2304)\n",
      "Train Epoch: 30 | Loss: 0.234 | Acc: 92.188% (2242/2432)\n",
      "Train Epoch: 30 | Loss: 0.233 | Acc: 92.266% (2362/2560)\n",
      "Train Epoch: 30 | Loss: 0.236 | Acc: 92.188% (2478/2688)\n",
      "Train Epoch: 30 | Loss: 0.235 | Acc: 92.223% (2597/2816)\n",
      "Train Epoch: 30 | Loss: 0.235 | Acc: 92.255% (2716/2944)\n",
      "Train Epoch: 30 | Loss: 0.232 | Acc: 92.350% (2837/3072)\n",
      "Train Epoch: 30 | Loss: 0.229 | Acc: 92.312% (2954/3200)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.368% (3074/3328)\n",
      "Train Epoch: 30 | Loss: 0.234 | Acc: 92.188% (3186/3456)\n",
      "Train Epoch: 30 | Loss: 0.233 | Acc: 92.188% (3304/3584)\n",
      "Train Epoch: 30 | Loss: 0.235 | Acc: 92.080% (3418/3712)\n",
      "Train Epoch: 30 | Loss: 0.232 | Acc: 92.188% (3540/3840)\n",
      "Train Epoch: 30 | Loss: 0.234 | Acc: 92.087% (3654/3968)\n",
      "Train Epoch: 30 | Loss: 0.232 | Acc: 92.139% (3774/4096)\n",
      "Train Epoch: 30 | Loss: 0.231 | Acc: 92.140% (3892/4224)\n",
      "Train Epoch: 30 | Loss: 0.232 | Acc: 92.004% (4004/4352)\n",
      "Train Epoch: 30 | Loss: 0.230 | Acc: 92.076% (4125/4480)\n",
      "Train Epoch: 30 | Loss: 0.228 | Acc: 92.122% (4245/4608)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.209% (4367/4736)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.249% (4487/4864)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.248% (4605/4992)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.227% (4722/5120)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.168% (4837/5248)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.132% (4953/5376)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.169% (5073/5504)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.241% (5195/5632)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.222% (5312/5760)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.238% (5431/5888)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.271% (5551/6016)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.285% (5670/6144)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.283% (5788/6272)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.172% (5899/6400)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.188% (6018/6528)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.188% (6136/6656)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.217% (6256/6784)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.188% (6372/6912)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.188% (6490/7040)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.215% (6610/7168)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.270% (6732/7296)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.268% (6850/7424)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.280% (6969/7552)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.318% (7090/7680)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.392% (7214/7808)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.377% (7331/7936)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.262% (7440/8064)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.249% (7557/8192)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.272% (7677/8320)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.223% (7791/8448)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.211% (7908/8576)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.199% (8025/8704)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.199% (8143/8832)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.221% (8263/8960)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.243% (8383/9088)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.220% (8499/9216)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.198% (8615/9344)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.145% (8728/9472)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.125% (8844/9600)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.126% (8962/9728)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.096% (9077/9856)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.077% (9193/9984)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.128% (9316/10112)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.109% (9432/10240)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.110% (9550/10368)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.149% (9672/10496)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.169% (9792/10624)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.132% (9906/10752)\n",
      "Train Epoch: 30 | Loss: 0.227 | Acc: 92.105% (10021/10880)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.133% (10142/11008)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.152% (10262/11136)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.170% (10382/11264)\n",
      "Train Epoch: 30 | Loss: 0.226 | Acc: 92.082% (10490/11392)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.109% (10611/11520)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.119% (10730/11648)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.162% (10853/11776)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.120% (10966/11904)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.096% (11081/12032)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.072% (11196/12160)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.065% (11313/12288)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.091% (11434/12416)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.076% (11550/12544)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.061% (11666/12672)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.039% (11781/12800)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.079% (11904/12928)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.119% (12027/13056)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.142% (12148/13184)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.127% (12264/13312)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.158% (12386/13440)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.165% (12505/13568)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.136% (12619/13696)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.115% (12734/13824)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.123% (12853/13952)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.138% (12973/14080)\n",
      "Train Epoch: 30 | Loss: 0.225 | Acc: 92.138% (13091/14208)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.153% (13211/14336)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.153% (13329/14464)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.174% (13450/14592)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.181% (13569/14720)\n",
      "Train Epoch: 30 | Loss: 0.224 | Acc: 92.194% (13689/14848)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.208% (13809/14976)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.201% (13926/15104)\n",
      "Train Epoch: 30 | Loss: 0.223 | Acc: 92.188% (14042/15232)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.194% (14161/15360)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.233% (14285/15488)\n",
      "Train Epoch: 30 | Loss: 0.222 | Acc: 92.245% (14405/15616)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.257% (14525/15744)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.257% (14643/15872)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.281% (14765/16000)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.293% (14885/16128)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.304% (15005/16256)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.310% (15124/16384)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.290% (15239/16512)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.296% (15358/16640)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.307% (15478/16768)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.288% (15593/16896)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.276% (15709/17024)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.281% (15828/17152)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.292% (15948/17280)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.308% (16069/17408)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.319% (16189/17536)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.329% (16309/17664)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.334% (16428/17792)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.327% (16545/17920)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.320% (16662/18048)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.342% (16784/18176)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.379% (16909/18304)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.367% (17025/18432)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.387% (17147/18560)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.391% (17266/18688)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.416% (17389/18816)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.441% (17512/18944)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.429% (17628/19072)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.417% (17744/19200)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.405% (17860/19328)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.383% (17974/19456)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.387% (18093/19584)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.380% (18210/19712)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.384% (18329/19840)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.373% (18445/19968)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.352% (18559/20096)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.356% (18678/20224)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.384% (18802/20352)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.373% (18918/20480)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.357% (19033/20608)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.351% (19150/20736)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.374% (19273/20864)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.369% (19390/20992)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.377% (19510/21120)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.385% (19630/21248)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.361% (19743/21376)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.369% (19863/21504)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.349% (19977/21632)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.344% (20094/21760)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.325% (20208/21888)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.328% (20327/22016)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.346% (20449/22144)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.363% (20571/22272)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.357% (20688/22400)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.356% (20806/22528)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.377% (20929/22656)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.403% (21053/22784)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.406% (21172/22912)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.400% (21289/23040)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.421% (21412/23168)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.436% (21534/23296)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.444% (21654/23424)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.442% (21772/23552)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.458% (21894/23680)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.440% (22008/23808)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.417% (22121/23936)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.420% (22240/24064)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.411% (22356/24192)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.393% (22470/24320)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.384% (22586/24448)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.379% (22703/24576)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.382% (22822/24704)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.377% (22939/24832)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.384% (23059/24960)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.387% (23178/25088)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.394% (23298/25216)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.393% (23416/25344)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.392% (23534/25472)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.395% (23653/25600)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.370% (23765/25728)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.381% (23886/25856)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.384% (24005/25984)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.390% (24125/26112)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.382% (24241/26240)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.400% (24364/26368)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.399% (24482/26496)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.402% (24601/26624)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.404% (24720/26752)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.411% (24840/26880)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.417% (24960/27008)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.398% (25073/27136)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.404% (25193/27264)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.385% (25306/27392)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.406% (25430/27520)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.415% (25551/27648)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.404% (25666/27776)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.410% (25786/27904)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.412% (25905/28032)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.411% (26023/28160)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.407% (26140/28288)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.413% (26260/28416)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.422% (26381/28544)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.418% (26498/28672)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.427% (26619/28800)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.429% (26738/28928)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.449% (26862/29056)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.451% (26981/29184)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.471% (27105/29312)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.469% (27223/29440)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.455% (27337/29568)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.450% (27454/29696)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.452% (27573/29824)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.435% (27686/29952)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.420% (27800/30080)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.413% (27916/30208)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.408% (28033/30336)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.401% (28149/30464)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.403% (28268/30592)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.419% (28391/30720)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.424% (28511/30848)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.423% (28629/30976)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.425% (28748/31104)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.440% (28871/31232)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.439% (28989/31360)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.445% (29109/31488)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.437% (29225/31616)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.443% (29345/31744)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.435% (29461/31872)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.441% (29581/32000)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.433% (29697/32128)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.442% (29818/32256)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.447% (29938/32384)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.434% (30052/32512)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.439% (30172/32640)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.438% (30290/32768)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.455% (30414/32896)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.427% (30523/33024)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.438% (30645/33152)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.452% (30768/33280)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.439% (30882/33408)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.450% (31004/33536)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.458% (31125/33664)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.460% (31244/33792)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.471% (31366/33920)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.469% (31484/34048)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.477% (31605/34176)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.476% (31723/34304)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.481% (31843/34432)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.471% (31958/34560)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.473% (32077/34688)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.478% (32197/34816)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.485% (32318/34944)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.490% (32438/35072)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.486% (32555/35200)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.482% (32672/35328)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.484% (32791/35456)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.485% (32910/35584)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.484% (33028/35712)\n",
      "Train Epoch: 30 | Loss: 0.215 | Acc: 92.480% (33145/35840)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.474% (33261/35968)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.462% (33375/36096)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.458% (33492/36224)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.463% (33612/36352)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.456% (33728/36480)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.463% (33849/36608)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.468% (33969/36736)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.467% (34087/36864)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.463% (34204/36992)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.443% (34315/37120)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.456% (34438/37248)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.460% (34558/37376)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.457% (34675/37504)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.461% (34795/37632)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.458% (34912/37760)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.462% (35032/37888)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.464% (35151/38016)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.476% (35274/38144)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.475% (35392/38272)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.471% (35509/38400)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.465% (35625/38528)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.454% (35739/38656)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.463% (35861/38784)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.473% (35983/38912)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.477% (36103/39040)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.494% (36228/39168)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.498% (36348/39296)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.502% (36468/39424)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.501% (36586/39552)\n",
      "Train Epoch: 30 | Loss: 0.216 | Acc: 92.508% (36707/39680)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.502% (36823/39808)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.480% (36933/39936)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.462% (37044/40064)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.459% (37161/40192)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.470% (37284/40320)\n",
      "Train Epoch: 30 | Loss: 0.217 | Acc: 92.469% (37402/40448)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.459% (37516/40576)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.458% (37634/40704)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.447% (37748/40832)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.451% (37868/40960)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.448% (37985/41088)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.445% (38102/41216)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.437% (38217/41344)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.436% (38335/41472)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.423% (38448/41600)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.415% (38563/41728)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.426% (38686/41856)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.426% (38804/41984)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.427% (38923/42112)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.422% (39039/42240)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.424% (39158/42368)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.423% (39276/42496)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.417% (39392/42624)\n",
      "Train Epoch: 30 | Loss: 0.218 | Acc: 92.414% (39509/42752)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.416% (39628/42880)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.415% (39746/43008)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.419% (39866/43136)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.402% (39977/43264)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.388% (40089/43392)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.392% (40209/43520)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.389% (40326/43648)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.400% (40449/43776)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.392% (40564/43904)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.406% (40688/44032)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.403% (40805/44160)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.402% (40923/44288)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.401% (41041/44416)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.392% (41155/44544)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.393% (41274/44672)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.397% (41394/44800)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.397% (41512/44928)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.396% (41630/45056)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.396% (41748/45184)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.388% (41863/45312)\n",
      "Train Epoch: 30 | Loss: 0.219 | Acc: 92.388% (41981/45440)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.381% (42096/45568)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.382% (42215/45696)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.382% (42333/45824)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.372% (42447/45952)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.374% (42566/46080)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.367% (42681/46208)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.371% (42801/46336)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.370% (42919/46464)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.366% (43035/46592)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.359% (43150/46720)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.352% (43265/46848)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.351% (43383/46976)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.345% (43498/47104)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.342% (43615/47232)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.344% (43734/47360)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.343% (43852/47488)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.332% (43965/47616)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.326% (44080/47744)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.323% (44197/47872)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.321% (44314/48000)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.331% (44437/48128)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.324% (44552/48256)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.330% (44673/48384)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.340% (44796/48512)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.338% (44913/48640)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.337% (45031/48768)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.331% (45146/48896)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.324% (45261/49024)\n",
      "Train Epoch: 30 | Loss: 0.220 | Acc: 92.330% (45382/49152)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.321% (45496/49280)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.313% (45610/49408)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.313% (45728/49536)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.320% (45850/49664)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.314% (45965/49792)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.308% (46080/49920)\n",
      "Train Epoch: 30 | Loss: 0.221 | Acc: 92.310% (46155/50000)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 30 | Loss: 0.410 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 30 | Loss: 0.350 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 30 | Loss: 0.387 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 30 | Loss: 0.366 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 30 | Loss: 0.335 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 30 | Loss: 0.359 | Acc: 88.714% (621/700)\n",
      "Test Epoch: 30 | Loss: 0.380 | Acc: 88.500% (708/800)\n",
      "Test Epoch: 30 | Loss: 0.372 | Acc: 88.667% (798/900)\n",
      "Test Epoch: 30 | Loss: 0.384 | Acc: 88.400% (884/1000)\n",
      "Test Epoch: 30 | Loss: 0.386 | Acc: 88.091% (969/1100)\n",
      "Test Epoch: 30 | Loss: 0.396 | Acc: 87.917% (1055/1200)\n",
      "Test Epoch: 30 | Loss: 0.397 | Acc: 87.923% (1143/1300)\n",
      "Test Epoch: 30 | Loss: 0.391 | Acc: 88.143% (1234/1400)\n",
      "Test Epoch: 30 | Loss: 0.389 | Acc: 88.067% (1321/1500)\n",
      "Test Epoch: 30 | Loss: 0.387 | Acc: 87.938% (1407/1600)\n",
      "Test Epoch: 30 | Loss: 0.388 | Acc: 87.941% (1495/1700)\n",
      "Test Epoch: 30 | Loss: 0.390 | Acc: 88.000% (1584/1800)\n",
      "Test Epoch: 30 | Loss: 0.398 | Acc: 87.842% (1669/1900)\n",
      "Test Epoch: 30 | Loss: 0.403 | Acc: 87.600% (1752/2000)\n",
      "Test Epoch: 30 | Loss: 0.407 | Acc: 87.429% (1836/2100)\n",
      "Test Epoch: 30 | Loss: 0.413 | Acc: 87.227% (1919/2200)\n",
      "Test Epoch: 30 | Loss: 0.413 | Acc: 87.304% (2008/2300)\n",
      "Test Epoch: 30 | Loss: 0.414 | Acc: 87.250% (2094/2400)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.160% (2179/2500)\n",
      "Test Epoch: 30 | Loss: 0.432 | Acc: 86.962% (2261/2600)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 87.074% (2351/2700)\n",
      "Test Epoch: 30 | Loss: 0.424 | Acc: 87.214% (2442/2800)\n",
      "Test Epoch: 30 | Loss: 0.428 | Acc: 87.241% (2530/2900)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 87.400% (2622/3000)\n",
      "Test Epoch: 30 | Loss: 0.429 | Acc: 87.387% (2709/3100)\n",
      "Test Epoch: 30 | Loss: 0.428 | Acc: 87.281% (2793/3200)\n",
      "Test Epoch: 30 | Loss: 0.432 | Acc: 87.121% (2875/3300)\n",
      "Test Epoch: 30 | Loss: 0.428 | Acc: 87.206% (2965/3400)\n",
      "Test Epoch: 30 | Loss: 0.435 | Acc: 87.086% (3048/3500)\n",
      "Test Epoch: 30 | Loss: 0.440 | Acc: 87.056% (3134/3600)\n",
      "Test Epoch: 30 | Loss: 0.442 | Acc: 87.081% (3222/3700)\n",
      "Test Epoch: 30 | Loss: 0.443 | Acc: 87.158% (3312/3800)\n",
      "Test Epoch: 30 | Loss: 0.440 | Acc: 87.282% (3404/3900)\n",
      "Test Epoch: 30 | Loss: 0.439 | Acc: 87.275% (3491/4000)\n",
      "Test Epoch: 30 | Loss: 0.441 | Acc: 87.195% (3575/4100)\n",
      "Test Epoch: 30 | Loss: 0.442 | Acc: 87.119% (3659/4200)\n",
      "Test Epoch: 30 | Loss: 0.439 | Acc: 87.163% (3748/4300)\n",
      "Test Epoch: 30 | Loss: 0.440 | Acc: 87.159% (3835/4400)\n",
      "Test Epoch: 30 | Loss: 0.438 | Acc: 87.244% (3926/4500)\n",
      "Test Epoch: 30 | Loss: 0.439 | Acc: 87.239% (4013/4600)\n",
      "Test Epoch: 30 | Loss: 0.435 | Acc: 87.234% (4100/4700)\n",
      "Test Epoch: 30 | Loss: 0.437 | Acc: 87.167% (4184/4800)\n",
      "Test Epoch: 30 | Loss: 0.433 | Acc: 87.327% (4279/4900)\n",
      "Test Epoch: 30 | Loss: 0.435 | Acc: 87.320% (4366/5000)\n",
      "Test Epoch: 30 | Loss: 0.431 | Acc: 87.471% (4461/5100)\n",
      "Test Epoch: 30 | Loss: 0.434 | Acc: 87.365% (4543/5200)\n",
      "Test Epoch: 30 | Loss: 0.433 | Acc: 87.302% (4627/5300)\n",
      "Test Epoch: 30 | Loss: 0.431 | Acc: 87.352% (4717/5400)\n",
      "Test Epoch: 30 | Loss: 0.431 | Acc: 87.309% (4802/5500)\n",
      "Test Epoch: 30 | Loss: 0.430 | Acc: 87.321% (4890/5600)\n",
      "Test Epoch: 30 | Loss: 0.429 | Acc: 87.281% (4975/5700)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 87.293% (5063/5800)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 87.288% (5150/5900)\n",
      "Test Epoch: 30 | Loss: 0.425 | Acc: 87.333% (5240/6000)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.361% (5329/6100)\n",
      "Test Epoch: 30 | Loss: 0.425 | Acc: 87.258% (5410/6200)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.333% (5502/6300)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.406% (5594/6400)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.415% (5682/6500)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.409% (5769/6600)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 87.448% (5859/6700)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.441% (5946/6800)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.464% (6035/6900)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.400% (6118/7000)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.437% (6208/7100)\n",
      "Test Epoch: 30 | Loss: 0.425 | Acc: 87.431% (6295/7200)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.479% (6386/7300)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.486% (6474/7400)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.413% (6556/7500)\n",
      "Test Epoch: 30 | Loss: 0.424 | Acc: 87.368% (6640/7600)\n",
      "Test Epoch: 30 | Loss: 0.425 | Acc: 87.338% (6725/7700)\n",
      "Test Epoch: 30 | Loss: 0.424 | Acc: 87.385% (6816/7800)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.418% (6906/7900)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.438% (6995/8000)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.481% (7086/8100)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.488% (7174/8200)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 87.494% (7262/8300)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 87.476% (7348/8400)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.400% (7429/8500)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.384% (7515/8600)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.368% (7601/8700)\n",
      "Test Epoch: 30 | Loss: 0.424 | Acc: 87.375% (7689/8800)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.360% (7775/8900)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.344% (7861/9000)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 87.286% (7943/9100)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.304% (8032/9200)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.312% (8120/9300)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.298% (8206/9400)\n",
      "Test Epoch: 30 | Loss: 0.422 | Acc: 87.305% (8294/9500)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.333% (8384/9600)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 87.381% (8476/9700)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.337% (8559/9800)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 87.343% (8647/9900)\n",
      "Test Epoch: 30 | Loss: 0.420 | Acc: 87.360% (8736/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 31\n",
      "Train Epoch: 31 | Loss: 0.302 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 31 | Loss: 0.245 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 31 | Loss: 0.244 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 31 | Loss: 0.245 | Acc: 91.992% (471/512)\n",
      "Train Epoch: 31 | Loss: 0.235 | Acc: 91.406% (585/640)\n",
      "Train Epoch: 31 | Loss: 0.221 | Acc: 91.667% (704/768)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 91.853% (823/896)\n",
      "Train Epoch: 31 | Loss: 0.224 | Acc: 91.699% (939/1024)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.014% (1060/1152)\n",
      "Train Epoch: 31 | Loss: 0.220 | Acc: 91.953% (1177/1280)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.188% (1298/1408)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 91.927% (1412/1536)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.067% (1532/1664)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.188% (1652/1792)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.292% (1772/1920)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.188% (1888/2048)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.004% (2002/2176)\n",
      "Train Epoch: 31 | Loss: 0.211 | Acc: 92.101% (2122/2304)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.229% (2243/2432)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.227% (2361/2560)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.299% (2481/2688)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.330% (2600/2816)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.527% (2724/2944)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.546% (2843/3072)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.594% (2963/3200)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.638% (3083/3328)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.622% (3201/3456)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.578% (3318/3584)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.565% (3436/3712)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.474% (3551/3840)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.566% (3673/3968)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.554% (3791/4096)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.543% (3909/4224)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.647% (4032/4352)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.522% (4145/4480)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.600% (4267/4608)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.652% (4388/4736)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.599% (4504/4864)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.608% (4623/4992)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.637% (4743/5120)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.683% (4864/5248)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.653% (4981/5376)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.605% (5097/5504)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.631% (5217/5632)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.622% (5335/5760)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.663% (5456/5888)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.670% (5575/6016)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.660% (5693/6144)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.714% (5815/6272)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.656% (5930/6400)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.632% (6047/6528)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.608% (6164/6656)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.630% (6284/6784)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.549% (6397/6912)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.571% (6517/7040)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.564% (6635/7168)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.612% (6757/7296)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.632% (6877/7424)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.598% (6993/7552)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.578% (7110/7680)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.610% (7231/7808)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.578% (7347/7936)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.609% (7468/8064)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.615% (7587/8192)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.584% (7703/8320)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.637% (7826/8448)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.666% (7947/8576)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.705% (8069/8704)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.731% (8190/8832)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.768% (8312/8960)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.738% (8428/9088)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.741% (8547/9216)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.712% (8663/9344)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.705% (8781/9472)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.740% (8903/9600)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.763% (9024/9728)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.817% (9148/9856)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.748% (9260/9984)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.801% (9384/10112)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.832% (9506/10240)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.824% (9624/10368)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.816% (9742/10496)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.818% (9861/10624)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.839% (9982/10752)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.812% (10098/10880)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.769% (10212/11008)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.762% (10330/11136)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.782% (10451/11264)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.741% (10565/11392)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.743% (10684/11520)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.737% (10802/11648)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.731% (10920/11776)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.759% (11042/11904)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.778% (11163/12032)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.763% (11280/12160)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.773% (11400/12288)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.775% (11519/12416)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.801% (11641/12544)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.779% (11757/12672)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.773% (11875/12800)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.806% (11998/12928)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.839% (12121/13056)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.847% (12241/13184)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.886% (12365/13312)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.917% (12488/13440)\n",
      "Train Epoch: 31 | Loss: 0.200 | Acc: 92.954% (12612/13568)\n",
      "Train Epoch: 31 | Loss: 0.200 | Acc: 92.932% (12728/13696)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.911% (12844/13824)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.933% (12966/13952)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.940% (13086/14080)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.927% (13203/14208)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.899% (13318/14336)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.893% (13436/14464)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.859% (13550/14592)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.840% (13666/14720)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.874% (13790/14848)\n",
      "Train Epoch: 31 | Loss: 0.201 | Acc: 92.889% (13911/14976)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.876% (14028/15104)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.870% (14146/15232)\n",
      "Train Epoch: 31 | Loss: 0.202 | Acc: 92.852% (14262/15360)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.801% (14373/15488)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.828% (14496/15616)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.823% (14614/15744)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.855% (14738/15872)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.862% (14858/16000)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.870% (14978/16128)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.858% (15095/16256)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.853% (15213/16384)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.860% (15333/16512)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.867% (15453/16640)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.855% (15570/16768)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.880% (15693/16896)\n",
      "Train Epoch: 31 | Loss: 0.203 | Acc: 92.881% (15812/17024)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.881% (15931/17152)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.870% (16048/17280)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.871% (16167/17408)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.878% (16287/17536)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.873% (16405/17664)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.873% (16524/17792)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.874% (16643/17920)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.875% (16762/18048)\n",
      "Train Epoch: 31 | Loss: 0.204 | Acc: 92.875% (16881/18176)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.865% (16998/18304)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.855% (17115/18432)\n",
      "Train Epoch: 31 | Loss: 0.205 | Acc: 92.861% (17235/18560)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.824% (17347/18688)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.820% (17465/18816)\n",
      "Train Epoch: 31 | Loss: 0.206 | Acc: 92.816% (17583/18944)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.801% (17699/19072)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.792% (17816/19200)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.793% (17935/19328)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.794% (18054/19456)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.770% (18168/19584)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.756% (18284/19712)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.762% (18404/19840)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.753% (18521/19968)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.760% (18641/20096)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.786% (18765/20224)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.797% (18886/20352)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.783% (19002/20480)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.765% (19117/20608)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.771% (19237/20736)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.777% (19357/20864)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.769% (19474/20992)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.760% (19591/21120)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.738% (19705/21248)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.725% (19821/21376)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.713% (19937/21504)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.719% (20057/21632)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.725% (20177/21760)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.727% (20296/21888)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.723% (20414/22016)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.711% (20530/22144)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.713% (20649/22272)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.719% (20769/22400)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.716% (20887/22528)\n",
      "Train Epoch: 31 | Loss: 0.207 | Acc: 92.717% (21006/22656)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.692% (21119/22784)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.703% (21240/22912)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.704% (21359/23040)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.684% (21473/23168)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.638% (21581/23296)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.640% (21700/23424)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.633% (21817/23552)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.614% (21931/23680)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.641% (22056/23808)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.647% (22176/23936)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.670% (22300/24064)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.688% (22423/24192)\n",
      "Train Epoch: 31 | Loss: 0.208 | Acc: 92.689% (22542/24320)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.670% (22656/24448)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.668% (22774/24576)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.657% (22890/24704)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.647% (23006/24832)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.648% (23125/24960)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.642% (23242/25088)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.636% (23359/25216)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.641% (23479/25344)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.623% (23593/25472)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.633% (23714/25600)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.654% (23838/25728)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.644% (23954/25856)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.657% (24076/25984)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.666% (24197/26112)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.668% (24316/26240)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.650% (24430/26368)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.648% (24548/26496)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.653% (24668/26624)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.658% (24788/26752)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.667% (24909/26880)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.661% (25026/27008)\n",
      "Train Epoch: 31 | Loss: 0.209 | Acc: 92.678% (25149/27136)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.642% (25258/27264)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.626% (25372/27392)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.631% (25492/27520)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.640% (25613/27648)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.638% (25731/27776)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.643% (25851/27904)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.651% (25972/28032)\n",
      "Train Epoch: 31 | Loss: 0.211 | Acc: 92.635% (26086/28160)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.651% (26209/28288)\n",
      "Train Epoch: 31 | Loss: 0.210 | Acc: 92.641% (26325/28416)\n",
      "Train Epoch: 31 | Loss: 0.211 | Acc: 92.629% (26440/28544)\n",
      "Train Epoch: 31 | Loss: 0.211 | Acc: 92.599% (26550/28672)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.576% (26662/28800)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.564% (26777/28928)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.563% (26895/29056)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.571% (27016/29184)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.576% (27136/29312)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.582% (27256/29440)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.566% (27370/29568)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.575% (27491/29696)\n",
      "Train Epoch: 31 | Loss: 0.212 | Acc: 92.580% (27611/29824)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.555% (27722/29952)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.540% (27836/30080)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.548% (27957/30208)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.547% (28075/30336)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.545% (28193/30464)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.554% (28314/30592)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.568% (28437/30720)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.573% (28557/30848)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.565% (28673/30976)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.580% (28796/31104)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.565% (28910/31232)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.567% (29029/31360)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.572% (29149/31488)\n",
      "Train Epoch: 31 | Loss: 0.213 | Acc: 92.551% (29261/31616)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.521% (29370/31744)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.504% (29483/31872)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.503% (29601/32000)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.496% (29717/32128)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.498% (29836/32256)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.506% (29957/32384)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.504% (30075/32512)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.509% (30195/32640)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.502% (30311/32768)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.507% (30431/32896)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.499% (30547/33024)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.498% (30665/33152)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.488% (30780/33280)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.502% (30903/33408)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.501% (31021/33536)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.496% (31138/33664)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.489% (31254/33792)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.479% (31369/33920)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.481% (31488/34048)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.486% (31608/34176)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.497% (31730/34304)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.490% (31846/34432)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.486% (31963/34560)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.490% (32083/34688)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.489% (32201/34816)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.497% (32322/34944)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.484% (32436/35072)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.497% (32559/35200)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.499% (32678/35328)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.509% (32800/35456)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.505% (32917/35584)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.507% (33036/35712)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.508% (33155/35840)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.504% (33272/35968)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.495% (33387/36096)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.486% (33502/36224)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.493% (33623/36352)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.486% (33739/36480)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.491% (33859/36608)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.506% (33983/36736)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.518% (34106/36864)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.520% (34225/36992)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.532% (34348/37120)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.537% (34468/37248)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.535% (34586/37376)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.521% (34699/37504)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.530% (34821/37632)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.526% (34938/37760)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.531% (35058/37888)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.524% (35174/38016)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.520% (35291/38144)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.517% (35408/38272)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.500% (35520/38400)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.491% (35635/38528)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.493% (35754/38656)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.479% (35867/38784)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.486% (35988/38912)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.500% (36112/39040)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.491% (36227/39168)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.480% (36341/39296)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.487% (36462/39424)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.504% (36587/39552)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.510% (36708/39680)\n",
      "Train Epoch: 31 | Loss: 0.214 | Acc: 92.504% (36824/39808)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.485% (36935/39936)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.485% (37053/40064)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.481% (37170/40192)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.485% (37290/40320)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.472% (37403/40448)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.461% (37517/40576)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.453% (37632/40704)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.452% (37750/40832)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.454% (37869/40960)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.460% (37990/41088)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.452% (38105/41216)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.461% (38227/41344)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.462% (38346/41472)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.462% (38464/41600)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.458% (38581/41728)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.462% (38701/41856)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.447% (38813/41984)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.418% (38919/42112)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.422% (39039/42240)\n",
      "Train Epoch: 31 | Loss: 0.215 | Acc: 92.424% (39158/42368)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.416% (39273/42496)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.417% (39392/42624)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.414% (39509/42752)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.418% (39629/42880)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.404% (39741/43008)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.396% (39856/43136)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.402% (39977/43264)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.413% (40100/43392)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.422% (40222/43520)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.407% (40334/43648)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.407% (40452/43776)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.404% (40569/43904)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.401% (40686/44032)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.398% (40803/44160)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.407% (40925/44288)\n",
      "Train Epoch: 31 | Loss: 0.216 | Acc: 92.415% (41047/44416)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.405% (41161/44544)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.409% (41281/44672)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.402% (41396/44800)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.399% (41513/44928)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.394% (41629/45056)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.396% (41748/45184)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.391% (41864/45312)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.392% (41983/45440)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.396% (42103/45568)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.393% (42220/45696)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.382% (42333/45824)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.381% (42451/45952)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.383% (42570/46080)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.380% (42687/46208)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.382% (42806/46336)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.390% (42928/46464)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.383% (43043/46592)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.376% (43158/46720)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.373% (43275/46848)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.379% (43396/46976)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.381% (43515/47104)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.387% (43636/47232)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.375% (43749/47360)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.375% (43867/47488)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.381% (43988/47616)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.386% (44109/47744)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.380% (44224/47872)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.383% (44344/48000)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.375% (44458/48128)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.382% (44580/48256)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.384% (44699/48384)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.383% (44817/48512)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.387% (44937/48640)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.391% (45057/48768)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.390% (45175/48896)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.391% (45294/49024)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.393% (45413/49152)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 92.382% (45526/49280)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 92.382% (45644/49408)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.381% (45762/49536)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 92.371% (45875/49664)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 92.370% (45993/49792)\n",
      "Train Epoch: 31 | Loss: 0.218 | Acc: 92.380% (46116/49920)\n",
      "Train Epoch: 31 | Loss: 0.217 | Acc: 92.382% (46191/50000)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 31 | Loss: 0.333 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 31 | Loss: 0.339 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 31 | Loss: 0.340 | Acc: 87.750% (351/400)\n",
      "Test Epoch: 31 | Loss: 0.360 | Acc: 87.400% (437/500)\n",
      "Test Epoch: 31 | Loss: 0.333 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 31 | Loss: 0.353 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 31 | Loss: 0.357 | Acc: 87.750% (702/800)\n",
      "Test Epoch: 31 | Loss: 0.379 | Acc: 87.222% (785/900)\n",
      "Test Epoch: 31 | Loss: 0.381 | Acc: 87.100% (871/1000)\n",
      "Test Epoch: 31 | Loss: 0.396 | Acc: 86.636% (953/1100)\n",
      "Test Epoch: 31 | Loss: 0.411 | Acc: 86.500% (1038/1200)\n",
      "Test Epoch: 31 | Loss: 0.410 | Acc: 86.692% (1127/1300)\n",
      "Test Epoch: 31 | Loss: 0.404 | Acc: 86.857% (1216/1400)\n",
      "Test Epoch: 31 | Loss: 0.398 | Acc: 87.133% (1307/1500)\n",
      "Test Epoch: 31 | Loss: 0.398 | Acc: 87.250% (1396/1600)\n",
      "Test Epoch: 31 | Loss: 0.400 | Acc: 87.412% (1486/1700)\n",
      "Test Epoch: 31 | Loss: 0.406 | Acc: 87.167% (1569/1800)\n",
      "Test Epoch: 31 | Loss: 0.403 | Acc: 87.263% (1658/1900)\n",
      "Test Epoch: 31 | Loss: 0.418 | Acc: 86.950% (1739/2000)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.571% (1818/2100)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 86.500% (1903/2200)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 86.435% (1988/2300)\n",
      "Test Epoch: 31 | Loss: 0.432 | Acc: 86.500% (2076/2400)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.520% (2163/2500)\n",
      "Test Epoch: 31 | Loss: 0.450 | Acc: 86.500% (2249/2600)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.630% (2339/2700)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.679% (2427/2800)\n",
      "Test Epoch: 31 | Loss: 0.441 | Acc: 86.828% (2518/2900)\n",
      "Test Epoch: 31 | Loss: 0.439 | Acc: 86.700% (2601/3000)\n",
      "Test Epoch: 31 | Loss: 0.442 | Acc: 86.613% (2685/3100)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.594% (2771/3200)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.606% (2858/3300)\n",
      "Test Epoch: 31 | Loss: 0.434 | Acc: 86.676% (2947/3400)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.600% (3031/3500)\n",
      "Test Epoch: 31 | Loss: 0.443 | Acc: 86.556% (3116/3600)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.568% (3203/3700)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.579% (3290/3800)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.641% (3379/3900)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.600% (3464/4000)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.561% (3549/4100)\n",
      "Test Epoch: 31 | Loss: 0.448 | Acc: 86.500% (3633/4200)\n",
      "Test Epoch: 31 | Loss: 0.443 | Acc: 86.581% (3723/4300)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.636% (3812/4400)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.622% (3898/4500)\n",
      "Test Epoch: 31 | Loss: 0.447 | Acc: 86.565% (3982/4600)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.681% (4074/4700)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.667% (4160/4800)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.694% (4248/4900)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.660% (4333/5000)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.706% (4422/5100)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.712% (4509/5200)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.660% (4593/5300)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.667% (4680/5400)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.636% (4765/5500)\n",
      "Test Epoch: 31 | Loss: 0.449 | Acc: 86.571% (4848/5600)\n",
      "Test Epoch: 31 | Loss: 0.448 | Acc: 86.614% (4937/5700)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.707% (5029/5800)\n",
      "Test Epoch: 31 | Loss: 0.447 | Acc: 86.661% (5113/5900)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.667% (5200/6000)\n",
      "Test Epoch: 31 | Loss: 0.442 | Acc: 86.770% (5293/6100)\n",
      "Test Epoch: 31 | Loss: 0.441 | Acc: 86.823% (5383/6200)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.873% (5473/6300)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.938% (5564/6400)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 86.938% (5651/6500)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 86.924% (5737/6600)\n",
      "Test Epoch: 31 | Loss: 0.434 | Acc: 86.985% (5828/6700)\n",
      "Test Epoch: 31 | Loss: 0.436 | Acc: 86.941% (5912/6800)\n",
      "Test Epoch: 31 | Loss: 0.436 | Acc: 86.957% (6000/6900)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 86.871% (6081/7000)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.887% (6169/7100)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.931% (6259/7200)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 86.959% (6348/7300)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.892% (6430/7400)\n",
      "Test Epoch: 31 | Loss: 0.441 | Acc: 86.827% (6512/7500)\n",
      "Test Epoch: 31 | Loss: 0.443 | Acc: 86.842% (6600/7600)\n",
      "Test Epoch: 31 | Loss: 0.442 | Acc: 86.909% (6692/7700)\n",
      "Test Epoch: 31 | Loss: 0.441 | Acc: 86.923% (6780/7800)\n",
      "Test Epoch: 31 | Loss: 0.442 | Acc: 86.924% (6867/7900)\n",
      "Test Epoch: 31 | Loss: 0.443 | Acc: 86.862% (6949/8000)\n",
      "Test Epoch: 31 | Loss: 0.441 | Acc: 86.914% (7040/8100)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.915% (7127/8200)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.916% (7214/8300)\n",
      "Test Epoch: 31 | Loss: 0.440 | Acc: 86.881% (7298/8400)\n",
      "Test Epoch: 31 | Loss: 0.443 | Acc: 86.824% (7380/8500)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.802% (7465/8600)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.793% (7551/8700)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.830% (7641/8800)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.820% (7727/8900)\n",
      "Test Epoch: 31 | Loss: 0.448 | Acc: 86.800% (7812/9000)\n",
      "Test Epoch: 31 | Loss: 0.447 | Acc: 86.824% (7901/9100)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.859% (7991/9200)\n",
      "Test Epoch: 31 | Loss: 0.447 | Acc: 86.796% (8072/9300)\n",
      "Test Epoch: 31 | Loss: 0.448 | Acc: 86.819% (8161/9400)\n",
      "Test Epoch: 31 | Loss: 0.447 | Acc: 86.811% (8247/9500)\n",
      "Test Epoch: 31 | Loss: 0.446 | Acc: 86.823% (8335/9600)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.845% (8424/9700)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.847% (8511/9800)\n",
      "Test Epoch: 31 | Loss: 0.445 | Acc: 86.879% (8601/9900)\n",
      "Test Epoch: 31 | Loss: 0.444 | Acc: 86.920% (8692/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Train Epoch: 32 | Loss: 0.143 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 32 | Loss: 0.152 | Acc: 93.359% (239/256)\n",
      "Train Epoch: 32 | Loss: 0.161 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 32 | Loss: 0.173 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 32 | Loss: 0.166 | Acc: 92.969% (595/640)\n",
      "Train Epoch: 32 | Loss: 0.170 | Acc: 93.099% (715/768)\n",
      "Train Epoch: 32 | Loss: 0.177 | Acc: 93.192% (835/896)\n",
      "Train Epoch: 32 | Loss: 0.182 | Acc: 92.969% (952/1024)\n",
      "Train Epoch: 32 | Loss: 0.181 | Acc: 93.056% (1072/1152)\n",
      "Train Epoch: 32 | Loss: 0.201 | Acc: 92.734% (1187/1280)\n",
      "Train Epoch: 32 | Loss: 0.199 | Acc: 92.756% (1306/1408)\n",
      "Train Epoch: 32 | Loss: 0.193 | Acc: 93.034% (1429/1536)\n",
      "Train Epoch: 32 | Loss: 0.190 | Acc: 93.149% (1550/1664)\n",
      "Train Epoch: 32 | Loss: 0.203 | Acc: 92.969% (1666/1792)\n",
      "Train Epoch: 32 | Loss: 0.202 | Acc: 93.125% (1788/1920)\n",
      "Train Epoch: 32 | Loss: 0.200 | Acc: 93.164% (1908/2048)\n",
      "Train Epoch: 32 | Loss: 0.199 | Acc: 92.969% (2023/2176)\n",
      "Train Epoch: 32 | Loss: 0.200 | Acc: 92.925% (2141/2304)\n",
      "Train Epoch: 32 | Loss: 0.203 | Acc: 92.763% (2256/2432)\n",
      "Train Epoch: 32 | Loss: 0.202 | Acc: 92.812% (2376/2560)\n",
      "Train Epoch: 32 | Loss: 0.205 | Acc: 92.746% (2493/2688)\n",
      "Train Epoch: 32 | Loss: 0.202 | Acc: 92.898% (2616/2816)\n",
      "Train Epoch: 32 | Loss: 0.201 | Acc: 92.969% (2737/2944)\n",
      "Train Epoch: 32 | Loss: 0.204 | Acc: 92.871% (2853/3072)\n",
      "Train Epoch: 32 | Loss: 0.208 | Acc: 92.656% (2965/3200)\n",
      "Train Epoch: 32 | Loss: 0.208 | Acc: 92.698% (3085/3328)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.708% (3204/3456)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.662% (3321/3584)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.753% (3443/3712)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.630% (3557/3840)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.389% (3666/3968)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.285% (3780/4096)\n",
      "Train Epoch: 32 | Loss: 0.219 | Acc: 92.211% (3895/4224)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.302% (4017/4352)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.411% (4140/4480)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.383% (4257/4608)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.462% (4379/4736)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.475% (4498/4864)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.328% (4609/4992)\n",
      "Train Epoch: 32 | Loss: 0.219 | Acc: 92.324% (4727/5120)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.359% (4847/5248)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.318% (4963/5376)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.333% (5082/5504)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.383% (5203/5632)\n",
      "Train Epoch: 32 | Loss: 0.215 | Acc: 92.448% (5325/5760)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.425% (5442/5888)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.387% (5558/6016)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.367% (5675/6144)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.395% (5795/6272)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.391% (5913/6400)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.402% (6032/6528)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.443% (6153/6656)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.423% (6270/6784)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.419% (6388/6912)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.429% (6507/7040)\n",
      "Train Epoch: 32 | Loss: 0.219 | Acc: 92.425% (6625/7168)\n",
      "Train Epoch: 32 | Loss: 0.218 | Acc: 92.448% (6745/7296)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.497% (6867/7424)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.479% (6984/7552)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.526% (7106/7680)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.559% (7227/7808)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.540% (7344/7936)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.498% (7459/8064)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.456% (7574/8192)\n",
      "Train Epoch: 32 | Loss: 0.217 | Acc: 92.452% (7692/8320)\n",
      "Train Epoch: 32 | Loss: 0.216 | Acc: 92.460% (7811/8448)\n",
      "Train Epoch: 32 | Loss: 0.215 | Acc: 92.467% (7930/8576)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.486% (8050/8704)\n",
      "Train Epoch: 32 | Loss: 0.215 | Acc: 92.493% (8169/8832)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.522% (8290/8960)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.562% (8412/9088)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.524% (8527/9216)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.509% (8644/9344)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.568% (8768/9472)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.573% (8887/9600)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.588% (9007/9728)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.654% (9132/9856)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.648% (9250/9984)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.652% (9369/10112)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.686% (9491/10240)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.708% (9612/10368)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.712% (9731/10496)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.705% (9849/10624)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.746% (9972/10752)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.721% (10088/10880)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.723% (10207/11008)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.726% (10326/11136)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.765% (10449/11264)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.741% (10565/11392)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.752% (10685/11520)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.746% (10803/11648)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.739% (10921/11776)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.734% (11039/11904)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.753% (11160/12032)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.722% (11275/12160)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.692% (11390/12288)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.687% (11508/12416)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.698% (11628/12544)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.724% (11750/12672)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.742% (11871/12800)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.690% (11983/12928)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.670% (12099/13056)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.650% (12215/13184)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.661% (12335/13312)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.671% (12455/13440)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.667% (12573/13568)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.647% (12689/13696)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.636% (12806/13824)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.661% (12928/13952)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.642% (13044/14080)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.645% (13163/14208)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.662% (13284/14336)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.692% (13407/14464)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.674% (13523/14592)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.636% (13636/14720)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.659% (13758/14848)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.662% (13877/14976)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.658% (13995/15104)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.647% (14112/15232)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.669% (14234/15360)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.685% (14355/15488)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.700% (14476/15616)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.721% (14598/15744)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.710% (14715/15872)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.700% (14832/16000)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.721% (14954/16128)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.717% (15072/16256)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.737% (15194/16384)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.739% (15313/16512)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.740% (15432/16640)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.748% (15552/16768)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.773% (15675/16896)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.781% (15795/17024)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.765% (15911/17152)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.772% (16031/17280)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.762% (16148/17408)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.752% (16265/17536)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.771% (16387/17664)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.800% (16511/17792)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.807% (16631/17920)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.808% (16750/18048)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.820% (16871/18176)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.794% (16985/18304)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.773% (17100/18432)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.786% (17221/18560)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.798% (17342/18688)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.809% (17463/18816)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.832% (17586/18944)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.817% (17702/19072)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.786% (17815/19200)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.793% (17935/19328)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.789% (18053/19456)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.785% (18171/19584)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.766% (18286/19712)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.782% (18408/19840)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.758% (18522/19968)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.770% (18643/20096)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.801% (18768/20224)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.802% (18887/20352)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.778% (19001/20480)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.804% (19125/20608)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.814% (19246/20736)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.796% (19361/20864)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.821% (19485/20992)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.827% (19605/21120)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.832% (19725/21248)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.824% (19842/21376)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.834% (19963/21504)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.839% (20083/21632)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.845% (20203/21760)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.832% (20319/21888)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.819% (20435/22016)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.820% (20554/22144)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.843% (20678/22272)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.839% (20796/22400)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.840% (20915/22528)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.836% (21033/22656)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.837% (21152/22784)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.842% (21272/22912)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.843% (21391/23040)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.852% (21512/23168)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.857% (21632/23296)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.853% (21750/23424)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.837% (21865/23552)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.817% (21979/23680)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.839% (22103/23808)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.831% (22220/23936)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.823% (22337/24064)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.836% (22459/24192)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.829% (22576/24320)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.821% (22693/24448)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.830% (22814/24576)\n",
      "Train Epoch: 32 | Loss: 0.209 | Acc: 92.847% (22937/24704)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.832% (23052/24832)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.829% (23170/24960)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.837% (23291/25088)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.846% (23412/25216)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.850% (23532/25344)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.851% (23651/25472)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.836% (23766/25600)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.840% (23886/25728)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.849% (24007/25856)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.846% (24125/25984)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.819% (24237/26112)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.832% (24359/26240)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.832% (24478/26368)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.810% (24591/26496)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.811% (24710/26624)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.815% (24830/26752)\n",
      "Train Epoch: 32 | Loss: 0.210 | Acc: 92.820% (24950/26880)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.806% (25065/27008)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.807% (25184/27136)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.800% (25301/27264)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.794% (25418/27392)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.769% (25530/27520)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.759% (25646/27648)\n",
      "Train Epoch: 32 | Loss: 0.211 | Acc: 92.774% (25769/27776)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.768% (25886/27904)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.744% (25998/28032)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.720% (26110/28160)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.725% (26230/28288)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.729% (26350/28416)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.738% (26471/28544)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.735% (26589/28672)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.729% (26706/28800)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.751% (26831/28928)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.745% (26948/29056)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.753% (27069/29184)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.747% (27186/29312)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.748% (27305/29440)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.746% (27423/29568)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.750% (27543/29696)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.754% (27663/29824)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.735% (27776/29952)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.719% (27890/30080)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.714% (28007/30208)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.725% (28129/30336)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.726% (28248/30464)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.733% (28369/30592)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.741% (28490/30720)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.739% (28608/30848)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.740% (28727/30976)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.737% (28845/31104)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.729% (28961/31232)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.723% (29078/31360)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.715% (29194/31488)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.719% (29314/31616)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.710% (29430/31744)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.705% (29547/31872)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.697% (29663/32000)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.689% (29779/32128)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.674% (29893/32256)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.678% (30013/32384)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.680% (30132/32512)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.684% (30252/32640)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.706% (30378/32768)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.707% (30497/32896)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.702% (30614/33024)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.703% (30733/33152)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.701% (30851/33280)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.699% (30969/33408)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.703% (31089/33536)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.707% (31209/33664)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.708% (31328/33792)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.703% (31445/33920)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.693% (31560/34048)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.691% (31678/34176)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.703% (31801/34304)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.702% (31919/34432)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.708% (32040/34560)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.712% (32160/34688)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.713% (32279/34816)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.714% (32398/34944)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.729% (32522/35072)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.727% (32640/35200)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.737% (32762/35328)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.715% (32873/35456)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.710% (32990/35584)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.720% (33112/35712)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.720% (33231/35840)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.716% (33348/35968)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.700% (33461/36096)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.695% (33578/36224)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.702% (33699/36352)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.697% (33816/36480)\n",
      "Train Epoch: 32 | Loss: 0.215 | Acc: 92.682% (33929/36608)\n",
      "Train Epoch: 32 | Loss: 0.215 | Acc: 92.675% (34045/36736)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.670% (34162/36864)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.674% (34282/36992)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.694% (34408/37120)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.698% (34528/37248)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.688% (34643/37376)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.689% (34762/37504)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.698% (34884/37632)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.707% (35006/37760)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.715% (35128/37888)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.721% (35249/38016)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.725% (35369/38144)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.718% (35485/38272)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.714% (35602/38400)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.704% (35717/38528)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.700% (35834/38656)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.695% (35951/38784)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.696% (36070/38912)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.700% (36190/39040)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.701% (36309/39168)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.702% (36428/39296)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.697% (36545/39424)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.693% (36662/39552)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.694% (36781/39680)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.680% (36894/39808)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.668% (37008/39936)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.674% (37129/40064)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.668% (37245/40192)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.669% (37364/40320)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.670% (37483/40448)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.653% (37595/40576)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.649% (37712/40704)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.650% (37831/40832)\n",
      "Train Epoch: 32 | Loss: 0.214 | Acc: 92.659% (37953/40960)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.665% (38074/41088)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.673% (38196/41216)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.679% (38317/41344)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.684% (38438/41472)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.671% (38551/41600)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.664% (38667/41728)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.665% (38786/41856)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.673% (38908/41984)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.670% (39025/42112)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.678% (39147/42240)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.678% (39266/42368)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.682% (39386/42496)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.690% (39508/42624)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.688% (39626/42752)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.689% (39745/42880)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.697% (39867/43008)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.695% (39985/43136)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.694% (40103/43264)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.692% (40221/43392)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.688% (40338/43520)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.696% (40460/43648)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.704% (40582/43776)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.695% (40697/43904)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.701% (40818/44032)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.711% (40941/44160)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.702% (41056/44288)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.710% (41178/44416)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.704% (41294/44544)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.702% (41412/44672)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.712% (41535/44800)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.713% (41654/44928)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.700% (41767/45056)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.681% (41877/45184)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.686% (41998/45312)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.687% (42117/45440)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.683% (42234/45568)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.684% (42353/45696)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.685% (42472/45824)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.686% (42591/45952)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.680% (42707/46080)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.681% (42826/46208)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.684% (42946/46336)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.685% (43065/46464)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.694% (43188/46592)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.693% (43306/46720)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.683% (43420/46848)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.692% (43543/46976)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.695% (43663/47104)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.685% (43777/47232)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.686% (43896/47360)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.687% (44015/47488)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.687% (44134/47616)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.673% (44246/47744)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.664% (44360/47872)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.662% (44478/48000)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.665% (44598/48128)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.666% (44717/48256)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.661% (44833/48384)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.657% (44950/48512)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.669% (45074/48640)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.663% (45190/48768)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.664% (45309/48896)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.665% (45428/49024)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.670% (45549/49152)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.668% (45667/49280)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.657% (45780/49408)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.656% (45898/49536)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.655% (46016/49664)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.647% (46131/49792)\n",
      "Train Epoch: 32 | Loss: 0.213 | Acc: 92.650% (46251/49920)\n",
      "Train Epoch: 32 | Loss: 0.212 | Acc: 92.652% (46326/50000)\n",
      "Test Epoch: 32 | Loss: 0.417 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 32 | Loss: 0.388 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 32 | Loss: 0.353 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 32 | Loss: 0.363 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 32 | Loss: 0.347 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 32 | Loss: 0.310 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 32 | Loss: 0.325 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 32 | Loss: 0.353 | Acc: 89.625% (717/800)\n",
      "Test Epoch: 32 | Loss: 0.387 | Acc: 88.333% (795/900)\n",
      "Test Epoch: 32 | Loss: 0.385 | Acc: 88.000% (880/1000)\n",
      "Test Epoch: 32 | Loss: 0.405 | Acc: 87.636% (964/1100)\n",
      "Test Epoch: 32 | Loss: 0.421 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 32 | Loss: 0.427 | Acc: 87.000% (1131/1300)\n",
      "Test Epoch: 32 | Loss: 0.426 | Acc: 87.071% (1219/1400)\n",
      "Test Epoch: 32 | Loss: 0.422 | Acc: 87.133% (1307/1500)\n",
      "Test Epoch: 32 | Loss: 0.421 | Acc: 87.188% (1395/1600)\n",
      "Test Epoch: 32 | Loss: 0.412 | Acc: 87.529% (1488/1700)\n",
      "Test Epoch: 32 | Loss: 0.416 | Acc: 87.333% (1572/1800)\n",
      "Test Epoch: 32 | Loss: 0.424 | Acc: 86.947% (1652/1900)\n",
      "Test Epoch: 32 | Loss: 0.437 | Acc: 86.750% (1735/2000)\n",
      "Test Epoch: 32 | Loss: 0.438 | Acc: 86.524% (1817/2100)\n",
      "Test Epoch: 32 | Loss: 0.435 | Acc: 86.455% (1902/2200)\n",
      "Test Epoch: 32 | Loss: 0.431 | Acc: 86.435% (1988/2300)\n",
      "Test Epoch: 32 | Loss: 0.428 | Acc: 86.458% (2075/2400)\n",
      "Test Epoch: 32 | Loss: 0.442 | Acc: 86.320% (2158/2500)\n",
      "Test Epoch: 32 | Loss: 0.452 | Acc: 86.269% (2243/2600)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.444% (2334/2700)\n",
      "Test Epoch: 32 | Loss: 0.439 | Acc: 86.464% (2421/2800)\n",
      "Test Epoch: 32 | Loss: 0.441 | Acc: 86.586% (2511/2900)\n",
      "Test Epoch: 32 | Loss: 0.440 | Acc: 86.633% (2599/3000)\n",
      "Test Epoch: 32 | Loss: 0.437 | Acc: 86.677% (2687/3100)\n",
      "Test Epoch: 32 | Loss: 0.439 | Acc: 86.656% (2773/3200)\n",
      "Test Epoch: 32 | Loss: 0.439 | Acc: 86.576% (2857/3300)\n",
      "Test Epoch: 32 | Loss: 0.437 | Acc: 86.559% (2943/3400)\n",
      "Test Epoch: 32 | Loss: 0.445 | Acc: 86.429% (3025/3500)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.472% (3113/3600)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.486% (3200/3700)\n",
      "Test Epoch: 32 | Loss: 0.445 | Acc: 86.526% (3288/3800)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.692% (3381/3900)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.600% (3464/4000)\n",
      "Test Epoch: 32 | Loss: 0.450 | Acc: 86.561% (3549/4100)\n",
      "Test Epoch: 32 | Loss: 0.455 | Acc: 86.500% (3633/4200)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.744% (3730/4300)\n",
      "Test Epoch: 32 | Loss: 0.450 | Acc: 86.750% (3817/4400)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.822% (3907/4500)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.761% (3991/4600)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.766% (4078/4700)\n",
      "Test Epoch: 32 | Loss: 0.450 | Acc: 86.771% (4165/4800)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.776% (4252/4900)\n",
      "Test Epoch: 32 | Loss: 0.452 | Acc: 86.680% (4334/5000)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.804% (4427/5100)\n",
      "Test Epoch: 32 | Loss: 0.451 | Acc: 86.731% (4510/5200)\n",
      "Test Epoch: 32 | Loss: 0.451 | Acc: 86.660% (4593/5300)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.741% (4684/5400)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.636% (4765/5500)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.571% (4848/5600)\n",
      "Test Epoch: 32 | Loss: 0.450 | Acc: 86.596% (4936/5700)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.672% (5027/5800)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.610% (5110/5900)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.633% (5198/6000)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.656% (5286/6100)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.597% (5369/6200)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.635% (5458/6300)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.672% (5547/6400)\n",
      "Test Epoch: 32 | Loss: 0.442 | Acc: 86.677% (5634/6500)\n",
      "Test Epoch: 32 | Loss: 0.441 | Acc: 86.697% (5722/6600)\n",
      "Test Epoch: 32 | Loss: 0.441 | Acc: 86.731% (5811/6700)\n",
      "Test Epoch: 32 | Loss: 0.442 | Acc: 86.647% (5892/6800)\n",
      "Test Epoch: 32 | Loss: 0.441 | Acc: 86.652% (5979/6900)\n",
      "Test Epoch: 32 | Loss: 0.442 | Acc: 86.586% (6061/7000)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.563% (6146/7100)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.542% (6231/7200)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.630% (6324/7300)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.649% (6412/7400)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.680% (6501/7500)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.711% (6590/7600)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.753% (6680/7700)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.744% (6766/7800)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.772% (6855/7900)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.737% (6939/8000)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.778% (7029/8100)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.744% (7113/8200)\n",
      "Test Epoch: 32 | Loss: 0.443 | Acc: 86.747% (7200/8300)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.714% (7284/8400)\n",
      "Test Epoch: 32 | Loss: 0.445 | Acc: 86.718% (7371/8500)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.640% (7451/8600)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.632% (7537/8700)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.614% (7622/8800)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.618% (7709/8900)\n",
      "Test Epoch: 32 | Loss: 0.451 | Acc: 86.578% (7792/9000)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.626% (7883/9100)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.630% (7970/9200)\n",
      "Test Epoch: 32 | Loss: 0.449 | Acc: 86.624% (8056/9300)\n",
      "Test Epoch: 32 | Loss: 0.448 | Acc: 86.649% (8145/9400)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.684% (8235/9500)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.708% (8324/9600)\n",
      "Test Epoch: 32 | Loss: 0.444 | Acc: 86.763% (8416/9700)\n",
      "Test Epoch: 32 | Loss: 0.445 | Acc: 86.776% (8504/9800)\n",
      "Test Epoch: 32 | Loss: 0.447 | Acc: 86.788% (8592/9900)\n",
      "Test Epoch: 32 | Loss: 0.446 | Acc: 86.820% (8682/10000)\n",
      "\n",
      "Epoch: 33\n",
      "Train Epoch: 33 | Loss: 0.260 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 33 | Loss: 0.196 | Acc: 93.945% (481/512)\n",
      "Train Epoch: 33 | Loss: 0.184 | Acc: 94.688% (606/640)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.490% (718/768)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.969% (833/896)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (952/1024)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 92.882% (1070/1152)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.125% (1192/1280)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.040% (1310/1408)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.359% (1434/1536)\n",
      "Train Epoch: 33 | Loss: 0.209 | Acc: 93.329% (1553/1664)\n",
      "Train Epoch: 33 | Loss: 0.208 | Acc: 93.136% (1669/1792)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.073% (1787/1920)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.115% (1907/2048)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.153% (2027/2176)\n",
      "Train Epoch: 33 | Loss: 0.211 | Acc: 92.969% (2142/2304)\n",
      "Train Epoch: 33 | Loss: 0.210 | Acc: 92.928% (2260/2432)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.125% (2384/2560)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.155% (2504/2688)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.324% (2628/2816)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.207% (2744/2944)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.197% (2863/3072)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.188% (2982/3200)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.119% (3099/3328)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.200% (3221/3456)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.304% (3344/3584)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.265% (3462/3712)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.385% (3586/3840)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.296% (3702/3968)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.262% (3820/4096)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.395% (3945/4224)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.290% (4060/4352)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.214% (4176/4480)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.207% (4295/4608)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.222% (4415/4736)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.318% (4539/4864)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.269% (4656/4992)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.223% (4773/5120)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.197% (4891/5248)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.080% (5004/5376)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.969% (5117/5504)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.933% (5234/5632)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.038% (5359/5760)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 93.020% (5477/5888)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.052% (5598/6016)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.099% (5720/6144)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.096% (5839/6272)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 93.125% (5960/6400)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.199% (6084/6528)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.179% (6202/6656)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.146% (6319/6784)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.099% (6435/6912)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.082% (6553/7040)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.164% (6678/7168)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.147% (6796/7296)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.103% (6912/7424)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.061% (7028/7552)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.034% (7145/7680)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.007% (7262/7808)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.906% (7373/7936)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 92.944% (7495/8064)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 92.981% (7617/8192)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.921% (7731/8320)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.992% (7856/8448)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.992% (7975/8576)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.946% (8090/8704)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 92.912% (8206/8832)\n",
      "Train Epoch: 33 | Loss: 0.209 | Acc: 92.846% (8319/8960)\n",
      "Train Epoch: 33 | Loss: 0.208 | Acc: 92.859% (8439/9088)\n",
      "Train Epoch: 33 | Loss: 0.208 | Acc: 92.828% (8555/9216)\n",
      "Train Epoch: 33 | Loss: 0.208 | Acc: 92.830% (8674/9344)\n",
      "Train Epoch: 33 | Loss: 0.207 | Acc: 92.842% (8794/9472)\n",
      "Train Epoch: 33 | Loss: 0.206 | Acc: 92.896% (8918/9600)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.938% (9041/9728)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.898% (9156/9856)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.939% (9279/9984)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.959% (9400/10112)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.949% (9518/10240)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.988% (9641/10368)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.007% (9762/10496)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.025% (9883/10624)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.015% (10001/10752)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.978% (10116/10880)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (10234/11008)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (10353/11136)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.951% (10470/11264)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (10591/11392)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.977% (10711/11520)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.020% (10835/11648)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.020% (10954/11776)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.053% (11077/11904)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.052% (11196/12032)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.067% (11317/12160)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.107% (11441/12288)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.162% (11567/12416)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.168% (11687/12544)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.158% (11805/12672)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.180% (11927/12800)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.185% (12047/12928)\n",
      "Train Epoch: 33 | Loss: 0.198 | Acc: 93.183% (12166/13056)\n",
      "Train Epoch: 33 | Loss: 0.198 | Acc: 93.189% (12286/13184)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.239% (12412/13312)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.237% (12531/13440)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.234% (12650/13568)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.239% (12770/13696)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.236% (12889/13824)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.220% (13006/13952)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.224% (13126/14080)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.208% (13243/14208)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.227% (13365/14336)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.245% (13487/14464)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.243% (13606/14592)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.247% (13726/14720)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.245% (13845/14848)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.236% (13963/14976)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.227% (14081/15104)\n",
      "Train Epoch: 33 | Loss: 0.197 | Acc: 93.225% (14200/15232)\n",
      "Train Epoch: 33 | Loss: 0.198 | Acc: 93.216% (14318/15360)\n",
      "Train Epoch: 33 | Loss: 0.198 | Acc: 93.188% (14433/15488)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.180% (14551/15616)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.153% (14666/15744)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.139% (14783/15872)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.156% (14905/16000)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.142% (15022/16128)\n",
      "Train Epoch: 33 | Loss: 0.200 | Acc: 93.129% (15139/16256)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.146% (15261/16384)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.144% (15380/16512)\n",
      "Train Epoch: 33 | Loss: 0.199 | Acc: 93.149% (15500/16640)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.100% (15611/16768)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.075% (15726/16896)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.092% (15848/17024)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.091% (15967/17152)\n",
      "Train Epoch: 33 | Loss: 0.201 | Acc: 93.079% (16084/17280)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.061% (16200/17408)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.054% (16318/17536)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.048% (16436/17664)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.019% (16550/17792)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.019% (16669/17920)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.013% (16787/18048)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.996% (16903/18176)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.991% (17021/18304)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.969% (17136/18432)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.969% (17255/18560)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.958% (17372/18688)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.953% (17490/18816)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.969% (17612/18944)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 92.969% (17731/19072)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.990% (17854/19200)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.020% (17979/19328)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.025% (18099/19456)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.066% (18226/19584)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.060% (18344/19712)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.065% (18464/19840)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.069% (18584/19968)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.083% (18706/20096)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.082% (18825/20224)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.077% (18943/20352)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.066% (19060/20480)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.051% (19176/20608)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.046% (19294/20736)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.060% (19416/20864)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.031% (19529/20992)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.030% (19648/21120)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.021% (19765/21248)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.025% (19885/21376)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.034% (20006/21504)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.033% (20125/21632)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.024% (20242/21760)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.033% (20363/21888)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.041% (20484/22016)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.046% (20604/22144)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.050% (20724/22272)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.054% (20844/22400)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.053% (20963/22528)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.048% (21081/22656)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.035% (21197/22784)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.052% (21320/22912)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.051% (21439/23040)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.055% (21559/23168)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.046% (21676/23296)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.037% (21793/23424)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.028% (21910/23552)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.041% (22032/23680)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.028% (22148/23808)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.036% (22269/23936)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.023% (22385/24064)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.039% (22508/24192)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.039% (22627/24320)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.014% (22740/24448)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.005% (22857/24576)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.017% (22979/24704)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.017% (23098/24832)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.013% (23216/24960)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.021% (23337/25088)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.020% (23456/25216)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.008% (23572/25344)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.016% (23693/25472)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.035% (23817/25600)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.054% (23941/25728)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.065% (24063/25856)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.065% (24182/25984)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.061% (24300/26112)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.064% (24420/26240)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.052% (24536/26368)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.048% (24654/26496)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.063% (24777/26624)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.047% (24892/26752)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.058% (25014/26880)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.061% (25134/27008)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.061% (25253/27136)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.046% (25368/27264)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.042% (25486/27392)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.041% (25605/27520)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.034% (25722/27648)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.026% (25839/27776)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.023% (25957/27904)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.033% (26079/28032)\n",
      "Train Epoch: 33 | Loss: 0.205 | Acc: 93.033% (26198/28160)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.039% (26319/28288)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.043% (26439/28416)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.042% (26558/28544)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.039% (26676/28672)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.028% (26792/28800)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.024% (26910/28928)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.031% (27031/29056)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.041% (27153/29184)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.037% (27271/29312)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.033% (27389/29440)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.026% (27506/29568)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.023% (27624/29696)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.032% (27746/29824)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.032% (27865/29952)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.022% (27981/30080)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.038% (28105/30208)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.038% (28224/30336)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.028% (28340/30464)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.031% (28460/30592)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.018% (28575/30720)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.027% (28697/30848)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 93.027% (28816/30976)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.039% (28939/31104)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.042% (29059/31232)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.048% (29180/31360)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.051% (29300/31488)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.045% (29417/31616)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.044% (29536/31744)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.057% (29659/31872)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.059% (29779/32000)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.047% (29894/32128)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.049% (30014/32256)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.049% (30133/32384)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.039% (30249/32512)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.048% (30371/32640)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.033% (30485/32768)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.045% (30608/32896)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.038% (30725/33024)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.035% (30843/33152)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.035% (30962/33280)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.032% (31080/33408)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.028% (31198/33536)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.013% (31312/33664)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.010% (31430/33792)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.019% (31552/33920)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.030% (31675/34048)\n",
      "Train Epoch: 33 | Loss: 0.202 | Acc: 93.039% (31797/34176)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.021% (31910/34304)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.001% (32022/34432)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.986% (32136/34560)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.983% (32254/34688)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.983% (32373/34816)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (32489/34944)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.972% (32607/35072)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.977% (32728/35200)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.991% (32852/35328)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.003% (32975/35456)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.000% (33093/35584)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.005% (33214/35712)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.991% (33328/35840)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.991% (33447/35968)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.980% (33562/36096)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.977% (33680/36224)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.955% (33791/36352)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (33917/36480)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (34035/36608)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.980% (34157/36736)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.961% (34269/36864)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (34391/36992)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.966% (34509/37120)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.961% (34626/37248)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.955% (34743/37376)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.958% (34863/37504)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.942% (34976/37632)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.932% (35091/37760)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.921% (35206/37888)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.911% (35321/38016)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.932% (35448/38144)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.937% (35569/38272)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.940% (35689/38400)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.940% (35808/38528)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.938% (35926/38656)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.940% (36046/38784)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.948% (36168/38912)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.953% (36289/39040)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.961% (36411/39168)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.961% (36530/39296)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (36654/39424)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (36773/39552)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.961% (36887/39680)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.966% (37008/39808)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.979% (37132/39936)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (37248/40064)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.966% (37365/40192)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (37487/40320)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.979% (37608/40448)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (37724/40576)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (37842/40704)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (37962/40832)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (38082/40960)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (38200/41088)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.974% (38320/41216)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (38437/41344)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.964% (38554/41472)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (38675/41600)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (38794/41728)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.971% (38914/41856)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.976% (39035/41984)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.973% (39153/42112)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (39270/42240)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.962% (39386/42368)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.955% (39502/42496)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.948% (39618/42624)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.964% (39744/42752)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.966% (39864/42880)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.976% (39987/43008)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.973% (40105/43136)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.980% (40227/43264)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.987% (40349/43392)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.966% (40459/43520)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.973% (40581/43648)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (40698/43776)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.962% (40814/43904)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.969% (40936/44032)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.973% (41057/44160)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.973% (41176/44288)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.980% (41298/44416)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.978% (41416/44544)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.980% (41536/44672)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.984% (41657/44800)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.995% (41781/44928)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.987% (41896/45056)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.995% (42019/45184)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.995% (42138/45312)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.986% (42253/45440)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.982% (42370/45568)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.988% (42492/45696)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.991% (42612/45824)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.986% (42729/45952)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.990% (42850/46080)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.993% (42970/46208)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.988% (43087/46336)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.982% (43203/46464)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.977% (43320/46592)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.979% (43440/46720)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.982% (43560/46848)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.982% (43679/46976)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.988% (43801/47104)\n",
      "Train Epoch: 33 | Loss: 0.204 | Acc: 92.984% (43918/47232)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.998% (44044/47360)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.996% (44162/47488)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.990% (44278/47616)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.994% (44399/47744)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.998% (44520/47872)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.004% (44642/48000)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 93.004% (44761/48128)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.987% (44872/48256)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.983% (44989/48384)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.985% (45109/48512)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.989% (45230/48640)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.991% (45350/48768)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.989% (45468/48896)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.989% (45587/49024)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.993% (45708/49152)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.985% (45823/49280)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.975% (45937/49408)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.975% (46056/49536)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.975% (46175/49664)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.981% (46297/49792)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.987% (46419/49920)\n",
      "Train Epoch: 33 | Loss: 0.203 | Acc: 92.992% (46496/50000)\n",
      "Test Epoch: 33 | Loss: 0.415 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 33 | Loss: 0.370 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 33 | Loss: 0.333 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 33 | Loss: 0.356 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 33 | Loss: 0.331 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 33 | Loss: 0.301 | Acc: 90.500% (543/600)\n",
      "Test Epoch: 33 | Loss: 0.306 | Acc: 90.429% (633/700)\n",
      "Test Epoch: 33 | Loss: 0.329 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 33 | Loss: 0.355 | Acc: 88.333% (795/900)\n",
      "Test Epoch: 33 | Loss: 0.360 | Acc: 88.100% (881/1000)\n",
      "Test Epoch: 33 | Loss: 0.372 | Acc: 87.727% (965/1100)\n",
      "Test Epoch: 33 | Loss: 0.380 | Acc: 87.667% (1052/1200)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.615% (1139/1300)\n",
      "Test Epoch: 33 | Loss: 0.377 | Acc: 87.929% (1231/1400)\n",
      "Test Epoch: 33 | Loss: 0.378 | Acc: 88.000% (1320/1500)\n",
      "Test Epoch: 33 | Loss: 0.377 | Acc: 88.000% (1408/1600)\n",
      "Test Epoch: 33 | Loss: 0.375 | Acc: 88.294% (1501/1700)\n",
      "Test Epoch: 33 | Loss: 0.383 | Acc: 88.056% (1585/1800)\n",
      "Test Epoch: 33 | Loss: 0.392 | Acc: 87.842% (1669/1900)\n",
      "Test Epoch: 33 | Loss: 0.398 | Acc: 87.850% (1757/2000)\n",
      "Test Epoch: 33 | Loss: 0.407 | Acc: 87.571% (1839/2100)\n",
      "Test Epoch: 33 | Loss: 0.412 | Acc: 87.318% (1921/2200)\n",
      "Test Epoch: 33 | Loss: 0.413 | Acc: 87.435% (2011/2300)\n",
      "Test Epoch: 33 | Loss: 0.416 | Acc: 87.333% (2096/2400)\n",
      "Test Epoch: 33 | Loss: 0.427 | Acc: 87.200% (2180/2500)\n",
      "Test Epoch: 33 | Loss: 0.439 | Acc: 87.000% (2262/2600)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.148% (2353/2700)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.214% (2442/2800)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.276% (2531/2900)\n",
      "Test Epoch: 33 | Loss: 0.429 | Acc: 87.300% (2619/3000)\n",
      "Test Epoch: 33 | Loss: 0.429 | Acc: 87.226% (2704/3100)\n",
      "Test Epoch: 33 | Loss: 0.427 | Acc: 87.219% (2791/3200)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.182% (2877/3300)\n",
      "Test Epoch: 33 | Loss: 0.428 | Acc: 87.206% (2965/3400)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.086% (3048/3500)\n",
      "Test Epoch: 33 | Loss: 0.438 | Acc: 87.111% (3136/3600)\n",
      "Test Epoch: 33 | Loss: 0.439 | Acc: 87.108% (3223/3700)\n",
      "Test Epoch: 33 | Loss: 0.436 | Acc: 87.053% (3308/3800)\n",
      "Test Epoch: 33 | Loss: 0.436 | Acc: 87.128% (3398/3900)\n",
      "Test Epoch: 33 | Loss: 0.438 | Acc: 87.150% (3486/4000)\n",
      "Test Epoch: 33 | Loss: 0.440 | Acc: 87.073% (3570/4100)\n",
      "Test Epoch: 33 | Loss: 0.442 | Acc: 86.905% (3650/4200)\n",
      "Test Epoch: 33 | Loss: 0.437 | Acc: 86.977% (3740/4300)\n",
      "Test Epoch: 33 | Loss: 0.439 | Acc: 87.068% (3831/4400)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.133% (3921/4500)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.152% (4009/4600)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.085% (4093/4700)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.062% (4179/4800)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.102% (4268/4900)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.080% (4354/5000)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.157% (4445/5100)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.135% (4531/5200)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.075% (4615/5300)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.148% (4706/5400)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.091% (4790/5500)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.089% (4877/5600)\n",
      "Test Epoch: 33 | Loss: 0.436 | Acc: 87.123% (4966/5700)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.103% (5052/5800)\n",
      "Test Epoch: 33 | Loss: 0.437 | Acc: 87.034% (5135/5900)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.100% (5226/6000)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.049% (5310/6100)\n",
      "Test Epoch: 33 | Loss: 0.437 | Acc: 87.000% (5394/6200)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.079% (5486/6300)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.109% (5575/6400)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.154% (5665/6500)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.212% (5756/6600)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.269% (5847/6700)\n",
      "Test Epoch: 33 | Loss: 0.429 | Acc: 87.235% (5932/6800)\n",
      "Test Epoch: 33 | Loss: 0.428 | Acc: 87.246% (6020/6900)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.214% (6105/7000)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.197% (6191/7100)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.222% (6280/7200)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.315% (6374/7300)\n",
      "Test Epoch: 33 | Loss: 0.431 | Acc: 87.324% (6462/7400)\n",
      "Test Epoch: 33 | Loss: 0.431 | Acc: 87.307% (6548/7500)\n",
      "Test Epoch: 33 | Loss: 0.431 | Acc: 87.316% (6636/7600)\n",
      "Test Epoch: 33 | Loss: 0.431 | Acc: 87.338% (6725/7700)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.359% (6814/7800)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.342% (6900/7900)\n",
      "Test Epoch: 33 | Loss: 0.431 | Acc: 87.375% (6990/8000)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.395% (7079/8100)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.402% (7167/8200)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.398% (7254/8300)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.393% (7341/8400)\n",
      "Test Epoch: 33 | Loss: 0.430 | Acc: 87.353% (7425/8500)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.302% (7508/8600)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.276% (7593/8700)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.261% (7679/8800)\n",
      "Test Epoch: 33 | Loss: 0.434 | Acc: 87.270% (7767/8900)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.278% (7855/9000)\n",
      "Test Epoch: 33 | Loss: 0.435 | Acc: 87.308% (7945/9100)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.359% (8037/9200)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.355% (8124/9300)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.362% (8212/9400)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.358% (8299/9500)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.385% (8389/9600)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.412% (8479/9700)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.388% (8564/9800)\n",
      "Test Epoch: 33 | Loss: 0.433 | Acc: 87.394% (8652/9900)\n",
      "Test Epoch: 33 | Loss: 0.432 | Acc: 87.380% (8738/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 34\n",
      "Train Epoch: 34 | Loss: 0.153 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 34 | Loss: 0.203 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 34 | Loss: 0.210 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 34 | Loss: 0.208 | Acc: 93.164% (477/512)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.438% (598/640)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.620% (719/768)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.192% (835/896)\n",
      "Train Epoch: 34 | Loss: 0.187 | Acc: 93.457% (957/1024)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.663% (1079/1152)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.828% (1201/1280)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.750% (1320/1408)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.815% (1441/1536)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.750% (1560/1664)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.973% (1684/1792)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.906% (1803/1920)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.701% (1919/2048)\n",
      "Train Epoch: 34 | Loss: 0.178 | Acc: 93.750% (2040/2176)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.750% (2160/2304)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.586% (2276/2432)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.633% (2397/2560)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.750% (2520/2688)\n",
      "Train Epoch: 34 | Loss: 0.174 | Acc: 93.821% (2642/2816)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.784% (2761/2944)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.815% (2882/3072)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.812% (3002/3200)\n",
      "Train Epoch: 34 | Loss: 0.178 | Acc: 93.750% (3120/3328)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.605% (3235/3456)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.638% (3356/3584)\n",
      "Train Epoch: 34 | Loss: 0.178 | Acc: 93.750% (3480/3712)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.802% (3602/3840)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.851% (3724/3968)\n",
      "Train Epoch: 34 | Loss: 0.174 | Acc: 93.921% (3847/4096)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.845% (3964/4224)\n",
      "Train Epoch: 34 | Loss: 0.178 | Acc: 93.727% (4079/4352)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.661% (4196/4480)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.663% (4316/4608)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.729% (4439/4736)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.750% (4560/4864)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.730% (4679/4992)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.750% (4800/5120)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.788% (4922/5248)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.787% (5042/5376)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.823% (5164/5504)\n",
      "Train Epoch: 34 | Loss: 0.174 | Acc: 93.857% (5286/5632)\n",
      "Train Epoch: 34 | Loss: 0.175 | Acc: 93.837% (5405/5760)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.767% (5521/5888)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.650% (5634/6016)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.750% (5760/6144)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.670% (5875/6272)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.766% (6001/6400)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.781% (6122/6528)\n",
      "Train Epoch: 34 | Loss: 0.177 | Acc: 93.735% (6239/6656)\n",
      "Train Epoch: 34 | Loss: 0.176 | Acc: 93.779% (6362/6784)\n",
      "Train Epoch: 34 | Loss: 0.178 | Acc: 93.721% (6478/6912)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.651% (6593/7040)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.694% (6716/7168)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.640% (6832/7296)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.710% (6957/7424)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.657% (7073/7552)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.620% (7190/7680)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.545% (7304/7808)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.523% (7422/7936)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.564% (7545/8064)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.604% (7668/8192)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.582% (7786/8320)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.584% (7906/8448)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.610% (8028/8576)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.612% (8148/8704)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.614% (8268/8832)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.638% (8390/8960)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.640% (8510/9088)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.685% (8634/9216)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.707% (8756/9344)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.708% (8876/9472)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.708% (8996/9600)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.688% (9114/9728)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.709% (9236/9856)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.730% (9358/9984)\n",
      "Train Epoch: 34 | Loss: 0.179 | Acc: 93.740% (9479/10112)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.730% (9598/10240)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.731% (9718/10368)\n",
      "Train Epoch: 34 | Loss: 0.180 | Acc: 93.740% (9839/10496)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.646% (9949/10624)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.610% (10065/10752)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.621% (10186/10880)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.650% (10309/11008)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.651% (10429/11136)\n",
      "Train Epoch: 34 | Loss: 0.181 | Acc: 93.626% (10546/11264)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.574% (10660/11392)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.533% (10775/11520)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.535% (10895/11648)\n",
      "Train Epoch: 34 | Loss: 0.182 | Acc: 93.555% (11017/11776)\n",
      "Train Epoch: 34 | Loss: 0.183 | Acc: 93.548% (11136/11904)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.492% (11249/12032)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.487% (11368/12160)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.498% (11489/12288)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.484% (11607/12416)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.471% (11725/12544)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.497% (11848/12672)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.477% (11965/12800)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.472% (12084/12928)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.520% (12210/13056)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.515% (12329/13184)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.517% (12449/13312)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.519% (12569/13440)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.514% (12688/13568)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.524% (12809/13696)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.547% (12932/13824)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.542% (13051/13952)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.537% (13170/14080)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.518% (13287/14208)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.520% (13407/14336)\n",
      "Train Epoch: 34 | Loss: 0.184 | Acc: 93.536% (13529/14464)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.510% (13645/14592)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.505% (13764/14720)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.534% (13888/14848)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.536% (14008/14976)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.532% (14127/15104)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.533% (14247/15232)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.542% (14368/15360)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.524% (14485/15488)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.532% (14606/15616)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.502% (14721/15744)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.529% (14845/15872)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.519% (14963/16000)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.527% (15084/16128)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.529% (15204/16256)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.524% (15323/16384)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.544% (15446/16512)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.504% (15559/16640)\n",
      "Train Epoch: 34 | Loss: 0.185 | Acc: 93.511% (15680/16768)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.501% (15798/16896)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.497% (15917/17024)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.523% (16041/17152)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.513% (16159/17280)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.497% (16276/17408)\n",
      "Train Epoch: 34 | Loss: 0.186 | Acc: 93.476% (16392/17536)\n",
      "Train Epoch: 34 | Loss: 0.187 | Acc: 93.456% (16508/17664)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.458% (16628/17792)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.443% (16745/17920)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.456% (16867/18048)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.431% (16982/18176)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.428% (17101/18304)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.446% (17224/18432)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.438% (17342/18560)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.445% (17463/18688)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.468% (17587/18816)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.433% (17700/18944)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.435% (17820/19072)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.448% (17942/19200)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.465% (18065/19328)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.416% (18175/19456)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.428% (18297/19584)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.435% (18418/19712)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.443% (18539/19840)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.470% (18664/19968)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.451% (18780/20096)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.468% (18903/20224)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.480% (19025/20352)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.486% (19146/20480)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.488% (19266/20608)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.499% (19388/20736)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.491% (19506/20864)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.474% (19622/20992)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.494% (19746/21120)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.496% (19866/21248)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.511% (19989/21376)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.513% (20109/21504)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.528% (20232/21632)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.543% (20355/21760)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.531% (20472/21888)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.546% (20595/22016)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.533% (20712/22144)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.512% (20827/22272)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.513% (20947/22400)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.515% (21067/22528)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.525% (21189/22656)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.531% (21310/22784)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.549% (21434/22912)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.555% (21555/23040)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.560% (21676/23168)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.544% (21792/23296)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.562% (21916/23424)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.555% (22034/23552)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.535% (22149/23680)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.544% (22271/23808)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.537% (22389/23936)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.542% (22510/24064)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.568% (22636/24192)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.557% (22753/24320)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.550% (22871/24448)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.522% (22984/24576)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.523% (23104/24704)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.524% (23224/24832)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.506% (23339/24960)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.519% (23462/25088)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.508% (23579/25216)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.505% (23698/25344)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.483% (23812/25472)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.488% (23933/25600)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.486% (24052/25728)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.479% (24170/25856)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.488% (24292/25984)\n",
      "Train Epoch: 34 | Loss: 0.188 | Acc: 93.490% (24412/26112)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.476% (24528/26240)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.469% (24646/26368)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.463% (24764/26496)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.446% (24879/26624)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.436% (24996/26752)\n",
      "Train Epoch: 34 | Loss: 0.189 | Acc: 93.445% (25118/26880)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.435% (25235/27008)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.418% (25350/27136)\n",
      "Train Epoch: 34 | Loss: 0.190 | Acc: 93.405% (25466/27264)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.385% (25580/27392)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.387% (25700/27520)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.377% (25817/27648)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.390% (25940/27776)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.388% (26059/27904)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.372% (26174/28032)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.374% (26294/28160)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.382% (26416/28288)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.366% (26531/28416)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.375% (26653/28544)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.373% (26772/28672)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.365% (26889/28800)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.384% (27014/28928)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.392% (27136/29056)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.373% (27250/29184)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.364% (27367/29312)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.359% (27485/29440)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.371% (27608/29568)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.373% (27728/29696)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.371% (27847/29824)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.369% (27966/29952)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.381% (28089/30080)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.379% (28208/30208)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.374% (28326/30336)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.376% (28446/30464)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.368% (28563/30592)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.379% (28686/30720)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.384% (28807/30848)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.388% (28928/30976)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.374% (29043/31104)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.379% (29164/31232)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.386% (29286/31360)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.391% (29407/31488)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.399% (29529/31616)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.397% (29648/31744)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.386% (29764/31872)\n",
      "Train Epoch: 34 | Loss: 0.191 | Acc: 93.388% (29884/32000)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.361% (29995/32128)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.344% (30109/32256)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.345% (30229/32384)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.341% (30347/32512)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.343% (30467/32640)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.350% (30589/32768)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.346% (30707/32896)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.350% (30828/33024)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.355% (30949/33152)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.356% (31069/33280)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.355% (31188/33408)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.359% (31309/33536)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.358% (31428/33664)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.353% (31546/33792)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.337% (31660/33920)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.330% (31777/34048)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.337% (31899/34176)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.330% (32016/34304)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.343% (32140/34432)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.336% (32257/34560)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.346% (32380/34688)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.336% (32496/34816)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.346% (32619/34944)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.362% (32744/35072)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.372% (32867/35200)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.365% (32984/35328)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.361% (33102/35456)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.362% (33222/35584)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.375% (33346/35712)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.373% (33465/35840)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.377% (33586/35968)\n",
      "Train Epoch: 34 | Loss: 0.192 | Acc: 93.368% (33702/36096)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.341% (33812/36224)\n",
      "Train Epoch: 34 | Loss: 0.193 | Acc: 93.346% (33933/36352)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.325% (34045/36480)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.327% (34165/36608)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.320% (34282/36736)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.313% (34399/36864)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.312% (34518/36992)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.305% (34635/37120)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.291% (34749/37248)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.287% (34867/37376)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.275% (34982/37504)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.266% (35098/37632)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.252% (35212/37760)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.259% (35334/37888)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.255% (35452/38016)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.249% (35569/38144)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.248% (35688/38272)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.253% (35809/38400)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.252% (35928/38528)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.246% (36045/38656)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.252% (36167/38784)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.254% (36287/38912)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.253% (36406/39040)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.244% (36522/39168)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.246% (36642/39296)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.253% (36764/39424)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.252% (36883/39552)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.251% (37002/39680)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.253% (37122/39808)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.242% (37237/39936)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.246% (37358/40064)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.232% (37472/40192)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.234% (37592/40320)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.236% (37712/40448)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.242% (37834/40576)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.244% (37954/40704)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.236% (38070/40832)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.240% (38191/40960)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.236% (38309/41088)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.238% (38429/41216)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.235% (38547/41344)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.236% (38667/41472)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.240% (38788/41600)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.235% (38905/41728)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.239% (39026/41856)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.238% (39145/41984)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.230% (39261/42112)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.239% (39384/42240)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.226% (39498/42368)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.223% (39616/42496)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.236% (39741/42624)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.249% (39866/42752)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.242% (39982/42880)\n",
      "Train Epoch: 34 | Loss: 0.194 | Acc: 93.236% (40099/43008)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.226% (40214/43136)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.228% (40334/43264)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.227% (40453/43392)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.222% (40570/43520)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.216% (40687/43648)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.213% (40805/43776)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.215% (40925/43904)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.216% (41045/44032)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.216% (41164/44160)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.222% (41286/44288)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.216% (41403/44416)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.213% (41521/44544)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.199% (41634/44672)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.208% (41757/44800)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.205% (41875/44928)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.191% (41988/45056)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.188% (42106/45184)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.187% (42225/45312)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.178% (42340/45440)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.171% (42456/45568)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.166% (42573/45696)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.163% (42691/45824)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.160% (42809/45952)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.155% (42926/46080)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.155% (43045/46208)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.159% (43166/46336)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.158% (43285/46464)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.147% (43399/46592)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.151% (43520/46720)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.159% (43643/46848)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.156% (43761/46976)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.162% (43883/47104)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.170% (44006/47232)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.159% (44120/47360)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.154% (44237/47488)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.154% (44356/47616)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.147% (44472/47744)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.148% (44592/47872)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.140% (44707/48000)\n",
      "Train Epoch: 34 | Loss: 0.195 | Acc: 93.139% (44826/48128)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.122% (44937/48256)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.120% (45055/48384)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.121% (45175/48512)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.111% (45289/48640)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.104% (45405/48768)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.104% (45524/48896)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.103% (45643/49024)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.099% (45760/49152)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.097% (45878/49280)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.092% (45995/49408)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.104% (46120/49536)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.100% (46237/49664)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.109% (46361/49792)\n",
      "Train Epoch: 34 | Loss: 0.196 | Acc: 93.115% (46483/49920)\n",
      "Train Epoch: 34 | Loss: 0.197 | Acc: 93.106% (46553/50000)\n",
      "Test Epoch: 34 | Loss: 0.631 | Acc: 81.000% (81/100)\n",
      "Test Epoch: 34 | Loss: 0.464 | Acc: 85.000% (170/200)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 34 | Loss: 0.476 | Acc: 85.750% (343/400)\n",
      "Test Epoch: 34 | Loss: 0.437 | Acc: 86.400% (432/500)\n",
      "Test Epoch: 34 | Loss: 0.393 | Acc: 87.667% (526/600)\n",
      "Test Epoch: 34 | Loss: 0.421 | Acc: 87.143% (610/700)\n",
      "Test Epoch: 34 | Loss: 0.441 | Acc: 86.625% (693/800)\n",
      "Test Epoch: 34 | Loss: 0.467 | Acc: 85.889% (773/900)\n",
      "Test Epoch: 34 | Loss: 0.474 | Acc: 86.100% (861/1000)\n",
      "Test Epoch: 34 | Loss: 0.485 | Acc: 86.000% (946/1100)\n",
      "Test Epoch: 34 | Loss: 0.499 | Acc: 85.750% (1029/1200)\n",
      "Test Epoch: 34 | Loss: 0.489 | Acc: 86.000% (1118/1300)\n",
      "Test Epoch: 34 | Loss: 0.483 | Acc: 85.857% (1202/1400)\n",
      "Test Epoch: 34 | Loss: 0.483 | Acc: 85.667% (1285/1500)\n",
      "Test Epoch: 34 | Loss: 0.484 | Acc: 85.438% (1367/1600)\n",
      "Test Epoch: 34 | Loss: 0.472 | Acc: 85.941% (1461/1700)\n",
      "Test Epoch: 34 | Loss: 0.473 | Acc: 86.000% (1548/1800)\n",
      "Test Epoch: 34 | Loss: 0.484 | Acc: 85.842% (1631/1900)\n",
      "Test Epoch: 34 | Loss: 0.497 | Acc: 85.650% (1713/2000)\n",
      "Test Epoch: 34 | Loss: 0.509 | Acc: 85.333% (1792/2100)\n",
      "Test Epoch: 34 | Loss: 0.514 | Acc: 85.091% (1872/2200)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.087% (1957/2300)\n",
      "Test Epoch: 34 | Loss: 0.515 | Acc: 85.125% (2043/2400)\n",
      "Test Epoch: 34 | Loss: 0.521 | Acc: 85.000% (2125/2500)\n",
      "Test Epoch: 34 | Loss: 0.532 | Acc: 84.962% (2209/2600)\n",
      "Test Epoch: 34 | Loss: 0.525 | Acc: 85.185% (2300/2700)\n",
      "Test Epoch: 34 | Loss: 0.524 | Acc: 85.214% (2386/2800)\n",
      "Test Epoch: 34 | Loss: 0.525 | Acc: 85.103% (2468/2900)\n",
      "Test Epoch: 34 | Loss: 0.524 | Acc: 85.133% (2554/3000)\n",
      "Test Epoch: 34 | Loss: 0.524 | Acc: 85.129% (2639/3100)\n",
      "Test Epoch: 34 | Loss: 0.520 | Acc: 85.188% (2726/3200)\n",
      "Test Epoch: 34 | Loss: 0.519 | Acc: 85.212% (2812/3300)\n",
      "Test Epoch: 34 | Loss: 0.519 | Acc: 85.147% (2895/3400)\n",
      "Test Epoch: 34 | Loss: 0.520 | Acc: 85.143% (2980/3500)\n",
      "Test Epoch: 34 | Loss: 0.523 | Acc: 85.194% (3067/3600)\n",
      "Test Epoch: 34 | Loss: 0.526 | Acc: 85.135% (3150/3700)\n",
      "Test Epoch: 34 | Loss: 0.525 | Acc: 85.184% (3237/3800)\n",
      "Test Epoch: 34 | Loss: 0.525 | Acc: 85.205% (3323/3900)\n",
      "Test Epoch: 34 | Loss: 0.522 | Acc: 85.300% (3412/4000)\n",
      "Test Epoch: 34 | Loss: 0.523 | Acc: 85.195% (3493/4100)\n",
      "Test Epoch: 34 | Loss: 0.521 | Acc: 85.190% (3578/4200)\n",
      "Test Epoch: 34 | Loss: 0.514 | Acc: 85.326% (3669/4300)\n",
      "Test Epoch: 34 | Loss: 0.517 | Acc: 85.386% (3757/4400)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.444% (3845/4500)\n",
      "Test Epoch: 34 | Loss: 0.514 | Acc: 85.370% (3927/4600)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.340% (4011/4700)\n",
      "Test Epoch: 34 | Loss: 0.514 | Acc: 85.312% (4095/4800)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.367% (4183/4900)\n",
      "Test Epoch: 34 | Loss: 0.516 | Acc: 85.340% (4267/5000)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.392% (4355/5100)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.365% (4439/5200)\n",
      "Test Epoch: 34 | Loss: 0.516 | Acc: 85.321% (4522/5300)\n",
      "Test Epoch: 34 | Loss: 0.514 | Acc: 85.389% (4611/5400)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.382% (4696/5500)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.429% (4784/5600)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.351% (4865/5700)\n",
      "Test Epoch: 34 | Loss: 0.509 | Acc: 85.431% (4955/5800)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.475% (5043/5900)\n",
      "Test Epoch: 34 | Loss: 0.506 | Acc: 85.550% (5133/6000)\n",
      "Test Epoch: 34 | Loss: 0.506 | Acc: 85.541% (5218/6100)\n",
      "Test Epoch: 34 | Loss: 0.507 | Acc: 85.613% (5308/6200)\n",
      "Test Epoch: 34 | Loss: 0.504 | Acc: 85.683% (5398/6300)\n",
      "Test Epoch: 34 | Loss: 0.501 | Acc: 85.766% (5489/6400)\n",
      "Test Epoch: 34 | Loss: 0.501 | Acc: 85.738% (5573/6500)\n",
      "Test Epoch: 34 | Loss: 0.500 | Acc: 85.758% (5660/6600)\n",
      "Test Epoch: 34 | Loss: 0.500 | Acc: 85.746% (5745/6700)\n",
      "Test Epoch: 34 | Loss: 0.500 | Acc: 85.706% (5828/6800)\n",
      "Test Epoch: 34 | Loss: 0.500 | Acc: 85.710% (5914/6900)\n",
      "Test Epoch: 34 | Loss: 0.502 | Acc: 85.657% (5996/7000)\n",
      "Test Epoch: 34 | Loss: 0.504 | Acc: 85.634% (6080/7100)\n",
      "Test Epoch: 34 | Loss: 0.507 | Acc: 85.597% (6163/7200)\n",
      "Test Epoch: 34 | Loss: 0.507 | Acc: 85.603% (6249/7300)\n",
      "Test Epoch: 34 | Loss: 0.506 | Acc: 85.635% (6337/7400)\n",
      "Test Epoch: 34 | Loss: 0.506 | Acc: 85.587% (6419/7500)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.553% (6502/7600)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.506% (6584/7700)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.564% (6674/7800)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.544% (6758/7900)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.513% (6841/8000)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.556% (6930/8100)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.512% (7012/8200)\n",
      "Test Epoch: 34 | Loss: 0.507 | Acc: 85.554% (7101/8300)\n",
      "Test Epoch: 34 | Loss: 0.507 | Acc: 85.548% (7186/8400)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.518% (7269/8500)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.477% (7351/8600)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.506% (7439/8700)\n",
      "Test Epoch: 34 | Loss: 0.512 | Acc: 85.511% (7525/8800)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.517% (7611/8900)\n",
      "Test Epoch: 34 | Loss: 0.513 | Acc: 85.511% (7696/9000)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.560% (7786/9100)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.533% (7869/9200)\n",
      "Test Epoch: 34 | Loss: 0.512 | Acc: 85.527% (7954/9300)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.532% (8040/9400)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.516% (8124/9500)\n",
      "Test Epoch: 34 | Loss: 0.511 | Acc: 85.531% (8211/9600)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.567% (8300/9700)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.612% (8390/9800)\n",
      "Test Epoch: 34 | Loss: 0.510 | Acc: 85.606% (8475/9900)\n",
      "Test Epoch: 34 | Loss: 0.508 | Acc: 85.630% (8563/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 35 | Loss: 0.160 | Acc: 94.531% (242/256)\n",
      "Train Epoch: 35 | Loss: 0.168 | Acc: 93.750% (360/384)\n",
      "Train Epoch: 35 | Loss: 0.162 | Acc: 94.531% (484/512)\n",
      "Train Epoch: 35 | Loss: 0.174 | Acc: 94.062% (602/640)\n",
      "Train Epoch: 35 | Loss: 0.177 | Acc: 93.750% (720/768)\n",
      "Train Epoch: 35 | Loss: 0.176 | Acc: 93.973% (842/896)\n",
      "Train Epoch: 35 | Loss: 0.172 | Acc: 93.848% (961/1024)\n",
      "Train Epoch: 35 | Loss: 0.165 | Acc: 94.097% (1084/1152)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.750% (1200/1280)\n",
      "Train Epoch: 35 | Loss: 0.176 | Acc: 93.963% (1323/1408)\n",
      "Train Epoch: 35 | Loss: 0.175 | Acc: 94.076% (1445/1536)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.750% (1560/1664)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.527% (1676/1792)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.438% (1794/1920)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.506% (1915/2048)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.658% (2038/2176)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.620% (2157/2304)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.586% (2276/2432)\n",
      "Train Epoch: 35 | Loss: 0.189 | Acc: 93.359% (2390/2560)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.490% (2513/2688)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.537% (2634/2816)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.682% (2758/2944)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.717% (2879/3072)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.594% (2995/3200)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.600% (3115/3328)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.519% (3232/3456)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.610% (3355/3584)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.642% (3476/3712)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.620% (3595/3840)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.624% (3715/3968)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.555% (3832/4096)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.513% (3950/4224)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.497% (4069/4352)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.393% (4184/4480)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.446% (4306/4608)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.370% (4422/4736)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.359% (4541/4864)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.309% (4658/4992)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.418% (4783/5120)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.388% (4901/5248)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.415% (5022/5376)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.405% (5141/5504)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.413% (5261/5632)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.403% (5380/5760)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.376% (5498/5888)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.368% (5617/6016)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.294% (5732/6144)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.208% (5846/6272)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.266% (5969/6400)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.275% (6089/6528)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.344% (6213/6656)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.396% (6336/6784)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.388% (6455/6912)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.324% (6570/7040)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.359% (6692/7168)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.380% (6813/7296)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.413% (6935/7424)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.459% (7058/7552)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.464% (7178/7680)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.468% (7298/7808)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.460% (7417/7936)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.452% (7536/8064)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.445% (7655/8192)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.425% (7773/8320)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.466% (7896/8448)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.447% (8014/8576)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.440% (8133/8704)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.456% (8254/8832)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.527% (8380/8960)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.552% (8502/9088)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.555% (8622/9216)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.568% (8743/9344)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.549% (8861/9472)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.583% (8984/9600)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.565% (9102/9728)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.567% (9222/9856)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.610% (9346/9984)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.661% (9471/10112)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.682% (9593/10240)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.682% (9713/10368)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.712% (9836/10496)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.694% (9954/10624)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.666% (10071/10752)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.676% (10192/10880)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.714% (10316/11008)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.759% (10441/11136)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.750% (10560/11264)\n",
      "Train Epoch: 35 | Loss: 0.177 | Acc: 93.776% (10683/11392)\n",
      "Train Epoch: 35 | Loss: 0.177 | Acc: 93.811% (10807/11520)\n",
      "Train Epoch: 35 | Loss: 0.177 | Acc: 93.810% (10927/11648)\n",
      "Train Epoch: 35 | Loss: 0.176 | Acc: 93.826% (11049/11776)\n",
      "Train Epoch: 35 | Loss: 0.177 | Acc: 93.792% (11165/11904)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.767% (11282/12032)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.808% (11407/12160)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.799% (11526/12288)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.774% (11643/12416)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.766% (11762/12544)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.774% (11883/12672)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.766% (12002/12800)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.742% (12119/12928)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.727% (12237/13056)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.689% (12352/13184)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.697% (12473/13312)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.676% (12590/13440)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.662% (12708/13568)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.670% (12829/13696)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.714% (12955/13824)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.685% (13071/13952)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.714% (13195/14080)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.708% (13314/14208)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.701% (13433/14336)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.695% (13552/14464)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.688% (13671/14592)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.655% (13786/14720)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.676% (13909/14848)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.690% (14031/14976)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.710% (14154/15104)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.724% (14276/15232)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.757% (14401/15360)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.750% (14520/15488)\n",
      "Train Epoch: 35 | Loss: 0.178 | Acc: 93.782% (14645/15616)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.763% (14762/15744)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.731% (14877/15872)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.737% (14998/16000)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.713% (15114/16128)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.744% (15239/16256)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.738% (15358/16384)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.714% (15474/16512)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.720% (15595/16640)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.714% (15714/16768)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.703% (15832/16896)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.738% (15958/17024)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.744% (16079/17152)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.756% (16201/17280)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.761% (16322/17408)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.756% (16441/17536)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.756% (16561/17664)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.756% (16681/17792)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.756% (16801/17920)\n",
      "Train Epoch: 35 | Loss: 0.179 | Acc: 93.772% (16924/18048)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.739% (17038/18176)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.750% (17160/18304)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.761% (17282/18432)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.761% (17402/18560)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.739% (17518/18688)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.729% (17636/18816)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.729% (17756/18944)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.740% (17878/19072)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.729% (17996/19200)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.719% (18114/19328)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.709% (18232/19456)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.704% (18351/19584)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.704% (18471/19712)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.710% (18592/19840)\n",
      "Train Epoch: 35 | Loss: 0.180 | Acc: 93.720% (18714/19968)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.685% (18827/20096)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.656% (18941/20224)\n",
      "Train Epoch: 35 | Loss: 0.181 | Acc: 93.642% (19058/20352)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.623% (19174/20480)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.619% (19293/20608)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.620% (19413/20736)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.616% (19532/20864)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.617% (19652/20992)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.627% (19774/21120)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.637% (19896/21248)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.647% (20018/21376)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.652% (20139/21504)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.653% (20259/21632)\n",
      "Train Epoch: 35 | Loss: 0.182 | Acc: 93.640% (20376/21760)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.604% (20488/21888)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.591% (20605/22016)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.601% (20727/22144)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.593% (20845/22272)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.585% (20963/22400)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.604% (21087/22528)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.613% (21209/22656)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.601% (21326/22784)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.593% (21444/22912)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.563% (21557/23040)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.569% (21678/23168)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.570% (21798/23296)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.566% (21917/23424)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.563% (22036/23552)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.539% (22150/23680)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.536% (22269/23808)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.554% (22393/23936)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.575% (22518/24064)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.581% (22639/24192)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.561% (22754/24320)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.566% (22875/24448)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.559% (22993/24576)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.572% (23116/24704)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.561% (23233/24832)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.562% (23353/24960)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.575% (23476/25088)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.572% (23595/25216)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.584% (23718/25344)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.558% (23831/25472)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.574% (23955/25600)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.591% (24079/25728)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.572% (24194/25856)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.565% (24312/25984)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.570% (24433/26112)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.567% (24552/26240)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.583% (24676/26368)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.580% (24795/26496)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.585% (24916/26624)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.597% (25039/26752)\n",
      "Train Epoch: 35 | Loss: 0.183 | Acc: 93.594% (25158/26880)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.572% (25272/27008)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.573% (25392/27136)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.581% (25514/27264)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.564% (25629/27392)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.561% (25748/27520)\n",
      "Train Epoch: 35 | Loss: 0.184 | Acc: 93.562% (25868/27648)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.548% (25984/27776)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.546% (26103/27904)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.529% (26218/28032)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.523% (26336/28160)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.513% (26453/28288)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.514% (26573/28416)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.522% (26695/28544)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.509% (26811/28672)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.507% (26930/28800)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.473% (27040/28928)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.478% (27161/29056)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.472% (27279/29184)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.463% (27396/29312)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.468% (27517/29440)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.463% (27635/29568)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.467% (27756/29696)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.482% (27880/29824)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.483% (28000/29952)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.487% (28121/30080)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.488% (28241/30208)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.490% (28361/30336)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.494% (28482/30464)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.492% (28601/30592)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.483% (28718/30720)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.494% (28841/30848)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.485% (28958/30976)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.477% (29075/31104)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.468% (29192/31232)\n",
      "Train Epoch: 35 | Loss: 0.185 | Acc: 93.479% (29315/31360)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.464% (29430/31488)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.468% (29551/31616)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.454% (29666/31744)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.439% (29781/31872)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.422% (29895/32000)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.423% (30015/32128)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.415% (30132/32256)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.429% (30256/32384)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.436% (30378/32512)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.425% (30494/32640)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.430% (30615/32768)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.428% (30734/32896)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.423% (30852/33024)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.418% (30970/33152)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.419% (31090/33280)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.415% (31208/33408)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.407% (31325/33536)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.402% (31443/33664)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.404% (31563/33792)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.411% (31685/33920)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.421% (31808/34048)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.419% (31927/34176)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.412% (32044/34304)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.422% (32167/34432)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.411% (32283/34560)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.418% (32405/34688)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.414% (32523/34816)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.409% (32641/34944)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.388% (32753/35072)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.395% (32875/35200)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.385% (32991/35328)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.403% (33117/35456)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.413% (33240/35584)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.425% (33364/35712)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.418% (33481/35840)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.419% (33601/35968)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.409% (33717/36096)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.413% (33838/36224)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.417% (33959/36352)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.410% (34076/36480)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.414% (34197/36608)\n",
      "Train Epoch: 35 | Loss: 0.186 | Acc: 93.412% (34316/36736)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.403% (34432/36864)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.399% (34550/36992)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.386% (34665/37120)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.382% (34783/37248)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.381% (34902/37376)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.369% (35017/37504)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.367% (35136/37632)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.371% (35257/37760)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.359% (35372/37888)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.355% (35490/38016)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.359% (35611/38144)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.361% (35731/38272)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.359% (35850/38400)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.366% (35972/38528)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.365% (36091/38656)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.376% (36215/38784)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.388% (36339/38912)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.381% (36456/39040)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.382% (36576/39168)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.386% (36697/39296)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.387% (36817/39424)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.394% (36939/39552)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.402% (37062/39680)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.411% (37185/39808)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.417% (37307/39936)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.423% (37429/40064)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.419% (37547/40192)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.418% (37666/40320)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.424% (37788/40448)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.427% (37909/40576)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.431% (38030/40704)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.417% (38144/40832)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.406% (38259/40960)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.414% (38382/41088)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.425% (38506/41216)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.423% (38625/41344)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.412% (38740/41472)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.413% (38860/41600)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.419% (38982/41728)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.420% (39102/41856)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.421% (39222/41984)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.415% (39339/42112)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.416% (39459/42240)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.410% (39576/42368)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.413% (39697/42496)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.407% (39814/42624)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.413% (39936/42752)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.417% (40057/42880)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.424% (40180/43008)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.437% (40305/43136)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.433% (40423/43264)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.439% (40545/43392)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.433% (40662/43520)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.443% (40786/43648)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.439% (40904/43776)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.445% (41026/43904)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.439% (41143/44032)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.440% (41263/44160)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.434% (41380/44288)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.419% (41493/44416)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.407% (41607/44544)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.403% (41725/44672)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.406% (41846/44800)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.403% (41964/44928)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.390% (42078/45056)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.400% (42202/45184)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.397% (42320/45312)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.398% (42440/45440)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.403% (42562/45568)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.411% (42685/45696)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.410% (42804/45824)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.411% (42924/45952)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.405% (43041/46080)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.415% (43165/46208)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.409% (43282/46336)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.406% (43400/46464)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.400% (43517/46592)\n",
      "Train Epoch: 35 | Loss: 0.187 | Acc: 93.393% (43633/46720)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.383% (43748/46848)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.380% (43866/46976)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.381% (43986/47104)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.379% (44105/47232)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.376% (44223/47360)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.373% (44341/47488)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.368% (44458/47616)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.354% (44571/47744)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.357% (44692/47872)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.354% (44810/48000)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.351% (44928/48128)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.350% (45047/48256)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.349% (45166/48384)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.358% (45290/48512)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.363% (45412/48640)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.369% (45534/48768)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.374% (45656/48896)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.364% (45771/49024)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.361% (45889/49152)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.358% (46007/49280)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.359% (46127/49408)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.360% (46247/49536)\n",
      "Train Epoch: 35 | Loss: 0.188 | Acc: 93.363% (46368/49664)\n",
      "Train Epoch: 35 | Loss: 0.189 | Acc: 93.350% (46481/49792)\n",
      "Train Epoch: 35 | Loss: 0.189 | Acc: 93.353% (46602/49920)\n",
      "Train Epoch: 35 | Loss: 0.189 | Acc: 93.358% (46679/50000)\n",
      "Test Epoch: 35 | Loss: 0.390 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 35 | Loss: 0.466 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 35 | Loss: 0.372 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 35 | Loss: 0.394 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 35 | Loss: 0.420 | Acc: 87.400% (437/500)\n",
      "Test Epoch: 35 | Loss: 0.396 | Acc: 87.833% (527/600)\n",
      "Test Epoch: 35 | Loss: 0.413 | Acc: 87.714% (614/700)\n",
      "Test Epoch: 35 | Loss: 0.464 | Acc: 86.750% (694/800)\n",
      "Test Epoch: 35 | Loss: 0.456 | Acc: 87.111% (784/900)\n",
      "Test Epoch: 35 | Loss: 0.460 | Acc: 87.000% (870/1000)\n",
      "Test Epoch: 35 | Loss: 0.460 | Acc: 86.909% (956/1100)\n",
      "Test Epoch: 35 | Loss: 0.457 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 35 | Loss: 0.462 | Acc: 87.000% (1131/1300)\n",
      "Test Epoch: 35 | Loss: 0.454 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 35 | Loss: 0.452 | Acc: 87.067% (1306/1500)\n",
      "Test Epoch: 35 | Loss: 0.454 | Acc: 87.125% (1394/1600)\n",
      "Test Epoch: 35 | Loss: 0.465 | Acc: 87.059% (1480/1700)\n",
      "Test Epoch: 35 | Loss: 0.465 | Acc: 87.056% (1567/1800)\n",
      "Test Epoch: 35 | Loss: 0.462 | Acc: 87.263% (1658/1900)\n",
      "Test Epoch: 35 | Loss: 0.479 | Acc: 86.850% (1737/2000)\n",
      "Test Epoch: 35 | Loss: 0.485 | Acc: 86.619% (1819/2100)\n",
      "Test Epoch: 35 | Loss: 0.482 | Acc: 86.682% (1907/2200)\n",
      "Test Epoch: 35 | Loss: 0.483 | Acc: 86.565% (1991/2300)\n",
      "Test Epoch: 35 | Loss: 0.483 | Acc: 86.625% (2079/2400)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.560% (2164/2500)\n",
      "Test Epoch: 35 | Loss: 0.501 | Acc: 86.538% (2250/2600)\n",
      "Test Epoch: 35 | Loss: 0.501 | Acc: 86.556% (2337/2700)\n",
      "Test Epoch: 35 | Loss: 0.497 | Acc: 86.571% (2424/2800)\n",
      "Test Epoch: 35 | Loss: 0.501 | Acc: 86.517% (2509/2900)\n",
      "Test Epoch: 35 | Loss: 0.504 | Acc: 86.433% (2593/3000)\n",
      "Test Epoch: 35 | Loss: 0.508 | Acc: 86.258% (2674/3100)\n",
      "Test Epoch: 35 | Loss: 0.505 | Acc: 86.281% (2761/3200)\n",
      "Test Epoch: 35 | Loss: 0.503 | Acc: 86.152% (2843/3300)\n",
      "Test Epoch: 35 | Loss: 0.506 | Acc: 86.029% (2925/3400)\n",
      "Test Epoch: 35 | Loss: 0.508 | Acc: 86.029% (3011/3500)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 86.000% (3096/3600)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 86.027% (3183/3700)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 85.974% (3267/3800)\n",
      "Test Epoch: 35 | Loss: 0.513 | Acc: 85.974% (3353/3900)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 86.050% (3442/4000)\n",
      "Test Epoch: 35 | Loss: 0.517 | Acc: 85.927% (3523/4100)\n",
      "Test Epoch: 35 | Loss: 0.522 | Acc: 85.833% (3605/4200)\n",
      "Test Epoch: 35 | Loss: 0.518 | Acc: 85.930% (3695/4300)\n",
      "Test Epoch: 35 | Loss: 0.517 | Acc: 86.068% (3787/4400)\n",
      "Test Epoch: 35 | Loss: 0.515 | Acc: 86.133% (3876/4500)\n",
      "Test Epoch: 35 | Loss: 0.514 | Acc: 86.196% (3965/4600)\n",
      "Test Epoch: 35 | Loss: 0.514 | Acc: 86.149% (4049/4700)\n",
      "Test Epoch: 35 | Loss: 0.514 | Acc: 86.062% (4131/4800)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 86.041% (4216/4900)\n",
      "Test Epoch: 35 | Loss: 0.512 | Acc: 86.020% (4301/5000)\n",
      "Test Epoch: 35 | Loss: 0.506 | Acc: 86.176% (4395/5100)\n",
      "Test Epoch: 35 | Loss: 0.508 | Acc: 86.096% (4477/5200)\n",
      "Test Epoch: 35 | Loss: 0.507 | Acc: 86.094% (4563/5300)\n",
      "Test Epoch: 35 | Loss: 0.503 | Acc: 86.204% (4655/5400)\n",
      "Test Epoch: 35 | Loss: 0.504 | Acc: 86.164% (4739/5500)\n",
      "Test Epoch: 35 | Loss: 0.505 | Acc: 86.196% (4827/5600)\n",
      "Test Epoch: 35 | Loss: 0.503 | Acc: 86.228% (4915/5700)\n",
      "Test Epoch: 35 | Loss: 0.500 | Acc: 86.241% (5002/5800)\n",
      "Test Epoch: 35 | Loss: 0.500 | Acc: 86.254% (5089/5900)\n",
      "Test Epoch: 35 | Loss: 0.499 | Acc: 86.200% (5172/6000)\n",
      "Test Epoch: 35 | Loss: 0.498 | Acc: 86.148% (5255/6100)\n",
      "Test Epoch: 35 | Loss: 0.497 | Acc: 86.065% (5336/6200)\n",
      "Test Epoch: 35 | Loss: 0.495 | Acc: 86.111% (5425/6300)\n",
      "Test Epoch: 35 | Loss: 0.491 | Acc: 86.156% (5514/6400)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.154% (5600/6500)\n",
      "Test Epoch: 35 | Loss: 0.491 | Acc: 86.152% (5686/6600)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.164% (5773/6700)\n",
      "Test Epoch: 35 | Loss: 0.491 | Acc: 86.088% (5854/6800)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.072% (5939/6900)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.029% (6022/7000)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.070% (6111/7100)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.111% (6200/7200)\n",
      "Test Epoch: 35 | Loss: 0.488 | Acc: 86.110% (6286/7300)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.149% (6375/7400)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.133% (6460/7500)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.105% (6544/7600)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.091% (6629/7700)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.064% (6713/7800)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.089% (6801/7900)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.100% (6888/8000)\n",
      "Test Epoch: 35 | Loss: 0.488 | Acc: 86.173% (6980/8100)\n",
      "Test Epoch: 35 | Loss: 0.488 | Acc: 86.183% (7067/8200)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.181% (7153/8300)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.131% (7235/8400)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.094% (7318/8500)\n",
      "Test Epoch: 35 | Loss: 0.492 | Acc: 86.047% (7400/8600)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.057% (7487/8700)\n",
      "Test Epoch: 35 | Loss: 0.492 | Acc: 86.034% (7571/8800)\n",
      "Test Epoch: 35 | Loss: 0.491 | Acc: 86.034% (7657/8900)\n",
      "Test Epoch: 35 | Loss: 0.490 | Acc: 86.056% (7745/9000)\n",
      "Test Epoch: 35 | Loss: 0.491 | Acc: 86.077% (7833/9100)\n",
      "Test Epoch: 35 | Loss: 0.488 | Acc: 86.141% (7925/9200)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.140% (8011/9300)\n",
      "Test Epoch: 35 | Loss: 0.488 | Acc: 86.128% (8096/9400)\n",
      "Test Epoch: 35 | Loss: 0.489 | Acc: 86.126% (8182/9500)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.198% (8275/9600)\n",
      "Test Epoch: 35 | Loss: 0.485 | Acc: 86.247% (8366/9700)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.153% (8443/9800)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.152% (8529/9900)\n",
      "Test Epoch: 35 | Loss: 0.487 | Acc: 86.150% (8615/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Train Epoch: 36 | Loss: 0.243 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 36 | Loss: 0.212 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 36 | Loss: 0.195 | Acc: 94.271% (362/384)\n",
      "Train Epoch: 36 | Loss: 0.209 | Acc: 93.750% (480/512)\n",
      "Train Epoch: 36 | Loss: 0.206 | Acc: 93.906% (601/640)\n",
      "Train Epoch: 36 | Loss: 0.203 | Acc: 93.750% (720/768)\n",
      "Train Epoch: 36 | Loss: 0.197 | Acc: 93.862% (841/896)\n",
      "Train Epoch: 36 | Loss: 0.189 | Acc: 94.141% (964/1024)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 94.531% (1089/1152)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 94.375% (1208/1280)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 94.105% (1325/1408)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 94.010% (1444/1536)\n",
      "Train Epoch: 36 | Loss: 0.173 | Acc: 93.990% (1564/1664)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.806% (1681/1792)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.698% (1799/1920)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.750% (1920/2048)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.750% (2040/2176)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.663% (2158/2304)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 93.873% (2283/2432)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 93.906% (2404/2560)\n",
      "Train Epoch: 36 | Loss: 0.162 | Acc: 94.048% (2528/2688)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.034% (2648/2816)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 93.988% (2767/2944)\n",
      "Train Epoch: 36 | Loss: 0.163 | Acc: 94.141% (2892/3072)\n",
      "Train Epoch: 36 | Loss: 0.163 | Acc: 94.156% (3013/3200)\n",
      "Train Epoch: 36 | Loss: 0.161 | Acc: 94.291% (3138/3328)\n",
      "Train Epoch: 36 | Loss: 0.162 | Acc: 94.271% (3258/3456)\n",
      "Train Epoch: 36 | Loss: 0.161 | Acc: 94.308% (3380/3584)\n",
      "Train Epoch: 36 | Loss: 0.161 | Acc: 94.343% (3502/3712)\n",
      "Train Epoch: 36 | Loss: 0.160 | Acc: 94.401% (3625/3840)\n",
      "Train Epoch: 36 | Loss: 0.160 | Acc: 94.430% (3747/3968)\n",
      "Train Epoch: 36 | Loss: 0.159 | Acc: 94.409% (3867/4096)\n",
      "Train Epoch: 36 | Loss: 0.162 | Acc: 94.247% (3981/4224)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.095% (4095/4352)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.129% (4217/4480)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.097% (4336/4608)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 93.982% (4451/4736)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 93.997% (4572/4864)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.071% (4696/4992)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.082% (4817/5120)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.036% (4935/5248)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.010% (5054/5376)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.004% (5174/5504)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 93.999% (5294/5632)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.028% (5416/5760)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.039% (5537/5888)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.049% (5658/6016)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.043% (5778/6144)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.005% (5896/6272)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.016% (6017/6400)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.102% (6143/6528)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.141% (6266/6656)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.133% (6386/6784)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.083% (6503/6912)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.119% (6626/7040)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.113% (6746/7168)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.120% (6867/7296)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.060% (6983/7424)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.041% (7102/7552)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.076% (7225/7680)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.070% (7345/7808)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.103% (7468/7936)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.110% (7589/8064)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.165% (7714/8192)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.171% (7835/8320)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.223% (7960/8448)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.205% (8079/8576)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.187% (8198/8704)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.090% (8310/8832)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.062% (8428/8960)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.047% (8547/9088)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.978% (8661/9216)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.911% (8775/9344)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.887% (8893/9472)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.885% (9013/9600)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.925% (9137/9728)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.963% (9261/9856)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.960% (9381/9984)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.968% (9502/10112)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 93.975% (9623/10240)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 93.991% (9745/10368)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 94.007% (9867/10496)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.032% (9990/10624)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.038% (10111/10752)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.053% (10233/10880)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.077% (10356/11008)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.100% (10479/11136)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.105% (10600/11264)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.127% (10723/11392)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.158% (10847/11520)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.145% (10966/11648)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.132% (11085/11776)\n",
      "Train Epoch: 36 | Loss: 0.164 | Acc: 94.136% (11206/11904)\n",
      "Train Epoch: 36 | Loss: 0.165 | Acc: 94.099% (11322/12032)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.054% (11437/12160)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.059% (11558/12288)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.048% (11677/12416)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.061% (11799/12544)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.066% (11920/12672)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.062% (12040/12800)\n",
      "Train Epoch: 36 | Loss: 0.166 | Acc: 94.044% (12158/12928)\n",
      "Train Epoch: 36 | Loss: 0.167 | Acc: 94.018% (12275/13056)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 93.993% (12392/13184)\n",
      "Train Epoch: 36 | Loss: 0.168 | Acc: 93.953% (12507/13312)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.936% (12625/13440)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.949% (12747/13568)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.933% (12865/13696)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.931% (12985/13824)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.936% (13106/13952)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.928% (13225/14080)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.940% (13347/14208)\n",
      "Train Epoch: 36 | Loss: 0.169 | Acc: 93.903% (13462/14336)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.874% (13578/14464)\n",
      "Train Epoch: 36 | Loss: 0.170 | Acc: 93.860% (13696/14592)\n",
      "Train Epoch: 36 | Loss: 0.171 | Acc: 93.832% (13812/14720)\n",
      "Train Epoch: 36 | Loss: 0.172 | Acc: 93.824% (13931/14848)\n",
      "Train Epoch: 36 | Loss: 0.172 | Acc: 93.797% (14047/14976)\n",
      "Train Epoch: 36 | Loss: 0.173 | Acc: 93.770% (14163/15104)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.743% (14279/15232)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.737% (14398/15360)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.744% (14519/15488)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.769% (14643/15616)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.775% (14764/15744)\n",
      "Train Epoch: 36 | Loss: 0.173 | Acc: 93.788% (14886/15872)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.781% (15005/16000)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.769% (15123/16128)\n",
      "Train Epoch: 36 | Loss: 0.174 | Acc: 93.762% (15242/16256)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.744% (15359/16384)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.744% (15479/16512)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.762% (15602/16640)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.756% (15721/16768)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.750% (15840/16896)\n",
      "Train Epoch: 36 | Loss: 0.175 | Acc: 93.738% (15958/17024)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.721% (16075/17152)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.704% (16192/17280)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.687% (16309/17408)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.699% (16431/17536)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.693% (16550/17664)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.694% (16670/17792)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.694% (16790/17920)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.700% (16911/18048)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.706% (17032/18176)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.674% (17146/18304)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.663% (17264/18432)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.675% (17386/18560)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.648% (17501/18688)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.649% (17621/18816)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.671% (17745/18944)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.687% (17868/19072)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.698% (17990/19200)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.693% (18109/19328)\n",
      "Train Epoch: 36 | Loss: 0.176 | Acc: 93.688% (18228/19456)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.679% (18346/19584)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.679% (18466/19712)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.684% (18587/19840)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.675% (18705/19968)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.675% (18825/20096)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.686% (18947/20224)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.686% (19067/20352)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.667% (19183/20480)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.663% (19302/20608)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.663% (19422/20736)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.683% (19546/20864)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.688% (19667/20992)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.688% (19787/21120)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.694% (19908/21248)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.699% (20029/21376)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.713% (20152/21504)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.685% (20266/21632)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.686% (20386/21760)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.695% (20508/21888)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.691% (20627/22016)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.696% (20748/22144)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.696% (20868/22272)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.701% (20989/22400)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.697% (21108/22528)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.693% (21227/22656)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.702% (21349/22784)\n",
      "Train Epoch: 36 | Loss: 0.177 | Acc: 93.698% (21468/22912)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.676% (21583/23040)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.681% (21704/23168)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.690% (21826/23296)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.677% (21943/23424)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.682% (22064/23552)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.691% (22186/23680)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.700% (22308/23808)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.683% (22424/23936)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.688% (22545/24064)\n",
      "Train Epoch: 36 | Loss: 0.178 | Acc: 93.684% (22664/24192)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.676% (22782/24320)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.672% (22901/24448)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.677% (23022/24576)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.673% (23141/24704)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.686% (23264/24832)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.690% (23385/24960)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.686% (23504/25088)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.683% (23623/25216)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.675% (23741/25344)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.668% (23859/25472)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.668% (23979/25600)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.664% (24098/25728)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.653% (24215/25856)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.642% (24332/25984)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.647% (24453/26112)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.639% (24571/26240)\n",
      "Train Epoch: 36 | Loss: 0.179 | Acc: 93.648% (24693/26368)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.637% (24810/26496)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.637% (24930/26624)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.634% (25049/26752)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.631% (25168/26880)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.613% (25283/27008)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.621% (25405/27136)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.607% (25521/27264)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.604% (25640/27392)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.597% (25758/27520)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.609% (25881/27648)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.613% (26002/27776)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.607% (26120/27904)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.611% (26241/28032)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.608% (26360/28160)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.591% (26475/28288)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.581% (26592/28416)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.585% (26713/28544)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.572% (26829/28672)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.583% (26952/28800)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.570% (27068/28928)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.585% (27192/29056)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.586% (27312/29184)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.583% (27431/29312)\n",
      "Train Epoch: 36 | Loss: 0.180 | Acc: 93.577% (27549/29440)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.571% (27667/29568)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.572% (27787/29696)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.559% (27903/29824)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.563% (28024/29952)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.557% (28142/30080)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.548% (28259/30208)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.546% (28378/30336)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.537% (28495/30464)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.528% (28612/30592)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.532% (28733/30720)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.530% (28852/30848)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.518% (28968/30976)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.528% (29091/31104)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.529% (29211/31232)\n",
      "Train Epoch: 36 | Loss: 0.181 | Acc: 93.517% (29327/31360)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.505% (29443/31488)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.503% (29562/31616)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.479% (29674/31744)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.477% (29793/31872)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.491% (29917/32000)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.479% (30033/32128)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.474% (30151/32256)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.478% (30272/32384)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.479% (30392/32512)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.490% (30515/32640)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.506% (30640/32768)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.519% (30764/32896)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.523% (30885/33024)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.533% (31008/33152)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.534% (31128/33280)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.540% (31250/33408)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.535% (31368/33536)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.542% (31490/33664)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.543% (31610/33792)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.541% (31729/33920)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.547% (31851/34048)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.539% (31968/34176)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.549% (32091/34304)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.544% (32209/34432)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.550% (32331/34560)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.540% (32447/34688)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.549% (32570/34816)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.558% (32693/34944)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.565% (32815/35072)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.571% (32937/35200)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.580% (33060/35328)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.575% (33178/35456)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.573% (33297/35584)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.562% (33413/35712)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.546% (33527/35840)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.547% (33647/35968)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.542% (33765/36096)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.532% (33881/36224)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.538% (34003/36352)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.547% (34126/36480)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.540% (34243/36608)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.540% (34363/36736)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.547% (34485/36864)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.553% (34607/36992)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.564% (34731/37120)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.565% (34851/37248)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.568% (34972/37376)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.553% (35086/37504)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.567% (35211/37632)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.573% (35333/37760)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.573% (35453/37888)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.574% (35573/38016)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.582% (35696/38144)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.583% (35816/38272)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.578% (35934/38400)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.589% (36058/38528)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.582% (36175/38656)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.582% (36295/38784)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.588% (36417/38912)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.584% (36535/39040)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.584% (36655/39168)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.577% (36772/39296)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.570% (36889/39424)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.565% (37007/39552)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.566% (37127/39680)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.574% (37250/39808)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.575% (37370/39936)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.578% (37491/40064)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.578% (37611/40192)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.571% (37728/40320)\n",
      "Train Epoch: 36 | Loss: 0.182 | Acc: 93.574% (37849/40448)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.545% (37957/40576)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.553% (38080/40704)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.561% (38203/40832)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.562% (38323/40960)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.563% (38443/41088)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.546% (38556/41216)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.547% (38676/41344)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.538% (38792/41472)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.541% (38913/41600)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.527% (39027/41728)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.518% (39143/41856)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.519% (39263/41984)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.513% (39380/42112)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.511% (39499/42240)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.514% (39620/42368)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.519% (39742/42496)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.518% (39861/42624)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.530% (39986/42752)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.533% (40107/42880)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.531% (40226/43008)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.520% (40341/43136)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.521% (40461/43264)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.524% (40582/43392)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.529% (40704/43520)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.532% (40825/43648)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.528% (40943/43776)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.527% (41062/43904)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.525% (41181/44032)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.530% (41303/44160)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.533% (41424/44288)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.516% (41536/44416)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.510% (41653/44544)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.517% (41776/44672)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.520% (41897/44800)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.523% (42018/44928)\n",
      "Train Epoch: 36 | Loss: 0.183 | Acc: 93.526% (42139/45056)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.518% (42255/45184)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.520% (42376/45312)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.512% (42492/45440)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.504% (42608/45568)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.511% (42731/45696)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.521% (42855/45824)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.522% (42975/45952)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.516% (43092/46080)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.505% (43207/46208)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.506% (43327/46336)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.500% (43444/46464)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.501% (43564/46592)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.500% (43683/46720)\n",
      "Train Epoch: 36 | Loss: 0.184 | Acc: 93.494% (43800/46848)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.482% (43914/46976)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.468% (44027/47104)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.473% (44149/47232)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.469% (44267/47360)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.474% (44389/47488)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.473% (44508/47616)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.465% (44624/47744)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.460% (44741/47872)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.456% (44859/48000)\n",
      "Train Epoch: 36 | Loss: 0.186 | Acc: 93.449% (44975/48128)\n",
      "Train Epoch: 36 | Loss: 0.186 | Acc: 93.450% (45095/48256)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.459% (45219/48384)\n",
      "Train Epoch: 36 | Loss: 0.186 | Acc: 93.457% (45338/48512)\n",
      "Train Epoch: 36 | Loss: 0.186 | Acc: 93.456% (45457/48640)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.459% (45578/48768)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.460% (45698/48896)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.464% (45820/49024)\n",
      "Train Epoch: 36 | Loss: 0.186 | Acc: 93.461% (45938/49152)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.466% (46060/49280)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.471% (46182/49408)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.471% (46302/49536)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.476% (46424/49664)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.477% (46544/49792)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.474% (46662/49920)\n",
      "Train Epoch: 36 | Loss: 0.185 | Acc: 93.472% (46736/50000)\n",
      "Test Epoch: 36 | Loss: 0.395 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 36 | Loss: 0.348 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 36 | Loss: 0.299 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 36 | Loss: 0.308 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 36 | Loss: 0.303 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 36 | Loss: 0.288 | Acc: 90.667% (544/600)\n",
      "Test Epoch: 36 | Loss: 0.320 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 36 | Loss: 0.355 | Acc: 89.375% (715/800)\n",
      "Test Epoch: 36 | Loss: 0.364 | Acc: 89.000% (801/900)\n",
      "Test Epoch: 36 | Loss: 0.358 | Acc: 89.100% (891/1000)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 88.727% (976/1100)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 88.667% (1064/1200)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 88.769% (1154/1300)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 88.786% (1243/1400)\n",
      "Test Epoch: 36 | Loss: 0.389 | Acc: 88.667% (1330/1500)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 88.625% (1418/1600)\n",
      "Test Epoch: 36 | Loss: 0.384 | Acc: 88.706% (1508/1700)\n",
      "Test Epoch: 36 | Loss: 0.384 | Acc: 88.722% (1597/1800)\n",
      "Test Epoch: 36 | Loss: 0.389 | Acc: 88.421% (1680/1900)\n",
      "Test Epoch: 36 | Loss: 0.403 | Acc: 88.150% (1763/2000)\n",
      "Test Epoch: 36 | Loss: 0.401 | Acc: 88.000% (1848/2100)\n",
      "Test Epoch: 36 | Loss: 0.398 | Acc: 87.864% (1933/2200)\n",
      "Test Epoch: 36 | Loss: 0.394 | Acc: 88.000% (2024/2300)\n",
      "Test Epoch: 36 | Loss: 0.396 | Acc: 88.042% (2113/2400)\n",
      "Test Epoch: 36 | Loss: 0.408 | Acc: 87.760% (2194/2500)\n",
      "Test Epoch: 36 | Loss: 0.419 | Acc: 87.654% (2279/2600)\n",
      "Test Epoch: 36 | Loss: 0.412 | Acc: 87.815% (2371/2700)\n",
      "Test Epoch: 36 | Loss: 0.408 | Acc: 87.786% (2458/2800)\n",
      "Test Epoch: 36 | Loss: 0.415 | Acc: 87.724% (2544/2900)\n",
      "Test Epoch: 36 | Loss: 0.415 | Acc: 87.800% (2634/3000)\n",
      "Test Epoch: 36 | Loss: 0.415 | Acc: 87.742% (2720/3100)\n",
      "Test Epoch: 36 | Loss: 0.413 | Acc: 87.750% (2808/3200)\n",
      "Test Epoch: 36 | Loss: 0.414 | Acc: 87.788% (2897/3300)\n",
      "Test Epoch: 36 | Loss: 0.415 | Acc: 87.765% (2984/3400)\n",
      "Test Epoch: 36 | Loss: 0.422 | Acc: 87.686% (3069/3500)\n",
      "Test Epoch: 36 | Loss: 0.422 | Acc: 87.667% (3156/3600)\n",
      "Test Epoch: 36 | Loss: 0.427 | Acc: 87.730% (3246/3700)\n",
      "Test Epoch: 36 | Loss: 0.429 | Acc: 87.684% (3332/3800)\n",
      "Test Epoch: 36 | Loss: 0.427 | Acc: 87.744% (3422/3900)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.750% (3510/4000)\n",
      "Test Epoch: 36 | Loss: 0.440 | Acc: 87.585% (3591/4100)\n",
      "Test Epoch: 36 | Loss: 0.444 | Acc: 87.476% (3674/4200)\n",
      "Test Epoch: 36 | Loss: 0.437 | Acc: 87.651% (3769/4300)\n",
      "Test Epoch: 36 | Loss: 0.440 | Acc: 87.659% (3857/4400)\n",
      "Test Epoch: 36 | Loss: 0.438 | Acc: 87.689% (3946/4500)\n",
      "Test Epoch: 36 | Loss: 0.438 | Acc: 87.652% (4032/4600)\n",
      "Test Epoch: 36 | Loss: 0.439 | Acc: 87.553% (4115/4700)\n",
      "Test Epoch: 36 | Loss: 0.441 | Acc: 87.479% (4199/4800)\n",
      "Test Epoch: 36 | Loss: 0.443 | Acc: 87.469% (4286/4900)\n",
      "Test Epoch: 36 | Loss: 0.446 | Acc: 87.360% (4368/5000)\n",
      "Test Epoch: 36 | Loss: 0.444 | Acc: 87.392% (4457/5100)\n",
      "Test Epoch: 36 | Loss: 0.448 | Acc: 87.327% (4541/5200)\n",
      "Test Epoch: 36 | Loss: 0.447 | Acc: 87.340% (4629/5300)\n",
      "Test Epoch: 36 | Loss: 0.444 | Acc: 87.426% (4721/5400)\n",
      "Test Epoch: 36 | Loss: 0.443 | Acc: 87.473% (4811/5500)\n",
      "Test Epoch: 36 | Loss: 0.444 | Acc: 87.464% (4898/5600)\n",
      "Test Epoch: 36 | Loss: 0.445 | Acc: 87.456% (4985/5700)\n",
      "Test Epoch: 36 | Loss: 0.442 | Acc: 87.534% (5077/5800)\n",
      "Test Epoch: 36 | Loss: 0.444 | Acc: 87.424% (5158/5900)\n",
      "Test Epoch: 36 | Loss: 0.442 | Acc: 87.433% (5246/6000)\n",
      "Test Epoch: 36 | Loss: 0.439 | Acc: 87.492% (5337/6100)\n",
      "Test Epoch: 36 | Loss: 0.439 | Acc: 87.468% (5423/6200)\n",
      "Test Epoch: 36 | Loss: 0.437 | Acc: 87.492% (5512/6300)\n",
      "Test Epoch: 36 | Loss: 0.434 | Acc: 87.562% (5604/6400)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.523% (5689/6500)\n",
      "Test Epoch: 36 | Loss: 0.431 | Acc: 87.576% (5780/6600)\n",
      "Test Epoch: 36 | Loss: 0.431 | Acc: 87.627% (5871/6700)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.632% (5959/6800)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.609% (6045/6900)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.557% (6129/7000)\n",
      "Test Epoch: 36 | Loss: 0.436 | Acc: 87.507% (6213/7100)\n",
      "Test Epoch: 36 | Loss: 0.436 | Acc: 87.514% (6301/7200)\n",
      "Test Epoch: 36 | Loss: 0.435 | Acc: 87.575% (6393/7300)\n",
      "Test Epoch: 36 | Loss: 0.434 | Acc: 87.595% (6482/7400)\n",
      "Test Epoch: 36 | Loss: 0.435 | Acc: 87.573% (6568/7500)\n",
      "Test Epoch: 36 | Loss: 0.435 | Acc: 87.592% (6657/7600)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.597% (6745/7700)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.577% (6831/7800)\n",
      "Test Epoch: 36 | Loss: 0.430 | Acc: 87.570% (6918/7900)\n",
      "Test Epoch: 36 | Loss: 0.431 | Acc: 87.500% (7000/8000)\n",
      "Test Epoch: 36 | Loss: 0.428 | Acc: 87.519% (7089/8100)\n",
      "Test Epoch: 36 | Loss: 0.428 | Acc: 87.476% (7173/8200)\n",
      "Test Epoch: 36 | Loss: 0.429 | Acc: 87.458% (7259/8300)\n",
      "Test Epoch: 36 | Loss: 0.429 | Acc: 87.440% (7345/8400)\n",
      "Test Epoch: 36 | Loss: 0.429 | Acc: 87.412% (7430/8500)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.384% (7515/8600)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.391% (7603/8700)\n",
      "Test Epoch: 36 | Loss: 0.435 | Acc: 87.364% (7688/8800)\n",
      "Test Epoch: 36 | Loss: 0.434 | Acc: 87.393% (7778/8900)\n",
      "Test Epoch: 36 | Loss: 0.435 | Acc: 87.378% (7864/9000)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.407% (7954/9100)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.424% (8043/9200)\n",
      "Test Epoch: 36 | Loss: 0.434 | Acc: 87.409% (8129/9300)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.426% (8218/9400)\n",
      "Test Epoch: 36 | Loss: 0.434 | Acc: 87.421% (8305/9500)\n",
      "Test Epoch: 36 | Loss: 0.433 | Acc: 87.438% (8394/9600)\n",
      "Test Epoch: 36 | Loss: 0.432 | Acc: 87.505% (8488/9700)\n",
      "Test Epoch: 36 | Loss: 0.430 | Acc: 87.551% (8580/9800)\n",
      "Test Epoch: 36 | Loss: 0.431 | Acc: 87.545% (8667/9900)\n",
      "Test Epoch: 36 | Loss: 0.430 | Acc: 87.550% (8755/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 37\n",
      "Train Epoch: 37 | Loss: 0.138 | Acc: 95.312% (122/128)\n",
      "Train Epoch: 37 | Loss: 0.143 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 37 | Loss: 0.142 | Acc: 95.312% (366/384)\n",
      "Train Epoch: 37 | Loss: 0.137 | Acc: 95.703% (490/512)\n",
      "Train Epoch: 37 | Loss: 0.150 | Acc: 95.156% (609/640)\n",
      "Train Epoch: 37 | Loss: 0.158 | Acc: 95.052% (730/768)\n",
      "Train Epoch: 37 | Loss: 0.154 | Acc: 95.201% (853/896)\n",
      "Train Epoch: 37 | Loss: 0.158 | Acc: 94.922% (972/1024)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.531% (1089/1152)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.688% (1212/1280)\n",
      "Train Epoch: 37 | Loss: 0.158 | Acc: 94.957% (1337/1408)\n",
      "Train Epoch: 37 | Loss: 0.154 | Acc: 95.052% (1460/1536)\n",
      "Train Epoch: 37 | Loss: 0.159 | Acc: 94.832% (1578/1664)\n",
      "Train Epoch: 37 | Loss: 0.158 | Acc: 94.866% (1700/1792)\n",
      "Train Epoch: 37 | Loss: 0.159 | Acc: 94.792% (1820/1920)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.580% (1937/2048)\n",
      "Train Epoch: 37 | Loss: 0.160 | Acc: 94.669% (2060/2176)\n",
      "Train Epoch: 37 | Loss: 0.159 | Acc: 94.618% (2180/2304)\n",
      "Train Epoch: 37 | Loss: 0.157 | Acc: 94.655% (2302/2432)\n",
      "Train Epoch: 37 | Loss: 0.156 | Acc: 94.648% (2423/2560)\n",
      "Train Epoch: 37 | Loss: 0.160 | Acc: 94.494% (2540/2688)\n",
      "Train Epoch: 37 | Loss: 0.160 | Acc: 94.425% (2659/2816)\n",
      "Train Epoch: 37 | Loss: 0.161 | Acc: 94.463% (2781/2944)\n",
      "Train Epoch: 37 | Loss: 0.161 | Acc: 94.401% (2900/3072)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.344% (3019/3200)\n",
      "Train Epoch: 37 | Loss: 0.160 | Acc: 94.441% (3143/3328)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.416% (3263/3456)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.364% (3382/3584)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.370% (3503/3712)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.245% (3619/3840)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.279% (3741/3968)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.238% (3860/4096)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.271% (3982/4224)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.210% (4100/4352)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.286% (4224/4480)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.358% (4348/4608)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.341% (4468/4736)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.387% (4591/4864)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.431% (4714/4992)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.453% (4836/5120)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.455% (4957/5248)\n",
      "Train Epoch: 37 | Loss: 0.161 | Acc: 94.475% (5079/5376)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.386% (5195/5504)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.371% (5315/5632)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.306% (5432/5760)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.327% (5554/5888)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.332% (5675/6016)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.352% (5797/6144)\n",
      "Train Epoch: 37 | Loss: 0.161 | Acc: 94.372% (5919/6272)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.391% (6041/6400)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.393% (6162/6528)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.411% (6284/6656)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.325% (6399/6784)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.314% (6519/6912)\n",
      "Train Epoch: 37 | Loss: 0.164 | Acc: 94.304% (6639/7040)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.308% (6760/7168)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.298% (6880/7296)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.316% (7002/7424)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.240% (7117/7552)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.206% (7235/7680)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.237% (7358/7808)\n",
      "Train Epoch: 37 | Loss: 0.162 | Acc: 94.254% (7480/7936)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.246% (7600/8064)\n",
      "Train Epoch: 37 | Loss: 0.163 | Acc: 94.250% (7721/8192)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.183% (7836/8320)\n",
      "Train Epoch: 37 | Loss: 0.165 | Acc: 94.188% (7957/8448)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.088% (8069/8576)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.072% (8188/8704)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.033% (8305/8832)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.018% (8424/8960)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.981% (8541/9088)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.989% (8662/9216)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.943% (8778/9344)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.972% (8901/9472)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.958% (9020/9600)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.956% (9140/9728)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.943% (9259/9856)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.930% (9378/9984)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.908% (9496/10112)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.916% (9617/10240)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.895% (9735/10368)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.921% (9858/10496)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.938% (9980/10624)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.927% (10099/10752)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.952% (10222/10880)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.968% (10344/11008)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.957% (10463/11136)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.972% (10585/11264)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.952% (10703/11392)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.941% (10822/11520)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.956% (10944/11648)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.937% (11062/11776)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.943% (11183/11904)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.958% (11305/12032)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.956% (11425/12160)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.970% (11547/12288)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.976% (11668/12416)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.973% (11788/12544)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.963% (11907/12672)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.961% (12027/12800)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.951% (12146/12928)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.934% (12264/13056)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.955% (12387/13184)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.975% (12510/13312)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.966% (12629/13440)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 93.993% (12753/13568)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.006% (12875/13696)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.025% (12998/13824)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.037% (13120/13952)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.006% (13236/14080)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.024% (13359/14208)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.015% (13478/14336)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.033% (13601/14464)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.031% (13721/14592)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.049% (13844/14720)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.053% (13965/14848)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.037% (14083/14976)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.041% (14204/15104)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.032% (14323/15232)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.049% (14446/15360)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.047% (14566/15488)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.051% (14687/15616)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.061% (14809/15744)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.071% (14931/15872)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.088% (15054/16000)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.122% (15180/16128)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.125% (15301/16256)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.141% (15424/16384)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.138% (15544/16512)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.141% (15665/16640)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.156% (15788/16768)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.164% (15910/16896)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.173% (16032/17024)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.176% (16153/17152)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.178% (16274/17280)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.146% (16389/17408)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.155% (16511/17536)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.163% (16633/17664)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.160% (16753/17792)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.135% (16869/17920)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.132% (16989/18048)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.135% (17110/18176)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.160% (17235/18304)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.162% (17356/18432)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.154% (17475/18560)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.151% (17595/18688)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.154% (17716/18816)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.172% (17840/18944)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.185% (17963/19072)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.188% (18084/19200)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.174% (18202/19328)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.177% (18323/19456)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.174% (18443/19584)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.181% (18565/19712)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.183% (18686/19840)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.186% (18807/19968)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.168% (18924/20096)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.185% (19048/20224)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.202% (19172/20352)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.194% (19291/20480)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.201% (19413/20608)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.218% (19537/20736)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.225% (19659/20864)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.212% (19777/20992)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.219% (19899/21120)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.225% (20021/21248)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.218% (20140/21376)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.215% (20260/21504)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.226% (20383/21632)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.233% (20505/21760)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.243% (20628/21888)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.218% (20743/22016)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.238% (20868/22144)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.239% (20989/22272)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.241% (21110/22400)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.234% (21229/22528)\n",
      "Train Epoch: 37 | Loss: 0.167 | Acc: 94.227% (21348/22656)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.206% (21464/22784)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.221% (21588/22912)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.201% (21704/23040)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.199% (21824/23168)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.179% (21940/23296)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.181% (22061/23424)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.192% (22184/23552)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.181% (22302/23680)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.166% (22419/23808)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.151% (22536/23936)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.149% (22656/24064)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.155% (22778/24192)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.153% (22898/24320)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.159% (23020/24448)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.153% (23139/24576)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.163% (23262/24704)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.157% (23381/24832)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.155% (23501/24960)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.169% (23625/25088)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.174% (23747/25216)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.172% (23867/25344)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.174% (23988/25472)\n",
      "Train Epoch: 37 | Loss: 0.168 | Acc: 94.199% (24115/25600)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.166% (24227/25728)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.160% (24346/25856)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.158% (24466/25984)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.156% (24586/26112)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.150% (24705/26240)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.141% (24823/26368)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.131% (24941/26496)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.137% (25063/26624)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.139% (25184/26752)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.126% (25301/26880)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.117% (25419/27008)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.126% (25542/27136)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.117% (25660/27264)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.126% (25783/27392)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.128% (25904/27520)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.133% (26026/27648)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.121% (26143/27776)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.123% (26264/27904)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.132% (26387/28032)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.137% (26509/28160)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.135% (26629/28288)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.148% (26753/28416)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.139% (26871/28544)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.134% (26990/28672)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.125% (27108/28800)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.110% (27224/28928)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.111% (27345/29056)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.100% (27462/29184)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.108% (27585/29312)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.100% (27703/29440)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.095% (27822/29568)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.097% (27943/29696)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.099% (28064/29824)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.111% (28188/29952)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.092% (28303/30080)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.104% (28427/30208)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.106% (28548/30336)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.101% (28667/30464)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.113% (28791/30592)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.124% (28915/30720)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.103% (29029/30848)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.105% (29150/30976)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.097% (29268/31104)\n",
      "Train Epoch: 37 | Loss: 0.169 | Acc: 94.086% (29385/31232)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.078% (29503/31360)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.080% (29624/31488)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.066% (29740/31616)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.065% (29860/31744)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.054% (29977/31872)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.050% (30096/32000)\n",
      "Train Epoch: 37 | Loss: 0.170 | Acc: 94.046% (30215/32128)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.026% (30329/32256)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.016% (30446/32384)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.024% (30569/32512)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.035% (30693/32640)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.034% (30813/32768)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.033% (30933/32896)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.038% (31055/33024)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.043% (31177/33152)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.032% (31294/33280)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.034% (31415/33408)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.036% (31536/33536)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.023% (31652/33664)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.016% (31770/33792)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.015% (31890/33920)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.014% (32010/34048)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.019% (32132/34176)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.021% (32253/34304)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 94.011% (32370/34432)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.990% (32483/34560)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.986% (32602/34688)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.983% (32721/34816)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.988% (32843/34944)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.987% (32963/35072)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.989% (33084/35200)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.988% (33204/35328)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.978% (33321/35456)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.989% (33445/35584)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.996% (33568/35712)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.996% (33688/35840)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.984% (33804/35968)\n",
      "Train Epoch: 37 | Loss: 0.171 | Acc: 93.983% (33924/36096)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.976% (34042/36224)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.959% (34156/36352)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.961% (34277/36480)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.963% (34398/36608)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.965% (34519/36736)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.970% (34641/36864)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.982% (34766/36992)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.974% (34883/37120)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.965% (35000/37248)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.967% (35121/37376)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.971% (35243/37504)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.965% (35361/37632)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.959% (35479/37760)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.953% (35597/37888)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.966% (35722/38016)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.975% (35846/38144)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.983% (35969/38272)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.974% (36086/38400)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.955% (36199/38528)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.944% (36315/38656)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.925% (36428/38784)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.914% (36544/38912)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.924% (36668/39040)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.916% (36785/39168)\n",
      "Train Epoch: 37 | Loss: 0.172 | Acc: 93.918% (36906/39296)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.905% (37021/39424)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.907% (37142/39552)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.911% (37264/39680)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.916% (37386/39808)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.910% (37504/39936)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.912% (37625/40064)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.917% (37747/40192)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.921% (37869/40320)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.916% (37987/40448)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.913% (38106/40576)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.915% (38227/40704)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.894% (38339/40832)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.899% (38461/40960)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.898% (38581/41088)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.891% (38698/41216)\n",
      "Train Epoch: 37 | Loss: 0.173 | Acc: 93.885% (38816/41344)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.883% (38935/41472)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.865% (39048/41600)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.860% (39166/41728)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.858% (39285/41856)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.855% (39404/41984)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.866% (39529/42112)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.866% (39649/42240)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.856% (39765/42368)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.846% (39881/42496)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.834% (39996/42624)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.830% (40114/42752)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.818% (40229/42880)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.803% (40343/43008)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.806% (40464/43136)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.805% (40584/43264)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.808% (40705/43392)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.798% (40821/43520)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.796% (40940/43648)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.805% (41064/43776)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.807% (41185/43904)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.809% (41306/44032)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.816% (41429/44160)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.813% (41548/44288)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.827% (41674/44416)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.824% (41793/44544)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.817% (41910/44672)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.826% (42034/44800)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.839% (42160/44928)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.843% (42282/45056)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.850% (42405/45184)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.836% (42519/45312)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.842% (42642/45440)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.847% (42764/45568)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.851% (42886/45696)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.853% (43007/45824)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.848% (43125/45952)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.845% (43244/46080)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.847% (43365/46208)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.847% (43485/46336)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.847% (43605/46464)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.851% (43727/46592)\n",
      "Train Epoch: 37 | Loss: 0.175 | Acc: 93.857% (43850/46720)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.859% (43971/46848)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.856% (44090/46976)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.846% (44205/47104)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.850% (44327/47232)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.849% (44447/47360)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.853% (44569/47488)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.855% (44690/47616)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.857% (44811/47744)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.857% (44931/47872)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.858% (45052/48000)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.862% (45174/48128)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.868% (45297/48256)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.874% (45420/48384)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.878% (45542/48512)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.877% (45662/48640)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.879% (45783/48768)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.877% (45902/48896)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.872% (46020/49024)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.870% (46139/49152)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.870% (46259/49280)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.871% (46380/49408)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.883% (46506/49536)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.887% (46628/49664)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.881% (46745/49792)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.864% (46857/49920)\n",
      "Train Epoch: 37 | Loss: 0.174 | Acc: 93.864% (46932/50000)\n",
      "Test Epoch: 37 | Loss: 0.514 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 37 | Loss: 0.351 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 37 | Loss: 0.376 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 37 | Loss: 0.373 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 37 | Loss: 0.333 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 37 | Loss: 0.352 | Acc: 89.000% (623/700)\n",
      "Test Epoch: 37 | Loss: 0.393 | Acc: 88.000% (704/800)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 88.000% (792/900)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 88.200% (882/1000)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 87.727% (965/1100)\n",
      "Test Epoch: 37 | Loss: 0.434 | Acc: 87.417% (1049/1200)\n",
      "Test Epoch: 37 | Loss: 0.428 | Acc: 87.538% (1138/1300)\n",
      "Test Epoch: 37 | Loss: 0.421 | Acc: 87.571% (1226/1400)\n",
      "Test Epoch: 37 | Loss: 0.419 | Acc: 87.400% (1311/1500)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.375% (1398/1600)\n",
      "Test Epoch: 37 | Loss: 0.406 | Acc: 87.647% (1490/1700)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.833% (1581/1800)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.842% (1669/1900)\n",
      "Test Epoch: 37 | Loss: 0.409 | Acc: 87.750% (1755/2000)\n",
      "Test Epoch: 37 | Loss: 0.407 | Acc: 87.571% (1839/2100)\n",
      "Test Epoch: 37 | Loss: 0.403 | Acc: 87.500% (1925/2200)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 87.609% (2015/2300)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 87.708% (2105/2400)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 87.760% (2194/2500)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 87.692% (2280/2600)\n",
      "Test Epoch: 37 | Loss: 0.407 | Acc: 87.778% (2370/2700)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 87.857% (2460/2800)\n",
      "Test Epoch: 37 | Loss: 0.409 | Acc: 88.034% (2553/2900)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 87.900% (2637/3000)\n",
      "Test Epoch: 37 | Loss: 0.409 | Acc: 87.903% (2725/3100)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 87.969% (2815/3200)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 87.939% (2902/3300)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 88.000% (2992/3400)\n",
      "Test Epoch: 37 | Loss: 0.408 | Acc: 88.029% (3081/3500)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 88.000% (3168/3600)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.946% (3254/3700)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 87.974% (3343/3800)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 87.923% (3429/3900)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.900% (3516/4000)\n",
      "Test Epoch: 37 | Loss: 0.420 | Acc: 87.756% (3598/4100)\n",
      "Test Epoch: 37 | Loss: 0.423 | Acc: 87.690% (3683/4200)\n",
      "Test Epoch: 37 | Loss: 0.418 | Acc: 87.860% (3778/4300)\n",
      "Test Epoch: 37 | Loss: 0.418 | Acc: 87.955% (3870/4400)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 88.000% (3960/4500)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 88.000% (4048/4600)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 88.000% (4136/4700)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 88.042% (4226/4800)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 88.061% (4315/4900)\n",
      "Test Epoch: 37 | Loss: 0.419 | Acc: 88.000% (4400/5000)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 88.098% (4493/5100)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 88.038% (4578/5200)\n",
      "Test Epoch: 37 | Loss: 0.417 | Acc: 87.962% (4662/5300)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 88.037% (4754/5400)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 88.036% (4842/5500)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 88.018% (4929/5600)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 87.982% (5015/5700)\n",
      "Test Epoch: 37 | Loss: 0.412 | Acc: 88.034% (5106/5800)\n",
      "Test Epoch: 37 | Loss: 0.412 | Acc: 88.051% (5195/5900)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 88.017% (5281/6000)\n",
      "Test Epoch: 37 | Loss: 0.408 | Acc: 88.066% (5372/6100)\n",
      "Test Epoch: 37 | Loss: 0.408 | Acc: 88.065% (5460/6200)\n",
      "Test Epoch: 37 | Loss: 0.408 | Acc: 88.079% (5549/6300)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 88.156% (5642/6400)\n",
      "Test Epoch: 37 | Loss: 0.404 | Acc: 88.169% (5731/6500)\n",
      "Test Epoch: 37 | Loss: 0.402 | Acc: 88.227% (5823/6600)\n",
      "Test Epoch: 37 | Loss: 0.401 | Acc: 88.239% (5912/6700)\n",
      "Test Epoch: 37 | Loss: 0.404 | Acc: 88.191% (5997/6800)\n",
      "Test Epoch: 37 | Loss: 0.405 | Acc: 88.130% (6081/6900)\n",
      "Test Epoch: 37 | Loss: 0.406 | Acc: 88.057% (6164/7000)\n",
      "Test Epoch: 37 | Loss: 0.409 | Acc: 88.014% (6249/7100)\n",
      "Test Epoch: 37 | Loss: 0.410 | Acc: 88.069% (6341/7200)\n",
      "Test Epoch: 37 | Loss: 0.410 | Acc: 88.082% (6430/7300)\n",
      "Test Epoch: 37 | Loss: 0.412 | Acc: 88.054% (6516/7400)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.987% (6599/7500)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.921% (6682/7600)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.935% (6771/7700)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.974% (6862/7800)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 87.975% (6950/7900)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.975% (7038/8000)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 88.025% (7130/8100)\n",
      "Test Epoch: 37 | Loss: 0.410 | Acc: 88.049% (7220/8200)\n",
      "Test Epoch: 37 | Loss: 0.410 | Acc: 88.072% (7310/8300)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 88.048% (7396/8400)\n",
      "Test Epoch: 37 | Loss: 0.411 | Acc: 88.035% (7483/8500)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.988% (7567/8600)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.966% (7653/8700)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 87.955% (7740/8800)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 87.955% (7828/8900)\n",
      "Test Epoch: 37 | Loss: 0.416 | Acc: 87.900% (7911/9000)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.923% (8001/9100)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.967% (8093/9200)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 87.935% (8178/9300)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.947% (8267/9400)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 87.937% (8354/9500)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 87.938% (8442/9600)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.979% (8534/9700)\n",
      "Test Epoch: 37 | Loss: 0.413 | Acc: 87.990% (8623/9800)\n",
      "Test Epoch: 37 | Loss: 0.415 | Acc: 87.990% (8711/9900)\n",
      "Test Epoch: 37 | Loss: 0.414 | Acc: 88.010% (8801/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 38\n",
      "Train Epoch: 38 | Loss: 0.135 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 38 | Loss: 0.149 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 38 | Loss: 0.124 | Acc: 94.531% (363/384)\n",
      "Train Epoch: 38 | Loss: 0.143 | Acc: 94.336% (483/512)\n",
      "Train Epoch: 38 | Loss: 0.135 | Acc: 94.688% (606/640)\n",
      "Train Epoch: 38 | Loss: 0.142 | Acc: 94.401% (725/768)\n",
      "Train Epoch: 38 | Loss: 0.138 | Acc: 94.643% (848/896)\n",
      "Train Epoch: 38 | Loss: 0.145 | Acc: 94.434% (967/1024)\n",
      "Train Epoch: 38 | Loss: 0.148 | Acc: 94.358% (1087/1152)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.297% (1207/1280)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.247% (1327/1408)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.401% (1450/1536)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.531% (1573/1664)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.364% (1691/1792)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.271% (1810/1920)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.336% (1932/2048)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.301% (2052/2176)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.531% (2178/2304)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.531% (2299/2432)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.570% (2421/2560)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.457% (2539/2688)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.531% (2662/2816)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.497% (2782/2944)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.531% (2904/3072)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.500% (3024/3200)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.471% (3144/3328)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.444% (3264/3456)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.280% (3379/3584)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.343% (3502/3712)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.401% (3625/3840)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.380% (3745/3968)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.360% (3865/4096)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.318% (3984/4224)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.301% (4104/4352)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.353% (4227/4480)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.336% (4347/4608)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.299% (4466/4736)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.305% (4587/4864)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.311% (4708/4992)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.297% (4828/5120)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.284% (4948/5248)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.327% (5071/5376)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.295% (5190/5504)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.336% (5313/5632)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.323% (5433/5760)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.327% (5554/5888)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.382% (5678/6016)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.417% (5801/6144)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.404% (5921/6272)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.391% (6041/6400)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.409% (6163/6528)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.336% (6279/6656)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.369% (6402/6784)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.343% (6521/6912)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.361% (6643/7040)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.336% (6762/7168)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.353% (6884/7296)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.397% (7008/7424)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.359% (7126/7552)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.375% (7248/7680)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.365% (7368/7808)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.380% (7490/7936)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.382% (7611/8064)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.348% (7729/8192)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.363% (7851/8320)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.437% (7978/8448)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.426% (8098/8576)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.405% (8217/8704)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.407% (8338/8832)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.475% (8465/8960)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.454% (8584/9088)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.455% (8705/9216)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.488% (8829/9344)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.489% (8950/9472)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.521% (9074/9600)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.531% (9196/9728)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.562% (9320/9856)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.581% (9443/9984)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.610% (9567/10112)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.619% (9689/10240)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.599% (9808/10368)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.598% (9929/10496)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.597% (10050/10624)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.615% (10173/10752)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.596% (10292/10880)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.613% (10415/11008)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.612% (10536/11136)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.593% (10655/11264)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.619% (10779/11392)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.627% (10901/11520)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.626% (11022/11648)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.667% (11148/11776)\n",
      "Train Epoch: 38 | Loss: 0.150 | Acc: 94.691% (11272/11904)\n",
      "Train Epoch: 38 | Loss: 0.150 | Acc: 94.689% (11393/12032)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.638% (11508/12160)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.629% (11628/12288)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.636% (11750/12416)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.611% (11868/12544)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.626% (11991/12672)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.648% (12115/12800)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.663% (12238/12928)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.661% (12359/13056)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.691% (12484/13184)\n",
      "Train Epoch: 38 | Loss: 0.151 | Acc: 94.659% (12601/13312)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.658% (12722/13440)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.657% (12843/13568)\n",
      "Train Epoch: 38 | Loss: 0.152 | Acc: 94.641% (12962/13696)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.618% (13080/13824)\n",
      "Train Epoch: 38 | Loss: 0.153 | Acc: 94.603% (13199/13952)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.595% (13319/14080)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.609% (13442/14208)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.601% (13562/14336)\n",
      "Train Epoch: 38 | Loss: 0.154 | Acc: 94.593% (13682/14464)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.566% (13799/14592)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.565% (13920/14720)\n",
      "Train Epoch: 38 | Loss: 0.155 | Acc: 94.558% (14040/14848)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.525% (14156/14976)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.518% (14276/15104)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.525% (14398/15232)\n",
      "Train Epoch: 38 | Loss: 0.156 | Acc: 94.518% (14518/15360)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.486% (14634/15488)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.461% (14751/15616)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.461% (14872/15744)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.437% (14989/15872)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.469% (15115/16000)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.469% (15236/16128)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.476% (15358/16256)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.464% (15477/16384)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.453% (15596/16512)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.465% (15719/16640)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.448% (15837/16768)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.460% (15960/16896)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.478% (16084/17024)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.496% (16208/17152)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.514% (16332/17280)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.520% (16454/17408)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.537% (16578/17536)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.537% (16699/17664)\n",
      "Train Epoch: 38 | Loss: 0.157 | Acc: 94.514% (16816/17792)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.520% (16938/17920)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.526% (17060/18048)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.520% (17180/18176)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.498% (17297/18304)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.482% (17415/18432)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.461% (17532/18560)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.456% (17652/18688)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.462% (17774/18816)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.484% (17899/18944)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.495% (18022/19072)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.490% (18142/19200)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.490% (18263/19328)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.475% (18381/19456)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.490% (18505/19584)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.486% (18625/19712)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.486% (18746/19840)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.481% (18866/19968)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.477% (18986/20096)\n",
      "Train Epoch: 38 | Loss: 0.158 | Acc: 94.477% (19107/20224)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.472% (19227/20352)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.448% (19343/20480)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.454% (19465/20608)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.464% (19588/20736)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.474% (19711/20864)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.474% (19832/20992)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.484% (19955/21120)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.451% (20069/21248)\n",
      "Train Epoch: 38 | Loss: 0.159 | Acc: 94.428% (20185/21376)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.438% (20308/21504)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.430% (20427/21632)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.430% (20548/21760)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.403% (20663/21888)\n",
      "Train Epoch: 38 | Loss: 0.160 | Acc: 94.390% (20781/22016)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.378% (20899/22144)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.383% (21021/22272)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.371% (21139/22400)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.354% (21256/22528)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.324% (21370/22656)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.321% (21490/22784)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.313% (21609/22912)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.319% (21731/23040)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.341% (21857/23168)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.351% (21980/23296)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.339% (22098/23424)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.323% (22215/23552)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.316% (22334/23680)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.317% (22455/23808)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.331% (22579/23936)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.332% (22700/24064)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.329% (22820/24192)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.338% (22943/24320)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.347% (23066/24448)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.356% (23189/24576)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.369% (23313/24704)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (23433/24832)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.371% (23555/24960)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.368% (23675/25088)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.369% (23796/25216)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (23916/25344)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (24037/25472)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.359% (24156/25600)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.352% (24275/25728)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.326% (24389/25856)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.343% (24514/25984)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.351% (24637/26112)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.345% (24756/26240)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.342% (24876/26368)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.335% (24995/26496)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.321% (25112/26624)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.322% (25233/26752)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.289% (25345/26880)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.294% (25467/27008)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.303% (25590/27136)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.322% (25716/27264)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.323% (25837/27392)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.328% (25959/27520)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.325% (26079/27648)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.333% (26202/27776)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.331% (26322/27904)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.324% (26441/28032)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.325% (26562/28160)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.344% (26688/28288)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.352% (26811/28416)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.360% (26934/28544)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.357% (27054/28672)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.344% (27171/28800)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.351% (27294/28928)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.359% (27417/29056)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.339% (27532/29184)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.354% (27657/29312)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.344% (27775/29440)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.345% (27896/29568)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.329% (28012/29696)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.327% (28132/29824)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.338% (28256/29952)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.328% (28374/30080)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.339% (28498/30208)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.353% (28623/30336)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.357% (28745/30464)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.365% (28868/30592)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.372% (28991/30720)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.359% (29108/30848)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.367% (29231/30976)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.364% (29351/31104)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.358% (29470/31232)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.369% (29594/31360)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.369% (29715/31488)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.370% (29836/31616)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.377% (29959/31744)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.374% (30079/31872)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.381% (30202/32000)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.373% (30320/32128)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.376% (30442/32256)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.368% (30560/32384)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.371% (30682/32512)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (30801/32640)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.379% (30926/32768)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.373% (31045/32896)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.371% (31165/33024)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.353% (31280/33152)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.345% (31398/33280)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.358% (31523/33408)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.358% (31644/33536)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.362% (31766/33664)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.363% (31887/33792)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.372% (32011/33920)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.364% (32129/34048)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.356% (32247/34176)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.348% (32365/34304)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.363% (32491/34432)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (32613/34560)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.367% (32734/34688)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.370% (32856/34816)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.374% (32978/34944)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.369% (33097/35072)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.378% (33221/35200)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.370% (33339/35328)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.373% (33461/35456)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.382% (33585/35584)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.374% (33703/35712)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.361% (33819/35840)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.353% (33937/35968)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.351% (34057/36096)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.363% (34182/36224)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.366% (34304/36352)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.364% (34424/36480)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.362% (34544/36608)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.371% (34668/36736)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.368% (34788/36864)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.374% (34911/36992)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.370% (35030/37120)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.359% (35147/37248)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.352% (35265/37376)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.355% (35387/37504)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.353% (35507/37632)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.351% (35627/37760)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.354% (35749/37888)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.352% (35869/38016)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.356% (35991/38144)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.354% (36111/38272)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.357% (36233/38400)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.368% (36358/38528)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.368% (36479/38656)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.369% (36600/38784)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.369% (36721/38912)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.367% (36841/39040)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.368% (36962/39168)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.366% (37082/39296)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.364% (37202/39424)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.367% (37324/39552)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.367% (37445/39680)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.370% (37567/39808)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.368% (37687/39936)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.364% (37806/40064)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.370% (37929/40192)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.373% (38051/40320)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.371% (38171/40448)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.376% (38294/40576)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.384% (38418/40704)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.375% (38535/40832)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.373% (38655/40960)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.375% (38777/41088)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.374% (38897/41216)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.381% (39021/41344)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.375% (39139/41472)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.373% (39259/41600)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.387% (39386/41728)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.374% (39501/41856)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.374% (39622/41984)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.370% (39741/42112)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.373% (39863/42240)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.378% (39986/42368)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.381% (40108/42496)\n",
      "Train Epoch: 38 | Loss: 0.161 | Acc: 94.374% (40226/42624)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.363% (40342/42752)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.359% (40461/42880)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.355% (40580/43008)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.330% (40690/43136)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.328% (40810/43264)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.328% (40931/43392)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.327% (41051/43520)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.323% (41170/43648)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.321% (41290/43776)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.315% (41408/43904)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.311% (41527/44032)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.309% (41647/44160)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.290% (41759/44288)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.293% (41881/44416)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.307% (42008/44544)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.303% (42127/44672)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.297% (42245/44800)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.293% (42364/44928)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.292% (42484/45056)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.288% (42603/45184)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.293% (42726/45312)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.298% (42849/45440)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.299% (42970/45568)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.304% (43093/45696)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.293% (43209/45824)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.296% (43331/45952)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.290% (43449/46080)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.298% (43573/46208)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.300% (43695/46336)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.292% (43812/46464)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.293% (43933/46592)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.287% (44051/46720)\n",
      "Train Epoch: 38 | Loss: 0.162 | Acc: 94.288% (44172/46848)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.280% (44289/46976)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.276% (44408/47104)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.277% (44529/47232)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.276% (44649/47360)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.272% (44768/47488)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.275% (44890/47616)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.267% (45007/47744)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.266% (45127/47872)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.267% (45248/48000)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.261% (45366/48128)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.260% (45486/48256)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.260% (45607/48384)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.263% (45729/48512)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.262% (45849/48640)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.259% (45968/48768)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.253% (46086/48896)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.242% (46201/49024)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.244% (46323/49152)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.249% (46446/49280)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.244% (46564/49408)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.243% (46684/49536)\n",
      "Train Epoch: 38 | Loss: 0.163 | Acc: 94.235% (46801/49664)\n",
      "Train Epoch: 38 | Loss: 0.164 | Acc: 94.232% (46920/49792)\n",
      "Train Epoch: 38 | Loss: 0.164 | Acc: 94.221% (47035/49920)\n",
      "Train Epoch: 38 | Loss: 0.164 | Acc: 94.224% (47112/50000)\n",
      "Test Epoch: 38 | Loss: 0.394 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 38 | Loss: 0.431 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 38 | Loss: 0.370 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 38 | Loss: 0.383 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 38 | Loss: 0.374 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 38 | Loss: 0.339 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 38 | Loss: 0.353 | Acc: 89.286% (625/700)\n",
      "Test Epoch: 38 | Loss: 0.350 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 38 | Loss: 0.360 | Acc: 89.111% (802/900)\n",
      "Test Epoch: 38 | Loss: 0.367 | Acc: 89.200% (892/1000)\n",
      "Test Epoch: 38 | Loss: 0.378 | Acc: 88.909% (978/1100)\n",
      "Test Epoch: 38 | Loss: 0.397 | Acc: 88.667% (1064/1200)\n",
      "Test Epoch: 38 | Loss: 0.392 | Acc: 88.846% (1155/1300)\n",
      "Test Epoch: 38 | Loss: 0.392 | Acc: 88.786% (1243/1400)\n",
      "Test Epoch: 38 | Loss: 0.396 | Acc: 88.533% (1328/1500)\n",
      "Test Epoch: 38 | Loss: 0.394 | Acc: 88.625% (1418/1600)\n",
      "Test Epoch: 38 | Loss: 0.398 | Acc: 88.765% (1509/1700)\n",
      "Test Epoch: 38 | Loss: 0.413 | Acc: 88.444% (1592/1800)\n",
      "Test Epoch: 38 | Loss: 0.416 | Acc: 88.263% (1677/1900)\n",
      "Test Epoch: 38 | Loss: 0.419 | Acc: 88.200% (1764/2000)\n",
      "Test Epoch: 38 | Loss: 0.434 | Acc: 88.000% (1848/2100)\n",
      "Test Epoch: 38 | Loss: 0.436 | Acc: 87.909% (1934/2200)\n",
      "Test Epoch: 38 | Loss: 0.436 | Acc: 87.870% (2021/2300)\n",
      "Test Epoch: 38 | Loss: 0.435 | Acc: 87.833% (2108/2400)\n",
      "Test Epoch: 38 | Loss: 0.446 | Acc: 87.720% (2193/2500)\n",
      "Test Epoch: 38 | Loss: 0.457 | Acc: 87.577% (2277/2600)\n",
      "Test Epoch: 38 | Loss: 0.447 | Acc: 87.852% (2372/2700)\n",
      "Test Epoch: 38 | Loss: 0.441 | Acc: 87.786% (2458/2800)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.828% (2547/2900)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.800% (2634/3000)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.581% (2715/3100)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.656% (2805/3200)\n",
      "Test Epoch: 38 | Loss: 0.446 | Acc: 87.515% (2888/3300)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.735% (2983/3400)\n",
      "Test Epoch: 38 | Loss: 0.447 | Acc: 87.657% (3068/3500)\n",
      "Test Epoch: 38 | Loss: 0.449 | Acc: 87.694% (3157/3600)\n",
      "Test Epoch: 38 | Loss: 0.452 | Acc: 87.730% (3246/3700)\n",
      "Test Epoch: 38 | Loss: 0.452 | Acc: 87.684% (3332/3800)\n",
      "Test Epoch: 38 | Loss: 0.453 | Acc: 87.615% (3417/3900)\n",
      "Test Epoch: 38 | Loss: 0.454 | Acc: 87.625% (3505/4000)\n",
      "Test Epoch: 38 | Loss: 0.456 | Acc: 87.585% (3591/4100)\n",
      "Test Epoch: 38 | Loss: 0.455 | Acc: 87.571% (3678/4200)\n",
      "Test Epoch: 38 | Loss: 0.450 | Acc: 87.605% (3767/4300)\n",
      "Test Epoch: 38 | Loss: 0.451 | Acc: 87.614% (3855/4400)\n",
      "Test Epoch: 38 | Loss: 0.449 | Acc: 87.622% (3943/4500)\n",
      "Test Epoch: 38 | Loss: 0.450 | Acc: 87.500% (4025/4600)\n",
      "Test Epoch: 38 | Loss: 0.449 | Acc: 87.511% (4113/4700)\n",
      "Test Epoch: 38 | Loss: 0.452 | Acc: 87.417% (4196/4800)\n",
      "Test Epoch: 38 | Loss: 0.449 | Acc: 87.531% (4289/4900)\n",
      "Test Epoch: 38 | Loss: 0.454 | Acc: 87.380% (4369/5000)\n",
      "Test Epoch: 38 | Loss: 0.455 | Acc: 87.373% (4456/5100)\n",
      "Test Epoch: 38 | Loss: 0.453 | Acc: 87.385% (4544/5200)\n",
      "Test Epoch: 38 | Loss: 0.451 | Acc: 87.377% (4631/5300)\n",
      "Test Epoch: 38 | Loss: 0.448 | Acc: 87.463% (4723/5400)\n",
      "Test Epoch: 38 | Loss: 0.450 | Acc: 87.418% (4808/5500)\n",
      "Test Epoch: 38 | Loss: 0.449 | Acc: 87.393% (4894/5600)\n",
      "Test Epoch: 38 | Loss: 0.447 | Acc: 87.456% (4985/5700)\n",
      "Test Epoch: 38 | Loss: 0.445 | Acc: 87.534% (5077/5800)\n",
      "Test Epoch: 38 | Loss: 0.445 | Acc: 87.475% (5161/5900)\n",
      "Test Epoch: 38 | Loss: 0.441 | Acc: 87.533% (5252/6000)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.541% (5340/6100)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.548% (5428/6200)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.571% (5517/6300)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.609% (5607/6400)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.600% (5694/6500)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.591% (5781/6600)\n",
      "Test Epoch: 38 | Loss: 0.436 | Acc: 87.627% (5871/6700)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.618% (5958/6800)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.594% (6044/6900)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.514% (6126/7000)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.535% (6215/7100)\n",
      "Test Epoch: 38 | Loss: 0.442 | Acc: 87.472% (6298/7200)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.548% (6391/7300)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.581% (6481/7400)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.573% (6568/7500)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.553% (6654/7600)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.545% (6741/7700)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.500% (6825/7800)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.519% (6914/7900)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.463% (6997/8000)\n",
      "Test Epoch: 38 | Loss: 0.438 | Acc: 87.481% (7086/8100)\n",
      "Test Epoch: 38 | Loss: 0.436 | Acc: 87.500% (7175/8200)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.458% (7259/8300)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.440% (7345/8400)\n",
      "Test Epoch: 38 | Loss: 0.440 | Acc: 87.353% (7425/8500)\n",
      "Test Epoch: 38 | Loss: 0.442 | Acc: 87.302% (7508/8600)\n",
      "Test Epoch: 38 | Loss: 0.441 | Acc: 87.322% (7597/8700)\n",
      "Test Epoch: 38 | Loss: 0.442 | Acc: 87.352% (7687/8800)\n",
      "Test Epoch: 38 | Loss: 0.441 | Acc: 87.371% (7776/8900)\n",
      "Test Epoch: 38 | Loss: 0.441 | Acc: 87.344% (7861/9000)\n",
      "Test Epoch: 38 | Loss: 0.439 | Acc: 87.374% (7951/9100)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.413% (8042/9200)\n",
      "Test Epoch: 38 | Loss: 0.436 | Acc: 87.452% (8133/9300)\n",
      "Test Epoch: 38 | Loss: 0.437 | Acc: 87.426% (8218/9400)\n",
      "Test Epoch: 38 | Loss: 0.435 | Acc: 87.442% (8307/9500)\n",
      "Test Epoch: 38 | Loss: 0.434 | Acc: 87.490% (8399/9600)\n",
      "Test Epoch: 38 | Loss: 0.433 | Acc: 87.515% (8489/9700)\n",
      "Test Epoch: 38 | Loss: 0.433 | Acc: 87.520% (8577/9800)\n",
      "Test Epoch: 38 | Loss: 0.433 | Acc: 87.505% (8663/9900)\n",
      "Test Epoch: 38 | Loss: 0.433 | Acc: 87.540% (8754/10000)\n",
      "\n",
      "Epoch: 39\n",
      "Train Epoch: 39 | Loss: 0.166 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 93.750% (240/256)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.010% (361/384)\n",
      "Train Epoch: 39 | Loss: 0.178 | Acc: 93.945% (481/512)\n",
      "Train Epoch: 39 | Loss: 0.186 | Acc: 93.594% (599/640)\n",
      "Train Epoch: 39 | Loss: 0.189 | Acc: 93.490% (718/768)\n",
      "Train Epoch: 39 | Loss: 0.185 | Acc: 93.638% (839/896)\n",
      "Train Epoch: 39 | Loss: 0.173 | Acc: 94.141% (964/1024)\n",
      "Train Epoch: 39 | Loss: 0.175 | Acc: 94.184% (1085/1152)\n",
      "Train Epoch: 39 | Loss: 0.168 | Acc: 94.453% (1209/1280)\n",
      "Train Epoch: 39 | Loss: 0.170 | Acc: 94.247% (1327/1408)\n",
      "Train Epoch: 39 | Loss: 0.168 | Acc: 94.271% (1448/1536)\n",
      "Train Epoch: 39 | Loss: 0.167 | Acc: 94.351% (1570/1664)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.420% (1692/1792)\n",
      "Train Epoch: 39 | Loss: 0.169 | Acc: 94.271% (1810/1920)\n",
      "Train Epoch: 39 | Loss: 0.171 | Acc: 94.141% (1928/2048)\n",
      "Train Epoch: 39 | Loss: 0.171 | Acc: 94.118% (2048/2176)\n",
      "Train Epoch: 39 | Loss: 0.172 | Acc: 94.054% (2167/2304)\n",
      "Train Epoch: 39 | Loss: 0.170 | Acc: 94.120% (2289/2432)\n",
      "Train Epoch: 39 | Loss: 0.168 | Acc: 94.141% (2410/2560)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.271% (2534/2688)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.354% (2657/2816)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.293% (2776/2944)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.336% (2898/3072)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.469% (3023/3200)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.411% (3142/3328)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.473% (3265/3456)\n",
      "Train Epoch: 39 | Loss: 0.153 | Acc: 94.531% (3388/3584)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.370% (3503/3712)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.349% (3623/3840)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.380% (3745/3968)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.360% (3865/4096)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.484% (3991/4224)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.531% (4114/4352)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.531% (4235/4480)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.510% (4355/4608)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.573% (4479/4736)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.593% (4601/4864)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.631% (4724/4992)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.492% (4838/5120)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.531% (4961/5248)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.550% (5083/5376)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.640% (5209/5504)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.602% (5328/5632)\n",
      "Train Epoch: 39 | Loss: 0.153 | Acc: 94.618% (5450/5760)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.616% (5571/5888)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.548% (5688/6016)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.499% (5806/6144)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.515% (5928/6272)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.453% (6045/6400)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.424% (6164/6528)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.351% (6280/6656)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.399% (6404/6784)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.372% (6523/6912)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.332% (6641/7040)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.294% (6759/7168)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.257% (6877/7296)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.208% (6994/7424)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.147% (7110/7552)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.141% (7230/7680)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.070% (7345/7808)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.065% (7465/7936)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.134% (7591/8064)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.153% (7713/8192)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.135% (7832/8320)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.176% (7956/8448)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.216% (8080/8576)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.256% (8204/8704)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.293% (8328/8832)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.286% (8448/8960)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.311% (8571/9088)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.336% (8694/9216)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.317% (8813/9344)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.341% (8936/9472)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.365% (9059/9600)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.387% (9182/9728)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.409% (9305/9856)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.431% (9428/9984)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.442% (9550/10112)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.443% (9671/10240)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.425% (9790/10368)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.417% (9910/10496)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.428% (10032/10624)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.457% (10156/10752)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.467% (10278/10880)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.477% (10400/11008)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.486% (10522/11136)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.487% (10643/11264)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.496% (10765/11392)\n",
      "Train Epoch: 39 | Loss: 0.154 | Acc: 94.488% (10885/11520)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.480% (11005/11648)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.480% (11126/11776)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.489% (11248/11904)\n",
      "Train Epoch: 39 | Loss: 0.155 | Acc: 94.481% (11368/12032)\n",
      "Train Epoch: 39 | Loss: 0.156 | Acc: 94.457% (11486/12160)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.434% (11604/12288)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.410% (11722/12416)\n",
      "Train Epoch: 39 | Loss: 0.157 | Acc: 94.388% (11840/12544)\n",
      "Train Epoch: 39 | Loss: 0.158 | Acc: 94.373% (11959/12672)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.352% (12077/12800)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.322% (12194/12928)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.317% (12314/13056)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.326% (12436/13184)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.298% (12553/13312)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.293% (12673/13440)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.318% (12797/13568)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.320% (12918/13696)\n",
      "Train Epoch: 39 | Loss: 0.159 | Acc: 94.314% (13038/13824)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.295% (13156/13952)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.290% (13276/14080)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.278% (13395/14208)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.301% (13519/14336)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.275% (13636/14464)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.264% (13755/14592)\n",
      "Train Epoch: 39 | Loss: 0.160 | Acc: 94.260% (13875/14720)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.275% (13998/14848)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.224% (14111/14976)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.227% (14232/15104)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.242% (14355/15232)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.225% (14473/15360)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.234% (14595/15488)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.224% (14714/15616)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.239% (14837/15744)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.260% (14961/15872)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.256% (15081/16000)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.271% (15204/16128)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.285% (15327/16256)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.281% (15447/16384)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.283% (15568/16512)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.297% (15691/16640)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.293% (15811/16768)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.295% (15932/16896)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.302% (16054/17024)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.316% (16177/17152)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.311% (16297/17280)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.313% (16418/17408)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.286% (16534/17536)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.293% (16656/17664)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.295% (16777/17792)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.302% (16899/17920)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.293% (17018/18048)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.289% (17138/18176)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.269% (17255/18304)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.265% (17375/18432)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.273% (17497/18560)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.269% (17617/18688)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.255% (17735/18816)\n",
      "Train Epoch: 39 | Loss: 0.161 | Acc: 94.262% (17857/18944)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.248% (17975/19072)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.245% (18095/19200)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.236% (18214/19328)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.249% (18337/19456)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.250% (18458/19584)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.247% (18578/19712)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.249% (18699/19840)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.246% (18819/19968)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.238% (18938/20096)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.259% (19063/20224)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.241% (19180/20352)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.219% (19296/20480)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.216% (19416/20608)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.208% (19535/20736)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.229% (19660/20864)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.245% (19784/20992)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.252% (19906/21120)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.244% (20025/21248)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.246% (20146/21376)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.224% (20262/21504)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.222% (20382/21632)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.219% (20502/21760)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.216% (20622/21888)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.182% (20735/22016)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.174% (20854/22144)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.177% (20975/22272)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.183% (21097/22400)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.185% (21218/22528)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.183% (21338/22656)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.189% (21460/22784)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.191% (21581/22912)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.201% (21704/23040)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.216% (21828/23168)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.205% (21946/23296)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.224% (22071/23424)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.209% (22188/23552)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.210% (22309/23680)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.195% (22426/23808)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.189% (22545/23936)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.190% (22666/24064)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.196% (22788/24192)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.215% (22913/24320)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.224% (23036/24448)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.230% (23158/24576)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.224% (23277/24704)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.221% (23397/24832)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.223% (23518/24960)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.224% (23639/25088)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.234% (23762/25216)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.212% (23877/25344)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.205% (23996/25472)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.215% (24119/25600)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.197% (24235/25728)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.214% (24360/25856)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.212% (24480/25984)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.221% (24603/26112)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.215% (24722/26240)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.205% (24840/26368)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.207% (24961/26496)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.212% (25083/26624)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.225% (25207/26752)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.215% (25325/26880)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.217% (25446/27008)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.233% (25571/27136)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.223% (25689/27264)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.225% (25810/27392)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.219% (25929/27520)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.227% (26052/27648)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.222% (26171/27776)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.212% (26289/27904)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.228% (26414/28032)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.233% (26536/28160)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (26651/28288)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.229% (26776/28416)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.237% (26899/28544)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.224% (27016/28672)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.205% (27131/28800)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.199% (27250/28928)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.197% (27370/29056)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (27495/29184)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.214% (27616/29312)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.226% (27740/29440)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.230% (27862/29568)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.232% (27983/29696)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.223% (28101/29824)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.227% (28223/29952)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.225% (28343/30080)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.227% (28464/30208)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.241% (28589/30336)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.252% (28713/30464)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.253% (28834/30592)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.251% (28954/30720)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.262% (29078/30848)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.273% (29202/30976)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.271% (29322/31104)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.259% (29439/31232)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.276% (29565/31360)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.290% (29690/31488)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.297% (29813/31616)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.311% (29938/31744)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.315% (30060/31872)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.303% (30177/32000)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.307% (30299/32128)\n",
      "Train Epoch: 39 | Loss: 0.162 | Acc: 94.289% (30414/32256)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.272% (30529/32384)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.267% (30648/32512)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.265% (30768/32640)\n",
      "Train Epoch: 39 | Loss: 0.163 | Acc: 94.260% (30887/32768)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.246% (31003/32896)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.210% (31112/33024)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.208% (31232/33152)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.225% (31358/33280)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.220% (31477/33408)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.215% (31596/33536)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.207% (31714/33664)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.203% (31833/33792)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.216% (31958/33920)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.217% (32079/34048)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.224% (32202/34176)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.219% (32321/34304)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.212% (32439/34432)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.216% (32561/34560)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.214% (32681/34688)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.215% (32802/34816)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.225% (32926/34944)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.226% (33047/35072)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (33163/35200)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.203% (33280/35328)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.201% (33400/35456)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.200% (33520/35584)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.192% (33638/35712)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.196% (33760/35840)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.203% (33883/35968)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.210% (34006/36096)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.205% (34125/36224)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.212% (34248/36352)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.197% (34363/36480)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.195% (34483/36608)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.199% (34605/36736)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.195% (34724/36864)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.199% (34846/36992)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.200% (34967/37120)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.198% (35087/37248)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.189% (35204/37376)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.198% (35328/37504)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.207% (35452/37632)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (35575/37760)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.207% (35693/37888)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.218% (35818/38016)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.227% (35942/38144)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.231% (36064/38272)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.232% (36185/38400)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.225% (36303/38528)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.216% (36420/38656)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.219% (36542/38784)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.220% (36663/38912)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.224% (36785/39040)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.227% (36907/39168)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.223% (37026/39296)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.224% (37147/39424)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.230% (37270/39552)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.244% (37396/39680)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.247% (37518/39808)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.248% (37639/39936)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.232% (37753/40064)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.228% (37872/40192)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.231% (37994/40320)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.232% (38115/40448)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.233% (38236/40576)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.229% (38355/40704)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.223% (38473/40832)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.226% (38595/40960)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.232% (38718/41088)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.235% (38840/41216)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.231% (38959/41344)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.232% (39080/41472)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.226% (39198/41600)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.222% (39317/41728)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.218% (39436/41856)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.210% (39553/41984)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.208% (39673/42112)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.207% (39793/42240)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.206% (39913/42368)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.209% (40035/42496)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.210% (40156/42624)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (40278/42752)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.209% (40397/42880)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.208% (40517/43008)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.204% (40636/43136)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.210% (40759/43264)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.216% (40882/43392)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.221% (41005/43520)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.233% (41131/43648)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.232% (41251/43776)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.235% (41373/43904)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.238% (41495/44032)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.244% (41618/44160)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.247% (41740/44288)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.245% (41860/44416)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.239% (41978/44544)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.231% (42095/44672)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.225% (42213/44800)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.224% (42333/44928)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.209% (42447/45056)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.213% (42569/45184)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.218% (42692/45312)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.212% (42810/45440)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.206% (42928/45568)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.205% (43048/45696)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.206% (43169/45824)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.196% (43285/45952)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.206% (43410/46080)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.194% (43525/46208)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.197% (43647/46336)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.198% (43768/46464)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.192% (43886/46592)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.193% (44007/46720)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.198% (44130/46848)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.197% (44250/46976)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.198% (44371/47104)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.192% (44489/47232)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.198% (44612/47360)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.199% (44733/47488)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.204% (44856/47616)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.209% (44979/47744)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.203% (45097/47872)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.202% (45217/48000)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.197% (45335/48128)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.187% (45451/48256)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.182% (45569/48384)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.185% (45691/48512)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.186% (45812/48640)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.181% (45930/48768)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.188% (46054/48896)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.193% (46177/49024)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.187% (46295/49152)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.184% (46414/49280)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.185% (46535/49408)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.184% (46655/49536)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.185% (46776/49664)\n",
      "Train Epoch: 39 | Loss: 0.165 | Acc: 94.190% (46899/49792)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.193% (47021/49920)\n",
      "Train Epoch: 39 | Loss: 0.164 | Acc: 94.192% (47096/50000)\n",
      "Test Epoch: 39 | Loss: 0.451 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 39 | Loss: 0.361 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 39 | Loss: 0.352 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 39 | Loss: 0.345 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 39 | Loss: 0.332 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 39 | Loss: 0.304 | Acc: 89.667% (538/600)\n",
      "Test Epoch: 39 | Loss: 0.336 | Acc: 89.000% (623/700)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 88.375% (707/800)\n",
      "Test Epoch: 39 | Loss: 0.374 | Acc: 88.333% (795/900)\n",
      "Test Epoch: 39 | Loss: 0.386 | Acc: 88.100% (881/1000)\n",
      "Test Epoch: 39 | Loss: 0.401 | Acc: 87.909% (967/1100)\n",
      "Test Epoch: 39 | Loss: 0.414 | Acc: 87.500% (1050/1200)\n",
      "Test Epoch: 39 | Loss: 0.405 | Acc: 87.615% (1139/1300)\n",
      "Test Epoch: 39 | Loss: 0.401 | Acc: 87.571% (1226/1400)\n",
      "Test Epoch: 39 | Loss: 0.395 | Acc: 87.733% (1316/1500)\n",
      "Test Epoch: 39 | Loss: 0.397 | Acc: 87.750% (1404/1600)\n",
      "Test Epoch: 39 | Loss: 0.393 | Acc: 88.000% (1496/1700)\n",
      "Test Epoch: 39 | Loss: 0.387 | Acc: 88.111% (1586/1800)\n",
      "Test Epoch: 39 | Loss: 0.384 | Acc: 88.105% (1674/1900)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 87.950% (1759/2000)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 87.952% (1847/2100)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 87.773% (1931/2200)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 87.913% (2022/2300)\n",
      "Test Epoch: 39 | Loss: 0.395 | Acc: 88.000% (2112/2400)\n",
      "Test Epoch: 39 | Loss: 0.413 | Acc: 87.840% (2196/2500)\n",
      "Test Epoch: 39 | Loss: 0.421 | Acc: 87.692% (2280/2600)\n",
      "Test Epoch: 39 | Loss: 0.418 | Acc: 87.778% (2370/2700)\n",
      "Test Epoch: 39 | Loss: 0.414 | Acc: 87.857% (2460/2800)\n",
      "Test Epoch: 39 | Loss: 0.411 | Acc: 88.034% (2553/2900)\n",
      "Test Epoch: 39 | Loss: 0.417 | Acc: 88.000% (2640/3000)\n",
      "Test Epoch: 39 | Loss: 0.415 | Acc: 88.065% (2730/3100)\n",
      "Test Epoch: 39 | Loss: 0.414 | Acc: 88.094% (2819/3200)\n",
      "Test Epoch: 39 | Loss: 0.413 | Acc: 88.030% (2905/3300)\n",
      "Test Epoch: 39 | Loss: 0.411 | Acc: 88.118% (2996/3400)\n",
      "Test Epoch: 39 | Loss: 0.414 | Acc: 88.086% (3083/3500)\n",
      "Test Epoch: 39 | Loss: 0.411 | Acc: 88.167% (3174/3600)\n",
      "Test Epoch: 39 | Loss: 0.415 | Acc: 88.216% (3264/3700)\n",
      "Test Epoch: 39 | Loss: 0.416 | Acc: 88.158% (3350/3800)\n",
      "Test Epoch: 39 | Loss: 0.415 | Acc: 88.154% (3438/3900)\n",
      "Test Epoch: 39 | Loss: 0.412 | Acc: 88.175% (3527/4000)\n",
      "Test Epoch: 39 | Loss: 0.415 | Acc: 88.122% (3613/4100)\n",
      "Test Epoch: 39 | Loss: 0.415 | Acc: 88.119% (3701/4200)\n",
      "Test Epoch: 39 | Loss: 0.408 | Acc: 88.279% (3796/4300)\n",
      "Test Epoch: 39 | Loss: 0.410 | Acc: 88.341% (3887/4400)\n",
      "Test Epoch: 39 | Loss: 0.408 | Acc: 88.400% (3978/4500)\n",
      "Test Epoch: 39 | Loss: 0.406 | Acc: 88.435% (4068/4600)\n",
      "Test Epoch: 39 | Loss: 0.405 | Acc: 88.426% (4156/4700)\n",
      "Test Epoch: 39 | Loss: 0.408 | Acc: 88.375% (4242/4800)\n",
      "Test Epoch: 39 | Loss: 0.407 | Acc: 88.490% (4336/4900)\n",
      "Test Epoch: 39 | Loss: 0.406 | Acc: 88.460% (4423/5000)\n",
      "Test Epoch: 39 | Loss: 0.403 | Acc: 88.529% (4515/5100)\n",
      "Test Epoch: 39 | Loss: 0.403 | Acc: 88.462% (4600/5200)\n",
      "Test Epoch: 39 | Loss: 0.402 | Acc: 88.453% (4688/5300)\n",
      "Test Epoch: 39 | Loss: 0.401 | Acc: 88.500% (4779/5400)\n",
      "Test Epoch: 39 | Loss: 0.400 | Acc: 88.509% (4868/5500)\n",
      "Test Epoch: 39 | Loss: 0.399 | Acc: 88.500% (4956/5600)\n",
      "Test Epoch: 39 | Loss: 0.398 | Acc: 88.509% (5045/5700)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 88.552% (5136/5800)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 88.525% (5223/5900)\n",
      "Test Epoch: 39 | Loss: 0.394 | Acc: 88.550% (5313/6000)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.590% (5404/6100)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.613% (5494/6200)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.635% (5584/6300)\n",
      "Test Epoch: 39 | Loss: 0.388 | Acc: 88.703% (5677/6400)\n",
      "Test Epoch: 39 | Loss: 0.386 | Acc: 88.754% (5769/6500)\n",
      "Test Epoch: 39 | Loss: 0.387 | Acc: 88.697% (5854/6600)\n",
      "Test Epoch: 39 | Loss: 0.386 | Acc: 88.746% (5946/6700)\n",
      "Test Epoch: 39 | Loss: 0.388 | Acc: 88.706% (6032/6800)\n",
      "Test Epoch: 39 | Loss: 0.387 | Acc: 88.681% (6119/6900)\n",
      "Test Epoch: 39 | Loss: 0.387 | Acc: 88.686% (6208/7000)\n",
      "Test Epoch: 39 | Loss: 0.390 | Acc: 88.704% (6298/7100)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.694% (6386/7200)\n",
      "Test Epoch: 39 | Loss: 0.390 | Acc: 88.767% (6480/7300)\n",
      "Test Epoch: 39 | Loss: 0.389 | Acc: 88.743% (6567/7400)\n",
      "Test Epoch: 39 | Loss: 0.390 | Acc: 88.747% (6656/7500)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.750% (6745/7600)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.753% (6834/7700)\n",
      "Test Epoch: 39 | Loss: 0.393 | Acc: 88.756% (6923/7800)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.759% (7012/7900)\n",
      "Test Epoch: 39 | Loss: 0.394 | Acc: 88.713% (7097/8000)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.790% (7192/8100)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.793% (7281/8200)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.783% (7369/8300)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.750% (7455/8400)\n",
      "Test Epoch: 39 | Loss: 0.393 | Acc: 88.694% (7539/8500)\n",
      "Test Epoch: 39 | Loss: 0.396 | Acc: 88.640% (7623/8600)\n",
      "Test Epoch: 39 | Loss: 0.393 | Acc: 88.690% (7716/8700)\n",
      "Test Epoch: 39 | Loss: 0.395 | Acc: 88.670% (7803/8800)\n",
      "Test Epoch: 39 | Loss: 0.395 | Acc: 88.708% (7895/8900)\n",
      "Test Epoch: 39 | Loss: 0.397 | Acc: 88.600% (7974/9000)\n",
      "Test Epoch: 39 | Loss: 0.397 | Acc: 88.604% (8063/9100)\n",
      "Test Epoch: 39 | Loss: 0.395 | Acc: 88.652% (8156/9200)\n",
      "Test Epoch: 39 | Loss: 0.394 | Acc: 88.677% (8247/9300)\n",
      "Test Epoch: 39 | Loss: 0.393 | Acc: 88.691% (8337/9400)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.705% (8427/9500)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.760% (8521/9600)\n",
      "Test Epoch: 39 | Loss: 0.390 | Acc: 88.794% (8613/9700)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.786% (8701/9800)\n",
      "Test Epoch: 39 | Loss: 0.392 | Acc: 88.798% (8791/9900)\n",
      "Test Epoch: 39 | Loss: 0.391 | Acc: 88.840% (8884/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 40\n",
      "Train Epoch: 40 | Loss: 0.258 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 40 | Loss: 0.182 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 40 | Loss: 0.164 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 40 | Loss: 0.147 | Acc: 95.898% (491/512)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 96.094% (615/640)\n",
      "Train Epoch: 40 | Loss: 0.136 | Acc: 96.224% (739/768)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.982% (860/896)\n",
      "Train Epoch: 40 | Loss: 0.138 | Acc: 95.898% (982/1024)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.660% (1102/1152)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.781% (1226/1280)\n",
      "Train Epoch: 40 | Loss: 0.133 | Acc: 95.952% (1351/1408)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.898% (1473/1536)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.733% (1593/1664)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.536% (1712/1792)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.625% (1836/1920)\n",
      "Train Epoch: 40 | Loss: 0.143 | Acc: 95.508% (1956/2048)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 95.404% (2076/2176)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 95.356% (2197/2304)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 95.312% (2318/2432)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 95.156% (2436/2560)\n",
      "Train Epoch: 40 | Loss: 0.154 | Acc: 95.164% (2558/2688)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 95.277% (2683/2816)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.414% (2809/2944)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.540% (2935/3072)\n",
      "Train Epoch: 40 | Loss: 0.144 | Acc: 95.531% (3057/3200)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.403% (3175/3328)\n",
      "Train Epoch: 40 | Loss: 0.147 | Acc: 95.370% (3296/3456)\n",
      "Train Epoch: 40 | Loss: 0.147 | Acc: 95.368% (3418/3584)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.420% (3542/3712)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.469% (3666/3840)\n",
      "Train Epoch: 40 | Loss: 0.143 | Acc: 95.590% (3793/3968)\n",
      "Train Epoch: 40 | Loss: 0.144 | Acc: 95.581% (3915/4096)\n",
      "Train Epoch: 40 | Loss: 0.142 | Acc: 95.573% (4037/4224)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.634% (4162/4352)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.647% (4285/4480)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.595% (4405/4608)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.524% (4524/4736)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.477% (4644/4864)\n",
      "Train Epoch: 40 | Loss: 0.142 | Acc: 95.413% (4763/4992)\n",
      "Train Epoch: 40 | Loss: 0.142 | Acc: 95.410% (4885/5120)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.465% (5010/5248)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.499% (5134/5376)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.549% (5259/5504)\n",
      "Train Epoch: 40 | Loss: 0.138 | Acc: 95.597% (5384/5632)\n",
      "Train Epoch: 40 | Loss: 0.137 | Acc: 95.608% (5507/5760)\n",
      "Train Epoch: 40 | Loss: 0.138 | Acc: 95.601% (5629/5888)\n",
      "Train Epoch: 40 | Loss: 0.137 | Acc: 95.595% (5751/6016)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.557% (5871/6144)\n",
      "Train Epoch: 40 | Loss: 0.138 | Acc: 95.568% (5994/6272)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.484% (6111/6400)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.435% (6230/6528)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.448% (6353/6656)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.460% (6476/6784)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.457% (6598/6912)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.455% (6720/7040)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.466% (6843/7168)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.463% (6965/7296)\n",
      "Train Epoch: 40 | Loss: 0.138 | Acc: 95.461% (7087/7424)\n",
      "Train Epoch: 40 | Loss: 0.139 | Acc: 95.445% (7208/7552)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.456% (7331/7680)\n",
      "Train Epoch: 40 | Loss: 0.140 | Acc: 95.441% (7452/7808)\n",
      "Train Epoch: 40 | Loss: 0.141 | Acc: 95.388% (7570/7936)\n",
      "Train Epoch: 40 | Loss: 0.142 | Acc: 95.362% (7690/8064)\n",
      "Train Epoch: 40 | Loss: 0.144 | Acc: 95.312% (7808/8192)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.240% (7924/8320)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.218% (8044/8448)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.231% (8167/8576)\n",
      "Train Epoch: 40 | Loss: 0.147 | Acc: 95.209% (8287/8704)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.222% (8410/8832)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.223% (8532/8960)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.257% (8657/9088)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.215% (8775/9216)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.259% (8901/9344)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.260% (9023/9472)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.250% (9144/9600)\n",
      "Train Epoch: 40 | Loss: 0.145 | Acc: 95.302% (9271/9728)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.292% (9392/9856)\n",
      "Train Epoch: 40 | Loss: 0.146 | Acc: 95.292% (9514/9984)\n",
      "Train Epoch: 40 | Loss: 0.147 | Acc: 95.243% (9631/10112)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.225% (9751/10240)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.206% (9871/10368)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.198% (9992/10496)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 95.181% (10112/10624)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.182% (10234/10752)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.202% (10358/10880)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.203% (10480/11008)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.205% (10602/11136)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.206% (10724/11264)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.190% (10844/11392)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.200% (10967/11520)\n",
      "Train Epoch: 40 | Loss: 0.148 | Acc: 95.175% (11086/11648)\n",
      "Train Epoch: 40 | Loss: 0.149 | Acc: 95.160% (11206/11776)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 95.119% (11323/11904)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 95.088% (11441/12032)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 95.049% (11558/12160)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 95.068% (11682/12288)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 95.023% (11798/12416)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 95.002% (11917/12544)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.997% (12038/12672)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.984% (12158/12800)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.980% (12279/12928)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.975% (12400/13056)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.986% (12523/13184)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.982% (12644/13312)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.985% (12766/13440)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 95.003% (12890/13568)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 95.013% (13013/13696)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.987% (13131/13824)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.983% (13252/13952)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.957% (13370/14080)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.932% (13488/14208)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.943% (13611/14336)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.925% (13730/14464)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.936% (13853/14592)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.959% (13978/14720)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.929% (14095/14848)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.939% (14218/14976)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.942% (14340/15104)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.919% (14458/15232)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.941% (14583/15360)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.964% (14708/15488)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.973% (14831/15616)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.976% (14953/15744)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.947% (15070/15872)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.931% (15189/16000)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.928% (15310/16128)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.943% (15434/16256)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.904% (15549/16384)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.901% (15670/16512)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.898% (15791/16640)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.907% (15914/16768)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.916% (16037/16896)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.907% (16157/17024)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.910% (16279/17152)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.902% (16399/17280)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.893% (16519/17408)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.902% (16642/17536)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.916% (16766/17664)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 94.930% (16890/17792)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 94.927% (17011/17920)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.925% (17132/18048)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 94.938% (17256/18176)\n",
      "Train Epoch: 40 | Loss: 0.150 | Acc: 94.946% (17379/18304)\n",
      "Train Epoch: 40 | Loss: 0.151 | Acc: 94.911% (17494/18432)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.887% (17611/18560)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.895% (17734/18688)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.893% (17855/18816)\n",
      "Train Epoch: 40 | Loss: 0.152 | Acc: 94.874% (17973/18944)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.841% (18088/19072)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.833% (18208/19200)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.826% (18328/19328)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.845% (18453/19456)\n",
      "Train Epoch: 40 | Loss: 0.153 | Acc: 94.843% (18574/19584)\n",
      "Train Epoch: 40 | Loss: 0.154 | Acc: 94.805% (18688/19712)\n",
      "Train Epoch: 40 | Loss: 0.154 | Acc: 94.803% (18809/19840)\n",
      "Train Epoch: 40 | Loss: 0.155 | Acc: 94.767% (18923/19968)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.760% (19043/20096)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.754% (19163/20224)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.752% (19284/20352)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.727% (19400/20480)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.716% (19519/20608)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.724% (19642/20736)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.723% (19763/20864)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.717% (19883/20992)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.730% (20007/21120)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.734% (20129/21248)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.714% (20246/21376)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.727% (20370/21504)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.721% (20490/21632)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.720% (20611/21760)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.714% (20731/21888)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.713% (20852/22016)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.703% (20971/22144)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.684% (21088/22272)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.688% (21210/22400)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.691% (21332/22528)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.686% (21452/22656)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.680% (21572/22784)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.697% (21697/22912)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.701% (21819/23040)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.700% (21940/23168)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.686% (22058/23296)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.685% (22179/23424)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.676% (22298/23552)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.688% (22422/23680)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.674% (22540/23808)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.665% (22659/23936)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.656% (22778/24064)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.651% (22898/24192)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.646% (23018/24320)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.658% (23142/24448)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.645% (23260/24576)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.645% (23381/24704)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.664% (23507/24832)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (23628/24960)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.671% (23751/25088)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.674% (23873/25216)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.677% (23995/25344)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.677% (24116/25472)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.680% (24238/25600)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.660% (24354/25728)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.655% (24474/25856)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.643% (24592/25984)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.631% (24710/26112)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.638% (24833/26240)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.622% (24950/26368)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.622% (25071/26496)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.618% (25191/26624)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.625% (25314/26752)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.613% (25432/26880)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.624% (25556/27008)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.609% (25673/27136)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.612% (25795/27264)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.608% (25915/27392)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.611% (26037/27520)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.607% (26157/27648)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.603% (26277/27776)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.599% (26397/27904)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.592% (26516/28032)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.595% (26638/28160)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.598% (26760/28288)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.612% (26885/28416)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.615% (27007/28544)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.632% (27133/28672)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.639% (27256/28800)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.631% (27375/28928)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.631% (27496/29056)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.600% (27608/29184)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.606% (27731/29312)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.609% (27853/29440)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.596% (27970/29568)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.602% (28093/29696)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.602% (28214/29824)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.608% (28337/29952)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.598% (28455/30080)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.594% (28575/30208)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.604% (28699/30336)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.603% (28820/30464)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.600% (28940/30592)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.619% (29067/30720)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.629% (29191/30848)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.628% (29312/30976)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.624% (29432/31104)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.624% (29553/31232)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.627% (29675/31360)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.617% (29793/31488)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.632% (29919/31616)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.645% (30044/31744)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.644% (30165/31872)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.641% (30285/32000)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.634% (30404/32128)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.649% (30530/32256)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.655% (30653/32384)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.648% (30772/32512)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.660% (30897/32640)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.675% (31023/32768)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.671% (31143/32896)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.677% (31266/33024)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.667% (31384/33152)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.669% (31506/33280)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (31625/33408)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.668% (31748/33536)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.659% (31866/33664)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.658% (31987/33792)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.652% (32106/33920)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (32231/34048)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.666% (32353/34176)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.662% (32473/34304)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.665% (32595/34432)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.664% (32716/34560)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.675% (32841/34688)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.678% (32963/34816)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.680% (33085/34944)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.688% (33209/35072)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.690% (33331/35200)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.695% (33454/35328)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.698% (33576/35456)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.697% (33697/35584)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.699% (33819/35712)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.701% (33941/35840)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.706% (34064/35968)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.692% (34180/36096)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.689% (34300/36224)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.683% (34419/36352)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.690% (34543/36480)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.687% (34663/36608)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.695% (34787/36736)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.689% (34906/36864)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.691% (35028/36992)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.690% (35149/37120)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.692% (35271/37248)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.692% (35392/37376)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.686% (35511/37504)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.685% (35632/37632)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.674% (35749/37760)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (35866/37888)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.679% (35993/38016)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.686% (36117/38144)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.680% (36236/38272)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.685% (36359/38400)\n",
      "Train Epoch: 40 | Loss: 0.156 | Acc: 94.684% (36480/38528)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.679% (36599/38656)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.668% (36716/38784)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.665% (36836/38912)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.659% (36955/39040)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.664% (37078/39168)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.666% (37200/39296)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.671% (37323/39424)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (37441/39552)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.655% (37559/39680)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.644% (37676/39808)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.646% (37798/39936)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.649% (37920/40064)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.656% (38044/40192)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.663% (38168/40320)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.660% (38288/40448)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.654% (38407/40576)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.654% (38528/40704)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.654% (38649/40832)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.646% (38767/40960)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.648% (38889/41088)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.638% (39006/41216)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.628% (39123/41344)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.637% (39248/41472)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.637% (39369/41600)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.644% (39493/41728)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.634% (39610/41856)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.629% (39729/41984)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.605% (39840/42112)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.609% (39963/42240)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.604% (40082/42368)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.609% (40205/42496)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.611% (40327/42624)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.608% (40447/42752)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.601% (40565/42880)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.589% (40681/43008)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.589% (40802/43136)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.591% (40924/43264)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.589% (41044/43392)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.586% (41164/43520)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.584% (41284/43648)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.579% (41403/43776)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.586% (41527/43904)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.583% (41647/44032)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.595% (41773/44160)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.604% (41898/44288)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.610% (42022/44416)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.612% (42144/44544)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.612% (42265/44672)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.616% (42388/44800)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.618% (42510/44928)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.624% (42634/45056)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.618% (42752/45184)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.620% (42874/45312)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.610% (42991/45440)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.621% (43117/45568)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.621% (43238/45696)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.625% (43361/45824)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.627% (43483/45952)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.633% (43607/46080)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.635% (43729/46208)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.628% (43847/46336)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.632% (43970/46464)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.641% (44095/46592)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.640% (44216/46720)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.636% (44335/46848)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.631% (44454/46976)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.635% (44577/47104)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.631% (44696/47232)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.626% (44815/47360)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.620% (44933/47488)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.613% (45051/47616)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.617% (45174/47744)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.621% (45297/47872)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.629% (45422/48000)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.633% (45545/48128)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.635% (45667/48256)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.626% (45784/48384)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.632% (45908/48512)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.634% (46030/48640)\n",
      "Train Epoch: 40 | Loss: 0.157 | Acc: 94.628% (46148/48768)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.623% (46267/48896)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.625% (46389/49024)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.625% (46510/49152)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.619% (46628/49280)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.618% (46749/49408)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.628% (46875/49536)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.620% (46992/49664)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.626% (47116/49792)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.627% (47238/49920)\n",
      "Train Epoch: 40 | Loss: 0.158 | Acc: 94.634% (47317/50000)\n",
      "Test Epoch: 40 | Loss: 0.227 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 40 | Loss: 0.277 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 40 | Loss: 0.248 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 40 | Loss: 0.286 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 40 | Loss: 0.261 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 40 | Loss: 0.238 | Acc: 91.000% (546/600)\n",
      "Test Epoch: 40 | Loss: 0.257 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 40 | Loss: 0.288 | Acc: 90.125% (721/800)\n",
      "Test Epoch: 40 | Loss: 0.291 | Acc: 90.111% (811/900)\n",
      "Test Epoch: 40 | Loss: 0.297 | Acc: 89.900% (899/1000)\n",
      "Test Epoch: 40 | Loss: 0.314 | Acc: 89.545% (985/1100)\n",
      "Test Epoch: 40 | Loss: 0.330 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 40 | Loss: 0.326 | Acc: 89.385% (1162/1300)\n",
      "Test Epoch: 40 | Loss: 0.322 | Acc: 89.357% (1251/1400)\n",
      "Test Epoch: 40 | Loss: 0.325 | Acc: 89.067% (1336/1500)\n",
      "Test Epoch: 40 | Loss: 0.323 | Acc: 88.938% (1423/1600)\n",
      "Test Epoch: 40 | Loss: 0.328 | Acc: 88.941% (1512/1700)\n",
      "Test Epoch: 40 | Loss: 0.333 | Acc: 88.889% (1600/1800)\n",
      "Test Epoch: 40 | Loss: 0.337 | Acc: 88.842% (1688/1900)\n",
      "Test Epoch: 40 | Loss: 0.347 | Acc: 88.750% (1775/2000)\n",
      "Test Epoch: 40 | Loss: 0.349 | Acc: 88.714% (1863/2100)\n",
      "Test Epoch: 40 | Loss: 0.345 | Acc: 88.727% (1952/2200)\n",
      "Test Epoch: 40 | Loss: 0.342 | Acc: 88.913% (2045/2300)\n",
      "Test Epoch: 40 | Loss: 0.343 | Acc: 88.958% (2135/2400)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.880% (2222/2500)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.885% (2311/2600)\n",
      "Test Epoch: 40 | Loss: 0.357 | Acc: 89.000% (2403/2700)\n",
      "Test Epoch: 40 | Loss: 0.356 | Acc: 88.964% (2491/2800)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 88.931% (2579/2900)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 89.033% (2671/3000)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 88.839% (2754/3100)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.812% (2842/3200)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 88.667% (2926/3300)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 88.735% (3017/3400)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.771% (3107/3500)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.778% (3196/3600)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.865% (3288/3700)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.868% (3377/3800)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.872% (3466/3900)\n",
      "Test Epoch: 40 | Loss: 0.367 | Acc: 88.850% (3554/4000)\n",
      "Test Epoch: 40 | Loss: 0.372 | Acc: 88.756% (3639/4100)\n",
      "Test Epoch: 40 | Loss: 0.373 | Acc: 88.714% (3726/4200)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.907% (3823/4300)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.932% (3913/4400)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 89.022% (4006/4500)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 89.065% (4097/4600)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 89.085% (4187/4700)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 89.042% (4274/4800)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 89.020% (4362/4900)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 88.880% (4444/5000)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.922% (4535/5100)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.827% (4619/5200)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.792% (4706/5300)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.852% (4798/5400)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.873% (4888/5500)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 88.857% (4976/5600)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 88.860% (5065/5700)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.966% (5160/5800)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 88.966% (5249/5900)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.950% (5337/6000)\n",
      "Test Epoch: 40 | Loss: 0.357 | Acc: 88.951% (5426/6100)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.919% (5513/6200)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.921% (5602/6300)\n",
      "Test Epoch: 40 | Loss: 0.356 | Acc: 88.938% (5692/6400)\n",
      "Test Epoch: 40 | Loss: 0.356 | Acc: 88.877% (5777/6500)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.833% (5863/6600)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.910% (5957/6700)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.882% (6044/6800)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.870% (6132/6900)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 88.814% (6217/7000)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 88.775% (6303/7100)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 88.778% (6392/7200)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.781% (6481/7300)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.770% (6569/7400)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.747% (6656/7500)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.737% (6744/7600)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.727% (6832/7700)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 88.718% (6920/7800)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.747% (7011/7900)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 88.750% (7100/8000)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 88.778% (7191/8100)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 88.756% (7278/8200)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 88.759% (7367/8300)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 88.786% (7458/8400)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 88.741% (7543/8500)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.674% (7626/8600)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.678% (7715/8700)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.670% (7803/8800)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.652% (7890/8900)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.667% (7980/9000)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.670% (8069/9100)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.685% (8159/9200)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.656% (8245/9300)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 88.670% (8335/9400)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.684% (8425/9500)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 88.677% (8513/9600)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.711% (8605/9700)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.735% (8696/9800)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.758% (8787/9900)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 88.760% (8876/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Train Epoch: 41 | Loss: 0.138 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 94.531% (242/256)\n",
      "Train Epoch: 41 | Loss: 0.139 | Acc: 95.573% (367/384)\n",
      "Train Epoch: 41 | Loss: 0.133 | Acc: 96.094% (492/512)\n",
      "Train Epoch: 41 | Loss: 0.121 | Acc: 96.562% (618/640)\n",
      "Train Epoch: 41 | Loss: 0.126 | Acc: 96.354% (740/768)\n",
      "Train Epoch: 41 | Loss: 0.128 | Acc: 96.094% (861/896)\n",
      "Train Epoch: 41 | Loss: 0.128 | Acc: 95.898% (982/1024)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.833% (1104/1152)\n",
      "Train Epoch: 41 | Loss: 0.122 | Acc: 96.172% (1231/1280)\n",
      "Train Epoch: 41 | Loss: 0.120 | Acc: 96.236% (1355/1408)\n",
      "Train Epoch: 41 | Loss: 0.118 | Acc: 96.354% (1480/1536)\n",
      "Train Epoch: 41 | Loss: 0.126 | Acc: 96.154% (1600/1664)\n",
      "Train Epoch: 41 | Loss: 0.122 | Acc: 96.261% (1725/1792)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 96.094% (1845/1920)\n",
      "Train Epoch: 41 | Loss: 0.126 | Acc: 96.240% (1971/2048)\n",
      "Train Epoch: 41 | Loss: 0.125 | Acc: 96.324% (2096/2176)\n",
      "Train Epoch: 41 | Loss: 0.124 | Acc: 96.311% (2219/2304)\n",
      "Train Epoch: 41 | Loss: 0.123 | Acc: 96.299% (2342/2432)\n",
      "Train Epoch: 41 | Loss: 0.125 | Acc: 96.250% (2464/2560)\n",
      "Train Epoch: 41 | Loss: 0.125 | Acc: 96.280% (2588/2688)\n",
      "Train Epoch: 41 | Loss: 0.126 | Acc: 96.200% (2709/2816)\n",
      "Train Epoch: 41 | Loss: 0.126 | Acc: 96.230% (2833/2944)\n",
      "Train Epoch: 41 | Loss: 0.127 | Acc: 96.126% (2953/3072)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 96.000% (3072/3200)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 96.004% (3195/3328)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.978% (3317/3456)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.926% (3438/3584)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.986% (3563/3712)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.911% (3683/3840)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.968% (3808/3968)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.947% (3930/4096)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.928% (4052/4224)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.910% (4174/4352)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.938% (4298/4480)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.898% (4419/4608)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.819% (4538/4736)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.826% (4661/4864)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.773% (4781/4992)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.820% (4906/5120)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.770% (5026/5248)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.815% (5151/5376)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.858% (5276/5504)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.845% (5398/5632)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.851% (5521/5760)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.805% (5641/5888)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.795% (5763/6016)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.785% (5885/6144)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.791% (6008/6272)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.766% (6129/6400)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.787% (6253/6528)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.778% (6375/6656)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.769% (6497/6784)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.804% (6622/6912)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.795% (6744/7040)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.773% (6865/7168)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.806% (6990/7296)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.811% (7113/7424)\n",
      "Train Epoch: 41 | Loss: 0.129 | Acc: 95.789% (7234/7552)\n",
      "Train Epoch: 41 | Loss: 0.130 | Acc: 95.742% (7353/7680)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.722% (7474/7808)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.716% (7596/7936)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.697% (7717/8064)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.703% (7840/8192)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.709% (7963/8320)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.739% (8088/8448)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.686% (8206/8576)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.692% (8329/8704)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.675% (8450/8832)\n",
      "Train Epoch: 41 | Loss: 0.131 | Acc: 95.714% (8576/8960)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.654% (8693/9088)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.649% (8815/9216)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.634% (8936/9344)\n",
      "Train Epoch: 41 | Loss: 0.133 | Acc: 95.619% (9057/9472)\n",
      "Train Epoch: 41 | Loss: 0.132 | Acc: 95.646% (9182/9600)\n",
      "Train Epoch: 41 | Loss: 0.133 | Acc: 95.631% (9303/9728)\n",
      "Train Epoch: 41 | Loss: 0.133 | Acc: 95.627% (9425/9856)\n",
      "Train Epoch: 41 | Loss: 0.133 | Acc: 95.633% (9548/9984)\n",
      "Train Epoch: 41 | Loss: 0.134 | Acc: 95.629% (9670/10112)\n",
      "Train Epoch: 41 | Loss: 0.134 | Acc: 95.615% (9791/10240)\n",
      "Train Epoch: 41 | Loss: 0.135 | Acc: 95.592% (9911/10368)\n",
      "Train Epoch: 41 | Loss: 0.135 | Acc: 95.570% (10031/10496)\n",
      "Train Epoch: 41 | Loss: 0.135 | Acc: 95.585% (10155/10624)\n",
      "Train Epoch: 41 | Loss: 0.135 | Acc: 95.526% (10271/10752)\n",
      "Train Epoch: 41 | Loss: 0.135 | Acc: 95.533% (10394/10880)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.521% (10515/11008)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.510% (10636/11136)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.517% (10759/11264)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.497% (10879/11392)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.469% (10998/11520)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.467% (11120/11648)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.474% (11243/11776)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.489% (11367/11904)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.462% (11486/12032)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.452% (11607/12160)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.451% (11729/12288)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.457% (11852/12416)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.464% (11975/12544)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.486% (12100/12672)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.484% (12222/12800)\n",
      "Train Epoch: 41 | Loss: 0.136 | Acc: 95.475% (12343/12928)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.473% (12465/13056)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.472% (12587/13184)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.455% (12707/13312)\n",
      "Train Epoch: 41 | Loss: 0.137 | Acc: 95.454% (12829/13440)\n",
      "Train Epoch: 41 | Loss: 0.138 | Acc: 95.438% (12949/13568)\n",
      "Train Epoch: 41 | Loss: 0.138 | Acc: 95.444% (13072/13696)\n",
      "Train Epoch: 41 | Loss: 0.138 | Acc: 95.435% (13193/13824)\n",
      "Train Epoch: 41 | Loss: 0.138 | Acc: 95.434% (13315/13952)\n",
      "Train Epoch: 41 | Loss: 0.139 | Acc: 95.398% (13432/14080)\n",
      "Train Epoch: 41 | Loss: 0.139 | Acc: 95.376% (13551/14208)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.340% (13668/14336)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.312% (13786/14464)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.299% (13906/14592)\n",
      "Train Epoch: 41 | Loss: 0.141 | Acc: 95.279% (14025/14720)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.312% (14152/14848)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.312% (14274/14976)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.306% (14395/15104)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.306% (14517/15232)\n",
      "Train Epoch: 41 | Loss: 0.140 | Acc: 95.299% (14638/15360)\n",
      "Train Epoch: 41 | Loss: 0.141 | Acc: 95.280% (14757/15488)\n",
      "Train Epoch: 41 | Loss: 0.141 | Acc: 95.274% (14878/15616)\n",
      "Train Epoch: 41 | Loss: 0.141 | Acc: 95.274% (15000/15744)\n",
      "Train Epoch: 41 | Loss: 0.141 | Acc: 95.262% (15120/15872)\n",
      "Train Epoch: 41 | Loss: 0.142 | Acc: 95.231% (15237/16000)\n",
      "Train Epoch: 41 | Loss: 0.142 | Acc: 95.219% (15357/16128)\n",
      "Train Epoch: 41 | Loss: 0.142 | Acc: 95.202% (15476/16256)\n",
      "Train Epoch: 41 | Loss: 0.142 | Acc: 95.209% (15599/16384)\n",
      "Train Epoch: 41 | Loss: 0.143 | Acc: 95.185% (15717/16512)\n",
      "Train Epoch: 41 | Loss: 0.142 | Acc: 95.198% (15841/16640)\n",
      "Train Epoch: 41 | Loss: 0.143 | Acc: 95.187% (15961/16768)\n",
      "Train Epoch: 41 | Loss: 0.143 | Acc: 95.176% (16081/16896)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.172% (16202/17024)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.184% (16326/17152)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.174% (16446/17280)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.157% (16565/17408)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.147% (16685/17536)\n",
      "Train Epoch: 41 | Loss: 0.144 | Acc: 95.143% (16806/17664)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.150% (16929/17792)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.145% (17050/17920)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.135% (17170/18048)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.125% (17290/18176)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.138% (17414/18304)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.123% (17533/18432)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.129% (17656/18560)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.104% (17773/18688)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.105% (17895/18816)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.101% (18016/18944)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.108% (18139/19072)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.099% (18259/19200)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.095% (18380/19328)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.107% (18504/19456)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.098% (18624/19584)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.084% (18743/19712)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.055% (18859/19840)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.052% (18980/19968)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.039% (19099/20096)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.045% (19222/20224)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.042% (19343/20352)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.029% (19462/20480)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.055% (19589/20608)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 95.028% (19705/20736)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.044% (19830/20864)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.055% (19954/20992)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.052% (20075/21120)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.044% (20195/21248)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.041% (20316/21376)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.057% (20441/21504)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.049% (20561/21632)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.064% (20686/21760)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.075% (20810/21888)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.063% (20929/22016)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.060% (21050/22144)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.070% (21174/22272)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.054% (21292/22400)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.055% (21414/22528)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.061% (21537/22656)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.058% (21658/22784)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.051% (21778/22912)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.056% (21901/23040)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.054% (22022/23168)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.046% (22142/23296)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.044% (22263/23424)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.062% (22389/23552)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.063% (22511/23680)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.073% (22635/23808)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.079% (22758/23936)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.063% (22876/24064)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.085% (23003/24192)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.086% (23125/24320)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.088% (23247/24448)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.081% (23367/24576)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.066% (23485/24704)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.067% (23607/24832)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.060% (23727/24960)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.069% (23851/25088)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.059% (23970/25216)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.064% (24093/25344)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.057% (24213/25472)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.066% (24337/25600)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.052% (24455/25728)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.050% (24576/25856)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.055% (24699/25984)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.052% (24820/26112)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.038% (24938/26240)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.032% (25058/26368)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.045% (25183/26496)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.053% (25307/26624)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.058% (25430/26752)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.078% (25557/26880)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.079% (25679/27008)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.077% (25800/27136)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.092% (25926/27264)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.090% (26047/27392)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.098% (26171/27520)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.110% (26296/27648)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.086% (26411/27776)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.072% (26529/27904)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.073% (26651/28032)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.060% (26769/28160)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.058% (26890/28288)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.056% (27011/28416)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.050% (27131/28544)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.058% (27255/28672)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.062% (27378/28800)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.067% (27501/28928)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.072% (27624/29056)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.069% (27745/29184)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.067% (27866/29312)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.061% (27986/29440)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.072% (28111/29568)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.070% (28232/29696)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.068% (28353/29824)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.069% (28475/29952)\n",
      "Train Epoch: 41 | Loss: 0.145 | Acc: 95.060% (28594/30080)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.051% (28713/30208)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.039% (28831/30336)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.037% (28952/30464)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.035% (29073/30592)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.033% (29194/30720)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.027% (29314/30848)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.025% (29435/30976)\n",
      "Train Epoch: 41 | Loss: 0.146 | Acc: 95.023% (29556/31104)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.005% (29672/31232)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 95.000% (29792/31360)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.979% (29907/31488)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.984% (30030/31616)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.985% (30152/31744)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.986% (30274/31872)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.994% (30398/32000)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.998% (30521/32128)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.996% (30642/32256)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.994% (30763/32384)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.990% (30883/32512)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.985% (31003/32640)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.992% (31127/32768)\n",
      "Train Epoch: 41 | Loss: 0.147 | Acc: 94.993% (31249/32896)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.964% (31361/33024)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.963% (31482/33152)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.958% (31602/33280)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.956% (31723/33408)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.967% (31848/33536)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.959% (31967/33664)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.969% (32092/33792)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.953% (32208/33920)\n",
      "Train Epoch: 41 | Loss: 0.148 | Acc: 94.951% (32329/34048)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.944% (32448/34176)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.919% (32561/34304)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.906% (32678/34432)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.896% (32796/34560)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.903% (32920/34688)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.908% (33043/34816)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.903% (33163/34944)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.899% (33283/35072)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.901% (33405/35200)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.899% (33526/35328)\n",
      "Train Epoch: 41 | Loss: 0.149 | Acc: 94.904% (33649/35456)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.897% (33768/35584)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.895% (33889/35712)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.880% (34005/35840)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.879% (34126/35968)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.880% (34248/36096)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.879% (34369/36224)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.878% (34490/36352)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.868% (34608/36480)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.867% (34729/36608)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.866% (34850/36736)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.857% (34968/36864)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.858% (35090/36992)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.865% (35214/37120)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.851% (35330/37248)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.858% (35454/37376)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.843% (35570/37504)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.842% (35691/37632)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.841% (35812/37760)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.843% (35934/37888)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.852% (36059/38016)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.851% (36180/38144)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.845% (36299/38272)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.841% (36419/38400)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.835% (36538/38528)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.831% (36658/38656)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.823% (36776/38784)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.827% (36899/38912)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.826% (37020/39040)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.825% (37141/39168)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.832% (37265/39296)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.833% (37387/39424)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.835% (37509/39552)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.834% (37630/39680)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.838% (37753/39808)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.834% (37873/39936)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.841% (37997/40064)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.835% (38116/40192)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.829% (38235/40320)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.828% (38356/40448)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.834% (38480/40576)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.836% (38602/40704)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.832% (38722/40832)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.836% (38845/40960)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.828% (38963/41088)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.822% (39082/41216)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.817% (39201/41344)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.821% (39324/41472)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.820% (39445/41600)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.824% (39568/41728)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.820% (39688/41856)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.822% (39810/41984)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.819% (39930/42112)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.830% (40056/42240)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.831% (40178/42368)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.830% (40299/42496)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.832% (40421/42624)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.835% (40544/42752)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.832% (40664/42880)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.843% (40790/43008)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.840% (40910/43136)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.832% (41028/43264)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.829% (41148/43392)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.821% (41266/43520)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.825% (41389/43648)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.828% (41512/43776)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.827% (41633/43904)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.833% (41757/44032)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.839% (41881/44160)\n",
      "Train Epoch: 41 | Loss: 0.150 | Acc: 94.845% (42005/44288)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.833% (42121/44416)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.834% (42243/44544)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.827% (42361/44672)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.824% (42481/44800)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.830% (42605/44928)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.838% (42730/45056)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.837% (42851/45184)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.829% (42969/45312)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.828% (43090/45440)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.814% (43205/45568)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.811% (43325/45696)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.811% (43446/45824)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.801% (43563/45952)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.805% (43686/46080)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.810% (43810/46208)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.805% (43929/46336)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.807% (44051/46464)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.795% (44167/46592)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.801% (44291/46720)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.800% (44412/46848)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.802% (44534/46976)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.797% (44653/47104)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.790% (44771/47232)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.793% (44894/47360)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.799% (45018/47488)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.794% (45137/47616)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.793% (45258/47744)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.788% (45377/47872)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.796% (45502/48000)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.787% (45619/48128)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.784% (45739/48256)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.779% (45858/48384)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.787% (45983/48512)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.782% (46102/48640)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.783% (46224/48768)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.785% (46346/48896)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.792% (46471/49024)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.784% (46588/49152)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.781% (46708/49280)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.782% (46830/49408)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.790% (46955/49536)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.783% (47073/49664)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.780% (47193/49792)\n",
      "Train Epoch: 41 | Loss: 0.152 | Acc: 94.782% (47315/49920)\n",
      "Train Epoch: 41 | Loss: 0.151 | Acc: 94.782% (47391/50000)\n",
      "Test Epoch: 41 | Loss: 0.253 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 41 | Loss: 0.320 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 41 | Loss: 0.318 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 41 | Loss: 0.359 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 41 | Loss: 0.327 | Acc: 89.400% (447/500)\n",
      "Test Epoch: 41 | Loss: 0.314 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 41 | Loss: 0.325 | Acc: 89.571% (627/700)\n",
      "Test Epoch: 41 | Loss: 0.339 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 41 | Loss: 0.338 | Acc: 89.000% (801/900)\n",
      "Test Epoch: 41 | Loss: 0.355 | Acc: 88.900% (889/1000)\n",
      "Test Epoch: 41 | Loss: 0.370 | Acc: 88.727% (976/1100)\n",
      "Test Epoch: 41 | Loss: 0.383 | Acc: 88.417% (1061/1200)\n",
      "Test Epoch: 41 | Loss: 0.381 | Acc: 88.462% (1150/1300)\n",
      "Test Epoch: 41 | Loss: 0.383 | Acc: 88.357% (1237/1400)\n",
      "Test Epoch: 41 | Loss: 0.387 | Acc: 88.133% (1322/1500)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 88.000% (1408/1600)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 88.118% (1498/1700)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 88.056% (1585/1800)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 87.947% (1671/1900)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 87.800% (1756/2000)\n",
      "Test Epoch: 41 | Loss: 0.408 | Acc: 87.667% (1841/2100)\n",
      "Test Epoch: 41 | Loss: 0.405 | Acc: 87.773% (1931/2200)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 87.870% (2021/2300)\n",
      "Test Epoch: 41 | Loss: 0.401 | Acc: 87.917% (2110/2400)\n",
      "Test Epoch: 41 | Loss: 0.419 | Acc: 87.720% (2193/2500)\n",
      "Test Epoch: 41 | Loss: 0.432 | Acc: 87.731% (2281/2600)\n",
      "Test Epoch: 41 | Loss: 0.424 | Acc: 87.778% (2370/2700)\n",
      "Test Epoch: 41 | Loss: 0.418 | Acc: 87.964% (2463/2800)\n",
      "Test Epoch: 41 | Loss: 0.421 | Acc: 87.966% (2551/2900)\n",
      "Test Epoch: 41 | Loss: 0.418 | Acc: 88.100% (2643/3000)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.129% (2732/3100)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.250% (2824/3200)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.152% (2909/3300)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.118% (2996/3400)\n",
      "Test Epoch: 41 | Loss: 0.419 | Acc: 88.114% (3084/3500)\n",
      "Test Epoch: 41 | Loss: 0.424 | Acc: 88.139% (3173/3600)\n",
      "Test Epoch: 41 | Loss: 0.426 | Acc: 88.081% (3259/3700)\n",
      "Test Epoch: 41 | Loss: 0.426 | Acc: 88.079% (3347/3800)\n",
      "Test Epoch: 41 | Loss: 0.425 | Acc: 88.103% (3436/3900)\n",
      "Test Epoch: 41 | Loss: 0.422 | Acc: 88.175% (3527/4000)\n",
      "Test Epoch: 41 | Loss: 0.425 | Acc: 88.000% (3608/4100)\n",
      "Test Epoch: 41 | Loss: 0.427 | Acc: 87.976% (3695/4200)\n",
      "Test Epoch: 41 | Loss: 0.422 | Acc: 88.093% (3788/4300)\n",
      "Test Epoch: 41 | Loss: 0.423 | Acc: 88.159% (3879/4400)\n",
      "Test Epoch: 41 | Loss: 0.419 | Acc: 88.267% (3972/4500)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.304% (4062/4600)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.298% (4150/4700)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.125% (4230/4800)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.224% (4323/4900)\n",
      "Test Epoch: 41 | Loss: 0.418 | Acc: 88.160% (4408/5000)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.235% (4500/5100)\n",
      "Test Epoch: 41 | Loss: 0.420 | Acc: 88.077% (4580/5200)\n",
      "Test Epoch: 41 | Loss: 0.420 | Acc: 88.019% (4665/5300)\n",
      "Test Epoch: 41 | Loss: 0.418 | Acc: 88.074% (4756/5400)\n",
      "Test Epoch: 41 | Loss: 0.422 | Acc: 88.073% (4844/5500)\n",
      "Test Epoch: 41 | Loss: 0.420 | Acc: 88.125% (4935/5600)\n",
      "Test Epoch: 41 | Loss: 0.419 | Acc: 88.088% (5021/5700)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.190% (5115/5800)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.237% (5206/5900)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.267% (5296/6000)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.311% (5387/6100)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.274% (5473/6200)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.333% (5565/6300)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.359% (5655/6400)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.338% (5742/6500)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.333% (5830/6600)\n",
      "Test Epoch: 41 | Loss: 0.410 | Acc: 88.388% (5922/6700)\n",
      "Test Epoch: 41 | Loss: 0.409 | Acc: 88.441% (6014/6800)\n",
      "Test Epoch: 41 | Loss: 0.410 | Acc: 88.435% (6102/6900)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.400% (6188/7000)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.408% (6277/7100)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.389% (6364/7200)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.384% (6452/7300)\n",
      "Test Epoch: 41 | Loss: 0.411 | Acc: 88.419% (6543/7400)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.387% (6629/7500)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.395% (6718/7600)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.377% (6805/7700)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.372% (6893/7800)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.380% (6982/7900)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.388% (7071/8000)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.370% (7158/8100)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.366% (7246/8200)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.337% (7332/8300)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.286% (7416/8400)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.247% (7501/8500)\n",
      "Test Epoch: 41 | Loss: 0.418 | Acc: 88.174% (7583/8600)\n",
      "Test Epoch: 41 | Loss: 0.416 | Acc: 88.230% (7676/8700)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.205% (7762/8800)\n",
      "Test Epoch: 41 | Loss: 0.416 | Acc: 88.191% (7849/8900)\n",
      "Test Epoch: 41 | Loss: 0.417 | Acc: 88.233% (7941/9000)\n",
      "Test Epoch: 41 | Loss: 0.415 | Acc: 88.253% (8031/9100)\n",
      "Test Epoch: 41 | Loss: 0.413 | Acc: 88.315% (8125/9200)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.323% (8214/9300)\n",
      "Test Epoch: 41 | Loss: 0.414 | Acc: 88.351% (8305/9400)\n",
      "Test Epoch: 41 | Loss: 0.412 | Acc: 88.379% (8396/9500)\n",
      "Test Epoch: 41 | Loss: 0.411 | Acc: 88.406% (8487/9600)\n",
      "Test Epoch: 41 | Loss: 0.409 | Acc: 88.443% (8579/9700)\n",
      "Test Epoch: 41 | Loss: 0.410 | Acc: 88.449% (8668/9800)\n",
      "Test Epoch: 41 | Loss: 0.410 | Acc: 88.455% (8757/9900)\n",
      "Test Epoch: 41 | Loss: 0.410 | Acc: 88.470% (8847/10000)\n",
      "\n",
      "Epoch: 42\n",
      "Train Epoch: 42 | Loss: 0.120 | Acc: 95.312% (122/128)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 94.922% (243/256)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 94.792% (364/384)\n",
      "Train Epoch: 42 | Loss: 0.148 | Acc: 94.336% (483/512)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.375% (604/640)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 94.531% (726/768)\n",
      "Train Epoch: 42 | Loss: 0.134 | Acc: 94.866% (850/896)\n",
      "Train Epoch: 42 | Loss: 0.130 | Acc: 95.215% (975/1024)\n",
      "Train Epoch: 42 | Loss: 0.131 | Acc: 95.139% (1096/1152)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 94.766% (1213/1280)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.815% (1335/1408)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.792% (1456/1536)\n",
      "Train Epoch: 42 | Loss: 0.139 | Acc: 94.952% (1580/1664)\n",
      "Train Epoch: 42 | Loss: 0.147 | Acc: 94.587% (1695/1792)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.583% (1816/1920)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.678% (1939/2048)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.623% (2059/2176)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 94.748% (2183/2304)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 94.696% (2303/2432)\n",
      "Train Epoch: 42 | Loss: 0.148 | Acc: 94.570% (2421/2560)\n",
      "Train Epoch: 42 | Loss: 0.147 | Acc: 94.680% (2545/2688)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.780% (2669/2816)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.803% (2791/2944)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.727% (2910/3072)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.719% (3031/3200)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.712% (3152/3328)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.734% (3274/3456)\n",
      "Train Epoch: 42 | Loss: 0.147 | Acc: 94.699% (3394/3584)\n",
      "Train Epoch: 42 | Loss: 0.147 | Acc: 94.720% (3516/3712)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.740% (3638/3840)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.783% (3761/3968)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.824% (3884/4096)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.863% (4007/4224)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.922% (4131/4352)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.022% (4257/4480)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.009% (4378/4608)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.038% (4501/4736)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.086% (4625/4864)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.132% (4749/4992)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.117% (4870/5120)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.103% (4991/5248)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.182% (5117/5376)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.203% (5240/5504)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.206% (5362/5632)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.156% (5481/5760)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.126% (5601/5888)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.180% (5726/6016)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.150% (5846/6144)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.169% (5969/6272)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.188% (6092/6400)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.236% (6217/6528)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.237% (6339/6656)\n",
      "Train Epoch: 42 | Loss: 0.139 | Acc: 95.283% (6464/6784)\n",
      "Train Epoch: 42 | Loss: 0.138 | Acc: 95.269% (6585/6912)\n",
      "Train Epoch: 42 | Loss: 0.139 | Acc: 95.213% (6703/7040)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.215% (6825/7168)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.230% (6948/7296)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.191% (7067/7424)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.207% (7190/7552)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.221% (7313/7680)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.159% (7430/7808)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.136% (7550/7936)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.151% (7673/8064)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.190% (7798/8192)\n",
      "Train Epoch: 42 | Loss: 0.140 | Acc: 95.168% (7918/8320)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.147% (8038/8448)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.149% (8160/8576)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.163% (8283/8704)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.165% (8405/8832)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.123% (8523/8960)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.092% (8642/9088)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.106% (8765/9216)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.141% (8890/9344)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.175% (9015/9472)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.177% (9137/9600)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.179% (9259/9728)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.110% (9374/9856)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.102% (9495/9984)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.125% (9619/10112)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.127% (9741/10240)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.120% (9862/10368)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.141% (9986/10496)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.134% (10107/10624)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.173% (10233/10752)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.175% (10355/10880)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.167% (10476/11008)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.214% (10603/11136)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.233% (10727/11264)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.216% (10847/11392)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.191% (10966/11520)\n",
      "Train Epoch: 42 | Loss: 0.141 | Acc: 95.167% (11085/11648)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.168% (11207/11776)\n",
      "Train Epoch: 42 | Loss: 0.142 | Acc: 95.195% (11332/11904)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.155% (11449/12032)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.140% (11569/12160)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.117% (11688/12288)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.055% (11802/12416)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.057% (11924/12544)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.052% (12045/12672)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.062% (12168/12800)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.050% (12288/12928)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.029% (12407/13056)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.017% (12527/13184)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.027% (12650/13312)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.030% (12772/13440)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.040% (12895/13568)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.013% (13013/13696)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.016% (13135/13824)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.011% (13256/13952)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.007% (13377/14080)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.010% (13499/14208)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.006% (13620/14336)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.022% (13744/14464)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.032% (13867/14592)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.041% (13990/14720)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.057% (14114/14848)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.045% (14234/14976)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.061% (14358/15104)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.083% (14483/15232)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.085% (14605/15360)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.099% (14729/15488)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.076% (14847/15616)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.097% (14972/15744)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.111% (15096/15872)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.112% (15218/16000)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.120% (15341/16128)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.116% (15462/16256)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.105% (15582/16384)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.101% (15703/16512)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.096% (15824/16640)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.074% (15942/16768)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 95.070% (16063/16896)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.083% (16187/17024)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.103% (16312/17152)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.075% (16429/17280)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.077% (16551/17408)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.096% (16676/17536)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.120% (16802/17664)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.105% (16921/17792)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.106% (17043/17920)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.130% (17169/18048)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.125% (17290/18176)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.132% (17413/18304)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.117% (17532/18432)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.102% (17651/18560)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.109% (17774/18688)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.105% (17895/18816)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.080% (18012/18944)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.087% (18135/19072)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.089% (18257/19200)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.106% (18382/19328)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.122% (18507/19456)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.113% (18627/19584)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.110% (18748/19712)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.101% (18868/19840)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.107% (18991/19968)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.108% (19113/20096)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.105% (19234/20224)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.121% (19359/20352)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.117% (19480/20480)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.089% (19596/20608)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.095% (19719/20736)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.087% (19839/20864)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.098% (19963/20992)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.080% (20081/21120)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.101% (20207/21248)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.107% (20330/21376)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.085% (20447/21504)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.109% (20574/21632)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.106% (20695/21760)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.111% (20818/21888)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.104% (20938/22016)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.105% (21060/22144)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.101% (21181/22272)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.076% (21297/22400)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.051% (21413/22528)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.048% (21534/22656)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.049% (21656/22784)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.046% (21777/22912)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.061% (21902/23040)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.066% (22025/23168)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.046% (22142/23296)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.044% (22263/23424)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.037% (22383/23552)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.046% (22507/23680)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.065% (22633/23808)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.066% (22755/23936)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.080% (22880/24064)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.093% (23005/24192)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.090% (23126/24320)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.083% (23246/24448)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.085% (23368/24576)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.090% (23491/24704)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.103% (23616/24832)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.072% (23730/24960)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.069% (23851/25088)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.067% (23972/25216)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.084% (24098/25344)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.104% (24225/25472)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.102% (24346/25600)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.095% (24466/25728)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.088% (24586/25856)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.074% (24704/25984)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (24828/26112)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.061% (24944/26240)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.074% (25069/26368)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.086% (25194/26496)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.087% (25316/26624)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (25435/26752)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.086% (25559/26880)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.087% (25681/27008)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.088% (25803/27136)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.096% (25927/27264)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.104% (26051/27392)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.094% (26170/27520)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.085% (26289/27648)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.093% (26413/27776)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.094% (26535/27904)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.091% (26656/28032)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.089% (26777/28160)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (26897/28288)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.073% (27016/28416)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (27140/28544)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.089% (27264/28672)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (27384/28800)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.098% (27510/28928)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.096% (27631/29056)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.097% (27753/29184)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.094% (27874/29312)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.099% (27997/29440)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.103% (28120/29568)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.104% (28242/29696)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.098% (28362/29824)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.109% (28487/29952)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.103% (28607/30080)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.091% (28725/30208)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.088% (28846/30336)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (28966/30464)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.087% (29089/30592)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.098% (29214/30720)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.089% (29333/30848)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.090% (29455/30976)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.084% (29575/31104)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.088% (29698/31232)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.092% (29821/31360)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (29939/31488)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.075% (30059/31616)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.073% (30180/31744)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.068% (30300/31872)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.066% (30421/32000)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.073% (30545/32128)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.074% (30667/32256)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.069% (30787/32384)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.070% (30909/32512)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.070% (31031/32640)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.071% (31153/32768)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.069% (31274/32896)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.076% (31398/33024)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.068% (31517/33152)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.072% (31640/33280)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.082% (31765/33408)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (31885/33536)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (32008/33664)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.079% (32129/33792)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (32252/33920)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.078% (32372/34048)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.067% (32490/34176)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.076% (32615/34304)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.074% (32736/34432)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.075% (32858/34560)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.079% (32981/34688)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.083% (33104/34816)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (33225/34944)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.076% (33345/35072)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (33467/35200)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.075% (33588/35328)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.073% (33709/35456)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.074% (33831/35584)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.066% (33950/35712)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (34077/35840)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.085% (34200/35968)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (34319/36096)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.081% (34442/36224)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.070% (34560/36352)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.082% (34686/36480)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.080% (34807/36608)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.078% (34928/36736)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.082% (35051/36864)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (35171/36992)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.073% (35291/37120)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.068% (35411/37248)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.069% (35533/37376)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.070% (35655/37504)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.065% (35775/37632)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.079% (35902/37760)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.078% (36023/37888)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.070% (36142/38016)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.071% (36264/38144)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.067% (36384/38272)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.065% (36505/38400)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.076% (36631/38528)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.069% (36750/38656)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.073% (36873/38784)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.071% (36994/38912)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.077% (37118/39040)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.075% (37239/39168)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.086% (37365/39296)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.082% (37485/39424)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.075% (37604/39552)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.068% (37723/39680)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.071% (37846/39808)\n",
      "Train Epoch: 42 | Loss: 0.143 | Acc: 95.080% (37971/39936)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.060% (38085/40064)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.056% (38205/40192)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.062% (38329/40320)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.055% (38448/40448)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.056% (38570/40576)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.050% (38689/40704)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.046% (38809/40832)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.051% (38933/40960)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.052% (39055/41088)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.050% (39176/41216)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.037% (39292/41344)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.011% (39403/41472)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.019% (39528/41600)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.013% (39647/41728)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.011% (39768/41856)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.012% (39890/41984)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.009% (40010/42112)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.012% (40133/42240)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 95.013% (40255/42368)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.009% (40375/42496)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.008% (40496/42624)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.999% (40614/42752)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.002% (40737/42880)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.999% (40857/43008)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 95.002% (40980/43136)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.991% (41097/43264)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.990% (41218/43392)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.993% (41341/43520)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.987% (41460/43648)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.981% (41579/43776)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.987% (41703/43904)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.988% (41825/44032)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.991% (41948/44160)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.992% (42070/44288)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.993% (42192/44416)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.987% (42311/44544)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.992% (42435/44672)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.991% (42556/44800)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.992% (42678/44928)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.988% (42798/45056)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.981% (42916/45184)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.977% (43036/45312)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.985% (43161/45440)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.977% (43279/45568)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.969% (43397/45696)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.974% (43521/45824)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.966% (43639/45952)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.965% (43760/46080)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.964% (43881/46208)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.965% (44003/46336)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.970% (44127/46464)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.973% (44250/46592)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.966% (44368/46720)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.965% (44489/46848)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.968% (44612/46976)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.962% (44731/47104)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.961% (44852/47232)\n",
      "Train Epoch: 42 | Loss: 0.144 | Acc: 94.956% (44971/47360)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.952% (45091/47488)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.945% (45209/47616)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.946% (45331/47744)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.947% (45453/47872)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.940% (45571/48000)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.938% (45692/48128)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.939% (45814/48256)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.940% (45936/48384)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.941% (46058/48512)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.934% (46176/48640)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.937% (46299/48768)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.920% (46412/48896)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.913% (46530/49024)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.912% (46651/49152)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.913% (46773/49280)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.912% (46894/49408)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.917% (47018/49536)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.924% (47143/49664)\n",
      "Train Epoch: 42 | Loss: 0.145 | Acc: 94.921% (47263/49792)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.910% (47379/49920)\n",
      "Train Epoch: 42 | Loss: 0.146 | Acc: 94.910% (47455/50000)\n",
      "Test Epoch: 42 | Loss: 0.421 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 42 | Loss: 0.483 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 42 | Loss: 0.480 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 42 | Loss: 0.501 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 42 | Loss: 0.461 | Acc: 87.400% (437/500)\n",
      "Test Epoch: 42 | Loss: 0.435 | Acc: 88.000% (528/600)\n",
      "Test Epoch: 42 | Loss: 0.472 | Acc: 88.143% (617/700)\n",
      "Test Epoch: 42 | Loss: 0.505 | Acc: 87.500% (700/800)\n",
      "Test Epoch: 42 | Loss: 0.498 | Acc: 87.556% (788/900)\n",
      "Test Epoch: 42 | Loss: 0.501 | Acc: 87.800% (878/1000)\n",
      "Test Epoch: 42 | Loss: 0.501 | Acc: 87.727% (965/1100)\n",
      "Test Epoch: 42 | Loss: 0.495 | Acc: 87.417% (1049/1200)\n",
      "Test Epoch: 42 | Loss: 0.490 | Acc: 87.385% (1136/1300)\n",
      "Test Epoch: 42 | Loss: 0.486 | Acc: 87.429% (1224/1400)\n",
      "Test Epoch: 42 | Loss: 0.485 | Acc: 87.333% (1310/1500)\n",
      "Test Epoch: 42 | Loss: 0.489 | Acc: 87.062% (1393/1600)\n",
      "Test Epoch: 42 | Loss: 0.491 | Acc: 86.941% (1478/1700)\n",
      "Test Epoch: 42 | Loss: 0.488 | Acc: 87.000% (1566/1800)\n",
      "Test Epoch: 42 | Loss: 0.491 | Acc: 86.895% (1651/1900)\n",
      "Test Epoch: 42 | Loss: 0.501 | Acc: 86.750% (1735/2000)\n",
      "Test Epoch: 42 | Loss: 0.514 | Acc: 86.571% (1818/2100)\n",
      "Test Epoch: 42 | Loss: 0.517 | Acc: 86.409% (1901/2200)\n",
      "Test Epoch: 42 | Loss: 0.517 | Acc: 86.391% (1987/2300)\n",
      "Test Epoch: 42 | Loss: 0.519 | Acc: 86.333% (2072/2400)\n",
      "Test Epoch: 42 | Loss: 0.531 | Acc: 86.040% (2151/2500)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 85.808% (2231/2600)\n",
      "Test Epoch: 42 | Loss: 0.535 | Acc: 85.926% (2320/2700)\n",
      "Test Epoch: 42 | Loss: 0.534 | Acc: 85.964% (2407/2800)\n",
      "Test Epoch: 42 | Loss: 0.537 | Acc: 85.966% (2493/2900)\n",
      "Test Epoch: 42 | Loss: 0.534 | Acc: 86.033% (2581/3000)\n",
      "Test Epoch: 42 | Loss: 0.534 | Acc: 86.000% (2666/3100)\n",
      "Test Epoch: 42 | Loss: 0.532 | Acc: 86.125% (2756/3200)\n",
      "Test Epoch: 42 | Loss: 0.533 | Acc: 86.030% (2839/3300)\n",
      "Test Epoch: 42 | Loss: 0.530 | Acc: 86.000% (2924/3400)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 85.971% (3009/3500)\n",
      "Test Epoch: 42 | Loss: 0.543 | Acc: 86.056% (3098/3600)\n",
      "Test Epoch: 42 | Loss: 0.545 | Acc: 86.081% (3185/3700)\n",
      "Test Epoch: 42 | Loss: 0.549 | Acc: 86.026% (3269/3800)\n",
      "Test Epoch: 42 | Loss: 0.550 | Acc: 86.103% (3358/3900)\n",
      "Test Epoch: 42 | Loss: 0.549 | Acc: 86.025% (3441/4000)\n",
      "Test Epoch: 42 | Loss: 0.551 | Acc: 85.976% (3525/4100)\n",
      "Test Epoch: 42 | Loss: 0.552 | Acc: 85.952% (3610/4200)\n",
      "Test Epoch: 42 | Loss: 0.547 | Acc: 86.023% (3699/4300)\n",
      "Test Epoch: 42 | Loss: 0.547 | Acc: 86.091% (3788/4400)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.200% (3879/4500)\n",
      "Test Epoch: 42 | Loss: 0.541 | Acc: 86.152% (3963/4600)\n",
      "Test Epoch: 42 | Loss: 0.541 | Acc: 86.170% (4050/4700)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 86.021% (4129/4800)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.143% (4221/4900)\n",
      "Test Epoch: 42 | Loss: 0.548 | Acc: 86.020% (4301/5000)\n",
      "Test Epoch: 42 | Loss: 0.542 | Acc: 86.176% (4395/5100)\n",
      "Test Epoch: 42 | Loss: 0.546 | Acc: 85.981% (4471/5200)\n",
      "Test Epoch: 42 | Loss: 0.545 | Acc: 85.981% (4557/5300)\n",
      "Test Epoch: 42 | Loss: 0.542 | Acc: 86.000% (4644/5400)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 85.964% (4728/5500)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 85.982% (4815/5600)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 85.947% (4899/5700)\n",
      "Test Epoch: 42 | Loss: 0.543 | Acc: 85.983% (4987/5800)\n",
      "Test Epoch: 42 | Loss: 0.546 | Acc: 85.983% (5073/5900)\n",
      "Test Epoch: 42 | Loss: 0.543 | Acc: 86.050% (5163/6000)\n",
      "Test Epoch: 42 | Loss: 0.546 | Acc: 86.000% (5246/6100)\n",
      "Test Epoch: 42 | Loss: 0.547 | Acc: 85.984% (5331/6200)\n",
      "Test Epoch: 42 | Loss: 0.544 | Acc: 86.048% (5421/6300)\n",
      "Test Epoch: 42 | Loss: 0.541 | Acc: 86.094% (5510/6400)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.123% (5598/6500)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.061% (5680/6600)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.104% (5769/6700)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.132% (5857/6800)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.145% (5944/6900)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.114% (6028/7000)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.155% (6117/7100)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.153% (6203/7200)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.205% (6293/7300)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.216% (6380/7400)\n",
      "Test Epoch: 42 | Loss: 0.537 | Acc: 86.253% (6469/7500)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.289% (6558/7600)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.260% (6642/7700)\n",
      "Test Epoch: 42 | Loss: 0.542 | Acc: 86.269% (6729/7800)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.329% (6820/7900)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.338% (6907/8000)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.395% (6998/8100)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.378% (7083/8200)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.386% (7170/8300)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.357% (7254/8400)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.318% (7337/8500)\n",
      "Test Epoch: 42 | Loss: 0.541 | Acc: 86.314% (7423/8600)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.322% (7510/8700)\n",
      "Test Epoch: 42 | Loss: 0.541 | Acc: 86.318% (7596/8800)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.348% (7685/8900)\n",
      "Test Epoch: 42 | Loss: 0.539 | Acc: 86.378% (7774/9000)\n",
      "Test Epoch: 42 | Loss: 0.540 | Acc: 86.341% (7857/9100)\n",
      "Test Epoch: 42 | Loss: 0.537 | Acc: 86.380% (7947/9200)\n",
      "Test Epoch: 42 | Loss: 0.538 | Acc: 86.355% (8031/9300)\n",
      "Test Epoch: 42 | Loss: 0.537 | Acc: 86.383% (8120/9400)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.400% (8208/9500)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.396% (8294/9600)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.412% (8382/9700)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.388% (8466/9800)\n",
      "Test Epoch: 42 | Loss: 0.536 | Acc: 86.374% (8551/9900)\n",
      "Test Epoch: 42 | Loss: 0.534 | Acc: 86.390% (8639/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Train Epoch: 43 | Loss: 0.150 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 43 | Loss: 0.153 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.833% (368/384)\n",
      "Train Epoch: 43 | Loss: 0.128 | Acc: 96.094% (492/512)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.781% (613/640)\n",
      "Train Epoch: 43 | Loss: 0.148 | Acc: 95.443% (733/768)\n",
      "Train Epoch: 43 | Loss: 0.147 | Acc: 95.424% (855/896)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.605% (979/1024)\n",
      "Train Epoch: 43 | Loss: 0.146 | Acc: 95.573% (1101/1152)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.625% (1224/1280)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.384% (1343/1408)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.443% (1466/1536)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.613% (1591/1664)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.592% (1713/1792)\n",
      "Train Epoch: 43 | Loss: 0.137 | Acc: 95.625% (1836/1920)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.557% (1957/2048)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.588% (2080/2176)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.399% (2198/2304)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.354% (2319/2432)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.508% (2445/2560)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.350% (2563/2688)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.490% (2689/2816)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.482% (2811/2944)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.475% (2933/3072)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.438% (3054/3200)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.373% (3174/3328)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.457% (3299/3456)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.340% (3417/3584)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.366% (3540/3712)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.234% (3657/3840)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.312% (3782/3968)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.361% (3906/4096)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.336% (4027/4224)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.244% (4145/4352)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.335% (4271/4480)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.247% (4389/4608)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.207% (4509/4736)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.169% (4629/4864)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.092% (4747/4992)\n",
      "Train Epoch: 43 | Loss: 0.148 | Acc: 94.980% (4863/5120)\n",
      "Train Epoch: 43 | Loss: 0.147 | Acc: 94.989% (4985/5248)\n",
      "Train Epoch: 43 | Loss: 0.147 | Acc: 95.033% (5109/5376)\n",
      "Train Epoch: 43 | Loss: 0.147 | Acc: 95.004% (5229/5504)\n",
      "Train Epoch: 43 | Loss: 0.146 | Acc: 95.028% (5352/5632)\n",
      "Train Epoch: 43 | Loss: 0.146 | Acc: 95.069% (5476/5760)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.126% (5601/5888)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.180% (5726/6016)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.231% (5851/6144)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.217% (5972/6272)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.234% (6095/6400)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.236% (6217/6528)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.147% (6333/6656)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.121% (6453/6784)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.124% (6575/6912)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.170% (6700/7040)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.131% (6819/7168)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.162% (6943/7296)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.191% (7067/7424)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.180% (7188/7552)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.169% (7309/7680)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.120% (7427/7808)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.123% (7549/7936)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.126% (7671/8064)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.166% (7796/8192)\n",
      "Train Epoch: 43 | Loss: 0.145 | Acc: 95.108% (7913/8320)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.159% (8039/8448)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.126% (8158/8576)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.106% (8278/8704)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.131% (8402/8832)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.145% (8525/8960)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.169% (8649/9088)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.215% (8775/9216)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.227% (8898/9344)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.207% (9018/9472)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.188% (9138/9600)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.199% (9261/9728)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.221% (9385/9856)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.212% (9506/9984)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.243% (9631/10112)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.234% (9752/10240)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.216% (9872/10368)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.227% (9995/10496)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.218% (10116/10624)\n",
      "Train Epoch: 43 | Loss: 0.144 | Acc: 95.219% (10238/10752)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.211% (10359/10880)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.203% (10480/11008)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.196% (10601/11136)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.224% (10726/11264)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.190% (10844/11392)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.182% (10965/11520)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.175% (11086/11648)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.185% (11209/11776)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.195% (11332/11904)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.163% (11450/12032)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.173% (11573/12160)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.174% (11695/12288)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.168% (11816/12416)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.161% (11937/12544)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.202% (12064/12672)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.211% (12187/12800)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.227% (12311/12928)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.236% (12434/13056)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.199% (12551/13184)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.192% (12672/13312)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.171% (12791/13440)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.180% (12914/13568)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.196% (13038/13696)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.190% (13159/13824)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.176% (13279/13952)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.185% (13402/14080)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.186% (13524/14208)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.173% (13644/14336)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.188% (13768/14464)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.203% (13892/14592)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.211% (14015/14720)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.218% (14138/14848)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.226% (14261/14976)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.200% (14379/15104)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.201% (14501/15232)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.202% (14623/15360)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.209% (14746/15488)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.229% (14871/15616)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.224% (14992/15744)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.205% (15111/15872)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.213% (15234/16000)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.182% (15351/16128)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.189% (15474/16256)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.178% (15594/16384)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.179% (15716/16512)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.192% (15840/16640)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.181% (15960/16768)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.194% (16084/16896)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.207% (16208/17024)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.213% (16331/17152)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.197% (16450/17280)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.192% (16571/17408)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.193% (16693/17536)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.205% (16817/17664)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.211% (16940/17792)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.201% (17060/17920)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.229% (17187/18048)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.235% (17310/18176)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.231% (17431/18304)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.220% (17551/18432)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.189% (17667/18560)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.200% (17791/18688)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.212% (17915/18816)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (18038/18944)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.229% (18162/19072)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.214% (18281/19200)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.240% (18408/19328)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.251% (18532/19456)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.256% (18655/19584)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.226% (18771/19712)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (18891/19840)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.232% (19016/19968)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.233% (19138/20096)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.248% (19263/20224)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.249% (19385/20352)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.269% (19511/20480)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.254% (19630/20608)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.250% (19751/20736)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.269% (19877/20864)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.270% (19999/20992)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.270% (20121/21120)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.270% (20243/21248)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.261% (20363/21376)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.261% (20485/21504)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.248% (20604/21632)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.248% (20726/21760)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.267% (20852/21888)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.276% (20976/22016)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.285% (21100/22144)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.281% (21221/22272)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.290% (21345/22400)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.286% (21466/22528)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.273% (21585/22656)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.282% (21709/22784)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.286% (21832/22912)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.286% (21954/23040)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.278% (22074/23168)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.261% (22192/23296)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.244% (22310/23424)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.253% (22434/23552)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.241% (22553/23680)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.237% (22674/23808)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.237% (22796/23936)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.225% (22915/24064)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (23035/24192)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.222% (23158/24320)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.227% (23281/24448)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.235% (23405/24576)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.215% (23522/24704)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.204% (23641/24832)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.192% (23760/24960)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.193% (23882/25088)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.170% (23998/25216)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.174% (24121/25344)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.171% (24242/25472)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.180% (24366/25600)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.180% (24488/25728)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.189% (24612/25856)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.197% (24736/25984)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.209% (24861/26112)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.217% (24985/26240)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.225% (25109/26368)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.233% (25233/26496)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.196% (25345/26624)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.197% (25467/26752)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.193% (25588/26880)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.198% (25711/27008)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.206% (25835/27136)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.221% (25961/27264)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.218% (26082/27392)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.222% (26205/27520)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.211% (26324/27648)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.222% (26449/27776)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.205% (26566/27904)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.202% (26687/28032)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.213% (26812/28160)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (26935/28288)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.232% (27061/28416)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.228% (27182/28544)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.218% (27301/28672)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.233% (27427/28800)\n",
      "Train Epoch: 43 | Loss: 0.138 | Acc: 95.230% (27548/28928)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.220% (27667/29056)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.223% (27790/29184)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.224% (27912/29312)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.228% (28035/29440)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.231% (28158/29568)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.222% (28277/29696)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.229% (28401/29824)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.229% (28523/29952)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.236% (28647/30080)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.233% (28768/30208)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.220% (28886/30336)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (29007/30464)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.208% (29126/30592)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.205% (29247/30720)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.193% (29365/30848)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.200% (29489/30976)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.203% (29612/31104)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.204% (29734/31232)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.201% (29855/31360)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.198% (29976/31488)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.211% (30102/31616)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.209% (30223/31744)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.200% (30342/31872)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.203% (30465/32000)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.200% (30586/32128)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.204% (30709/32256)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.208% (30832/32384)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.214% (30956/32512)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.211% (31077/32640)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.224% (31203/32768)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.221% (31324/32896)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.216% (31444/33024)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.213% (31565/33152)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.213% (31687/33280)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.211% (31808/33408)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.217% (31932/33536)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.214% (32053/33664)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.215% (32175/33792)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.215% (32297/33920)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.221% (32421/34048)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.213% (32540/34176)\n",
      "Train Epoch: 43 | Loss: 0.139 | Acc: 95.208% (32660/34304)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.202% (32780/34432)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.200% (32901/34560)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.191% (33020/34688)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.180% (33138/34816)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.189% (33263/34944)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.187% (33384/35072)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.185% (33505/35200)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.179% (33625/35328)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.183% (33748/35456)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.183% (33870/35584)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.170% (33987/35712)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.179% (34112/35840)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.187% (34237/35968)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.191% (34360/36096)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.180% (34478/36224)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.189% (34603/36352)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.186% (34724/36480)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.190% (34847/36608)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.190% (34969/36736)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.174% (35085/36864)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.180% (35209/36992)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.178% (35330/37120)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.159% (35445/37248)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.149% (35563/37376)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.142% (35682/37504)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.137% (35802/37632)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.143% (35926/37760)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.149% (36050/37888)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.147% (36171/38016)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.147% (36293/38144)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.153% (36417/38272)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.146% (36536/38400)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.146% (36658/38528)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.150% (36781/38656)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.153% (36904/38784)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.135% (37019/38912)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.126% (37137/39040)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.121% (37257/39168)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.109% (37374/39296)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.099% (37492/39424)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.090% (37610/39552)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.096% (37734/39680)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.094% (37855/39808)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.090% (37975/39936)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.095% (38099/40064)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.081% (38215/40192)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.069% (38332/40320)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.063% (38451/40448)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.064% (38573/40576)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.059% (38693/40704)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.046% (38809/40832)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.049% (38932/40960)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.055% (39056/41088)\n",
      "Train Epoch: 43 | Loss: 0.143 | Acc: 95.055% (39178/41216)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.066% (39304/41344)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.076% (39430/41472)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.077% (39552/41600)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.085% (39677/41728)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.090% (39801/41856)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.096% (39925/41984)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.096% (40047/42112)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.090% (40166/42240)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.093% (40289/42368)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.096% (40412/42496)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.097% (40534/42624)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.100% (40657/42752)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.096% (40777/42880)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.101% (40901/43008)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.095% (41020/43136)\n",
      "Train Epoch: 43 | Loss: 0.142 | Acc: 95.093% (41141/43264)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.098% (41265/43392)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.106% (41390/43520)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.111% (41514/43648)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.107% (41634/43776)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.105% (41755/43904)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.108% (41878/44032)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.115% (42003/44160)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.123% (42128/44288)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.123% (42250/44416)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.119% (42370/44544)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.118% (42491/44672)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.127% (42617/44800)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.134% (42742/44928)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.131% (42862/45056)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.120% (42979/45184)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.125% (43103/45312)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.130% (43227/45440)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.137% (43352/45568)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.140% (43475/45696)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.138% (43596/45824)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.132% (43715/45952)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.137% (43839/46080)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.144% (43964/46208)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.148% (44088/46336)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.149% (44210/46464)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.156% (44335/46592)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.161% (44459/46720)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.152% (44577/46848)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.151% (44698/46976)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.147% (44818/47104)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.143% (44938/47232)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.135% (45056/47360)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.134% (45177/47488)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.128% (45296/47616)\n",
      "Train Epoch: 43 | Loss: 0.140 | Acc: 95.137% (45422/47744)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.133% (45542/47872)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.133% (45664/48000)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.134% (45786/48128)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.132% (45907/48256)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.129% (46027/48384)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.121% (46145/48512)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.132% (46272/48640)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.130% (46393/48768)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.130% (46515/48896)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.123% (46633/49024)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.123% (46755/49152)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.120% (46875/49280)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.118% (46996/49408)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.117% (47117/49536)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.113% (47237/49664)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.112% (47358/49792)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.112% (47480/49920)\n",
      "Train Epoch: 43 | Loss: 0.141 | Acc: 95.114% (47557/50000)\n",
      "Test Epoch: 43 | Loss: 0.263 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 43 | Loss: 0.288 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 43 | Loss: 0.245 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 43 | Loss: 0.320 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 43 | Loss: 0.284 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 43 | Loss: 0.308 | Acc: 91.000% (637/700)\n",
      "Test Epoch: 43 | Loss: 0.345 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 43 | Loss: 0.350 | Acc: 90.000% (810/900)\n",
      "Test Epoch: 43 | Loss: 0.358 | Acc: 89.900% (899/1000)\n",
      "Test Epoch: 43 | Loss: 0.366 | Acc: 89.545% (985/1100)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 89.167% (1070/1200)\n",
      "Test Epoch: 43 | Loss: 0.369 | Acc: 89.308% (1161/1300)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 89.000% (1246/1400)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 88.800% (1332/1500)\n",
      "Test Epoch: 43 | Loss: 0.381 | Acc: 88.688% (1419/1600)\n",
      "Test Epoch: 43 | Loss: 0.380 | Acc: 88.647% (1507/1700)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 88.722% (1597/1800)\n",
      "Test Epoch: 43 | Loss: 0.383 | Acc: 88.579% (1683/1900)\n",
      "Test Epoch: 43 | Loss: 0.403 | Acc: 88.250% (1765/2000)\n",
      "Test Epoch: 43 | Loss: 0.409 | Acc: 88.095% (1850/2100)\n",
      "Test Epoch: 43 | Loss: 0.407 | Acc: 88.000% (1936/2200)\n",
      "Test Epoch: 43 | Loss: 0.401 | Acc: 88.174% (2028/2300)\n",
      "Test Epoch: 43 | Loss: 0.397 | Acc: 88.208% (2117/2400)\n",
      "Test Epoch: 43 | Loss: 0.417 | Acc: 87.960% (2199/2500)\n",
      "Test Epoch: 43 | Loss: 0.428 | Acc: 87.846% (2284/2600)\n",
      "Test Epoch: 43 | Loss: 0.427 | Acc: 87.889% (2373/2700)\n",
      "Test Epoch: 43 | Loss: 0.423 | Acc: 88.036% (2465/2800)\n",
      "Test Epoch: 43 | Loss: 0.428 | Acc: 88.069% (2554/2900)\n",
      "Test Epoch: 43 | Loss: 0.433 | Acc: 87.967% (2639/3000)\n",
      "Test Epoch: 43 | Loss: 0.433 | Acc: 88.032% (2729/3100)\n",
      "Test Epoch: 43 | Loss: 0.428 | Acc: 88.062% (2818/3200)\n",
      "Test Epoch: 43 | Loss: 0.431 | Acc: 87.909% (2901/3300)\n",
      "Test Epoch: 43 | Loss: 0.428 | Acc: 87.941% (2990/3400)\n",
      "Test Epoch: 43 | Loss: 0.434 | Acc: 87.829% (3074/3500)\n",
      "Test Epoch: 43 | Loss: 0.438 | Acc: 87.833% (3162/3600)\n",
      "Test Epoch: 43 | Loss: 0.440 | Acc: 87.865% (3251/3700)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.789% (3336/3800)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.872% (3427/3900)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.925% (3517/4000)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.951% (3606/4100)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.881% (3691/4200)\n",
      "Test Epoch: 43 | Loss: 0.441 | Acc: 88.000% (3784/4300)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 88.045% (3874/4400)\n",
      "Test Epoch: 43 | Loss: 0.441 | Acc: 88.111% (3965/4500)\n",
      "Test Epoch: 43 | Loss: 0.439 | Acc: 88.087% (4052/4600)\n",
      "Test Epoch: 43 | Loss: 0.439 | Acc: 88.000% (4136/4700)\n",
      "Test Epoch: 43 | Loss: 0.439 | Acc: 88.021% (4225/4800)\n",
      "Test Epoch: 43 | Loss: 0.437 | Acc: 88.061% (4315/4900)\n",
      "Test Epoch: 43 | Loss: 0.443 | Acc: 88.000% (4400/5000)\n",
      "Test Epoch: 43 | Loss: 0.440 | Acc: 88.059% (4491/5100)\n",
      "Test Epoch: 43 | Loss: 0.441 | Acc: 87.923% (4572/5200)\n",
      "Test Epoch: 43 | Loss: 0.443 | Acc: 87.830% (4655/5300)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.852% (4744/5400)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.800% (4829/5500)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.804% (4917/5600)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.807% (5005/5700)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.914% (5099/5800)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.847% (5183/5900)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.817% (5269/6000)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.803% (5356/6100)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.790% (5443/6200)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.794% (5531/6300)\n",
      "Test Epoch: 43 | Loss: 0.441 | Acc: 87.766% (5617/6400)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.738% (5703/6500)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.667% (5786/6600)\n",
      "Test Epoch: 43 | Loss: 0.441 | Acc: 87.701% (5876/6700)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.632% (5959/6800)\n",
      "Test Epoch: 43 | Loss: 0.442 | Acc: 87.652% (6048/6900)\n",
      "Test Epoch: 43 | Loss: 0.443 | Acc: 87.643% (6135/7000)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.634% (6222/7100)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.597% (6307/7200)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.699% (6402/7300)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.743% (6493/7400)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.707% (6578/7500)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.737% (6668/7600)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.701% (6753/7700)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.628% (6835/7800)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.633% (6923/7900)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.625% (7010/8000)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.679% (7102/8100)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.671% (7189/8200)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.699% (7279/8300)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.643% (7362/8400)\n",
      "Test Epoch: 43 | Loss: 0.449 | Acc: 87.624% (7448/8500)\n",
      "Test Epoch: 43 | Loss: 0.453 | Acc: 87.535% (7528/8600)\n",
      "Test Epoch: 43 | Loss: 0.451 | Acc: 87.598% (7621/8700)\n",
      "Test Epoch: 43 | Loss: 0.452 | Acc: 87.602% (7709/8800)\n",
      "Test Epoch: 43 | Loss: 0.452 | Acc: 87.618% (7798/8900)\n",
      "Test Epoch: 43 | Loss: 0.451 | Acc: 87.622% (7886/9000)\n",
      "Test Epoch: 43 | Loss: 0.450 | Acc: 87.626% (7974/9100)\n",
      "Test Epoch: 43 | Loss: 0.448 | Acc: 87.685% (8067/9200)\n",
      "Test Epoch: 43 | Loss: 0.448 | Acc: 87.667% (8153/9300)\n",
      "Test Epoch: 43 | Loss: 0.448 | Acc: 87.660% (8240/9400)\n",
      "Test Epoch: 43 | Loss: 0.447 | Acc: 87.695% (8331/9500)\n",
      "Test Epoch: 43 | Loss: 0.446 | Acc: 87.708% (8420/9600)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.763% (8513/9700)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.765% (8601/9800)\n",
      "Test Epoch: 43 | Loss: 0.445 | Acc: 87.778% (8690/9900)\n",
      "Test Epoch: 43 | Loss: 0.444 | Acc: 87.810% (8781/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Train Epoch: 44 | Loss: 0.158 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 44 | Loss: 0.126 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 44 | Loss: 0.109 | Acc: 96.094% (369/384)\n",
      "Train Epoch: 44 | Loss: 0.161 | Acc: 94.336% (483/512)\n",
      "Train Epoch: 44 | Loss: 0.154 | Acc: 94.688% (606/640)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.182% (731/768)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.201% (853/896)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.215% (975/1024)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.312% (1098/1152)\n",
      "Train Epoch: 44 | Loss: 0.143 | Acc: 95.469% (1222/1280)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.384% (1343/1408)\n",
      "Train Epoch: 44 | Loss: 0.151 | Acc: 95.052% (1460/1536)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.252% (1585/1664)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.424% (1710/1792)\n",
      "Train Epoch: 44 | Loss: 0.147 | Acc: 95.312% (1830/1920)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.215% (1950/2048)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.221% (2072/2176)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.182% (2193/2304)\n",
      "Train Epoch: 44 | Loss: 0.152 | Acc: 95.148% (2314/2432)\n",
      "Train Epoch: 44 | Loss: 0.149 | Acc: 95.234% (2438/2560)\n",
      "Train Epoch: 44 | Loss: 0.148 | Acc: 95.275% (2561/2688)\n",
      "Train Epoch: 44 | Loss: 0.146 | Acc: 95.277% (2683/2816)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.346% (2807/2944)\n",
      "Train Epoch: 44 | Loss: 0.143 | Acc: 95.443% (2932/3072)\n",
      "Train Epoch: 44 | Loss: 0.142 | Acc: 95.406% (3053/3200)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.282% (3171/3328)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.197% (3290/3456)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.173% (3411/3584)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.124% (3531/3712)\n",
      "Train Epoch: 44 | Loss: 0.145 | Acc: 95.156% (3654/3840)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.186% (3777/3968)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.166% (3898/4096)\n",
      "Train Epoch: 44 | Loss: 0.144 | Acc: 95.147% (4019/4224)\n",
      "Train Epoch: 44 | Loss: 0.143 | Acc: 95.175% (4142/4352)\n",
      "Train Epoch: 44 | Loss: 0.143 | Acc: 95.156% (4263/4480)\n",
      "Train Epoch: 44 | Loss: 0.143 | Acc: 95.095% (4382/4608)\n",
      "Train Epoch: 44 | Loss: 0.142 | Acc: 95.101% (4504/4736)\n",
      "Train Epoch: 44 | Loss: 0.141 | Acc: 95.107% (4626/4864)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.192% (4752/4992)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.234% (4876/5120)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.293% (5001/5248)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.312% (5124/5376)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.331% (5247/5504)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.277% (5366/5632)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.260% (5487/5760)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.245% (5608/5888)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.229% (5729/6016)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.247% (5852/6144)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.265% (5975/6272)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.281% (6098/6400)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.282% (6220/6528)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.267% (6341/6656)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.268% (6463/6784)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.240% (6583/6912)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.284% (6708/7040)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.257% (6828/7168)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.244% (6949/7296)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.191% (7067/7424)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.207% (7190/7552)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.208% (7312/7680)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.223% (7435/7808)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.224% (7557/7936)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.238% (7680/8064)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.251% (7803/8192)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.204% (7921/8320)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.170% (8040/8448)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.149% (8160/8576)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.186% (8285/8704)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.188% (8407/8832)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.234% (8533/8960)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.268% (8658/9088)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.269% (8780/9216)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.291% (8904/9344)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.302% (9027/9472)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.281% (9147/9600)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.282% (9269/9728)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.292% (9392/9856)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.292% (9514/9984)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.283% (9635/10112)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.264% (9755/10240)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.284% (9879/10368)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.274% (10000/10496)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.275% (10122/10624)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.285% (10245/10752)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.239% (10362/10880)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.249% (10485/11008)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.268% (10609/11136)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.277% (10732/11264)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.277% (10854/11392)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.260% (10974/11520)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.287% (11099/11648)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.287% (11221/11776)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.329% (11348/11904)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.337% (11471/12032)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.354% (11595/12160)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.361% (11718/12288)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.377% (11842/12416)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.384% (11965/12544)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.399% (12089/12672)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.414% (12213/12800)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.413% (12335/12928)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.381% (12453/13056)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.388% (12576/13184)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.410% (12701/13312)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.417% (12824/13440)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.438% (12949/13568)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.459% (13074/13696)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.435% (13193/13824)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.420% (13313/13952)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.433% (13437/14080)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.446% (13561/14208)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.445% (13683/14336)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.451% (13806/14464)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.429% (13925/14592)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.421% (14046/14720)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.434% (14170/14848)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.406% (14288/14976)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.412% (14411/15104)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.411% (14533/15232)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.436% (14659/15360)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.448% (14783/15488)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.441% (14904/15616)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.459% (15029/15744)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.470% (15153/15872)\n",
      "Train Epoch: 44 | Loss: 0.131 | Acc: 95.475% (15276/16000)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.468% (15397/16128)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.454% (15517/16256)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.435% (15636/16384)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.428% (15757/16512)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.433% (15880/16640)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.426% (16001/16768)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.413% (16121/16896)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.418% (16244/17024)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.406% (16364/17152)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.405% (16486/17280)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.387% (16605/17408)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.404% (16730/17536)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.397% (16851/17664)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.408% (16975/17792)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.396% (17095/17920)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.396% (17217/18048)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.406% (17341/18176)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.389% (17460/18304)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.378% (17580/18432)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.393% (17705/18560)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.409% (17830/18688)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.419% (17954/18816)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.408% (18074/18944)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.391% (18193/19072)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.385% (18314/19200)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.395% (18438/19328)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.420% (18565/19456)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.415% (18686/19584)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.419% (18809/19712)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.423% (18932/19840)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.398% (19049/19968)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.367% (19165/20096)\n",
      "Train Epoch: 44 | Loss: 0.132 | Acc: 95.382% (19290/20224)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.371% (19410/20352)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.347% (19527/20480)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.342% (19648/20608)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.341% (19770/20736)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.341% (19892/20864)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.332% (20012/20992)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.322% (20132/21120)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.308% (20251/21248)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.303% (20372/21376)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.331% (20500/21504)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.322% (20620/21632)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.312% (20740/21760)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.317% (20863/21888)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.312% (20984/22016)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.303% (21104/22144)\n",
      "Train Epoch: 44 | Loss: 0.133 | Acc: 95.317% (21229/22272)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.312% (21350/22400)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.312% (21472/22528)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.317% (21595/22656)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.308% (21715/22784)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.282% (21831/22912)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.282% (21953/23040)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.282% (22075/23168)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.282% (22197/23296)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.278% (22318/23424)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.287% (22442/23552)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.283% (22563/23680)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.258% (22679/23808)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.275% (22805/23936)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.279% (22928/24064)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.259% (23045/24192)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.263% (23168/24320)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.259% (23289/24448)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.268% (23413/24576)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.268% (23535/24704)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.288% (23662/24832)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.296% (23786/24960)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.301% (23909/25088)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.316% (24035/25216)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.301% (24153/25344)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.301% (24275/25472)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.305% (24398/25600)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.324% (24525/25728)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.309% (24643/25856)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.297% (24762/25984)\n",
      "Train Epoch: 44 | Loss: 0.134 | Acc: 95.301% (24885/26112)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.290% (25004/26240)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.282% (25124/26368)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.275% (25244/26496)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.267% (25364/26624)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.256% (25483/26752)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.253% (25604/26880)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.257% (25727/27008)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.265% (25851/27136)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.257% (25971/27264)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.250% (26091/27392)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.254% (26214/27520)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.269% (26340/27648)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.262% (26460/27776)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.262% (26582/27904)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.263% (26704/28032)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.266% (26827/28160)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.259% (26947/28288)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.235% (27062/28416)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.246% (27187/28544)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.232% (27305/28672)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.236% (27428/28800)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.230% (27548/28928)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.226% (27669/29056)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.220% (27789/29184)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.227% (27913/29312)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.228% (28035/29440)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.238% (28160/29568)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.245% (28284/29696)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.232% (28402/29824)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.239% (28526/29952)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.249% (28651/30080)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.250% (28773/30208)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.250% (28895/30336)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.257% (29019/30464)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.263% (29143/30592)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.260% (29264/30720)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.270% (29389/30848)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.264% (29509/30976)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.274% (29634/31104)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.284% (29759/31232)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.297% (29885/31360)\n",
      "Train Epoch: 44 | Loss: 0.135 | Acc: 95.303% (30009/31488)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.303% (30131/31616)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.297% (30251/31744)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.291% (30371/31872)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.287% (30492/32000)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.288% (30614/32128)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.269% (30730/32256)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.279% (30855/32384)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.276% (30976/32512)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.279% (31099/32640)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.291% (31225/32768)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.279% (31343/32896)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.279% (31465/33024)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.276% (31586/33152)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.282% (31710/33280)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.289% (31834/33408)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.289% (31956/33536)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.295% (32080/33664)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.292% (32201/33792)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.289% (32322/33920)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.295% (32446/34048)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.298% (32569/34176)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.301% (32692/34304)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.315% (32819/34432)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.310% (32939/34560)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.307% (33060/34688)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.310% (33183/34816)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.312% (33306/34944)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.315% (33429/35072)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.298% (33545/35200)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.298% (33667/35328)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.298% (33789/35456)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.298% (33911/35584)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.301% (34034/35712)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.296% (34154/35840)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.296% (34276/35968)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.290% (34396/36096)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.282% (34515/36224)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.288% (34639/36352)\n",
      "Train Epoch: 44 | Loss: 0.136 | Acc: 95.282% (34759/36480)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.261% (34873/36608)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.253% (34992/36736)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.247% (35112/36864)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.245% (35233/36992)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.248% (35356/37120)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.229% (35471/37248)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.224% (35591/37376)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.233% (35716/37504)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.222% (35834/37632)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.225% (35957/37760)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.225% (36079/37888)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.231% (36203/38016)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.234% (36326/38144)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.245% (36452/38272)\n",
      "Train Epoch: 44 | Loss: 0.137 | Acc: 95.234% (36570/38400)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.224% (36688/38528)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.219% (36808/38656)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.225% (36932/38784)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.223% (37053/38912)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.220% (37174/39040)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.226% (37298/39168)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.226% (37420/39296)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.219% (37539/39424)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.221% (37662/39552)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.219% (37783/39680)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.220% (37905/39808)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.205% (38021/39936)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.195% (38139/40064)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.196% (38261/40192)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.201% (38385/40320)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.191% (38503/40448)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.194% (38626/40576)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.180% (38742/40704)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.178% (38863/40832)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.186% (38988/40960)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.191% (39112/41088)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.196% (39236/41216)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.194% (39357/41344)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.194% (39479/41472)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.192% (39600/41600)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.183% (39718/41728)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.181% (39839/41856)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.174% (39958/41984)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.175% (40080/42112)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.170% (40200/42240)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.169% (40321/42368)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.157% (40438/42496)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.160% (40561/42624)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.153% (40680/42752)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.145% (40798/42880)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.140% (40918/43008)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.143% (41041/43136)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.155% (41168/43264)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.156% (41290/43392)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.163% (41415/43520)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.173% (41541/43648)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.166% (41660/43776)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.169% (41783/43904)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.174% (41907/44032)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.170% (42027/44160)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.166% (42147/44288)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.164% (42268/44416)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.169% (42392/44544)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.176% (42517/44672)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.174% (42638/44800)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.183% (42764/44928)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.186% (42887/45056)\n",
      "Train Epoch: 44 | Loss: 0.138 | Acc: 95.193% (43012/45184)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.189% (43132/45312)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.185% (43252/45440)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.181% (43372/45568)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.183% (43495/45696)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.184% (43617/45824)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.180% (43737/45952)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.182% (43860/46080)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.170% (43976/46208)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.157% (44092/46336)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.158% (44214/46464)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.160% (44337/46592)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.152% (44455/46720)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.146% (44574/46848)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.144% (44695/46976)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.141% (44815/47104)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.143% (44938/47232)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.139% (45058/47360)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.140% (45180/47488)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.144% (45304/47616)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.147% (45427/47744)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.145% (45548/47872)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.138% (45666/48000)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.138% (45788/48128)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.130% (45906/48256)\n",
      "Train Epoch: 44 | Loss: 0.140 | Acc: 95.139% (46032/48384)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.146% (46157/48512)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.156% (46284/48640)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.159% (46407/48768)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.161% (46530/48896)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.155% (46649/49024)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.152% (46769/49152)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.148% (46889/49280)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.161% (47017/49408)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.161% (47139/49536)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.157% (47259/49664)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.158% (47381/49792)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.146% (47497/49920)\n",
      "Train Epoch: 44 | Loss: 0.139 | Acc: 95.144% (47572/50000)\n",
      "Test Epoch: 44 | Loss: 0.464 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 44 | Loss: 0.374 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 44 | Loss: 0.410 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 44 | Loss: 0.408 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 44 | Loss: 0.371 | Acc: 89.286% (625/700)\n",
      "Test Epoch: 44 | Loss: 0.405 | Acc: 88.500% (708/800)\n",
      "Test Epoch: 44 | Loss: 0.423 | Acc: 88.111% (793/900)\n",
      "Test Epoch: 44 | Loss: 0.423 | Acc: 87.900% (879/1000)\n",
      "Test Epoch: 44 | Loss: 0.449 | Acc: 87.545% (963/1100)\n",
      "Test Epoch: 44 | Loss: 0.454 | Acc: 87.417% (1049/1200)\n",
      "Test Epoch: 44 | Loss: 0.444 | Acc: 87.615% (1139/1300)\n",
      "Test Epoch: 44 | Loss: 0.435 | Acc: 87.714% (1228/1400)\n",
      "Test Epoch: 44 | Loss: 0.429 | Acc: 87.800% (1317/1500)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.125% (1410/1600)\n",
      "Test Epoch: 44 | Loss: 0.419 | Acc: 88.235% (1500/1700)\n",
      "Test Epoch: 44 | Loss: 0.421 | Acc: 88.111% (1586/1800)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.211% (1676/1900)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.000% (1760/2000)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 87.667% (1841/2100)\n",
      "Test Epoch: 44 | Loss: 0.431 | Acc: 87.636% (1928/2200)\n",
      "Test Epoch: 44 | Loss: 0.427 | Acc: 87.565% (2014/2300)\n",
      "Test Epoch: 44 | Loss: 0.427 | Acc: 87.667% (2104/2400)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 87.560% (2189/2500)\n",
      "Test Epoch: 44 | Loss: 0.444 | Acc: 87.538% (2276/2600)\n",
      "Test Epoch: 44 | Loss: 0.435 | Acc: 87.815% (2371/2700)\n",
      "Test Epoch: 44 | Loss: 0.430 | Acc: 87.821% (2459/2800)\n",
      "Test Epoch: 44 | Loss: 0.431 | Acc: 87.897% (2549/2900)\n",
      "Test Epoch: 44 | Loss: 0.433 | Acc: 87.833% (2635/3000)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 87.871% (2724/3100)\n",
      "Test Epoch: 44 | Loss: 0.433 | Acc: 87.906% (2813/3200)\n",
      "Test Epoch: 44 | Loss: 0.432 | Acc: 87.909% (2901/3300)\n",
      "Test Epoch: 44 | Loss: 0.430 | Acc: 88.029% (2993/3400)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 87.914% (3077/3500)\n",
      "Test Epoch: 44 | Loss: 0.438 | Acc: 88.000% (3168/3600)\n",
      "Test Epoch: 44 | Loss: 0.441 | Acc: 88.000% (3256/3700)\n",
      "Test Epoch: 44 | Loss: 0.440 | Acc: 88.026% (3345/3800)\n",
      "Test Epoch: 44 | Loss: 0.438 | Acc: 88.103% (3436/3900)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 88.100% (3524/4000)\n",
      "Test Epoch: 44 | Loss: 0.440 | Acc: 88.024% (3609/4100)\n",
      "Test Epoch: 44 | Loss: 0.443 | Acc: 88.024% (3697/4200)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 88.163% (3791/4300)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 88.273% (3884/4400)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.378% (3977/4500)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.370% (4065/4600)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.383% (4154/4700)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.396% (4243/4800)\n",
      "Test Epoch: 44 | Loss: 0.431 | Acc: 88.490% (4336/4900)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.400% (4420/5000)\n",
      "Test Epoch: 44 | Loss: 0.431 | Acc: 88.490% (4513/5100)\n",
      "Test Epoch: 44 | Loss: 0.433 | Acc: 88.442% (4599/5200)\n",
      "Test Epoch: 44 | Loss: 0.435 | Acc: 88.340% (4682/5300)\n",
      "Test Epoch: 44 | Loss: 0.433 | Acc: 88.389% (4773/5400)\n",
      "Test Epoch: 44 | Loss: 0.433 | Acc: 88.291% (4856/5500)\n",
      "Test Epoch: 44 | Loss: 0.436 | Acc: 88.214% (4940/5600)\n",
      "Test Epoch: 44 | Loss: 0.434 | Acc: 88.263% (5031/5700)\n",
      "Test Epoch: 44 | Loss: 0.432 | Acc: 88.276% (5120/5800)\n",
      "Test Epoch: 44 | Loss: 0.432 | Acc: 88.288% (5209/5900)\n",
      "Test Epoch: 44 | Loss: 0.430 | Acc: 88.317% (5299/6000)\n",
      "Test Epoch: 44 | Loss: 0.426 | Acc: 88.393% (5392/6100)\n",
      "Test Epoch: 44 | Loss: 0.427 | Acc: 88.387% (5480/6200)\n",
      "Test Epoch: 44 | Loss: 0.425 | Acc: 88.429% (5571/6300)\n",
      "Test Epoch: 44 | Loss: 0.422 | Acc: 88.500% (5664/6400)\n",
      "Test Epoch: 44 | Loss: 0.420 | Acc: 88.492% (5752/6500)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.545% (5844/6600)\n",
      "Test Epoch: 44 | Loss: 0.415 | Acc: 88.627% (5938/6700)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.588% (6024/6800)\n",
      "Test Epoch: 44 | Loss: 0.416 | Acc: 88.638% (6116/6900)\n",
      "Test Epoch: 44 | Loss: 0.416 | Acc: 88.600% (6202/7000)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.606% (6291/7100)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.611% (6380/7200)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.630% (6470/7300)\n",
      "Test Epoch: 44 | Loss: 0.419 | Acc: 88.568% (6554/7400)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.600% (6645/7500)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.618% (6735/7600)\n",
      "Test Epoch: 44 | Loss: 0.419 | Acc: 88.636% (6825/7700)\n",
      "Test Epoch: 44 | Loss: 0.419 | Acc: 88.603% (6911/7800)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.620% (7001/7900)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.600% (7088/8000)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.605% (7177/8100)\n",
      "Test Epoch: 44 | Loss: 0.415 | Acc: 88.646% (7269/8200)\n",
      "Test Epoch: 44 | Loss: 0.414 | Acc: 88.651% (7358/8300)\n",
      "Test Epoch: 44 | Loss: 0.416 | Acc: 88.643% (7446/8400)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.588% (7530/8500)\n",
      "Test Epoch: 44 | Loss: 0.420 | Acc: 88.547% (7615/8600)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.575% (7706/8700)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.580% (7795/8800)\n",
      "Test Epoch: 44 | Loss: 0.418 | Acc: 88.573% (7883/8900)\n",
      "Test Epoch: 44 | Loss: 0.419 | Acc: 88.578% (7972/9000)\n",
      "Test Epoch: 44 | Loss: 0.417 | Acc: 88.582% (8061/9100)\n",
      "Test Epoch: 44 | Loss: 0.416 | Acc: 88.630% (8154/9200)\n",
      "Test Epoch: 44 | Loss: 0.415 | Acc: 88.634% (8243/9300)\n",
      "Test Epoch: 44 | Loss: 0.415 | Acc: 88.681% (8336/9400)\n",
      "Test Epoch: 44 | Loss: 0.415 | Acc: 88.705% (8427/9500)\n",
      "Test Epoch: 44 | Loss: 0.413 | Acc: 88.750% (8520/9600)\n",
      "Test Epoch: 44 | Loss: 0.411 | Acc: 88.784% (8612/9700)\n",
      "Test Epoch: 44 | Loss: 0.412 | Acc: 88.755% (8698/9800)\n",
      "Test Epoch: 44 | Loss: 0.413 | Acc: 88.768% (8788/9900)\n",
      "Test Epoch: 44 | Loss: 0.412 | Acc: 88.780% (8878/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Epoch: 45 | Loss: 0.103 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 45 | Loss: 0.101 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 45 | Loss: 0.124 | Acc: 94.531% (363/384)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 94.531% (484/512)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 94.531% (605/640)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 94.531% (726/768)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 94.978% (851/896)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.312% (976/1024)\n",
      "Train Epoch: 45 | Loss: 0.126 | Acc: 95.486% (1100/1152)\n",
      "Train Epoch: 45 | Loss: 0.122 | Acc: 95.703% (1225/1280)\n",
      "Train Epoch: 45 | Loss: 0.121 | Acc: 95.810% (1349/1408)\n",
      "Train Epoch: 45 | Loss: 0.126 | Acc: 95.768% (1471/1536)\n",
      "Train Epoch: 45 | Loss: 0.127 | Acc: 95.493% (1589/1664)\n",
      "Train Epoch: 45 | Loss: 0.126 | Acc: 95.536% (1712/1792)\n",
      "Train Epoch: 45 | Loss: 0.129 | Acc: 95.469% (1833/1920)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.459% (1955/2048)\n",
      "Train Epoch: 45 | Loss: 0.127 | Acc: 95.542% (2079/2176)\n",
      "Train Epoch: 45 | Loss: 0.126 | Acc: 95.530% (2201/2304)\n",
      "Train Epoch: 45 | Loss: 0.128 | Acc: 95.600% (2325/2432)\n",
      "Train Epoch: 45 | Loss: 0.127 | Acc: 95.664% (2449/2560)\n",
      "Train Epoch: 45 | Loss: 0.127 | Acc: 95.573% (2569/2688)\n",
      "Train Epoch: 45 | Loss: 0.128 | Acc: 95.526% (2690/2816)\n",
      "Train Epoch: 45 | Loss: 0.128 | Acc: 95.550% (2813/2944)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.475% (2933/3072)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.531% (3057/3200)\n",
      "Train Epoch: 45 | Loss: 0.129 | Acc: 95.553% (3180/3328)\n",
      "Train Epoch: 45 | Loss: 0.128 | Acc: 95.544% (3302/3456)\n",
      "Train Epoch: 45 | Loss: 0.128 | Acc: 95.564% (3425/3584)\n",
      "Train Epoch: 45 | Loss: 0.129 | Acc: 95.501% (3545/3712)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.495% (3667/3840)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.413% (3786/3968)\n",
      "Train Epoch: 45 | Loss: 0.129 | Acc: 95.435% (3909/4096)\n",
      "Train Epoch: 45 | Loss: 0.129 | Acc: 95.431% (4031/4224)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.381% (4151/4352)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.268% (4268/4480)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.312% (4392/4608)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.334% (4515/4736)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.333% (4637/4864)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.373% (4761/4992)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.430% (4886/5120)\n",
      "Train Epoch: 45 | Loss: 0.130 | Acc: 95.484% (5011/5248)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.424% (5130/5376)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.331% (5247/5504)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.312% (5368/5632)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.278% (5488/5760)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.279% (5610/5888)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.246% (5730/6016)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.280% (5854/6144)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.312% (5978/6272)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.281% (6098/6400)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.236% (6217/6528)\n",
      "Train Epoch: 45 | Loss: 0.137 | Acc: 95.237% (6339/6656)\n",
      "Train Epoch: 45 | Loss: 0.137 | Acc: 95.224% (6460/6784)\n",
      "Train Epoch: 45 | Loss: 0.137 | Acc: 95.226% (6582/6912)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.284% (6708/7040)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.326% (6833/7168)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.340% (6956/7296)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.353% (7079/7424)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.339% (7200/7552)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.365% (7324/7680)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.402% (7449/7808)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.413% (7572/7936)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.424% (7695/8064)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.410% (7816/8192)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.397% (7937/8320)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.431% (8062/8448)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.464% (8187/8576)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.485% (8311/8704)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.471% (8432/8832)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.491% (8556/8960)\n",
      "Train Epoch: 45 | Loss: 0.131 | Acc: 95.489% (8678/9088)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.486% (8800/9216)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.473% (8921/9344)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.471% (9043/9472)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.479% (9166/9600)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.477% (9288/9728)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.455% (9408/9856)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.423% (9527/9984)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.451% (9652/10112)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.400% (9769/10240)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.419% (9893/10368)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.398% (10013/10496)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.388% (10134/10624)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.340% (10251/10752)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.340% (10373/10880)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.340% (10495/11008)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.348% (10618/11136)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.366% (10742/11264)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.330% (10860/11392)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.365% (10986/11520)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.373% (11109/11648)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.380% (11232/11776)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.388% (11355/11904)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.362% (11474/12032)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.362% (11596/12160)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (11721/12288)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.393% (11844/12416)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.416% (11969/12544)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.376% (12086/12672)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.391% (12210/12800)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.405% (12334/12928)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.412% (12457/13056)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.419% (12580/13184)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.395% (12699/13312)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.424% (12825/13440)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.379% (12941/13568)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.400% (13066/13696)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.356% (13182/13824)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.348% (13303/13952)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.348% (13425/14080)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.355% (13548/14208)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.333% (13667/14336)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.326% (13788/14464)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.333% (13911/14592)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.333% (14033/14720)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.353% (14158/14848)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.359% (14281/14976)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.359% (14403/15104)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.372% (14527/15232)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.358% (14647/15360)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.351% (14768/15488)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.325% (14886/15616)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.351% (15012/15744)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.363% (15136/15872)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.369% (15259/16000)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.387% (15384/16128)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (15506/16256)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.404% (15631/16384)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.422% (15756/16512)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.421% (15878/16640)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.420% (16000/16768)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.431% (16124/16896)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.453% (16250/17024)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.429% (16368/17152)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.434% (16491/17280)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.427% (16612/17408)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.421% (16733/17536)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.397% (16851/17664)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.402% (16974/17792)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.385% (17093/17920)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.373% (17213/18048)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.384% (17337/18176)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.405% (17463/18304)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.399% (17584/18432)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.404% (17707/18560)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.403% (17829/18688)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.387% (17948/18816)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (18070/18944)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.396% (18194/19072)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.406% (18318/19200)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.416% (18442/19328)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.400% (18561/19456)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.384% (18680/19584)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.378% (18801/19712)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.373% (18922/19840)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.378% (19045/19968)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.392% (19170/20096)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.397% (19293/20224)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (19413/20352)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.381% (19534/20480)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.376% (19655/20608)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.390% (19780/20736)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.394% (19903/20864)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.398% (20026/20992)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.398% (20148/21120)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.388% (20268/21248)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.392% (20391/21376)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.392% (20513/21504)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.382% (20633/21632)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (20756/21760)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.408% (20883/21888)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.399% (21003/22016)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.380% (21121/22144)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.371% (21241/22272)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.371% (21363/22400)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.357% (21482/22528)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.352% (21603/22656)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.365% (21728/22784)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.365% (21850/22912)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.369% (21973/23040)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.373% (22096/23168)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.364% (22216/23296)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.372% (22340/23424)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.376% (22463/23552)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.372% (22584/23680)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.380% (22708/23808)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.384% (22831/23936)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.375% (22951/24064)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.387% (23076/24192)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.387% (23198/24320)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.398% (23323/24448)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.398% (23445/24576)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.393% (23566/24704)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.397% (23689/24832)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.393% (23810/24960)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.396% (23933/25088)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.396% (24055/25216)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.399% (24178/25344)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.395% (24299/25472)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.398% (24422/25600)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (24541/25728)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.390% (24664/25856)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.401% (24789/25984)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.404% (24912/26112)\n",
      "Train Epoch: 45 | Loss: 0.132 | Acc: 95.415% (25037/26240)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.407% (25157/26368)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.411% (25280/26496)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.414% (25403/26624)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.398% (25521/26752)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.406% (25645/26880)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.398% (25765/27008)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.383% (25883/27136)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.386% (26006/27264)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.393% (26130/27392)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.382% (26249/27520)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.385% (26372/27648)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.388% (26495/27776)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.370% (26612/27904)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.355% (26730/28032)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.369% (26856/28160)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.355% (26974/28288)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.344% (27093/28416)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.327% (27210/28544)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (27334/28672)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.330% (27455/28800)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (27578/28928)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.340% (27702/29056)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.347% (27826/29184)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (27944/29312)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (28066/29440)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.336% (28189/29568)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.336% (28311/29696)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (28432/29824)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.319% (28550/29952)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.316% (28671/30080)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.326% (28796/30208)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.332% (28920/30336)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.339% (29044/30464)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.326% (29162/30592)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.326% (29284/30720)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.329% (29407/30848)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.342% (29533/30976)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.329% (29651/31104)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.322% (29771/31232)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.325% (29894/31360)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.328% (30017/31488)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.319% (30136/31616)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.322% (30259/31744)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.322% (30381/31872)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.319% (30502/32000)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.325% (30626/32128)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.309% (30743/32256)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.306% (30864/32384)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (30983/32512)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (31105/32640)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.294% (31226/32768)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.282% (31344/32896)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.279% (31465/33024)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.285% (31589/33152)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (31715/33280)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.292% (31835/33408)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.301% (31960/33536)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.310% (32085/33664)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.307% (32206/33792)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.307% (32328/33920)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.304% (32449/34048)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.298% (32569/34176)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.301% (32692/34304)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.304% (32815/34432)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.298% (32935/34560)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.292% (33055/34688)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.298% (33179/34816)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.292% (33299/34944)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.275% (33415/35072)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.278% (33538/35200)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.281% (33661/35328)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.284% (33784/35456)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.284% (33906/35584)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.290% (34030/35712)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.293% (34153/35840)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.290% (34274/35968)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.288% (34395/36096)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.288% (34517/36224)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.293% (34641/36352)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.291% (34762/36480)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.282% (34881/36608)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.283% (35003/36736)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.285% (35126/36864)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.283% (35247/36992)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.283% (35369/37120)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.294% (35495/37248)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.288% (35615/37376)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.299% (35741/37504)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.297% (35862/37632)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.299% (35985/37760)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.297% (36106/37888)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.286% (36224/38016)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.286% (36346/38144)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.286% (36468/38272)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.284% (36589/38400)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.281% (36710/38528)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.279% (36831/38656)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.271% (36950/38784)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.277% (37074/38912)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.282% (37198/39040)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.282% (37320/39168)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.290% (37445/39296)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (37570/39424)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.300% (37693/39552)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (37814/39680)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.297% (37936/39808)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.290% (38055/39936)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.280% (38173/40064)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.285% (38297/40192)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.278% (38416/40320)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.278% (38538/40448)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.278% (38660/40576)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.276% (38781/40704)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.278% (38904/40832)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.281% (39027/40960)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.276% (39147/41088)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.271% (39267/41216)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.281% (39393/41344)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.288% (39518/41472)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.281% (39637/41600)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.279% (39758/41728)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.260% (39872/41856)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.267% (39997/41984)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.263% (40117/42112)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.265% (40240/42240)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.263% (40361/42368)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.261% (40482/42496)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.263% (40605/42624)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.261% (40726/42752)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.266% (40850/42880)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.261% (40970/43008)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.257% (41090/43136)\n",
      "Train Epoch: 45 | Loss: 0.136 | Acc: 95.257% (41212/43264)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.257% (41334/43392)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.262% (41458/43520)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.267% (41582/43648)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.271% (41706/43776)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.256% (41821/43904)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.253% (41942/44032)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.256% (42065/44160)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.256% (42187/44288)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.258% (42310/44416)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.252% (42429/44544)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.259% (42554/44672)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.259% (42676/44800)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.266% (42801/44928)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.264% (42922/45056)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.268% (43046/45184)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.273% (43170/45312)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.284% (43297/45440)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.284% (43419/45568)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.288% (43543/45696)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.293% (43667/45824)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.297% (43791/45952)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.293% (43911/46080)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.284% (44029/46208)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.282% (44150/46336)\n",
      "Train Epoch: 45 | Loss: 0.135 | Acc: 95.285% (44273/46464)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.291% (44398/46592)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.300% (44524/46720)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.293% (44643/46848)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.298% (44767/46976)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.302% (44891/47104)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.304% (45014/47232)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.312% (45140/47360)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.321% (45266/47488)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.323% (45389/47616)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.325% (45512/47744)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.325% (45634/47872)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.327% (45757/48000)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (45882/48128)\n",
      "Train Epoch: 45 | Loss: 0.134 | Acc: 95.333% (46004/48256)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.335% (46127/48384)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.341% (46252/48512)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.345% (46376/48640)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.351% (46501/48768)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.355% (46625/48896)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.363% (46751/49024)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.361% (46872/49152)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.359% (46993/49280)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.365% (47118/49408)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.377% (47246/49536)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.377% (47368/49664)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.379% (47491/49792)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.377% (47612/49920)\n",
      "Train Epoch: 45 | Loss: 0.133 | Acc: 95.382% (47691/50000)\n",
      "Test Epoch: 45 | Loss: 0.352 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 45 | Loss: 0.377 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 45 | Loss: 0.336 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 45 | Loss: 0.349 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 45 | Loss: 0.318 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 45 | Loss: 0.286 | Acc: 91.000% (546/600)\n",
      "Test Epoch: 45 | Loss: 0.302 | Acc: 91.000% (637/700)\n",
      "Test Epoch: 45 | Loss: 0.329 | Acc: 90.125% (721/800)\n",
      "Test Epoch: 45 | Loss: 0.340 | Acc: 89.778% (808/900)\n",
      "Test Epoch: 45 | Loss: 0.331 | Acc: 90.100% (901/1000)\n",
      "Test Epoch: 45 | Loss: 0.349 | Acc: 89.636% (986/1100)\n",
      "Test Epoch: 45 | Loss: 0.354 | Acc: 89.417% (1073/1200)\n",
      "Test Epoch: 45 | Loss: 0.354 | Acc: 89.462% (1163/1300)\n",
      "Test Epoch: 45 | Loss: 0.361 | Acc: 89.214% (1249/1400)\n",
      "Test Epoch: 45 | Loss: 0.357 | Acc: 89.133% (1337/1500)\n",
      "Test Epoch: 45 | Loss: 0.352 | Acc: 89.312% (1429/1600)\n",
      "Test Epoch: 45 | Loss: 0.348 | Acc: 89.588% (1523/1700)\n",
      "Test Epoch: 45 | Loss: 0.346 | Acc: 89.556% (1612/1800)\n",
      "Test Epoch: 45 | Loss: 0.348 | Acc: 89.368% (1698/1900)\n",
      "Test Epoch: 45 | Loss: 0.370 | Acc: 89.150% (1783/2000)\n",
      "Test Epoch: 45 | Loss: 0.379 | Acc: 88.905% (1867/2100)\n",
      "Test Epoch: 45 | Loss: 0.380 | Acc: 88.818% (1954/2200)\n",
      "Test Epoch: 45 | Loss: 0.374 | Acc: 89.000% (2047/2300)\n",
      "Test Epoch: 45 | Loss: 0.368 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 45 | Loss: 0.384 | Acc: 89.040% (2226/2500)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 88.962% (2313/2600)\n",
      "Test Epoch: 45 | Loss: 0.388 | Acc: 89.000% (2403/2700)\n",
      "Test Epoch: 45 | Loss: 0.388 | Acc: 89.000% (2492/2800)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 88.966% (2580/2900)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 88.967% (2669/3000)\n",
      "Test Epoch: 45 | Loss: 0.386 | Acc: 88.903% (2756/3100)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 88.844% (2843/3200)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 88.758% (2929/3300)\n",
      "Test Epoch: 45 | Loss: 0.386 | Acc: 88.824% (3020/3400)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 88.771% (3107/3500)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 88.806% (3197/3600)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 88.865% (3288/3700)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 88.868% (3377/3800)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 88.923% (3468/3900)\n",
      "Test Epoch: 45 | Loss: 0.399 | Acc: 89.000% (3560/4000)\n",
      "Test Epoch: 45 | Loss: 0.405 | Acc: 88.927% (3646/4100)\n",
      "Test Epoch: 45 | Loss: 0.407 | Acc: 88.881% (3733/4200)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 89.047% (3829/4300)\n",
      "Test Epoch: 45 | Loss: 0.405 | Acc: 89.091% (3920/4400)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 89.200% (4014/4500)\n",
      "Test Epoch: 45 | Loss: 0.398 | Acc: 89.217% (4104/4600)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 89.191% (4192/4700)\n",
      "Test Epoch: 45 | Loss: 0.398 | Acc: 89.146% (4279/4800)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 89.286% (4375/4900)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 89.200% (4460/5000)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 89.294% (4554/5100)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 89.192% (4638/5200)\n",
      "Test Epoch: 45 | Loss: 0.398 | Acc: 89.132% (4724/5300)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 89.185% (4816/5400)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 89.182% (4905/5500)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 89.214% (4996/5600)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 89.211% (5085/5700)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 89.259% (5177/5800)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 89.254% (5266/5900)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 89.233% (5354/6000)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 89.246% (5444/6100)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 89.258% (5534/6200)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 89.333% (5628/6300)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.406% (5722/6400)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.415% (5812/6500)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.470% (5905/6600)\n",
      "Test Epoch: 45 | Loss: 0.385 | Acc: 89.522% (5998/6700)\n",
      "Test Epoch: 45 | Loss: 0.386 | Acc: 89.485% (6085/6800)\n",
      "Test Epoch: 45 | Loss: 0.385 | Acc: 89.522% (6177/6900)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.514% (6266/7000)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.507% (6355/7100)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 89.472% (6442/7200)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.507% (6534/7300)\n",
      "Test Epoch: 45 | Loss: 0.388 | Acc: 89.527% (6625/7400)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.533% (6715/7500)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.566% (6807/7600)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 89.545% (6895/7700)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 89.487% (6980/7800)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.506% (7071/7900)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.475% (7158/8000)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.531% (7252/8100)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.512% (7340/8200)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.482% (7427/8300)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.452% (7514/8400)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 89.435% (7602/8500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 89.384% (7687/8600)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.414% (7779/8700)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 89.409% (7868/8800)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 89.382% (7955/8900)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 89.356% (8042/9000)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 89.363% (8132/9100)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.402% (8225/9200)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 89.409% (8315/9300)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.426% (8406/9400)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 89.453% (8498/9500)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.469% (8589/9600)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.474% (8679/9700)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.469% (8768/9800)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 89.475% (8858/9900)\n",
      "Test Epoch: 45 | Loss: 0.387 | Acc: 89.500% (8950/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 46\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 98.438% (126/128)\n",
      "Train Epoch: 46 | Loss: 0.100 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 96.615% (371/384)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 96.094% (492/512)\n",
      "Train Epoch: 46 | Loss: 0.146 | Acc: 95.625% (612/640)\n",
      "Train Epoch: 46 | Loss: 0.138 | Acc: 95.833% (736/768)\n",
      "Train Epoch: 46 | Loss: 0.138 | Acc: 95.759% (858/896)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.898% (982/1024)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 96.007% (1106/1152)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.859% (1227/1280)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.739% (1348/1408)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.443% (1466/1536)\n",
      "Train Epoch: 46 | Loss: 0.121 | Acc: 95.553% (1590/1664)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.759% (1716/1792)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.729% (1838/1920)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.752% (1961/2048)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.818% (2085/2176)\n",
      "Train Epoch: 46 | Loss: 0.113 | Acc: 96.007% (2212/2304)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.888% (2332/2432)\n",
      "Train Epoch: 46 | Loss: 0.119 | Acc: 95.898% (2455/2560)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.908% (2578/2688)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.987% (2703/2816)\n",
      "Train Epoch: 46 | Loss: 0.114 | Acc: 96.060% (2828/2944)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.931% (2947/3072)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.906% (3069/3200)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.974% (3194/3328)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.978% (3317/3456)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.010% (3441/3584)\n",
      "Train Epoch: 46 | Loss: 0.114 | Acc: 96.067% (3566/3712)\n",
      "Train Epoch: 46 | Loss: 0.112 | Acc: 96.120% (3691/3840)\n",
      "Train Epoch: 46 | Loss: 0.113 | Acc: 96.069% (3812/3968)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.045% (3934/4096)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.046% (4057/4224)\n",
      "Train Epoch: 46 | Loss: 0.114 | Acc: 96.117% (4183/4352)\n",
      "Train Epoch: 46 | Loss: 0.113 | Acc: 96.183% (4309/4480)\n",
      "Train Epoch: 46 | Loss: 0.111 | Acc: 96.246% (4435/4608)\n",
      "Train Epoch: 46 | Loss: 0.111 | Acc: 96.199% (4556/4736)\n",
      "Train Epoch: 46 | Loss: 0.113 | Acc: 95.991% (4669/4864)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.893% (4787/4992)\n",
      "Train Epoch: 46 | Loss: 0.114 | Acc: 95.898% (4910/5120)\n",
      "Train Epoch: 46 | Loss: 0.114 | Acc: 95.865% (5031/5248)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.852% (5153/5376)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.858% (5276/5504)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.863% (5399/5632)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.851% (5521/5760)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.907% (5647/5888)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.878% (5768/6016)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.850% (5889/6144)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.855% (6012/6272)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.844% (6134/6400)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.803% (6254/6528)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.748% (6373/6656)\n",
      "Train Epoch: 46 | Loss: 0.119 | Acc: 95.769% (6497/6784)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.790% (6621/6912)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.810% (6745/7040)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.829% (6869/7168)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.833% (6992/7296)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.865% (7117/7424)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.882% (7241/7552)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.898% (7365/7680)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.902% (7488/7808)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.905% (7611/7936)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.883% (7732/8064)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.911% (7857/8192)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.962% (7984/8320)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 95.975% (8108/8448)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.000% (8233/8576)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.002% (8356/8704)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.026% (8481/8832)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.004% (8602/8960)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.028% (8727/9088)\n",
      "Train Epoch: 46 | Loss: 0.115 | Acc: 96.018% (8849/9216)\n",
      "Train Epoch: 46 | Loss: 0.116 | Acc: 95.944% (8965/9344)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.893% (9083/9472)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.896% (9206/9600)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.929% (9332/9728)\n",
      "Train Epoch: 46 | Loss: 0.117 | Acc: 95.942% (9456/9856)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.903% (9575/9984)\n",
      "Train Epoch: 46 | Loss: 0.118 | Acc: 95.876% (9695/10112)\n",
      "Train Epoch: 46 | Loss: 0.119 | Acc: 95.869% (9817/10240)\n",
      "Train Epoch: 46 | Loss: 0.120 | Acc: 95.833% (9936/10368)\n",
      "Train Epoch: 46 | Loss: 0.120 | Acc: 95.837% (10059/10496)\n",
      "Train Epoch: 46 | Loss: 0.120 | Acc: 95.811% (10179/10624)\n",
      "Train Epoch: 46 | Loss: 0.120 | Acc: 95.824% (10303/10752)\n",
      "Train Epoch: 46 | Loss: 0.121 | Acc: 95.754% (10418/10880)\n",
      "Train Epoch: 46 | Loss: 0.121 | Acc: 95.730% (10538/11008)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.708% (10658/11136)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.676% (10777/11264)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.699% (10902/11392)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.686% (11023/11520)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.707% (11148/11648)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.729% (11273/11776)\n",
      "Train Epoch: 46 | Loss: 0.121 | Acc: 95.724% (11395/11904)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.645% (11508/12032)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.633% (11629/12160)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.630% (11751/12288)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.651% (11876/12416)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.671% (12001/12544)\n",
      "Train Epoch: 46 | Loss: 0.122 | Acc: 95.668% (12123/12672)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.594% (12236/12800)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.599% (12359/12928)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.596% (12481/13056)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.593% (12603/13184)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.590% (12725/13312)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.595% (12848/13440)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.593% (12970/13568)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.583% (13091/13696)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.558% (13210/13824)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.563% (13333/13952)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.575% (13457/14080)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.594% (13582/14208)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.598% (13705/14336)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.589% (13826/14464)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.580% (13947/14592)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.577% (14069/14720)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.589% (14193/14848)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.606% (14318/14976)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.597% (14439/15104)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.575% (14558/15232)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.579% (14681/15360)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.564% (14801/15488)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.581% (14926/15616)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.605% (15052/15744)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.609% (15175/15872)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.619% (15299/16000)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.635% (15424/16128)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.639% (15547/16256)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.636% (15669/16384)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.652% (15794/16512)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.667% (15919/16640)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.682% (16044/16768)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.685% (16167/16896)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.688% (16290/17024)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.697% (16414/17152)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.700% (16537/17280)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.703% (16660/17408)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.677% (16778/17536)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.675% (16900/17664)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.667% (17021/17792)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.675% (17145/17920)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.678% (17268/18048)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.681% (17391/18176)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.668% (17511/18304)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.676% (17635/18432)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.684% (17759/18560)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.698% (17884/18688)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.706% (18008/18816)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.698% (18129/18944)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.701% (18252/19072)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.703% (18375/19200)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.690% (18495/19328)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.693% (18618/19456)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.695% (18741/19584)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.713% (18867/19712)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.716% (18990/19840)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.728% (19115/19968)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.740% (19240/20096)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.743% (19363/20224)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.740% (19485/20352)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.742% (19608/20480)\n",
      "Train Epoch: 46 | Loss: 0.123 | Acc: 95.735% (19729/20608)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.732% (19851/20736)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.725% (19972/20864)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.736% (20097/20992)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.715% (20215/21120)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.708% (20336/21248)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.715% (20460/21376)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.712% (20582/21504)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.719% (20706/21632)\n",
      "Train Epoch: 46 | Loss: 0.124 | Acc: 95.712% (20827/21760)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.696% (20946/21888)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.694% (21068/22016)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.683% (21188/22144)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.681% (21310/22272)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.688% (21434/22400)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.676% (21554/22528)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.674% (21676/22656)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.677% (21799/22784)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.683% (21923/22912)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.673% (22043/23040)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.679% (22167/23168)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.673% (22288/23296)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.688% (22414/23424)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.707% (22541/23552)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.701% (22662/23680)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.699% (22784/23808)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.689% (22904/23936)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.678% (23024/24064)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.680% (23147/24192)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.691% (23272/24320)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.677% (23391/24448)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.671% (23512/24576)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.673% (23635/24704)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.663% (23755/24832)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.641% (23872/24960)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.639% (23994/25088)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.630% (24114/25216)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.620% (24234/25344)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.638% (24361/25472)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.633% (24482/25600)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.623% (24602/25728)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.614% (24722/25856)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.613% (24844/25984)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.627% (24970/26112)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.640% (25096/26240)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.654% (25222/26368)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.656% (25345/26496)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.654% (25467/26624)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.638% (25585/26752)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.636% (25707/26880)\n",
      "Train Epoch: 46 | Loss: 0.125 | Acc: 95.635% (25829/27008)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.626% (25949/27136)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.621% (26070/27264)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.616% (26191/27392)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.610% (26312/27520)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.605% (26433/27648)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.604% (26555/27776)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.606% (26678/27904)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.594% (26797/28032)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.593% (26919/28160)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.592% (27041/28288)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.591% (27163/28416)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.600% (27288/28544)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.592% (27408/28672)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.594% (27531/28800)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.593% (27653/28928)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.605% (27779/29056)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.593% (27898/29184)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.602% (28023/29312)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.601% (28145/29440)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.597% (28266/29568)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.592% (28387/29696)\n",
      "Train Epoch: 46 | Loss: 0.126 | Acc: 95.598% (28511/29824)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.583% (28629/29952)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.585% (28752/30080)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.577% (28872/30208)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.586% (28997/30336)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.569% (29114/30464)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.561% (29234/30592)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.566% (29358/30720)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.562% (29479/30848)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.564% (29602/30976)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.557% (29722/31104)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.546% (29841/31232)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.542% (29962/31360)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.548% (30086/31488)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.540% (30206/31616)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.542% (30329/31744)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.551% (30454/31872)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.550% (30576/32000)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.555% (30700/32128)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.557% (30823/32256)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.547% (30942/32384)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.540% (31062/32512)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.530% (31181/32640)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.520% (31300/32768)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.507% (31418/32896)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.515% (31543/33024)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.524% (31668/33152)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.529% (31792/33280)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.528% (31914/33408)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.527% (32036/33536)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.520% (32156/33664)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.517% (32277/33792)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.522% (32401/33920)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.521% (32523/34048)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.529% (32648/34176)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.522% (32768/34304)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.522% (32890/34432)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.521% (33012/34560)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.534% (33139/34688)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.539% (33263/34816)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.544% (33387/34944)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.541% (33508/35072)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.534% (33628/35200)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.539% (33752/35328)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.538% (33874/35456)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.532% (33994/35584)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.525% (34114/35712)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.527% (34237/35840)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.527% (34359/35968)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.529% (34482/36096)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.531% (34605/36224)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.535% (34729/36352)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.535% (34851/36480)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.528% (34971/36608)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.530% (35094/36736)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.540% (35220/36864)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.542% (35343/36992)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.541% (35465/37120)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.543% (35588/37248)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.543% (35710/37376)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.536% (35830/37504)\n",
      "Train Epoch: 46 | Loss: 0.127 | Acc: 95.541% (35954/37632)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.532% (36073/37760)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.534% (36196/37888)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.531% (36317/38016)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.527% (36438/38144)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.524% (36559/38272)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.523% (36681/38400)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.518% (36801/38528)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.527% (36927/38656)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.529% (37050/38784)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.521% (37169/38912)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.525% (37293/39040)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.522% (37414/39168)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.519% (37535/39296)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.513% (37655/39424)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.510% (37776/39552)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.512% (37899/39680)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.508% (38020/39808)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.500% (38139/39936)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.507% (38264/40064)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.499% (38383/40192)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.501% (38506/40320)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.510% (38632/40448)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.517% (38757/40576)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.519% (38880/40704)\n",
      "Train Epoch: 46 | Loss: 0.128 | Acc: 95.521% (39003/40832)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.525% (39127/40960)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.524% (39249/41088)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.514% (39367/41216)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.511% (39488/41344)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.515% (39612/41472)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.514% (39734/41600)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.507% (39853/41728)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.504% (39974/41856)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.501% (40095/41984)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.500% (40217/42112)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.497% (40338/42240)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.501% (40462/42368)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.505% (40586/42496)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.498% (40705/42624)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.488% (40823/42752)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.492% (40947/42880)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.503% (41074/43008)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.500% (41195/43136)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.493% (41314/43264)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.497% (41438/43392)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.492% (41558/43520)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.489% (41679/43648)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.493% (41803/43776)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.490% (41924/43904)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.483% (42043/44032)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.487% (42167/44160)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.486% (42289/44288)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.488% (42412/44416)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.485% (42533/44544)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.489% (42657/44672)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.491% (42780/44800)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.497% (42905/44928)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.503% (43030/45056)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.505% (43153/45184)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.511% (43278/45312)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.506% (43398/45440)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.497% (43516/45568)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.490% (43635/45696)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.489% (43757/45824)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.493% (43881/45952)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.490% (44002/46080)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.483% (44121/46208)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.481% (44242/46336)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.474% (44361/46464)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.480% (44486/46592)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.484% (44610/46720)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.485% (44733/46848)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.493% (44859/46976)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.491% (44980/47104)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.495% (45104/47232)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.496% (45227/47360)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.494% (45348/47488)\n",
      "Train Epoch: 46 | Loss: 0.129 | Acc: 95.495% (45471/47616)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.480% (45586/47744)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.475% (45706/47872)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.473% (45827/48000)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.464% (45945/48128)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.462% (46066/48256)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.465% (46190/48384)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.457% (46308/48512)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.456% (46430/48640)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.448% (46548/48768)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.450% (46671/48896)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.453% (46795/49024)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.461% (46921/49152)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.459% (47042/49280)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.460% (47165/49408)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.456% (47285/49536)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.464% (47411/49664)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.461% (47532/49792)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.471% (47659/49920)\n",
      "Train Epoch: 46 | Loss: 0.130 | Acc: 95.470% (47735/50000)\n",
      "Test Epoch: 46 | Loss: 0.433 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 92.500% (185/200)\n",
      "Test Epoch: 46 | Loss: 0.334 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 46 | Loss: 0.367 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 46 | Loss: 0.324 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 46 | Loss: 0.343 | Acc: 91.143% (638/700)\n",
      "Test Epoch: 46 | Loss: 0.380 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 89.889% (809/900)\n",
      "Test Epoch: 46 | Loss: 0.385 | Acc: 89.900% (899/1000)\n",
      "Test Epoch: 46 | Loss: 0.399 | Acc: 89.455% (984/1100)\n",
      "Test Epoch: 46 | Loss: 0.399 | Acc: 89.417% (1073/1200)\n",
      "Test Epoch: 46 | Loss: 0.394 | Acc: 89.462% (1163/1300)\n",
      "Test Epoch: 46 | Loss: 0.388 | Acc: 89.357% (1251/1400)\n",
      "Test Epoch: 46 | Loss: 0.380 | Acc: 89.467% (1342/1500)\n",
      "Test Epoch: 46 | Loss: 0.377 | Acc: 89.500% (1432/1600)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 89.529% (1522/1700)\n",
      "Test Epoch: 46 | Loss: 0.380 | Acc: 89.333% (1608/1800)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 89.368% (1698/1900)\n",
      "Test Epoch: 46 | Loss: 0.400 | Acc: 89.050% (1781/2000)\n",
      "Test Epoch: 46 | Loss: 0.408 | Acc: 88.762% (1864/2100)\n",
      "Test Epoch: 46 | Loss: 0.407 | Acc: 88.773% (1953/2200)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 88.783% (2042/2300)\n",
      "Test Epoch: 46 | Loss: 0.400 | Acc: 88.667% (2128/2400)\n",
      "Test Epoch: 46 | Loss: 0.411 | Acc: 88.600% (2215/2500)\n",
      "Test Epoch: 46 | Loss: 0.421 | Acc: 88.538% (2302/2600)\n",
      "Test Epoch: 46 | Loss: 0.411 | Acc: 88.741% (2396/2700)\n",
      "Test Epoch: 46 | Loss: 0.405 | Acc: 88.821% (2487/2800)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 88.862% (2577/2900)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 88.900% (2667/3000)\n",
      "Test Epoch: 46 | Loss: 0.404 | Acc: 88.935% (2757/3100)\n",
      "Test Epoch: 46 | Loss: 0.402 | Acc: 88.969% (2847/3200)\n",
      "Test Epoch: 46 | Loss: 0.397 | Acc: 89.121% (2941/3300)\n",
      "Test Epoch: 46 | Loss: 0.396 | Acc: 89.118% (3030/3400)\n",
      "Test Epoch: 46 | Loss: 0.399 | Acc: 89.029% (3116/3500)\n",
      "Test Epoch: 46 | Loss: 0.402 | Acc: 89.083% (3207/3600)\n",
      "Test Epoch: 46 | Loss: 0.407 | Acc: 88.946% (3291/3700)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 88.895% (3378/3800)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 89.000% (3471/3900)\n",
      "Test Epoch: 46 | Loss: 0.404 | Acc: 89.025% (3561/4000)\n",
      "Test Epoch: 46 | Loss: 0.409 | Acc: 88.878% (3644/4100)\n",
      "Test Epoch: 46 | Loss: 0.408 | Acc: 88.881% (3733/4200)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 89.000% (3827/4300)\n",
      "Test Epoch: 46 | Loss: 0.405 | Acc: 88.955% (3914/4400)\n",
      "Test Epoch: 46 | Loss: 0.405 | Acc: 88.956% (4003/4500)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 88.978% (4093/4600)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 89.000% (4183/4700)\n",
      "Test Epoch: 46 | Loss: 0.407 | Acc: 88.792% (4262/4800)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 88.857% (4354/4900)\n",
      "Test Epoch: 46 | Loss: 0.408 | Acc: 88.780% (4439/5000)\n",
      "Test Epoch: 46 | Loss: 0.404 | Acc: 88.902% (4534/5100)\n",
      "Test Epoch: 46 | Loss: 0.405 | Acc: 88.885% (4622/5200)\n",
      "Test Epoch: 46 | Loss: 0.407 | Acc: 88.849% (4709/5300)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 88.833% (4797/5400)\n",
      "Test Epoch: 46 | Loss: 0.406 | Acc: 88.836% (4886/5500)\n",
      "Test Epoch: 46 | Loss: 0.407 | Acc: 88.839% (4975/5600)\n",
      "Test Epoch: 46 | Loss: 0.405 | Acc: 88.877% (5066/5700)\n",
      "Test Epoch: 46 | Loss: 0.403 | Acc: 88.931% (5158/5800)\n",
      "Test Epoch: 46 | Loss: 0.402 | Acc: 88.949% (5248/5900)\n",
      "Test Epoch: 46 | Loss: 0.400 | Acc: 88.933% (5336/6000)\n",
      "Test Epoch: 46 | Loss: 0.400 | Acc: 88.918% (5424/6100)\n",
      "Test Epoch: 46 | Loss: 0.398 | Acc: 88.952% (5515/6200)\n",
      "Test Epoch: 46 | Loss: 0.396 | Acc: 89.016% (5608/6300)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.094% (5702/6400)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.092% (5791/6500)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.000% (5874/6600)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.060% (5967/6700)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.059% (6056/6800)\n",
      "Test Epoch: 46 | Loss: 0.391 | Acc: 89.116% (6149/6900)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.086% (6236/7000)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.141% (6329/7100)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.153% (6419/7200)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.205% (6512/7300)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.230% (6603/7400)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.173% (6688/7500)\n",
      "Test Epoch: 46 | Loss: 0.395 | Acc: 89.105% (6772/7600)\n",
      "Test Epoch: 46 | Loss: 0.395 | Acc: 89.156% (6865/7700)\n",
      "Test Epoch: 46 | Loss: 0.394 | Acc: 89.167% (6955/7800)\n",
      "Test Epoch: 46 | Loss: 0.394 | Acc: 89.127% (7041/7900)\n",
      "Test Epoch: 46 | Loss: 0.394 | Acc: 89.062% (7125/8000)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.062% (7214/8100)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.085% (7305/8200)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.084% (7394/8300)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.048% (7480/8400)\n",
      "Test Epoch: 46 | Loss: 0.395 | Acc: 89.012% (7566/8500)\n",
      "Test Epoch: 46 | Loss: 0.398 | Acc: 88.965% (7651/8600)\n",
      "Test Epoch: 46 | Loss: 0.396 | Acc: 88.989% (7742/8700)\n",
      "Test Epoch: 46 | Loss: 0.397 | Acc: 88.989% (7831/8800)\n",
      "Test Epoch: 46 | Loss: 0.396 | Acc: 89.000% (7921/8900)\n",
      "Test Epoch: 46 | Loss: 0.396 | Acc: 88.978% (8008/9000)\n",
      "Test Epoch: 46 | Loss: 0.394 | Acc: 89.011% (8100/9100)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.076% (8195/9200)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 89.054% (8282/9300)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.096% (8375/9400)\n",
      "Test Epoch: 46 | Loss: 0.392 | Acc: 89.074% (8462/9500)\n",
      "Test Epoch: 46 | Loss: 0.391 | Acc: 89.094% (8553/9600)\n",
      "Test Epoch: 46 | Loss: 0.390 | Acc: 89.124% (8645/9700)\n",
      "Test Epoch: 46 | Loss: 0.391 | Acc: 89.122% (8734/9800)\n",
      "Test Epoch: 46 | Loss: 0.391 | Acc: 89.141% (8825/9900)\n",
      "Test Epoch: 46 | Loss: 0.391 | Acc: 89.170% (8917/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 47 | Loss: 0.105 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 47 | Loss: 0.097 | Acc: 97.656% (375/384)\n",
      "Train Epoch: 47 | Loss: 0.089 | Acc: 97.852% (501/512)\n",
      "Train Epoch: 47 | Loss: 0.105 | Acc: 96.719% (619/640)\n",
      "Train Epoch: 47 | Loss: 0.112 | Acc: 96.354% (740/768)\n",
      "Train Epoch: 47 | Loss: 0.111 | Acc: 96.317% (863/896)\n",
      "Train Epoch: 47 | Loss: 0.103 | Acc: 96.680% (990/1024)\n",
      "Train Epoch: 47 | Loss: 0.102 | Acc: 96.701% (1114/1152)\n",
      "Train Epoch: 47 | Loss: 0.101 | Acc: 96.797% (1239/1280)\n",
      "Train Epoch: 47 | Loss: 0.099 | Acc: 96.875% (1364/1408)\n",
      "Train Epoch: 47 | Loss: 0.099 | Acc: 96.810% (1487/1536)\n",
      "Train Epoch: 47 | Loss: 0.100 | Acc: 96.755% (1610/1664)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.708% (1733/1792)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.719% (1857/1920)\n",
      "Train Epoch: 47 | Loss: 0.108 | Acc: 96.582% (1978/2048)\n",
      "Train Epoch: 47 | Loss: 0.108 | Acc: 96.599% (2102/2176)\n",
      "Train Epoch: 47 | Loss: 0.109 | Acc: 96.528% (2224/2304)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.628% (2350/2432)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.523% (2471/2560)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.540% (2595/2688)\n",
      "Train Epoch: 47 | Loss: 0.107 | Acc: 96.520% (2718/2816)\n",
      "Train Epoch: 47 | Loss: 0.108 | Acc: 96.433% (2839/2944)\n",
      "Train Epoch: 47 | Loss: 0.108 | Acc: 96.419% (2962/3072)\n",
      "Train Epoch: 47 | Loss: 0.107 | Acc: 96.438% (3086/3200)\n",
      "Train Epoch: 47 | Loss: 0.108 | Acc: 96.514% (3212/3328)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.557% (3337/3456)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.540% (3460/3584)\n",
      "Train Epoch: 47 | Loss: 0.106 | Acc: 96.525% (3583/3712)\n",
      "Train Epoch: 47 | Loss: 0.110 | Acc: 96.354% (3700/3840)\n",
      "Train Epoch: 47 | Loss: 0.109 | Acc: 96.371% (3824/3968)\n",
      "Train Epoch: 47 | Loss: 0.111 | Acc: 96.289% (3944/4096)\n",
      "Train Epoch: 47 | Loss: 0.111 | Acc: 96.354% (4070/4224)\n",
      "Train Epoch: 47 | Loss: 0.110 | Acc: 96.415% (4196/4352)\n",
      "Train Epoch: 47 | Loss: 0.111 | Acc: 96.339% (4316/4480)\n",
      "Train Epoch: 47 | Loss: 0.111 | Acc: 96.354% (4440/4608)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.263% (4559/4736)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.176% (4678/4864)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.154% (4800/4992)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 96.113% (4921/5120)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.132% (5045/5248)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.150% (5169/5376)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.148% (5292/5504)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.200% (5418/5632)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.163% (5539/5760)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.145% (5661/5888)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.193% (5787/6016)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.159% (5908/6144)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.189% (6033/6272)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.188% (6156/6400)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.216% (6281/6528)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.199% (6403/6656)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.167% (6524/6784)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.195% (6649/6912)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.193% (6772/7040)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.219% (6897/7168)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.245% (7022/7296)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.255% (7146/7424)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.292% (7272/7552)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.263% (7393/7680)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.260% (7516/7808)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.295% (7642/7936)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.305% (7766/8064)\n",
      "Train Epoch: 47 | Loss: 0.112 | Acc: 96.326% (7891/8192)\n",
      "Train Epoch: 47 | Loss: 0.112 | Acc: 96.322% (8014/8320)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.307% (8136/8448)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.292% (8258/8576)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.232% (8376/8704)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.207% (8497/8832)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.205% (8620/8960)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.215% (8744/9088)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.224% (8868/9216)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.211% (8990/9344)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.178% (9110/9472)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.167% (9232/9600)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.186% (9357/9728)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.175% (9479/9856)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.174% (9602/9984)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.193% (9727/10112)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.191% (9850/10240)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.181% (9972/10368)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.160% (10093/10496)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.122% (10212/10624)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.140% (10337/10752)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.149% (10461/10880)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.130% (10582/11008)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.130% (10705/11136)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.156% (10831/11264)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.164% (10955/11392)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.163% (11078/11520)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.171% (11202/11648)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.153% (11323/11776)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.169% (11448/11904)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.169% (11571/12032)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.160% (11693/12160)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.159% (11816/12288)\n",
      "Train Epoch: 47 | Loss: 0.113 | Acc: 96.166% (11940/12416)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.142% (12060/12544)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.117% (12180/12672)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.086% (12299/12800)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.094% (12423/12928)\n",
      "Train Epoch: 47 | Loss: 0.114 | Acc: 96.094% (12546/13056)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.048% (12663/13184)\n",
      "Train Epoch: 47 | Loss: 0.115 | Acc: 96.049% (12786/13312)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.027% (12906/13440)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.005% (13026/13568)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 95.992% (13147/13696)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.007% (13272/13824)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.044% (13400/13952)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.051% (13524/14080)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.052% (13647/14208)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.052% (13770/14336)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.059% (13894/14464)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.053% (14016/14592)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.053% (14139/14720)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.047% (14261/14848)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.047% (14384/14976)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.067% (14510/15104)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.074% (14634/15232)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.068% (14756/15360)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.068% (14879/15488)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.087% (15005/15616)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.081% (15127/15744)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.100% (15253/15872)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.094% (15375/16000)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.081% (15496/16128)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.081% (15619/16256)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.088% (15743/16384)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.057% (15861/16512)\n",
      "Train Epoch: 47 | Loss: 0.116 | Acc: 96.034% (15980/16640)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 96.016% (16100/16768)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 95.999% (16220/16896)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 95.965% (16337/17024)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 95.960% (16459/17152)\n",
      "Train Epoch: 47 | Loss: 0.117 | Acc: 95.961% (16582/17280)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.927% (16699/17408)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.923% (16821/17536)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.913% (16942/17664)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.897% (17062/17792)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.898% (17185/17920)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.905% (17309/18048)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.907% (17432/18176)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.919% (17557/18304)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.909% (17678/18432)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.921% (17803/18560)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.912% (17924/18688)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.902% (18045/18816)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.909% (18169/18944)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.905% (18291/19072)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.911% (18415/19200)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.918% (18539/19328)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.883% (18655/19456)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.890% (18779/19584)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.901% (18904/19712)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.912% (19029/19840)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.898% (19149/19968)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.890% (19270/20096)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.911% (19397/20224)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.902% (19518/20352)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.918% (19644/20480)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.929% (19769/20608)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.944% (19895/20736)\n",
      "Train Epoch: 47 | Loss: 0.118 | Acc: 95.936% (20016/20864)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.917% (20135/20992)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.919% (20258/21120)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.896% (20376/21248)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.893% (20498/21376)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.894% (20621/21504)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.881% (20741/21632)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.878% (20863/21760)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.879% (20986/21888)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.871% (21107/22016)\n",
      "Train Epoch: 47 | Loss: 0.119 | Acc: 95.877% (21231/22144)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.856% (21349/22272)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.853% (21471/22400)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.858% (21595/22528)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.851% (21716/22656)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.848% (21838/22784)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.849% (21961/22912)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.859% (22086/23040)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.848% (22206/23168)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.828% (22324/23296)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.833% (22448/23424)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.831% (22570/23552)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.845% (22696/23680)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.846% (22819/23808)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.847% (22942/23936)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.844% (23064/24064)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.833% (23184/24192)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.847% (23310/24320)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.840% (23431/24448)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.850% (23556/24576)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.851% (23679/24704)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.848% (23801/24832)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.845% (23923/24960)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.843% (24045/25088)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.848% (24169/25216)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.853% (24293/25344)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.850% (24415/25472)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.844% (24536/25600)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.841% (24658/25728)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.842% (24781/25856)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.851% (24906/25984)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.845% (25027/26112)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.857% (25153/26240)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.847% (25273/26368)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.822% (25389/26496)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.827% (25513/26624)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.832% (25637/26752)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.837% (25761/26880)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.842% (25885/27008)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.851% (26010/27136)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.837% (26129/27264)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.842% (26253/27392)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.839% (26375/27520)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.841% (26498/27648)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.824% (26616/27776)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.829% (26740/27904)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.815% (26859/28032)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.817% (26982/28160)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.825% (27107/28288)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.833% (27232/28416)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.824% (27352/28544)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.804% (27469/28672)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.809% (27593/28800)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.817% (27718/28928)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.815% (27840/29056)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.816% (27963/29184)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.797% (28080/29312)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.805% (28205/29440)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.803% (28327/29568)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.814% (28453/29696)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.809% (28574/29824)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.813% (28698/29952)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.814% (28821/30080)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.819% (28945/30208)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.827% (29070/30336)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.834% (29195/30464)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.836% (29318/30592)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.843% (29443/30720)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.851% (29568/30848)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.842% (29688/30976)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.843% (29811/31104)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.844% (29934/31232)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.842% (30056/31360)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.833% (30176/31488)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.828% (30297/31616)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.829% (30420/31744)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.827% (30542/31872)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.819% (30662/32000)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.835% (30790/32128)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.846% (30916/32256)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.847% (31039/32384)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.851% (31163/32512)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.861% (31289/32640)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.856% (31410/32768)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.848% (31530/32896)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.839% (31650/33024)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.840% (31773/33152)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.850% (31899/33280)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.845% (32020/33408)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.840% (32141/33536)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.838% (32263/33664)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.827% (32382/33792)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.828% (32505/33920)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.824% (32626/34048)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.819% (32747/34176)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.817% (32869/34304)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.818% (32992/34432)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.819% (33115/34560)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.823% (33239/34688)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.821% (33361/34816)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.822% (33484/34944)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.820% (33606/35072)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.824% (33730/35200)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.836% (33857/35328)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.837% (33980/35456)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.835% (34102/35584)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.825% (34221/35712)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.804% (34336/35840)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.796% (34456/35968)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.797% (34579/36096)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.796% (34701/36224)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.805% (34827/36352)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.800% (34948/36480)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.801% (35071/36608)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.811% (35197/36736)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.812% (35320/36864)\n",
      "Train Epoch: 47 | Loss: 0.120 | Acc: 95.818% (35445/36992)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.811% (35565/37120)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.788% (35679/37248)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.797% (35805/37376)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.792% (35926/37504)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.804% (36053/37632)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.808% (36177/37760)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.811% (36301/37888)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.812% (36424/38016)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.803% (36543/38144)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.793% (36662/38272)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.797% (36786/38400)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.798% (36909/38528)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.791% (37029/38656)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.795% (37153/38784)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.798% (37277/38912)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.791% (37397/39040)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.795% (37521/39168)\n",
      "Train Epoch: 47 | Loss: 0.121 | Acc: 95.801% (37646/39296)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.792% (37765/39424)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.788% (37886/39552)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.789% (38009/39680)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.787% (38131/39808)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.793% (38256/39936)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.789% (38377/40064)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.793% (38501/40192)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.796% (38625/40320)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.804% (38751/40448)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.800% (38872/40576)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.796% (38993/40704)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.800% (39117/40832)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.798% (39239/40960)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.799% (39362/41088)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.803% (39486/41216)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.796% (39606/41344)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.788% (39725/41472)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.791% (39849/41600)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.787% (39970/41728)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.778% (40089/41856)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.775% (40210/41984)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.773% (40332/42112)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.769% (40453/42240)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.770% (40576/42368)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.774% (40700/42496)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.777% (40824/42624)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.773% (40945/42752)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.777% (41069/42880)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.773% (41190/43008)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.767% (41310/43136)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.770% (41434/43264)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.767% (41555/43392)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.774% (41681/43520)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.766% (41800/43648)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.772% (41925/43776)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.770% (42047/43904)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.764% (42167/44032)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.756% (42286/44160)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.764% (42412/44288)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.763% (42534/44416)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.757% (42654/44544)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.749% (42773/44672)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.743% (42893/44800)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.751% (43019/44928)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.754% (43143/45056)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.760% (43268/45184)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.758% (43390/45312)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.761% (43514/45440)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.767% (43639/45568)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.768% (43762/45696)\n",
      "Train Epoch: 47 | Loss: 0.122 | Acc: 95.769% (43885/45824)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.769% (44008/45952)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.768% (44130/46080)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.760% (44249/46208)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.757% (44370/46336)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.749% (44489/46464)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.748% (44611/46592)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.732% (44726/46720)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.737% (44851/46848)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.736% (44973/46976)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.733% (45094/47104)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.734% (45217/47232)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.735% (45340/47360)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.734% (45462/47488)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.741% (45588/47616)\n",
      "Train Epoch: 47 | Loss: 0.123 | Acc: 95.740% (45710/47744)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.728% (45827/47872)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.721% (45946/48000)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.714% (46065/48128)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.704% (46183/48256)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.705% (46306/48384)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.706% (46429/48512)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.705% (46551/48640)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.700% (46671/48768)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.695% (46791/48896)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.692% (46912/49024)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.693% (47035/49152)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.696% (47159/49280)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.693% (47280/49408)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.686% (47399/49536)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.687% (47522/49664)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.684% (47643/49792)\n",
      "Train Epoch: 47 | Loss: 0.125 | Acc: 95.685% (47766/49920)\n",
      "Train Epoch: 47 | Loss: 0.124 | Acc: 95.688% (47844/50000)\n",
      "Test Epoch: 47 | Loss: 0.428 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 47 | Loss: 0.377 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 47 | Loss: 0.363 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 47 | Loss: 0.440 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 47 | Loss: 0.416 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 47 | Loss: 0.373 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 47 | Loss: 0.370 | Acc: 90.000% (630/700)\n",
      "Test Epoch: 47 | Loss: 0.402 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 47 | Loss: 0.433 | Acc: 88.333% (795/900)\n",
      "Test Epoch: 47 | Loss: 0.429 | Acc: 88.600% (886/1000)\n",
      "Test Epoch: 47 | Loss: 0.444 | Acc: 88.091% (969/1100)\n",
      "Test Epoch: 47 | Loss: 0.464 | Acc: 87.833% (1054/1200)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 88.231% (1147/1300)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.929% (1231/1400)\n",
      "Test Epoch: 47 | Loss: 0.444 | Acc: 87.867% (1318/1500)\n",
      "Test Epoch: 47 | Loss: 0.439 | Acc: 87.938% (1407/1600)\n",
      "Test Epoch: 47 | Loss: 0.431 | Acc: 88.118% (1498/1700)\n",
      "Test Epoch: 47 | Loss: 0.431 | Acc: 87.944% (1583/1800)\n",
      "Test Epoch: 47 | Loss: 0.432 | Acc: 87.947% (1671/1900)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.800% (1756/2000)\n",
      "Test Epoch: 47 | Loss: 0.456 | Acc: 87.476% (1837/2100)\n",
      "Test Epoch: 47 | Loss: 0.451 | Acc: 87.545% (1926/2200)\n",
      "Test Epoch: 47 | Loss: 0.440 | Acc: 87.739% (2018/2300)\n",
      "Test Epoch: 47 | Loss: 0.436 | Acc: 87.875% (2109/2400)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.720% (2193/2500)\n",
      "Test Epoch: 47 | Loss: 0.457 | Acc: 87.615% (2278/2600)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.704% (2368/2700)\n",
      "Test Epoch: 47 | Loss: 0.447 | Acc: 87.750% (2457/2800)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.828% (2547/2900)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 87.933% (2638/3000)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 87.968% (2727/3100)\n",
      "Test Epoch: 47 | Loss: 0.445 | Acc: 87.969% (2815/3200)\n",
      "Test Epoch: 47 | Loss: 0.442 | Acc: 88.091% (2907/3300)\n",
      "Test Epoch: 47 | Loss: 0.439 | Acc: 88.059% (2994/3400)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.914% (3077/3500)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.944% (3166/3600)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.919% (3253/3700)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.868% (3339/3800)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.897% (3428/3900)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.900% (3516/4000)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.878% (3603/4100)\n",
      "Test Epoch: 47 | Loss: 0.454 | Acc: 87.810% (3688/4200)\n",
      "Test Epoch: 47 | Loss: 0.447 | Acc: 88.000% (3784/4300)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 88.000% (3872/4400)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 88.000% (3960/4500)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.957% (4046/4600)\n",
      "Test Epoch: 47 | Loss: 0.447 | Acc: 87.915% (4132/4700)\n",
      "Test Epoch: 47 | Loss: 0.451 | Acc: 87.854% (4217/4800)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.918% (4308/4900)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.840% (4392/5000)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.882% (4482/5100)\n",
      "Test Epoch: 47 | Loss: 0.451 | Acc: 87.846% (4568/5200)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.830% (4655/5300)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.815% (4742/5400)\n",
      "Test Epoch: 47 | Loss: 0.451 | Acc: 87.818% (4830/5500)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.821% (4918/5600)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.825% (5006/5700)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.845% (5095/5800)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.797% (5180/5900)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.817% (5269/6000)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.836% (5358/6100)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.806% (5444/6200)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.857% (5535/6300)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.906% (5626/6400)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.862% (5711/6500)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 87.955% (5805/6600)\n",
      "Test Epoch: 47 | Loss: 0.444 | Acc: 88.030% (5898/6700)\n",
      "Test Epoch: 47 | Loss: 0.445 | Acc: 88.044% (5987/6800)\n",
      "Test Epoch: 47 | Loss: 0.444 | Acc: 88.072% (6077/6900)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 88.057% (6164/7000)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 88.070% (6253/7100)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 88.069% (6341/7200)\n",
      "Test Epoch: 47 | Loss: 0.447 | Acc: 88.123% (6433/7300)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 88.068% (6517/7400)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.960% (6597/7500)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.947% (6684/7600)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.935% (6771/7700)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 87.974% (6862/7800)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.987% (6951/7900)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 87.925% (7034/8000)\n",
      "Test Epoch: 47 | Loss: 0.445 | Acc: 88.049% (7132/8100)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 88.049% (7220/8200)\n",
      "Test Epoch: 47 | Loss: 0.446 | Acc: 88.060% (7309/8300)\n",
      "Test Epoch: 47 | Loss: 0.448 | Acc: 88.012% (7393/8400)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 87.988% (7479/8500)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.919% (7561/8600)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.931% (7650/8700)\n",
      "Test Epoch: 47 | Loss: 0.455 | Acc: 87.864% (7732/8800)\n",
      "Test Epoch: 47 | Loss: 0.454 | Acc: 87.876% (7821/8900)\n",
      "Test Epoch: 47 | Loss: 0.456 | Acc: 87.844% (7906/9000)\n",
      "Test Epoch: 47 | Loss: 0.454 | Acc: 87.901% (7999/9100)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.957% (8092/9200)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.957% (8180/9300)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.947% (8267/9400)\n",
      "Test Epoch: 47 | Loss: 0.452 | Acc: 87.937% (8354/9500)\n",
      "Test Epoch: 47 | Loss: 0.453 | Acc: 87.958% (8444/9600)\n",
      "Test Epoch: 47 | Loss: 0.451 | Acc: 88.000% (8536/9700)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 88.041% (8628/9800)\n",
      "Test Epoch: 47 | Loss: 0.450 | Acc: 88.051% (8717/9900)\n",
      "Test Epoch: 47 | Loss: 0.449 | Acc: 88.050% (8805/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Train Epoch: 48 | Loss: 0.125 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 48 | Loss: 0.130 | Acc: 93.359% (239/256)\n",
      "Train Epoch: 48 | Loss: 0.146 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 48 | Loss: 0.132 | Acc: 94.336% (483/512)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.156% (609/640)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.052% (730/768)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.424% (855/896)\n",
      "Train Epoch: 48 | Loss: 0.109 | Acc: 95.703% (980/1024)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.486% (1100/1152)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.312% (1220/1280)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.099% (1339/1408)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 94.857% (1457/1536)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 94.832% (1578/1664)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 94.866% (1700/1792)\n",
      "Train Epoch: 48 | Loss: 0.132 | Acc: 94.688% (1818/1920)\n",
      "Train Epoch: 48 | Loss: 0.134 | Acc: 94.580% (1937/2048)\n",
      "Train Epoch: 48 | Loss: 0.134 | Acc: 94.715% (2061/2176)\n",
      "Train Epoch: 48 | Loss: 0.133 | Acc: 94.705% (2182/2304)\n",
      "Train Epoch: 48 | Loss: 0.133 | Acc: 94.655% (2302/2432)\n",
      "Train Epoch: 48 | Loss: 0.132 | Acc: 94.727% (2425/2560)\n",
      "Train Epoch: 48 | Loss: 0.133 | Acc: 94.717% (2546/2688)\n",
      "Train Epoch: 48 | Loss: 0.130 | Acc: 94.851% (2671/2816)\n",
      "Train Epoch: 48 | Loss: 0.132 | Acc: 94.803% (2791/2944)\n",
      "Train Epoch: 48 | Loss: 0.134 | Acc: 94.727% (2910/3072)\n",
      "Train Epoch: 48 | Loss: 0.132 | Acc: 94.844% (3035/3200)\n",
      "Train Epoch: 48 | Loss: 0.130 | Acc: 94.952% (3160/3328)\n",
      "Train Epoch: 48 | Loss: 0.131 | Acc: 94.936% (3281/3456)\n",
      "Train Epoch: 48 | Loss: 0.129 | Acc: 95.033% (3406/3584)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 95.097% (3530/3712)\n",
      "Train Epoch: 48 | Loss: 0.129 | Acc: 95.052% (3650/3840)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 95.086% (3773/3968)\n",
      "Train Epoch: 48 | Loss: 0.129 | Acc: 95.068% (3894/4096)\n",
      "Train Epoch: 48 | Loss: 0.127 | Acc: 95.170% (4020/4224)\n",
      "Train Epoch: 48 | Loss: 0.130 | Acc: 95.175% (4142/4352)\n",
      "Train Epoch: 48 | Loss: 0.129 | Acc: 95.246% (4267/4480)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 95.269% (4390/4608)\n",
      "Train Epoch: 48 | Loss: 0.129 | Acc: 95.207% (4509/4736)\n",
      "Train Epoch: 48 | Loss: 0.128 | Acc: 95.312% (4636/4864)\n",
      "Train Epoch: 48 | Loss: 0.127 | Acc: 95.333% (4759/4992)\n",
      "Train Epoch: 48 | Loss: 0.125 | Acc: 95.410% (4885/5120)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.484% (5011/5248)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.480% (5133/5376)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.512% (5257/5504)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.490% (5378/5632)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.451% (5498/5760)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.465% (5621/5888)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.412% (5740/6016)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.410% (5862/6144)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.424% (5985/6272)\n",
      "Train Epoch: 48 | Loss: 0.125 | Acc: 95.359% (6103/6400)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.420% (6229/6528)\n",
      "Train Epoch: 48 | Loss: 0.122 | Acc: 95.493% (6356/6656)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.504% (6479/6784)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.486% (6600/6912)\n",
      "Train Epoch: 48 | Loss: 0.124 | Acc: 95.455% (6720/7040)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.480% (6844/7168)\n",
      "Train Epoch: 48 | Loss: 0.123 | Acc: 95.518% (6969/7296)\n",
      "Train Epoch: 48 | Loss: 0.122 | Acc: 95.568% (7095/7424)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.564% (7217/7552)\n",
      "Train Epoch: 48 | Loss: 0.122 | Acc: 95.547% (7338/7680)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.581% (7463/7808)\n",
      "Train Epoch: 48 | Loss: 0.122 | Acc: 95.539% (7582/7936)\n",
      "Train Epoch: 48 | Loss: 0.122 | Acc: 95.536% (7704/8064)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.544% (7827/8192)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.565% (7951/8320)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.537% (8071/8448)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.546% (8194/8576)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.588% (8320/8704)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.528% (8437/8832)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.513% (8558/8960)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.500% (8679/9088)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.530% (8804/9216)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.484% (8922/9344)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.481% (9044/9472)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.490% (9167/9600)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.508% (9291/9728)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.536% (9416/9856)\n",
      "Train Epoch: 48 | Loss: 0.121 | Acc: 95.523% (9537/9984)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.550% (9662/10112)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.557% (9785/10240)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.554% (9907/10368)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.541% (10028/10496)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.538% (10150/10624)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.536% (10272/10752)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.570% (10398/10880)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.585% (10522/11008)\n",
      "Train Epoch: 48 | Loss: 0.120 | Acc: 95.537% (10639/11136)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.552% (10763/11264)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.558% (10886/11392)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.564% (11009/11520)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.561% (11131/11648)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.584% (11256/11776)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.598% (11380/11904)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.620% (11505/12032)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.625% (11628/12160)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.622% (11750/12288)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.611% (11871/12416)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.592% (11991/12544)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.589% (12113/12672)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.602% (12237/12800)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.622% (12362/12928)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.634% (12486/13056)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.623% (12607/13184)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.620% (12729/13312)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.595% (12848/13440)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.600% (12971/13568)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.619% (13096/13696)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.616% (13218/13824)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.614% (13340/13952)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.604% (13461/14080)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.615% (13585/14208)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.598% (13705/14336)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.610% (13829/14464)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.614% (13952/14592)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.625% (14076/14720)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.643% (14201/14848)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.660% (14326/14976)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.644% (14446/15104)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.647% (14569/15232)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.632% (14689/15360)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.622% (14810/15488)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.620% (14932/15616)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.630% (15056/15744)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.634% (15179/15872)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.625% (15300/16000)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.623% (15422/16128)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.614% (15543/16256)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.599% (15663/16384)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.609% (15787/16512)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.607% (15909/16640)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.617% (16033/16768)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.626% (16157/16896)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.653% (16284/17024)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.680% (16411/17152)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.694% (16536/17280)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.692% (16658/17408)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.695% (16781/17536)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.709% (16906/17664)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.712% (17029/17792)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.725% (17154/17920)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.723% (17276/18048)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.731% (17400/18176)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.733% (17523/18304)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.725% (17644/18432)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.722% (17766/18560)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.708% (17886/18688)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.716% (18010/18816)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.740% (18137/18944)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.758% (18263/19072)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.771% (18388/19200)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.788% (18514/19328)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.780% (18635/19456)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.792% (18760/19584)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.805% (18885/19712)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.806% (19008/19840)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.823% (19134/19968)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.840% (19260/20096)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.847% (19384/20224)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.843% (19506/20352)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.840% (19628/20480)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.851% (19753/20608)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.872% (19880/20736)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.868% (20002/20864)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.875% (20126/20992)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.885% (20251/21120)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.887% (20374/21248)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.897% (20499/21376)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.903% (20623/21504)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.918% (20749/21632)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.910% (20870/21760)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.916% (20994/21888)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.921% (21118/22016)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.922% (21241/22144)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.923% (21364/22272)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.929% (21488/22400)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.925% (21610/22528)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.926% (21733/22656)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.949% (21861/22784)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.937% (21981/22912)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.929% (22102/23040)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.934% (22226/23168)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.931% (22348/23296)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.932% (22471/23424)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.932% (22594/23552)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.942% (22719/23680)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.938% (22841/23808)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.922% (22960/23936)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.936% (23086/24064)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.945% (23211/24192)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.946% (23334/24320)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.942% (23456/24448)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.947% (23580/24576)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.944% (23702/24704)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.953% (23827/24832)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.958% (23951/24960)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.966% (24076/25088)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.955% (24196/25216)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.956% (24319/25344)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.964% (24444/25472)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.965% (24567/25600)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.962% (24689/25728)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.974% (24815/25856)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.982% (24940/25984)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.983% (25063/26112)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.987% (25187/26240)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.972% (25306/26368)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.977% (25430/26496)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.981% (25554/26624)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.978% (25676/26752)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.978% (25799/26880)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.975% (25921/27008)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.987% (26047/27136)\n",
      "Train Epoch: 48 | Loss: 0.111 | Acc: 95.980% (26168/27264)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.973% (26289/27392)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.970% (26411/27520)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.964% (26532/27648)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.968% (26656/27776)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.965% (26778/27904)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.962% (26900/28032)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.969% (27025/28160)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.974% (27149/28288)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.964% (27269/28416)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.971% (27394/28544)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.968% (27516/28672)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.972% (27640/28800)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.983% (27766/28928)\n",
      "Train Epoch: 48 | Loss: 0.112 | Acc: 95.977% (27887/29056)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.974% (28009/29184)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.964% (28129/29312)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.971% (28254/29440)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.975% (28378/29568)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.983% (28503/29696)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.973% (28623/29824)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.977% (28747/29952)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.967% (28867/30080)\n",
      "Train Epoch: 48 | Loss: 0.113 | Acc: 95.965% (28989/30208)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.968% (29113/30336)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.969% (29236/30464)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.970% (29359/30592)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.951% (29476/30720)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.932% (29593/30848)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.929% (29715/30976)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.917% (29834/31104)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.914% (29956/31232)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.915% (30079/31360)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.919% (30203/31488)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.926% (30328/31616)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.927% (30451/31744)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.921% (30572/31872)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.925% (30696/32000)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.913% (30815/32128)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.914% (30938/32256)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.918% (31062/32384)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.915% (31184/32512)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.922% (31309/32640)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.920% (31431/32768)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.924% (31555/32896)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.927% (31679/33024)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.925% (31801/33152)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.913% (31920/33280)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.917% (32044/33408)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.918% (32167/33536)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.921% (32291/33664)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.928% (32416/33792)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.935% (32541/33920)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.929% (32662/34048)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.930% (32785/34176)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.928% (32907/34304)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.925% (33029/34432)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.932% (33154/34560)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.932% (33277/34688)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.927% (33398/34816)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.928% (33521/34944)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.920% (33641/35072)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.912% (33761/35200)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.918% (33886/35328)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.925% (34011/35456)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.917% (34131/35584)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.917% (34254/35712)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.924% (34379/35840)\n",
      "Train Epoch: 48 | Loss: 0.114 | Acc: 95.930% (34504/35968)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.922% (34624/36096)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.917% (34745/36224)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.909% (34865/36352)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.905% (34986/36480)\n",
      "Train Epoch: 48 | Loss: 0.115 | Acc: 95.900% (35107/36608)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.887% (35225/36736)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.890% (35349/36864)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.891% (35472/36992)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.886% (35593/37120)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.892% (35718/37248)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.893% (35841/37376)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.891% (35963/37504)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.900% (36089/37632)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.892% (36209/37760)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.898% (36334/37888)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.896% (36456/38016)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.900% (36580/38144)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.882% (36696/38272)\n",
      "Train Epoch: 48 | Loss: 0.116 | Acc: 95.865% (36812/38400)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.852% (36930/38528)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.856% (37054/38656)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.857% (37177/38784)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.847% (37296/38912)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.843% (37417/39040)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.826% (37533/39168)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.829% (37657/39296)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.827% (37779/39424)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.836% (37905/39552)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.844% (38031/39680)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.838% (38151/39808)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.828% (38270/39936)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.829% (38393/40064)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.825% (38514/40192)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.823% (38636/40320)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.822% (38758/40448)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.820% (38880/40576)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.824% (39004/40704)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.815% (39123/40832)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.818% (39247/40960)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.816% (39369/41088)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.817% (39492/41216)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.813% (39613/41344)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.809% (39734/41472)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.810% (39857/41600)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.806% (39978/41728)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.809% (40102/41856)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.820% (40229/41984)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.816% (40350/42112)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.817% (40473/42240)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.815% (40595/42368)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.811% (40716/42496)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.808% (40837/42624)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.806% (40959/42752)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.800% (41079/42880)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.805% (41204/43008)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.806% (41327/43136)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.805% (41449/43264)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.806% (41572/43392)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.800% (41692/43520)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.796% (41813/43648)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.799% (41937/43776)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.795% (42058/43904)\n",
      "Train Epoch: 48 | Loss: 0.119 | Acc: 95.801% (42183/44032)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.811% (42310/44160)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.809% (42432/44288)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.806% (42553/44416)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.811% (42678/44544)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.818% (42804/44672)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.824% (42929/44800)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.820% (43050/44928)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.830% (43177/45056)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.835% (43302/45184)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.844% (43429/45312)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.847% (43553/45440)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.846% (43675/45568)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.846% (43798/45696)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.849% (43922/45824)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.854% (44047/45952)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.853% (44169/46080)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.856% (44293/46208)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.854% (44415/46336)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.859% (44540/46464)\n",
      "Train Epoch: 48 | Loss: 0.118 | Acc: 95.856% (44661/46592)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.865% (44788/46720)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.870% (44913/46848)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.879% (45040/46976)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.884% (45165/47104)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.878% (45285/47232)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.874% (45406/47360)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.860% (45522/47488)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.859% (45644/47616)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.863% (45769/47744)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.862% (45891/47872)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.865% (46015/48000)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.871% (46141/48128)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.874% (46265/48256)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.873% (46387/48384)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.869% (46508/48512)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.868% (46630/48640)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.862% (46750/48768)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.867% (46875/48896)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.869% (46999/49024)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.870% (47122/49152)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.860% (47240/49280)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.861% (47363/49408)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.868% (47489/49536)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.870% (47613/49664)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.867% (47734/49792)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.873% (47860/49920)\n",
      "Train Epoch: 48 | Loss: 0.117 | Acc: 95.874% (47937/50000)\n",
      "Test Epoch: 48 | Loss: 0.484 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 48 | Loss: 0.423 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 48 | Loss: 0.358 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 48 | Loss: 0.378 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 48 | Loss: 0.335 | Acc: 89.000% (534/600)\n",
      "Test Epoch: 48 | Loss: 0.348 | Acc: 89.429% (626/700)\n",
      "Test Epoch: 48 | Loss: 0.393 | Acc: 88.375% (707/800)\n",
      "Test Epoch: 48 | Loss: 0.409 | Acc: 87.889% (791/900)\n",
      "Test Epoch: 48 | Loss: 0.416 | Acc: 87.700% (877/1000)\n",
      "Test Epoch: 48 | Loss: 0.423 | Acc: 87.364% (961/1100)\n",
      "Test Epoch: 48 | Loss: 0.426 | Acc: 87.167% (1046/1200)\n",
      "Test Epoch: 48 | Loss: 0.422 | Acc: 87.385% (1136/1300)\n",
      "Test Epoch: 48 | Loss: 0.426 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 48 | Loss: 0.420 | Acc: 87.400% (1311/1500)\n",
      "Test Epoch: 48 | Loss: 0.415 | Acc: 87.500% (1400/1600)\n",
      "Test Epoch: 48 | Loss: 0.413 | Acc: 87.647% (1490/1700)\n",
      "Test Epoch: 48 | Loss: 0.409 | Acc: 87.667% (1578/1800)\n",
      "Test Epoch: 48 | Loss: 0.408 | Acc: 87.632% (1665/1900)\n",
      "Test Epoch: 48 | Loss: 0.416 | Acc: 87.700% (1754/2000)\n",
      "Test Epoch: 48 | Loss: 0.417 | Acc: 87.714% (1842/2100)\n",
      "Test Epoch: 48 | Loss: 0.423 | Acc: 87.591% (1927/2200)\n",
      "Test Epoch: 48 | Loss: 0.415 | Acc: 87.739% (2018/2300)\n",
      "Test Epoch: 48 | Loss: 0.419 | Acc: 87.833% (2108/2400)\n",
      "Test Epoch: 48 | Loss: 0.433 | Acc: 87.600% (2190/2500)\n",
      "Test Epoch: 48 | Loss: 0.450 | Acc: 87.538% (2276/2600)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.667% (2367/2700)\n",
      "Test Epoch: 48 | Loss: 0.444 | Acc: 87.786% (2458/2800)\n",
      "Test Epoch: 48 | Loss: 0.445 | Acc: 87.966% (2551/2900)\n",
      "Test Epoch: 48 | Loss: 0.443 | Acc: 87.867% (2636/3000)\n",
      "Test Epoch: 48 | Loss: 0.440 | Acc: 87.903% (2725/3100)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.000% (2816/3200)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 87.909% (2901/3300)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 87.912% (2989/3400)\n",
      "Test Epoch: 48 | Loss: 0.445 | Acc: 87.743% (3071/3500)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.778% (3160/3600)\n",
      "Test Epoch: 48 | Loss: 0.454 | Acc: 87.784% (3248/3700)\n",
      "Test Epoch: 48 | Loss: 0.455 | Acc: 87.789% (3336/3800)\n",
      "Test Epoch: 48 | Loss: 0.453 | Acc: 87.846% (3426/3900)\n",
      "Test Epoch: 48 | Loss: 0.449 | Acc: 87.825% (3513/4000)\n",
      "Test Epoch: 48 | Loss: 0.452 | Acc: 87.732% (3597/4100)\n",
      "Test Epoch: 48 | Loss: 0.456 | Acc: 87.643% (3681/4200)\n",
      "Test Epoch: 48 | Loss: 0.451 | Acc: 87.791% (3775/4300)\n",
      "Test Epoch: 48 | Loss: 0.453 | Acc: 87.864% (3866/4400)\n",
      "Test Epoch: 48 | Loss: 0.448 | Acc: 87.911% (3956/4500)\n",
      "Test Epoch: 48 | Loss: 0.445 | Acc: 87.957% (4046/4600)\n",
      "Test Epoch: 48 | Loss: 0.445 | Acc: 87.936% (4133/4700)\n",
      "Test Epoch: 48 | Loss: 0.448 | Acc: 87.812% (4215/4800)\n",
      "Test Epoch: 48 | Loss: 0.446 | Acc: 87.857% (4305/4900)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.880% (4394/5000)\n",
      "Test Epoch: 48 | Loss: 0.443 | Acc: 88.020% (4489/5100)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.923% (4572/5200)\n",
      "Test Epoch: 48 | Loss: 0.450 | Acc: 87.849% (4656/5300)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.944% (4749/5400)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.964% (4838/5500)\n",
      "Test Epoch: 48 | Loss: 0.447 | Acc: 87.964% (4926/5600)\n",
      "Test Epoch: 48 | Loss: 0.446 | Acc: 88.000% (5016/5700)\n",
      "Test Epoch: 48 | Loss: 0.443 | Acc: 88.069% (5108/5800)\n",
      "Test Epoch: 48 | Loss: 0.444 | Acc: 88.017% (5193/5900)\n",
      "Test Epoch: 48 | Loss: 0.442 | Acc: 88.050% (5283/6000)\n",
      "Test Epoch: 48 | Loss: 0.442 | Acc: 88.033% (5370/6100)\n",
      "Test Epoch: 48 | Loss: 0.444 | Acc: 87.984% (5455/6200)\n",
      "Test Epoch: 48 | Loss: 0.443 | Acc: 88.000% (5544/6300)\n",
      "Test Epoch: 48 | Loss: 0.441 | Acc: 88.062% (5636/6400)\n",
      "Test Epoch: 48 | Loss: 0.440 | Acc: 88.046% (5723/6500)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.106% (5815/6600)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.164% (5907/6700)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.206% (5998/6800)\n",
      "Test Epoch: 48 | Loss: 0.435 | Acc: 88.275% (6091/6900)\n",
      "Test Epoch: 48 | Loss: 0.435 | Acc: 88.229% (6176/7000)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.268% (6267/7100)\n",
      "Test Epoch: 48 | Loss: 0.440 | Acc: 88.250% (6354/7200)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.288% (6445/7300)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.311% (6535/7400)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.293% (6622/7500)\n",
      "Test Epoch: 48 | Loss: 0.440 | Acc: 88.250% (6707/7600)\n",
      "Test Epoch: 48 | Loss: 0.442 | Acc: 88.260% (6796/7700)\n",
      "Test Epoch: 48 | Loss: 0.441 | Acc: 88.321% (6889/7800)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.367% (6981/7900)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.400% (7072/8000)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.444% (7164/8100)\n",
      "Test Epoch: 48 | Loss: 0.436 | Acc: 88.415% (7250/8200)\n",
      "Test Epoch: 48 | Loss: 0.435 | Acc: 88.458% (7342/8300)\n",
      "Test Epoch: 48 | Loss: 0.435 | Acc: 88.440% (7429/8400)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.365% (7511/8500)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.337% (7597/8600)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.333% (7685/8700)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.352% (7775/8800)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.337% (7862/8900)\n",
      "Test Epoch: 48 | Loss: 0.438 | Acc: 88.378% (7954/9000)\n",
      "Test Epoch: 48 | Loss: 0.439 | Acc: 88.374% (8042/9100)\n",
      "Test Epoch: 48 | Loss: 0.437 | Acc: 88.424% (8135/9200)\n",
      "Test Epoch: 48 | Loss: 0.436 | Acc: 88.452% (8226/9300)\n",
      "Test Epoch: 48 | Loss: 0.434 | Acc: 88.489% (8318/9400)\n",
      "Test Epoch: 48 | Loss: 0.434 | Acc: 88.495% (8407/9500)\n",
      "Test Epoch: 48 | Loss: 0.434 | Acc: 88.500% (8496/9600)\n",
      "Test Epoch: 48 | Loss: 0.431 | Acc: 88.557% (8590/9700)\n",
      "Test Epoch: 48 | Loss: 0.433 | Acc: 88.561% (8679/9800)\n",
      "Test Epoch: 48 | Loss: 0.433 | Acc: 88.576% (8769/9900)\n",
      "Test Epoch: 48 | Loss: 0.433 | Acc: 88.580% (8858/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.094% (123/128)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 95.703% (245/256)\n",
      "Train Epoch: 49 | Loss: 0.092 | Acc: 96.354% (370/384)\n",
      "Train Epoch: 49 | Loss: 0.080 | Acc: 96.875% (496/512)\n",
      "Train Epoch: 49 | Loss: 0.098 | Acc: 96.719% (619/640)\n",
      "Train Epoch: 49 | Loss: 0.091 | Acc: 97.135% (746/768)\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.652% (866/896)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.484% (988/1024)\n",
      "Train Epoch: 49 | Loss: 0.099 | Acc: 96.615% (1113/1152)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.406% (1234/1280)\n",
      "Train Epoch: 49 | Loss: 0.101 | Acc: 96.449% (1358/1408)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.289% (1479/1536)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.334% (1603/1664)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.317% (1726/1792)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.354% (1850/1920)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.484% (1976/2048)\n",
      "Train Epoch: 49 | Loss: 0.100 | Acc: 96.645% (2103/2176)\n",
      "Train Epoch: 49 | Loss: 0.101 | Acc: 96.658% (2227/2304)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.505% (2347/2432)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.445% (2469/2560)\n",
      "Train Epoch: 49 | Loss: 0.101 | Acc: 96.577% (2596/2688)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.236% (2710/2816)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.298% (2835/2944)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.322% (2959/3072)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.281% (3081/3200)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.304% (3205/3328)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.383% (3331/3456)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.429% (3456/3584)\n",
      "Train Epoch: 49 | Loss: 0.101 | Acc: 96.417% (3579/3712)\n",
      "Train Epoch: 49 | Loss: 0.100 | Acc: 96.432% (3703/3840)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.421% (3826/3968)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.460% (3951/4096)\n",
      "Train Epoch: 49 | Loss: 0.100 | Acc: 96.496% (4076/4224)\n",
      "Train Epoch: 49 | Loss: 0.100 | Acc: 96.507% (4200/4352)\n",
      "Train Epoch: 49 | Loss: 0.099 | Acc: 96.585% (4327/4480)\n",
      "Train Epoch: 49 | Loss: 0.098 | Acc: 96.636% (4453/4608)\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.643% (4577/4736)\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.669% (4702/4864)\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.655% (4825/4992)\n",
      "Train Epoch: 49 | Loss: 0.098 | Acc: 96.602% (4946/5120)\n",
      "Train Epoch: 49 | Loss: 0.097 | Acc: 96.608% (5070/5248)\n",
      "Train Epoch: 49 | Loss: 0.099 | Acc: 96.559% (5191/5376)\n",
      "Train Epoch: 49 | Loss: 0.100 | Acc: 96.530% (5313/5504)\n",
      "Train Epoch: 49 | Loss: 0.101 | Acc: 96.467% (5433/5632)\n",
      "Train Epoch: 49 | Loss: 0.102 | Acc: 96.424% (5554/5760)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.382% (5675/5888)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.360% (5797/6016)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.387% (5922/6144)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.349% (6043/6272)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.328% (6165/6400)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.308% (6287/6528)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.319% (6411/6656)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.285% (6532/6784)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.311% (6657/6912)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.349% (6783/7040)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.345% (6906/7168)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.354% (7030/7296)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.363% (7154/7424)\n",
      "Train Epoch: 49 | Loss: 0.103 | Acc: 96.425% (7282/7552)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.328% (7398/7680)\n",
      "Train Epoch: 49 | Loss: 0.104 | Acc: 96.350% (7523/7808)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.346% (7646/7936)\n",
      "Train Epoch: 49 | Loss: 0.105 | Acc: 96.342% (7769/8064)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.301% (7889/8192)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.298% (8012/8320)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.283% (8134/8448)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.304% (8259/8576)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.324% (8384/8704)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.320% (8507/8832)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.328% (8631/8960)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.314% (8753/9088)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.343% (8879/9216)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.361% (9004/9344)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.379% (9129/9472)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.375% (9252/9600)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.392% (9377/9728)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.368% (9498/9856)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.364% (9621/9984)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.361% (9744/10112)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.387% (9870/10240)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.364% (9991/10368)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.361% (10114/10496)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.357% (10237/10624)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.354% (10360/10752)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.369% (10485/10880)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.366% (10608/11008)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.372% (10732/11136)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.378% (10856/11264)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.383% (10980/11392)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.363% (11101/11520)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.351% (11223/11648)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.365% (11348/11776)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.388% (11474/11904)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.385% (11597/12032)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.398% (11722/12160)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.395% (11845/12288)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.384% (11967/12416)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.349% (12086/12544)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.354% (12210/12672)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.344% (12332/12800)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.357% (12457/12928)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.347% (12579/13056)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.359% (12704/13184)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.372% (12829/13312)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.362% (12951/13440)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.374% (13076/13568)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.364% (13198/13696)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.390% (13325/13824)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.380% (13447/13952)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.371% (13569/14080)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.382% (13694/14208)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.366% (13815/14336)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.356% (13937/14464)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.354% (14060/14592)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.352% (14183/14720)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.356% (14307/14848)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.314% (14424/14976)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.332% (14550/15104)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.343% (14675/15232)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.361% (14801/15360)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.358% (14924/15488)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.356% (15047/15616)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.373% (15173/15744)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.371% (15296/15872)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.350% (15416/16000)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.360% (15541/16128)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.334% (15660/16256)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.332% (15783/16384)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.330% (15906/16512)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.310% (16026/16640)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.314% (16150/16768)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.307% (16272/16896)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.323% (16398/17024)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.333% (16523/17152)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.325% (16645/17280)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.335% (16770/17408)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.339% (16894/17536)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.354% (17020/17664)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.347% (17142/17792)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.334% (17263/17920)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.326% (17385/18048)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.308% (17505/18176)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.323% (17631/18304)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.332% (17756/18432)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.325% (17878/18560)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.335% (18003/18688)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.333% (18126/18816)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.337% (18250/18944)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.298% (18366/19072)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.318% (18493/19200)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.306% (18614/19328)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.315% (18739/19456)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.329% (18865/19584)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.337% (18990/19712)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.351% (19116/19840)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.359% (19241/19968)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.372% (19367/20096)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.376% (19491/20224)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.389% (19617/20352)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.396% (19742/20480)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.390% (19864/20608)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.378% (19985/20736)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.367% (20106/20864)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.365% (20229/20992)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.378% (20355/21120)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.367% (20476/21248)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.379% (20602/21376)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.359% (20721/21504)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.357% (20844/21632)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.365% (20969/21760)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.363% (21092/21888)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.353% (21213/22016)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.338% (21333/22144)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.332% (21455/22272)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.344% (21581/22400)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.356% (21707/22528)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.367% (21833/22656)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.348% (21952/22784)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.334% (22072/22912)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.337% (22196/23040)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.348% (22322/23168)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.351% (22446/23296)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.358% (22571/23424)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.374% (22698/23552)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.377% (22822/23680)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.371% (22944/23808)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.361% (23065/23936)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.368% (23190/24064)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.367% (23313/24192)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.361% (23435/24320)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.368% (23560/24448)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.358% (23681/24576)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.357% (23804/24704)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.347% (23925/24832)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.354% (24050/24960)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.357% (24174/25088)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.348% (24295/25216)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.342% (24417/25344)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.357% (24544/25472)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.363% (24669/25600)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.366% (24793/25728)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.376% (24919/25856)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.382% (25044/25984)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.389% (25169/26112)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.395% (25294/26240)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.378% (25413/26368)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.384% (25538/26496)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.368% (25657/26624)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.367% (25780/26752)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.380% (25907/26880)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.383% (26031/27008)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.385% (26155/27136)\n",
      "Train Epoch: 49 | Loss: 0.106 | Acc: 96.380% (26277/27264)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.379% (26400/27392)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.384% (26525/27520)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.376% (26646/27648)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.367% (26767/27776)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.359% (26888/27904)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.361% (27012/28032)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.360% (27135/28160)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.373% (27262/28288)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.361% (27382/28416)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.360% (27505/28544)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.352% (27626/28672)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.358% (27751/28800)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.356% (27874/28928)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.352% (27996/29056)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.351% (28119/29184)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.356% (28244/29312)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.359% (28368/29440)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.354% (28490/29568)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.346% (28611/29696)\n",
      "Train Epoch: 49 | Loss: 0.107 | Acc: 96.339% (28732/29824)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.321% (28850/29952)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.313% (28971/30080)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.306% (29092/30208)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.285% (29209/30336)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.287% (29333/30464)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.280% (29454/30592)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.276% (29576/30720)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.285% (29702/30848)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.287% (29826/30976)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.280% (29947/31104)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.286% (30072/31232)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.288% (30196/31360)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.294% (30321/31488)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.280% (30440/31616)\n",
      "Train Epoch: 49 | Loss: 0.108 | Acc: 96.280% (30563/31744)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.273% (30684/31872)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.266% (30805/32000)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.252% (30924/32128)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.243% (31044/32256)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.245% (31168/32384)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.251% (31293/32512)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.250% (31416/32640)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.249% (31539/32768)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.249% (31662/32896)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.251% (31786/33024)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.242% (31906/33152)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.247% (32031/33280)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.246% (32154/33408)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.255% (32280/33536)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.263% (32406/33664)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.259% (32528/33792)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.259% (32651/33920)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.261% (32775/34048)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.246% (32893/34176)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.257% (33020/34304)\n",
      "Train Epoch: 49 | Loss: 0.109 | Acc: 96.259% (33144/34432)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.256% (33266/34560)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.255% (33389/34688)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.243% (33508/34816)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.228% (33626/34944)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.233% (33751/35072)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.222% (33870/35200)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.227% (33995/35328)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.218% (34115/35456)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.217% (34238/35584)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.225% (34364/35712)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.228% (34488/35840)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.238% (34615/35968)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.227% (34734/36096)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.210% (34851/36224)\n",
      "Train Epoch: 49 | Loss: 0.110 | Acc: 96.204% (34972/36352)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.190% (35090/36480)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.187% (35212/36608)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.186% (35335/36736)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.178% (35455/36864)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.169% (35575/36992)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.161% (35695/37120)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.161% (35818/37248)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.158% (35940/37376)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.150% (36060/37504)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.155% (36185/37632)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.163% (36311/37760)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.160% (36433/37888)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.157% (36555/38016)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.149% (36675/38144)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.151% (36799/38272)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.151% (36922/38400)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.151% (37045/38528)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.161% (37172/38656)\n",
      "Train Epoch: 49 | Loss: 0.111 | Acc: 96.166% (37297/38784)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.158% (37417/38912)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.155% (37539/39040)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.147% (37659/39168)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.145% (37781/39296)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.142% (37903/39424)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.147% (38028/39552)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.137% (38147/39680)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.141% (38272/39808)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.144% (38396/39936)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.144% (38519/40064)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.144% (38642/40192)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.143% (38765/40320)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.136% (38885/40448)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.141% (39010/40576)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.138% (39132/40704)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.135% (39254/40832)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.140% (39379/40960)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.145% (39504/41088)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.147% (39628/41216)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.137% (39747/41344)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.135% (39869/41472)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.135% (39992/41600)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.132% (40114/41728)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.134% (40238/41856)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.127% (40358/41984)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.125% (40480/42112)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.113% (40598/42240)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.117% (40723/42368)\n",
      "Train Epoch: 49 | Loss: 0.112 | Acc: 96.120% (40847/42496)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.110% (40966/42624)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.105% (41087/42752)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.105% (41210/42880)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.108% (41334/43008)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.105% (41456/43136)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.105% (41579/43264)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.112% (41705/43392)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.112% (41828/43520)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.096% (41944/43648)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.096% (42067/43776)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.094% (42189/43904)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.094% (42312/44032)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.087% (42432/44160)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.082% (42553/44288)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.089% (42679/44416)\n",
      "Train Epoch: 49 | Loss: 0.113 | Acc: 96.080% (42798/44544)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.080% (42921/44672)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.076% (43042/44800)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.071% (43163/44928)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.078% (43289/45056)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.080% (43413/45184)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (43537/45312)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.087% (43662/45440)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (43783/45568)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (43906/45696)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.072% (44024/45824)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.074% (44148/45952)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.076% (44272/46080)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.074% (44394/46208)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.085% (44522/46336)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.089% (44647/46464)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.089% (44770/46592)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.087% (44892/46720)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.087% (45015/46848)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (45136/46976)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.090% (45262/47104)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.087% (45384/47232)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.090% (45508/47360)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.094% (45633/47488)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.094% (45756/47616)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (45874/47744)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.083% (45997/47872)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.081% (46119/48000)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.085% (46244/48128)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.077% (46363/48256)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.079% (46487/48384)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.079% (46610/48512)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.081% (46734/48640)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.079% (46856/48768)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.081% (46980/48896)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.084% (47104/49024)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.084% (47227/49152)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.078% (47347/49280)\n",
      "Train Epoch: 49 | Loss: 0.115 | Acc: 96.074% (47468/49408)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.082% (47595/49536)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.084% (47719/49664)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.084% (47842/49792)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.090% (47968/49920)\n",
      "Train Epoch: 49 | Loss: 0.114 | Acc: 96.090% (48045/50000)\n",
      "Test Epoch: 49 | Loss: 0.326 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 49 | Loss: 0.366 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 49 | Loss: 0.303 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 49 | Loss: 0.323 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 49 | Loss: 0.313 | Acc: 91.000% (455/500)\n",
      "Test Epoch: 49 | Loss: 0.286 | Acc: 91.667% (550/600)\n",
      "Test Epoch: 49 | Loss: 0.313 | Acc: 91.429% (640/700)\n",
      "Test Epoch: 49 | Loss: 0.333 | Acc: 90.750% (726/800)\n",
      "Test Epoch: 49 | Loss: 0.340 | Acc: 90.333% (813/900)\n",
      "Test Epoch: 49 | Loss: 0.340 | Acc: 90.500% (905/1000)\n",
      "Test Epoch: 49 | Loss: 0.346 | Acc: 90.364% (994/1100)\n",
      "Test Epoch: 49 | Loss: 0.353 | Acc: 90.083% (1081/1200)\n",
      "Test Epoch: 49 | Loss: 0.348 | Acc: 90.231% (1173/1300)\n",
      "Test Epoch: 49 | Loss: 0.347 | Acc: 90.357% (1265/1400)\n",
      "Test Epoch: 49 | Loss: 0.346 | Acc: 90.067% (1351/1500)\n",
      "Test Epoch: 49 | Loss: 0.345 | Acc: 90.125% (1442/1600)\n",
      "Test Epoch: 49 | Loss: 0.350 | Acc: 90.176% (1533/1700)\n",
      "Test Epoch: 49 | Loss: 0.354 | Acc: 90.000% (1620/1800)\n",
      "Test Epoch: 49 | Loss: 0.356 | Acc: 89.895% (1708/1900)\n",
      "Test Epoch: 49 | Loss: 0.365 | Acc: 89.650% (1793/2000)\n",
      "Test Epoch: 49 | Loss: 0.373 | Acc: 89.333% (1876/2100)\n",
      "Test Epoch: 49 | Loss: 0.373 | Acc: 89.182% (1962/2200)\n",
      "Test Epoch: 49 | Loss: 0.364 | Acc: 89.348% (2055/2300)\n",
      "Test Epoch: 49 | Loss: 0.364 | Acc: 89.375% (2145/2400)\n",
      "Test Epoch: 49 | Loss: 0.372 | Acc: 89.320% (2233/2500)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.231% (2320/2600)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.222% (2409/2700)\n",
      "Test Epoch: 49 | Loss: 0.376 | Acc: 89.179% (2497/2800)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 89.172% (2586/2900)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 89.100% (2673/3000)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 89.032% (2760/3100)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.125% (2852/3200)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 89.061% (2939/3300)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 89.176% (3032/3400)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.029% (3116/3500)\n",
      "Test Epoch: 49 | Loss: 0.387 | Acc: 88.972% (3203/3600)\n",
      "Test Epoch: 49 | Loss: 0.393 | Acc: 89.000% (3293/3700)\n",
      "Test Epoch: 49 | Loss: 0.396 | Acc: 89.026% (3383/3800)\n",
      "Test Epoch: 49 | Loss: 0.394 | Acc: 89.103% (3475/3900)\n",
      "Test Epoch: 49 | Loss: 0.393 | Acc: 89.100% (3564/4000)\n",
      "Test Epoch: 49 | Loss: 0.399 | Acc: 88.902% (3645/4100)\n",
      "Test Epoch: 49 | Loss: 0.399 | Acc: 88.881% (3733/4200)\n",
      "Test Epoch: 49 | Loss: 0.394 | Acc: 89.000% (3827/4300)\n",
      "Test Epoch: 49 | Loss: 0.397 | Acc: 89.045% (3918/4400)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 89.111% (4010/4500)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 89.065% (4097/4600)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 89.043% (4185/4700)\n",
      "Test Epoch: 49 | Loss: 0.391 | Acc: 89.062% (4275/4800)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 89.224% (4372/4900)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 89.120% (4456/5000)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 49 | Loss: 0.391 | Acc: 89.077% (4632/5200)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 89.057% (4720/5300)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 89.056% (4809/5400)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 89.036% (4897/5500)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 89.054% (4987/5600)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.088% (5078/5700)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 89.155% (5171/5800)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.153% (5260/5900)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 89.167% (5350/6000)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 89.197% (5441/6100)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 89.210% (5531/6200)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 89.254% (5623/6300)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.359% (5719/6400)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 89.385% (5810/6500)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 89.409% (5901/6600)\n",
      "Test Epoch: 49 | Loss: 0.375 | Acc: 89.478% (5995/6700)\n",
      "Test Epoch: 49 | Loss: 0.375 | Acc: 89.500% (6086/6800)\n",
      "Test Epoch: 49 | Loss: 0.374 | Acc: 89.507% (6176/6900)\n",
      "Test Epoch: 49 | Loss: 0.375 | Acc: 89.471% (6263/7000)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 89.479% (6353/7100)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.444% (6440/7200)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.466% (6531/7300)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.473% (6621/7400)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.427% (6707/7500)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 89.421% (6796/7600)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.403% (6884/7700)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.410% (6974/7800)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 89.443% (7066/7900)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.438% (7155/8000)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 89.494% (7249/8100)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.439% (7334/8200)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 89.434% (7423/8300)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 89.393% (7509/8400)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 89.365% (7596/8500)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 89.337% (7683/8600)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 89.368% (7775/8700)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.341% (7862/8800)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.337% (7951/8900)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.344% (8041/9000)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.319% (8128/9100)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 89.337% (8219/9200)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 89.323% (8307/9300)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 89.340% (8398/9400)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 89.347% (8488/9500)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 89.375% (8580/9600)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.443% (8676/9700)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.439% (8765/9800)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.455% (8856/9900)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 89.470% (8947/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Train Epoch: 50 | Loss: 0.075 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 50 | Loss: 0.116 | Acc: 95.703% (245/256)\n",
      "Train Epoch: 50 | Loss: 0.094 | Acc: 96.875% (372/384)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.094% (492/512)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.562% (618/640)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.484% (741/768)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.317% (863/896)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.191% (985/1024)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 95.920% (1105/1152)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.172% (1231/1280)\n",
      "Train Epoch: 50 | Loss: 0.111 | Acc: 95.952% (1351/1408)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.159% (1477/1536)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.394% (1604/1664)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.317% (1726/1792)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.406% (1851/1920)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.484% (1976/2048)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.415% (2098/2176)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.398% (2221/2304)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.464% (2346/2432)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.484% (2470/2560)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.317% (2589/2688)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.271% (2711/2816)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.332% (2836/2944)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.452% (2963/3072)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.375% (3084/3200)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.244% (3203/3328)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.238% (3326/3456)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.289% (3451/3584)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.309% (3575/3712)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.354% (3700/3840)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.396% (3825/3968)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.411% (3949/4096)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.402% (4072/4224)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.438% (4197/4352)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.451% (4321/4480)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.463% (4445/4608)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.495% (4570/4736)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.505% (4694/4864)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.474% (4816/4992)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.426% (4937/5120)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.418% (5060/5248)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.447% (5185/5376)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.421% (5307/5504)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.431% (5431/5632)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.389% (5552/5760)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.399% (5676/5888)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.410% (5800/6016)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.452% (5926/6144)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.460% (6050/6272)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.453% (6173/6400)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.431% (6295/6528)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.409% (6417/6656)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.418% (6541/6784)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.470% (6668/6912)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.420% (6788/7040)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.387% (6909/7168)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.382% (7032/7296)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.336% (7152/7424)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.306% (7273/7552)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.315% (7397/7680)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.247% (7515/7808)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.270% (7640/7936)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.292% (7765/8064)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.289% (7888/8192)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.262% (8009/8320)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.259% (8132/8448)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.280% (8257/8576)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.266% (8379/8704)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.264% (8502/8832)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.261% (8625/8960)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.292% (8751/9088)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.246% (8870/9216)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.233% (8992/9344)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.199% (9112/9472)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.229% (9238/9600)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.227% (9361/9728)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.236% (9485/9856)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.234% (9608/9984)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.222% (9730/10112)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.211% (9852/10240)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.219% (9976/10368)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.237% (10101/10496)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.244% (10225/10624)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.261% (10350/10752)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.259% (10473/10880)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.257% (10596/11008)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.282% (10722/11136)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.289% (10846/11264)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.261% (10966/11392)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.224% (11085/11520)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.248% (11211/11648)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.247% (11334/11776)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.270% (11460/11904)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.285% (11585/12032)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.299% (11710/12160)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.297% (11833/12288)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.311% (11958/12416)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.317% (12082/12544)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.338% (12208/12672)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.344% (12332/12800)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.364% (12458/12928)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.392% (12585/13056)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.374% (12706/13184)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.342% (12825/13312)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.347% (12949/13440)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.352% (13073/13568)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.364% (13198/13696)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.347% (13319/13824)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.345% (13442/13952)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.342% (13565/14080)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.312% (13684/14208)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.289% (13804/14336)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.260% (13923/14464)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.279% (14049/14592)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.264% (14170/14720)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.262% (14293/14848)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.274% (14418/14976)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.292% (14544/15104)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.291% (14667/15232)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.296% (14791/15360)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.307% (14916/15488)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.311% (15040/15616)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.310% (15163/15744)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.302% (15285/15872)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.306% (15409/16000)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.280% (15528/16128)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.284% (15652/16256)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.295% (15777/16384)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.300% (15901/16512)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.292% (16023/16640)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.273% (16143/16768)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.283% (16268/16896)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.282% (16391/17024)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.274% (16513/17152)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.279% (16637/17280)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.283% (16761/17408)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.305% (16888/17536)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.326% (17015/17664)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.335% (17140/17792)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.339% (17264/17920)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.326% (17385/18048)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.341% (17511/18176)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.351% (17636/18304)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.360% (17761/18432)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.374% (17887/18560)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.388% (18013/18688)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.381% (18135/18816)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.379% (18258/18944)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.377% (18381/19072)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.396% (18508/19200)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.415% (18635/19328)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.402% (18756/19456)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.395% (18878/19584)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.378% (18998/19712)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.371% (19120/19840)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.384% (19246/19968)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.392% (19371/20096)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.390% (19494/20224)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.389% (19617/20352)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.382% (19739/20480)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.390% (19864/20608)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.388% (19987/20736)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.396% (20112/20864)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.399% (20236/20992)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.416% (20363/21120)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.428% (20489/21248)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.435% (20614/21376)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.424% (20735/21504)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.417% (20857/21632)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.420% (20981/21760)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.409% (21102/21888)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.407% (21225/22016)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.410% (21349/22144)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.430% (21477/22272)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.420% (21598/22400)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.427% (21723/22528)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.434% (21848/22656)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.440% (21973/22784)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.434% (22095/22912)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.437% (22219/23040)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.452% (22346/23168)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.446% (22468/23296)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.448% (22592/23424)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.446% (22715/23552)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.444% (22838/23680)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.455% (22964/23808)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.457% (23088/23936)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.455% (23211/24064)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.453% (23334/24192)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.443% (23455/24320)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.437% (23577/24448)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.448% (23703/24576)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.458% (23829/24704)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.452% (23951/24832)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.458% (24076/24960)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.460% (24200/25088)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.459% (24323/25216)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.465% (24448/25344)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.459% (24570/25472)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.457% (24693/25600)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.467% (24819/25728)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.465% (24942/25856)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.471% (25067/25984)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.473% (25191/26112)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.471% (25314/26240)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.473% (25438/26368)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.479% (25563/26496)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.481% (25687/26624)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.483% (25811/26752)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.492% (25937/26880)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.501% (26063/27008)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.506% (26188/27136)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.494% (26308/27264)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.499% (26433/27392)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.490% (26554/27520)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.474% (26673/27648)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.475% (26797/27776)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.477% (26921/27904)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.475% (27044/28032)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.474% (27167/28160)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.479% (27292/28288)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.481% (27416/28416)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.476% (27538/28544)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.484% (27664/28672)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.486% (27788/28800)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.491% (27913/28928)\n",
      "Train Epoch: 50 | Loss: 0.103 | Acc: 96.486% (28035/29056)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.474% (28155/29184)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.472% (28278/29312)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.454% (28396/29440)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.442% (28516/29568)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.451% (28642/29696)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.442% (28763/29824)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.431% (28883/29952)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.439% (29009/30080)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.441% (29133/30208)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.446% (29258/30336)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.455% (29384/30464)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.453% (29507/30592)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.449% (29629/30720)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.441% (29750/30848)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.436% (29872/30976)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.435% (29995/31104)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.430% (30117/31232)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.429% (30240/31360)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.427% (30363/31488)\n",
      "Train Epoch: 50 | Loss: 0.104 | Acc: 96.429% (30487/31616)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.425% (30609/31744)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.423% (30732/31872)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.416% (30853/32000)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.408% (30974/32128)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.391% (31092/32256)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.390% (31215/32384)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.386% (31337/32512)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.388% (31461/32640)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.384% (31583/32768)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.392% (31709/32896)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.403% (31836/33024)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.392% (31956/33152)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.376% (32074/33280)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.387% (32201/33408)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.395% (32327/33536)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.394% (32450/33664)\n",
      "Train Epoch: 50 | Loss: 0.105 | Acc: 96.393% (32573/33792)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.389% (32695/33920)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.390% (32819/34048)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.389% (32942/34176)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.391% (33066/34304)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.378% (33185/34432)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.363% (33303/34560)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.362% (33426/34688)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.352% (33546/34816)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.354% (33670/34944)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.345% (33790/35072)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.338% (33911/35200)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.343% (34036/35328)\n",
      "Train Epoch: 50 | Loss: 0.106 | Acc: 96.350% (34162/35456)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.344% (34283/35584)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.343% (34406/35712)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.339% (34528/35840)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.333% (34649/35968)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.329% (34771/36096)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.337% (34897/36224)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.339% (35021/36352)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.338% (35144/36480)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.331% (35265/36608)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.331% (35388/36736)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.332% (35512/36864)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.340% (35638/36992)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.342% (35762/37120)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.341% (35885/37248)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.335% (36006/37376)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.334% (36129/37504)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.333% (36252/37632)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.335% (36376/37760)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.326% (36496/37888)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.325% (36619/38016)\n",
      "Train Epoch: 50 | Loss: 0.107 | Acc: 96.319% (36740/38144)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.313% (36861/38272)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.294% (36977/38400)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.286% (37097/38528)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.275% (37216/38656)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.274% (37339/38784)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.279% (37464/38912)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.278% (37587/39040)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.272% (37708/39168)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.269% (37830/39296)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.269% (37953/39424)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.268% (38076/39552)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.270% (38200/39680)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.265% (38321/39808)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.267% (38445/39936)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.266% (38568/40064)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.265% (38691/40192)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.270% (38816/40320)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.274% (38941/40448)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.284% (39068/40576)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.276% (39188/40704)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.277% (39312/40832)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.277% (39435/40960)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.281% (39560/41088)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.281% (39683/41216)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.275% (39804/41344)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.282% (39930/41472)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.267% (40047/41600)\n",
      "Train Epoch: 50 | Loss: 0.108 | Acc: 96.259% (40167/41728)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.249% (40286/41856)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.246% (40408/41984)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.253% (40534/42112)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (40655/42240)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.245% (40777/42368)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.237% (40897/42496)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.239% (41021/42624)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.243% (41146/42752)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (41271/42880)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.254% (41397/43008)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.249% (41518/43136)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.246% (41640/43264)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (41764/43392)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.243% (41885/43520)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.234% (42004/43648)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.233% (42127/43776)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.233% (42250/43904)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.225% (42370/44032)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.225% (42493/44160)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.227% (42617/44288)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.231% (42742/44416)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.233% (42866/44544)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.235% (42990/44672)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.225% (43109/44800)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.230% (43234/44928)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.231% (43358/45056)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.231% (43481/45184)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.235% (43606/45312)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.237% (43730/45440)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.241% (43855/45568)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.245% (43980/45696)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.251% (44106/45824)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (44228/45952)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (44351/46080)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.245% (44473/46208)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.249% (44598/46336)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.251% (44722/46464)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.253% (44846/46592)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.256% (44971/46720)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.262% (45097/46848)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.260% (45219/46976)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.261% (45343/47104)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.259% (45465/47232)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.261% (45589/47360)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.264% (45714/47488)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.262% (45836/47616)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.257% (45957/47744)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.255% (46079/47872)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.254% (46202/48000)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.250% (46323/48128)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.249% (46446/48256)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.251% (46570/48384)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.252% (46694/48512)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.250% (46816/48640)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.252% (46940/48768)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.249% (47062/48896)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.251% (47186/49024)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.250% (47309/49152)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.252% (47433/49280)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.248% (47554/49408)\n",
      "Train Epoch: 50 | Loss: 0.109 | Acc: 96.253% (47680/49536)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.247% (47800/49664)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.240% (47920/49792)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.240% (48043/49920)\n",
      "Train Epoch: 50 | Loss: 0.110 | Acc: 96.242% (48121/50000)\n",
      "Test Epoch: 50 | Loss: 0.453 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 50 | Loss: 0.388 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 50 | Loss: 0.344 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 50 | Loss: 0.371 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 50 | Loss: 0.357 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 50 | Loss: 0.323 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 50 | Loss: 0.341 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 50 | Loss: 0.365 | Acc: 89.375% (715/800)\n",
      "Test Epoch: 50 | Loss: 0.379 | Acc: 88.889% (800/900)\n",
      "Test Epoch: 50 | Loss: 0.386 | Acc: 89.300% (893/1000)\n",
      "Test Epoch: 50 | Loss: 0.398 | Acc: 89.273% (982/1100)\n",
      "Test Epoch: 50 | Loss: 0.406 | Acc: 88.917% (1067/1200)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 88.923% (1156/1300)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 89.071% (1247/1400)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.133% (1337/1500)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 89.312% (1429/1600)\n",
      "Test Epoch: 50 | Loss: 0.378 | Acc: 89.412% (1520/1700)\n",
      "Test Epoch: 50 | Loss: 0.378 | Acc: 89.333% (1608/1800)\n",
      "Test Epoch: 50 | Loss: 0.379 | Acc: 89.316% (1697/1900)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.150% (1783/2000)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 88.810% (1865/2100)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 88.727% (1952/2200)\n",
      "Test Epoch: 50 | Loss: 0.386 | Acc: 88.957% (2046/2300)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 89.000% (2136/2400)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.000% (2225/2500)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 88.962% (2313/2600)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.148% (2407/2700)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 89.143% (2496/2800)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.207% (2587/2900)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.167% (2675/3000)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 89.290% (2768/3100)\n",
      "Test Epoch: 50 | Loss: 0.388 | Acc: 89.219% (2855/3200)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 89.152% (2942/3300)\n",
      "Test Epoch: 50 | Loss: 0.386 | Acc: 89.176% (3032/3400)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.000% (3115/3500)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.028% (3205/3600)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 89.081% (3296/3700)\n",
      "Test Epoch: 50 | Loss: 0.398 | Acc: 89.158% (3388/3800)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 89.077% (3474/3900)\n",
      "Test Epoch: 50 | Loss: 0.400 | Acc: 89.050% (3562/4000)\n",
      "Test Epoch: 50 | Loss: 0.406 | Acc: 88.951% (3647/4100)\n",
      "Test Epoch: 50 | Loss: 0.406 | Acc: 88.952% (3736/4200)\n",
      "Test Epoch: 50 | Loss: 0.398 | Acc: 89.116% (3832/4300)\n",
      "Test Epoch: 50 | Loss: 0.400 | Acc: 89.159% (3923/4400)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 89.267% (4017/4500)\n",
      "Test Epoch: 50 | Loss: 0.396 | Acc: 89.196% (4103/4600)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.234% (4194/4700)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 89.125% (4278/4800)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.224% (4372/4900)\n",
      "Test Epoch: 50 | Loss: 0.400 | Acc: 89.120% (4456/5000)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 50 | Loss: 0.401 | Acc: 89.115% (4634/5200)\n",
      "Test Epoch: 50 | Loss: 0.402 | Acc: 89.057% (4720/5300)\n",
      "Test Epoch: 50 | Loss: 0.402 | Acc: 89.093% (4811/5400)\n",
      "Test Epoch: 50 | Loss: 0.403 | Acc: 89.073% (4899/5500)\n",
      "Test Epoch: 50 | Loss: 0.405 | Acc: 89.054% (4987/5600)\n",
      "Test Epoch: 50 | Loss: 0.405 | Acc: 89.018% (5074/5700)\n",
      "Test Epoch: 50 | Loss: 0.403 | Acc: 89.034% (5164/5800)\n",
      "Test Epoch: 50 | Loss: 0.404 | Acc: 88.983% (5250/5900)\n",
      "Test Epoch: 50 | Loss: 0.402 | Acc: 88.983% (5339/6000)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 89.049% (5432/6100)\n",
      "Test Epoch: 50 | Loss: 0.399 | Acc: 89.048% (5521/6200)\n",
      "Test Epoch: 50 | Loss: 0.398 | Acc: 89.079% (5612/6300)\n",
      "Test Epoch: 50 | Loss: 0.396 | Acc: 89.172% (5707/6400)\n",
      "Test Epoch: 50 | Loss: 0.397 | Acc: 89.138% (5794/6500)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.242% (5890/6600)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 89.299% (5983/6700)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.309% (6073/6800)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.275% (6160/6900)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.271% (6249/7000)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.296% (6340/7100)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.278% (6428/7200)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.274% (6517/7300)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.284% (6607/7400)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.280% (6696/7500)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.289% (6786/7600)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 89.260% (6873/7700)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.269% (6963/7800)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.291% (7054/7900)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.287% (7143/8000)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 89.333% (7236/8100)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 89.317% (7324/8200)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.361% (7417/8300)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 89.345% (7505/8400)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.306% (7591/8500)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.291% (7679/8600)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 89.299% (7769/8700)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.284% (7857/8800)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.247% (7943/8900)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 89.189% (8027/9000)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 89.231% (8120/9100)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.250% (8211/9200)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 89.258% (8301/9300)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 89.266% (8391/9400)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 89.305% (8484/9500)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 89.323% (8575/9600)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.371% (8669/9700)\n",
      "Test Epoch: 50 | Loss: 0.388 | Acc: 89.408% (8762/9800)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 89.414% (8852/9900)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 89.460% (8946/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Train Epoch: 51 | Loss: 0.087 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 51 | Loss: 0.081 | Acc: 96.875% (248/256)\n",
      "Train Epoch: 51 | Loss: 0.090 | Acc: 96.615% (371/384)\n",
      "Train Epoch: 51 | Loss: 0.097 | Acc: 96.484% (494/512)\n",
      "Train Epoch: 51 | Loss: 0.087 | Acc: 97.031% (621/640)\n",
      "Train Epoch: 51 | Loss: 0.094 | Acc: 96.745% (743/768)\n",
      "Train Epoch: 51 | Loss: 0.100 | Acc: 96.205% (862/896)\n",
      "Train Epoch: 51 | Loss: 0.095 | Acc: 96.582% (989/1024)\n",
      "Train Epoch: 51 | Loss: 0.093 | Acc: 96.875% (1116/1152)\n",
      "Train Epoch: 51 | Loss: 0.094 | Acc: 96.719% (1238/1280)\n",
      "Train Epoch: 51 | Loss: 0.096 | Acc: 96.662% (1361/1408)\n",
      "Train Epoch: 51 | Loss: 0.100 | Acc: 96.615% (1484/1536)\n",
      "Train Epoch: 51 | Loss: 0.098 | Acc: 96.635% (1608/1664)\n",
      "Train Epoch: 51 | Loss: 0.099 | Acc: 96.540% (1730/1792)\n",
      "Train Epoch: 51 | Loss: 0.101 | Acc: 96.510% (1853/1920)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.387% (1974/2048)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.140% (2092/2176)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.137% (2215/2304)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.094% (2337/2432)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.133% (2461/2560)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.131% (2584/2688)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.236% (2710/2816)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.264% (2834/2944)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.289% (2958/3072)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.344% (3083/3200)\n",
      "Train Epoch: 51 | Loss: 0.111 | Acc: 96.124% (3199/3328)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.181% (3324/3456)\n",
      "Train Epoch: 51 | Loss: 0.111 | Acc: 96.150% (3446/3584)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.255% (3573/3712)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.198% (3694/3840)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.245% (3819/3968)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.289% (3944/4096)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.330% (4069/4224)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.278% (4190/4352)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.295% (4314/4480)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.332% (4439/4608)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.347% (4563/4736)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.361% (4687/4864)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.394% (4812/4992)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.328% (4932/5120)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.303% (5054/5248)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.373% (5181/5376)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.421% (5307/5504)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.378% (5428/5632)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.424% (5554/5760)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.433% (5678/5888)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.376% (5798/6016)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.387% (5922/6144)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.413% (6047/6272)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.453% (6173/6400)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.415% (6294/6528)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.409% (6417/6656)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.403% (6540/6784)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.398% (6663/6912)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.435% (6789/7040)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.470% (6915/7168)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.450% (7037/7296)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.430% (7159/7424)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.345% (7276/7552)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.328% (7398/7680)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.350% (7523/7808)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.308% (7643/7936)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.280% (7764/8064)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.289% (7888/8192)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.262% (8009/8320)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.295% (8135/8448)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.280% (8257/8576)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.255% (8378/8704)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.275% (8503/8832)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.306% (8629/8960)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.292% (8751/9088)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.267% (8872/9216)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.318% (9000/9344)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.337% (9125/9472)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.323% (9247/9600)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.330% (9371/9728)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.337% (9495/9856)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.364% (9621/9984)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.351% (9743/10112)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.357% (9867/10240)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.373% (9992/10368)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.361% (10114/10496)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.367% (10238/10624)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.373% (10362/10752)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.379% (10486/10880)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.394% (10611/11008)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.390% (10734/11136)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.387% (10857/11264)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.392% (10981/11392)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.389% (11104/11520)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.386% (11227/11648)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.399% (11352/11776)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.430% (11479/11904)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.418% (11601/12032)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.406% (11723/12160)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.395% (11845/12288)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.424% (11972/12416)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.413% (12094/12544)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.425% (12219/12672)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.406% (12340/12800)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.403% (12463/12928)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.415% (12588/13056)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.390% (12708/13184)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.394% (12832/13312)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.376% (12953/13440)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.381% (13077/13568)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.379% (13200/13696)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.390% (13325/13824)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.373% (13446/13952)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.371% (13569/14080)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.389% (13695/14208)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.394% (13819/14336)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.356% (13937/14464)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.340% (14058/14592)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.338% (14181/14720)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.356% (14307/14848)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.368% (14432/14976)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.372% (14556/15104)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.369% (14679/15232)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.367% (14802/15360)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.371% (14926/15488)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.350% (15046/15616)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.354% (15170/15744)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.358% (15294/15872)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.369% (15419/16000)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.373% (15543/16128)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.383% (15668/16256)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.381% (15791/16384)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.391% (15916/16512)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.406% (16042/16640)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.404% (16165/16768)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.402% (16288/16896)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.399% (16411/17024)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.385% (16532/17152)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.400% (16658/17280)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.410% (16783/17408)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.424% (16909/17536)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.428% (17033/17664)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.437% (17158/17792)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.451% (17284/17920)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.459% (17409/18048)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.451% (17531/18176)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.460% (17656/18304)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.468% (17781/18432)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.471% (17905/18560)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.447% (18024/18688)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.455% (18149/18816)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.458% (18273/18944)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.445% (18394/19072)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.448% (18518/19200)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.461% (18644/19328)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.469% (18769/19456)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.467% (18892/19584)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.464% (19015/19712)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.457% (19137/19840)\n",
      "Train Epoch: 51 | Loss: 0.102 | Acc: 96.449% (19259/19968)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.427% (19378/20096)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.430% (19502/20224)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.413% (19622/20352)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.401% (19743/20480)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.404% (19867/20608)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.417% (19993/20736)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.405% (20114/20864)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.399% (20236/20992)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.411% (20362/21120)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.414% (20486/21248)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.398% (20606/21376)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.415% (20733/21504)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.408% (20855/21632)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.420% (20981/21760)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.409% (21102/21888)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.389% (21221/22016)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.401% (21347/22144)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.390% (21468/22272)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.388% (21591/22400)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.400% (21717/22528)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.412% (21843/22656)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.423% (21969/22784)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.399% (22087/22912)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.402% (22211/23040)\n",
      "Train Epoch: 51 | Loss: 0.103 | Acc: 96.400% (22334/23168)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.386% (22454/23296)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.384% (22577/23424)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.382% (22700/23552)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.389% (22825/23680)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.400% (22951/23808)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.378% (23069/23936)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.380% (23193/24064)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.375% (23315/24192)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.365% (23436/24320)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.376% (23562/24448)\n",
      "Train Epoch: 51 | Loss: 0.104 | Acc: 96.375% (23685/24576)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.357% (23804/24704)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.356% (23927/24832)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.358% (24051/24960)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.365% (24176/25088)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.355% (24297/25216)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.338% (24416/25344)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.341% (24540/25472)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.332% (24661/25600)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.311% (24779/25728)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.322% (24905/25856)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.321% (25028/25984)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.327% (25153/26112)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.334% (25278/26240)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.340% (25403/26368)\n",
      "Train Epoch: 51 | Loss: 0.105 | Acc: 96.324% (25522/26496)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.323% (25645/26624)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.322% (25768/26752)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.321% (25891/26880)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.312% (26012/27008)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.300% (26132/27136)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.292% (26253/27264)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.291% (26376/27392)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.279% (26496/27520)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.271% (26617/27648)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.277% (26742/27776)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.287% (26868/27904)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.283% (26990/28032)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.282% (27113/28160)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.271% (27233/28288)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.277% (27358/28416)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.290% (27485/28544)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.296% (27610/28672)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.299% (27734/28800)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.280% (27852/28928)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.283% (27976/29056)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.286% (28100/29184)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.288% (28224/29312)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.287% (28347/29440)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.300% (28474/29568)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.303% (28598/29696)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.312% (28724/29824)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.317% (28849/29952)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.316% (28972/30080)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.312% (29094/30208)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.301% (29214/30336)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.304% (29338/30464)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.303% (29461/30592)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.292% (29581/30720)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.291% (29704/30848)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.297% (29829/30976)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.296% (29952/31104)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.299% (30076/31232)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.301% (30200/31360)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.303% (30324/31488)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.312% (30450/31616)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.314% (30574/31744)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.307% (30695/31872)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.300% (30816/32000)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.299% (30939/32128)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.298% (31062/32256)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.291% (31183/32384)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.291% (31306/32512)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.284% (31427/32640)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.286% (31551/32768)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.282% (31673/32896)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.269% (31792/33024)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.263% (31913/33152)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.259% (32035/33280)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.252% (32156/33408)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.252% (32279/33536)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.257% (32404/33664)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.259% (32528/33792)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.250% (32648/33920)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.255% (32773/34048)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.266% (32900/34176)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.254% (33019/34304)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.256% (33143/34432)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.262% (33268/34560)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.255% (33389/34688)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.266% (33516/34816)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.265% (33639/34944)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.268% (33763/35072)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.270% (33887/35200)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.266% (34009/35328)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.266% (34132/35456)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.262% (34254/35584)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.248% (34372/35712)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.247% (34495/35840)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.252% (34620/35968)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.249% (34742/36096)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.257% (34868/36224)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.256% (34991/36352)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.258% (35115/36480)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.266% (35241/36608)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.257% (35361/36736)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.265% (35487/36864)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.261% (35609/36992)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.261% (35732/37120)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.263% (35856/37248)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.262% (35979/37376)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.262% (36102/37504)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.272% (36229/37632)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.269% (36351/37760)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.271% (36475/37888)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.259% (36594/38016)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.272% (36722/38144)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.274% (36846/38272)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.258% (36963/38400)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.262% (37088/38528)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.267% (37213/38656)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.256% (37332/38784)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.256% (37455/38912)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.265% (37582/39040)\n",
      "Train Epoch: 51 | Loss: 0.106 | Acc: 96.265% (37705/39168)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.252% (37823/39296)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.246% (37944/39424)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.245% (38067/39552)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.253% (38193/39680)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.255% (38317/39808)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.249% (38438/39936)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.244% (38559/40064)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.236% (38679/40192)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.248% (38807/40320)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.240% (38927/40448)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.234% (39048/40576)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.229% (39169/40704)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.228% (39292/40832)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.226% (39414/40960)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.223% (39536/41088)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.220% (39658/41216)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.220% (39781/41344)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.219% (39904/41472)\n",
      "Train Epoch: 51 | Loss: 0.107 | Acc: 96.228% (40031/41600)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.226% (40153/41728)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.225% (40276/41856)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.227% (40400/41984)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.227% (40523/42112)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.217% (40642/42240)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.221% (40767/42368)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.218% (40889/42496)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.218% (41012/42624)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.222% (41137/42752)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.222% (41260/42880)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.222% (41383/43008)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.212% (41502/43136)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.207% (41623/43264)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.200% (41743/43392)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.197% (41865/43520)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.195% (41987/43648)\n",
      "Train Epoch: 51 | Loss: 0.108 | Acc: 96.197% (42111/43776)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.192% (42232/43904)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.191% (42355/44032)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.196% (42480/44160)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.191% (42601/44288)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.193% (42725/44416)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.190% (42847/44544)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.177% (42964/44672)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.174% (43086/44800)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.174% (43209/44928)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.169% (43330/45056)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.169% (43453/45184)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.173% (43578/45312)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.175% (43702/45440)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.171% (43823/45568)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.173% (43947/45696)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.172% (44070/45824)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.170% (44192/45952)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.168% (44314/46080)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.165% (44436/46208)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.154% (44554/46336)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.152% (44676/46464)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.150% (44798/46592)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.152% (44922/46720)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.156% (45047/46848)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.155% (45170/46976)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.155% (45293/47104)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.155% (45416/47232)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.149% (45536/47360)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.144% (45657/47488)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.142% (45779/47616)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.136% (45899/47744)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.136% (46022/47872)\n",
      "Train Epoch: 51 | Loss: 0.110 | Acc: 96.138% (46146/48000)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.146% (46273/48128)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.154% (46400/48256)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.156% (46524/48384)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.154% (46646/48512)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.149% (46767/48640)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.153% (46892/48768)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.145% (47011/48896)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.143% (47133/49024)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.149% (47259/49152)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.153% (47384/49280)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.148% (47505/49408)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.150% (47629/49536)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.152% (47753/49664)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.156% (47878/49792)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.158% (48002/49920)\n",
      "Train Epoch: 51 | Loss: 0.109 | Acc: 96.156% (48078/50000)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 51 | Loss: 0.345 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 51 | Loss: 0.317 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 51 | Loss: 0.365 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 51 | Loss: 0.347 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 51 | Loss: 0.320 | Acc: 90.333% (542/600)\n",
      "Test Epoch: 51 | Loss: 0.336 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 51 | Loss: 0.373 | Acc: 89.375% (715/800)\n",
      "Test Epoch: 51 | Loss: 0.388 | Acc: 89.111% (802/900)\n",
      "Test Epoch: 51 | Loss: 0.382 | Acc: 89.000% (890/1000)\n",
      "Test Epoch: 51 | Loss: 0.389 | Acc: 88.545% (974/1100)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 88.500% (1062/1200)\n",
      "Test Epoch: 51 | Loss: 0.405 | Acc: 88.462% (1150/1300)\n",
      "Test Epoch: 51 | Loss: 0.409 | Acc: 88.429% (1238/1400)\n",
      "Test Epoch: 51 | Loss: 0.415 | Acc: 88.267% (1324/1500)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 88.688% (1419/1600)\n",
      "Test Epoch: 51 | Loss: 0.397 | Acc: 88.824% (1510/1700)\n",
      "Test Epoch: 51 | Loss: 0.404 | Acc: 88.500% (1593/1800)\n",
      "Test Epoch: 51 | Loss: 0.409 | Acc: 88.421% (1680/1900)\n",
      "Test Epoch: 51 | Loss: 0.426 | Acc: 88.150% (1763/2000)\n",
      "Test Epoch: 51 | Loss: 0.427 | Acc: 88.048% (1849/2100)\n",
      "Test Epoch: 51 | Loss: 0.429 | Acc: 87.955% (1935/2200)\n",
      "Test Epoch: 51 | Loss: 0.422 | Acc: 88.000% (2024/2300)\n",
      "Test Epoch: 51 | Loss: 0.424 | Acc: 88.083% (2114/2400)\n",
      "Test Epoch: 51 | Loss: 0.436 | Acc: 87.880% (2197/2500)\n",
      "Test Epoch: 51 | Loss: 0.444 | Acc: 87.923% (2286/2600)\n",
      "Test Epoch: 51 | Loss: 0.437 | Acc: 88.037% (2377/2700)\n",
      "Test Epoch: 51 | Loss: 0.432 | Acc: 88.036% (2465/2800)\n",
      "Test Epoch: 51 | Loss: 0.440 | Acc: 88.069% (2554/2900)\n",
      "Test Epoch: 51 | Loss: 0.438 | Acc: 88.133% (2644/3000)\n",
      "Test Epoch: 51 | Loss: 0.439 | Acc: 88.129% (2732/3100)\n",
      "Test Epoch: 51 | Loss: 0.434 | Acc: 88.250% (2824/3200)\n",
      "Test Epoch: 51 | Loss: 0.434 | Acc: 88.182% (2910/3300)\n",
      "Test Epoch: 51 | Loss: 0.431 | Acc: 88.206% (2999/3400)\n",
      "Test Epoch: 51 | Loss: 0.441 | Acc: 88.114% (3084/3500)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.194% (3175/3600)\n",
      "Test Epoch: 51 | Loss: 0.455 | Acc: 88.135% (3261/3700)\n",
      "Test Epoch: 51 | Loss: 0.456 | Acc: 88.105% (3348/3800)\n",
      "Test Epoch: 51 | Loss: 0.454 | Acc: 88.179% (3439/3900)\n",
      "Test Epoch: 51 | Loss: 0.457 | Acc: 88.200% (3528/4000)\n",
      "Test Epoch: 51 | Loss: 0.461 | Acc: 88.122% (3613/4100)\n",
      "Test Epoch: 51 | Loss: 0.460 | Acc: 88.119% (3701/4200)\n",
      "Test Epoch: 51 | Loss: 0.452 | Acc: 88.279% (3796/4300)\n",
      "Test Epoch: 51 | Loss: 0.453 | Acc: 88.341% (3887/4400)\n",
      "Test Epoch: 51 | Loss: 0.450 | Acc: 88.422% (3979/4500)\n",
      "Test Epoch: 51 | Loss: 0.452 | Acc: 88.304% (4062/4600)\n",
      "Test Epoch: 51 | Loss: 0.450 | Acc: 88.298% (4150/4700)\n",
      "Test Epoch: 51 | Loss: 0.450 | Acc: 88.292% (4238/4800)\n",
      "Test Epoch: 51 | Loss: 0.445 | Acc: 88.388% (4331/4900)\n",
      "Test Epoch: 51 | Loss: 0.451 | Acc: 88.280% (4414/5000)\n",
      "Test Epoch: 51 | Loss: 0.450 | Acc: 88.275% (4502/5100)\n",
      "Test Epoch: 51 | Loss: 0.453 | Acc: 88.173% (4585/5200)\n",
      "Test Epoch: 51 | Loss: 0.452 | Acc: 88.132% (4671/5300)\n",
      "Test Epoch: 51 | Loss: 0.450 | Acc: 88.167% (4761/5400)\n",
      "Test Epoch: 51 | Loss: 0.451 | Acc: 88.182% (4850/5500)\n",
      "Test Epoch: 51 | Loss: 0.456 | Acc: 88.125% (4935/5600)\n",
      "Test Epoch: 51 | Loss: 0.454 | Acc: 88.140% (5024/5700)\n",
      "Test Epoch: 51 | Loss: 0.452 | Acc: 88.190% (5115/5800)\n",
      "Test Epoch: 51 | Loss: 0.451 | Acc: 88.186% (5203/5900)\n",
      "Test Epoch: 51 | Loss: 0.449 | Acc: 88.217% (5293/6000)\n",
      "Test Epoch: 51 | Loss: 0.445 | Acc: 88.262% (5384/6100)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.226% (5470/6200)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.238% (5559/6300)\n",
      "Test Epoch: 51 | Loss: 0.445 | Acc: 88.250% (5648/6400)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.185% (5732/6500)\n",
      "Test Epoch: 51 | Loss: 0.444 | Acc: 88.273% (5826/6600)\n",
      "Test Epoch: 51 | Loss: 0.442 | Acc: 88.373% (5921/6700)\n",
      "Test Epoch: 51 | Loss: 0.444 | Acc: 88.353% (6008/6800)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.333% (6095/6900)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.229% (6176/7000)\n",
      "Test Epoch: 51 | Loss: 0.448 | Acc: 88.225% (6264/7100)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.222% (6352/7200)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.233% (6441/7300)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.230% (6529/7400)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.187% (6614/7500)\n",
      "Test Epoch: 51 | Loss: 0.449 | Acc: 88.171% (6701/7600)\n",
      "Test Epoch: 51 | Loss: 0.449 | Acc: 88.169% (6789/7700)\n",
      "Test Epoch: 51 | Loss: 0.449 | Acc: 88.154% (6876/7800)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.190% (6967/7900)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.200% (7056/8000)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.284% (7151/8100)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.293% (7240/8200)\n",
      "Test Epoch: 51 | Loss: 0.442 | Acc: 88.265% (7326/8300)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.238% (7412/8400)\n",
      "Test Epoch: 51 | Loss: 0.445 | Acc: 88.165% (7494/8500)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.116% (7578/8600)\n",
      "Test Epoch: 51 | Loss: 0.447 | Acc: 88.103% (7665/8700)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.114% (7754/8800)\n",
      "Test Epoch: 51 | Loss: 0.445 | Acc: 88.124% (7843/8900)\n",
      "Test Epoch: 51 | Loss: 0.446 | Acc: 88.122% (7931/9000)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.187% (8025/9100)\n",
      "Test Epoch: 51 | Loss: 0.442 | Acc: 88.174% (8112/9200)\n",
      "Test Epoch: 51 | Loss: 0.442 | Acc: 88.129% (8196/9300)\n",
      "Test Epoch: 51 | Loss: 0.444 | Acc: 88.128% (8284/9400)\n",
      "Test Epoch: 51 | Loss: 0.444 | Acc: 88.147% (8374/9500)\n",
      "Test Epoch: 51 | Loss: 0.443 | Acc: 88.198% (8467/9600)\n",
      "Test Epoch: 51 | Loss: 0.441 | Acc: 88.237% (8559/9700)\n",
      "Test Epoch: 51 | Loss: 0.440 | Acc: 88.235% (8647/9800)\n",
      "Test Epoch: 51 | Loss: 0.439 | Acc: 88.232% (8735/9900)\n",
      "Test Epoch: 51 | Loss: 0.438 | Acc: 88.270% (8827/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.094% (123/128)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.484% (247/256)\n",
      "Train Epoch: 52 | Loss: 0.080 | Acc: 97.135% (373/384)\n",
      "Train Epoch: 52 | Loss: 0.082 | Acc: 97.070% (497/512)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.719% (619/640)\n",
      "Train Epoch: 52 | Loss: 0.088 | Acc: 96.615% (742/768)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.652% (866/896)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.680% (990/1024)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.615% (1113/1152)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.641% (1237/1280)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.591% (1360/1408)\n",
      "Train Epoch: 52 | Loss: 0.087 | Acc: 96.680% (1485/1536)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.575% (1607/1664)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.763% (1734/1792)\n",
      "Train Epoch: 52 | Loss: 0.086 | Acc: 96.823% (1859/1920)\n",
      "Train Epoch: 52 | Loss: 0.083 | Acc: 96.973% (1986/2048)\n",
      "Train Epoch: 52 | Loss: 0.082 | Acc: 97.013% (2111/2176)\n",
      "Train Epoch: 52 | Loss: 0.082 | Acc: 96.962% (2234/2304)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.957% (2358/2432)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.992% (2483/2560)\n",
      "Train Epoch: 52 | Loss: 0.085 | Acc: 96.987% (2607/2688)\n",
      "Train Epoch: 52 | Loss: 0.086 | Acc: 96.946% (2730/2816)\n",
      "Train Epoch: 52 | Loss: 0.087 | Acc: 96.841% (2851/2944)\n",
      "Train Epoch: 52 | Loss: 0.087 | Acc: 96.842% (2975/3072)\n",
      "Train Epoch: 52 | Loss: 0.085 | Acc: 96.906% (3101/3200)\n",
      "Train Epoch: 52 | Loss: 0.085 | Acc: 96.875% (3224/3328)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.933% (3350/3456)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.959% (3475/3584)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.956% (3599/3712)\n",
      "Train Epoch: 52 | Loss: 0.083 | Acc: 97.005% (3725/3840)\n",
      "Train Epoch: 52 | Loss: 0.084 | Acc: 96.976% (3848/3968)\n",
      "Train Epoch: 52 | Loss: 0.085 | Acc: 96.948% (3971/4096)\n",
      "Train Epoch: 52 | Loss: 0.085 | Acc: 96.922% (4094/4224)\n",
      "Train Epoch: 52 | Loss: 0.086 | Acc: 96.921% (4218/4352)\n",
      "Train Epoch: 52 | Loss: 0.087 | Acc: 96.853% (4339/4480)\n",
      "Train Epoch: 52 | Loss: 0.087 | Acc: 96.897% (4465/4608)\n",
      "Train Epoch: 52 | Loss: 0.088 | Acc: 96.812% (4585/4736)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.793% (4708/4864)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.775% (4831/4992)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.719% (4952/5120)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.742% (5077/5248)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.689% (5198/5376)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.730% (5324/5504)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.751% (5449/5632)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.753% (5573/5760)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.756% (5697/5888)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.775% (5822/6016)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.810% (5948/6144)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.827% (6073/6272)\n",
      "Train Epoch: 52 | Loss: 0.089 | Acc: 96.859% (6199/6400)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.768% (6317/6528)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.770% (6441/6656)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.772% (6565/6784)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.817% (6692/6912)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.776% (6813/7040)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.749% (6935/7168)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.738% (7058/7296)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.740% (7182/7424)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.756% (7307/7552)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.784% (7433/7680)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.798% (7558/7808)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.799% (7682/7936)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.813% (7807/8064)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.863% (7935/8192)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.875% (8060/8320)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.875% (8184/8448)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.887% (8309/8576)\n",
      "Train Epoch: 52 | Loss: 0.090 | Acc: 96.898% (8434/8704)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.875% (8556/8832)\n",
      "Train Epoch: 52 | Loss: 0.091 | Acc: 96.875% (8680/8960)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.886% (8805/9088)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.875% (8928/9216)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.875% (9052/9344)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.864% (9175/9472)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.833% (9296/9600)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.865% (9423/9728)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.865% (9547/9856)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.875% (9672/9984)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.845% (9793/10112)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.797% (9912/10240)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.817% (10038/10368)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.808% (10161/10496)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.800% (10284/10624)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.791% (10407/10752)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.811% (10533/10880)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.830% (10659/11008)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.839% (10784/11136)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.822% (10906/11264)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.822% (11030/11392)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.771% (11148/11520)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.789% (11274/11648)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.824% (11402/11776)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.825% (11526/11904)\n",
      "Train Epoch: 52 | Loss: 0.092 | Acc: 96.817% (11649/12032)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.785% (11769/12160)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.802% (11895/12288)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.794% (12018/12416)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.779% (12140/12544)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.772% (12263/12672)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.750% (12384/12800)\n",
      "Train Epoch: 52 | Loss: 0.093 | Acc: 96.767% (12510/12928)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.737% (12630/13056)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.738% (12754/13184)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.695% (12872/13312)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.682% (12994/13440)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.698% (13120/13568)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.714% (13246/13696)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.723% (13371/13824)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.710% (13493/13952)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.683% (13613/14080)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.685% (13737/14208)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.694% (13862/14336)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.688% (13985/14464)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.697% (14110/14592)\n",
      "Train Epoch: 52 | Loss: 0.094 | Acc: 96.698% (14234/14720)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.680% (14355/14848)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.675% (14478/14976)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.670% (14601/15104)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.671% (14725/15232)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.654% (14846/15360)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.668% (14972/15488)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.651% (15093/15616)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.653% (15217/15744)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.636% (15338/15872)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.638% (15462/16000)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.639% (15586/16128)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.654% (15712/16256)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.655% (15836/16384)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.651% (15959/16512)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.623% (16078/16640)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.642% (16205/16768)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.656% (16331/16896)\n",
      "Train Epoch: 52 | Loss: 0.095 | Acc: 96.669% (16457/17024)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.659% (16579/17152)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.661% (16703/17280)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.651% (16825/17408)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.658% (16950/17536)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.654% (17073/17664)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.650% (17196/17792)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.646% (17319/17920)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.648% (17443/18048)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.638% (17565/18176)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.635% (17688/18304)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.631% (17811/18432)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.638% (17936/18560)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.650% (18062/18688)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.641% (18184/18816)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.632% (18306/18944)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.634% (18430/19072)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.646% (18556/19200)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.637% (18678/19328)\n",
      "Train Epoch: 52 | Loss: 0.096 | Acc: 96.639% (18802/19456)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.640% (18926/19584)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.626% (19047/19712)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.623% (19170/19840)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.620% (19293/19968)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.626% (19418/20096)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.613% (19539/20224)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.610% (19662/20352)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.606% (19785/20480)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.603% (19908/20608)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.600% (20031/20736)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.602% (20155/20864)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.613% (20281/20992)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.615% (20405/21120)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.602% (20526/21248)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.590% (20647/21376)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.591% (20771/21504)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.602% (20897/21632)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.595% (21019/21760)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.601% (21144/21888)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.602% (21268/22016)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.586% (21388/22144)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.601% (21515/22272)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.603% (21639/22400)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.600% (21762/22528)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.588% (21883/22656)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.585% (22006/22784)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.583% (22129/22912)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.589% (22254/23040)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.599% (22380/23168)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.609% (22506/23296)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.598% (22627/23424)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.591% (22749/23552)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.605% (22876/23680)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.594% (22997/23808)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.578% (23117/23936)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.584% (23242/24064)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.590% (23367/24192)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.600% (23493/24320)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.585% (23613/24448)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.590% (23738/24576)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.596% (23863/24704)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.605% (23989/24832)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.611% (24114/24960)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.616% (24239/25088)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.609% (24361/25216)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.599% (24482/25344)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.608% (24608/25472)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.609% (24732/25600)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.611% (24856/25728)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.608% (24979/25856)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.602% (25101/25984)\n",
      "Train Epoch: 52 | Loss: 0.097 | Acc: 96.599% (25224/26112)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.589% (25345/26240)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.587% (25468/26368)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.592% (25593/26496)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.593% (25717/26624)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.587% (25839/26752)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.570% (25958/26880)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.571% (26082/27008)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.584% (26209/27136)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.593% (26335/27264)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.598% (26460/27392)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.602% (26585/27520)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.600% (26708/27648)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.594% (26830/27776)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.592% (26953/27904)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.582% (27074/28032)\n",
      "Train Epoch: 52 | Loss: 0.098 | Acc: 96.584% (27198/28160)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.585% (27322/28288)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.583% (27445/28416)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.574% (27566/28544)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.575% (27690/28672)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.576% (27814/28800)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.574% (27937/28928)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.576% (28061/29056)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.570% (28183/29184)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (28304/29312)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.566% (28429/29440)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.574% (28555/29568)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.579% (28680/29696)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.560% (28798/29824)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (28922/29952)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.556% (29044/30080)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.554% (29167/30208)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.552% (29290/30336)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.550% (29413/30464)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.548% (29536/30592)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.559% (29663/30720)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.564% (29788/30848)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (29911/30976)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.560% (30034/31104)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.552% (30155/31232)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.550% (30278/31360)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.548% (30401/31488)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.546% (30524/31616)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.554% (30650/31744)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.549% (30772/31872)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.556% (30898/32000)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.548% (31019/32128)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.549% (31143/32256)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.548% (31266/32384)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.543% (31388/32512)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.538% (31510/32640)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.530% (31631/32768)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.531% (31755/32896)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.536% (31880/33024)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.540% (32005/33152)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.535% (32127/33280)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.537% (32251/33408)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.544% (32377/33536)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.545% (32501/33664)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.547% (32625/33792)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.539% (32746/33920)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.540% (32870/34048)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.533% (32991/34176)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.534% (33115/34304)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.538% (33240/34432)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.542% (33365/34560)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.532% (33485/34688)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.527% (33607/34816)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.532% (33732/34944)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.530% (33855/35072)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.531% (33979/35200)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.538% (34105/35328)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.542% (34230/35456)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.543% (34354/35584)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.547% (34479/35712)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.549% (34603/35840)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.547% (34726/35968)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.545% (34849/36096)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.533% (34968/36224)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.539% (35094/36352)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.538% (35217/36480)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.534% (35339/36608)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.546% (35467/36736)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.544% (35590/36864)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.534% (35710/36992)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.541% (35836/37120)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.545% (35961/37248)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.543% (36084/37376)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.539% (36206/37504)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.540% (36330/37632)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.536% (36452/37760)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.540% (36577/37888)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.544% (36702/38016)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.542% (36825/38144)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.546% (36950/38272)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.555% (37077/38400)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.558% (37202/38528)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.557% (37325/38656)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.558% (37449/38784)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (37574/38912)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (37698/39040)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.569% (37824/39168)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (37945/39296)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.555% (38066/39424)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.549% (38187/39552)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.547% (38310/39680)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.538% (38430/39808)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.547% (38557/39936)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.548% (38681/40064)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.542% (38802/40192)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.530% (38921/40320)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.536% (39047/40448)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.532% (39169/40576)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.534% (39293/40704)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.535% (39417/40832)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.541% (39543/40960)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.539% (39666/41088)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.543% (39791/41216)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.544% (39915/41344)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.547% (40040/41472)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.550% (40165/41600)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (40293/41728)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.555% (40414/41856)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (40540/41984)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.559% (40663/42112)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (40788/42240)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.566% (40913/42368)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (41035/42496)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.561% (41158/42624)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.562% (41282/42752)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.560% (41405/42880)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.559% (41528/43008)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.557% (41651/43136)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.561% (41776/43264)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.566% (41902/43392)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.560% (42023/43520)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.566% (42149/43648)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.560% (42270/43776)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.563% (42395/43904)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.555% (42515/44032)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.549% (42636/44160)\n",
      "Train Epoch: 52 | Loss: 0.099 | Acc: 96.552% (42761/44288)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.537% (42878/44416)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.536% (43001/44544)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.539% (43126/44672)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.536% (43248/44800)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.543% (43375/44928)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.531% (43493/45056)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.525% (43614/45184)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.524% (43737/45312)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.527% (43862/45440)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.528% (43986/45568)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.529% (44110/45696)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.524% (44231/45824)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.525% (44355/45952)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.523% (44478/46080)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.524% (44602/46208)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.525% (44726/46336)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.522% (44848/46464)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.519% (44970/46592)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.511% (45090/46720)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.516% (45216/46848)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.515% (45339/46976)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.514% (45462/47104)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.513% (45585/47232)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.514% (45709/47360)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.506% (45829/47488)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.503% (45951/47616)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.506% (46076/47744)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.503% (46198/47872)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.504% (46322/48000)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.505% (46446/48128)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.504% (46569/48256)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.503% (46692/48384)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.500% (46814/48512)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.503% (46939/48640)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.502% (47062/48768)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.497% (47183/48896)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.498% (47307/49024)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.488% (47426/49152)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.491% (47551/49280)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.486% (47672/49408)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.487% (47796/49536)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.490% (47921/49664)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.499% (48049/49792)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.502% (48174/49920)\n",
      "Train Epoch: 52 | Loss: 0.100 | Acc: 96.502% (48251/50000)\n",
      "Test Epoch: 52 | Loss: 0.445 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 52 | Loss: 0.414 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 52 | Loss: 0.414 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 52 | Loss: 0.384 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 90.000% (540/600)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 90.143% (631/700)\n",
      "Test Epoch: 52 | Loss: 0.379 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 52 | Loss: 0.403 | Acc: 88.556% (797/900)\n",
      "Test Epoch: 52 | Loss: 0.422 | Acc: 88.500% (885/1000)\n",
      "Test Epoch: 52 | Loss: 0.430 | Acc: 88.364% (972/1100)\n",
      "Test Epoch: 52 | Loss: 0.445 | Acc: 88.083% (1057/1200)\n",
      "Test Epoch: 52 | Loss: 0.442 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 52 | Loss: 0.439 | Acc: 88.214% (1235/1400)\n",
      "Test Epoch: 52 | Loss: 0.446 | Acc: 88.000% (1320/1500)\n",
      "Test Epoch: 52 | Loss: 0.441 | Acc: 88.250% (1412/1600)\n",
      "Test Epoch: 52 | Loss: 0.443 | Acc: 88.235% (1500/1700)\n",
      "Test Epoch: 52 | Loss: 0.441 | Acc: 88.056% (1585/1800)\n",
      "Test Epoch: 52 | Loss: 0.446 | Acc: 87.842% (1669/1900)\n",
      "Test Epoch: 52 | Loss: 0.450 | Acc: 87.650% (1753/2000)\n",
      "Test Epoch: 52 | Loss: 0.468 | Acc: 87.381% (1835/2100)\n",
      "Test Epoch: 52 | Loss: 0.473 | Acc: 87.000% (1914/2200)\n",
      "Test Epoch: 52 | Loss: 0.468 | Acc: 87.130% (2004/2300)\n",
      "Test Epoch: 52 | Loss: 0.464 | Acc: 87.208% (2093/2400)\n",
      "Test Epoch: 52 | Loss: 0.480 | Acc: 87.080% (2177/2500)\n",
      "Test Epoch: 52 | Loss: 0.491 | Acc: 87.077% (2264/2600)\n",
      "Test Epoch: 52 | Loss: 0.484 | Acc: 87.259% (2356/2700)\n",
      "Test Epoch: 52 | Loss: 0.482 | Acc: 87.286% (2444/2800)\n",
      "Test Epoch: 52 | Loss: 0.485 | Acc: 87.345% (2533/2900)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.467% (2624/3000)\n",
      "Test Epoch: 52 | Loss: 0.482 | Acc: 87.484% (2712/3100)\n",
      "Test Epoch: 52 | Loss: 0.479 | Acc: 87.562% (2802/3200)\n",
      "Test Epoch: 52 | Loss: 0.487 | Acc: 87.303% (2881/3300)\n",
      "Test Epoch: 52 | Loss: 0.485 | Acc: 87.441% (2973/3400)\n",
      "Test Epoch: 52 | Loss: 0.496 | Acc: 87.286% (3055/3500)\n",
      "Test Epoch: 52 | Loss: 0.499 | Acc: 87.306% (3143/3600)\n",
      "Test Epoch: 52 | Loss: 0.500 | Acc: 87.351% (3232/3700)\n",
      "Test Epoch: 52 | Loss: 0.501 | Acc: 87.395% (3321/3800)\n",
      "Test Epoch: 52 | Loss: 0.498 | Acc: 87.487% (3412/3900)\n",
      "Test Epoch: 52 | Loss: 0.501 | Acc: 87.525% (3501/4000)\n",
      "Test Epoch: 52 | Loss: 0.503 | Acc: 87.561% (3590/4100)\n",
      "Test Epoch: 52 | Loss: 0.504 | Acc: 87.524% (3676/4200)\n",
      "Test Epoch: 52 | Loss: 0.498 | Acc: 87.628% (3768/4300)\n",
      "Test Epoch: 52 | Loss: 0.502 | Acc: 87.636% (3856/4400)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.733% (3948/4500)\n",
      "Test Epoch: 52 | Loss: 0.496 | Acc: 87.717% (4035/4600)\n",
      "Test Epoch: 52 | Loss: 0.495 | Acc: 87.681% (4121/4700)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.625% (4206/4800)\n",
      "Test Epoch: 52 | Loss: 0.494 | Acc: 87.735% (4299/4900)\n",
      "Test Epoch: 52 | Loss: 0.500 | Acc: 87.620% (4381/5000)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.667% (4471/5100)\n",
      "Test Epoch: 52 | Loss: 0.500 | Acc: 87.558% (4553/5200)\n",
      "Test Epoch: 52 | Loss: 0.499 | Acc: 87.566% (4641/5300)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.611% (4731/5400)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.636% (4820/5500)\n",
      "Test Epoch: 52 | Loss: 0.497 | Acc: 87.643% (4908/5600)\n",
      "Test Epoch: 52 | Loss: 0.495 | Acc: 87.649% (4996/5700)\n",
      "Test Epoch: 52 | Loss: 0.494 | Acc: 87.672% (5085/5800)\n",
      "Test Epoch: 52 | Loss: 0.494 | Acc: 87.610% (5169/5900)\n",
      "Test Epoch: 52 | Loss: 0.492 | Acc: 87.617% (5257/6000)\n",
      "Test Epoch: 52 | Loss: 0.492 | Acc: 87.639% (5346/6100)\n",
      "Test Epoch: 52 | Loss: 0.494 | Acc: 87.613% (5432/6200)\n",
      "Test Epoch: 52 | Loss: 0.491 | Acc: 87.683% (5524/6300)\n",
      "Test Epoch: 52 | Loss: 0.490 | Acc: 87.688% (5612/6400)\n",
      "Test Epoch: 52 | Loss: 0.491 | Acc: 87.646% (5697/6500)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.682% (5787/6600)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.716% (5877/6700)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.662% (5961/6800)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.609% (6045/6900)\n",
      "Test Epoch: 52 | Loss: 0.491 | Acc: 87.586% (6131/7000)\n",
      "Test Epoch: 52 | Loss: 0.491 | Acc: 87.563% (6217/7100)\n",
      "Test Epoch: 52 | Loss: 0.492 | Acc: 87.569% (6305/7200)\n",
      "Test Epoch: 52 | Loss: 0.490 | Acc: 87.616% (6396/7300)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.635% (6485/7400)\n",
      "Test Epoch: 52 | Loss: 0.490 | Acc: 87.653% (6574/7500)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.711% (6666/7600)\n",
      "Test Epoch: 52 | Loss: 0.490 | Acc: 87.675% (6751/7700)\n",
      "Test Epoch: 52 | Loss: 0.490 | Acc: 87.679% (6839/7800)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.709% (6929/7900)\n",
      "Test Epoch: 52 | Loss: 0.486 | Acc: 87.737% (7019/8000)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.765% (7109/8100)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.744% (7195/8200)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.771% (7285/8300)\n",
      "Test Epoch: 52 | Loss: 0.484 | Acc: 87.726% (7369/8400)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.647% (7450/8500)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.605% (7534/8600)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.621% (7623/8700)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.636% (7712/8800)\n",
      "Test Epoch: 52 | Loss: 0.488 | Acc: 87.607% (7797/8900)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.544% (7879/9000)\n",
      "Test Epoch: 52 | Loss: 0.489 | Acc: 87.549% (7967/9100)\n",
      "Test Epoch: 52 | Loss: 0.486 | Acc: 87.587% (8058/9200)\n",
      "Test Epoch: 52 | Loss: 0.487 | Acc: 87.581% (8145/9300)\n",
      "Test Epoch: 52 | Loss: 0.487 | Acc: 87.596% (8234/9400)\n",
      "Test Epoch: 52 | Loss: 0.485 | Acc: 87.600% (8322/9500)\n",
      "Test Epoch: 52 | Loss: 0.485 | Acc: 87.615% (8411/9600)\n",
      "Test Epoch: 52 | Loss: 0.484 | Acc: 87.629% (8500/9700)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.653% (8590/9800)\n",
      "Test Epoch: 52 | Loss: 0.483 | Acc: 87.657% (8678/9900)\n",
      "Test Epoch: 52 | Loss: 0.481 | Acc: 87.660% (8766/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Train Epoch: 53 | Loss: 0.088 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 53 | Loss: 0.124 | Acc: 95.703% (245/256)\n",
      "Train Epoch: 53 | Loss: 0.100 | Acc: 96.875% (372/384)\n",
      "Train Epoch: 53 | Loss: 0.099 | Acc: 96.680% (495/512)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 97.031% (621/640)\n",
      "Train Epoch: 53 | Loss: 0.099 | Acc: 96.615% (742/768)\n",
      "Train Epoch: 53 | Loss: 0.104 | Acc: 96.317% (863/896)\n",
      "Train Epoch: 53 | Loss: 0.114 | Acc: 95.996% (983/1024)\n",
      "Train Epoch: 53 | Loss: 0.112 | Acc: 96.007% (1106/1152)\n",
      "Train Epoch: 53 | Loss: 0.121 | Acc: 96.016% (1229/1280)\n",
      "Train Epoch: 53 | Loss: 0.120 | Acc: 96.023% (1352/1408)\n",
      "Train Epoch: 53 | Loss: 0.118 | Acc: 96.094% (1476/1536)\n",
      "Train Epoch: 53 | Loss: 0.111 | Acc: 96.274% (1602/1664)\n",
      "Train Epoch: 53 | Loss: 0.109 | Acc: 96.317% (1726/1792)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.406% (1851/1920)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.387% (1974/2048)\n",
      "Train Epoch: 53 | Loss: 0.102 | Acc: 96.507% (2100/2176)\n",
      "Train Epoch: 53 | Loss: 0.101 | Acc: 96.571% (2225/2304)\n",
      "Train Epoch: 53 | Loss: 0.106 | Acc: 96.423% (2345/2432)\n",
      "Train Epoch: 53 | Loss: 0.106 | Acc: 96.367% (2467/2560)\n",
      "Train Epoch: 53 | Loss: 0.106 | Acc: 96.391% (2591/2688)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.484% (2717/2816)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.535% (2842/2944)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.517% (2965/3072)\n",
      "Train Epoch: 53 | Loss: 0.102 | Acc: 96.625% (3092/3200)\n",
      "Train Epoch: 53 | Loss: 0.102 | Acc: 96.635% (3216/3328)\n",
      "Train Epoch: 53 | Loss: 0.101 | Acc: 96.644% (3340/3456)\n",
      "Train Epoch: 53 | Loss: 0.102 | Acc: 96.568% (3461/3584)\n",
      "Train Epoch: 53 | Loss: 0.103 | Acc: 96.552% (3584/3712)\n",
      "Train Epoch: 53 | Loss: 0.106 | Acc: 96.510% (3706/3840)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.522% (3830/3968)\n",
      "Train Epoch: 53 | Loss: 0.105 | Acc: 96.533% (3954/4096)\n",
      "Train Epoch: 53 | Loss: 0.103 | Acc: 96.615% (4081/4224)\n",
      "Train Epoch: 53 | Loss: 0.102 | Acc: 96.645% (4206/4352)\n",
      "Train Epoch: 53 | Loss: 0.101 | Acc: 96.674% (4331/4480)\n",
      "Train Epoch: 53 | Loss: 0.101 | Acc: 96.723% (4457/4608)\n",
      "Train Epoch: 53 | Loss: 0.099 | Acc: 96.769% (4583/4736)\n",
      "Train Epoch: 53 | Loss: 0.098 | Acc: 96.813% (4709/4864)\n",
      "Train Epoch: 53 | Loss: 0.097 | Acc: 96.855% (4835/4992)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.914% (4962/5120)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.875% (5084/5248)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.912% (5210/5376)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.930% (5335/5504)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.964% (5461/5632)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.979% (5586/5760)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.943% (5708/5888)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.908% (5830/6016)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.956% (5957/6144)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.939% (6080/6272)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.984% (6207/6400)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.952% (6329/6528)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.010% (6457/6656)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.052% (6584/6784)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.049% (6708/6912)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.003% (6829/7040)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.987% (6952/7168)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.012% (7078/7296)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.023% (7203/7424)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.047% (7329/7552)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.044% (7453/7680)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.041% (7577/7808)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.001% (7698/7936)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.011% (7823/8064)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.046% (7950/8192)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.055% (8075/8320)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.064% (8200/8448)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.050% (8323/8576)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 97.024% (8445/8704)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.056% (8572/8832)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.076% (8698/8960)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.062% (8821/9088)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.081% (8947/9216)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.078% (9071/9344)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.076% (9195/9472)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.083% (9320/9600)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.101% (9446/9728)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.129% (9573/9856)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.145% (9699/9984)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.162% (9825/10112)\n",
      "Train Epoch: 53 | Loss: 0.090 | Acc: 97.178% (9951/10240)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.164% (10074/10368)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.142% (10196/10496)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.129% (10319/10624)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.117% (10442/10752)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.123% (10567/10880)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.129% (10692/11008)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.117% (10815/11136)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.088% (10936/11264)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.086% (11060/11392)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.066% (11182/11520)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.064% (11306/11648)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.062% (11430/11776)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.060% (11554/11904)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.066% (11679/12032)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.072% (11804/12160)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.054% (11926/12288)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.052% (12050/12416)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.050% (12174/12544)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.064% (12300/12672)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.062% (12424/12800)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.030% (12544/12928)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.028% (12668/13056)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.027% (12792/13184)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.025% (12916/13312)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.031% (13041/13440)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.052% (13168/13568)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.072% (13295/13696)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.070% (13419/13824)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.076% (13544/13952)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.060% (13666/14080)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.072% (13792/14208)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.063% (13915/14336)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.048% (14037/14464)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.039% (14160/14592)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.038% (14284/14720)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.050% (14410/14848)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.055% (14535/14976)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 97.067% (14661/15104)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.052% (14783/15232)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.025% (14903/15360)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.030% (15028/15488)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 97.016% (15150/15616)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 97.002% (15272/15744)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.988% (15394/15872)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.963% (15514/16000)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.968% (15639/16128)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.949% (15760/16256)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.942% (15883/16384)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.954% (16009/16512)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.953% (16133/16640)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.953% (16257/16768)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.940% (16379/16896)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.928% (16501/17024)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.939% (16627/17152)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.939% (16751/17280)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.932% (16874/17408)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.926% (16997/17536)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.915% (17119/17664)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.914% (17243/17792)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.903% (17365/17920)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.903% (17489/18048)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.875% (17608/18176)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.875% (17732/18304)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.870% (17855/18432)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.870% (17979/18560)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.864% (18102/18688)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.875% (18228/18816)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.886% (18354/18944)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.885% (18478/19072)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.885% (18602/19200)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.906% (18730/19328)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.901% (18853/19456)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.885% (18974/19584)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.890% (19099/19712)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.865% (19218/19840)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.880% (19345/19968)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.900% (19473/20096)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.910% (19599/20224)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.904% (19722/20352)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.895% (19844/20480)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.904% (19970/20608)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.904% (20094/20736)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.909% (20219/20864)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.913% (20344/20992)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.922% (20470/21120)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.917% (20593/21248)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.908% (20715/21376)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.912% (20840/21504)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.912% (20964/21632)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.912% (21088/21760)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.907% (21211/21888)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.911% (21336/22016)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.911% (21460/22144)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.924% (21587/22272)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.906% (21707/22400)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.906% (21831/22528)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.906% (21955/22656)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.915% (22081/22784)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.906% (22203/22912)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.910% (22328/23040)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.927% (22456/23168)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.935% (22582/23296)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.930% (22705/23424)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.926% (22828/23552)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.930% (22953/23680)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.930% (23077/23808)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.925% (23200/23936)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.921% (23323/24064)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.916% (23446/24192)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.916% (23570/24320)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.916% (23694/24448)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.928% (23821/24576)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.936% (23947/24704)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.927% (24069/24832)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.931% (24194/24960)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.923% (24316/25088)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.927% (24441/25216)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.926% (24565/25344)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.922% (24688/25472)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.926% (24813/25600)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.933% (24939/25728)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.925% (25061/25856)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.929% (25186/25984)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.936% (25312/26112)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.932% (25435/26240)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.939% (25561/26368)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.932% (25683/26496)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.931% (25807/26624)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.931% (25931/26752)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.908% (26049/26880)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.908% (26173/27008)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.897% (26294/27136)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.890% (26416/27264)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.901% (26543/27392)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.897% (26666/27520)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.908% (26793/27648)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.918% (26920/27776)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.925% (27046/27904)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.929% (27171/28032)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.925% (27294/28160)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.924% (27418/28288)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.907% (27537/28416)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.896% (27658/28544)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.896% (27782/28672)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.896% (27906/28800)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.896% (28030/28928)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.899% (28155/29056)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.896% (28278/29184)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.895% (28402/29312)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.889% (28524/29440)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.878% (28645/29568)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.882% (28770/29696)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.885% (28895/29824)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.892% (29021/29952)\n",
      "Train Epoch: 53 | Loss: 0.091 | Acc: 96.895% (29146/30080)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.878% (29265/30208)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.885% (29391/30336)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.872% (29511/30464)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.868% (29634/30592)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.868% (29758/30720)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.869% (29882/30848)\n",
      "Train Epoch: 53 | Loss: 0.092 | Acc: 96.872% (30007/30976)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.862% (30128/31104)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.862% (30252/31232)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.859% (30375/31360)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.853% (30497/31488)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.847% (30619/31616)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.856% (30746/31744)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.856% (30870/31872)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.856% (30994/32000)\n",
      "Train Epoch: 53 | Loss: 0.093 | Acc: 96.850% (31116/32128)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.838% (31236/32256)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.826% (31356/32384)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.813% (31476/32512)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.817% (31601/32640)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.814% (31724/32768)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.796% (31842/32896)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.799% (31967/33024)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.797% (32090/33152)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.788% (32211/33280)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.791% (32336/33408)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.792% (32460/33536)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.795% (32585/33664)\n",
      "Train Epoch: 53 | Loss: 0.094 | Acc: 96.798% (32710/33792)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.784% (32829/33920)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.766% (32947/34048)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.764% (33070/34176)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.770% (33196/34304)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.779% (33323/34432)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.774% (33445/34560)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.768% (33567/34688)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.772% (33692/34816)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.763% (33813/34944)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.761% (33936/35072)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.753% (34057/35200)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.748% (34179/35328)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.751% (34304/35456)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.757% (34430/35584)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.749% (34551/35712)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.755% (34677/35840)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.755% (34801/35968)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.750% (34923/36096)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.745% (35045/36224)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.740% (35167/36352)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.730% (35287/36480)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.733% (35412/36608)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.731% (35535/36736)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.737% (35661/36864)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.729% (35782/36992)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.738% (35909/37120)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.738% (36033/37248)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.736% (36156/37376)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.742% (36282/37504)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.739% (36405/37632)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.724% (36523/37760)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.727% (36648/37888)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.728% (36772/38016)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.736% (36899/38144)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.734% (37022/38272)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (37141/38400)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.727% (37267/38528)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.730% (37392/38656)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.728% (37515/38784)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (37636/38912)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (37760/39040)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.732% (37888/39168)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.727% (38010/39296)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.723% (38132/39424)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.718% (38254/39552)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (38379/39680)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.722% (38503/39808)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.717% (38625/39936)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.718% (38749/40064)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.718% (38873/40192)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.719% (38997/40320)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.709% (39117/40448)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.710% (39241/40576)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.710% (39365/40704)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.713% (39490/40832)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.719% (39616/40960)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.707% (39735/41088)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.708% (39859/41216)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (39985/41344)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.711% (40108/41472)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.707% (40230/41600)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.705% (40353/41728)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.705% (40477/41856)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.704% (40600/41984)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.706% (40725/42112)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.714% (40852/42240)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.717% (40977/42368)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.722% (41103/42496)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.720% (41226/42624)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (41350/42752)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.723% (41475/42880)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.722% (41598/43008)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.727% (41724/43136)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.722% (41846/43264)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.714% (41966/43392)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.716% (42091/43520)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.721% (42217/43648)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (42337/43776)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (42461/43904)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.714% (42585/44032)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.716% (42710/44160)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.715% (42833/44288)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.708% (42954/44416)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (43080/44544)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.712% (43203/44672)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.714% (43328/44800)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.715% (43452/44928)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (43575/45056)\n",
      "Train Epoch: 53 | Loss: 0.095 | Acc: 96.713% (43699/45184)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.712% (43822/45312)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.710% (43945/45440)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.710% (44069/45568)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.715% (44195/45696)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.716% (44319/45824)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.707% (44439/45952)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.701% (44560/46080)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.702% (44684/46208)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.694% (44804/46336)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.694% (44928/46464)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.695% (45052/46592)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.697% (45177/46720)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.685% (45295/46848)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.679% (45416/46976)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.682% (45541/47104)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.672% (45660/47232)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.668% (45782/47360)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.667% (45905/47488)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.663% (46027/47616)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.661% (46150/47744)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.664% (46275/47872)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.662% (46398/48000)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.659% (46520/48128)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.662% (46645/48256)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.666% (46771/48384)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.669% (46896/48512)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.661% (47016/48640)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.660% (47139/48768)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.658% (47262/48896)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.663% (47388/49024)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.670% (47515/49152)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.664% (47636/49280)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.660% (47758/49408)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.665% (47884/49536)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.662% (48006/49664)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.656% (48127/49792)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.657% (48251/49920)\n",
      "Train Epoch: 53 | Loss: 0.096 | Acc: 96.654% (48327/50000)\n",
      "Test Epoch: 53 | Loss: 0.585 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 53 | Loss: 0.549 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 53 | Loss: 0.457 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 53 | Loss: 0.500 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 53 | Loss: 0.443 | Acc: 87.600% (438/500)\n",
      "Test Epoch: 53 | Loss: 0.396 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 53 | Loss: 0.434 | Acc: 88.286% (618/700)\n",
      "Test Epoch: 53 | Loss: 0.450 | Acc: 87.625% (701/800)\n",
      "Test Epoch: 53 | Loss: 0.439 | Acc: 88.000% (792/900)\n",
      "Test Epoch: 53 | Loss: 0.451 | Acc: 88.000% (880/1000)\n",
      "Test Epoch: 53 | Loss: 0.467 | Acc: 87.636% (964/1100)\n",
      "Test Epoch: 53 | Loss: 0.479 | Acc: 87.333% (1048/1200)\n",
      "Test Epoch: 53 | Loss: 0.483 | Acc: 87.385% (1136/1300)\n",
      "Test Epoch: 53 | Loss: 0.484 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 53 | Loss: 0.490 | Acc: 87.267% (1309/1500)\n",
      "Test Epoch: 53 | Loss: 0.480 | Acc: 87.375% (1398/1600)\n",
      "Test Epoch: 53 | Loss: 0.471 | Acc: 87.588% (1489/1700)\n",
      "Test Epoch: 53 | Loss: 0.473 | Acc: 87.500% (1575/1800)\n",
      "Test Epoch: 53 | Loss: 0.483 | Acc: 87.421% (1661/1900)\n",
      "Test Epoch: 53 | Loss: 0.499 | Acc: 87.450% (1749/2000)\n",
      "Test Epoch: 53 | Loss: 0.514 | Acc: 87.048% (1828/2100)\n",
      "Test Epoch: 53 | Loss: 0.522 | Acc: 86.909% (1912/2200)\n",
      "Test Epoch: 53 | Loss: 0.519 | Acc: 87.087% (2003/2300)\n",
      "Test Epoch: 53 | Loss: 0.519 | Acc: 86.792% (2083/2400)\n",
      "Test Epoch: 53 | Loss: 0.529 | Acc: 86.720% (2168/2500)\n",
      "Test Epoch: 53 | Loss: 0.542 | Acc: 86.538% (2250/2600)\n",
      "Test Epoch: 53 | Loss: 0.530 | Acc: 86.778% (2343/2700)\n",
      "Test Epoch: 53 | Loss: 0.527 | Acc: 86.821% (2431/2800)\n",
      "Test Epoch: 53 | Loss: 0.528 | Acc: 86.759% (2516/2900)\n",
      "Test Epoch: 53 | Loss: 0.524 | Acc: 86.767% (2603/3000)\n",
      "Test Epoch: 53 | Loss: 0.520 | Acc: 86.806% (2691/3100)\n",
      "Test Epoch: 53 | Loss: 0.519 | Acc: 86.844% (2779/3200)\n",
      "Test Epoch: 53 | Loss: 0.520 | Acc: 86.909% (2868/3300)\n",
      "Test Epoch: 53 | Loss: 0.514 | Acc: 87.000% (2958/3400)\n",
      "Test Epoch: 53 | Loss: 0.521 | Acc: 86.743% (3036/3500)\n",
      "Test Epoch: 53 | Loss: 0.526 | Acc: 86.750% (3123/3600)\n",
      "Test Epoch: 53 | Loss: 0.529 | Acc: 86.757% (3210/3700)\n",
      "Test Epoch: 53 | Loss: 0.529 | Acc: 86.842% (3300/3800)\n",
      "Test Epoch: 53 | Loss: 0.523 | Acc: 86.974% (3392/3900)\n",
      "Test Epoch: 53 | Loss: 0.521 | Acc: 87.025% (3481/4000)\n",
      "Test Epoch: 53 | Loss: 0.526 | Acc: 86.951% (3565/4100)\n",
      "Test Epoch: 53 | Loss: 0.523 | Acc: 87.000% (3654/4200)\n",
      "Test Epoch: 53 | Loss: 0.514 | Acc: 87.116% (3746/4300)\n",
      "Test Epoch: 53 | Loss: 0.519 | Acc: 87.159% (3835/4400)\n",
      "Test Epoch: 53 | Loss: 0.517 | Acc: 87.200% (3924/4500)\n",
      "Test Epoch: 53 | Loss: 0.515 | Acc: 87.217% (4012/4600)\n",
      "Test Epoch: 53 | Loss: 0.512 | Acc: 87.255% (4101/4700)\n",
      "Test Epoch: 53 | Loss: 0.514 | Acc: 87.229% (4187/4800)\n",
      "Test Epoch: 53 | Loss: 0.511 | Acc: 87.347% (4280/4900)\n",
      "Test Epoch: 53 | Loss: 0.512 | Acc: 87.320% (4366/5000)\n",
      "Test Epoch: 53 | Loss: 0.511 | Acc: 87.373% (4456/5100)\n",
      "Test Epoch: 53 | Loss: 0.511 | Acc: 87.346% (4542/5200)\n",
      "Test Epoch: 53 | Loss: 0.513 | Acc: 87.340% (4629/5300)\n",
      "Test Epoch: 53 | Loss: 0.510 | Acc: 87.352% (4717/5400)\n",
      "Test Epoch: 53 | Loss: 0.511 | Acc: 87.327% (4803/5500)\n",
      "Test Epoch: 53 | Loss: 0.511 | Acc: 87.375% (4893/5600)\n",
      "Test Epoch: 53 | Loss: 0.508 | Acc: 87.368% (4980/5700)\n",
      "Test Epoch: 53 | Loss: 0.506 | Acc: 87.414% (5070/5800)\n",
      "Test Epoch: 53 | Loss: 0.509 | Acc: 87.390% (5156/5900)\n",
      "Test Epoch: 53 | Loss: 0.507 | Acc: 87.400% (5244/6000)\n",
      "Test Epoch: 53 | Loss: 0.505 | Acc: 87.410% (5332/6100)\n",
      "Test Epoch: 53 | Loss: 0.506 | Acc: 87.435% (5421/6200)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.492% (5512/6300)\n",
      "Test Epoch: 53 | Loss: 0.500 | Acc: 87.625% (5608/6400)\n",
      "Test Epoch: 53 | Loss: 0.500 | Acc: 87.585% (5693/6500)\n",
      "Test Epoch: 53 | Loss: 0.497 | Acc: 87.606% (5782/6600)\n",
      "Test Epoch: 53 | Loss: 0.497 | Acc: 87.627% (5871/6700)\n",
      "Test Epoch: 53 | Loss: 0.496 | Acc: 87.647% (5960/6800)\n",
      "Test Epoch: 53 | Loss: 0.492 | Acc: 87.696% (6051/6900)\n",
      "Test Epoch: 53 | Loss: 0.495 | Acc: 87.600% (6132/7000)\n",
      "Test Epoch: 53 | Loss: 0.496 | Acc: 87.577% (6218/7100)\n",
      "Test Epoch: 53 | Loss: 0.499 | Acc: 87.597% (6307/7200)\n",
      "Test Epoch: 53 | Loss: 0.498 | Acc: 87.658% (6399/7300)\n",
      "Test Epoch: 53 | Loss: 0.496 | Acc: 87.716% (6491/7400)\n",
      "Test Epoch: 53 | Loss: 0.499 | Acc: 87.693% (6577/7500)\n",
      "Test Epoch: 53 | Loss: 0.499 | Acc: 87.684% (6664/7600)\n",
      "Test Epoch: 53 | Loss: 0.502 | Acc: 87.649% (6749/7700)\n",
      "Test Epoch: 53 | Loss: 0.501 | Acc: 87.679% (6839/7800)\n",
      "Test Epoch: 53 | Loss: 0.502 | Acc: 87.633% (6923/7900)\n",
      "Test Epoch: 53 | Loss: 0.502 | Acc: 87.612% (7009/8000)\n",
      "Test Epoch: 53 | Loss: 0.500 | Acc: 87.593% (7095/8100)\n",
      "Test Epoch: 53 | Loss: 0.498 | Acc: 87.622% (7185/8200)\n",
      "Test Epoch: 53 | Loss: 0.497 | Acc: 87.639% (7274/8300)\n",
      "Test Epoch: 53 | Loss: 0.498 | Acc: 87.655% (7363/8400)\n",
      "Test Epoch: 53 | Loss: 0.499 | Acc: 87.624% (7448/8500)\n",
      "Test Epoch: 53 | Loss: 0.503 | Acc: 87.523% (7527/8600)\n",
      "Test Epoch: 53 | Loss: 0.501 | Acc: 87.529% (7615/8700)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.511% (7701/8800)\n",
      "Test Epoch: 53 | Loss: 0.503 | Acc: 87.551% (7792/8900)\n",
      "Test Epoch: 53 | Loss: 0.506 | Acc: 87.533% (7878/9000)\n",
      "Test Epoch: 53 | Loss: 0.506 | Acc: 87.549% (7967/9100)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.565% (8056/9200)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.570% (8144/9300)\n",
      "Test Epoch: 53 | Loss: 0.503 | Acc: 87.574% (8232/9400)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.537% (8316/9500)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.562% (8406/9600)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.598% (8497/9700)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.633% (8588/9800)\n",
      "Test Epoch: 53 | Loss: 0.504 | Acc: 87.616% (8674/9900)\n",
      "Test Epoch: 53 | Loss: 0.502 | Acc: 87.650% (8765/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Train Epoch: 54 | Loss: 0.070 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 54 | Loss: 0.074 | Acc: 97.656% (250/256)\n",
      "Train Epoch: 54 | Loss: 0.069 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 54 | Loss: 0.065 | Acc: 98.438% (504/512)\n",
      "Train Epoch: 54 | Loss: 0.073 | Acc: 98.281% (629/640)\n",
      "Train Epoch: 54 | Loss: 0.084 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 54 | Loss: 0.079 | Acc: 97.879% (877/896)\n",
      "Train Epoch: 54 | Loss: 0.083 | Acc: 97.656% (1000/1024)\n",
      "Train Epoch: 54 | Loss: 0.089 | Acc: 97.483% (1123/1152)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.500% (1248/1280)\n",
      "Train Epoch: 54 | Loss: 0.090 | Acc: 97.372% (1371/1408)\n",
      "Train Epoch: 54 | Loss: 0.090 | Acc: 97.396% (1496/1536)\n",
      "Train Epoch: 54 | Loss: 0.089 | Acc: 97.476% (1622/1664)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.489% (1747/1792)\n",
      "Train Epoch: 54 | Loss: 0.086 | Acc: 97.448% (1871/1920)\n",
      "Train Epoch: 54 | Loss: 0.089 | Acc: 97.314% (1993/2048)\n",
      "Train Epoch: 54 | Loss: 0.089 | Acc: 97.289% (2117/2176)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.266% (2241/2304)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.286% (2366/2432)\n",
      "Train Epoch: 54 | Loss: 0.090 | Acc: 97.227% (2489/2560)\n",
      "Train Epoch: 54 | Loss: 0.089 | Acc: 97.284% (2615/2688)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.337% (2741/2816)\n",
      "Train Epoch: 54 | Loss: 0.086 | Acc: 97.385% (2867/2944)\n",
      "Train Epoch: 54 | Loss: 0.084 | Acc: 97.428% (2993/3072)\n",
      "Train Epoch: 54 | Loss: 0.088 | Acc: 97.219% (3111/3200)\n",
      "Train Epoch: 54 | Loss: 0.090 | Acc: 97.175% (3234/3328)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 97.078% (3355/3456)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 97.042% (3478/3584)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.983% (3600/3712)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.953% (3723/3840)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.850% (3843/3968)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.802% (3965/4096)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.757% (4087/4224)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.806% (4213/4352)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.808% (4337/4480)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.766% (4459/4608)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.727% (4581/4736)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.649% (4701/4864)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.695% (4827/4992)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.758% (4954/5120)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.761% (5078/5248)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.708% (5199/5376)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.730% (5324/5504)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.768% (5450/5632)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.823% (5577/5760)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.807% (5700/5888)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.825% (5825/6016)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.810% (5948/6144)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.795% (6071/6272)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.812% (6196/6400)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.860% (6323/6528)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.890% (6449/6656)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.875% (6572/6784)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.889% (6697/6912)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.903% (6822/7040)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.931% (6948/7168)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.916% (7071/7296)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.915% (7195/7424)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.849% (7314/7552)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.836% (7437/7680)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.837% (7561/7808)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.875% (7688/7936)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.875% (7812/8064)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.875% (7936/8192)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.863% (8059/8320)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.839% (8181/8448)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.817% (8303/8576)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.852% (8430/8704)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.807% (8550/8832)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.819% (8675/8960)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.820% (8799/9088)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.853% (8926/9216)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.843% (9049/9344)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.812% (9170/9472)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.823% (9295/9600)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.834% (9420/9728)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.814% (9542/9856)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.805% (9665/9984)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.816% (9790/10112)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.807% (9913/10240)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.807% (10037/10368)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.808% (10161/10496)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.809% (10285/10624)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.828% (10411/10752)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.829% (10535/10880)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.820% (10658/11008)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.839% (10784/11136)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.831% (10907/11264)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.796% (11027/11392)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.814% (11153/11520)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.815% (11277/11648)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.816% (11401/11776)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.816% (11525/11904)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.775% (11644/12032)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.785% (11769/12160)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.777% (11892/12288)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.794% (12018/12416)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.811% (12144/12544)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.843% (12272/12672)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.828% (12394/12800)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.836% (12519/12928)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.852% (12645/13056)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.852% (12769/13184)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.860% (12894/13312)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.853% (13017/13440)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.853% (13141/13568)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.853% (13265/13696)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.861% (13390/13824)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.861% (13514/13952)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.847% (13636/14080)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.847% (13760/14208)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.861% (13886/14336)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.875% (14012/14464)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.848% (14132/14592)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.848% (14256/14720)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.835% (14378/14848)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.848% (14504/14976)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.849% (14628/15104)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.836% (14750/15232)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.842% (14875/15360)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.849% (15000/15488)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.869% (15127/15616)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.856% (15249/15744)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.850% (15372/15872)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.850% (15496/16000)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.863% (15622/16128)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.869% (15747/16256)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.844% (15867/16384)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.851% (15992/16512)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.833% (16113/16640)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.803% (16232/16768)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.810% (16357/16896)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.805% (16480/17024)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.823% (16607/17152)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.817% (16730/17280)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.829% (16856/17408)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.835% (16981/17536)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.830% (17104/17664)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.836% (17229/17792)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.802% (17347/17920)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.814% (17473/18048)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.825% (17599/18176)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.831% (17724/18304)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.821% (17846/18432)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.832% (17972/18560)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.848% (18099/18688)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.854% (18224/18816)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.864% (18350/18944)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.865% (18474/19072)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.875% (18600/19200)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.849% (18719/19328)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.860% (18845/19456)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.865% (18970/19584)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.880% (19097/19712)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.890% (19223/19840)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.895% (19348/19968)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.900% (19473/20096)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.895% (19596/20224)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.895% (19720/20352)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.895% (19844/20480)\n",
      "Train Epoch: 54 | Loss: 0.092 | Acc: 96.890% (19967/20608)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.875% (20088/20736)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.870% (20211/20864)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.865% (20334/20992)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.851% (20455/21120)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.847% (20578/21248)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.852% (20703/21376)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.838% (20824/21504)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.838% (20948/21632)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.834% (21071/21760)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.820% (21192/21888)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.830% (21318/22016)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.830% (21442/22144)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.826% (21565/22272)\n",
      "Train Epoch: 54 | Loss: 0.093 | Acc: 96.835% (21691/22400)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.826% (21813/22528)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.813% (21934/22656)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.818% (22059/22784)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.818% (22183/22912)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.814% (22306/23040)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.810% (22429/23168)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.823% (22556/23296)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.832% (22682/23424)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.824% (22804/23552)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.824% (22928/23680)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.816% (23050/23808)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.825% (23176/23936)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.838% (23303/24064)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.838% (23427/24192)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.830% (23549/24320)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.834% (23674/24448)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.810% (23792/24576)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.798% (23913/24704)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.807% (24039/24832)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.815% (24165/24960)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.823% (24291/25088)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.823% (24415/25216)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.820% (24538/25344)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.824% (24663/25472)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.832% (24789/25600)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.836% (24914/25728)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.829% (25036/25856)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.813% (25156/25984)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.802% (25277/26112)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.810% (25403/26240)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.803% (25525/26368)\n",
      "Train Epoch: 54 | Loss: 0.094 | Acc: 96.815% (25652/26496)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.796% (25771/26624)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.800% (25896/26752)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.793% (26018/26880)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.779% (26138/27008)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.779% (26262/27136)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.780% (26386/27264)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.776% (26509/27392)\n",
      "Train Epoch: 54 | Loss: 0.095 | Acc: 96.759% (26628/27520)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.752% (26750/27648)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.738% (26870/27776)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.728% (26991/27904)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.722% (27113/28032)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.733% (27240/28160)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.748% (27368/28288)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.738% (27489/28416)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.738% (27613/28544)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.722% (27732/28672)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.726% (27857/28800)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.730% (27982/28928)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.730% (28106/29056)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.724% (28228/29184)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.728% (28353/29312)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.729% (28477/29440)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.726% (28600/29568)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.723% (28723/29696)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.711% (28843/29824)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.701% (28964/29952)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.699% (29087/30080)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.709% (29214/30208)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.713% (29339/30336)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.704% (29460/30464)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.708% (29585/30592)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.709% (29709/30720)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.716% (29835/30848)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.710% (29957/30976)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.701% (30078/31104)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.705% (30203/31232)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.703% (30326/31360)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.707% (30451/31488)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.701% (30573/31616)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.702% (30697/31744)\n",
      "Train Epoch: 54 | Loss: 0.096 | Acc: 96.699% (30820/31872)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.691% (30941/32000)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.691% (31065/32128)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.680% (31185/32256)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.680% (31309/32384)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.690% (31436/32512)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.673% (31554/32640)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.674% (31678/32768)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.662% (31798/32896)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.663% (31922/33024)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.658% (32044/33152)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.659% (32168/33280)\n",
      "Train Epoch: 54 | Loss: 0.097 | Acc: 96.659% (32292/33408)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.645% (32411/33536)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.649% (32536/33664)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.650% (32660/33792)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.654% (32785/33920)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.649% (32907/34048)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.638% (33027/34176)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.642% (33152/34304)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.651% (33279/34432)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.644% (33400/34560)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.639% (33522/34688)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.639% (33646/34816)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.637% (33769/34944)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.638% (33893/35072)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.645% (34019/35200)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.634% (34139/35328)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.632% (34262/35456)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.633% (34386/35584)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.617% (34504/35712)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.613% (34626/35840)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.614% (34750/35968)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.615% (34874/36096)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.618% (34999/36224)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.616% (35122/36352)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.609% (35243/36480)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.613% (35368/36608)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.608% (35490/36736)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.612% (35615/36864)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.610% (35738/36992)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.598% (35857/37120)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.585% (35976/37248)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.591% (36102/37376)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.598% (36228/37504)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.593% (36350/37632)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.594% (36474/37760)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.595% (36598/37888)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.591% (36720/38016)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.594% (36845/38144)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.595% (36969/38272)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.594% (37092/38400)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.600% (37218/38528)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.601% (37342/38656)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.597% (37464/38784)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.603% (37590/38912)\n",
      "Train Epoch: 54 | Loss: 0.098 | Acc: 96.601% (37713/39040)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.597% (37835/39168)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.587% (37955/39296)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.586% (38078/39424)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.577% (38198/39552)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.565% (38317/39680)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.566% (38441/39808)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.570% (38566/39936)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.578% (38693/40064)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.579% (38817/40192)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.575% (38939/40320)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.576% (39063/40448)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.572% (39185/40576)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.578% (39311/40704)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.576% (39434/40832)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.570% (39555/40960)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.571% (39679/41088)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.569% (39802/41216)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.575% (39928/41344)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.569% (40049/41472)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.570% (40173/41600)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.571% (40297/41728)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.567% (40419/41856)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.573% (40545/41984)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.576% (40670/42112)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.577% (40794/42240)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.582% (40920/42368)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.569% (41038/42496)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.563% (41159/42624)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.564% (41283/42752)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.565% (41407/42880)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.566% (41531/43008)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.569% (41656/43136)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.558% (41775/43264)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.552% (41896/43392)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.544% (42016/43520)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.538% (42137/43648)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.544% (42263/43776)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.545% (42387/43904)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.546% (42511/44032)\n",
      "Train Epoch: 54 | Loss: 0.099 | Acc: 96.542% (42633/44160)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.532% (42752/44288)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.522% (42871/44416)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.518% (42993/44544)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.521% (43118/44672)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.520% (43241/44800)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.523% (43366/44928)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.520% (43488/45056)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.519% (43611/45184)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.513% (43732/45312)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.518% (43858/45440)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.506% (43976/45568)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.501% (44097/45696)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.497% (44219/45824)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.492% (44340/45952)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.495% (44465/46080)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.488% (44585/46208)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.484% (44707/46336)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.483% (44830/46464)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.489% (44956/46592)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.492% (45081/46720)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.501% (45209/46848)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.505% (45334/46976)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.508% (45459/47104)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.509% (45583/47232)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.508% (45706/47360)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.506% (45829/47488)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.505% (45952/47616)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.504% (46075/47744)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.505% (46199/47872)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.500% (46320/48000)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.499% (46443/48128)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.485% (46560/48256)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.482% (46682/48384)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.481% (46805/48512)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.486% (46931/48640)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.487% (47055/48768)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.484% (47177/48896)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.477% (47297/49024)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.476% (47420/49152)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.479% (47545/49280)\n",
      "Train Epoch: 54 | Loss: 0.101 | Acc: 96.468% (47663/49408)\n",
      "Train Epoch: 54 | Loss: 0.101 | Acc: 96.461% (47783/49536)\n",
      "Train Epoch: 54 | Loss: 0.101 | Acc: 96.466% (47909/49664)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.467% (48033/49792)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.468% (48157/49920)\n",
      "Train Epoch: 54 | Loss: 0.100 | Acc: 96.468% (48234/50000)\n",
      "Test Epoch: 54 | Loss: 0.333 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 54 | Loss: 0.337 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 54 | Loss: 0.282 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 54 | Loss: 0.338 | Acc: 90.000% (360/400)\n",
      "Test Epoch: 54 | Loss: 0.336 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 54 | Loss: 0.292 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 54 | Loss: 0.301 | Acc: 90.714% (635/700)\n",
      "Test Epoch: 54 | Loss: 0.329 | Acc: 90.250% (722/800)\n",
      "Test Epoch: 54 | Loss: 0.338 | Acc: 90.000% (810/900)\n",
      "Test Epoch: 54 | Loss: 0.342 | Acc: 90.400% (904/1000)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 89.727% (987/1100)\n",
      "Test Epoch: 54 | Loss: 0.373 | Acc: 89.500% (1074/1200)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 89.538% (1164/1300)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 89.643% (1255/1400)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 89.533% (1343/1500)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 89.688% (1435/1600)\n",
      "Test Epoch: 54 | Loss: 0.355 | Acc: 89.941% (1529/1700)\n",
      "Test Epoch: 54 | Loss: 0.352 | Acc: 89.833% (1617/1800)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 89.789% (1706/1900)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 89.700% (1794/2000)\n",
      "Test Epoch: 54 | Loss: 0.378 | Acc: 89.381% (1877/2100)\n",
      "Test Epoch: 54 | Loss: 0.374 | Acc: 89.318% (1965/2200)\n",
      "Test Epoch: 54 | Loss: 0.371 | Acc: 89.522% (2059/2300)\n",
      "Test Epoch: 54 | Loss: 0.369 | Acc: 89.583% (2150/2400)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.440% (2236/2500)\n",
      "Test Epoch: 54 | Loss: 0.392 | Acc: 89.423% (2325/2600)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.630% (2420/2700)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.643% (2510/2800)\n",
      "Test Epoch: 54 | Loss: 0.387 | Acc: 89.621% (2599/2900)\n",
      "Test Epoch: 54 | Loss: 0.387 | Acc: 89.600% (2688/3000)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.645% (2779/3100)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.688% (2870/3200)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.667% (2959/3300)\n",
      "Test Epoch: 54 | Loss: 0.379 | Acc: 89.824% (3054/3400)\n",
      "Test Epoch: 54 | Loss: 0.388 | Acc: 89.657% (3138/3500)\n",
      "Test Epoch: 54 | Loss: 0.391 | Acc: 89.722% (3230/3600)\n",
      "Test Epoch: 54 | Loss: 0.396 | Acc: 89.757% (3321/3700)\n",
      "Test Epoch: 54 | Loss: 0.398 | Acc: 89.658% (3407/3800)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.744% (3500/3900)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.725% (3589/4000)\n",
      "Test Epoch: 54 | Loss: 0.401 | Acc: 89.561% (3672/4100)\n",
      "Test Epoch: 54 | Loss: 0.402 | Acc: 89.476% (3758/4200)\n",
      "Test Epoch: 54 | Loss: 0.398 | Acc: 89.605% (3853/4300)\n",
      "Test Epoch: 54 | Loss: 0.401 | Acc: 89.636% (3944/4400)\n",
      "Test Epoch: 54 | Loss: 0.399 | Acc: 89.733% (4038/4500)\n",
      "Test Epoch: 54 | Loss: 0.399 | Acc: 89.652% (4124/4600)\n",
      "Test Epoch: 54 | Loss: 0.397 | Acc: 89.660% (4214/4700)\n",
      "Test Epoch: 54 | Loss: 0.399 | Acc: 89.562% (4299/4800)\n",
      "Test Epoch: 54 | Loss: 0.397 | Acc: 89.714% (4396/4900)\n",
      "Test Epoch: 54 | Loss: 0.399 | Acc: 89.620% (4481/5000)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.706% (4575/5100)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.635% (4661/5200)\n",
      "Test Epoch: 54 | Loss: 0.397 | Acc: 89.547% (4746/5300)\n",
      "Test Epoch: 54 | Loss: 0.397 | Acc: 89.574% (4837/5400)\n",
      "Test Epoch: 54 | Loss: 0.394 | Acc: 89.600% (4928/5500)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.589% (5017/5600)\n",
      "Test Epoch: 54 | Loss: 0.395 | Acc: 89.649% (5110/5700)\n",
      "Test Epoch: 54 | Loss: 0.393 | Acc: 89.672% (5201/5800)\n",
      "Test Epoch: 54 | Loss: 0.393 | Acc: 89.729% (5294/5900)\n",
      "Test Epoch: 54 | Loss: 0.390 | Acc: 89.750% (5385/6000)\n",
      "Test Epoch: 54 | Loss: 0.389 | Acc: 89.770% (5476/6100)\n",
      "Test Epoch: 54 | Loss: 0.390 | Acc: 89.790% (5567/6200)\n",
      "Test Epoch: 54 | Loss: 0.389 | Acc: 89.841% (5660/6300)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.906% (5754/6400)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.923% (5845/6500)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.924% (5935/6600)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.955% (6027/6700)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.926% (6115/6800)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.957% (6207/6900)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.886% (6292/7000)\n",
      "Test Epoch: 54 | Loss: 0.386 | Acc: 89.873% (6381/7100)\n",
      "Test Epoch: 54 | Loss: 0.387 | Acc: 89.875% (6471/7200)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.918% (6564/7300)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.946% (6656/7400)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.947% (6746/7500)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.921% (6834/7600)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.857% (6919/7700)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.846% (7008/7800)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.835% (7097/7900)\n",
      "Test Epoch: 54 | Loss: 0.386 | Acc: 89.812% (7185/8000)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.877% (7280/8100)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.902% (7372/8200)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.904% (7462/8300)\n",
      "Test Epoch: 54 | Loss: 0.382 | Acc: 89.857% (7548/8400)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.788% (7632/8500)\n",
      "Test Epoch: 54 | Loss: 0.387 | Acc: 89.767% (7720/8600)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.805% (7813/8700)\n",
      "Test Epoch: 54 | Loss: 0.387 | Acc: 89.795% (7902/8800)\n",
      "Test Epoch: 54 | Loss: 0.386 | Acc: 89.820% (7994/8900)\n",
      "Test Epoch: 54 | Loss: 0.386 | Acc: 89.844% (8086/9000)\n",
      "Test Epoch: 54 | Loss: 0.385 | Acc: 89.857% (8177/9100)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.870% (8268/9200)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.871% (8358/9300)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.862% (8447/9400)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.832% (8534/9500)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.854% (8626/9600)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.866% (8717/9700)\n",
      "Test Epoch: 54 | Loss: 0.383 | Acc: 89.867% (8807/9800)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.889% (8899/9900)\n",
      "Test Epoch: 54 | Loss: 0.384 | Acc: 89.910% (8991/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 55\n",
      "Train Epoch: 55 | Loss: 0.155 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 55 | Loss: 0.116 | Acc: 94.922% (243/256)\n",
      "Train Epoch: 55 | Loss: 0.100 | Acc: 95.573% (367/384)\n",
      "Train Epoch: 55 | Loss: 0.097 | Acc: 95.898% (491/512)\n",
      "Train Epoch: 55 | Loss: 0.095 | Acc: 96.094% (615/640)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.354% (740/768)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.429% (864/896)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.387% (987/1024)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.528% (1112/1152)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.484% (1235/1280)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 96.662% (1361/1408)\n",
      "Train Epoch: 55 | Loss: 0.081 | Acc: 96.875% (1488/1536)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.695% (1609/1664)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.708% (1733/1792)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.823% (1859/1920)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 96.924% (1985/2048)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.921% (2109/2176)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.832% (2231/2304)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.875% (2356/2432)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.953% (2482/2560)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.987% (2607/2688)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 97.017% (2732/2816)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.977% (2855/2944)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.940% (2978/3072)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.906% (3101/3200)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.905% (3225/3328)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.817% (3346/3456)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.819% (3470/3584)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.848% (3595/3712)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.875% (3720/3840)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.900% (3845/3968)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.875% (3968/4096)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.828% (4090/4224)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.852% (4215/4352)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.853% (4339/4480)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.853% (4463/4608)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.896% (4589/4736)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.957% (4716/4864)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.995% (4842/4992)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.992% (4966/5120)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.027% (5092/5248)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.042% (5217/5376)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.039% (5341/5504)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.999% (5463/5632)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.979% (5586/5760)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.011% (5712/5888)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.058% (5839/6016)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.087% (5965/6144)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.003% (6084/6272)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.000% (6208/6400)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.013% (6333/6528)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.040% (6459/6656)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.067% (6585/6784)\n",
      "Train Epoch: 55 | Loss: 0.083 | Acc: 97.092% (6711/6912)\n",
      "Train Epoch: 55 | Loss: 0.083 | Acc: 97.131% (6838/7040)\n",
      "Train Epoch: 55 | Loss: 0.083 | Acc: 97.126% (6962/7168)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.081% (7083/7296)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.064% (7206/7424)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.047% (7329/7552)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.044% (7453/7680)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.990% (7573/7808)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.951% (7694/7936)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 96.999% (7822/8064)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 96.997% (7946/8192)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.983% (8069/8320)\n",
      "Train Epoch: 55 | Loss: 0.084 | Acc: 97.005% (8195/8448)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.992% (8318/8576)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.013% (8444/8704)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.000% (8567/8832)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.009% (8692/8960)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.007% (8816/9088)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.984% (8938/9216)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.950% (9059/9344)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.981% (9186/9472)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.010% (9313/9600)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.019% (9438/9728)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 96.997% (9560/9856)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.005% (9685/9984)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.013% (9810/10112)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.021% (9935/10240)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.039% (10061/10368)\n",
      "Train Epoch: 55 | Loss: 0.085 | Acc: 97.056% (10187/10496)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.035% (10309/10624)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.996% (10429/10752)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.031% (10557/10880)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.029% (10681/11008)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.028% (10805/11136)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.026% (10929/11264)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.015% (11052/11392)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.023% (11177/11520)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.012% (11300/11648)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.019% (11425/11776)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.009% (11548/11904)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 97.025% (11674/12032)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.990% (11794/12160)\n",
      "Train Epoch: 55 | Loss: 0.086 | Acc: 96.997% (11919/12288)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.988% (12042/12416)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.987% (12166/12544)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.962% (12287/12672)\n",
      "Train Epoch: 55 | Loss: 0.087 | Acc: 96.969% (12412/12800)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.945% (12533/12928)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.944% (12657/13056)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.943% (12781/13184)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.935% (12904/13312)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.935% (13028/13440)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.941% (13153/13568)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.948% (13278/13696)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.947% (13402/13824)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.940% (13525/13952)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.946% (13650/14080)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.938% (13773/14208)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.938% (13897/14336)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.910% (14017/14464)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.916% (14142/14592)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.929% (14268/14720)\n",
      "Train Epoch: 55 | Loss: 0.088 | Acc: 96.915% (14390/14848)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.895% (14511/14976)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.895% (14635/15104)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.908% (14761/15232)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.908% (14885/15360)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.920% (15011/15488)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.920% (15135/15616)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.907% (15257/15744)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.913% (15382/15872)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.912% (15506/16000)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.912% (15630/16128)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.906% (15753/16256)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.912% (15878/16384)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.899% (16000/16512)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.911% (16126/16640)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.905% (16249/16768)\n",
      "Train Epoch: 55 | Loss: 0.089 | Acc: 96.899% (16372/16896)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.881% (16493/17024)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.875% (16616/17152)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.875% (16740/17280)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.892% (16867/17408)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.881% (16989/17536)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.881% (17113/17664)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.858% (17233/17792)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.881% (17361/17920)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.881% (17485/18048)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.886% (17610/18176)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.875% (17732/18304)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.859% (17853/18432)\n",
      "Train Epoch: 55 | Loss: 0.090 | Acc: 96.859% (17977/18560)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.843% (18098/18688)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.838% (18221/18816)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.838% (18345/18944)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.833% (18468/19072)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.844% (18594/19200)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.828% (18715/19328)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.829% (18839/19456)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.829% (18963/19584)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.819% (19085/19712)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.825% (19210/19840)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.830% (19335/19968)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.815% (19456/20096)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.830% (19583/20224)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.796% (19700/20352)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.787% (19822/20480)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.793% (19947/20608)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.798% (20072/20736)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.803% (20197/20864)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.813% (20323/20992)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.818% (20448/21120)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.823% (20573/21248)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.819% (20696/21376)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.828% (20822/21504)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.833% (20947/21632)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.834% (21071/21760)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.843% (21197/21888)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.843% (21321/22016)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.839% (21444/22144)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.839% (21568/22272)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.839% (21692/22400)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.826% (21813/22528)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.826% (21937/22656)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.809% (22057/22784)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.814% (22182/22912)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.819% (22307/23040)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.815% (22430/23168)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.815% (22554/23296)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.824% (22680/23424)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.833% (22806/23552)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.837% (22931/23680)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.846% (23057/23808)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.837% (23179/23936)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.833% (23302/24064)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.830% (23425/24192)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.817% (23546/24320)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.818% (23670/24448)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (23792/24576)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (23916/24704)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.815% (24041/24832)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.811% (24164/24960)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.811% (24288/25088)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.816% (24413/25216)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.820% (24538/25344)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.816% (24661/25472)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.809% (24783/25600)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.801% (24905/25728)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.794% (25027/25856)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.786% (25149/25984)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.772% (25269/26112)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.780% (25395/26240)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.776% (25518/26368)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.784% (25644/26496)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.789% (25769/26624)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.793% (25894/26752)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.793% (26018/26880)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.801% (26144/27008)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.790% (26265/27136)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.802% (26392/27264)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.795% (26514/27392)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.799% (26639/27520)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.799% (26763/27648)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (26890/27776)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.800% (27011/27904)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.797% (27134/28032)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.804% (27260/28160)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.804% (27384/28288)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.812% (27510/28416)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.815% (27635/28544)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.823% (27761/28672)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.826% (27886/28800)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.813% (28006/28928)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.813% (28130/29056)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.817% (28255/29184)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.820% (28380/29312)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.814% (28502/29440)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.818% (28627/29568)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.814% (28750/29696)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.815% (28874/29824)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.808% (28996/29952)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.812% (29121/30080)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.809% (29244/30208)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.809% (29368/30336)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.809% (29492/30464)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.806% (29615/30592)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (29740/30720)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (29864/30848)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.814% (29989/30976)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.817% (30114/31104)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.817% (30238/31232)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.827% (30365/31360)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.824% (30488/31488)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.824% (30612/31616)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.818% (30734/31744)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.822% (30859/31872)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.816% (30981/32000)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.816% (31105/32128)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (31227/32256)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.801% (31348/32384)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.804% (31473/32512)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.805% (31597/32640)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.808% (31722/32768)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.814% (31848/32896)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.817% (31973/33024)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.815% (32096/33152)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.818% (32221/33280)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.815% (32344/33408)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.806% (32465/33536)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.810% (32590/33664)\n",
      "Train Epoch: 55 | Loss: 0.091 | Acc: 96.813% (32715/33792)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.801% (32835/33920)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.796% (32957/34048)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.793% (33080/34176)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.796% (33205/34304)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.797% (33329/34432)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.782% (33448/34560)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.774% (33569/34688)\n",
      "Train Epoch: 55 | Loss: 0.092 | Acc: 96.774% (33693/34816)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.766% (33814/34944)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.752% (33933/35072)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.750% (34056/35200)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.756% (34182/35328)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (34305/35456)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.751% (34428/35584)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.746% (34550/35712)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.741% (34672/35840)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.728% (34791/35968)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.731% (34916/36096)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.734% (35041/36224)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.737% (35166/36352)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.732% (35288/36480)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.730% (35411/36608)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.731% (35535/36736)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.737% (35661/36864)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.737% (35785/36992)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.730% (35906/37120)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.730% (36030/37248)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.720% (36150/37376)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.726% (36276/37504)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.729% (36401/37632)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.727% (36524/37760)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.719% (36645/37888)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.720% (36769/38016)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.715% (36891/38144)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.713% (37014/38272)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.716% (37139/38400)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.724% (37266/38528)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.733% (37393/38656)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.736% (37518/38784)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.731% (37640/38912)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.739% (37767/39040)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.742% (37892/39168)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.740% (38015/39296)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.746% (38141/39424)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.736% (38261/39552)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.739% (38386/39680)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.737% (38509/39808)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.742% (38635/39936)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.748% (38761/40064)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.748% (38885/40192)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.749% (39009/40320)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.749% (39133/40448)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (39259/40576)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.750% (39381/40704)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.753% (39506/40832)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.746% (39627/40960)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.746% (39751/41088)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.746% (39875/41216)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.742% (39997/41344)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.750% (40124/41472)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.752% (40249/41600)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.753% (40373/41728)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.751% (40496/41856)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.756% (40622/41984)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.761% (40748/42112)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.768% (40875/42240)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.762% (40996/42368)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.760% (41119/42496)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.765% (41245/42624)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.770% (41371/42752)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.768% (41494/42880)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.768% (41618/43008)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.768% (41742/43136)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.766% (41865/43264)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.774% (41992/43392)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.767% (42113/43520)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.763% (42235/43648)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (42355/43776)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.759% (42481/43904)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.759% (42605/44032)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.760% (42729/44160)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.760% (42853/44288)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.758% (42976/44416)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (43098/44544)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.745% (43218/44672)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.743% (43341/44800)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.750% (43468/44928)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.751% (43592/45056)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.755% (43718/45184)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.749% (43839/45312)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.752% (43964/45440)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.752% (44088/45568)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.750% (44211/45696)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.751% (44335/45824)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.751% (44459/45952)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.743% (44579/46080)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.732% (44698/46208)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.733% (44822/46336)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.742% (44950/46464)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.746% (45076/46592)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.753% (45203/46720)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.760% (45330/46848)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.764% (45456/46976)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.762% (45579/47104)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.756% (45700/47232)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.759% (45825/47360)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.763% (45951/47488)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.766% (46076/47616)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.768% (46201/47744)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.764% (46323/47872)\n",
      "Train Epoch: 55 | Loss: 0.094 | Acc: 96.763% (46446/48000)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.763% (46570/48128)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.765% (46695/48256)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.763% (46818/48384)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.766% (46943/48512)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.770% (47069/48640)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.775% (47195/48768)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.773% (47318/48896)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.767% (47439/49024)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.763% (47561/49152)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.761% (47684/49280)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.760% (47807/49408)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (47928/49536)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.754% (48052/49664)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.757% (48177/49792)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.749% (48297/49920)\n",
      "Train Epoch: 55 | Loss: 0.093 | Acc: 96.748% (48374/50000)\n",
      "Test Epoch: 55 | Loss: 0.461 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 55 | Loss: 0.422 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 55 | Loss: 0.424 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 55 | Loss: 0.397 | Acc: 90.000% (540/600)\n",
      "Test Epoch: 55 | Loss: 0.407 | Acc: 90.143% (631/700)\n",
      "Test Epoch: 55 | Loss: 0.434 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 55 | Loss: 0.434 | Acc: 89.000% (801/900)\n",
      "Test Epoch: 55 | Loss: 0.425 | Acc: 89.100% (891/1000)\n",
      "Test Epoch: 55 | Loss: 0.445 | Acc: 88.636% (975/1100)\n",
      "Test Epoch: 55 | Loss: 0.455 | Acc: 88.583% (1063/1200)\n",
      "Test Epoch: 55 | Loss: 0.451 | Acc: 88.615% (1152/1300)\n",
      "Test Epoch: 55 | Loss: 0.443 | Acc: 88.714% (1242/1400)\n",
      "Test Epoch: 55 | Loss: 0.441 | Acc: 88.600% (1329/1500)\n",
      "Test Epoch: 55 | Loss: 0.429 | Acc: 89.000% (1424/1600)\n",
      "Test Epoch: 55 | Loss: 0.419 | Acc: 89.118% (1515/1700)\n",
      "Test Epoch: 55 | Loss: 0.421 | Acc: 88.944% (1601/1800)\n",
      "Test Epoch: 55 | Loss: 0.422 | Acc: 88.789% (1687/1900)\n",
      "Test Epoch: 55 | Loss: 0.433 | Acc: 88.550% (1771/2000)\n",
      "Test Epoch: 55 | Loss: 0.436 | Acc: 88.333% (1855/2100)\n",
      "Test Epoch: 55 | Loss: 0.439 | Acc: 88.182% (1940/2200)\n",
      "Test Epoch: 55 | Loss: 0.437 | Acc: 88.261% (2030/2300)\n",
      "Test Epoch: 55 | Loss: 0.442 | Acc: 88.250% (2118/2400)\n",
      "Test Epoch: 55 | Loss: 0.453 | Acc: 88.080% (2202/2500)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 87.962% (2287/2600)\n",
      "Test Epoch: 55 | Loss: 0.458 | Acc: 88.185% (2381/2700)\n",
      "Test Epoch: 55 | Loss: 0.458 | Acc: 88.286% (2472/2800)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 88.414% (2564/2900)\n",
      "Test Epoch: 55 | Loss: 0.455 | Acc: 88.400% (2652/3000)\n",
      "Test Epoch: 55 | Loss: 0.452 | Acc: 88.419% (2741/3100)\n",
      "Test Epoch: 55 | Loss: 0.453 | Acc: 88.500% (2832/3200)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 88.424% (2918/3300)\n",
      "Test Epoch: 55 | Loss: 0.451 | Acc: 88.529% (3010/3400)\n",
      "Test Epoch: 55 | Loss: 0.461 | Acc: 88.400% (3094/3500)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 88.389% (3182/3600)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.459% (3273/3700)\n",
      "Test Epoch: 55 | Loss: 0.470 | Acc: 88.500% (3363/3800)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.487% (3451/3900)\n",
      "Test Epoch: 55 | Loss: 0.467 | Acc: 88.575% (3543/4000)\n",
      "Test Epoch: 55 | Loss: 0.471 | Acc: 88.488% (3628/4100)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.500% (3717/4200)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 88.558% (3808/4300)\n",
      "Test Epoch: 55 | Loss: 0.468 | Acc: 88.591% (3898/4400)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 88.667% (3990/4500)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 88.565% (4074/4600)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 88.532% (4161/4700)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.375% (4242/4800)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 88.469% (4335/4900)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.420% (4421/5000)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 88.471% (4512/5100)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 88.346% (4594/5200)\n",
      "Test Epoch: 55 | Loss: 0.468 | Acc: 88.340% (4682/5300)\n",
      "Test Epoch: 55 | Loss: 0.467 | Acc: 88.352% (4771/5400)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 88.345% (4859/5500)\n",
      "Test Epoch: 55 | Loss: 0.468 | Acc: 88.375% (4949/5600)\n",
      "Test Epoch: 55 | Loss: 0.467 | Acc: 88.386% (5038/5700)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 88.466% (5131/5800)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 88.475% (5220/5900)\n",
      "Test Epoch: 55 | Loss: 0.462 | Acc: 88.450% (5307/6000)\n",
      "Test Epoch: 55 | Loss: 0.462 | Acc: 88.492% (5398/6100)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 88.500% (5487/6200)\n",
      "Test Epoch: 55 | Loss: 0.460 | Acc: 88.556% (5579/6300)\n",
      "Test Epoch: 55 | Loss: 0.456 | Acc: 88.656% (5674/6400)\n",
      "Test Epoch: 55 | Loss: 0.455 | Acc: 88.631% (5761/6500)\n",
      "Test Epoch: 55 | Loss: 0.452 | Acc: 88.652% (5851/6600)\n",
      "Test Epoch: 55 | Loss: 0.450 | Acc: 88.701% (5943/6700)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 88.676% (6030/6800)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 88.623% (6115/6900)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 88.600% (6202/7000)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 88.620% (6292/7100)\n",
      "Test Epoch: 55 | Loss: 0.450 | Acc: 88.583% (6378/7200)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 88.616% (6469/7300)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 88.635% (6559/7400)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 88.613% (6646/7500)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 88.632% (6736/7600)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 88.688% (6829/7700)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 88.692% (6918/7800)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 88.646% (7003/7900)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 88.638% (7091/8000)\n",
      "Test Epoch: 55 | Loss: 0.443 | Acc: 88.716% (7186/8100)\n",
      "Test Epoch: 55 | Loss: 0.441 | Acc: 88.720% (7275/8200)\n",
      "Test Epoch: 55 | Loss: 0.439 | Acc: 88.723% (7364/8300)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.679% (7449/8400)\n",
      "Test Epoch: 55 | Loss: 0.442 | Acc: 88.647% (7535/8500)\n",
      "Test Epoch: 55 | Loss: 0.442 | Acc: 88.640% (7623/8600)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.678% (7715/8700)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.648% (7801/8800)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.640% (7889/8900)\n",
      "Test Epoch: 55 | Loss: 0.441 | Acc: 88.611% (7975/9000)\n",
      "Test Epoch: 55 | Loss: 0.442 | Acc: 88.604% (8063/9100)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.674% (8158/9200)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.634% (8243/9300)\n",
      "Test Epoch: 55 | Loss: 0.441 | Acc: 88.617% (8330/9400)\n",
      "Test Epoch: 55 | Loss: 0.440 | Acc: 88.611% (8418/9500)\n",
      "Test Epoch: 55 | Loss: 0.439 | Acc: 88.646% (8510/9600)\n",
      "Test Epoch: 55 | Loss: 0.436 | Acc: 88.722% (8606/9700)\n",
      "Test Epoch: 55 | Loss: 0.437 | Acc: 88.704% (8693/9800)\n",
      "Test Epoch: 55 | Loss: 0.437 | Acc: 88.727% (8784/9900)\n",
      "Test Epoch: 55 | Loss: 0.435 | Acc: 88.760% (8876/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 96.094% (123/128)\n",
      "Train Epoch: 56 | Loss: 0.066 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 56 | Loss: 0.064 | Acc: 97.656% (375/384)\n",
      "Train Epoch: 56 | Loss: 0.057 | Acc: 98.242% (503/512)\n",
      "Train Epoch: 56 | Loss: 0.073 | Acc: 97.812% (626/640)\n",
      "Train Epoch: 56 | Loss: 0.070 | Acc: 97.917% (752/768)\n",
      "Train Epoch: 56 | Loss: 0.082 | Acc: 97.545% (874/896)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.461% (998/1024)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.396% (1122/1152)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.266% (1245/1280)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.230% (1369/1408)\n",
      "Train Epoch: 56 | Loss: 0.085 | Acc: 97.266% (1494/1536)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.236% (1618/1664)\n",
      "Train Epoch: 56 | Loss: 0.085 | Acc: 97.266% (1743/1792)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.240% (1867/1920)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.217% (1991/2048)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.059% (2112/2176)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.135% (2238/2304)\n",
      "Train Epoch: 56 | Loss: 0.085 | Acc: 97.204% (2364/2432)\n",
      "Train Epoch: 56 | Loss: 0.082 | Acc: 97.305% (2491/2560)\n",
      "Train Epoch: 56 | Loss: 0.085 | Acc: 97.210% (2613/2688)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.159% (2736/2816)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.011% (2856/2944)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.973% (2979/3072)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.812% (3098/3200)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.845% (3223/3328)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.904% (3349/3456)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.875% (3472/3584)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.929% (3598/3712)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.927% (3722/3840)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.925% (3846/3968)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.948% (3971/4096)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 96.946% (4095/4224)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 96.967% (4220/4352)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 96.942% (4343/4480)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 96.897% (4465/4608)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 96.959% (4592/4736)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 96.998% (4718/4864)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.015% (4843/4992)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.012% (4967/5120)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.008% (5091/5248)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 96.987% (5214/5376)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.984% (5338/5504)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.999% (5463/5632)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.979% (5586/5760)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.011% (5712/5888)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.008% (5836/6016)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.038% (5962/6144)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.003% (6084/6272)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.000% (6208/6400)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.044% (6335/6528)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.055% (6460/6656)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.096% (6587/6784)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.121% (6713/6912)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.088% (6835/7040)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.056% (6957/7168)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.012% (7078/7296)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.983% (7200/7424)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.981% (7324/7552)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.018% (7451/7680)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.977% (7572/7808)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.988% (7697/7936)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.036% (7825/8064)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.021% (7948/8192)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.031% (8073/8320)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.029% (8197/8448)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.073% (8325/8576)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.059% (8448/8704)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.067% (8573/8832)\n",
      "Train Epoch: 56 | Loss: 0.086 | Acc: 97.098% (8700/8960)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.073% (8822/9088)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.059% (8945/9216)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.025% (9066/9344)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.012% (9189/9472)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.052% (9317/9600)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.009% (9437/9728)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.007% (9561/9856)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.045% (9689/9984)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.004% (9809/10112)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.992% (9932/10240)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.971% (10054/10368)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.008% (10182/10496)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.979% (10303/10624)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.015% (10431/10752)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.004% (10554/10880)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.002% (10678/11008)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.028% (10805/11136)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.035% (10930/11264)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.024% (11053/11392)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.023% (11177/11520)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.030% (11302/11648)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.036% (11427/11776)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.060% (11554/11904)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.066% (11679/12032)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.031% (11799/12160)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.013% (11921/12288)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.996% (12043/12416)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.979% (12165/12544)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.985% (12290/12672)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.977% (12413/12800)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.983% (12538/12928)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.975% (12661/13056)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.996% (12788/13184)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.995% (12912/13312)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.979% (13034/13440)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.978% (13158/13568)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.970% (13281/13696)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.976% (13406/13824)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.975% (13530/13952)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.982% (13655/14080)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.995% (13781/14208)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.015% (13908/14336)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.027% (14034/14464)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.026% (14158/14592)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.038% (14284/14720)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.043% (14409/14848)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.055% (14535/14976)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.060% (14660/15104)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.059% (14784/15232)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.057% (14908/15360)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.056% (15032/15488)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.067% (15158/15616)\n",
      "Train Epoch: 56 | Loss: 0.087 | Acc: 97.053% (15280/15744)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.045% (15403/15872)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.044% (15527/16000)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.042% (15651/16128)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.041% (15775/16256)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.028% (15897/16384)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.014% (16019/16512)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 97.025% (16145/16640)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.994% (16264/16768)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.993% (16388/16896)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.969% (16508/17024)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.974% (16633/17152)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.985% (16759/17280)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.996% (16885/17408)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.983% (17007/17536)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.977% (17130/17664)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.965% (17252/17792)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.948% (17373/17920)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.941% (17496/18048)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.930% (17618/18176)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.924% (17741/18304)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.918% (17864/18432)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.913% (17987/18560)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.923% (18113/18688)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.923% (18237/18816)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.928% (18362/18944)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.933% (18487/19072)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.943% (18613/19200)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.937% (18736/19328)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.911% (18855/19456)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.916% (18980/19584)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.926% (19106/19712)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.925% (19230/19840)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.930% (19355/19968)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.925% (19478/20096)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.915% (19600/20224)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.904% (19722/20352)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.899% (19845/20480)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.909% (19971/20608)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.909% (20095/20736)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.909% (20219/20864)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.913% (20344/20992)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.903% (20466/21120)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.889% (20587/21248)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.889% (20711/21376)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.908% (20839/21504)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.912% (20964/21632)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.916% (21089/21760)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.925% (21215/21888)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.934% (21341/22016)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.938% (21466/22144)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.947% (21592/22272)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.951% (21717/22400)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.950% (21841/22528)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.959% (21967/22656)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.963% (22092/22784)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.967% (22217/22912)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.979% (22344/23040)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.974% (22467/23168)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.974% (22591/23296)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.973% (22715/23424)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.973% (22839/23552)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.976% (22964/23680)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.967% (23086/23808)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.979% (23213/23936)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.975% (23336/24064)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.982% (23462/24192)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.974% (23584/24320)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.973% (23708/24448)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.973% (23832/24576)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.984% (23959/24704)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.992% (24085/24832)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.995% (24210/24960)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.995% (24334/25088)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.990% (24457/25216)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.993% (24582/25344)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.993% (24706/25472)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.992% (24830/25600)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.999% (24956/25728)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 96.999% (25080/25856)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.006% (25206/25984)\n",
      "Train Epoch: 56 | Loss: 0.088 | Acc: 97.001% (25329/26112)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.989% (25450/26240)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.985% (25573/26368)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.981% (25696/26496)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.961% (25815/26624)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.950% (25936/26752)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.946% (26059/26880)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.938% (26181/27008)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.927% (26302/27136)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.923% (26425/27264)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.922% (26549/27392)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.922% (26673/27520)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.926% (26798/27648)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.918% (26920/27776)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.925% (27046/27904)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.929% (27171/28032)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.921% (27293/28160)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.907% (27413/28288)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.896% (27534/28416)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.896% (27658/28544)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.896% (27782/28672)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.896% (27906/28800)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.903% (28032/28928)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.903% (28156/29056)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.909% (28282/29184)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.919% (28409/29312)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.906% (28529/29440)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.905% (28653/29568)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.905% (28777/29696)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.898% (28899/29824)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.902% (29024/29952)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.912% (29151/30080)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.921% (29278/30208)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.928% (29404/30336)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.918% (29525/30464)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.917% (29649/30592)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.908% (29770/30720)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.904% (29893/30848)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.894% (30014/30976)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.888% (30136/31104)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.891% (30261/31232)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.901% (30388/31360)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.897% (30511/31488)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.894% (30634/31616)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.897% (30759/31744)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.891% (30881/31872)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.884% (31003/32000)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (31124/32128)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (31248/32256)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.863% (31368/32384)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.869% (31494/32512)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (31620/32640)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.866% (31741/32768)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.869% (31866/32896)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.863% (31988/33024)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.869% (32114/33152)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.872% (32239/33280)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.857% (32358/33408)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.863% (32484/33536)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.866% (32609/33664)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.866% (32733/33792)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.860% (32855/33920)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.840% (32972/34048)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.846% (33098/34176)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.852% (33224/34304)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.849% (33347/34432)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.849% (33471/34560)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.858% (33598/34688)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.864% (33724/34816)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.864% (33848/34944)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.869% (33974/35072)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.869% (34098/35200)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.858% (34218/35328)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.867% (34345/35456)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.869% (34470/35584)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.878% (34597/35712)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.875% (34720/35840)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.883% (34847/35968)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.892% (34974/36096)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.894% (35099/36224)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.900% (35225/36352)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.897% (35348/36480)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.900% (35473/36608)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.908% (35600/36736)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.916% (35727/36864)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.913% (35850/36992)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.910% (35973/37120)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.915% (36099/37248)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.918% (36224/37376)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.912% (36346/37504)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.915% (36471/37632)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.915% (36595/37760)\n",
      "Train Epoch: 56 | Loss: 0.089 | Acc: 96.923% (36722/37888)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.917% (36844/38016)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.912% (36966/38144)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.912% (37090/38272)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.904% (37211/38400)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.898% (37333/38528)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.896% (37456/38656)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.903% (37583/38784)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.896% (37704/38912)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.885% (37824/39040)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.883% (37947/39168)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.885% (38072/39296)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.883% (38195/39424)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.890% (38322/39552)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.885% (38444/39680)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.883% (38567/39808)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.872% (38687/39936)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (38812/40064)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.882% (38939/40192)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.887% (39065/40320)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.895% (39192/40448)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.885% (39312/40576)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.887% (39437/40704)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.892% (39563/40832)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.892% (39687/40960)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.892% (39811/41088)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.887% (39933/41216)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.887% (40057/41344)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.880% (40178/41472)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.880% (40302/41600)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (40423/41728)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (40547/41856)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (40672/41984)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.880% (40798/42112)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (40920/42240)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.868% (41041/42368)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.870% (41166/42496)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (41292/42624)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.880% (41418/42752)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.884% (41544/42880)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (41664/43008)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.870% (41786/43136)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.870% (41910/43264)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (42035/43392)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (42159/43520)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (42285/43648)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.880% (42410/43776)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (42533/43904)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.870% (42654/44032)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (42781/44160)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.870% (42902/44288)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (43027/44416)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (43152/44544)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (43276/44672)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (43401/44800)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.879% (43526/44928)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.884% (43652/45056)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (43773/45184)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (43896/45312)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (44020/45440)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (44145/45568)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.873% (44267/45696)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.875% (44392/45824)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.879% (44518/45952)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.886% (44645/46080)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.888% (44770/46208)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.877% (44889/46336)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.881% (45015/46464)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.884% (45140/46592)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.890% (45267/46720)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.890% (45391/46848)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.892% (45516/46976)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.894% (45641/47104)\n",
      "Train Epoch: 56 | Loss: 0.091 | Acc: 96.900% (45768/47232)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.902% (45893/47360)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.904% (46018/47488)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.909% (46144/47616)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.909% (46268/47744)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.913% (46394/47872)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.910% (46517/48000)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.910% (46641/48128)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.914% (46767/48256)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.910% (46889/48384)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.914% (47015/48512)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.916% (47140/48640)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.914% (47263/48768)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.918% (47389/48896)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.906% (47507/49024)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.908% (47632/49152)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.905% (47755/49280)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.909% (47881/49408)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.909% (48005/49536)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.913% (48131/49664)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.905% (48251/49792)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.905% (48375/49920)\n",
      "Train Epoch: 56 | Loss: 0.090 | Acc: 96.910% (48455/50000)\n",
      "Test Epoch: 56 | Loss: 0.436 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 56 | Loss: 0.391 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 56 | Loss: 0.319 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 56 | Loss: 0.366 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 56 | Loss: 0.354 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 56 | Loss: 0.313 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 56 | Loss: 0.327 | Acc: 91.286% (639/700)\n",
      "Test Epoch: 56 | Loss: 0.377 | Acc: 90.000% (720/800)\n",
      "Test Epoch: 56 | Loss: 0.366 | Acc: 90.111% (811/900)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 90.300% (903/1000)\n",
      "Test Epoch: 56 | Loss: 0.361 | Acc: 90.182% (992/1100)\n",
      "Test Epoch: 56 | Loss: 0.376 | Acc: 89.833% (1078/1200)\n",
      "Test Epoch: 56 | Loss: 0.379 | Acc: 89.615% (1165/1300)\n",
      "Test Epoch: 56 | Loss: 0.379 | Acc: 89.429% (1252/1400)\n",
      "Test Epoch: 56 | Loss: 0.382 | Acc: 89.267% (1339/1500)\n",
      "Test Epoch: 56 | Loss: 0.374 | Acc: 89.500% (1432/1600)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 89.529% (1522/1700)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 89.722% (1615/1800)\n",
      "Test Epoch: 56 | Loss: 0.365 | Acc: 89.684% (1704/1900)\n",
      "Test Epoch: 56 | Loss: 0.380 | Acc: 89.400% (1788/2000)\n",
      "Test Epoch: 56 | Loss: 0.385 | Acc: 89.190% (1873/2100)\n",
      "Test Epoch: 56 | Loss: 0.384 | Acc: 89.182% (1962/2200)\n",
      "Test Epoch: 56 | Loss: 0.377 | Acc: 89.391% (2056/2300)\n",
      "Test Epoch: 56 | Loss: 0.380 | Acc: 89.125% (2139/2400)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 88.800% (2220/2500)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 88.808% (2309/2600)\n",
      "Test Epoch: 56 | Loss: 0.391 | Acc: 89.037% (2404/2700)\n",
      "Test Epoch: 56 | Loss: 0.387 | Acc: 89.214% (2498/2800)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.207% (2587/2900)\n",
      "Test Epoch: 56 | Loss: 0.388 | Acc: 89.300% (2679/3000)\n",
      "Test Epoch: 56 | Loss: 0.383 | Acc: 89.419% (2772/3100)\n",
      "Test Epoch: 56 | Loss: 0.378 | Acc: 89.406% (2861/3200)\n",
      "Test Epoch: 56 | Loss: 0.378 | Acc: 89.424% (2951/3300)\n",
      "Test Epoch: 56 | Loss: 0.378 | Acc: 89.353% (3038/3400)\n",
      "Test Epoch: 56 | Loss: 0.388 | Acc: 89.229% (3123/3500)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.222% (3212/3600)\n",
      "Test Epoch: 56 | Loss: 0.397 | Acc: 89.297% (3304/3700)\n",
      "Test Epoch: 56 | Loss: 0.396 | Acc: 89.342% (3395/3800)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.359% (3485/3900)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.350% (3574/4000)\n",
      "Test Epoch: 56 | Loss: 0.401 | Acc: 89.220% (3658/4100)\n",
      "Test Epoch: 56 | Loss: 0.402 | Acc: 89.262% (3749/4200)\n",
      "Test Epoch: 56 | Loss: 0.399 | Acc: 89.349% (3842/4300)\n",
      "Test Epoch: 56 | Loss: 0.403 | Acc: 89.409% (3934/4400)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 89.511% (4028/4500)\n",
      "Test Epoch: 56 | Loss: 0.399 | Acc: 89.543% (4119/4600)\n",
      "Test Epoch: 56 | Loss: 0.397 | Acc: 89.532% (4208/4700)\n",
      "Test Epoch: 56 | Loss: 0.399 | Acc: 89.438% (4293/4800)\n",
      "Test Epoch: 56 | Loss: 0.397 | Acc: 89.531% (4387/4900)\n",
      "Test Epoch: 56 | Loss: 0.401 | Acc: 89.420% (4471/5000)\n",
      "Test Epoch: 56 | Loss: 0.398 | Acc: 89.471% (4563/5100)\n",
      "Test Epoch: 56 | Loss: 0.398 | Acc: 89.423% (4650/5200)\n",
      "Test Epoch: 56 | Loss: 0.399 | Acc: 89.396% (4738/5300)\n",
      "Test Epoch: 56 | Loss: 0.398 | Acc: 89.426% (4829/5400)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 89.400% (4917/5500)\n",
      "Test Epoch: 56 | Loss: 0.401 | Acc: 89.375% (5005/5600)\n",
      "Test Epoch: 56 | Loss: 0.402 | Acc: 89.351% (5093/5700)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 89.414% (5186/5800)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 89.407% (5275/5900)\n",
      "Test Epoch: 56 | Loss: 0.401 | Acc: 89.333% (5360/6000)\n",
      "Test Epoch: 56 | Loss: 0.400 | Acc: 89.344% (5450/6100)\n",
      "Test Epoch: 56 | Loss: 0.401 | Acc: 89.258% (5534/6200)\n",
      "Test Epoch: 56 | Loss: 0.399 | Acc: 89.270% (5624/6300)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.375% (5720/6400)\n",
      "Test Epoch: 56 | Loss: 0.397 | Acc: 89.338% (5807/6500)\n",
      "Test Epoch: 56 | Loss: 0.394 | Acc: 89.364% (5898/6600)\n",
      "Test Epoch: 56 | Loss: 0.394 | Acc: 89.418% (5991/6700)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.456% (6083/6800)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.522% (6177/6900)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.529% (6267/7000)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.549% (6358/7100)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.528% (6446/7200)\n",
      "Test Epoch: 56 | Loss: 0.394 | Acc: 89.562% (6538/7300)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.622% (6632/7400)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.573% (6718/7500)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.579% (6808/7600)\n",
      "Test Epoch: 56 | Loss: 0.396 | Acc: 89.558% (6896/7700)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.603% (6989/7800)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.595% (7078/7900)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.612% (7169/8000)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.630% (7260/8100)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.634% (7350/8200)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.627% (7439/8300)\n",
      "Test Epoch: 56 | Loss: 0.394 | Acc: 89.560% (7523/8400)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.541% (7611/8500)\n",
      "Test Epoch: 56 | Loss: 0.398 | Acc: 89.523% (7699/8600)\n",
      "Test Epoch: 56 | Loss: 0.396 | Acc: 89.529% (7789/8700)\n",
      "Test Epoch: 56 | Loss: 0.397 | Acc: 89.489% (7875/8800)\n",
      "Test Epoch: 56 | Loss: 0.396 | Acc: 89.494% (7965/8900)\n",
      "Test Epoch: 56 | Loss: 0.396 | Acc: 89.511% (8056/9000)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.538% (8148/9100)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.533% (8237/9200)\n",
      "Test Epoch: 56 | Loss: 0.395 | Acc: 89.505% (8324/9300)\n",
      "Test Epoch: 56 | Loss: 0.394 | Acc: 89.521% (8415/9400)\n",
      "Test Epoch: 56 | Loss: 0.393 | Acc: 89.547% (8507/9500)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.594% (8601/9600)\n",
      "Test Epoch: 56 | Loss: 0.391 | Acc: 89.619% (8693/9700)\n",
      "Test Epoch: 56 | Loss: 0.391 | Acc: 89.612% (8782/9800)\n",
      "Test Epoch: 56 | Loss: 0.392 | Acc: 89.596% (8870/9900)\n",
      "Test Epoch: 56 | Loss: 0.390 | Acc: 89.620% (8962/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Train Epoch: 57 | Loss: 0.066 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 57 | Loss: 0.061 | Acc: 98.438% (252/256)\n",
      "Train Epoch: 57 | Loss: 0.062 | Acc: 97.917% (376/384)\n",
      "Train Epoch: 57 | Loss: 0.068 | Acc: 97.656% (500/512)\n",
      "Train Epoch: 57 | Loss: 0.080 | Acc: 97.344% (623/640)\n",
      "Train Epoch: 57 | Loss: 0.083 | Acc: 97.135% (746/768)\n",
      "Train Epoch: 57 | Loss: 0.091 | Acc: 97.098% (870/896)\n",
      "Train Epoch: 57 | Loss: 0.092 | Acc: 97.168% (995/1024)\n",
      "Train Epoch: 57 | Loss: 0.103 | Acc: 96.788% (1115/1152)\n",
      "Train Epoch: 57 | Loss: 0.100 | Acc: 96.797% (1239/1280)\n",
      "Train Epoch: 57 | Loss: 0.096 | Acc: 96.946% (1365/1408)\n",
      "Train Epoch: 57 | Loss: 0.098 | Acc: 96.810% (1487/1536)\n",
      "Train Epoch: 57 | Loss: 0.101 | Acc: 96.815% (1611/1664)\n",
      "Train Epoch: 57 | Loss: 0.100 | Acc: 96.763% (1734/1792)\n",
      "Train Epoch: 57 | Loss: 0.100 | Acc: 96.771% (1858/1920)\n",
      "Train Epoch: 57 | Loss: 0.098 | Acc: 96.826% (1983/2048)\n",
      "Train Epoch: 57 | Loss: 0.097 | Acc: 96.783% (2106/2176)\n",
      "Train Epoch: 57 | Loss: 0.094 | Acc: 96.918% (2233/2304)\n",
      "Train Epoch: 57 | Loss: 0.094 | Acc: 96.875% (2356/2432)\n",
      "Train Epoch: 57 | Loss: 0.094 | Acc: 96.797% (2478/2560)\n",
      "Train Epoch: 57 | Loss: 0.095 | Acc: 96.689% (2599/2688)\n",
      "Train Epoch: 57 | Loss: 0.095 | Acc: 96.697% (2723/2816)\n",
      "Train Epoch: 57 | Loss: 0.094 | Acc: 96.671% (2846/2944)\n",
      "Train Epoch: 57 | Loss: 0.093 | Acc: 96.680% (2970/3072)\n",
      "Train Epoch: 57 | Loss: 0.095 | Acc: 96.688% (3094/3200)\n",
      "Train Epoch: 57 | Loss: 0.093 | Acc: 96.755% (3220/3328)\n",
      "Train Epoch: 57 | Loss: 0.094 | Acc: 96.730% (3343/3456)\n",
      "Train Epoch: 57 | Loss: 0.093 | Acc: 96.819% (3470/3584)\n",
      "Train Epoch: 57 | Loss: 0.092 | Acc: 96.821% (3594/3712)\n",
      "Train Epoch: 57 | Loss: 0.092 | Acc: 96.849% (3719/3840)\n",
      "Train Epoch: 57 | Loss: 0.092 | Acc: 96.774% (3840/3968)\n",
      "Train Epoch: 57 | Loss: 0.093 | Acc: 96.729% (3962/4096)\n",
      "Train Epoch: 57 | Loss: 0.093 | Acc: 96.757% (4087/4224)\n",
      "Train Epoch: 57 | Loss: 0.092 | Acc: 96.852% (4215/4352)\n",
      "Train Epoch: 57 | Loss: 0.090 | Acc: 96.875% (4340/4480)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.918% (4466/4608)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.959% (4592/4736)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 97.019% (4719/4864)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 97.015% (4843/4992)\n",
      "Train Epoch: 57 | Loss: 0.090 | Acc: 96.914% (4962/5120)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.951% (5088/5248)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.987% (5214/5376)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.966% (5337/5504)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.017% (5464/5632)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.962% (5585/5760)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.926% (5707/5888)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.925% (5831/6016)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.924% (5955/6144)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.923% (6079/6272)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.891% (6201/6400)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.906% (6326/6528)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.905% (6450/6656)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.949% (6577/6784)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.918% (6699/6912)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.903% (6822/7040)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.861% (6943/7168)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.875% (7068/7296)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.902% (7194/7424)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.928% (7320/7552)\n",
      "Train Epoch: 57 | Loss: 0.089 | Acc: 96.940% (7445/7680)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.965% (7571/7808)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.976% (7696/7936)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.949% (7818/8064)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.948% (7942/8192)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.899% (8062/8320)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.899% (8186/8448)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.922% (8312/8576)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.944% (8438/8704)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.966% (8564/8832)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.942% (8686/8960)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.963% (8812/9088)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.962% (8936/9216)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.961% (9060/9344)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.981% (9186/9472)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.948% (9307/9600)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.937% (9430/9728)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.946% (9555/9856)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.945% (9679/9984)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.974% (9806/10112)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.973% (9930/10240)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.962% (10053/10368)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.980% (10179/10496)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.997% (10305/10624)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.015% (10431/10752)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.985% (10552/10880)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.011% (10679/11008)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 97.001% (10802/11136)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.026% (10929/11264)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.015% (11052/11392)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.023% (11177/11520)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.030% (11302/11648)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.994% (11422/11776)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.993% (11546/11904)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 97.000% (11671/12032)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 97.023% (11798/12160)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.997% (11919/12288)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.980% (12041/12416)\n",
      "Train Epoch: 57 | Loss: 0.088 | Acc: 96.995% (12167/12544)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.009% (12293/12672)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.008% (12417/12800)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.030% (12544/12928)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.044% (12670/13056)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.049% (12795/13184)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.063% (12921/13312)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.061% (13045/13440)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.059% (13169/13568)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (13291/13696)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.041% (13415/13824)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.018% (13536/13952)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.024% (13661/14080)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.023% (13785/14208)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (13911/14336)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.062% (14039/14464)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.060% (14163/14592)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.038% (14284/14720)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (14409/14848)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.042% (14533/14976)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.034% (14656/15104)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.019% (14778/15232)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.012% (14901/15360)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.024% (15027/15488)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.048% (15155/15616)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.059% (15281/15744)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.026% (15400/15872)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.031% (15525/16000)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.030% (15649/16128)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (15774/16256)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (15899/16384)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.032% (16022/16512)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.007% (16142/16640)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.006% (16266/16768)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.017% (16392/16896)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.987% (16511/17024)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.997% (16637/17152)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.014% (16764/17280)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.001% (16886/17408)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.006% (17011/17536)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.017% (17137/17664)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (17262/17792)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.037% (17389/17920)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.052% (17516/18048)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (17638/18176)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (17760/18304)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.027% (17884/18432)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.020% (18007/18560)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.030% (18133/18688)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.024% (18256/18816)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (18379/18944)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.011% (18502/19072)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.016% (18627/19200)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.010% (18750/19328)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.024% (18877/19456)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.033% (19003/19584)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.027% (19126/19712)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.031% (19251/19840)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.040% (19377/19968)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.049% (19503/20096)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.043% (19626/20224)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.037% (19749/20352)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.036% (19873/20480)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.030% (19996/20608)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.034% (20121/20736)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.043% (20247/20864)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.046% (20372/20992)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.045% (20496/21120)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.049% (20621/21248)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.053% (20746/21376)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.052% (20870/21504)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.051% (20994/21632)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.054% (21119/21760)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.053% (21243/21888)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.061% (21369/22016)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.038% (21488/22144)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.046% (21614/22272)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.049% (21739/22400)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.066% (21867/22528)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.065% (21991/22656)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.064% (22115/22784)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.063% (22239/22912)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.057% (22362/23040)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.052% (22485/23168)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.042% (22607/23296)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.046% (22732/23424)\n",
      "Train Epoch: 57 | Loss: 0.085 | Acc: 97.049% (22857/23552)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (22979/23680)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.026% (23100/23808)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.030% (23225/23936)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.041% (23352/24064)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.036% (23475/24192)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.039% (23600/24320)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.026% (23721/24448)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (23844/24576)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.013% (23966/24704)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.016% (24091/24832)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.019% (24216/24960)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (24340/25088)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.014% (24463/25216)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (24589/25344)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.024% (24714/25472)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.027% (24839/25600)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.019% (24961/25728)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.030% (25088/25856)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.029% (25212/25984)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (25334/26112)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.012% (25456/26240)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.015% (25581/26368)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (25706/26496)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (25831/26624)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.017% (25954/26752)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.024% (26080/26880)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.023% (26204/27008)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.019% (26327/27136)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.014% (26450/27264)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.014% (26574/27392)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.017% (26699/27520)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.016% (26823/27648)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.023% (26949/27776)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.022% (27073/27904)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (27199/28032)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.038% (27326/28160)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.031% (27448/28288)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.023% (27570/28416)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.033% (27697/28544)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.032% (27821/28672)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (27946/28800)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.037% (28071/28928)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (28196/29056)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.036% (28319/29184)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (28443/29312)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.041% (28569/29440)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.037% (28692/29568)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (28817/29696)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (28942/29824)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.045% (29067/29952)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.041% (29190/30080)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.037% (29313/30208)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.020% (29432/30336)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.013% (29554/30464)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.009% (29677/30592)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.005% (29800/30720)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.008% (29925/30848)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.014% (30051/30976)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.013% (30175/31104)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.013% (30299/31232)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (30425/31360)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (30549/31488)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.008% (30670/31616)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.017% (30797/31744)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 97.013% (30920/31872)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.019% (31046/32000)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.021% (31171/32128)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.030% (31298/32256)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.029% (31422/32384)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.038% (31549/32512)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (31674/32640)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.031% (31795/32768)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.027% (31918/32896)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.029% (32043/33024)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.023% (32165/33152)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (32291/33280)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (32415/33408)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.027% (32539/33536)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.026% (32663/33664)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.026% (32787/33792)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.025% (32911/33920)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (33036/34048)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.033% (33162/34176)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (33287/34304)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.038% (33412/34432)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.037% (33536/34560)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.031% (33658/34688)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.039% (33785/34816)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.041% (33910/34944)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (34035/35072)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.048% (34161/35200)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.045% (34284/35328)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.050% (34410/35456)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (34529/35584)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (34656/35712)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.048% (34782/35840)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.050% (34907/35968)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.055% (35033/36096)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.049% (35155/36224)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.046% (35278/36352)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.042% (35401/36480)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.044% (35526/36608)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.041% (35649/36736)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (35774/36864)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.045% (35899/36992)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.050% (36025/37120)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.050% (36149/37248)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.049% (36273/37376)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.043% (36395/37504)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (36518/37632)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.031% (36639/37760)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.033% (36764/37888)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.035% (36889/38016)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.040% (37015/38144)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.047% (37142/38272)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.049% (37267/38400)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.049% (37391/38528)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.056% (37518/38656)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.053% (37641/38784)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.045% (37762/38912)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.036% (37883/39040)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.028% (38004/39168)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.018% (38124/39296)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.015% (38247/39424)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.009% (38369/39552)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.998% (38489/39680)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.996% (38612/39808)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.993% (38735/39936)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.992% (38859/40064)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.989% (38982/40192)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.997% (39109/40320)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.996% (39233/40448)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.993% (39356/40576)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.995% (39481/40704)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.000% (39607/40832)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.997% (39730/40960)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.002% (39856/41088)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.004% (39981/41216)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.001% (40104/41344)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.991% (40224/41472)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.988% (40347/41600)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.988% (40471/41728)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.987% (40595/41856)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.985% (40718/41984)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.977% (40839/42112)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.982% (40965/42240)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.984% (41090/42368)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.983% (41214/42496)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.990% (41341/42624)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.992% (41466/42752)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.994% (41591/42880)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.996% (41716/43008)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.993% (41839/43136)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.995% (41964/43264)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.995% (42088/43392)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.992% (42211/43520)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.985% (42332/43648)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.989% (42458/43776)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.991% (42583/43904)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.993% (42708/44032)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.000% (42835/44160)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.997% (42958/44288)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.999% (43083/44416)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.003% (43209/44544)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.003% (43333/44672)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.004% (43458/44800)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 97.004% (43582/44928)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.999% (43704/45056)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.997% (43827/45184)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.994% (43950/45312)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.994% (44074/45440)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.989% (44196/45568)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.989% (44320/45696)\n",
      "Train Epoch: 57 | Loss: 0.086 | Acc: 96.984% (44442/45824)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.977% (44563/45952)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.979% (44688/46080)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.972% (44809/46208)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.974% (44934/46336)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.974% (45058/46464)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.974% (45182/46592)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.971% (45305/46720)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.973% (45430/46848)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.969% (45552/46976)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.973% (45678/47104)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.979% (45805/47232)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.981% (45930/47360)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.974% (46051/47488)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.976% (46176/47616)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.971% (46298/47744)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.969% (46421/47872)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.967% (46544/48000)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.964% (46667/48128)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.954% (46786/48256)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.951% (46909/48384)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.945% (47030/48512)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.949% (47156/48640)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.953% (47282/48768)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.955% (47407/48896)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.950% (47529/49024)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.952% (47654/49152)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.954% (47779/49280)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.952% (47902/49408)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.952% (48026/49536)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.956% (48152/49664)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.955% (48276/49792)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.955% (48400/49920)\n",
      "Train Epoch: 57 | Loss: 0.087 | Acc: 96.958% (48479/50000)\n",
      "Test Epoch: 57 | Loss: 0.392 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 57 | Loss: 0.492 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 57 | Loss: 0.393 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 57 | Loss: 0.379 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 57 | Loss: 0.329 | Acc: 91.000% (546/600)\n",
      "Test Epoch: 57 | Loss: 0.358 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 57 | Loss: 0.385 | Acc: 89.375% (715/800)\n",
      "Test Epoch: 57 | Loss: 0.376 | Acc: 89.111% (802/900)\n",
      "Test Epoch: 57 | Loss: 0.396 | Acc: 88.800% (888/1000)\n",
      "Test Epoch: 57 | Loss: 0.413 | Acc: 88.727% (976/1100)\n",
      "Test Epoch: 57 | Loss: 0.428 | Acc: 88.500% (1062/1200)\n",
      "Test Epoch: 57 | Loss: 0.426 | Acc: 88.769% (1154/1300)\n",
      "Test Epoch: 57 | Loss: 0.421 | Acc: 88.714% (1242/1400)\n",
      "Test Epoch: 57 | Loss: 0.418 | Acc: 88.600% (1329/1500)\n",
      "Test Epoch: 57 | Loss: 0.410 | Acc: 88.562% (1417/1600)\n",
      "Test Epoch: 57 | Loss: 0.415 | Acc: 88.588% (1506/1700)\n",
      "Test Epoch: 57 | Loss: 0.420 | Acc: 88.667% (1596/1800)\n",
      "Test Epoch: 57 | Loss: 0.429 | Acc: 88.368% (1679/1900)\n",
      "Test Epoch: 57 | Loss: 0.440 | Acc: 88.350% (1767/2000)\n",
      "Test Epoch: 57 | Loss: 0.444 | Acc: 88.190% (1852/2100)\n",
      "Test Epoch: 57 | Loss: 0.451 | Acc: 88.045% (1937/2200)\n",
      "Test Epoch: 57 | Loss: 0.452 | Acc: 88.087% (2026/2300)\n",
      "Test Epoch: 57 | Loss: 0.447 | Acc: 88.208% (2117/2400)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 87.920% (2198/2500)\n",
      "Test Epoch: 57 | Loss: 0.470 | Acc: 87.808% (2283/2600)\n",
      "Test Epoch: 57 | Loss: 0.461 | Acc: 88.037% (2377/2700)\n",
      "Test Epoch: 57 | Loss: 0.457 | Acc: 88.071% (2466/2800)\n",
      "Test Epoch: 57 | Loss: 0.463 | Acc: 88.103% (2555/2900)\n",
      "Test Epoch: 57 | Loss: 0.463 | Acc: 88.167% (2645/3000)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.161% (2733/3100)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.219% (2823/3200)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 88.030% (2905/3300)\n",
      "Test Epoch: 57 | Loss: 0.460 | Acc: 88.088% (2995/3400)\n",
      "Test Epoch: 57 | Loss: 0.465 | Acc: 87.943% (3078/3500)\n",
      "Test Epoch: 57 | Loss: 0.467 | Acc: 87.972% (3167/3600)\n",
      "Test Epoch: 57 | Loss: 0.470 | Acc: 88.027% (3257/3700)\n",
      "Test Epoch: 57 | Loss: 0.474 | Acc: 88.026% (3345/3800)\n",
      "Test Epoch: 57 | Loss: 0.468 | Acc: 88.103% (3436/3900)\n",
      "Test Epoch: 57 | Loss: 0.468 | Acc: 88.175% (3527/4000)\n",
      "Test Epoch: 57 | Loss: 0.470 | Acc: 88.171% (3615/4100)\n",
      "Test Epoch: 57 | Loss: 0.472 | Acc: 88.119% (3701/4200)\n",
      "Test Epoch: 57 | Loss: 0.466 | Acc: 88.209% (3793/4300)\n",
      "Test Epoch: 57 | Loss: 0.469 | Acc: 88.250% (3883/4400)\n",
      "Test Epoch: 57 | Loss: 0.465 | Acc: 88.289% (3973/4500)\n",
      "Test Epoch: 57 | Loss: 0.464 | Acc: 88.283% (4061/4600)\n",
      "Test Epoch: 57 | Loss: 0.465 | Acc: 88.213% (4146/4700)\n",
      "Test Epoch: 57 | Loss: 0.467 | Acc: 88.062% (4227/4800)\n",
      "Test Epoch: 57 | Loss: 0.464 | Acc: 88.163% (4320/4900)\n",
      "Test Epoch: 57 | Loss: 0.470 | Acc: 88.060% (4403/5000)\n",
      "Test Epoch: 57 | Loss: 0.464 | Acc: 88.196% (4498/5100)\n",
      "Test Epoch: 57 | Loss: 0.467 | Acc: 88.077% (4580/5200)\n",
      "Test Epoch: 57 | Loss: 0.466 | Acc: 88.019% (4665/5300)\n",
      "Test Epoch: 57 | Loss: 0.464 | Acc: 88.093% (4757/5400)\n",
      "Test Epoch: 57 | Loss: 0.464 | Acc: 88.145% (4848/5500)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 88.179% (4938/5600)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 88.211% (5028/5700)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.259% (5119/5800)\n",
      "Test Epoch: 57 | Loss: 0.461 | Acc: 88.186% (5203/5900)\n",
      "Test Epoch: 57 | Loss: 0.461 | Acc: 88.217% (5293/6000)\n",
      "Test Epoch: 57 | Loss: 0.461 | Acc: 88.213% (5381/6100)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 88.177% (5467/6200)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.254% (5560/6300)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.344% (5654/6400)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.277% (5738/6500)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.288% (5827/6600)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.358% (5920/6700)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.338% (6007/6800)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.362% (6097/6900)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.314% (6182/7000)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.338% (6272/7100)\n",
      "Test Epoch: 57 | Loss: 0.462 | Acc: 88.306% (6358/7200)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.356% (6450/7300)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.419% (6543/7400)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.427% (6632/7500)\n",
      "Test Epoch: 57 | Loss: 0.457 | Acc: 88.487% (6725/7600)\n",
      "Test Epoch: 57 | Loss: 0.460 | Acc: 88.468% (6812/7700)\n",
      "Test Epoch: 57 | Loss: 0.461 | Acc: 88.410% (6896/7800)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.418% (6985/7900)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.425% (7074/8000)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.444% (7164/8100)\n",
      "Test Epoch: 57 | Loss: 0.457 | Acc: 88.488% (7256/8200)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.482% (7344/8300)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.440% (7429/8400)\n",
      "Test Epoch: 57 | Loss: 0.459 | Acc: 88.400% (7514/8500)\n",
      "Test Epoch: 57 | Loss: 0.460 | Acc: 88.349% (7598/8600)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.391% (7690/8700)\n",
      "Test Epoch: 57 | Loss: 0.458 | Acc: 88.375% (7777/8800)\n",
      "Test Epoch: 57 | Loss: 0.457 | Acc: 88.348% (7863/8900)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.367% (7953/9000)\n",
      "Test Epoch: 57 | Loss: 0.456 | Acc: 88.341% (8039/9100)\n",
      "Test Epoch: 57 | Loss: 0.454 | Acc: 88.413% (8134/9200)\n",
      "Test Epoch: 57 | Loss: 0.455 | Acc: 88.376% (8219/9300)\n",
      "Test Epoch: 57 | Loss: 0.454 | Acc: 88.436% (8313/9400)\n",
      "Test Epoch: 57 | Loss: 0.453 | Acc: 88.453% (8403/9500)\n",
      "Test Epoch: 57 | Loss: 0.452 | Acc: 88.490% (8495/9600)\n",
      "Test Epoch: 57 | Loss: 0.452 | Acc: 88.515% (8586/9700)\n",
      "Test Epoch: 57 | Loss: 0.452 | Acc: 88.490% (8672/9800)\n",
      "Test Epoch: 57 | Loss: 0.452 | Acc: 88.485% (8760/9900)\n",
      "Test Epoch: 57 | Loss: 0.450 | Acc: 88.520% (8852/10000)\n",
      "\n",
      "Epoch: 58\n",
      "Train Epoch: 58 | Loss: 0.035 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 58 | Loss: 0.058 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 58 | Loss: 0.053 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 58 | Loss: 0.074 | Acc: 97.266% (498/512)\n",
      "Train Epoch: 58 | Loss: 0.071 | Acc: 97.500% (624/640)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 96.745% (743/768)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 96.763% (867/896)\n",
      "Train Epoch: 58 | Loss: 0.078 | Acc: 96.875% (992/1024)\n",
      "Train Epoch: 58 | Loss: 0.074 | Acc: 97.135% (1119/1152)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.031% (1242/1280)\n",
      "Train Epoch: 58 | Loss: 0.076 | Acc: 97.159% (1368/1408)\n",
      "Train Epoch: 58 | Loss: 0.073 | Acc: 97.396% (1496/1536)\n",
      "Train Epoch: 58 | Loss: 0.074 | Acc: 97.536% (1623/1664)\n",
      "Train Epoch: 58 | Loss: 0.077 | Acc: 97.321% (1744/1792)\n",
      "Train Epoch: 58 | Loss: 0.086 | Acc: 97.031% (1863/1920)\n",
      "Train Epoch: 58 | Loss: 0.085 | Acc: 97.070% (1988/2048)\n",
      "Train Epoch: 58 | Loss: 0.085 | Acc: 97.059% (2112/2176)\n",
      "Train Epoch: 58 | Loss: 0.087 | Acc: 97.005% (2235/2304)\n",
      "Train Epoch: 58 | Loss: 0.087 | Acc: 96.916% (2357/2432)\n",
      "Train Epoch: 58 | Loss: 0.087 | Acc: 96.875% (2480/2560)\n",
      "Train Epoch: 58 | Loss: 0.085 | Acc: 96.949% (2606/2688)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.053% (2733/2816)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.045% (2857/2944)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.070% (2982/3072)\n",
      "Train Epoch: 58 | Loss: 0.086 | Acc: 96.875% (3100/3200)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 96.935% (3226/3328)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 96.991% (3352/3456)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.070% (3479/3584)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.010% (3601/3712)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.031% (3726/3840)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.051% (3851/3968)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.095% (3977/4096)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.112% (4102/4224)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.151% (4228/4352)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.210% (4355/4480)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.179% (4478/4608)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.149% (4601/4736)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.225% (4729/4864)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.216% (4853/4992)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.266% (4980/5120)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.256% (5104/5248)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.266% (5229/5376)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.275% (5354/5504)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.283% (5479/5632)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.240% (5601/5760)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.249% (5726/5888)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.191% (5847/6016)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.233% (5974/6144)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.258% (6100/6272)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.250% (6224/6400)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.258% (6349/6528)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.296% (6476/6656)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.288% (6600/6784)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.295% (6725/6912)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.244% (6846/7040)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.238% (6970/7168)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.245% (7095/7296)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.279% (7222/7424)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.312% (7349/7552)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.318% (7474/7680)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.336% (7600/7808)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.366% (7727/7936)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.371% (7852/8064)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.400% (7979/8192)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.392% (8103/8320)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.372% (8226/8448)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.365% (8350/8576)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.392% (8477/8704)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.407% (8603/8832)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.400% (8727/8960)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.381% (8850/9088)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.352% (8972/9216)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.378% (9099/9344)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.382% (9224/9472)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.365% (9347/9600)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.389% (9474/9728)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.372% (9597/9856)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.366% (9721/9984)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.360% (9845/10112)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.324% (9966/10240)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.348% (10093/10368)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.361% (10219/10496)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.383% (10346/10624)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.377% (10470/10752)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.381% (10595/10880)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.356% (10717/11008)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.351% (10841/11136)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.354% (10966/11264)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.367% (11092/11392)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.352% (11215/11520)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.364% (11341/11648)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.351% (11464/11776)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.345% (11588/11904)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.340% (11712/12032)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.360% (11839/12160)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.347% (11962/12288)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.350% (12087/12416)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.345% (12211/12544)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.317% (12332/12672)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.289% (12453/12800)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.293% (12578/12928)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.312% (12705/13056)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.307% (12829/13184)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.326% (12956/13312)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.329% (13081/13440)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.332% (13206/13568)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.335% (13331/13696)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.338% (13456/13824)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.305% (13576/13952)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.280% (13697/14080)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.297% (13824/14208)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.301% (13949/14336)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.311% (14075/14464)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.307% (14199/14592)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.330% (14327/14720)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.346% (14454/14848)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.356% (14580/14976)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.365% (14706/15104)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.381% (14833/15232)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.383% (14958/15360)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.392% (15084/15488)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.394% (15209/15616)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.402% (15335/15744)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.411% (15461/15872)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.419% (15587/16000)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.402% (15709/16128)\n",
      "Train Epoch: 58 | Loss: 0.079 | Acc: 97.398% (15833/16256)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.382% (15955/16384)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.378% (16079/16512)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.368% (16202/16640)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.370% (16327/16768)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.378% (16453/16896)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.398% (16581/17024)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.388% (16704/17152)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.390% (16829/17280)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.392% (16954/17408)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.383% (17077/17536)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.379% (17201/17664)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.358% (17322/17792)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.366% (17448/17920)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.368% (17573/18048)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.376% (17699/18176)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.389% (17826/18304)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.380% (17949/18432)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.387% (18075/18560)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.389% (18200/18688)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.385% (18324/18816)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.392% (18450/18944)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.405% (18577/19072)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.391% (18699/19200)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.387% (18823/19328)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.389% (18948/19456)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.370% (19069/19584)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.372% (19194/19712)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.369% (19318/19840)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.376% (19444/19968)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.348% (19563/20096)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.340% (19686/20224)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.337% (19810/20352)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.334% (19934/20480)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.336% (20059/20608)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.338% (20184/20736)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.330% (20307/20864)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.318% (20429/20992)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.315% (20553/21120)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.317% (20678/21248)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.315% (20802/21376)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.312% (20926/21504)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.300% (21048/21632)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.307% (21174/21760)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.309% (21299/21888)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.316% (21425/22016)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.331% (21553/22144)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.324% (21676/22272)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.326% (21801/22400)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.323% (21925/22528)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.325% (22050/22656)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.336% (22177/22784)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.333% (22301/22912)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.331% (22425/23040)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.320% (22547/23168)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.330% (22674/23296)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.328% (22798/23424)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.317% (22920/23552)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.327% (23047/23680)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.320% (23170/23808)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.309% (23292/23936)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.295% (23413/24064)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.301% (23539/24192)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.294% (23662/24320)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.300% (23788/24448)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.302% (23913/24576)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.308% (24039/24704)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.298% (24161/24832)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.300% (24286/24960)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.298% (24410/25088)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.299% (24535/25216)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.301% (24660/25344)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.299% (24784/25472)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.293% (24907/25600)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.291% (25031/25728)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.277% (25152/25856)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.271% (25275/25984)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.281% (25402/26112)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.290% (25529/26240)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.285% (25652/26368)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.279% (25775/26496)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.277% (25899/26624)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.290% (26027/26752)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.295% (26153/26880)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.297% (26278/27008)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.295% (26402/27136)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.300% (26528/27264)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.302% (26653/27392)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.304% (26778/27520)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.298% (26901/27648)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.296% (27025/27776)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.294% (27149/27904)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.296% (27274/28032)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.283% (27395/28160)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.289% (27521/28288)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.294% (27647/28416)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.285% (27769/28544)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.290% (27895/28672)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.295% (28021/28800)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.293% (28145/28928)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.305% (28273/29056)\n",
      "Train Epoch: 58 | Loss: 0.080 | Acc: 97.310% (28399/29184)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.284% (28516/29312)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.293% (28643/29440)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.288% (28766/29568)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.289% (28891/29696)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.271% (29010/29824)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.269% (29134/29952)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.261% (29256/30080)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.262% (29381/30208)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.267% (29507/30336)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.269% (29632/30464)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.267% (29756/30592)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.266% (29880/30720)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.261% (30003/30848)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.262% (30128/30976)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.261% (30252/31104)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.269% (30379/31232)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.274% (30505/31360)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.285% (30633/31488)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.286% (30758/31616)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.285% (30882/31744)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.283% (31006/31872)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.281% (31130/32000)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.277% (31253/32128)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.287% (31381/32256)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.283% (31504/32384)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.272% (31625/32512)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.279% (31752/32640)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.287% (31879/32768)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.282% (32002/32896)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.278% (32125/33024)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.273% (32248/33152)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.275% (32373/33280)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.279% (32499/33408)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.275% (32622/33536)\n",
      "Train Epoch: 58 | Loss: 0.081 | Acc: 97.270% (32745/33664)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.266% (32868/33792)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.264% (32992/33920)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.248% (33111/34048)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.247% (33235/34176)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.242% (33358/34304)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.235% (33480/34432)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.240% (33606/34560)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.230% (33727/34688)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.234% (33853/34816)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.236% (33978/34944)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.240% (34104/35072)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.227% (34224/35200)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.229% (34349/35328)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.236% (34476/35456)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.232% (34599/35584)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.228% (34722/35712)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.232% (34848/35840)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.231% (34972/35968)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.230% (35096/36096)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.231% (35221/36224)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.235% (35347/36352)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.240% (35473/36480)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.236% (35596/36608)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.232% (35719/36736)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.230% (35843/36864)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.224% (35965/36992)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.220% (36088/37120)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.219% (36212/37248)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.223% (36338/37376)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.224% (36463/37504)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.218% (36585/37632)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.217% (36709/37760)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.213% (36832/37888)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.214% (36957/38016)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.221% (37084/38144)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.209% (37204/38272)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.219% (37332/38400)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.223% (37458/38528)\n",
      "Train Epoch: 58 | Loss: 0.082 | Acc: 97.219% (37581/38656)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.215% (37704/38784)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.212% (37827/38912)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.218% (37954/39040)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.209% (38075/39168)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.213% (38201/39296)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.205% (38322/39424)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.204% (38446/39552)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.205% (38571/39680)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.209% (38697/39808)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.211% (38822/39936)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.202% (38943/40064)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.201% (39067/40192)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.200% (39191/40320)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.204% (39317/40448)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.205% (39442/40576)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.194% (39562/40704)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.196% (39687/40832)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.192% (39810/40960)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.191% (39934/41088)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.198% (40061/41216)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.194% (40184/41344)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.191% (40307/41472)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.185% (40429/41600)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.187% (40554/41728)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.190% (40680/41856)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.194% (40806/41984)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.198% (40932/42112)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.202% (41058/42240)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.196% (41180/42368)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.183% (41299/42496)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.182% (41423/42624)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.177% (41545/42752)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.162% (41663/42880)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.161% (41787/43008)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.158% (41910/43136)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.159% (42035/43264)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.161% (42160/43392)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.158% (42283/43520)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.155% (42406/43648)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.158% (42532/43776)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.157% (42656/43904)\n",
      "Train Epoch: 58 | Loss: 0.083 | Acc: 97.159% (42781/44032)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.147% (42900/44160)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.141% (43022/44288)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.136% (43144/44416)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.129% (43265/44544)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.126% (43388/44672)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.127% (43513/44800)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.122% (43635/44928)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.117% (43757/45056)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.114% (43880/45184)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.109% (44002/45312)\n",
      "Train Epoch: 58 | Loss: 0.085 | Acc: 97.106% (44125/45440)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.108% (44250/45568)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.107% (44374/45696)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.113% (44501/45824)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.108% (44623/45952)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.107% (44747/46080)\n",
      "Train Epoch: 58 | Loss: 0.085 | Acc: 97.098% (44867/46208)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.104% (44994/46336)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.103% (45118/46464)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.107% (45244/46592)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.108% (45369/46720)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.112% (45495/46848)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.113% (45620/46976)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.113% (45744/47104)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.110% (45867/47232)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.105% (45989/47360)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.105% (46113/47488)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.108% (46239/47616)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.114% (46366/47744)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.115% (46491/47872)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.112% (46614/48000)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.112% (46738/48128)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.109% (46861/48256)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.109% (46985/48384)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.110% (47110/48512)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.103% (47231/48640)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.109% (47358/48768)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.112% (47484/48896)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.118% (47611/49024)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.121% (47737/49152)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.119% (47860/49280)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.120% (47985/49408)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.113% (48106/49536)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.111% (48229/49664)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.104% (48350/49792)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.101% (48473/49920)\n",
      "Train Epoch: 58 | Loss: 0.084 | Acc: 97.100% (48550/50000)\n",
      "Test Epoch: 58 | Loss: 0.384 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 58 | Loss: 0.372 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 58 | Loss: 0.327 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 58 | Loss: 0.384 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 58 | Loss: 0.354 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 58 | Loss: 0.326 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 58 | Loss: 0.325 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 58 | Loss: 0.351 | Acc: 89.625% (717/800)\n",
      "Test Epoch: 58 | Loss: 0.376 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 58 | Loss: 0.384 | Acc: 89.400% (894/1000)\n",
      "Test Epoch: 58 | Loss: 0.394 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 58 | Loss: 0.412 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 58 | Loss: 0.408 | Acc: 89.385% (1162/1300)\n",
      "Test Epoch: 58 | Loss: 0.399 | Acc: 89.429% (1252/1400)\n",
      "Test Epoch: 58 | Loss: 0.406 | Acc: 89.333% (1340/1500)\n",
      "Test Epoch: 58 | Loss: 0.403 | Acc: 89.500% (1432/1600)\n",
      "Test Epoch: 58 | Loss: 0.402 | Acc: 89.647% (1524/1700)\n",
      "Test Epoch: 58 | Loss: 0.401 | Acc: 89.611% (1613/1800)\n",
      "Test Epoch: 58 | Loss: 0.405 | Acc: 89.421% (1699/1900)\n",
      "Test Epoch: 58 | Loss: 0.410 | Acc: 89.400% (1788/2000)\n",
      "Test Epoch: 58 | Loss: 0.426 | Acc: 89.000% (1869/2100)\n",
      "Test Epoch: 58 | Loss: 0.424 | Acc: 88.909% (1956/2200)\n",
      "Test Epoch: 58 | Loss: 0.429 | Acc: 88.957% (2046/2300)\n",
      "Test Epoch: 58 | Loss: 0.431 | Acc: 88.833% (2132/2400)\n",
      "Test Epoch: 58 | Loss: 0.442 | Acc: 88.720% (2218/2500)\n",
      "Test Epoch: 58 | Loss: 0.455 | Acc: 88.577% (2303/2600)\n",
      "Test Epoch: 58 | Loss: 0.454 | Acc: 88.704% (2395/2700)\n",
      "Test Epoch: 58 | Loss: 0.455 | Acc: 88.714% (2484/2800)\n",
      "Test Epoch: 58 | Loss: 0.456 | Acc: 88.759% (2574/2900)\n",
      "Test Epoch: 58 | Loss: 0.454 | Acc: 88.733% (2662/3000)\n",
      "Test Epoch: 58 | Loss: 0.451 | Acc: 88.710% (2750/3100)\n",
      "Test Epoch: 58 | Loss: 0.446 | Acc: 88.750% (2840/3200)\n",
      "Test Epoch: 58 | Loss: 0.449 | Acc: 88.667% (2926/3300)\n",
      "Test Epoch: 58 | Loss: 0.444 | Acc: 88.794% (3019/3400)\n",
      "Test Epoch: 58 | Loss: 0.447 | Acc: 88.657% (3103/3500)\n",
      "Test Epoch: 58 | Loss: 0.449 | Acc: 88.694% (3193/3600)\n",
      "Test Epoch: 58 | Loss: 0.449 | Acc: 88.730% (3283/3700)\n",
      "Test Epoch: 58 | Loss: 0.454 | Acc: 88.711% (3371/3800)\n",
      "Test Epoch: 58 | Loss: 0.452 | Acc: 88.795% (3463/3900)\n",
      "Test Epoch: 58 | Loss: 0.453 | Acc: 88.800% (3552/4000)\n",
      "Test Epoch: 58 | Loss: 0.450 | Acc: 88.732% (3638/4100)\n",
      "Test Epoch: 58 | Loss: 0.447 | Acc: 88.786% (3729/4200)\n",
      "Test Epoch: 58 | Loss: 0.443 | Acc: 88.907% (3823/4300)\n",
      "Test Epoch: 58 | Loss: 0.447 | Acc: 88.977% (3915/4400)\n",
      "Test Epoch: 58 | Loss: 0.447 | Acc: 89.044% (4007/4500)\n",
      "Test Epoch: 58 | Loss: 0.444 | Acc: 89.087% (4098/4600)\n",
      "Test Epoch: 58 | Loss: 0.443 | Acc: 89.085% (4187/4700)\n",
      "Test Epoch: 58 | Loss: 0.444 | Acc: 89.000% (4272/4800)\n",
      "Test Epoch: 58 | Loss: 0.439 | Acc: 89.143% (4368/4900)\n",
      "Test Epoch: 58 | Loss: 0.442 | Acc: 89.120% (4456/5000)\n",
      "Test Epoch: 58 | Loss: 0.438 | Acc: 89.176% (4548/5100)\n",
      "Test Epoch: 58 | Loss: 0.440 | Acc: 89.135% (4635/5200)\n",
      "Test Epoch: 58 | Loss: 0.440 | Acc: 89.113% (4723/5300)\n",
      "Test Epoch: 58 | Loss: 0.438 | Acc: 89.185% (4816/5400)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.200% (4906/5500)\n",
      "Test Epoch: 58 | Loss: 0.441 | Acc: 89.196% (4995/5600)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.263% (5088/5700)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.276% (5178/5800)\n",
      "Test Epoch: 58 | Loss: 0.438 | Acc: 89.220% (5264/5900)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.250% (5355/6000)\n",
      "Test Epoch: 58 | Loss: 0.435 | Acc: 89.328% (5449/6100)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.339% (5539/6200)\n",
      "Test Epoch: 58 | Loss: 0.434 | Acc: 89.381% (5631/6300)\n",
      "Test Epoch: 58 | Loss: 0.428 | Acc: 89.516% (5729/6400)\n",
      "Test Epoch: 58 | Loss: 0.428 | Acc: 89.492% (5817/6500)\n",
      "Test Epoch: 58 | Loss: 0.426 | Acc: 89.439% (5903/6600)\n",
      "Test Epoch: 58 | Loss: 0.425 | Acc: 89.478% (5995/6700)\n",
      "Test Epoch: 58 | Loss: 0.425 | Acc: 89.456% (6083/6800)\n",
      "Test Epoch: 58 | Loss: 0.423 | Acc: 89.507% (6176/6900)\n",
      "Test Epoch: 58 | Loss: 0.424 | Acc: 89.457% (6262/7000)\n",
      "Test Epoch: 58 | Loss: 0.426 | Acc: 89.451% (6351/7100)\n",
      "Test Epoch: 58 | Loss: 0.428 | Acc: 89.431% (6439/7200)\n",
      "Test Epoch: 58 | Loss: 0.427 | Acc: 89.452% (6530/7300)\n",
      "Test Epoch: 58 | Loss: 0.426 | Acc: 89.473% (6621/7400)\n",
      "Test Epoch: 58 | Loss: 0.426 | Acc: 89.467% (6710/7500)\n",
      "Test Epoch: 58 | Loss: 0.428 | Acc: 89.421% (6796/7600)\n",
      "Test Epoch: 58 | Loss: 0.431 | Acc: 89.364% (6881/7700)\n",
      "Test Epoch: 58 | Loss: 0.431 | Acc: 89.346% (6969/7800)\n",
      "Test Epoch: 58 | Loss: 0.432 | Acc: 89.342% (7058/7900)\n",
      "Test Epoch: 58 | Loss: 0.431 | Acc: 89.338% (7147/8000)\n",
      "Test Epoch: 58 | Loss: 0.429 | Acc: 89.346% (7237/8100)\n",
      "Test Epoch: 58 | Loss: 0.429 | Acc: 89.378% (7329/8200)\n",
      "Test Epoch: 58 | Loss: 0.429 | Acc: 89.337% (7415/8300)\n",
      "Test Epoch: 58 | Loss: 0.430 | Acc: 89.298% (7501/8400)\n",
      "Test Epoch: 58 | Loss: 0.433 | Acc: 89.212% (7583/8500)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.186% (7670/8600)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.172% (7758/8700)\n",
      "Test Epoch: 58 | Loss: 0.438 | Acc: 89.182% (7848/8800)\n",
      "Test Epoch: 58 | Loss: 0.438 | Acc: 89.169% (7936/8900)\n",
      "Test Epoch: 58 | Loss: 0.439 | Acc: 89.167% (8025/9000)\n",
      "Test Epoch: 58 | Loss: 0.439 | Acc: 89.165% (8114/9100)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.217% (8208/9200)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.237% (8299/9300)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.213% (8386/9400)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.211% (8475/9500)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.208% (8564/9600)\n",
      "Test Epoch: 58 | Loss: 0.435 | Acc: 89.247% (8657/9700)\n",
      "Test Epoch: 58 | Loss: 0.436 | Acc: 89.255% (8747/9800)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.232% (8834/9900)\n",
      "Test Epoch: 58 | Loss: 0.437 | Acc: 89.200% (8920/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Train Epoch: 59 | Loss: 0.101 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 59 | Loss: 0.083 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 59 | Loss: 0.058 | Acc: 98.438% (504/512)\n",
      "Train Epoch: 59 | Loss: 0.051 | Acc: 98.594% (631/640)\n",
      "Train Epoch: 59 | Loss: 0.056 | Acc: 98.438% (756/768)\n",
      "Train Epoch: 59 | Loss: 0.052 | Acc: 98.549% (883/896)\n",
      "Train Epoch: 59 | Loss: 0.051 | Acc: 98.633% (1010/1024)\n",
      "Train Epoch: 59 | Loss: 0.051 | Acc: 98.611% (1136/1152)\n",
      "Train Epoch: 59 | Loss: 0.053 | Acc: 98.438% (1260/1280)\n",
      "Train Epoch: 59 | Loss: 0.062 | Acc: 98.082% (1381/1408)\n",
      "Train Epoch: 59 | Loss: 0.062 | Acc: 98.047% (1506/1536)\n",
      "Train Epoch: 59 | Loss: 0.064 | Acc: 97.957% (1630/1664)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.935% (1755/1792)\n",
      "Train Epoch: 59 | Loss: 0.063 | Acc: 98.021% (1882/1920)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.900% (2005/2048)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.794% (2128/2176)\n",
      "Train Epoch: 59 | Loss: 0.066 | Acc: 97.830% (2254/2304)\n",
      "Train Epoch: 59 | Loss: 0.066 | Acc: 97.862% (2380/2432)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.891% (2506/2560)\n",
      "Train Epoch: 59 | Loss: 0.064 | Acc: 97.954% (2633/2688)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.940% (2758/2816)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.928% (2883/2944)\n",
      "Train Epoch: 59 | Loss: 0.065 | Acc: 97.949% (3009/3072)\n",
      "Train Epoch: 59 | Loss: 0.066 | Acc: 97.844% (3131/3200)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.867% (3257/3328)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.859% (3382/3456)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.879% (3508/3584)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.926% (3635/3712)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.917% (3760/3840)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.883% (3884/3968)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.949% (4012/4096)\n",
      "Train Epoch: 59 | Loss: 0.066 | Acc: 97.988% (4139/4224)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.978% (4264/4352)\n",
      "Train Epoch: 59 | Loss: 0.067 | Acc: 97.946% (4388/4480)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.895% (4511/4608)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.910% (4637/4736)\n",
      "Train Epoch: 59 | Loss: 0.068 | Acc: 97.882% (4761/4864)\n",
      "Train Epoch: 59 | Loss: 0.069 | Acc: 97.817% (4883/4992)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.656% (5000/5120)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.637% (5124/5248)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.638% (5249/5376)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.656% (5375/5504)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.692% (5502/5632)\n",
      "Train Epoch: 59 | Loss: 0.072 | Acc: 97.691% (5627/5760)\n",
      "Train Epoch: 59 | Loss: 0.072 | Acc: 97.741% (5755/5888)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.656% (5875/6016)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.624% (5998/6144)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.624% (6123/6272)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.656% (6250/6400)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.610% (6372/6528)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.566% (6494/6656)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.597% (6621/6784)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.598% (6746/6912)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.543% (6867/7040)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.573% (6994/7168)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.601% (7121/7296)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.616% (7247/7424)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.643% (7374/7552)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.630% (7498/7680)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.618% (7622/7808)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.644% (7749/7936)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.656% (7875/8064)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.668% (8001/8192)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.668% (8126/8320)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.656% (8250/8448)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.668% (8376/8576)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.645% (8499/8704)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.634% (8623/8832)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.623% (8747/8960)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.623% (8872/9088)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.635% (8998/9216)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.624% (9122/9344)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.603% (9245/9472)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.604% (9370/9600)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.574% (9492/9728)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.585% (9618/9856)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.556% (9740/9984)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.547% (9864/10112)\n",
      "Train Epoch: 59 | Loss: 0.073 | Acc: 97.549% (9989/10240)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.502% (10109/10368)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.485% (10232/10496)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.468% (10355/10624)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.470% (10480/10752)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.454% (10603/10880)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.484% (10731/11008)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.486% (10856/11136)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.479% (10980/11264)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.489% (11106/11392)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.491% (11231/11520)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.502% (11357/11648)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.452% (11476/11776)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.438% (11599/11904)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.424% (11722/12032)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.434% (11848/12160)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.428% (11972/12288)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.455% (12100/12416)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.465% (12226/12544)\n",
      "Train Epoch: 59 | Loss: 0.074 | Acc: 97.467% (12351/12672)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.430% (12471/12800)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.424% (12595/12928)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.419% (12719/13056)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.414% (12843/13184)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.408% (12967/13312)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.396% (13090/13440)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.406% (13216/13568)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.401% (13340/13696)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.403% (13465/13824)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.427% (13593/13952)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.408% (13715/14080)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.396% (13838/14208)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.391% (13962/14336)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.394% (14087/14464)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.403% (14213/14592)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.412% (14339/14720)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.407% (14463/14848)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.396% (14586/14976)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.405% (14712/15104)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.413% (14838/15232)\n",
      "Train Epoch: 59 | Loss: 0.075 | Acc: 97.396% (14960/15360)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.385% (15083/15488)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.355% (15203/15616)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.358% (15328/15744)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.360% (15453/15872)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.369% (15579/16000)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.390% (15707/16128)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.386% (15831/16256)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.369% (15953/16384)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.378% (16079/16512)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.368% (16202/16640)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.358% (16325/16768)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.360% (16450/16896)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.363% (16575/17024)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.365% (16700/17152)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.355% (16823/17280)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.363% (16949/17408)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.365% (17074/17536)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.373% (17200/17664)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.381% (17326/17792)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.388% (17452/17920)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.385% (17576/18048)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.392% (17702/18176)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.389% (17826/18304)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.390% (17951/18432)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.403% (18078/18560)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.389% (18200/18688)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.391% (18325/18816)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.398% (18451/18944)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.399% (18576/19072)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.401% (18701/19200)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.408% (18827/19328)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.410% (18952/19456)\n",
      "Train Epoch: 59 | Loss: 0.076 | Acc: 97.401% (19075/19584)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.382% (19196/19712)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.369% (19318/19840)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.361% (19441/19968)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.363% (19566/20096)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.355% (19689/20224)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.361% (19815/20352)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.363% (19940/20480)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.360% (20064/20608)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.338% (20184/20736)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.340% (20309/20864)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.342% (20434/20992)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.330% (20556/21120)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.327% (20680/21248)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.338% (20807/21376)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.331% (20930/21504)\n",
      "Train Epoch: 59 | Loss: 0.077 | Acc: 97.337% (21056/21632)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.330% (21179/21760)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.327% (21303/21888)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.325% (21427/22016)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.322% (21551/22144)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.324% (21676/22272)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.321% (21800/22400)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.319% (21924/22528)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.312% (22047/22656)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.310% (22171/22784)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.307% (22295/22912)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.300% (22418/23040)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.311% (22545/23168)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.313% (22670/23296)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.310% (22794/23424)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.312% (22919/23552)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.306% (23042/23680)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.308% (23167/23808)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.314% (23293/23936)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.311% (23417/24064)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.305% (23540/24192)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.319% (23668/24320)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.329% (23795/24448)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.310% (23915/24576)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.300% (24037/24704)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.294% (24160/24832)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.292% (24284/24960)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.298% (24410/25088)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.299% (24535/25216)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.297% (24659/25344)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.295% (24783/25472)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.285% (24905/25600)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.283% (25029/25728)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.285% (25154/25856)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.283% (25278/25984)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.289% (25404/26112)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.294% (25530/26240)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.281% (25651/26368)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.283% (25776/26496)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.269% (25897/26624)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.256% (26018/26752)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.258% (26143/26880)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.264% (26269/27008)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.258% (26392/27136)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.264% (26518/27264)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.266% (26643/27392)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.260% (26766/27520)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.269% (26893/27648)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.267% (27017/27776)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.266% (27141/27904)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.264% (27265/28032)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.255% (27387/28160)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.260% (27513/28288)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.245% (27633/28416)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.253% (27760/28544)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.248% (27883/28672)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.243% (28006/28800)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.241% (28130/28928)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.243% (28255/29056)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.231% (28376/29184)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.230% (28500/29312)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.232% (28625/29440)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.240% (28752/29568)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.249% (28879/29696)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.257% (29006/29824)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.256% (29130/29952)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.254% (29254/30080)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.262% (29381/30208)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.261% (29505/30336)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.259% (29629/30464)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.254% (29752/30592)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.266% (29880/30720)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.274% (30007/30848)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.279% (30133/30976)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.283% (30259/31104)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.291% (30386/31232)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.299% (30513/31360)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.294% (30636/31488)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.280% (30756/31616)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.278% (30880/31744)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.273% (31003/31872)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.278% (31129/32000)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.286% (31256/32128)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.290% (31382/32256)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.289% (31506/32384)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.284% (31629/32512)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.292% (31756/32640)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.296% (31882/32768)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.276% (32000/32896)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.278% (32125/33024)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.282% (32251/33152)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.281% (32375/33280)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.282% (32500/33408)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.284% (32625/33536)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.291% (32752/33664)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.289% (32876/33792)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.285% (32999/33920)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.280% (33122/34048)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.282% (33247/34176)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.292% (33375/34304)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.293% (33500/34432)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.295% (33625/34560)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.302% (33752/34688)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.291% (33873/34816)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.299% (34000/34944)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.303% (34126/35072)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.310% (34253/35200)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.311% (34378/35328)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.309% (34502/35456)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.308% (34626/35584)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.315% (34753/35712)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.324% (34881/35840)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.320% (35004/35968)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.307% (35124/36096)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.317% (35252/36224)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.321% (35378/36352)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.316% (35501/36480)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.323% (35628/36608)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.321% (35752/36736)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.320% (35876/36864)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.321% (36001/36992)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.311% (36122/37120)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.310% (36246/37248)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.316% (36373/37376)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.318% (36498/37504)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.319% (36623/37632)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.323% (36749/37760)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.326% (36875/37888)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.330% (37001/38016)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.329% (37125/38144)\n",
      "Train Epoch: 59 | Loss: 0.078 | Acc: 97.335% (37252/38272)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.336% (37377/38400)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.332% (37500/38528)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.325% (37622/38656)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.321% (37745/38784)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.325% (37871/38912)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.326% (37996/39040)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.322% (38119/39168)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.315% (38241/39296)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.311% (38364/39424)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.312% (38489/39552)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.306% (38611/39680)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.302% (38734/39808)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.301% (38858/39936)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.299% (38982/40064)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.298% (39106/40192)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.299% (39231/40320)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.300% (39356/40448)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.301% (39481/40576)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.298% (39604/40704)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.294% (39727/40832)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.300% (39854/40960)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.303% (39980/41088)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.302% (40104/41216)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.296% (40226/41344)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.295% (40350/41472)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.296% (40475/41600)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.299% (40601/41728)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.300% (40726/41856)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.299% (40850/41984)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.300% (40975/42112)\n",
      "Train Epoch: 59 | Loss: 0.079 | Acc: 97.304% (41101/42240)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.297% (41223/42368)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.292% (41345/42496)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.293% (41470/42624)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.280% (41589/42752)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.283% (41715/42880)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.280% (41838/43008)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.278% (41962/43136)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.275% (42085/43264)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.274% (42209/43392)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.273% (42333/43520)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.271% (42457/43648)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.270% (42581/43776)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.276% (42708/43904)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.266% (42828/44032)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.267% (42953/44160)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.268% (43078/44288)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.269% (43203/44416)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.272% (43329/44544)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.265% (43450/44672)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.257% (43571/44800)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.256% (43695/44928)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.257% (43820/45056)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.258% (43945/45184)\n",
      "Train Epoch: 59 | Loss: 0.080 | Acc: 97.255% (44068/45312)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.254% (44192/45440)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.246% (44313/45568)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.249% (44439/45696)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.246% (44562/45824)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.245% (44686/45952)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.240% (44808/46080)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.239% (44932/46208)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.235% (45055/46336)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.237% (45180/46464)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.233% (45303/46592)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.228% (45425/46720)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.229% (45550/46848)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.226% (45673/46976)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.221% (45795/47104)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.220% (45919/47232)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.221% (46044/47360)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.220% (46168/47488)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.222% (46293/47616)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.221% (46417/47744)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.220% (46541/47872)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.221% (46666/48000)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.226% (46793/48128)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.231% (46920/48256)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.233% (47045/48384)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.236% (47171/48512)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.241% (47298/48640)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.240% (47422/48768)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.237% (47545/48896)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.234% (47668/49024)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.231% (47791/49152)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.238% (47919/49280)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.239% (48044/49408)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.234% (48166/49536)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.237% (48292/49664)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.232% (48414/49792)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.236% (48540/49920)\n",
      "Train Epoch: 59 | Loss: 0.081 | Acc: 97.236% (48618/50000)\n",
      "Test Epoch: 59 | Loss: 0.467 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 59 | Loss: 0.388 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 59 | Loss: 0.316 | Acc: 91.667% (275/300)\n",
      "Test Epoch: 59 | Loss: 0.342 | Acc: 91.250% (365/400)\n",
      "Test Epoch: 59 | Loss: 0.327 | Acc: 91.600% (458/500)\n",
      "Test Epoch: 59 | Loss: 0.283 | Acc: 92.667% (556/600)\n",
      "Test Epoch: 59 | Loss: 0.299 | Acc: 92.571% (648/700)\n",
      "Test Epoch: 59 | Loss: 0.327 | Acc: 92.000% (736/800)\n",
      "Test Epoch: 59 | Loss: 0.316 | Acc: 92.222% (830/900)\n",
      "Test Epoch: 59 | Loss: 0.332 | Acc: 92.000% (920/1000)\n",
      "Test Epoch: 59 | Loss: 0.343 | Acc: 91.636% (1008/1100)\n",
      "Test Epoch: 59 | Loss: 0.359 | Acc: 91.083% (1093/1200)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 90.923% (1182/1300)\n",
      "Test Epoch: 59 | Loss: 0.363 | Acc: 90.786% (1271/1400)\n",
      "Test Epoch: 59 | Loss: 0.361 | Acc: 90.667% (1360/1500)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 90.688% (1451/1600)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 90.765% (1543/1700)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 90.833% (1635/1800)\n",
      "Test Epoch: 59 | Loss: 0.354 | Acc: 90.842% (1726/1900)\n",
      "Test Epoch: 59 | Loss: 0.371 | Acc: 90.600% (1812/2000)\n",
      "Test Epoch: 59 | Loss: 0.379 | Acc: 90.333% (1897/2100)\n",
      "Test Epoch: 59 | Loss: 0.378 | Acc: 90.227% (1985/2200)\n",
      "Test Epoch: 59 | Loss: 0.381 | Acc: 90.217% (2075/2300)\n",
      "Test Epoch: 59 | Loss: 0.378 | Acc: 90.083% (2162/2400)\n",
      "Test Epoch: 59 | Loss: 0.388 | Acc: 89.880% (2247/2500)\n",
      "Test Epoch: 59 | Loss: 0.399 | Acc: 89.769% (2334/2600)\n",
      "Test Epoch: 59 | Loss: 0.393 | Acc: 89.889% (2427/2700)\n",
      "Test Epoch: 59 | Loss: 0.392 | Acc: 89.893% (2517/2800)\n",
      "Test Epoch: 59 | Loss: 0.397 | Acc: 89.897% (2607/2900)\n",
      "Test Epoch: 59 | Loss: 0.395 | Acc: 89.867% (2696/3000)\n",
      "Test Epoch: 59 | Loss: 0.398 | Acc: 89.742% (2782/3100)\n",
      "Test Epoch: 59 | Loss: 0.394 | Acc: 89.781% (2873/3200)\n",
      "Test Epoch: 59 | Loss: 0.394 | Acc: 89.788% (2963/3300)\n",
      "Test Epoch: 59 | Loss: 0.391 | Acc: 89.676% (3049/3400)\n",
      "Test Epoch: 59 | Loss: 0.393 | Acc: 89.657% (3138/3500)\n",
      "Test Epoch: 59 | Loss: 0.395 | Acc: 89.722% (3230/3600)\n",
      "Test Epoch: 59 | Loss: 0.402 | Acc: 89.730% (3320/3700)\n",
      "Test Epoch: 59 | Loss: 0.404 | Acc: 89.711% (3409/3800)\n",
      "Test Epoch: 59 | Loss: 0.399 | Acc: 89.821% (3503/3900)\n",
      "Test Epoch: 59 | Loss: 0.401 | Acc: 89.775% (3591/4000)\n",
      "Test Epoch: 59 | Loss: 0.410 | Acc: 89.634% (3675/4100)\n",
      "Test Epoch: 59 | Loss: 0.411 | Acc: 89.595% (3763/4200)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.721% (3858/4300)\n",
      "Test Epoch: 59 | Loss: 0.410 | Acc: 89.682% (3946/4400)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.711% (4037/4500)\n",
      "Test Epoch: 59 | Loss: 0.410 | Acc: 89.630% (4123/4600)\n",
      "Test Epoch: 59 | Loss: 0.408 | Acc: 89.638% (4213/4700)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.604% (4301/4800)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.653% (4393/4900)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.560% (4478/5000)\n",
      "Test Epoch: 59 | Loss: 0.404 | Acc: 89.667% (4573/5100)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.596% (4659/5200)\n",
      "Test Epoch: 59 | Loss: 0.407 | Acc: 89.453% (4741/5300)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.481% (4832/5400)\n",
      "Test Epoch: 59 | Loss: 0.407 | Acc: 89.473% (4921/5500)\n",
      "Test Epoch: 59 | Loss: 0.408 | Acc: 89.500% (5012/5600)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.544% (5104/5700)\n",
      "Test Epoch: 59 | Loss: 0.403 | Acc: 89.603% (5197/5800)\n",
      "Test Epoch: 59 | Loss: 0.405 | Acc: 89.576% (5285/5900)\n",
      "Test Epoch: 59 | Loss: 0.404 | Acc: 89.550% (5373/6000)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.541% (5462/6100)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.597% (5555/6200)\n",
      "Test Epoch: 59 | Loss: 0.404 | Acc: 89.635% (5647/6300)\n",
      "Test Epoch: 59 | Loss: 0.400 | Acc: 89.734% (5743/6400)\n",
      "Test Epoch: 59 | Loss: 0.400 | Acc: 89.723% (5832/6500)\n",
      "Test Epoch: 59 | Loss: 0.400 | Acc: 89.742% (5923/6600)\n",
      "Test Epoch: 59 | Loss: 0.397 | Acc: 89.821% (6018/6700)\n",
      "Test Epoch: 59 | Loss: 0.396 | Acc: 89.853% (6110/6800)\n",
      "Test Epoch: 59 | Loss: 0.394 | Acc: 89.884% (6202/6900)\n",
      "Test Epoch: 59 | Loss: 0.395 | Acc: 89.857% (6290/7000)\n",
      "Test Epoch: 59 | Loss: 0.397 | Acc: 89.817% (6377/7100)\n",
      "Test Epoch: 59 | Loss: 0.400 | Acc: 89.806% (6466/7200)\n",
      "Test Epoch: 59 | Loss: 0.398 | Acc: 89.863% (6560/7300)\n",
      "Test Epoch: 59 | Loss: 0.397 | Acc: 89.905% (6653/7400)\n",
      "Test Epoch: 59 | Loss: 0.400 | Acc: 89.853% (6739/7500)\n",
      "Test Epoch: 59 | Loss: 0.402 | Acc: 89.816% (6826/7600)\n",
      "Test Epoch: 59 | Loss: 0.404 | Acc: 89.779% (6913/7700)\n",
      "Test Epoch: 59 | Loss: 0.403 | Acc: 89.795% (7004/7800)\n",
      "Test Epoch: 59 | Loss: 0.403 | Acc: 89.823% (7096/7900)\n",
      "Test Epoch: 59 | Loss: 0.403 | Acc: 89.812% (7185/8000)\n",
      "Test Epoch: 59 | Loss: 0.401 | Acc: 89.827% (7276/8100)\n",
      "Test Epoch: 59 | Loss: 0.401 | Acc: 89.829% (7366/8200)\n",
      "Test Epoch: 59 | Loss: 0.401 | Acc: 89.831% (7456/8300)\n",
      "Test Epoch: 59 | Loss: 0.403 | Acc: 89.786% (7542/8400)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.706% (7625/8500)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.628% (7708/8600)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.621% (7797/8700)\n",
      "Test Epoch: 59 | Loss: 0.410 | Acc: 89.636% (7888/8800)\n",
      "Test Epoch: 59 | Loss: 0.410 | Acc: 89.607% (7975/8900)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.644% (8068/9000)\n",
      "Test Epoch: 59 | Loss: 0.408 | Acc: 89.648% (8158/9100)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.707% (8253/9200)\n",
      "Test Epoch: 59 | Loss: 0.408 | Acc: 89.688% (8341/9300)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.702% (8432/9400)\n",
      "Test Epoch: 59 | Loss: 0.409 | Acc: 89.695% (8521/9500)\n",
      "Test Epoch: 59 | Loss: 0.407 | Acc: 89.708% (8612/9600)\n",
      "Test Epoch: 59 | Loss: 0.406 | Acc: 89.711% (8702/9700)\n",
      "Test Epoch: 59 | Loss: 0.407 | Acc: 89.704% (8791/9800)\n",
      "Test Epoch: 59 | Loss: 0.407 | Acc: 89.687% (8879/9900)\n",
      "Test Epoch: 59 | Loss: 0.405 | Acc: 89.740% (8974/10000)\n",
      "\n",
      "Epoch: 60\n",
      "Train Epoch: 60 | Loss: 0.066 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 60 | Loss: 0.084 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.917% (376/384)\n",
      "Train Epoch: 60 | Loss: 0.059 | Acc: 98.242% (503/512)\n",
      "Train Epoch: 60 | Loss: 0.059 | Acc: 98.281% (629/640)\n",
      "Train Epoch: 60 | Loss: 0.066 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 60 | Loss: 0.064 | Acc: 97.879% (877/896)\n",
      "Train Epoch: 60 | Loss: 0.064 | Acc: 97.852% (1002/1024)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.569% (1124/1152)\n",
      "Train Epoch: 60 | Loss: 0.065 | Acc: 97.734% (1251/1280)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.585% (1374/1408)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.396% (1496/1536)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.296% (1619/1664)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.321% (1744/1792)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.344% (1869/1920)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.314% (1993/2048)\n",
      "Train Epoch: 60 | Loss: 0.076 | Acc: 97.243% (2116/2176)\n",
      "Train Epoch: 60 | Loss: 0.075 | Acc: 97.309% (2242/2304)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.327% (2367/2432)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.383% (2493/2560)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.284% (2615/2688)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.230% (2738/2816)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.283% (2864/2944)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.363% (2991/3072)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.375% (3116/3200)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.386% (3241/3328)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.396% (3366/3456)\n",
      "Train Epoch: 60 | Loss: 0.075 | Acc: 97.294% (3487/3584)\n",
      "Train Epoch: 60 | Loss: 0.075 | Acc: 97.279% (3611/3712)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.292% (3736/3840)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.303% (3861/3968)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.363% (3988/4096)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.372% (4113/4224)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.449% (4241/4352)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.455% (4366/4480)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.483% (4492/4608)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.508% (4618/4736)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.512% (4743/4864)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.556% (4870/4992)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.559% (4995/5120)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.618% (5123/5248)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.619% (5248/5376)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.584% (5371/5504)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.638% (5499/5632)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.674% (5626/5760)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.673% (5751/5888)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.689% (5877/6016)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.705% (6003/6144)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.736% (6130/6272)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.719% (6254/6400)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.687% (6377/6528)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.671% (6501/6656)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.627% (6623/6784)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.642% (6749/6912)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.685% (6877/7040)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (7000/7168)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.643% (7124/7296)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (7250/7424)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.669% (7376/7552)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.695% (7503/7680)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.695% (7628/7808)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.694% (7753/7936)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.706% (7879/8064)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.681% (8002/8192)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.692% (8128/8320)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.680% (8252/8448)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.668% (8376/8576)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.679% (8502/8704)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.679% (8627/8832)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (8750/8960)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.667% (8876/9088)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.645% (8999/9216)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.646% (9124/9344)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.667% (9251/9472)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.646% (9374/9600)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.667% (9501/9728)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.646% (9624/9856)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.676% (9752/9984)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.696% (9879/10112)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.686% (10003/10240)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.666% (10126/10368)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (10250/10496)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (10375/10624)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.675% (10502/10752)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.675% (10627/10880)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.684% (10753/11008)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.692% (10879/11136)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.701% (11005/11264)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.718% (11132/11392)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.682% (11253/11520)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.682% (11378/11648)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.682% (11503/11776)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.665% (11626/11904)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (11750/12032)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (11875/12160)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.648% (11999/12288)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (12125/12416)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (12250/12544)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.664% (12376/12672)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.648% (12499/12800)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.664% (12626/12928)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (12750/13056)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.656% (12875/13184)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.641% (12998/13312)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.641% (13123/13440)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.627% (13246/13568)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.612% (13369/13696)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.613% (13494/13824)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.628% (13621/13952)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.635% (13747/14080)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.649% (13874/14208)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.663% (14001/14336)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.663% (14126/14464)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.663% (14251/14592)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.670% (14377/14720)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.670% (14502/14848)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.670% (14627/14976)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.669% (14752/15104)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.656% (14875/15232)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.669% (15002/15360)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.669% (15127/15488)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.669% (15252/15616)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.644% (15373/15744)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.644% (15498/15872)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.656% (15625/16000)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.669% (15752/16128)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.662% (15876/16256)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.668% (16002/16384)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.687% (16130/16512)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.686% (16255/16640)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.680% (16379/16768)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.680% (16504/16896)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.674% (16628/17024)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.680% (16754/17152)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.674% (16878/17280)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.679% (17004/17408)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.673% (17128/17536)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.685% (17255/17664)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.690% (17381/17792)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.679% (17504/17920)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.695% (17632/18048)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.689% (17756/18176)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.689% (17881/18304)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.700% (18008/18432)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.667% (18127/18560)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.672% (18253/18688)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.683% (18380/18816)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.683% (18505/18944)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.682% (18630/19072)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.672% (18753/19200)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.682% (18880/19328)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.687% (19006/19456)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.702% (19134/19584)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.702% (19259/19712)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.697% (19383/19840)\n",
      "Train Epoch: 60 | Loss: 0.068 | Acc: 97.696% (19508/19968)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.676% (19629/20096)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.661% (19751/20224)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.646% (19873/20352)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.651% (19999/20480)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.656% (20125/20608)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.651% (20249/20736)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.651% (20374/20864)\n",
      "Train Epoch: 60 | Loss: 0.069 | Acc: 97.637% (20496/20992)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.633% (20620/21120)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.633% (20745/21248)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.624% (20868/21376)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.619% (20992/21504)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.619% (21117/21632)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.619% (21242/21760)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.592% (21361/21888)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.597% (21487/22016)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.607% (21614/22144)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.611% (21740/22272)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.607% (21864/22400)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.616% (21991/22528)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.612% (22115/22656)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.604% (22238/22784)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.595% (22361/22912)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.591% (22485/23040)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.592% (22610/23168)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.600% (22737/23296)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.605% (22863/23424)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.618% (22991/23552)\n",
      "Train Epoch: 60 | Loss: 0.070 | Acc: 97.618% (23116/23680)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.606% (23238/23808)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.614% (23365/23936)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.606% (23488/24064)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.598% (23611/24192)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.599% (23736/24320)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.579% (23856/24448)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.579% (23981/24576)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.583% (24107/24704)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.584% (24232/24832)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.580% (24356/24960)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.588% (24483/25088)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.589% (24608/25216)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.593% (24734/25344)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.597% (24860/25472)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.582% (24981/25600)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.586% (25107/25728)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.563% (25226/25856)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.568% (25352/25984)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.572% (25478/26112)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.584% (25606/26240)\n",
      "Train Epoch: 60 | Loss: 0.071 | Acc: 97.588% (25732/26368)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.566% (25851/26496)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.570% (25977/26624)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.574% (26103/26752)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.571% (26227/26880)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.567% (26351/27008)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.571% (26477/27136)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.572% (26602/27264)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.565% (26725/27392)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.558% (26848/27520)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.544% (26969/27648)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.537% (27092/27776)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.538% (27217/27904)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.524% (27338/28032)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.525% (27463/28160)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.529% (27589/28288)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.530% (27714/28416)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.530% (27839/28544)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.527% (27963/28672)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.510% (28083/28800)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.518% (28210/28928)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.522% (28336/29056)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.519% (28460/29184)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.527% (28587/29312)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.527% (28712/29440)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.514% (28833/29568)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.508% (28956/29696)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.502% (29079/29824)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.509% (29206/29952)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.513% (29332/30080)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.517% (29458/30208)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.511% (29581/30336)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.512% (29706/30464)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.516% (29832/30592)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.520% (29958/30720)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.523% (30084/30848)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.524% (30209/30976)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.528% (30335/31104)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.535% (30462/31232)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.522% (30583/31360)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.523% (30708/31488)\n",
      "Train Epoch: 60 | Loss: 0.072 | Acc: 97.527% (30834/31616)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.524% (30958/31744)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.512% (31079/31872)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.513% (31204/32000)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.510% (31328/32128)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.507% (31452/32256)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.508% (31577/32384)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.515% (31704/32512)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.521% (31831/32640)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.525% (31957/32768)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.532% (32084/32896)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.535% (32210/33024)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.530% (32333/33152)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.527% (32457/33280)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.525% (32581/33408)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.519% (32704/33536)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.523% (32830/33664)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.526% (32956/33792)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.529% (33082/33920)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.536% (33209/34048)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.542% (33336/34176)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.540% (33460/34304)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.540% (33585/34432)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.538% (33709/34560)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.529% (33831/34688)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.536% (33958/34816)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.539% (34084/34944)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.548% (34212/35072)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.543% (34335/35200)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.543% (34460/35328)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.543% (34585/35456)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.547% (34711/35584)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.541% (34834/35712)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.542% (34959/35840)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.528% (35079/35968)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.529% (35204/36096)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.527% (35328/36224)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.527% (35453/36352)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.516% (35574/36480)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.517% (35699/36608)\n",
      "Train Epoch: 60 | Loss: 0.073 | Acc: 97.512% (35822/36736)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.510% (35946/36864)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.510% (36071/36992)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (36193/37120)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.498% (36316/37248)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.496% (36440/37376)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.491% (36563/37504)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.489% (36687/37632)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.497% (36815/37760)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.498% (36940/37888)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.501% (37066/38016)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.507% (37193/38144)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.510% (37319/38272)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (37441/38400)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.501% (37565/38528)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.498% (37689/38656)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.494% (37812/38784)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.499% (37939/38912)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.508% (38067/39040)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (38190/39168)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.498% (38313/39296)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.496% (38437/39424)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.497% (38562/39552)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.492% (38685/39680)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.495% (38811/39808)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.498% (38937/39936)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.494% (39060/40064)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.500% (39187/40192)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.495% (39310/40320)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.500% (39437/40448)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.501% (39562/40576)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.501% (39687/40704)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.502% (39812/40832)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.502% (39937/40960)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.508% (40064/41088)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.506% (40188/41216)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.499% (40310/41344)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.497% (40434/41472)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.502% (40561/41600)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (40686/41728)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (40811/41856)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.509% (40938/41984)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.507% (41062/42112)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.509% (41188/42240)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.510% (41313/42368)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.508% (41437/42496)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.504% (41560/42624)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.502% (41684/42752)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.500% (41808/42880)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.503% (41934/43008)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.496% (42056/43136)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.501% (42183/43264)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.506% (42310/43392)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.493% (42429/43520)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.494% (42554/43648)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.489% (42677/43776)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.485% (42800/43904)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.488% (42926/44032)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.484% (43049/44160)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.487% (43175/44288)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.485% (43299/44416)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.488% (43425/44544)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.486% (43549/44672)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.487% (43674/44800)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.489% (43800/44928)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.485% (43923/45056)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.479% (44045/45184)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.477% (44169/45312)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.474% (44292/45440)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.474% (44417/45568)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.475% (44542/45696)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.469% (44664/45824)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.469% (44789/45952)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.470% (44914/46080)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.461% (45035/46208)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.464% (45161/46336)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.467% (45287/46464)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.467% (45412/46592)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.468% (45537/46720)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.468% (45662/46848)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.473% (45789/46976)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.472% (45913/47104)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.468% (46036/47232)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.464% (46159/47360)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.465% (46284/47488)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.465% (46409/47616)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.468% (46535/47744)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.466% (46659/47872)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.467% (46784/48000)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.467% (46909/48128)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.459% (47030/48256)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.462% (47156/48384)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.465% (47282/48512)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.459% (47404/48640)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.453% (47526/48768)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.458% (47653/48896)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.462% (47780/49024)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.461% (47904/49152)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.459% (48028/49280)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.462% (48154/49408)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.458% (48277/49536)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.461% (48403/49664)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.461% (48528/49792)\n",
      "Train Epoch: 60 | Loss: 0.074 | Acc: 97.460% (48652/49920)\n",
      "Train Epoch: 60 | Loss: 0.075 | Acc: 97.454% (48727/50000)\n",
      "Test Epoch: 60 | Loss: 0.352 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 60 | Loss: 0.364 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 60 | Loss: 0.296 | Acc: 91.667% (275/300)\n",
      "Test Epoch: 60 | Loss: 0.355 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 60 | Loss: 0.330 | Acc: 90.800% (454/500)\n",
      "Test Epoch: 60 | Loss: 0.292 | Acc: 91.833% (551/600)\n",
      "Test Epoch: 60 | Loss: 0.316 | Acc: 91.143% (638/700)\n",
      "Test Epoch: 60 | Loss: 0.343 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 60 | Loss: 0.334 | Acc: 90.556% (815/900)\n",
      "Test Epoch: 60 | Loss: 0.348 | Acc: 90.300% (903/1000)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 89.909% (989/1100)\n",
      "Test Epoch: 60 | Loss: 0.366 | Acc: 89.667% (1076/1200)\n",
      "Test Epoch: 60 | Loss: 0.359 | Acc: 89.923% (1169/1300)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 89.714% (1256/1400)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 89.600% (1344/1500)\n",
      "Test Epoch: 60 | Loss: 0.361 | Acc: 89.625% (1434/1600)\n",
      "Test Epoch: 60 | Loss: 0.368 | Acc: 89.529% (1522/1700)\n",
      "Test Epoch: 60 | Loss: 0.372 | Acc: 89.389% (1609/1800)\n",
      "Test Epoch: 60 | Loss: 0.382 | Acc: 89.105% (1693/1900)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 88.950% (1779/2000)\n",
      "Test Epoch: 60 | Loss: 0.402 | Acc: 88.857% (1866/2100)\n",
      "Test Epoch: 60 | Loss: 0.403 | Acc: 88.864% (1955/2200)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.043% (2048/2300)\n",
      "Test Epoch: 60 | Loss: 0.398 | Acc: 89.042% (2137/2400)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 89.000% (2225/2500)\n",
      "Test Epoch: 60 | Loss: 0.411 | Acc: 88.846% (2310/2600)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 89.148% (2407/2700)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.250% (2499/2800)\n",
      "Test Epoch: 60 | Loss: 0.402 | Acc: 89.172% (2586/2900)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 89.133% (2674/3000)\n",
      "Test Epoch: 60 | Loss: 0.397 | Acc: 89.161% (2764/3100)\n",
      "Test Epoch: 60 | Loss: 0.393 | Acc: 89.250% (2856/3200)\n",
      "Test Epoch: 60 | Loss: 0.398 | Acc: 89.182% (2943/3300)\n",
      "Test Epoch: 60 | Loss: 0.396 | Acc: 89.265% (3035/3400)\n",
      "Test Epoch: 60 | Loss: 0.404 | Acc: 89.171% (3121/3500)\n",
      "Test Epoch: 60 | Loss: 0.406 | Acc: 89.250% (3213/3600)\n",
      "Test Epoch: 60 | Loss: 0.414 | Acc: 89.270% (3303/3700)\n",
      "Test Epoch: 60 | Loss: 0.418 | Acc: 89.237% (3391/3800)\n",
      "Test Epoch: 60 | Loss: 0.415 | Acc: 89.308% (3483/3900)\n",
      "Test Epoch: 60 | Loss: 0.414 | Acc: 89.350% (3574/4000)\n",
      "Test Epoch: 60 | Loss: 0.418 | Acc: 89.244% (3659/4100)\n",
      "Test Epoch: 60 | Loss: 0.420 | Acc: 89.214% (3747/4200)\n",
      "Test Epoch: 60 | Loss: 0.415 | Acc: 89.326% (3841/4300)\n",
      "Test Epoch: 60 | Loss: 0.417 | Acc: 89.318% (3930/4400)\n",
      "Test Epoch: 60 | Loss: 0.413 | Acc: 89.378% (4022/4500)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.391% (4112/4600)\n",
      "Test Epoch: 60 | Loss: 0.410 | Acc: 89.319% (4198/4700)\n",
      "Test Epoch: 60 | Loss: 0.413 | Acc: 89.250% (4284/4800)\n",
      "Test Epoch: 60 | Loss: 0.410 | Acc: 89.347% (4378/4900)\n",
      "Test Epoch: 60 | Loss: 0.415 | Acc: 89.260% (4463/5000)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.353% (4557/5100)\n",
      "Test Epoch: 60 | Loss: 0.414 | Acc: 89.269% (4642/5200)\n",
      "Test Epoch: 60 | Loss: 0.414 | Acc: 89.189% (4727/5300)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.259% (4820/5400)\n",
      "Test Epoch: 60 | Loss: 0.415 | Acc: 89.273% (4910/5500)\n",
      "Test Epoch: 60 | Loss: 0.416 | Acc: 89.321% (5002/5600)\n",
      "Test Epoch: 60 | Loss: 0.414 | Acc: 89.333% (5092/5700)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.345% (5182/5800)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.339% (5271/5900)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.367% (5362/6000)\n",
      "Test Epoch: 60 | Loss: 0.412 | Acc: 89.393% (5453/6100)\n",
      "Test Epoch: 60 | Loss: 0.411 | Acc: 89.387% (5542/6200)\n",
      "Test Epoch: 60 | Loss: 0.411 | Acc: 89.429% (5634/6300)\n",
      "Test Epoch: 60 | Loss: 0.408 | Acc: 89.469% (5726/6400)\n",
      "Test Epoch: 60 | Loss: 0.408 | Acc: 89.492% (5817/6500)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.485% (5906/6600)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.522% (5998/6700)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.544% (6089/6800)\n",
      "Test Epoch: 60 | Loss: 0.405 | Acc: 89.609% (6183/6900)\n",
      "Test Epoch: 60 | Loss: 0.405 | Acc: 89.571% (6270/7000)\n",
      "Test Epoch: 60 | Loss: 0.406 | Acc: 89.592% (6361/7100)\n",
      "Test Epoch: 60 | Loss: 0.410 | Acc: 89.542% (6447/7200)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.589% (6540/7300)\n",
      "Test Epoch: 60 | Loss: 0.406 | Acc: 89.608% (6631/7400)\n",
      "Test Epoch: 60 | Loss: 0.405 | Acc: 89.613% (6721/7500)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.618% (6811/7600)\n",
      "Test Epoch: 60 | Loss: 0.407 | Acc: 89.584% (6898/7700)\n",
      "Test Epoch: 60 | Loss: 0.406 | Acc: 89.564% (6986/7800)\n",
      "Test Epoch: 60 | Loss: 0.403 | Acc: 89.557% (7075/7900)\n",
      "Test Epoch: 60 | Loss: 0.405 | Acc: 89.562% (7165/8000)\n",
      "Test Epoch: 60 | Loss: 0.402 | Acc: 89.630% (7260/8100)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 89.646% (7351/8200)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.651% (7441/8300)\n",
      "Test Epoch: 60 | Loss: 0.399 | Acc: 89.643% (7530/8400)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.635% (7619/8500)\n",
      "Test Epoch: 60 | Loss: 0.401 | Acc: 89.581% (7704/8600)\n",
      "Test Epoch: 60 | Loss: 0.399 | Acc: 89.609% (7796/8700)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.625% (7887/8800)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.629% (7977/8900)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.578% (8062/9000)\n",
      "Test Epoch: 60 | Loss: 0.400 | Acc: 89.538% (8148/9100)\n",
      "Test Epoch: 60 | Loss: 0.397 | Acc: 89.598% (8243/9200)\n",
      "Test Epoch: 60 | Loss: 0.398 | Acc: 89.581% (8331/9300)\n",
      "Test Epoch: 60 | Loss: 0.398 | Acc: 89.574% (8420/9400)\n",
      "Test Epoch: 60 | Loss: 0.397 | Acc: 89.600% (8512/9500)\n",
      "Test Epoch: 60 | Loss: 0.396 | Acc: 89.635% (8605/9600)\n",
      "Test Epoch: 60 | Loss: 0.395 | Acc: 89.670% (8698/9700)\n",
      "Test Epoch: 60 | Loss: 0.396 | Acc: 89.684% (8789/9800)\n",
      "Test Epoch: 60 | Loss: 0.395 | Acc: 89.677% (8878/9900)\n",
      "Test Epoch: 60 | Loss: 0.393 | Acc: 89.670% (8967/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Train Epoch: 61 | Loss: 0.082 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 61 | Loss: 0.094 | Acc: 96.094% (246/256)\n",
      "Train Epoch: 61 | Loss: 0.092 | Acc: 96.354% (370/384)\n",
      "Train Epoch: 61 | Loss: 0.080 | Acc: 97.070% (497/512)\n",
      "Train Epoch: 61 | Loss: 0.078 | Acc: 97.344% (623/640)\n",
      "Train Epoch: 61 | Loss: 0.082 | Acc: 97.135% (746/768)\n",
      "Train Epoch: 61 | Loss: 0.078 | Acc: 97.433% (873/896)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.656% (1000/1024)\n",
      "Train Epoch: 61 | Loss: 0.076 | Acc: 97.483% (1123/1152)\n",
      "Train Epoch: 61 | Loss: 0.075 | Acc: 97.578% (1249/1280)\n",
      "Train Epoch: 61 | Loss: 0.076 | Acc: 97.514% (1373/1408)\n",
      "Train Epoch: 61 | Loss: 0.077 | Acc: 97.461% (1497/1536)\n",
      "Train Epoch: 61 | Loss: 0.075 | Acc: 97.596% (1624/1664)\n",
      "Train Epoch: 61 | Loss: 0.078 | Acc: 97.489% (1747/1792)\n",
      "Train Epoch: 61 | Loss: 0.077 | Acc: 97.552% (1873/1920)\n",
      "Train Epoch: 61 | Loss: 0.075 | Acc: 97.607% (1999/2048)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.656% (2125/2176)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.656% (2250/2304)\n",
      "Train Epoch: 61 | Loss: 0.075 | Acc: 97.574% (2373/2432)\n",
      "Train Epoch: 61 | Loss: 0.075 | Acc: 97.578% (2498/2560)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.693% (2626/2688)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.692% (2751/2816)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.622% (2874/2944)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.656% (3000/3072)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.562% (3122/3200)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.626% (3249/3328)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.569% (3372/3456)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.656% (3500/3584)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.656% (3625/3712)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (3750/3840)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.707% (3877/3968)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.754% (4004/4096)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.751% (4129/4224)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.748% (4254/4352)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.679% (4376/4480)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.656% (4500/4608)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.656% (4625/4736)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.615% (4748/4864)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.636% (4874/4992)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (5000/5120)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.675% (5126/5248)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.638% (5249/5376)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.656% (5375/5504)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.674% (5501/5632)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.674% (5626/5760)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.605% (5747/5888)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.640% (5874/6016)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.640% (5999/6144)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.624% (6123/6272)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.609% (6247/6400)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.641% (6374/6528)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.626% (6498/6656)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.612% (6622/6784)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.613% (6747/6912)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.585% (6870/7040)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.586% (6995/7168)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.574% (7119/7296)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.589% (7245/7424)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.630% (7373/7552)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.630% (7498/7680)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.669% (7626/7808)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.694% (7753/7936)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.693% (7878/8064)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.693% (8003/8192)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.680% (8127/8320)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.692% (8253/8448)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.726% (8381/8576)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.725% (8506/8704)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.690% (8628/8832)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.723% (8756/8960)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.722% (8881/9088)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.711% (9005/9216)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.710% (9130/9344)\n",
      "Train Epoch: 61 | Loss: 0.068 | Acc: 97.720% (9256/9472)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.719% (9381/9600)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.687% (9503/9728)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.646% (9624/9856)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.636% (9748/9984)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.646% (9874/10112)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.617% (9996/10240)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.618% (10121/10368)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.618% (10246/10496)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.628% (10372/10624)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.638% (10498/10752)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.647% (10624/10880)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.620% (10746/11008)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.629% (10872/11136)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.621% (10996/11264)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.612% (11120/11392)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.622% (11246/11520)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.630% (11372/11648)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.631% (11497/11776)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (11625/11904)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (11750/12032)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (11875/12160)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.656% (12000/12288)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.672% (12127/12416)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.672% (12252/12544)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.680% (12378/12672)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.695% (12505/12800)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.703% (12631/12928)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.687% (12754/13056)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.679% (12878/13184)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.679% (13003/13312)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.679% (13128/13440)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.686% (13254/13568)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.693% (13380/13696)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.678% (13503/13824)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.671% (13627/13952)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.649% (13749/14080)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.628% (13871/14208)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.628% (13996/14336)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.615% (14119/14464)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.622% (14245/14592)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.609% (14368/14720)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.596% (14491/14848)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.583% (14614/14976)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.590% (14740/15104)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.571% (14862/15232)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.572% (14987/15360)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.579% (15113/15488)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.586% (15239/15616)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.593% (15365/15744)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.587% (15489/15872)\n",
      "Train Epoch: 61 | Loss: 0.069 | Acc: 97.581% (15613/16000)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.563% (15735/16128)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.564% (15860/16256)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.571% (15986/16384)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.571% (16111/16512)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.566% (16235/16640)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.573% (16361/16768)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.567% (16485/16896)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.580% (16612/17024)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.563% (16734/17152)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.564% (16859/17280)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.553% (16982/17408)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.559% (17108/17536)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.560% (17233/17664)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.561% (17358/17792)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.561% (17483/17920)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.540% (17604/18048)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.552% (17731/18176)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.563% (17858/18304)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.564% (17983/18432)\n",
      "Train Epoch: 61 | Loss: 0.070 | Acc: 97.570% (18109/18560)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.533% (18227/18688)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.534% (18352/18816)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.540% (18478/18944)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.546% (18604/19072)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.552% (18730/19200)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.553% (18855/19328)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.559% (18981/19456)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.544% (19103/19584)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.555% (19230/19712)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.560% (19356/19840)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.561% (19481/19968)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.552% (19604/20096)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.552% (19729/20224)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.563% (19856/20352)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.554% (19979/20480)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.549% (20103/20608)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.555% (20229/20736)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.551% (20353/20864)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.551% (20478/20992)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.547% (20602/21120)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.548% (20727/21248)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.553% (20853/21376)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.540% (20975/21504)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.536% (21099/21632)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.546% (21226/21760)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.551% (21352/21888)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.565% (21480/22016)\n",
      "Train Epoch: 61 | Loss: 0.071 | Acc: 97.543% (21600/22144)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.535% (21723/22272)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.531% (21847/22400)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.536% (21973/22528)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.515% (22093/22656)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.511% (22217/22784)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.512% (22342/22912)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.504% (22465/23040)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.505% (22590/23168)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.493% (22712/23296)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.485% (22835/23424)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.478% (22958/23552)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.479% (23083/23680)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.471% (23206/23808)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.472% (23331/23936)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.461% (23453/24064)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.470% (23580/24192)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.467% (23704/24320)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.472% (23830/24448)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.477% (23956/24576)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (24083/24704)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.487% (24208/24832)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.476% (24330/24960)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.469% (24453/25088)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.478% (24580/25216)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.479% (24705/25344)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.476% (24829/25472)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.480% (24955/25600)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.481% (25080/25728)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.482% (25205/25856)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.483% (25330/25984)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.488% (25456/26112)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.489% (25581/26240)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.478% (25703/26368)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.479% (25828/26496)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.483% (25954/26624)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.473% (26076/26752)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.474% (26201/26880)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.467% (26324/27008)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.454% (26445/27136)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.447% (26568/27264)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.448% (26693/27392)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.445% (26817/27520)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.454% (26944/27648)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.458% (27070/27776)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.463% (27196/27904)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.460% (27320/28032)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.457% (27444/28160)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.458% (27569/28288)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.459% (27694/28416)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.460% (27819/28544)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.450% (27941/28672)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.448% (28065/28800)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.452% (28191/28928)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.457% (28317/29056)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.458% (28442/29184)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.458% (28567/29312)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.452% (28690/29440)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.450% (28814/29568)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.447% (28938/29696)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.448% (29063/29824)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.453% (29189/29952)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.453% (29314/30080)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.451% (29438/30208)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.455% (29564/30336)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.459% (29690/30464)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.457% (29814/30592)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.464% (29941/30720)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.475% (30069/30848)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.479% (30195/30976)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.476% (30319/31104)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (30447/31232)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (30572/31360)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.482% (30695/31488)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.473% (30817/31616)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.477% (30943/31744)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.477% (31068/31872)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (31196/32000)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.485% (31320/32128)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.480% (31443/32256)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.474% (31566/32384)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.469% (31689/32512)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.466% (31813/32640)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.470% (31939/32768)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.465% (32062/32896)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.459% (32185/33024)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.457% (32309/33152)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.458% (32434/33280)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.462% (32560/33408)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.465% (32686/33536)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.457% (32808/33664)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.452% (32931/33792)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.453% (33056/33920)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.445% (33178/34048)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.440% (33301/34176)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.443% (33427/34304)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.438% (33550/34432)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.442% (33676/34560)\n",
      "Train Epoch: 61 | Loss: 0.074 | Acc: 97.446% (33802/34688)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.452% (33929/34816)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.450% (34053/34944)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.454% (34179/35072)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.463% (34307/35200)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.455% (34429/35328)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.453% (34553/35456)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.460% (34680/35584)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.469% (34808/35712)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.475% (34935/35840)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.478% (35061/35968)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.482% (35187/36096)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.482% (35312/36224)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (35438/36352)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (35563/36480)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.487% (35688/36608)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.479% (35810/36736)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.488% (35938/36864)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.491% (36064/36992)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.495% (36190/37120)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.482% (36310/37248)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.477% (36433/37376)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.475% (36557/37504)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.476% (36682/37632)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.476% (36807/37760)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.466% (36928/37888)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.475% (37056/38016)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.470% (37179/38144)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.466% (37302/38272)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.464% (37426/38400)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.464% (37551/38528)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.467% (37677/38656)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.473% (37804/38784)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.481% (37932/38912)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.487% (38059/39040)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.493% (38186/39168)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.491% (38310/39296)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.489% (38434/39424)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.494% (38561/39552)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.490% (38684/39680)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.493% (38810/39808)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.493% (38935/39936)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.494% (39060/40064)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.497% (39186/40192)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.495% (39310/40320)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.488% (39432/40448)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.491% (39558/40576)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.487% (39681/40704)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.490% (39807/40832)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.495% (39934/40960)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.488% (40056/41088)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.484% (40179/41216)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.487% (40305/41344)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.480% (40427/41472)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (40554/41600)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (40679/41728)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.482% (40802/41856)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.485% (40928/41984)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.483% (41052/42112)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (41178/42240)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.484% (41302/42368)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (41428/42496)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.492% (41555/42624)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.488% (41678/42752)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.479% (41799/42880)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.473% (41921/43008)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.475% (42047/43136)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.481% (42174/43264)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.479% (42298/43392)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.486% (42426/43520)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.480% (42548/43648)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.485% (42675/43776)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.485% (42800/43904)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (42925/44032)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (43050/44160)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (43177/44288)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.499% (43305/44416)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.497% (43429/44544)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.495% (43553/44672)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.498% (43679/44800)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.498% (43804/44928)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.496% (43928/45056)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.492% (44051/45184)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.493% (44176/45312)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (44300/45440)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.494% (44426/45568)\n",
      "Train Epoch: 61 | Loss: 0.072 | Acc: 97.494% (44551/45696)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.495% (44676/45824)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.497% (44802/45952)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.493% (44925/46080)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.492% (45049/46208)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.490% (45173/46336)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (45298/46464)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (45421/46592)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.485% (45545/46720)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.488% (45671/46848)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.490% (45797/46976)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.489% (45921/47104)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (46047/47232)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.489% (46171/47360)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.484% (46293/47488)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.484% (46418/47616)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (46546/47744)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.487% (46669/47872)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.483% (46792/48000)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (46918/48128)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (47043/48256)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.489% (47169/48384)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.495% (47297/48512)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.490% (47419/48640)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.490% (47544/48768)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.484% (47666/48896)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.481% (47789/49024)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.483% (47915/49152)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.486% (48041/49280)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.488% (48167/49408)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (48293/49536)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.491% (48418/49664)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.496% (48545/49792)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.498% (48671/49920)\n",
      "Train Epoch: 61 | Loss: 0.073 | Acc: 97.498% (48749/50000)\n",
      "Test Epoch: 61 | Loss: 0.288 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 61 | Loss: 0.351 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 61 | Loss: 0.383 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 61 | Loss: 0.387 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 61 | Loss: 0.388 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 61 | Loss: 0.345 | Acc: 90.500% (543/600)\n",
      "Test Epoch: 61 | Loss: 0.354 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 61 | Loss: 0.374 | Acc: 89.625% (717/800)\n",
      "Test Epoch: 61 | Loss: 0.379 | Acc: 89.556% (806/900)\n",
      "Test Epoch: 61 | Loss: 0.394 | Acc: 89.400% (894/1000)\n",
      "Test Epoch: 61 | Loss: 0.413 | Acc: 89.182% (981/1100)\n",
      "Test Epoch: 61 | Loss: 0.436 | Acc: 88.750% (1065/1200)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 88.846% (1155/1300)\n",
      "Test Epoch: 61 | Loss: 0.424 | Acc: 88.929% (1245/1400)\n",
      "Test Epoch: 61 | Loss: 0.418 | Acc: 88.800% (1332/1500)\n",
      "Test Epoch: 61 | Loss: 0.417 | Acc: 88.812% (1421/1600)\n",
      "Test Epoch: 61 | Loss: 0.415 | Acc: 89.059% (1514/1700)\n",
      "Test Epoch: 61 | Loss: 0.415 | Acc: 89.222% (1606/1800)\n",
      "Test Epoch: 61 | Loss: 0.424 | Acc: 88.947% (1690/1900)\n",
      "Test Epoch: 61 | Loss: 0.436 | Acc: 88.900% (1778/2000)\n",
      "Test Epoch: 61 | Loss: 0.447 | Acc: 88.762% (1864/2100)\n",
      "Test Epoch: 61 | Loss: 0.440 | Acc: 88.682% (1951/2200)\n",
      "Test Epoch: 61 | Loss: 0.438 | Acc: 88.913% (2045/2300)\n",
      "Test Epoch: 61 | Loss: 0.434 | Acc: 88.917% (2134/2400)\n",
      "Test Epoch: 61 | Loss: 0.448 | Acc: 88.840% (2221/2500)\n",
      "Test Epoch: 61 | Loss: 0.458 | Acc: 88.731% (2307/2600)\n",
      "Test Epoch: 61 | Loss: 0.448 | Acc: 89.000% (2403/2700)\n",
      "Test Epoch: 61 | Loss: 0.447 | Acc: 89.000% (2492/2800)\n",
      "Test Epoch: 61 | Loss: 0.453 | Acc: 89.034% (2582/2900)\n",
      "Test Epoch: 61 | Loss: 0.451 | Acc: 89.033% (2671/3000)\n",
      "Test Epoch: 61 | Loss: 0.447 | Acc: 89.161% (2764/3100)\n",
      "Test Epoch: 61 | Loss: 0.446 | Acc: 89.219% (2855/3200)\n",
      "Test Epoch: 61 | Loss: 0.446 | Acc: 89.152% (2942/3300)\n",
      "Test Epoch: 61 | Loss: 0.443 | Acc: 89.206% (3033/3400)\n",
      "Test Epoch: 61 | Loss: 0.447 | Acc: 89.143% (3120/3500)\n",
      "Test Epoch: 61 | Loss: 0.453 | Acc: 89.139% (3209/3600)\n",
      "Test Epoch: 61 | Loss: 0.460 | Acc: 89.162% (3299/3700)\n",
      "Test Epoch: 61 | Loss: 0.457 | Acc: 89.184% (3389/3800)\n",
      "Test Epoch: 61 | Loss: 0.454 | Acc: 89.282% (3482/3900)\n",
      "Test Epoch: 61 | Loss: 0.453 | Acc: 89.250% (3570/4000)\n",
      "Test Epoch: 61 | Loss: 0.456 | Acc: 89.220% (3658/4100)\n",
      "Test Epoch: 61 | Loss: 0.457 | Acc: 89.214% (3747/4200)\n",
      "Test Epoch: 61 | Loss: 0.449 | Acc: 89.372% (3843/4300)\n",
      "Test Epoch: 61 | Loss: 0.450 | Acc: 89.477% (3937/4400)\n",
      "Test Epoch: 61 | Loss: 0.447 | Acc: 89.533% (4029/4500)\n",
      "Test Epoch: 61 | Loss: 0.444 | Acc: 89.522% (4118/4600)\n",
      "Test Epoch: 61 | Loss: 0.444 | Acc: 89.511% (4207/4700)\n",
      "Test Epoch: 61 | Loss: 0.444 | Acc: 89.500% (4296/4800)\n",
      "Test Epoch: 61 | Loss: 0.441 | Acc: 89.551% (4388/4900)\n",
      "Test Epoch: 61 | Loss: 0.446 | Acc: 89.460% (4473/5000)\n",
      "Test Epoch: 61 | Loss: 0.443 | Acc: 89.549% (4567/5100)\n",
      "Test Epoch: 61 | Loss: 0.445 | Acc: 89.442% (4651/5200)\n",
      "Test Epoch: 61 | Loss: 0.445 | Acc: 89.453% (4741/5300)\n",
      "Test Epoch: 61 | Loss: 0.442 | Acc: 89.500% (4833/5400)\n",
      "Test Epoch: 61 | Loss: 0.444 | Acc: 89.473% (4921/5500)\n",
      "Test Epoch: 61 | Loss: 0.442 | Acc: 89.500% (5012/5600)\n",
      "Test Epoch: 61 | Loss: 0.440 | Acc: 89.526% (5103/5700)\n",
      "Test Epoch: 61 | Loss: 0.438 | Acc: 89.569% (5195/5800)\n",
      "Test Epoch: 61 | Loss: 0.441 | Acc: 89.508% (5281/5900)\n",
      "Test Epoch: 61 | Loss: 0.437 | Acc: 89.533% (5372/6000)\n",
      "Test Epoch: 61 | Loss: 0.435 | Acc: 89.574% (5464/6100)\n",
      "Test Epoch: 61 | Loss: 0.435 | Acc: 89.548% (5552/6200)\n",
      "Test Epoch: 61 | Loss: 0.434 | Acc: 89.603% (5645/6300)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.594% (5734/6400)\n",
      "Test Epoch: 61 | Loss: 0.430 | Acc: 89.508% (5818/6500)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.515% (5908/6600)\n",
      "Test Epoch: 61 | Loss: 0.426 | Acc: 89.582% (6002/6700)\n",
      "Test Epoch: 61 | Loss: 0.427 | Acc: 89.529% (6088/6800)\n",
      "Test Epoch: 61 | Loss: 0.427 | Acc: 89.493% (6175/6900)\n",
      "Test Epoch: 61 | Loss: 0.429 | Acc: 89.457% (6262/7000)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.493% (6354/7100)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.458% (6441/7200)\n",
      "Test Epoch: 61 | Loss: 0.429 | Acc: 89.452% (6530/7300)\n",
      "Test Epoch: 61 | Loss: 0.427 | Acc: 89.514% (6624/7400)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.480% (6711/7500)\n",
      "Test Epoch: 61 | Loss: 0.429 | Acc: 89.461% (6799/7600)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.416% (6885/7700)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.397% (6973/7800)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.405% (7063/7900)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.412% (7153/8000)\n",
      "Test Epoch: 61 | Loss: 0.429 | Acc: 89.469% (7247/8100)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.512% (7340/8200)\n",
      "Test Epoch: 61 | Loss: 0.429 | Acc: 89.518% (7430/8300)\n",
      "Test Epoch: 61 | Loss: 0.428 | Acc: 89.476% (7516/8400)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.388% (7598/8500)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.407% (7689/8600)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.437% (7781/8700)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.455% (7872/8800)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.483% (7964/8900)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.456% (8051/9000)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.451% (8140/9100)\n",
      "Test Epoch: 61 | Loss: 0.430 | Acc: 89.500% (8234/9200)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.484% (8322/9300)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.457% (8409/9400)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.442% (8497/9500)\n",
      "Test Epoch: 61 | Loss: 0.432 | Acc: 89.417% (8584/9600)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.423% (8674/9700)\n",
      "Test Epoch: 61 | Loss: 0.430 | Acc: 89.439% (8765/9800)\n",
      "Test Epoch: 61 | Loss: 0.431 | Acc: 89.434% (8854/9900)\n",
      "Test Epoch: 61 | Loss: 0.430 | Acc: 89.460% (8946/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Train Epoch: 62 | Loss: 0.067 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 62 | Loss: 0.071 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 62 | Loss: 0.050 | Acc: 98.698% (379/384)\n",
      "Train Epoch: 62 | Loss: 0.050 | Acc: 98.633% (505/512)\n",
      "Train Epoch: 62 | Loss: 0.052 | Acc: 98.281% (629/640)\n",
      "Train Epoch: 62 | Loss: 0.054 | Acc: 98.307% (755/768)\n",
      "Train Epoch: 62 | Loss: 0.061 | Acc: 98.103% (879/896)\n",
      "Train Epoch: 62 | Loss: 0.067 | Acc: 97.852% (1002/1024)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.743% (1126/1152)\n",
      "Train Epoch: 62 | Loss: 0.067 | Acc: 97.812% (1252/1280)\n",
      "Train Epoch: 62 | Loss: 0.068 | Acc: 97.727% (1376/1408)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.656% (1500/1536)\n",
      "Train Epoch: 62 | Loss: 0.076 | Acc: 97.476% (1622/1664)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.545% (1748/1792)\n",
      "Train Epoch: 62 | Loss: 0.076 | Acc: 97.604% (1874/1920)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.607% (1999/2048)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.610% (2124/2176)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.439% (2245/2304)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.410% (2369/2432)\n",
      "Train Epoch: 62 | Loss: 0.071 | Acc: 97.461% (2495/2560)\n",
      "Train Epoch: 62 | Loss: 0.071 | Acc: 97.470% (2620/2688)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.408% (2743/2816)\n",
      "Train Epoch: 62 | Loss: 0.071 | Acc: 97.486% (2870/2944)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.559% (2997/3072)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.562% (3122/3200)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.566% (3247/3328)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.569% (3372/3456)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.573% (3497/3584)\n",
      "Train Epoch: 62 | Loss: 0.070 | Acc: 97.548% (3621/3712)\n",
      "Train Epoch: 62 | Loss: 0.070 | Acc: 97.552% (3746/3840)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.581% (3872/3968)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.583% (3997/4096)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.562% (4121/4224)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.564% (4246/4352)\n",
      "Train Epoch: 62 | Loss: 0.068 | Acc: 97.612% (4373/4480)\n",
      "Train Epoch: 62 | Loss: 0.068 | Acc: 97.591% (4497/4608)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.572% (4621/4736)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.595% (4747/4864)\n",
      "Train Epoch: 62 | Loss: 0.068 | Acc: 97.576% (4871/4992)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.578% (4996/5120)\n",
      "Train Epoch: 62 | Loss: 0.068 | Acc: 97.580% (5121/5248)\n",
      "Train Epoch: 62 | Loss: 0.069 | Acc: 97.526% (5243/5376)\n",
      "Train Epoch: 62 | Loss: 0.070 | Acc: 97.438% (5363/5504)\n",
      "Train Epoch: 62 | Loss: 0.070 | Acc: 97.425% (5487/5632)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.378% (5609/5760)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.351% (5732/5888)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.324% (5855/6016)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.314% (5979/6144)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.305% (6103/6272)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.344% (6230/6400)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.304% (6352/6528)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.311% (6477/6656)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.347% (6604/6784)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.338% (6728/6912)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.315% (6851/7040)\n",
      "Train Epoch: 62 | Loss: 0.076 | Acc: 97.252% (6971/7168)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.286% (7098/7296)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.306% (7224/7424)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.325% (7350/7552)\n",
      "Train Epoch: 62 | Loss: 0.076 | Acc: 97.292% (7472/7680)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.285% (7596/7808)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.303% (7722/7936)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.346% (7850/8064)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.363% (7976/8192)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.368% (8101/8320)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.372% (8226/8448)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.353% (8349/8576)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.381% (8476/8704)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.362% (8599/8832)\n",
      "Train Epoch: 62 | Loss: 0.075 | Acc: 97.344% (8722/8960)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.381% (8850/9088)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.396% (8976/9216)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.399% (9101/9344)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.424% (9228/9472)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.417% (9352/9600)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.430% (9478/9728)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.403% (9600/9856)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.396% (9724/9984)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.389% (9848/10112)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.422% (9976/10240)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.434% (10102/10368)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.447% (10228/10496)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.459% (10354/10624)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.470% (10480/10752)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.463% (10604/10880)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.456% (10728/11008)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.468% (10854/11136)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.470% (10979/11264)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.481% (11105/11392)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.491% (11231/11520)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.467% (11353/11648)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.461% (11477/11776)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.455% (11601/11904)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.457% (11726/12032)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (11853/12160)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (11978/12288)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.487% (12104/12416)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (12229/12544)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.514% (12357/12672)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.516% (12482/12800)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.509% (12606/12928)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.518% (12732/13056)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.512% (12856/13184)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.514% (12981/13312)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.500% (13104/13440)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.487% (13227/13568)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.488% (13352/13696)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (13476/13824)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (13600/13952)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.464% (13723/14080)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.473% (13849/14208)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.468% (13973/14336)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (14100/14464)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.478% (14224/14592)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.480% (14349/14720)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.501% (14477/14848)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (14599/14976)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (14723/15104)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.499% (14851/15232)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.500% (14976/15360)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.495% (15100/15488)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.509% (15227/15616)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.510% (15352/15744)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.518% (15478/15872)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.525% (15604/16000)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.526% (15729/16128)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.509% (15851/16256)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.510% (15976/16384)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.517% (16102/16512)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.512% (16226/16640)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (16347/16768)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.479% (16470/16896)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.486% (16596/17024)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.499% (16723/17152)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.506% (16849/17280)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.513% (16975/17408)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.491% (17096/17536)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.509% (17224/17664)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.510% (17349/17792)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.528% (17477/17920)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.512% (17599/18048)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.519% (17725/18176)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.525% (17851/18304)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.537% (17978/18432)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.543% (18104/18560)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.549% (18230/18688)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.561% (18357/18816)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.572% (18484/18944)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.578% (18610/19072)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.583% (18736/19200)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.589% (18862/19328)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.595% (18988/19456)\n",
      "Train Epoch: 62 | Loss: 0.071 | Acc: 97.600% (19114/19584)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.595% (19238/19712)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.591% (19362/19840)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.596% (19488/19968)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.597% (19613/20096)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.582% (19735/20224)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.592% (19862/20352)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.598% (19988/20480)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.593% (20112/20608)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.584% (20235/20736)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.575% (20358/20864)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.575% (20483/20992)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.580% (20609/21120)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.586% (20735/21248)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.572% (20857/21376)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.582% (20984/21504)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.568% (21106/21632)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.574% (21232/21760)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.569% (21356/21888)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.570% (21481/22016)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.570% (21606/22144)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.562% (21729/22272)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.549% (21851/22400)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.550% (21976/22528)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.524% (22095/22656)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.520% (22219/22784)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.525% (22345/22912)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.539% (22473/23040)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.535% (22597/23168)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.532% (22721/23296)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.541% (22848/23424)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.529% (22970/23552)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.525% (23094/23680)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.526% (23219/23808)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.527% (23344/23936)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.515% (23466/24064)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.512% (23590/24192)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.516% (23716/24320)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.517% (23841/24448)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.522% (23967/24576)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.523% (24092/24704)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.523% (24217/24832)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.516% (24340/24960)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.517% (24465/25088)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.525% (24592/25216)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.530% (24718/25344)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.527% (24842/25472)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.535% (24969/25600)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.528% (25092/25728)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.529% (25217/25856)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.510% (25337/25984)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.515% (25463/26112)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.500% (25584/26240)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.505% (25710/26368)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.505% (25835/26496)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.510% (25961/26624)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.496% (26082/26752)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.496% (26207/26880)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.497% (26332/27008)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.498% (26457/27136)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.499% (26582/27264)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.485% (26703/27392)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.485% (26828/27520)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (26952/27648)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.487% (27078/27776)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (27202/27904)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.492% (27329/28032)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.496% (27455/28160)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.494% (27579/28288)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.491% (27703/28416)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.488% (27827/28544)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (27952/28672)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.500% (28080/28800)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.501% (28205/28928)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.501% (28330/29056)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.505% (28456/29184)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.496% (28578/29312)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.500% (28704/29440)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.497% (28828/29568)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.498% (28953/29696)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.499% (29078/29824)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.496% (29202/29952)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.490% (29325/30080)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.497% (29452/30208)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.495% (29576/30336)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.486% (29698/30464)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.480% (29821/30592)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (29947/30720)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.491% (30074/30848)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.495% (30200/30976)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.502% (30327/31104)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.503% (30452/31232)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.503% (30577/31360)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.510% (30704/31488)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.504% (30827/31616)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.499% (30950/31744)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.499% (31075/31872)\n",
      "Train Epoch: 62 | Loss: 0.072 | Acc: 97.503% (31201/32000)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.498% (31324/32128)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.495% (31448/32256)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.499% (31574/32384)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.499% (31699/32512)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.491% (31821/32640)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.491% (31946/32768)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (32070/32896)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (32193/33024)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.478% (32316/33152)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.479% (32441/33280)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.480% (32566/33408)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (32692/33536)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (32817/33664)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.479% (32940/33792)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.482% (33066/33920)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.474% (33188/34048)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.469% (33311/34176)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.473% (33437/34304)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.476% (33563/34432)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.474% (33687/34560)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.472% (33811/34688)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (33937/34816)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.476% (34062/34944)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.471% (34185/35072)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (34312/35200)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (34436/35328)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.467% (34558/35456)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.460% (34680/35584)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.463% (34806/35712)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.461% (34930/35840)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.462% (35055/35968)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.462% (35180/36096)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.469% (35307/36224)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (35434/36352)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.473% (35558/36480)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.479% (35685/36608)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (35809/36736)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.466% (35930/36864)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.464% (36054/36992)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.460% (36177/37120)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.458% (36301/37248)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.464% (36428/37376)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.464% (36553/37504)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.468% (36679/37632)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.471% (36805/37760)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.474% (36931/37888)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.477% (37057/38016)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.478% (37182/38144)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.481% (37308/38272)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.482% (37433/38400)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.482% (37558/38528)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.488% (37685/38656)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (37810/38784)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.487% (37934/38912)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.485% (38058/39040)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.488% (38184/39168)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.476% (38304/39296)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.479% (38430/39424)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.469% (38551/39552)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.465% (38674/39680)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.455% (38795/39808)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.458% (38921/39936)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.462% (39047/40064)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.457% (39170/40192)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.460% (39296/40320)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.458% (39420/40448)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.457% (39544/40576)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.450% (39666/40704)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.446% (39789/40832)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.441% (39912/40960)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.442% (40037/41088)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.445% (40163/41216)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.448% (40289/41344)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.451% (40415/41472)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.454% (40541/41600)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.455% (40666/41728)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.463% (40794/41856)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.468% (40921/41984)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.469% (41046/42112)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.464% (41169/42240)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.470% (41296/42368)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.459% (41416/42496)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.447% (41536/42624)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.450% (41662/42752)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.453% (41788/42880)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.456% (41914/43008)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.450% (42036/43136)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.455% (42163/43264)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.458% (42289/43392)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.454% (42412/43520)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.457% (42538/43648)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.455% (42662/43776)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.456% (42787/43904)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.454% (42911/44032)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.457% (43037/44160)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.462% (43164/44288)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.465% (43290/44416)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.461% (43413/44544)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.468% (43541/44672)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.471% (43667/44800)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.476% (43794/44928)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.470% (43916/45056)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (44043/45184)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.471% (44166/45312)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.474% (44292/45440)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.470% (44415/45568)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.468% (44539/45696)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.471% (44665/45824)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.469% (44789/45952)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.472% (44915/46080)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.466% (45037/46208)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.471% (45164/46336)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.469% (45288/46464)\n",
      "Train Epoch: 62 | Loss: 0.074 | Acc: 97.470% (45413/46592)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.474% (45540/46720)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.475% (45665/46848)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.480% (45792/46976)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.480% (45917/47104)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.478% (46041/47232)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (46168/47360)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (46293/47488)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.486% (46419/47616)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.485% (46543/47744)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (46670/47872)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.492% (46796/48000)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.494% (46922/48128)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.493% (47046/48256)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.483% (47166/48384)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.485% (47292/48512)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.488% (47418/48640)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.486% (47542/48768)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (47666/48896)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.487% (47792/49024)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.481% (47914/49152)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (48040/49280)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.484% (48165/49408)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (48292/49536)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.489% (48417/49664)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.482% (48538/49792)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.482% (48663/49920)\n",
      "Train Epoch: 62 | Loss: 0.073 | Acc: 97.478% (48739/50000)\n",
      "Test Epoch: 62 | Loss: 0.239 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 62 | Loss: 0.255 | Acc: 92.500% (185/200)\n",
      "Test Epoch: 62 | Loss: 0.249 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 62 | Loss: 0.310 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 62 | Loss: 0.299 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 62 | Loss: 0.312 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 62 | Loss: 0.352 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 62 | Loss: 0.364 | Acc: 89.556% (806/900)\n",
      "Test Epoch: 62 | Loss: 0.365 | Acc: 89.700% (897/1000)\n",
      "Test Epoch: 62 | Loss: 0.396 | Acc: 89.545% (985/1100)\n",
      "Test Epoch: 62 | Loss: 0.409 | Acc: 89.417% (1073/1200)\n",
      "Test Epoch: 62 | Loss: 0.403 | Acc: 89.615% (1165/1300)\n",
      "Test Epoch: 62 | Loss: 0.403 | Acc: 89.714% (1256/1400)\n",
      "Test Epoch: 62 | Loss: 0.398 | Acc: 89.667% (1345/1500)\n",
      "Test Epoch: 62 | Loss: 0.391 | Acc: 89.875% (1438/1600)\n",
      "Test Epoch: 62 | Loss: 0.388 | Acc: 89.941% (1529/1700)\n",
      "Test Epoch: 62 | Loss: 0.389 | Acc: 89.889% (1618/1800)\n",
      "Test Epoch: 62 | Loss: 0.390 | Acc: 89.632% (1703/1900)\n",
      "Test Epoch: 62 | Loss: 0.417 | Acc: 89.350% (1787/2000)\n",
      "Test Epoch: 62 | Loss: 0.427 | Acc: 89.143% (1872/2100)\n",
      "Test Epoch: 62 | Loss: 0.417 | Acc: 89.136% (1961/2200)\n",
      "Test Epoch: 62 | Loss: 0.413 | Acc: 89.174% (2051/2300)\n",
      "Test Epoch: 62 | Loss: 0.411 | Acc: 89.250% (2142/2400)\n",
      "Test Epoch: 62 | Loss: 0.429 | Acc: 89.160% (2229/2500)\n",
      "Test Epoch: 62 | Loss: 0.434 | Acc: 89.154% (2318/2600)\n",
      "Test Epoch: 62 | Loss: 0.424 | Acc: 89.407% (2414/2700)\n",
      "Test Epoch: 62 | Loss: 0.422 | Acc: 89.357% (2502/2800)\n",
      "Test Epoch: 62 | Loss: 0.428 | Acc: 89.310% (2590/2900)\n",
      "Test Epoch: 62 | Loss: 0.427 | Acc: 89.233% (2677/3000)\n",
      "Test Epoch: 62 | Loss: 0.426 | Acc: 89.258% (2767/3100)\n",
      "Test Epoch: 62 | Loss: 0.429 | Acc: 89.312% (2858/3200)\n",
      "Test Epoch: 62 | Loss: 0.426 | Acc: 89.273% (2946/3300)\n",
      "Test Epoch: 62 | Loss: 0.423 | Acc: 89.294% (3036/3400)\n",
      "Test Epoch: 62 | Loss: 0.434 | Acc: 89.114% (3119/3500)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.111% (3208/3600)\n",
      "Test Epoch: 62 | Loss: 0.443 | Acc: 89.108% (3297/3700)\n",
      "Test Epoch: 62 | Loss: 0.444 | Acc: 89.105% (3386/3800)\n",
      "Test Epoch: 62 | Loss: 0.443 | Acc: 89.103% (3475/3900)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 89.050% (3562/4000)\n",
      "Test Epoch: 62 | Loss: 0.455 | Acc: 88.902% (3645/4100)\n",
      "Test Epoch: 62 | Loss: 0.453 | Acc: 88.881% (3733/4200)\n",
      "Test Epoch: 62 | Loss: 0.446 | Acc: 89.023% (3828/4300)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 89.068% (3919/4400)\n",
      "Test Epoch: 62 | Loss: 0.445 | Acc: 89.156% (4012/4500)\n",
      "Test Epoch: 62 | Loss: 0.447 | Acc: 89.109% (4099/4600)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 89.085% (4187/4700)\n",
      "Test Epoch: 62 | Loss: 0.450 | Acc: 89.083% (4276/4800)\n",
      "Test Epoch: 62 | Loss: 0.446 | Acc: 89.122% (4367/4900)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 89.040% (4452/5000)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 89.039% (4541/5100)\n",
      "Test Epoch: 62 | Loss: 0.447 | Acc: 89.000% (4628/5200)\n",
      "Test Epoch: 62 | Loss: 0.447 | Acc: 89.000% (4717/5300)\n",
      "Test Epoch: 62 | Loss: 0.444 | Acc: 89.056% (4809/5400)\n",
      "Test Epoch: 62 | Loss: 0.442 | Acc: 89.036% (4897/5500)\n",
      "Test Epoch: 62 | Loss: 0.448 | Acc: 88.982% (4983/5600)\n",
      "Test Epoch: 62 | Loss: 0.445 | Acc: 88.982% (5072/5700)\n",
      "Test Epoch: 62 | Loss: 0.442 | Acc: 89.086% (5167/5800)\n",
      "Test Epoch: 62 | Loss: 0.444 | Acc: 89.085% (5256/5900)\n",
      "Test Epoch: 62 | Loss: 0.444 | Acc: 89.100% (5346/6000)\n",
      "Test Epoch: 62 | Loss: 0.443 | Acc: 89.066% (5433/6100)\n",
      "Test Epoch: 62 | Loss: 0.442 | Acc: 89.081% (5523/6200)\n",
      "Test Epoch: 62 | Loss: 0.441 | Acc: 89.111% (5614/6300)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.172% (5707/6400)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.200% (5798/6500)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.227% (5889/6600)\n",
      "Test Epoch: 62 | Loss: 0.433 | Acc: 89.313% (5984/6700)\n",
      "Test Epoch: 62 | Loss: 0.436 | Acc: 89.279% (6071/6800)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.348% (6165/6900)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.314% (6252/7000)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.310% (6341/7100)\n",
      "Test Epoch: 62 | Loss: 0.437 | Acc: 89.292% (6429/7200)\n",
      "Test Epoch: 62 | Loss: 0.436 | Acc: 89.342% (6522/7300)\n",
      "Test Epoch: 62 | Loss: 0.436 | Acc: 89.365% (6613/7400)\n",
      "Test Epoch: 62 | Loss: 0.437 | Acc: 89.333% (6700/7500)\n",
      "Test Epoch: 62 | Loss: 0.437 | Acc: 89.329% (6789/7600)\n",
      "Test Epoch: 62 | Loss: 0.436 | Acc: 89.325% (6878/7700)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.321% (6967/7800)\n",
      "Test Epoch: 62 | Loss: 0.434 | Acc: 89.316% (7056/7900)\n",
      "Test Epoch: 62 | Loss: 0.434 | Acc: 89.287% (7143/8000)\n",
      "Test Epoch: 62 | Loss: 0.430 | Acc: 89.358% (7238/8100)\n",
      "Test Epoch: 62 | Loss: 0.429 | Acc: 89.366% (7328/8200)\n",
      "Test Epoch: 62 | Loss: 0.430 | Acc: 89.325% (7414/8300)\n",
      "Test Epoch: 62 | Loss: 0.432 | Acc: 89.286% (7500/8400)\n",
      "Test Epoch: 62 | Loss: 0.434 | Acc: 89.235% (7585/8500)\n",
      "Test Epoch: 62 | Loss: 0.436 | Acc: 89.198% (7671/8600)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.218% (7762/8700)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.216% (7851/8800)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.157% (7935/8900)\n",
      "Test Epoch: 62 | Loss: 0.441 | Acc: 89.111% (8020/9000)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.165% (8114/9100)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.217% (8208/9200)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.172% (8293/9300)\n",
      "Test Epoch: 62 | Loss: 0.439 | Acc: 89.202% (8385/9400)\n",
      "Test Epoch: 62 | Loss: 0.438 | Acc: 89.211% (8475/9500)\n",
      "Test Epoch: 62 | Loss: 0.437 | Acc: 89.250% (8568/9600)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.299% (8662/9700)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.327% (8754/9800)\n",
      "Test Epoch: 62 | Loss: 0.435 | Acc: 89.333% (8844/9900)\n",
      "Test Epoch: 62 | Loss: 0.433 | Acc: 89.370% (8937/10000)\n",
      "\n",
      "Epoch: 63\n",
      "Train Epoch: 63 | Loss: 0.013 | Acc: 100.000% (128/128)\n",
      "Train Epoch: 63 | Loss: 0.045 | Acc: 99.219% (254/256)\n",
      "Train Epoch: 63 | Loss: 0.044 | Acc: 98.958% (380/384)\n",
      "Train Epoch: 63 | Loss: 0.056 | Acc: 98.828% (506/512)\n",
      "Train Epoch: 63 | Loss: 0.057 | Acc: 98.906% (633/640)\n",
      "Train Epoch: 63 | Loss: 0.059 | Acc: 98.828% (759/768)\n",
      "Train Epoch: 63 | Loss: 0.058 | Acc: 98.661% (884/896)\n",
      "Train Epoch: 63 | Loss: 0.057 | Acc: 98.535% (1009/1024)\n",
      "Train Epoch: 63 | Loss: 0.053 | Acc: 98.698% (1137/1152)\n",
      "Train Epoch: 63 | Loss: 0.050 | Acc: 98.750% (1264/1280)\n",
      "Train Epoch: 63 | Loss: 0.052 | Acc: 98.651% (1389/1408)\n",
      "Train Epoch: 63 | Loss: 0.057 | Acc: 98.438% (1512/1536)\n",
      "Train Epoch: 63 | Loss: 0.059 | Acc: 98.438% (1638/1664)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 98.270% (1761/1792)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 98.177% (1885/1920)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 98.242% (2012/2048)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 98.162% (2136/2176)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 98.047% (2259/2304)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.944% (2382/2432)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.930% (2507/2560)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.991% (2634/2688)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.940% (2758/2816)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.894% (2882/2944)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.949% (3009/3072)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.969% (3135/3200)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.927% (3259/3328)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.946% (3385/3456)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.991% (3512/3584)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.872% (3633/3712)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.891% (3759/3840)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.933% (3886/3968)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.876% (4009/4096)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.940% (4137/4224)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.932% (4262/4352)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.924% (4387/4480)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.917% (4512/4608)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.973% (4640/4736)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.965% (4765/4864)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.977% (4891/4992)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.949% (5015/5120)\n",
      "Train Epoch: 63 | Loss: 0.060 | Acc: 97.980% (5142/5248)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.879% (5262/5376)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.802% (5383/5504)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.852% (5511/5632)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.865% (5637/5760)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.860% (5762/5888)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.889% (5889/6016)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.900% (6015/6144)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.911% (6141/6272)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.922% (6267/6400)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.901% (6391/6528)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.912% (6517/6656)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.892% (6641/6784)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.917% (6768/6912)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.926% (6894/7040)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.921% (7019/7168)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.944% (7146/7296)\n",
      "Train Epoch: 63 | Loss: 0.060 | Acc: 97.966% (7273/7424)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.934% (7396/7552)\n",
      "Train Epoch: 63 | Loss: 0.061 | Acc: 97.891% (7518/7680)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.874% (7642/7808)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.858% (7766/7936)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.867% (7892/8064)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.852% (8016/8192)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.861% (8142/8320)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.869% (8268/8448)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.843% (8391/8576)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.863% (8518/8704)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.871% (8644/8832)\n",
      "Train Epoch: 63 | Loss: 0.062 | Acc: 97.868% (8769/8960)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.854% (8893/9088)\n",
      "Train Epoch: 63 | Loss: 0.063 | Acc: 97.841% (9017/9216)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.838% (9142/9344)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.825% (9266/9472)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.802% (9389/9600)\n",
      "Train Epoch: 63 | Loss: 0.064 | Acc: 97.800% (9514/9728)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.748% (9634/9856)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.726% (9757/9984)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.735% (9883/10112)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.734% (10008/10240)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.743% (10134/10368)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.752% (10260/10496)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.741% (10384/10624)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.740% (10509/10752)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.739% (10634/10880)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.747% (10760/11008)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.746% (10885/11136)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.763% (11012/11264)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.762% (11137/11392)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.760% (11262/11520)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.751% (11386/11648)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.758% (11512/11776)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.782% (11640/11904)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.781% (11765/12032)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.788% (11891/12160)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.786% (12016/12288)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.785% (12141/12416)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.776% (12265/12544)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.783% (12391/12672)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.789% (12517/12800)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.788% (12642/12928)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.794% (12768/13056)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.800% (12894/13184)\n",
      "Train Epoch: 63 | Loss: 0.065 | Acc: 97.799% (13019/13312)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.798% (13144/13440)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.782% (13267/13568)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.802% (13395/13696)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.779% (13517/13824)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.764% (13640/13952)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.770% (13766/14080)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.776% (13892/14208)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.782% (14018/14336)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.767% (14141/14464)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.745% (14263/14592)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.731% (14386/14720)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.744% (14513/14848)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.756% (14640/14976)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.742% (14763/15104)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.742% (14888/15232)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.747% (15014/15360)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.734% (15137/15488)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.746% (15264/15616)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.732% (15387/15744)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.744% (15514/15872)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.725% (15636/16000)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.737% (15763/16128)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.749% (15890/16256)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.748% (16015/16384)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.735% (16138/16512)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.740% (16264/16640)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.758% (16392/16768)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.751% (16516/16896)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.762% (16643/17024)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.750% (16766/17152)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.743% (16890/17280)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.737% (17014/17408)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.747% (17141/17536)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.752% (17267/17664)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.741% (17390/17792)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.757% (17518/17920)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.756% (17643/18048)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.739% (17765/18176)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.733% (17889/18304)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.743% (18016/18432)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.742% (18141/18560)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.758% (18269/18688)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.752% (18393/18816)\n",
      "Train Epoch: 63 | Loss: 0.066 | Acc: 97.741% (18516/18944)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.714% (18636/19072)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.714% (18761/19200)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.713% (18886/19328)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.718% (19012/19456)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (19136/19584)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (19261/19712)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (19386/19840)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.711% (19511/19968)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.711% (19636/20096)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.721% (19763/20224)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.730% (19890/20352)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.744% (20018/20480)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.744% (20143/20608)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.743% (20268/20736)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.747% (20394/20864)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.756% (20521/20992)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.751% (20645/21120)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.760% (20772/21248)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.759% (20897/21376)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.773% (21025/21504)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.781% (21152/21632)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.771% (21275/21760)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.775% (21401/21888)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.770% (21525/22016)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.765% (21649/22144)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.768% (21775/22272)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.772% (21901/22400)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.781% (22028/22528)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.780% (22153/22656)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.779% (22278/22784)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.778% (22403/22912)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.773% (22527/23040)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.777% (22653/23168)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.764% (22775/23296)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.746% (22896/23424)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.741% (23020/23552)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.728% (23142/23680)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.723% (23266/23808)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.706% (23387/23936)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.710% (23513/24064)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.714% (23639/24192)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.718% (23765/24320)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.726% (23892/24448)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.725% (24017/24576)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.725% (24142/24704)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.721% (24266/24832)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.728% (24393/24960)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.732% (24519/25088)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.720% (24641/25216)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.727% (24768/25344)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.735% (24895/25472)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.738% (25021/25600)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.742% (25147/25728)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.730% (25269/25856)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.729% (25394/25984)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.737% (25521/26112)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.732% (25645/26240)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.728% (25769/26368)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.732% (25895/26496)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.720% (26017/26624)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.727% (26144/26752)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.731% (26270/26880)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.730% (26395/27008)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.726% (26519/27136)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.733% (26646/27264)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.718% (26767/27392)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.722% (26893/27520)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.721% (27018/27648)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.732% (27146/27776)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.732% (27271/27904)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.717% (27392/28032)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.720% (27518/28160)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.730% (27646/28288)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.741% (27774/28416)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.737% (27898/28544)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.736% (28023/28672)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.715% (28142/28800)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.715% (28267/28928)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.715% (28392/29056)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.715% (28517/29184)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.714% (28642/29312)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.704% (28764/29440)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.710% (28891/29568)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.720% (29019/29696)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.713% (29142/29824)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.713% (29267/29952)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.709% (29391/30080)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.709% (29516/30208)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (29642/30336)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (29767/30464)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (29892/30592)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.718% (30019/30720)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.711% (30142/30848)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.718% (30269/30976)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.721% (30395/31104)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.723% (30521/31232)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.720% (30645/31360)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.726% (30772/31488)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.726% (30897/31616)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.732% (31024/31744)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.725% (31147/31872)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.725% (31272/32000)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (31393/32128)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.709% (31517/32256)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.709% (31642/32384)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.705% (31766/32512)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.702% (31890/32640)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.699% (32014/32768)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.705% (32141/32896)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.708% (32267/33024)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.708% (32392/33152)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.707% (32517/33280)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.716% (32645/33408)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.722% (32772/33536)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.722% (32897/33664)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.712% (33019/33792)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.718% (33146/33920)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.721% (33272/34048)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.724% (33398/34176)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.729% (33525/34304)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.732% (33651/34432)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.734% (33777/34560)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.737% (33903/34688)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.737% (34028/34816)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.734% (34152/34944)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.730% (34276/35072)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.736% (34403/35200)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.733% (34527/35328)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.735% (34653/35456)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.727% (34775/35584)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.726% (34900/35712)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.734% (35028/35840)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.729% (35151/35968)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.731% (35277/36096)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.731% (35402/36224)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.720% (35523/36352)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.719% (35648/36480)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.714% (35771/36608)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.708% (35894/36736)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.713% (36021/36864)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.713% (36146/36992)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.716% (36272/37120)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.715% (36397/37248)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.710% (36520/37376)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.707% (36644/37504)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.709% (36770/37632)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.712% (36896/37760)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.712% (37021/37888)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.709% (37145/38016)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.706% (37269/38144)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.706% (37394/38272)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.688% (37512/38400)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.687% (37637/38528)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.695% (37765/38656)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.698% (37891/38784)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.700% (38017/38912)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.697% (38141/39040)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.695% (38265/39168)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.692% (38389/39296)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.694% (38515/39424)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.694% (38640/39552)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.699% (38767/39680)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.701% (38893/39808)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.701% (39018/39936)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.701% (39143/40064)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.701% (39268/40192)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.691% (39389/40320)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.683% (39511/40448)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.686% (39637/40576)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.688% (39763/40704)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.688% (39888/40832)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.693% (40015/40960)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.690% (40139/41088)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.693% (40265/41216)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.695% (40391/41344)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.700% (40518/41472)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.697% (40642/41600)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.692% (40765/41728)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.692% (40890/41856)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.682% (41011/41984)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.675% (41133/42112)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.680% (41260/42240)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.687% (41388/42368)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.692% (41515/42496)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.698% (41643/42624)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.703% (41770/42752)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.698% (41893/42880)\n",
      "Train Epoch: 63 | Loss: 0.067 | Acc: 97.696% (42017/43008)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.693% (42141/43136)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.693% (42266/43264)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.686% (42388/43392)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.686% (42513/43520)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.684% (42637/43648)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.686% (42763/43776)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.686% (42888/43904)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.684% (43012/44032)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.688% (43139/44160)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.681% (43261/44288)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.686% (43388/44416)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.681% (43511/44544)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.681% (43636/44672)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.674% (43758/44800)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.672% (43882/44928)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.667% (44005/45056)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.667% (44130/45184)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.667% (44255/45312)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.665% (44379/45440)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.665% (44504/45568)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.669% (44631/45696)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.665% (44754/45824)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.663% (44878/45952)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.658% (45001/46080)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.658% (45126/46208)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.661% (45252/46336)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.652% (45373/46464)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.654% (45499/46592)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.646% (45620/46720)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.648% (45746/46848)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.648% (45871/46976)\n",
      "Train Epoch: 63 | Loss: 0.068 | Acc: 97.646% (45995/47104)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.644% (46119/47232)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.631% (46238/47360)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.635% (46365/47488)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.639% (46492/47616)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.639% (46617/47744)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.635% (46740/47872)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.629% (46862/48000)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.625% (46985/48128)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.619% (47107/48256)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.619% (47232/48384)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.615% (47355/48512)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.609% (47477/48640)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.613% (47604/48768)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.613% (47729/48896)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.615% (47855/49024)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.607% (47976/49152)\n",
      "Train Epoch: 63 | Loss: 0.069 | Acc: 97.601% (48098/49280)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.596% (48220/49408)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.598% (48346/49536)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.590% (48467/49664)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.580% (48587/49792)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.568% (48706/49920)\n",
      "Train Epoch: 63 | Loss: 0.070 | Acc: 97.568% (48784/50000)\n",
      "Test Epoch: 63 | Loss: 0.304 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 63 | Loss: 0.328 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 63 | Loss: 0.274 | Acc: 92.000% (276/300)\n",
      "Test Epoch: 63 | Loss: 0.281 | Acc: 91.250% (365/400)\n",
      "Test Epoch: 63 | Loss: 0.267 | Acc: 91.600% (458/500)\n",
      "Test Epoch: 63 | Loss: 0.238 | Acc: 92.333% (554/600)\n",
      "Test Epoch: 63 | Loss: 0.253 | Acc: 92.286% (646/700)\n",
      "Test Epoch: 63 | Loss: 0.320 | Acc: 90.875% (727/800)\n",
      "Test Epoch: 63 | Loss: 0.323 | Acc: 90.556% (815/900)\n",
      "Test Epoch: 63 | Loss: 0.341 | Acc: 90.400% (904/1000)\n",
      "Test Epoch: 63 | Loss: 0.361 | Acc: 90.091% (991/1100)\n",
      "Test Epoch: 63 | Loss: 0.371 | Acc: 90.167% (1082/1200)\n",
      "Test Epoch: 63 | Loss: 0.367 | Acc: 90.077% (1171/1300)\n",
      "Test Epoch: 63 | Loss: 0.368 | Acc: 90.000% (1260/1400)\n",
      "Test Epoch: 63 | Loss: 0.369 | Acc: 90.067% (1351/1500)\n",
      "Test Epoch: 63 | Loss: 0.366 | Acc: 90.125% (1442/1600)\n",
      "Test Epoch: 63 | Loss: 0.359 | Acc: 90.294% (1535/1700)\n",
      "Test Epoch: 63 | Loss: 0.358 | Acc: 90.333% (1626/1800)\n",
      "Test Epoch: 63 | Loss: 0.358 | Acc: 90.211% (1714/1900)\n",
      "Test Epoch: 63 | Loss: 0.367 | Acc: 90.000% (1800/2000)\n",
      "Test Epoch: 63 | Loss: 0.374 | Acc: 89.905% (1888/2100)\n",
      "Test Epoch: 63 | Loss: 0.375 | Acc: 89.773% (1975/2200)\n",
      "Test Epoch: 63 | Loss: 0.372 | Acc: 89.913% (2068/2300)\n",
      "Test Epoch: 63 | Loss: 0.368 | Acc: 89.958% (2159/2400)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 89.720% (2243/2500)\n",
      "Test Epoch: 63 | Loss: 0.400 | Acc: 89.654% (2331/2600)\n",
      "Test Epoch: 63 | Loss: 0.391 | Acc: 89.889% (2427/2700)\n",
      "Test Epoch: 63 | Loss: 0.390 | Acc: 89.857% (2516/2800)\n",
      "Test Epoch: 63 | Loss: 0.396 | Acc: 89.862% (2606/2900)\n",
      "Test Epoch: 63 | Loss: 0.395 | Acc: 89.833% (2695/3000)\n",
      "Test Epoch: 63 | Loss: 0.395 | Acc: 89.806% (2784/3100)\n",
      "Test Epoch: 63 | Loss: 0.393 | Acc: 89.906% (2877/3200)\n",
      "Test Epoch: 63 | Loss: 0.396 | Acc: 89.818% (2964/3300)\n",
      "Test Epoch: 63 | Loss: 0.396 | Acc: 89.824% (3054/3400)\n",
      "Test Epoch: 63 | Loss: 0.399 | Acc: 89.743% (3141/3500)\n",
      "Test Epoch: 63 | Loss: 0.401 | Acc: 89.778% (3232/3600)\n",
      "Test Epoch: 63 | Loss: 0.407 | Acc: 89.757% (3321/3700)\n",
      "Test Epoch: 63 | Loss: 0.408 | Acc: 89.789% (3412/3800)\n",
      "Test Epoch: 63 | Loss: 0.405 | Acc: 89.718% (3499/3900)\n",
      "Test Epoch: 63 | Loss: 0.405 | Acc: 89.750% (3590/4000)\n",
      "Test Epoch: 63 | Loss: 0.408 | Acc: 89.683% (3677/4100)\n",
      "Test Epoch: 63 | Loss: 0.411 | Acc: 89.595% (3763/4200)\n",
      "Test Epoch: 63 | Loss: 0.405 | Acc: 89.721% (3858/4300)\n",
      "Test Epoch: 63 | Loss: 0.406 | Acc: 89.818% (3952/4400)\n",
      "Test Epoch: 63 | Loss: 0.401 | Acc: 89.911% (4046/4500)\n",
      "Test Epoch: 63 | Loss: 0.399 | Acc: 89.913% (4136/4600)\n",
      "Test Epoch: 63 | Loss: 0.398 | Acc: 89.894% (4225/4700)\n",
      "Test Epoch: 63 | Loss: 0.398 | Acc: 89.833% (4312/4800)\n",
      "Test Epoch: 63 | Loss: 0.395 | Acc: 89.939% (4407/4900)\n",
      "Test Epoch: 63 | Loss: 0.395 | Acc: 89.920% (4496/5000)\n",
      "Test Epoch: 63 | Loss: 0.390 | Acc: 90.020% (4591/5100)\n",
      "Test Epoch: 63 | Loss: 0.393 | Acc: 89.904% (4675/5200)\n",
      "Test Epoch: 63 | Loss: 0.393 | Acc: 89.830% (4761/5300)\n",
      "Test Epoch: 63 | Loss: 0.392 | Acc: 89.833% (4851/5400)\n",
      "Test Epoch: 63 | Loss: 0.392 | Acc: 89.818% (4940/5500)\n",
      "Test Epoch: 63 | Loss: 0.392 | Acc: 89.893% (5034/5600)\n",
      "Test Epoch: 63 | Loss: 0.390 | Acc: 89.895% (5124/5700)\n",
      "Test Epoch: 63 | Loss: 0.388 | Acc: 89.931% (5216/5800)\n",
      "Test Epoch: 63 | Loss: 0.390 | Acc: 89.864% (5302/5900)\n",
      "Test Epoch: 63 | Loss: 0.388 | Acc: 89.883% (5393/6000)\n",
      "Test Epoch: 63 | Loss: 0.389 | Acc: 89.852% (5481/6100)\n",
      "Test Epoch: 63 | Loss: 0.389 | Acc: 89.919% (5575/6200)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 89.968% (5668/6300)\n",
      "Test Epoch: 63 | Loss: 0.382 | Acc: 90.078% (5765/6400)\n",
      "Test Epoch: 63 | Loss: 0.382 | Acc: 90.092% (5856/6500)\n",
      "Test Epoch: 63 | Loss: 0.381 | Acc: 90.061% (5944/6600)\n",
      "Test Epoch: 63 | Loss: 0.381 | Acc: 90.119% (6038/6700)\n",
      "Test Epoch: 63 | Loss: 0.383 | Acc: 90.074% (6125/6800)\n",
      "Test Epoch: 63 | Loss: 0.380 | Acc: 90.159% (6221/6900)\n",
      "Test Epoch: 63 | Loss: 0.379 | Acc: 90.186% (6313/7000)\n",
      "Test Epoch: 63 | Loss: 0.381 | Acc: 90.183% (6403/7100)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.153% (6491/7200)\n",
      "Test Epoch: 63 | Loss: 0.383 | Acc: 90.205% (6585/7300)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.243% (6678/7400)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.213% (6766/7500)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.184% (6854/7600)\n",
      "Test Epoch: 63 | Loss: 0.388 | Acc: 90.143% (6941/7700)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.167% (7033/7800)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.165% (7123/7900)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.100% (7208/8000)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.148% (7302/8100)\n",
      "Test Epoch: 63 | Loss: 0.383 | Acc: 90.171% (7394/8200)\n",
      "Test Epoch: 63 | Loss: 0.382 | Acc: 90.193% (7486/8300)\n",
      "Test Epoch: 63 | Loss: 0.382 | Acc: 90.179% (7575/8400)\n",
      "Test Epoch: 63 | Loss: 0.385 | Acc: 90.118% (7660/8500)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.047% (7744/8600)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.034% (7833/8700)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.034% (7923/8800)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.011% (8011/8900)\n",
      "Test Epoch: 63 | Loss: 0.388 | Acc: 90.000% (8100/9000)\n",
      "Test Epoch: 63 | Loss: 0.387 | Acc: 90.022% (8192/9100)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.065% (8286/9200)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.054% (8375/9300)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.053% (8465/9400)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.053% (8555/9500)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.062% (8646/9600)\n",
      "Test Epoch: 63 | Loss: 0.384 | Acc: 90.093% (8739/9700)\n",
      "Test Epoch: 63 | Loss: 0.386 | Acc: 90.082% (8828/9800)\n",
      "Test Epoch: 63 | Loss: 0.385 | Acc: 90.111% (8921/9900)\n",
      "Test Epoch: 63 | Loss: 0.383 | Acc: 90.150% (9015/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 64\n",
      "Train Epoch: 64 | Loss: 0.030 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 64 | Loss: 0.051 | Acc: 98.438% (252/256)\n",
      "Train Epoch: 64 | Loss: 0.054 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 64 | Loss: 0.055 | Acc: 98.242% (503/512)\n",
      "Train Epoch: 64 | Loss: 0.054 | Acc: 98.281% (629/640)\n",
      "Train Epoch: 64 | Loss: 0.052 | Acc: 98.307% (755/768)\n",
      "Train Epoch: 64 | Loss: 0.056 | Acc: 98.103% (879/896)\n",
      "Train Epoch: 64 | Loss: 0.056 | Acc: 97.949% (1003/1024)\n",
      "Train Epoch: 64 | Loss: 0.056 | Acc: 97.830% (1127/1152)\n",
      "Train Epoch: 64 | Loss: 0.058 | Acc: 97.812% (1252/1280)\n",
      "Train Epoch: 64 | Loss: 0.057 | Acc: 97.940% (1379/1408)\n",
      "Train Epoch: 64 | Loss: 0.056 | Acc: 97.982% (1505/1536)\n",
      "Train Epoch: 64 | Loss: 0.056 | Acc: 98.017% (1631/1664)\n",
      "Train Epoch: 64 | Loss: 0.062 | Acc: 97.768% (1752/1792)\n",
      "Train Epoch: 64 | Loss: 0.062 | Acc: 97.812% (1878/1920)\n",
      "Train Epoch: 64 | Loss: 0.061 | Acc: 97.852% (2004/2048)\n",
      "Train Epoch: 64 | Loss: 0.061 | Acc: 97.886% (2130/2176)\n",
      "Train Epoch: 64 | Loss: 0.059 | Acc: 97.917% (2256/2304)\n",
      "Train Epoch: 64 | Loss: 0.058 | Acc: 98.026% (2384/2432)\n",
      "Train Epoch: 64 | Loss: 0.059 | Acc: 98.047% (2510/2560)\n",
      "Train Epoch: 64 | Loss: 0.060 | Acc: 97.954% (2633/2688)\n",
      "Train Epoch: 64 | Loss: 0.062 | Acc: 97.905% (2757/2816)\n",
      "Train Epoch: 64 | Loss: 0.064 | Acc: 97.792% (2879/2944)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.721% (3002/3072)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.688% (3126/3200)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.626% (3249/3328)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.598% (3373/3456)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.600% (3498/3584)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.602% (3623/3712)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.604% (3748/3840)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.581% (3872/3968)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.607% (3998/4096)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.633% (4124/4224)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.656% (4250/4352)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.679% (4376/4480)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.656% (4500/4608)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.635% (4624/4736)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.636% (4749/4864)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.636% (4874/4992)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.676% (5001/5120)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.675% (5126/5248)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.712% (5253/5376)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.674% (5376/5504)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.674% (5501/5632)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.639% (5624/5760)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.622% (5748/5888)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.606% (5872/6016)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.607% (5997/6144)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.640% (6124/6272)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.625% (6248/6400)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.610% (6372/6528)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.626% (6498/6656)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.627% (6623/6784)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.584% (6745/6912)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.599% (6871/7040)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.642% (6999/7168)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.643% (7124/7296)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.643% (7249/7424)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.617% (7372/7552)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.604% (7496/7680)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.631% (7623/7808)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.631% (7748/7936)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.619% (7872/8064)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.620% (7997/8192)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.632% (8123/8320)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.609% (8246/8448)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.575% (8368/8576)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.564% (8492/8704)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.600% (8620/8832)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.612% (8746/8960)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.590% (8869/9088)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.569% (8992/9216)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.581% (9118/9344)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.593% (9244/9472)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.604% (9370/9600)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.605% (9495/9728)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.595% (9619/9856)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.596% (9744/9984)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.627% (9872/10112)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.607% (9995/10240)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.618% (10121/10368)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.618% (10246/10496)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.600% (10369/10624)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.619% (10496/10752)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.619% (10621/10880)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.611% (10745/11008)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.602% (10869/11136)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.594% (10993/11264)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.604% (11119/11392)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.595% (11243/11520)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.605% (11369/11648)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.631% (11497/11776)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.639% (11623/11904)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.640% (11748/12032)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.656% (11875/12160)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.656% (12000/12288)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.648% (12124/12416)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.648% (12249/12544)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.633% (12372/12672)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.617% (12495/12800)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.602% (12618/12928)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.595% (12742/13056)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.611% (12869/13184)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.634% (12997/13312)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.641% (13123/13440)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.649% (13249/13568)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.664% (13376/13696)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.685% (13504/13824)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.692% (13630/13952)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (13757/14080)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.698% (13881/14208)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.698% (14006/14336)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.705% (14132/14464)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.704% (14257/14592)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.697% (14381/14720)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.690% (14505/14848)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.683% (14629/14976)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.676% (14753/15104)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.689% (14880/15232)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.689% (15005/15360)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.701% (15132/15488)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.714% (15259/15616)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.720% (15385/15744)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.707% (15508/15872)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.706% (15633/16000)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.706% (15758/16128)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.724% (15886/16256)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.711% (16009/16384)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.723% (16136/16512)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.734% (16263/16640)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.740% (16389/16768)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.739% (16514/16896)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.756% (16642/17024)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.750% (16766/17152)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.743% (16890/17280)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.737% (17014/17408)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.730% (17138/17536)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.741% (17265/17664)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.741% (17390/17792)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.746% (17516/17920)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.734% (17639/18048)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.750% (17767/18176)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.744% (17891/18304)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.754% (18018/18432)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.764% (18145/18560)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.753% (18268/18688)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.752% (18393/18816)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.746% (18517/18944)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.756% (18644/19072)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.755% (18769/19200)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.760% (18895/19328)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.764% (19021/19456)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.763% (19146/19584)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.778% (19274/19712)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.777% (19399/19840)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.781% (19525/19968)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.786% (19651/20096)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.760% (19771/20224)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.769% (19898/20352)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.764% (20022/20480)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.763% (20147/20608)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.762% (20272/20736)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.776% (20400/20864)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.775% (20525/20992)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.765% (20648/21120)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.774% (20775/21248)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.787% (20903/21376)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.777% (21026/21504)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.776% (21151/21632)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.780% (21277/21760)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.784% (21403/21888)\n",
      "Train Epoch: 64 | Loss: 0.064 | Acc: 97.793% (21530/22016)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.792% (21655/22144)\n",
      "Train Epoch: 64 | Loss: 0.064 | Acc: 97.804% (21783/22272)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.795% (21906/22400)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.794% (22031/22528)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.775% (22152/22656)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.770% (22276/22784)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.778% (22403/22912)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.782% (22529/23040)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.773% (22652/23168)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.764% (22775/23296)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.759% (22899/23424)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.754% (23023/23552)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.758% (23149/23680)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.765% (23276/23808)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.752% (23398/23936)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.752% (23523/24064)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.755% (23649/24192)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.751% (23773/24320)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.742% (23896/24448)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.729% (24018/24576)\n",
      "Train Epoch: 64 | Loss: 0.065 | Acc: 97.733% (24144/24704)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.721% (24266/24832)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.728% (24393/24960)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.720% (24516/25088)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.720% (24641/25216)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.711% (24764/25344)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.715% (24890/25472)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.711% (25014/25600)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.707% (25138/25728)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.703% (25262/25856)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.699% (25386/25984)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.698% (25511/26112)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.710% (25639/26240)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.702% (25762/26368)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.698% (25886/26496)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.694% (26010/26624)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.694% (26135/26752)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.682% (26257/26880)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (26380/27008)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.682% (26507/27136)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.682% (26632/27264)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.685% (26758/27392)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.685% (26883/27520)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.696% (27011/27648)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.696% (27136/27776)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.699% (27262/27904)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.703% (27388/28032)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.710% (27515/28160)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.709% (27640/28288)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (27764/28416)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.712% (27891/28544)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.719% (28018/28672)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.719% (28143/28800)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.718% (28268/28928)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.715% (28392/29056)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.715% (28517/29184)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.721% (28644/29312)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.721% (28769/29440)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.727% (28896/29568)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.724% (29020/29696)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.723% (29145/29824)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.720% (29269/29952)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.723% (29395/30080)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.716% (29518/30208)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.722% (29645/30336)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.715% (29768/30464)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.722% (29895/30592)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.728% (30022/30720)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.721% (30145/30848)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.721% (30270/30976)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.727% (30397/31104)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.727% (30522/31232)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.726% (30647/31360)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.732% (30774/31488)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.735% (30900/31616)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.729% (31023/31744)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.722% (31146/31872)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.728% (31273/32000)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.725% (31397/32128)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.728% (31523/32256)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.718% (31645/32384)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.712% (31768/32512)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.705% (31891/32640)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.705% (32016/32768)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.702% (32140/32896)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.708% (32267/33024)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.714% (32394/33152)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.716% (32520/33280)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.716% (32645/33408)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.716% (32770/33536)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.716% (32895/33664)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.718% (33021/33792)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.712% (33144/33920)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (33267/34048)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (33392/34176)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.709% (33518/34304)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (33642/34432)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.697% (33764/34560)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.705% (33892/34688)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.694% (34013/34816)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.696% (34139/34944)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.693% (34263/35072)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.702% (34391/35200)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.710% (34519/35328)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.710% (34644/35456)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.707% (34768/35584)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.707% (34893/35712)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.706% (35018/35840)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.709% (35144/35968)\n",
      "Train Epoch: 64 | Loss: 0.066 | Acc: 97.698% (35265/36096)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.689% (35387/36224)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.687% (35511/36352)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.678% (35633/36480)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (35757/36608)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.678% (35883/36736)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.681% (36009/36864)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.681% (36134/36992)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.680% (36259/37120)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.686% (36386/37248)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.691% (36513/37376)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.686% (36636/37504)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.688% (36762/37632)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.680% (36884/37760)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.683% (37010/37888)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.685% (37136/38016)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.682% (37260/38144)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.680% (37384/38272)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.677% (37508/38400)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.682% (37635/38528)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.680% (37759/38656)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.674% (37882/38784)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.672% (38006/38912)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.672% (38131/39040)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.677% (38258/39168)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.679% (38384/39296)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.684% (38511/39424)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.687% (38637/39552)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.679% (38759/39680)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.679% (38884/39808)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.681% (39010/39936)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.676% (39133/40064)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.684% (39261/40192)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.686% (39387/40320)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.691% (39514/40448)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.691% (39639/40576)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.693% (39765/40704)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.691% (39889/40832)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.683% (40011/40960)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.688% (40138/41088)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.690% (40264/41216)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.680% (40385/41344)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.676% (40508/41472)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.671% (40631/41600)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.671% (40756/41728)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (40883/41856)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (41008/41984)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.673% (41132/42112)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (41258/42240)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.675% (41383/42368)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.673% (41507/42496)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.670% (41631/42624)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.668% (41755/42752)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.668% (41880/42880)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.670% (42006/43008)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.670% (42131/43136)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.668% (42255/43264)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.665% (42379/43392)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.659% (42501/43520)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.661% (42627/43648)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.661% (42752/43776)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.663% (42878/43904)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.663% (43003/44032)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.663% (43128/44160)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.665% (43254/44288)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.663% (43378/44416)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.663% (43503/44544)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.663% (43628/44672)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.654% (43749/44800)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.658% (43876/44928)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.654% (43999/45056)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.656% (44125/45184)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.656% (44250/45312)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.658% (44376/45440)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.650% (44497/45568)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.650% (44622/45696)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.652% (44748/45824)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.652% (44873/45952)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.654% (44999/46080)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.654% (45124/46208)\n",
      "Train Epoch: 64 | Loss: 0.067 | Acc: 97.656% (45250/46336)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.648% (45371/46464)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.643% (45494/46592)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.639% (45617/46720)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.641% (45743/46848)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.633% (45864/46976)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.631% (45988/47104)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.624% (46110/47232)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.629% (46237/47360)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.631% (46363/47488)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.627% (46486/47616)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.616% (46606/47744)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.617% (46731/47872)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.610% (46853/48000)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.602% (46974/48128)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.604% (47100/48256)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.600% (47223/48384)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.592% (47344/48512)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.593% (47469/48640)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.591% (47593/48768)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.593% (47719/48896)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.593% (47844/49024)\n",
      "Train Epoch: 64 | Loss: 0.069 | Acc: 97.589% (47967/49152)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.593% (48094/49280)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.589% (48217/49408)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.588% (48341/49536)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.592% (48468/49664)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.594% (48594/49792)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.592% (48718/49920)\n",
      "Train Epoch: 64 | Loss: 0.068 | Acc: 97.594% (48797/50000)\n",
      "Test Epoch: 64 | Loss: 0.539 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 64 | Loss: 0.357 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 64 | Loss: 0.339 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 64 | Loss: 0.359 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 64 | Loss: 0.356 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 64 | Loss: 0.312 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 64 | Loss: 0.332 | Acc: 91.000% (637/700)\n",
      "Test Epoch: 64 | Loss: 0.350 | Acc: 89.750% (718/800)\n",
      "Test Epoch: 64 | Loss: 0.361 | Acc: 89.556% (806/900)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 89.500% (895/1000)\n",
      "Test Epoch: 64 | Loss: 0.398 | Acc: 89.455% (984/1100)\n",
      "Test Epoch: 64 | Loss: 0.431 | Acc: 88.833% (1066/1200)\n",
      "Test Epoch: 64 | Loss: 0.436 | Acc: 88.769% (1154/1300)\n",
      "Test Epoch: 64 | Loss: 0.441 | Acc: 88.857% (1244/1400)\n",
      "Test Epoch: 64 | Loss: 0.433 | Acc: 88.933% (1334/1500)\n",
      "Test Epoch: 64 | Loss: 0.428 | Acc: 89.062% (1425/1600)\n",
      "Test Epoch: 64 | Loss: 0.423 | Acc: 89.294% (1518/1700)\n",
      "Test Epoch: 64 | Loss: 0.425 | Acc: 89.056% (1603/1800)\n",
      "Test Epoch: 64 | Loss: 0.428 | Acc: 88.947% (1690/1900)\n",
      "Test Epoch: 64 | Loss: 0.453 | Acc: 88.700% (1774/2000)\n",
      "Test Epoch: 64 | Loss: 0.451 | Acc: 88.619% (1861/2100)\n",
      "Test Epoch: 64 | Loss: 0.452 | Acc: 88.727% (1952/2200)\n",
      "Test Epoch: 64 | Loss: 0.443 | Acc: 88.913% (2045/2300)\n",
      "Test Epoch: 64 | Loss: 0.440 | Acc: 89.000% (2136/2400)\n",
      "Test Epoch: 64 | Loss: 0.450 | Acc: 88.720% (2218/2500)\n",
      "Test Epoch: 64 | Loss: 0.458 | Acc: 88.692% (2306/2600)\n",
      "Test Epoch: 64 | Loss: 0.447 | Acc: 88.926% (2401/2700)\n",
      "Test Epoch: 64 | Loss: 0.445 | Acc: 89.000% (2492/2800)\n",
      "Test Epoch: 64 | Loss: 0.445 | Acc: 89.069% (2583/2900)\n",
      "Test Epoch: 64 | Loss: 0.448 | Acc: 88.967% (2669/3000)\n",
      "Test Epoch: 64 | Loss: 0.446 | Acc: 88.935% (2757/3100)\n",
      "Test Epoch: 64 | Loss: 0.445 | Acc: 88.875% (2844/3200)\n",
      "Test Epoch: 64 | Loss: 0.449 | Acc: 88.848% (2932/3300)\n",
      "Test Epoch: 64 | Loss: 0.449 | Acc: 88.853% (3021/3400)\n",
      "Test Epoch: 64 | Loss: 0.455 | Acc: 88.629% (3102/3500)\n",
      "Test Epoch: 64 | Loss: 0.457 | Acc: 88.667% (3192/3600)\n",
      "Test Epoch: 64 | Loss: 0.459 | Acc: 88.649% (3280/3700)\n",
      "Test Epoch: 64 | Loss: 0.458 | Acc: 88.684% (3370/3800)\n",
      "Test Epoch: 64 | Loss: 0.455 | Acc: 88.718% (3460/3900)\n",
      "Test Epoch: 64 | Loss: 0.457 | Acc: 88.675% (3547/4000)\n",
      "Test Epoch: 64 | Loss: 0.463 | Acc: 88.537% (3630/4100)\n",
      "Test Epoch: 64 | Loss: 0.462 | Acc: 88.500% (3717/4200)\n",
      "Test Epoch: 64 | Loss: 0.452 | Acc: 88.744% (3816/4300)\n",
      "Test Epoch: 64 | Loss: 0.456 | Acc: 88.818% (3908/4400)\n",
      "Test Epoch: 64 | Loss: 0.450 | Acc: 88.933% (4002/4500)\n",
      "Test Epoch: 64 | Loss: 0.448 | Acc: 88.957% (4092/4600)\n",
      "Test Epoch: 64 | Loss: 0.448 | Acc: 88.936% (4180/4700)\n",
      "Test Epoch: 64 | Loss: 0.449 | Acc: 88.938% (4269/4800)\n",
      "Test Epoch: 64 | Loss: 0.447 | Acc: 88.980% (4360/4900)\n",
      "Test Epoch: 64 | Loss: 0.454 | Acc: 88.820% (4441/5000)\n",
      "Test Epoch: 64 | Loss: 0.452 | Acc: 88.863% (4532/5100)\n",
      "Test Epoch: 64 | Loss: 0.454 | Acc: 88.827% (4619/5200)\n",
      "Test Epoch: 64 | Loss: 0.454 | Acc: 88.774% (4705/5300)\n",
      "Test Epoch: 64 | Loss: 0.452 | Acc: 88.796% (4795/5400)\n",
      "Test Epoch: 64 | Loss: 0.450 | Acc: 88.782% (4883/5500)\n",
      "Test Epoch: 64 | Loss: 0.452 | Acc: 88.786% (4972/5600)\n",
      "Test Epoch: 64 | Loss: 0.450 | Acc: 88.860% (5065/5700)\n",
      "Test Epoch: 64 | Loss: 0.447 | Acc: 88.966% (5160/5800)\n",
      "Test Epoch: 64 | Loss: 0.448 | Acc: 88.932% (5247/5900)\n",
      "Test Epoch: 64 | Loss: 0.446 | Acc: 88.967% (5338/6000)\n",
      "Test Epoch: 64 | Loss: 0.446 | Acc: 88.984% (5428/6100)\n",
      "Test Epoch: 64 | Loss: 0.446 | Acc: 89.032% (5520/6200)\n",
      "Test Epoch: 64 | Loss: 0.443 | Acc: 89.079% (5612/6300)\n",
      "Test Epoch: 64 | Loss: 0.440 | Acc: 89.125% (5704/6400)\n",
      "Test Epoch: 64 | Loss: 0.441 | Acc: 89.092% (5791/6500)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.121% (5882/6600)\n",
      "Test Epoch: 64 | Loss: 0.436 | Acc: 89.164% (5974/6700)\n",
      "Test Epoch: 64 | Loss: 0.435 | Acc: 89.176% (6064/6800)\n",
      "Test Epoch: 64 | Loss: 0.432 | Acc: 89.174% (6153/6900)\n",
      "Test Epoch: 64 | Loss: 0.432 | Acc: 89.157% (6241/7000)\n",
      "Test Epoch: 64 | Loss: 0.435 | Acc: 89.155% (6330/7100)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.139% (6418/7200)\n",
      "Test Epoch: 64 | Loss: 0.435 | Acc: 89.205% (6512/7300)\n",
      "Test Epoch: 64 | Loss: 0.434 | Acc: 89.257% (6605/7400)\n",
      "Test Epoch: 64 | Loss: 0.434 | Acc: 89.240% (6693/7500)\n",
      "Test Epoch: 64 | Loss: 0.436 | Acc: 89.211% (6780/7600)\n",
      "Test Epoch: 64 | Loss: 0.436 | Acc: 89.169% (6866/7700)\n",
      "Test Epoch: 64 | Loss: 0.434 | Acc: 89.218% (6959/7800)\n",
      "Test Epoch: 64 | Loss: 0.433 | Acc: 89.228% (7049/7900)\n",
      "Test Epoch: 64 | Loss: 0.433 | Acc: 89.225% (7138/8000)\n",
      "Test Epoch: 64 | Loss: 0.429 | Acc: 89.284% (7232/8100)\n",
      "Test Epoch: 64 | Loss: 0.428 | Acc: 89.293% (7322/8200)\n",
      "Test Epoch: 64 | Loss: 0.427 | Acc: 89.277% (7410/8300)\n",
      "Test Epoch: 64 | Loss: 0.429 | Acc: 89.214% (7494/8400)\n",
      "Test Epoch: 64 | Loss: 0.433 | Acc: 89.188% (7581/8500)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.140% (7666/8600)\n",
      "Test Epoch: 64 | Loss: 0.435 | Acc: 89.172% (7758/8700)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.136% (7844/8800)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.112% (7931/8900)\n",
      "Test Epoch: 64 | Loss: 0.440 | Acc: 89.089% (8018/9000)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.099% (8108/9100)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.109% (8198/9200)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.075% (8284/9300)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.074% (8373/9400)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.063% (8461/9500)\n",
      "Test Epoch: 64 | Loss: 0.438 | Acc: 89.062% (8550/9600)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.093% (8642/9700)\n",
      "Test Epoch: 64 | Loss: 0.437 | Acc: 89.102% (8732/9800)\n",
      "Test Epoch: 64 | Loss: 0.436 | Acc: 89.111% (8822/9900)\n",
      "Test Epoch: 64 | Loss: 0.433 | Acc: 89.160% (8916/10000)\n",
      "\n",
      "Epoch: 65\n",
      "Train Epoch: 65 | Loss: 0.056 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 97.656% (250/256)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.396% (374/384)\n",
      "Train Epoch: 65 | Loss: 0.057 | Acc: 97.656% (500/512)\n",
      "Train Epoch: 65 | Loss: 0.055 | Acc: 97.812% (626/640)\n",
      "Train Epoch: 65 | Loss: 0.052 | Acc: 97.917% (752/768)\n",
      "Train Epoch: 65 | Loss: 0.057 | Acc: 97.991% (878/896)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.047% (1004/1024)\n",
      "Train Epoch: 65 | Loss: 0.058 | Acc: 98.090% (1130/1152)\n",
      "Train Epoch: 65 | Loss: 0.057 | Acc: 98.125% (1256/1280)\n",
      "Train Epoch: 65 | Loss: 0.058 | Acc: 98.082% (1381/1408)\n",
      "Train Epoch: 65 | Loss: 0.057 | Acc: 98.112% (1507/1536)\n",
      "Train Epoch: 65 | Loss: 0.059 | Acc: 98.017% (1631/1664)\n",
      "Train Epoch: 65 | Loss: 0.057 | Acc: 98.158% (1759/1792)\n",
      "Train Epoch: 65 | Loss: 0.056 | Acc: 98.177% (1885/1920)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 98.096% (2009/2048)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.116% (2135/2176)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.220% (2263/2304)\n",
      "Train Epoch: 65 | Loss: 0.059 | Acc: 98.191% (2388/2432)\n",
      "Train Epoch: 65 | Loss: 0.059 | Acc: 98.125% (2512/2560)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.065% (2636/2688)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.011% (2760/2816)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.928% (2883/2944)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.982% (3010/3072)\n",
      "Train Epoch: 65 | Loss: 0.065 | Acc: 97.844% (3131/3200)\n",
      "Train Epoch: 65 | Loss: 0.065 | Acc: 97.867% (3257/3328)\n",
      "Train Epoch: 65 | Loss: 0.066 | Acc: 97.830% (3381/3456)\n",
      "Train Epoch: 65 | Loss: 0.066 | Acc: 97.824% (3506/3584)\n",
      "Train Epoch: 65 | Loss: 0.065 | Acc: 97.872% (3633/3712)\n",
      "Train Epoch: 65 | Loss: 0.066 | Acc: 97.839% (3757/3840)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.883% (3884/3968)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.852% (4008/4096)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.869% (4134/4224)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.886% (4260/4352)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.902% (4386/4480)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.873% (4510/4608)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.910% (4637/4736)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.924% (4763/4864)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.877% (4886/4992)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.910% (5013/5120)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.961% (5141/5248)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.972% (5267/5376)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.001% (5394/5504)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.976% (5518/5632)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.003% (5645/5760)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.013% (5771/5888)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.055% (5899/6016)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.031% (6023/6144)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.007% (6147/6272)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.031% (6274/6400)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.039% (6400/6528)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.032% (6525/6656)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.995% (6648/6784)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.018% (6775/6912)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.997% (6899/7040)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.005% (7025/7168)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.026% (7152/7296)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.047% (7279/7424)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.067% (7406/7552)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.047% (7530/7680)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.015% (7653/7808)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.009% (7778/7936)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.979% (7901/8064)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.998% (8028/8192)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.017% (8155/8320)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.023% (8281/8448)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.018% (8406/8576)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.024% (8532/8704)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.996% (8655/8832)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.991% (8780/8960)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.986% (8905/9088)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.014% (9033/9216)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.988% (9156/9344)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.984% (9281/9472)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.010% (9409/9600)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.026% (9536/9728)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.022% (9661/9856)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.047% (9789/9984)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.062% (9916/10112)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.076% (10043/10240)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.090% (10170/10368)\n",
      "Train Epoch: 65 | Loss: 0.060 | Acc: 98.075% (10294/10496)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.052% (10417/10624)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.038% (10541/10752)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 98.006% (10663/10880)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 98.001% (10788/11008)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.989% (10912/11136)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 98.002% (11039/11264)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.999% (11164/11392)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.977% (11287/11520)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.965% (11411/11648)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.962% (11536/11776)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.975% (11663/11904)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.972% (11788/12032)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.944% (11910/12160)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (12034/12288)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (12160/12416)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.919% (12283/12544)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (12411/12672)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.922% (12534/12800)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.904% (12657/12928)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.924% (12785/13056)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.907% (12908/13184)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.912% (13034/13312)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.894% (13157/13440)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.899% (13283/13568)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.919% (13411/13696)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (13538/13824)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.929% (13663/13952)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (13790/14080)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.952% (13917/14208)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.949% (14042/14336)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (14166/14464)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.944% (14292/14592)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.942% (14417/14720)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.932% (14541/14848)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.943% (14668/14976)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.954% (14795/15104)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.952% (14920/15232)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.949% (15045/15360)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.953% (15171/15488)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.951% (15296/15616)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.948% (15421/15744)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.952% (15547/15872)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (15670/16000)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.935% (15795/16128)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (15920/16256)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.949% (16048/16384)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.953% (16174/16512)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.951% (16299/16640)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.948% (16424/16768)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.958% (16551/16896)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.968% (16678/17024)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.965% (16803/17152)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.963% (16928/17280)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.955% (17052/17408)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.941% (17175/17536)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.945% (17301/17664)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.943% (17426/17792)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.935% (17550/17920)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (17675/18048)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (17800/18176)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (17927/18304)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.944% (18053/18432)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.936% (18177/18560)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.935% (18302/18688)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.927% (18426/18816)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (18552/18944)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.939% (18679/19072)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.927% (18802/19200)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.936% (18929/19328)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.939% (19055/19456)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.932% (19179/19584)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (19306/19712)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (19430/19840)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.937% (19556/19968)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.945% (19683/20096)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.943% (19808/20224)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.941% (19933/20352)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.944% (20059/20480)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.952% (20186/20608)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.946% (20310/20736)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.944% (20435/20864)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.942% (20560/20992)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.945% (20686/21120)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.934% (20809/21248)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.923% (20932/21376)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.917% (21056/21504)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.906% (21179/21632)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.909% (21305/21760)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.921% (21433/21888)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (21561/22016)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.936% (21687/22144)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.926% (21810/22272)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.929% (21936/22400)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.927% (22061/22528)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.934% (22188/22656)\n",
      "Train Epoch: 65 | Loss: 0.061 | Acc: 97.942% (22315/22784)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.922% (22436/22912)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.899% (22556/23040)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.902% (22682/23168)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.888% (22804/23296)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.891% (22930/23424)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.894% (23056/23552)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.897% (23182/23680)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.896% (23307/23808)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.894% (23432/23936)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.881% (23554/24064)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.888% (23681/24192)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.895% (23808/24320)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.906% (23936/24448)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.900% (24060/24576)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.891% (24183/24704)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.890% (24308/24832)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.897% (24435/24960)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.899% (24561/25088)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.906% (24688/25216)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.905% (24813/25344)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.896% (24936/25472)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.895% (25061/25600)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.897% (25187/25728)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.892% (25311/25856)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.891% (25436/25984)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.894% (25562/26112)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.904% (25690/26240)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.899% (25814/26368)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.898% (25939/26496)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.897% (26064/26624)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.888% (26187/26752)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.887% (26312/26880)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.882% (26436/27008)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.877% (26560/27136)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.880% (26686/27264)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.886% (26813/27392)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.892% (26940/27520)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.895% (27066/27648)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.901% (27193/27776)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.889% (27315/27904)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.895% (27442/28032)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.898% (27568/28160)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.907% (27696/28288)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.910% (27822/28416)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.912% (27948/28544)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.918% (28075/28672)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.913% (28199/28800)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.912% (28324/28928)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.914% (28450/29056)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.913% (28575/29184)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.912% (28700/29312)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.908% (28824/29440)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.913% (28951/29568)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.916% (29077/29696)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.918% (29203/29824)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.923% (29330/29952)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.926% (29456/30080)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.928% (29582/30208)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.927% (29707/30336)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.929% (29833/30464)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.921% (29956/30592)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.920% (30081/30720)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.922% (30207/30848)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.924% (30333/30976)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.926% (30459/31104)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.935% (30587/31232)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.937% (30713/31360)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.942% (30840/31488)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.944% (30966/31616)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.946% (31092/31744)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.948% (31218/31872)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.947% (31343/32000)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.949% (31469/32128)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.945% (31593/32256)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.943% (31718/32384)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.948% (31845/32512)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.953% (31972/32640)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.949% (32096/32768)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.951% (32222/32896)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.950% (32347/33024)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.958% (32475/33152)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.954% (32599/33280)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.950% (32723/33408)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.940% (32845/33536)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (32970/33664)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.934% (33094/33792)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.939% (33221/33920)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (33346/34048)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (33469/34176)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.927% (33593/34304)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.926% (33718/34432)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (33845/34560)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.921% (33967/34688)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.920% (34092/34816)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.928% (34220/34944)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.933% (34347/35072)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.935% (34473/35200)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (34597/35328)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (34725/35456)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.946% (34853/35584)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.942% (34977/35712)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.938% (35101/35840)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.931% (35224/35968)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.936% (35351/36096)\n",
      "Train Epoch: 65 | Loss: 0.062 | Acc: 97.932% (35475/36224)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.926% (35598/36352)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.925% (35723/36480)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.924% (35848/36608)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.926% (35974/36736)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.930% (36101/36864)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.927% (36225/36992)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.920% (36348/37120)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.922% (36474/37248)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.924% (36600/37376)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.915% (36722/37504)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.914% (36847/37632)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.916% (36973/37760)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.912% (37097/37888)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.906% (37220/38016)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.908% (37346/38144)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.910% (37472/38272)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.909% (37597/38400)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.905% (37721/38528)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.905% (37846/38656)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.896% (37968/38784)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.900% (38095/38912)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.902% (38221/39040)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.891% (38342/39168)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.890% (38467/39296)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.890% (38592/39424)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.889% (38717/39552)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.886% (38841/39680)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.890% (38968/39808)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.887% (39092/39936)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.888% (39218/40064)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.885% (39342/40192)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.892% (39470/40320)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.891% (39595/40448)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.890% (39720/40576)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (39847/40704)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.901% (39975/40832)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.898% (40099/40960)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (40223/41088)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.894% (40348/41216)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.896% (40474/41344)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (40600/41472)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (40725/41600)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.901% (40852/41728)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (40975/41856)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (41101/41984)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.898% (41227/42112)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.900% (41353/42240)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.899% (41478/42368)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.906% (41606/42496)\n",
      "Train Epoch: 65 | Loss: 0.063 | Acc: 97.903% (41730/42624)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (41853/42752)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.896% (41978/42880)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.896% (42103/43008)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (42229/43136)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.899% (42355/43264)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.898% (42480/43392)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.893% (42603/43520)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (42729/43648)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.892% (42853/43776)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (42980/43904)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.883% (43100/44032)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.880% (43224/44160)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.880% (43349/44288)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.884% (43476/44416)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.881% (43600/44544)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.878% (43724/44672)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.873% (43847/44800)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.870% (43971/44928)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.869% (44096/45056)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.869% (44221/45184)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.866% (44345/45312)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.863% (44469/45440)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.865% (44595/45568)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.866% (44721/45696)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.866% (44846/45824)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.854% (44966/45952)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.860% (45094/46080)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.864% (45221/46208)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.866% (45347/46336)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.871% (45475/46464)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.873% (45601/46592)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.879% (45729/46720)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.874% (45852/46848)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.878% (45979/46976)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.881% (46106/47104)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.881% (46231/47232)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.886% (46359/47360)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.888% (46485/47488)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.891% (46612/47616)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.891% (46737/47744)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.890% (46862/47872)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.883% (46984/48000)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.889% (47112/48128)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.882% (47234/48256)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.877% (47357/48384)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.879% (47483/48512)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.880% (47609/48640)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.884% (47736/48768)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.883% (47861/48896)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.887% (47988/49024)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.886% (48113/49152)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.892% (48241/49280)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.895% (48368/49408)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.894% (48493/49536)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.898% (48620/49664)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.899% (48746/49792)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.897% (48870/49920)\n",
      "Train Epoch: 65 | Loss: 0.064 | Acc: 97.896% (48948/50000)\n",
      "Test Epoch: 65 | Loss: 0.510 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 65 | Loss: 0.405 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 65 | Loss: 0.337 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 65 | Loss: 0.358 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 65 | Loss: 0.375 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 65 | Loss: 0.333 | Acc: 89.833% (539/600)\n",
      "Test Epoch: 65 | Loss: 0.330 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 65 | Loss: 0.365 | Acc: 89.375% (715/800)\n",
      "Test Epoch: 65 | Loss: 0.369 | Acc: 89.111% (802/900)\n",
      "Test Epoch: 65 | Loss: 0.373 | Acc: 89.200% (892/1000)\n",
      "Test Epoch: 65 | Loss: 0.383 | Acc: 88.727% (976/1100)\n",
      "Test Epoch: 65 | Loss: 0.397 | Acc: 88.583% (1063/1200)\n",
      "Test Epoch: 65 | Loss: 0.396 | Acc: 88.615% (1152/1300)\n",
      "Test Epoch: 65 | Loss: 0.397 | Acc: 88.857% (1244/1400)\n",
      "Test Epoch: 65 | Loss: 0.400 | Acc: 88.800% (1332/1500)\n",
      "Test Epoch: 65 | Loss: 0.386 | Acc: 89.188% (1427/1600)\n",
      "Test Epoch: 65 | Loss: 0.383 | Acc: 89.412% (1520/1700)\n",
      "Test Epoch: 65 | Loss: 0.388 | Acc: 89.222% (1606/1800)\n",
      "Test Epoch: 65 | Loss: 0.391 | Acc: 89.211% (1695/1900)\n",
      "Test Epoch: 65 | Loss: 0.404 | Acc: 89.100% (1782/2000)\n",
      "Test Epoch: 65 | Loss: 0.408 | Acc: 88.952% (1868/2100)\n",
      "Test Epoch: 65 | Loss: 0.408 | Acc: 89.000% (1958/2200)\n",
      "Test Epoch: 65 | Loss: 0.403 | Acc: 89.087% (2049/2300)\n",
      "Test Epoch: 65 | Loss: 0.403 | Acc: 89.125% (2139/2400)\n",
      "Test Epoch: 65 | Loss: 0.408 | Acc: 89.120% (2228/2500)\n",
      "Test Epoch: 65 | Loss: 0.420 | Acc: 89.000% (2314/2600)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.111% (2406/2700)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.214% (2498/2800)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.310% (2590/2900)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.333% (2680/3000)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.323% (2769/3100)\n",
      "Test Epoch: 65 | Loss: 0.406 | Acc: 89.469% (2863/3200)\n",
      "Test Epoch: 65 | Loss: 0.409 | Acc: 89.424% (2951/3300)\n",
      "Test Epoch: 65 | Loss: 0.409 | Acc: 89.588% (3046/3400)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.486% (3132/3500)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.556% (3224/3600)\n",
      "Test Epoch: 65 | Loss: 0.423 | Acc: 89.514% (3312/3700)\n",
      "Test Epoch: 65 | Loss: 0.426 | Acc: 89.526% (3402/3800)\n",
      "Test Epoch: 65 | Loss: 0.424 | Acc: 89.487% (3490/3900)\n",
      "Test Epoch: 65 | Loss: 0.423 | Acc: 89.525% (3581/4000)\n",
      "Test Epoch: 65 | Loss: 0.424 | Acc: 89.463% (3668/4100)\n",
      "Test Epoch: 65 | Loss: 0.425 | Acc: 89.452% (3757/4200)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.558% (3851/4300)\n",
      "Test Epoch: 65 | Loss: 0.420 | Acc: 89.659% (3945/4400)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.778% (4040/4500)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.761% (4129/4600)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.745% (4218/4700)\n",
      "Test Epoch: 65 | Loss: 0.418 | Acc: 89.688% (4305/4800)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.755% (4398/4900)\n",
      "Test Epoch: 65 | Loss: 0.418 | Acc: 89.660% (4483/5000)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.725% (4576/5100)\n",
      "Test Epoch: 65 | Loss: 0.417 | Acc: 89.654% (4662/5200)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.566% (4747/5300)\n",
      "Test Epoch: 65 | Loss: 0.417 | Acc: 89.574% (4837/5400)\n",
      "Test Epoch: 65 | Loss: 0.417 | Acc: 89.545% (4925/5500)\n",
      "Test Epoch: 65 | Loss: 0.420 | Acc: 89.536% (5014/5600)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.509% (5102/5700)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.517% (5192/5800)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.475% (5279/5900)\n",
      "Test Epoch: 65 | Loss: 0.417 | Acc: 89.500% (5370/6000)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.525% (5461/6100)\n",
      "Test Epoch: 65 | Loss: 0.419 | Acc: 89.484% (5548/6200)\n",
      "Test Epoch: 65 | Loss: 0.418 | Acc: 89.508% (5639/6300)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.625% (5736/6400)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.585% (5823/6500)\n",
      "Test Epoch: 65 | Loss: 0.409 | Acc: 89.652% (5917/6600)\n",
      "Test Epoch: 65 | Loss: 0.407 | Acc: 89.716% (6011/6700)\n",
      "Test Epoch: 65 | Loss: 0.406 | Acc: 89.750% (6103/6800)\n",
      "Test Epoch: 65 | Loss: 0.405 | Acc: 89.768% (6194/6900)\n",
      "Test Epoch: 65 | Loss: 0.407 | Acc: 89.700% (6279/7000)\n",
      "Test Epoch: 65 | Loss: 0.412 | Acc: 89.676% (6367/7100)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.639% (6454/7200)\n",
      "Test Epoch: 65 | Loss: 0.412 | Acc: 89.685% (6547/7300)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.689% (6637/7400)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.680% (6726/7500)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.684% (6816/7600)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.701% (6907/7700)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.718% (6998/7800)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.709% (7087/7900)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.638% (7171/8000)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.679% (7264/8100)\n",
      "Test Epoch: 65 | Loss: 0.410 | Acc: 89.707% (7356/8200)\n",
      "Test Epoch: 65 | Loss: 0.410 | Acc: 89.735% (7448/8300)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.726% (7537/8400)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.706% (7625/8500)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.651% (7710/8600)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.644% (7799/8700)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.670% (7891/8800)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.663% (7980/8900)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.667% (8070/9000)\n",
      "Test Epoch: 65 | Loss: 0.416 | Acc: 89.659% (8159/9100)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.674% (8250/9200)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.656% (8338/9300)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.670% (8429/9400)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.695% (8521/9500)\n",
      "Test Epoch: 65 | Loss: 0.415 | Acc: 89.688% (8610/9600)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.742% (8705/9700)\n",
      "Test Epoch: 65 | Loss: 0.414 | Acc: 89.724% (8793/9800)\n",
      "Test Epoch: 65 | Loss: 0.413 | Acc: 89.747% (8885/9900)\n",
      "Test Epoch: 65 | Loss: 0.411 | Acc: 89.780% (8978/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Train Epoch: 66 | Loss: 0.077 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 66 | Loss: 0.074 | Acc: 97.396% (374/384)\n",
      "Train Epoch: 66 | Loss: 0.067 | Acc: 97.461% (499/512)\n",
      "Train Epoch: 66 | Loss: 0.071 | Acc: 97.500% (624/640)\n",
      "Train Epoch: 66 | Loss: 0.067 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 66 | Loss: 0.064 | Acc: 97.768% (876/896)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.949% (1003/1024)\n",
      "Train Epoch: 66 | Loss: 0.056 | Acc: 98.090% (1130/1152)\n",
      "Train Epoch: 66 | Loss: 0.055 | Acc: 98.125% (1256/1280)\n",
      "Train Epoch: 66 | Loss: 0.056 | Acc: 98.082% (1381/1408)\n",
      "Train Epoch: 66 | Loss: 0.054 | Acc: 98.112% (1507/1536)\n",
      "Train Epoch: 66 | Loss: 0.056 | Acc: 98.017% (1631/1664)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.879% (1754/1792)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.865% (1879/1920)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.900% (2005/2048)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.932% (2131/2176)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.917% (2256/2304)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.903% (2381/2432)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.930% (2507/2560)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.954% (2633/2688)\n",
      "Train Epoch: 66 | Loss: 0.056 | Acc: 98.047% (2761/2816)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.996% (2885/2944)\n",
      "Train Epoch: 66 | Loss: 0.057 | Acc: 98.079% (3013/3072)\n",
      "Train Epoch: 66 | Loss: 0.056 | Acc: 98.125% (3140/3200)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 97.987% (3261/3328)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.032% (3388/3456)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.075% (3515/3584)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 98.006% (3638/3712)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.047% (3765/3840)\n",
      "Train Epoch: 66 | Loss: 0.057 | Acc: 98.085% (3892/3968)\n",
      "Train Epoch: 66 | Loss: 0.057 | Acc: 98.120% (4019/4096)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.059% (4142/4224)\n",
      "Train Epoch: 66 | Loss: 0.057 | Acc: 98.093% (4269/4352)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.013% (4391/4480)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.003% (4516/4608)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.015% (4642/4736)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.985% (4766/4864)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.017% (4893/4992)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.027% (5019/5120)\n",
      "Train Epoch: 66 | Loss: 0.058 | Acc: 98.018% (5144/5248)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.991% (5268/5376)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.947% (5391/5504)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.994% (5519/5632)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.969% (5643/5760)\n",
      "Train Epoch: 66 | Loss: 0.059 | Acc: 97.911% (5765/5888)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.889% (5889/6016)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.868% (6013/6144)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.848% (6137/6272)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.891% (6265/6400)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.886% (6390/6528)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.912% (6517/6656)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.907% (6642/6784)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.902% (6767/6912)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.912% (6893/7040)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.879% (7016/7168)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.862% (7140/7296)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.845% (7264/7424)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.828% (7388/7552)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.799% (7511/7680)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.772% (7634/7808)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.757% (7758/7936)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.768% (7884/8064)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.742% (8007/8192)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.740% (8132/8320)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.715% (8255/8448)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.726% (8381/8576)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.714% (8505/8704)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.724% (8631/8832)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.723% (8756/8960)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.744% (8883/9088)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.754% (9009/9216)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.753% (9134/9344)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.762% (9260/9472)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.760% (9385/9600)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.749% (9509/9728)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.737% (9633/9856)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.736% (9758/9984)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.755% (9885/10112)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.764% (10011/10240)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.772% (10137/10368)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.761% (10261/10496)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.760% (10386/10624)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.777% (10513/10752)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.776% (10638/10880)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.793% (10765/11008)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.809% (10892/11136)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.825% (11019/11264)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.832% (11145/11392)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.830% (11270/11520)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.845% (11397/11648)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.843% (11522/11776)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.849% (11648/11904)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.847% (11773/12032)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.837% (11897/12160)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.843% (12023/12288)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.858% (12150/12416)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.879% (12278/12544)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.885% (12404/12672)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.883% (12529/12800)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.888% (12655/12928)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.871% (12778/13056)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.831% (12898/13184)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.837% (13024/13312)\n",
      "Train Epoch: 66 | Loss: 0.060 | Acc: 97.842% (13150/13440)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.833% (13274/13568)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.831% (13399/13696)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.830% (13524/13824)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.792% (13644/13952)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.798% (13770/14080)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.811% (13897/14208)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.803% (14021/14336)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.815% (14148/14464)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.834% (14276/14592)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.819% (14399/14720)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.838% (14527/14848)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.850% (14654/14976)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.855% (14780/15104)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.853% (14905/15232)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.845% (15029/15360)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.850% (15155/15488)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.861% (15282/15616)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.860% (15407/15744)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.864% (15533/15872)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.862% (15658/16000)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.855% (15782/16128)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.853% (15907/16256)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.845% (16031/16384)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.850% (16157/16512)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.849% (16282/16640)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.859% (16409/16768)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.857% (16534/16896)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.862% (16660/17024)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.854% (16784/17152)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.853% (16909/17280)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.857% (17035/17408)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.867% (17162/17536)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.866% (17287/17664)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.864% (17412/17792)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.879% (17540/17920)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.861% (17662/18048)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.849% (17785/18176)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.853% (17911/18304)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.846% (18035/18432)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.839% (18159/18560)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.844% (18285/18688)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.848% (18411/18816)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.852% (18537/18944)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.845% (18661/19072)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.849% (18787/19200)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.848% (18912/19328)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.857% (19039/19456)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.835% (19160/19584)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.839% (19286/19712)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (19410/19840)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.827% (19534/19968)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.825% (19659/20096)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.824% (19784/20224)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.799% (19904/20352)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.812% (20032/20480)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.816% (20158/20608)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.825% (20285/20736)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.834% (20412/20864)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.842% (20539/20992)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.836% (20663/21120)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.830% (20787/21248)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.829% (20912/21376)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.828% (21037/21504)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (21163/21632)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.840% (21290/21760)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.844% (21416/21888)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.838% (21540/22016)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.837% (21665/22144)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.849% (21793/22272)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.848% (21918/22400)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (22042/22528)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.850% (22169/22656)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.849% (22294/22784)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.853% (22420/22912)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.865% (22548/23040)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.859% (22672/23168)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.858% (22797/23296)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.853% (22921/23424)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.860% (23048/23552)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.863% (23174/23680)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.866% (23300/23808)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.869% (23426/23936)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.868% (23551/24064)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.851% (23672/24192)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.862% (23800/24320)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.865% (23926/24448)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.872% (24053/24576)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.875% (24179/24704)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.870% (24303/24832)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.873% (24429/24960)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.879% (24556/25088)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.878% (24681/25216)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.881% (24807/25344)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.884% (24933/25472)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.875% (25056/25600)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.870% (25180/25728)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.865% (25304/25856)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.872% (25431/25984)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.878% (25558/26112)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.885% (25685/26240)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.865% (25805/26368)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.875% (25933/26496)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.878% (26059/26624)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.888% (26187/26752)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.887% (26312/26880)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.893% (26439/27008)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.892% (26564/27136)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.891% (26689/27264)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.875% (26810/27392)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.867% (26933/27520)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.859% (27056/27648)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.865% (27183/27776)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.857% (27306/27904)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.856% (27431/28032)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.848% (27554/28160)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.844% (27678/28288)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (27800/28416)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.824% (27923/28544)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.831% (28050/28672)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (28176/28800)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (28301/28928)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.839% (28428/29056)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.848% (28556/29184)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.847% (28681/29312)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (28805/29440)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.829% (28926/29568)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.831% (29052/29696)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.834% (29178/29824)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.840% (29305/29952)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.846% (29432/30080)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.838% (29555/30208)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.838% (29680/30336)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (29807/30464)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.846% (29933/30592)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.852% (30060/30720)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.851% (30185/30848)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (30308/30976)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.836% (30431/31104)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (30555/31232)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (30680/31360)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.828% (30804/31488)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.821% (30927/31616)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.817% (31051/31744)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.816% (31176/31872)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.816% (31301/32000)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.821% (31428/32128)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.814% (31551/32256)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.814% (31676/32384)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.816% (31802/32512)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.812% (31926/32640)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.806% (32049/32768)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.805% (32174/32896)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.805% (32299/33024)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.804% (32424/33152)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.794% (32546/33280)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.782% (32667/33408)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.781% (32792/33536)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.787% (32919/33664)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.795% (33047/33792)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.798% (33173/33920)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.791% (33296/34048)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.794% (33422/34176)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.796% (33548/34304)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.787% (33670/34432)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.784% (33794/34560)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.789% (33921/34688)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.797% (34049/34816)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.794% (34173/34944)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.802% (34301/35072)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.804% (34427/35200)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.806% (34553/35328)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.811% (34680/35456)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.819% (34808/35584)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.816% (34932/35712)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.821% (35059/35840)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.820% (35184/35968)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.822% (35310/36096)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.819% (35434/36224)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.824% (35561/36352)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.823% (35686/36480)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.828% (35813/36608)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (35940/36736)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.835% (36066/36864)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.835% (36191/36992)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.834% (36316/37120)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.836% (36442/37248)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.844% (36570/37376)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (36695/37504)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.840% (36819/37632)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.834% (36942/37760)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (37067/37888)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (37192/38016)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.827% (37315/38144)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.829% (37441/38272)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.833% (37568/38400)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.830% (37692/38528)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (37818/38656)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.834% (37944/38784)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.823% (38065/38912)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.825% (38191/39040)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.830% (38318/39168)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.837% (38446/39296)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.841% (38573/39424)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (38699/39552)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.850% (38827/39680)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.850% (38952/39808)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.857% (39080/39936)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.856% (39205/40064)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.850% (39328/40192)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.855% (39455/40320)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.857% (39581/40448)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.851% (39704/40576)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.855% (39831/40704)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.862% (39959/40832)\n",
      "Train Epoch: 66 | Loss: 0.061 | Acc: 97.866% (40086/40960)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.856% (40207/41088)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (40327/41216)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.838% (40450/41344)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.840% (40576/41472)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.844% (40703/41600)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.836% (40825/41728)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.843% (40953/41856)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.837% (41076/41984)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.832% (41199/42112)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.829% (41323/42240)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.831% (41449/42368)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.826% (41572/42496)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.830% (41699/42624)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.829% (41824/42752)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.831% (41950/42880)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.824% (42072/43008)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.823% (42197/43136)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.825% (42323/43264)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.827% (42449/43392)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.826% (42574/43520)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.823% (42698/43648)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.821% (42822/43776)\n",
      "Train Epoch: 66 | Loss: 0.062 | Acc: 97.823% (42948/43904)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.817% (43071/44032)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.817% (43196/44160)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.814% (43320/44288)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.809% (43443/44416)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.813% (43570/44544)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.811% (43694/44672)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.810% (43819/44800)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.805% (43942/44928)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.809% (44069/45056)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.809% (44194/45184)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.809% (44319/45312)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.810% (44445/45440)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.814% (44572/45568)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.812% (44696/45696)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.809% (44820/45824)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.802% (44942/45952)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.799% (45066/46080)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.806% (45194/46208)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.805% (45319/46336)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.807% (45445/46464)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.804% (45569/46592)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.802% (45693/46720)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.801% (45818/46848)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.799% (45942/46976)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.803% (46069/47104)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.804% (46195/47232)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.800% (46318/47360)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.799% (46443/47488)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.797% (46567/47616)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.799% (46693/47744)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.802% (46820/47872)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.806% (46947/48000)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.808% (47073/48128)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.812% (47200/48256)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.815% (47327/48384)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.813% (47451/48512)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.819% (47579/48640)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.818% (47704/48768)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.814% (47827/48896)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.811% (47951/49024)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.813% (48077/49152)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.815% (48203/49280)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.816% (48329/49408)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.820% (48456/49536)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.823% (48583/49664)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.821% (48707/49792)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.821% (48832/49920)\n",
      "Train Epoch: 66 | Loss: 0.063 | Acc: 97.822% (48911/50000)\n",
      "Test Epoch: 66 | Loss: 0.359 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 66 | Loss: 0.311 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 66 | Loss: 0.282 | Acc: 91.400% (457/500)\n",
      "Test Epoch: 66 | Loss: 0.251 | Acc: 92.167% (553/600)\n",
      "Test Epoch: 66 | Loss: 0.259 | Acc: 92.571% (648/700)\n",
      "Test Epoch: 66 | Loss: 0.297 | Acc: 91.875% (735/800)\n",
      "Test Epoch: 66 | Loss: 0.309 | Acc: 91.778% (826/900)\n",
      "Test Epoch: 66 | Loss: 0.324 | Acc: 91.500% (915/1000)\n",
      "Test Epoch: 66 | Loss: 0.349 | Acc: 91.091% (1002/1100)\n",
      "Test Epoch: 66 | Loss: 0.366 | Acc: 91.167% (1094/1200)\n",
      "Test Epoch: 66 | Loss: 0.355 | Acc: 91.462% (1189/1300)\n",
      "Test Epoch: 66 | Loss: 0.356 | Acc: 91.429% (1280/1400)\n",
      "Test Epoch: 66 | Loss: 0.354 | Acc: 91.400% (1371/1500)\n",
      "Test Epoch: 66 | Loss: 0.345 | Acc: 91.625% (1466/1600)\n",
      "Test Epoch: 66 | Loss: 0.341 | Acc: 91.588% (1557/1700)\n",
      "Test Epoch: 66 | Loss: 0.346 | Acc: 91.333% (1644/1800)\n",
      "Test Epoch: 66 | Loss: 0.353 | Acc: 91.053% (1730/1900)\n",
      "Test Epoch: 66 | Loss: 0.378 | Acc: 90.850% (1817/2000)\n",
      "Test Epoch: 66 | Loss: 0.384 | Acc: 90.810% (1907/2100)\n",
      "Test Epoch: 66 | Loss: 0.384 | Acc: 90.682% (1995/2200)\n",
      "Test Epoch: 66 | Loss: 0.383 | Acc: 90.739% (2087/2300)\n",
      "Test Epoch: 66 | Loss: 0.375 | Acc: 90.750% (2178/2400)\n",
      "Test Epoch: 66 | Loss: 0.385 | Acc: 90.600% (2265/2500)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.500% (2353/2600)\n",
      "Test Epoch: 66 | Loss: 0.391 | Acc: 90.630% (2447/2700)\n",
      "Test Epoch: 66 | Loss: 0.391 | Acc: 90.643% (2538/2800)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.621% (2628/2900)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.567% (2717/3000)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.516% (2806/3100)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.500% (2896/3200)\n",
      "Test Epoch: 66 | Loss: 0.394 | Acc: 90.576% (2989/3300)\n",
      "Test Epoch: 66 | Loss: 0.394 | Acc: 90.559% (3079/3400)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.429% (3165/3500)\n",
      "Test Epoch: 66 | Loss: 0.402 | Acc: 90.389% (3254/3600)\n",
      "Test Epoch: 66 | Loss: 0.409 | Acc: 90.324% (3342/3700)\n",
      "Test Epoch: 66 | Loss: 0.413 | Acc: 90.237% (3429/3800)\n",
      "Test Epoch: 66 | Loss: 0.412 | Acc: 90.308% (3522/3900)\n",
      "Test Epoch: 66 | Loss: 0.411 | Acc: 90.350% (3614/4000)\n",
      "Test Epoch: 66 | Loss: 0.413 | Acc: 90.317% (3703/4100)\n",
      "Test Epoch: 66 | Loss: 0.416 | Acc: 90.310% (3793/4200)\n",
      "Test Epoch: 66 | Loss: 0.408 | Acc: 90.465% (3890/4300)\n",
      "Test Epoch: 66 | Loss: 0.409 | Acc: 90.500% (3982/4400)\n",
      "Test Epoch: 66 | Loss: 0.405 | Acc: 90.578% (4076/4500)\n",
      "Test Epoch: 66 | Loss: 0.407 | Acc: 90.478% (4162/4600)\n",
      "Test Epoch: 66 | Loss: 0.406 | Acc: 90.447% (4251/4700)\n",
      "Test Epoch: 66 | Loss: 0.407 | Acc: 90.396% (4339/4800)\n",
      "Test Epoch: 66 | Loss: 0.403 | Acc: 90.449% (4432/4900)\n",
      "Test Epoch: 66 | Loss: 0.403 | Acc: 90.420% (4521/5000)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.451% (4613/5100)\n",
      "Test Epoch: 66 | Loss: 0.398 | Acc: 90.404% (4701/5200)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.358% (4789/5300)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.352% (4879/5400)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.345% (4969/5500)\n",
      "Test Epoch: 66 | Loss: 0.402 | Acc: 90.321% (5058/5600)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.421% (5154/5700)\n",
      "Test Epoch: 66 | Loss: 0.398 | Acc: 90.414% (5244/5800)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.407% (5334/5900)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.417% (5425/6000)\n",
      "Test Epoch: 66 | Loss: 0.396 | Acc: 90.410% (5515/6100)\n",
      "Test Epoch: 66 | Loss: 0.396 | Acc: 90.371% (5603/6200)\n",
      "Test Epoch: 66 | Loss: 0.395 | Acc: 90.397% (5695/6300)\n",
      "Test Epoch: 66 | Loss: 0.392 | Acc: 90.453% (5789/6400)\n",
      "Test Epoch: 66 | Loss: 0.392 | Acc: 90.385% (5875/6500)\n",
      "Test Epoch: 66 | Loss: 0.389 | Acc: 90.348% (5963/6600)\n",
      "Test Epoch: 66 | Loss: 0.388 | Acc: 90.373% (6055/6700)\n",
      "Test Epoch: 66 | Loss: 0.390 | Acc: 90.353% (6144/6800)\n",
      "Test Epoch: 66 | Loss: 0.390 | Acc: 90.362% (6235/6900)\n",
      "Test Epoch: 66 | Loss: 0.390 | Acc: 90.329% (6323/7000)\n",
      "Test Epoch: 66 | Loss: 0.393 | Acc: 90.268% (6409/7100)\n",
      "Test Epoch: 66 | Loss: 0.394 | Acc: 90.278% (6500/7200)\n",
      "Test Epoch: 66 | Loss: 0.395 | Acc: 90.274% (6590/7300)\n",
      "Test Epoch: 66 | Loss: 0.396 | Acc: 90.270% (6680/7400)\n",
      "Test Epoch: 66 | Loss: 0.396 | Acc: 90.293% (6772/7500)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.276% (6861/7600)\n",
      "Test Epoch: 66 | Loss: 0.398 | Acc: 90.286% (6952/7700)\n",
      "Test Epoch: 66 | Loss: 0.397 | Acc: 90.321% (7045/7800)\n",
      "Test Epoch: 66 | Loss: 0.395 | Acc: 90.354% (7138/7900)\n",
      "Test Epoch: 66 | Loss: 0.396 | Acc: 90.362% (7229/8000)\n",
      "Test Epoch: 66 | Loss: 0.393 | Acc: 90.395% (7322/8100)\n",
      "Test Epoch: 66 | Loss: 0.394 | Acc: 90.402% (7413/8200)\n",
      "Test Epoch: 66 | Loss: 0.394 | Acc: 90.398% (7503/8300)\n",
      "Test Epoch: 66 | Loss: 0.395 | Acc: 90.357% (7590/8400)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.318% (7677/8500)\n",
      "Test Epoch: 66 | Loss: 0.402 | Acc: 90.279% (7764/8600)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.299% (7856/8700)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.318% (7948/8800)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.326% (8039/8900)\n",
      "Test Epoch: 66 | Loss: 0.401 | Acc: 90.333% (8130/9000)\n",
      "Test Epoch: 66 | Loss: 0.401 | Acc: 90.297% (8217/9100)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.326% (8310/9200)\n",
      "Test Epoch: 66 | Loss: 0.401 | Acc: 90.301% (8398/9300)\n",
      "Test Epoch: 66 | Loss: 0.402 | Acc: 90.287% (8487/9400)\n",
      "Test Epoch: 66 | Loss: 0.401 | Acc: 90.295% (8578/9500)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.302% (8669/9600)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.330% (8762/9700)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.306% (8850/9800)\n",
      "Test Epoch: 66 | Loss: 0.400 | Acc: 90.313% (8941/9900)\n",
      "Test Epoch: 66 | Loss: 0.399 | Acc: 90.310% (9031/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 67\n",
      "Train Epoch: 67 | Loss: 0.033 | Acc: 100.000% (128/128)\n",
      "Train Epoch: 67 | Loss: 0.066 | Acc: 98.438% (252/256)\n",
      "Train Epoch: 67 | Loss: 0.067 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 67 | Loss: 0.079 | Acc: 97.266% (498/512)\n",
      "Train Epoch: 67 | Loss: 0.076 | Acc: 97.344% (623/640)\n",
      "Train Epoch: 67 | Loss: 0.066 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 67 | Loss: 0.068 | Acc: 97.879% (877/896)\n",
      "Train Epoch: 67 | Loss: 0.067 | Acc: 97.949% (1003/1024)\n",
      "Train Epoch: 67 | Loss: 0.070 | Acc: 97.743% (1126/1152)\n",
      "Train Epoch: 67 | Loss: 0.066 | Acc: 97.891% (1253/1280)\n",
      "Train Epoch: 67 | Loss: 0.066 | Acc: 97.940% (1379/1408)\n",
      "Train Epoch: 67 | Loss: 0.069 | Acc: 97.786% (1502/1536)\n",
      "Train Epoch: 67 | Loss: 0.072 | Acc: 97.596% (1624/1664)\n",
      "Train Epoch: 67 | Loss: 0.070 | Acc: 97.656% (1750/1792)\n",
      "Train Epoch: 67 | Loss: 0.069 | Acc: 97.656% (1875/1920)\n",
      "Train Epoch: 67 | Loss: 0.069 | Acc: 97.656% (2000/2048)\n",
      "Train Epoch: 67 | Loss: 0.067 | Acc: 97.748% (2127/2176)\n",
      "Train Epoch: 67 | Loss: 0.066 | Acc: 97.743% (2252/2304)\n",
      "Train Epoch: 67 | Loss: 0.064 | Acc: 97.821% (2379/2432)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.930% (2507/2560)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.028% (2635/2688)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.082% (2762/2816)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.132% (2889/2944)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.079% (3013/3072)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.125% (3140/3200)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.047% (3263/3328)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.975% (3386/3456)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.963% (3511/3584)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.006% (3638/3712)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.047% (3765/3840)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.034% (3890/3968)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.047% (4016/4096)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.035% (4141/4224)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.047% (4267/4352)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.103% (4395/4480)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.134% (4522/4608)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.057% (4644/4736)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.047% (4769/4864)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.997% (4892/4992)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.027% (5019/5120)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.999% (5143/5248)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.047% (5271/5376)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 98.001% (5394/5504)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.976% (5518/5632)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.969% (5643/5760)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.962% (5768/5888)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.955% (5893/6016)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.949% (6018/6144)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.959% (6144/6272)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.969% (6270/6400)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.963% (6395/6528)\n",
      "Train Epoch: 67 | Loss: 0.061 | Acc: 97.927% (6518/6656)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.936% (6644/6784)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.960% (6771/6912)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.983% (6898/7040)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (7024/7168)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.999% (7150/7296)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.966% (7273/7424)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.961% (7398/7552)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.995% (7526/7680)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (7650/7808)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.996% (7777/7936)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.991% (7902/8064)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.998% (8028/8192)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.957% (8150/8320)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.952% (8275/8448)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.948% (8400/8576)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.932% (8524/8704)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.917% (8648/8832)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.913% (8773/8960)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.909% (8898/9088)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.928% (9025/9216)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.935% (9151/9344)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.952% (9278/9472)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.896% (9398/9600)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.903% (9524/9728)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.900% (9649/9856)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.917% (9776/9984)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.864% (9896/10112)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.881% (10023/10240)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.888% (10149/10368)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.894% (10275/10496)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.901% (10401/10624)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.898% (10526/10752)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.895% (10651/10880)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.902% (10777/11008)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.926% (10905/11136)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.914% (11029/11264)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.911% (11154/11392)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.908% (11279/11520)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.905% (11404/11648)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.919% (11531/11776)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.917% (11656/11904)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.931% (11783/12032)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.919% (11907/12160)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.941% (12035/12288)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.946% (12161/12416)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.919% (12283/12544)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.925% (12409/12672)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.914% (12533/12800)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.919% (12659/12928)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.924% (12785/13056)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.929% (12911/13184)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.934% (13037/13312)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.924% (13161/13440)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.929% (13287/13568)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.926% (13412/13696)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.895% (13533/13824)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.871% (13655/13952)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.869% (13780/14080)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.874% (13906/14208)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.872% (14031/14336)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.864% (14155/14464)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.869% (14281/14592)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.874% (14407/14720)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.872% (14532/14848)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.877% (14658/14976)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.881% (14784/15104)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.886% (14910/15232)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.878% (15034/15360)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.882% (15160/15488)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.887% (15286/15616)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.898% (15413/15744)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.908% (15540/15872)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.894% (15663/16000)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.892% (15788/16128)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.896% (15914/16256)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.894% (16039/16384)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.905% (16166/16512)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.897% (16290/16640)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.907% (16417/16768)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.905% (16542/16896)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.909% (16668/17024)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.919% (16795/17152)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.928% (16922/17280)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.920% (17046/17408)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.924% (17172/17536)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.922% (17297/17664)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.926% (17423/17792)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.930% (17549/17920)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.922% (17673/18048)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.926% (17799/18176)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.918% (17923/18304)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.928% (18050/18432)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.920% (18174/18560)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.924% (18300/18688)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.922% (18425/18816)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.925% (18551/18944)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.918% (18675/19072)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.922% (18801/19200)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.930% (18928/19328)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.944% (19056/19456)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.952% (19183/19584)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.961% (19310/19712)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.974% (19438/19840)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.972% (19563/19968)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.985% (19691/20096)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.988% (19817/20224)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.985% (19942/20352)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.993% (20069/20480)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.986% (20193/20608)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.994% (20320/20736)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.992% (20445/20864)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.999% (20572/20992)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.997% (20697/21120)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.990% (20821/21248)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 97.998% (20948/21376)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.000% (21074/21504)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.012% (21202/21632)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.024% (21330/21760)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.022% (21455/21888)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.020% (21580/22016)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.027% (21707/22144)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.020% (21831/22272)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.022% (21957/22400)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.025% (22083/22528)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.027% (22209/22656)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.029% (22335/22784)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.032% (22461/22912)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.034% (22587/23040)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.032% (22712/23168)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.034% (22838/23296)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.032% (22963/23424)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.021% (23086/23552)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.019% (23211/23680)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.022% (23337/23808)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.016% (23461/23936)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.022% (23588/24064)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.024% (23714/24192)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.030% (23841/24320)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.033% (23967/24448)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.031% (24092/24576)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.029% (24217/24704)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.039% (24345/24832)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.049% (24473/24960)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.051% (24599/25088)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.049% (24724/25216)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.047% (24849/25344)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.049% (24975/25472)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.051% (25101/25600)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.053% (25227/25728)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.055% (25353/25856)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.060% (25480/25984)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.058% (25605/26112)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.064% (25732/26240)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.054% (25855/26368)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.053% (25980/26496)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.054% (26106/26624)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.049% (26230/26752)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.058% (26358/26880)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.060% (26484/27008)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.062% (26610/27136)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.063% (26736/27264)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (26861/27392)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.060% (26986/27520)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.069% (27114/27648)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.067% (27239/27776)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.072% (27366/27904)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.077% (27493/28032)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.082% (27620/28160)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.088% (27747/28288)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.096% (27875/28416)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.098% (28001/28544)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.092% (28125/28672)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.083% (28248/28800)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.068% (28369/28928)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.076% (28497/29056)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.085% (28625/29184)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.079% (28749/29312)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.071% (28872/29440)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.065% (28996/29568)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (29123/29696)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.065% (29247/29824)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (29374/29952)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.072% (29500/30080)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (29625/30208)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.068% (29750/30336)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (29876/30464)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.075% (30003/30592)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (30127/30720)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (30250/30848)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.066% (30377/30976)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.071% (30504/31104)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.063% (30627/31232)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.068% (30754/31360)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.069% (30880/31488)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.064% (31004/31616)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.069% (31131/31744)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (31254/31872)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.069% (31382/32000)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (31505/32128)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.059% (31630/32256)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (31756/32384)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.059% (31881/32512)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.058% (32006/32640)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.065% (32134/32768)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (32258/32896)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.059% (32383/33024)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.060% (32509/33152)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.068% (32637/33280)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.063% (32761/33408)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.065% (32887/33536)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.063% (33012/33664)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.068% (33139/33792)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.072% (33266/33920)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.073% (33392/34048)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.078% (33519/34176)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.070% (33642/34304)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.072% (33768/34432)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.076% (33895/34560)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.077% (34021/34688)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.081% (34148/34816)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.083% (34274/34944)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.084% (34400/35072)\n",
      "Train Epoch: 67 | Loss: 0.057 | Acc: 98.077% (34523/35200)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.070% (34646/35328)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.071% (34772/35456)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.072% (34898/35584)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.076% (35025/35712)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.078% (35151/35840)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.073% (35275/35968)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.072% (35400/36096)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.065% (35523/36224)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.061% (35647/36352)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.065% (35774/36480)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.052% (35895/36608)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.048% (36019/36736)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.044% (36143/36864)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.046% (36269/36992)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.044% (36394/37120)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.048% (36521/37248)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.050% (36647/37376)\n",
      "Train Epoch: 67 | Loss: 0.058 | Acc: 98.038% (36768/37504)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.026% (36889/37632)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.030% (37016/37760)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.028% (37141/37888)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.025% (37265/38016)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.023% (37390/38144)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.025% (37516/38272)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.023% (37641/38400)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.022% (37766/38528)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.024% (37892/38656)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.012% (38013/38784)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.016% (38140/38912)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.010% (38263/39040)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.011% (38389/39168)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.010% (38514/39296)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.009% (38639/39424)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.008% (38764/39552)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.014% (38892/39680)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.008% (39015/39808)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.999% (39137/39936)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.993% (39260/40064)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.000% (39388/40192)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.001% (39514/40320)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 98.002% (39640/40448)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.999% (39764/40576)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.998% (39889/40704)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.992% (40012/40832)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (40137/40960)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.985% (40260/41088)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (40385/41216)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.980% (40509/41344)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (40636/41472)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.986% (40762/41600)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.989% (40889/41728)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (41014/41856)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.985% (41138/41984)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.986% (41264/42112)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.985% (41389/42240)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.987% (41515/42368)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.981% (41638/42496)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.980% (41763/42624)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (41890/42752)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.980% (42014/42880)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.982% (42140/43008)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (42263/43136)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.980% (42390/43264)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.983% (42517/43392)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.980% (42641/43520)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (42768/43648)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.981% (42892/43776)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.975% (43015/43904)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.981% (43143/44032)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.978% (43267/44160)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.979% (43393/44288)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (43517/44416)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.975% (43642/44544)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (43768/44672)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.975% (43893/44800)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.977% (44019/44928)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.974% (44143/45056)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.979% (44271/45184)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (44395/45312)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.982% (44523/45440)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (44651/45568)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (44778/45696)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.992% (44904/45824)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.989% (45028/45952)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.986% (45152/46080)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.990% (45279/46208)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (45402/46336)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (45529/46464)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.989% (45655/46592)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (45780/46720)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.985% (45904/46848)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (46031/46976)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.990% (46157/47104)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.993% (46284/47232)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.990% (46408/47360)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (46534/47488)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.994% (46661/47616)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.998% (46788/47744)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.999% (46914/47872)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.994% (47037/48000)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.995% (47163/48128)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.992% (47287/48256)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (47412/48384)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.994% (47539/48512)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.991% (47663/48640)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.993% (47789/48768)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.992% (47914/48896)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.987% (48037/49024)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.988% (48163/49152)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.987% (48288/49280)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.984% (48412/49408)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.975% (48533/49536)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.976% (48659/49664)\n",
      "Train Epoch: 67 | Loss: 0.059 | Acc: 97.974% (48783/49792)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.973% (48908/49920)\n",
      "Train Epoch: 67 | Loss: 0.060 | Acc: 97.972% (48986/50000)\n",
      "Test Epoch: 67 | Loss: 0.490 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 67 | Loss: 0.413 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 67 | Loss: 0.368 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 67 | Loss: 0.371 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 67 | Loss: 0.332 | Acc: 90.800% (454/500)\n",
      "Test Epoch: 67 | Loss: 0.293 | Acc: 92.000% (552/600)\n",
      "Test Epoch: 67 | Loss: 0.307 | Acc: 92.000% (644/700)\n",
      "Test Epoch: 67 | Loss: 0.328 | Acc: 90.875% (727/800)\n",
      "Test Epoch: 67 | Loss: 0.324 | Acc: 91.222% (821/900)\n",
      "Test Epoch: 67 | Loss: 0.345 | Acc: 91.000% (910/1000)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 90.545% (996/1100)\n",
      "Test Epoch: 67 | Loss: 0.394 | Acc: 90.500% (1086/1200)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 90.692% (1179/1300)\n",
      "Test Epoch: 67 | Loss: 0.382 | Acc: 90.786% (1271/1400)\n",
      "Test Epoch: 67 | Loss: 0.377 | Acc: 90.800% (1362/1500)\n",
      "Test Epoch: 67 | Loss: 0.366 | Acc: 90.938% (1455/1600)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 90.882% (1545/1700)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 90.889% (1636/1800)\n",
      "Test Epoch: 67 | Loss: 0.370 | Acc: 90.737% (1724/1900)\n",
      "Test Epoch: 67 | Loss: 0.385 | Acc: 90.550% (1811/2000)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 90.333% (1897/2100)\n",
      "Test Epoch: 67 | Loss: 0.390 | Acc: 90.091% (1982/2200)\n",
      "Test Epoch: 67 | Loss: 0.384 | Acc: 90.130% (2073/2300)\n",
      "Test Epoch: 67 | Loss: 0.381 | Acc: 90.167% (2164/2400)\n",
      "Test Epoch: 67 | Loss: 0.389 | Acc: 90.080% (2252/2500)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 89.923% (2338/2600)\n",
      "Test Epoch: 67 | Loss: 0.397 | Acc: 89.963% (2429/2700)\n",
      "Test Epoch: 67 | Loss: 0.396 | Acc: 89.964% (2519/2800)\n",
      "Test Epoch: 67 | Loss: 0.395 | Acc: 90.069% (2612/2900)\n",
      "Test Epoch: 67 | Loss: 0.395 | Acc: 90.133% (2704/3000)\n",
      "Test Epoch: 67 | Loss: 0.397 | Acc: 90.065% (2792/3100)\n",
      "Test Epoch: 67 | Loss: 0.394 | Acc: 90.094% (2883/3200)\n",
      "Test Epoch: 67 | Loss: 0.400 | Acc: 89.939% (2968/3300)\n",
      "Test Epoch: 67 | Loss: 0.397 | Acc: 90.029% (3061/3400)\n",
      "Test Epoch: 67 | Loss: 0.401 | Acc: 89.914% (3147/3500)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 89.917% (3237/3600)\n",
      "Test Epoch: 67 | Loss: 0.413 | Acc: 89.865% (3325/3700)\n",
      "Test Epoch: 67 | Loss: 0.415 | Acc: 89.868% (3415/3800)\n",
      "Test Epoch: 67 | Loss: 0.414 | Acc: 89.897% (3506/3900)\n",
      "Test Epoch: 67 | Loss: 0.414 | Acc: 89.875% (3595/4000)\n",
      "Test Epoch: 67 | Loss: 0.416 | Acc: 89.829% (3683/4100)\n",
      "Test Epoch: 67 | Loss: 0.417 | Acc: 89.786% (3771/4200)\n",
      "Test Epoch: 67 | Loss: 0.409 | Acc: 89.930% (3867/4300)\n",
      "Test Epoch: 67 | Loss: 0.411 | Acc: 90.023% (3961/4400)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.156% (4057/4500)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.109% (4145/4600)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.085% (4234/4700)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.083% (4324/4800)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.143% (4417/4900)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.100% (4505/5000)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.118% (4596/5100)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.058% (4683/5200)\n",
      "Test Epoch: 67 | Loss: 0.408 | Acc: 90.038% (4772/5300)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.074% (4864/5400)\n",
      "Test Epoch: 67 | Loss: 0.407 | Acc: 90.073% (4954/5500)\n",
      "Test Epoch: 67 | Loss: 0.409 | Acc: 90.054% (5043/5600)\n",
      "Test Epoch: 67 | Loss: 0.407 | Acc: 90.105% (5136/5700)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.121% (5227/5800)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.085% (5315/5900)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.033% (5402/6000)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.000% (5490/6100)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.000% (5580/6200)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.095% (5676/6300)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.109% (5767/6400)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.077% (5855/6500)\n",
      "Test Epoch: 67 | Loss: 0.401 | Acc: 90.106% (5947/6600)\n",
      "Test Epoch: 67 | Loss: 0.402 | Acc: 90.119% (6038/6700)\n",
      "Test Epoch: 67 | Loss: 0.402 | Acc: 90.103% (6127/6800)\n",
      "Test Epoch: 67 | Loss: 0.400 | Acc: 90.159% (6221/6900)\n",
      "Test Epoch: 67 | Loss: 0.402 | Acc: 90.129% (6309/7000)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.155% (6401/7100)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.181% (6493/7200)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.205% (6585/7300)\n",
      "Test Epoch: 67 | Loss: 0.406 | Acc: 90.216% (6676/7400)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.187% (6764/7500)\n",
      "Test Epoch: 67 | Loss: 0.407 | Acc: 90.197% (6855/7600)\n",
      "Test Epoch: 67 | Loss: 0.409 | Acc: 90.156% (6942/7700)\n",
      "Test Epoch: 67 | Loss: 0.407 | Acc: 90.179% (7034/7800)\n",
      "Test Epoch: 67 | Loss: 0.408 | Acc: 90.203% (7126/7900)\n",
      "Test Epoch: 67 | Loss: 0.408 | Acc: 90.225% (7218/8000)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.272% (7312/8100)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.305% (7405/8200)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.313% (7496/8300)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.333% (7588/8400)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.282% (7674/8500)\n",
      "Test Epoch: 67 | Loss: 0.405 | Acc: 90.256% (7762/8600)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.264% (7853/8700)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.295% (7946/8800)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.258% (8033/8900)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.244% (8122/9000)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.231% (8211/9100)\n",
      "Test Epoch: 67 | Loss: 0.402 | Acc: 90.272% (8305/9200)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.258% (8394/9300)\n",
      "Test Epoch: 67 | Loss: 0.404 | Acc: 90.266% (8485/9400)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.274% (8576/9500)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.302% (8669/9600)\n",
      "Test Epoch: 67 | Loss: 0.401 | Acc: 90.309% (8760/9700)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.286% (8848/9800)\n",
      "Test Epoch: 67 | Loss: 0.403 | Acc: 90.313% (8941/9900)\n",
      "Test Epoch: 67 | Loss: 0.401 | Acc: 90.340% (9034/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 68\n",
      "Train Epoch: 68 | Loss: 0.113 | Acc: 95.312% (122/128)\n",
      "Train Epoch: 68 | Loss: 0.096 | Acc: 96.484% (247/256)\n",
      "Train Epoch: 68 | Loss: 0.077 | Acc: 97.135% (373/384)\n",
      "Train Epoch: 68 | Loss: 0.068 | Acc: 97.461% (499/512)\n",
      "Train Epoch: 68 | Loss: 0.059 | Acc: 97.969% (627/640)\n",
      "Train Epoch: 68 | Loss: 0.061 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.103% (879/896)\n",
      "Train Epoch: 68 | Loss: 0.061 | Acc: 97.852% (1002/1024)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.090% (1130/1152)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.125% (1256/1280)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.295% (1384/1408)\n",
      "Train Epoch: 68 | Loss: 0.052 | Acc: 98.372% (1511/1536)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.317% (1636/1664)\n",
      "Train Epoch: 68 | Loss: 0.051 | Acc: 98.382% (1763/1792)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.281% (1887/1920)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.291% (2013/2048)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.346% (2140/2176)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.351% (2266/2304)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.355% (2392/2432)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.320% (2517/2560)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.289% (2642/2688)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.189% (2765/2816)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.166% (2890/2944)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.210% (3017/3072)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.219% (3143/3200)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.287% (3271/3328)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.264% (3396/3456)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.270% (3522/3584)\n",
      "Train Epoch: 68 | Loss: 0.052 | Acc: 98.330% (3650/3712)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.307% (3775/3840)\n",
      "Train Epoch: 68 | Loss: 0.052 | Acc: 98.337% (3902/3968)\n",
      "Train Epoch: 68 | Loss: 0.052 | Acc: 98.315% (4027/4096)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.319% (4153/4224)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.323% (4279/4352)\n",
      "Train Epoch: 68 | Loss: 0.052 | Acc: 98.348% (4406/4480)\n",
      "Train Epoch: 68 | Loss: 0.051 | Acc: 98.372% (4533/4608)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.332% (4657/4736)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.314% (4782/4864)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.297% (4907/4992)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.203% (5028/5120)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.209% (5154/5248)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.214% (5280/5376)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.219% (5406/5504)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.242% (5533/5632)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.247% (5659/5760)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.234% (5784/5888)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.221% (5909/6016)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.210% (6034/6144)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.214% (6160/6272)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.219% (6286/6400)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.238% (6413/6528)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.212% (6537/6656)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.216% (6663/6784)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.206% (6788/6912)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.210% (6914/7040)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.242% (7042/7168)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.218% (7166/7296)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.235% (7293/7424)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.212% (7417/7552)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.177% (7540/7680)\n",
      "Train Epoch: 68 | Loss: 0.053 | Acc: 98.181% (7666/7808)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.173% (7791/7936)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.177% (7917/8064)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.157% (8041/8192)\n",
      "Train Epoch: 68 | Loss: 0.054 | Acc: 98.149% (8166/8320)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.130% (8290/8448)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.099% (8413/8576)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.127% (8541/8704)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.120% (8666/8832)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.136% (8793/8960)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.118% (8917/9088)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.123% (9043/9216)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.116% (9168/9344)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.142% (9296/9472)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.125% (9420/9600)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.139% (9547/9728)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.153% (9674/9856)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.167% (9801/9984)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.141% (9924/10112)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.135% (10049/10240)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.129% (10174/10368)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.114% (10298/10496)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.117% (10424/10624)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.121% (10550/10752)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.070% (10670/10880)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.092% (10798/11008)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.096% (10924/11136)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.082% (11048/11264)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.095% (11175/11392)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.090% (11300/11520)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.103% (11427/11648)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.115% (11554/11776)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.093% (11677/11904)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.088% (11802/12032)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.100% (11929/12160)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.112% (12056/12288)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.107% (12181/12416)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.111% (12307/12544)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.106% (12432/12672)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.117% (12559/12800)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.120% (12685/12928)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.116% (12810/13056)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.119% (12936/13184)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.130% (13063/13312)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.140% (13190/13440)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.150% (13317/13568)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.145% (13442/13696)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.126% (13565/13824)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.136% (13692/13952)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.132% (13817/14080)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.135% (13943/14208)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.152% (14071/14336)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.147% (14196/14464)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.150% (14322/14592)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.145% (14447/14720)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.114% (14568/14848)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (14693/14976)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.106% (14818/15104)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (14943/15232)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (15069/15360)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.108% (15195/15488)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (15320/15616)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.107% (15446/15744)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.091% (15569/15872)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.100% (15696/16000)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (15822/16128)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.093% (15946/16256)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.096% (16072/16384)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (16200/16512)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.095% (16323/16640)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.098% (16449/16768)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.088% (16573/16896)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.085% (16698/17024)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.082% (16823/17152)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.084% (16949/17280)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.070% (17072/17408)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.044% (17193/17536)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.030% (17316/17664)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.027% (17441/17792)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.002% (17562/17920)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.000% (17687/18048)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.997% (17812/18176)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.000% (17938/18304)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.993% (18062/18432)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.996% (18188/18560)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.993% (18313/18688)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.996% (18439/18816)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.999% (18565/18944)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.008% (18692/19072)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.016% (18819/19200)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.008% (18943/19328)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.011% (19069/19456)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.014% (19195/19584)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.006% (19319/19712)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.009% (19445/19840)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.992% (19567/19968)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.985% (19691/20096)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.988% (19817/20224)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.985% (19942/20352)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.993% (20069/20480)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.001% (20196/20608)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.003% (20322/20736)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.977% (20442/20864)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.980% (20568/20992)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.983% (20694/21120)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.981% (20819/21248)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.988% (20946/21376)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 97.996% (21073/21504)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.003% (21200/21632)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.015% (21328/21760)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.003% (21451/21888)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.011% (21578/22016)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.022% (21706/22144)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.024% (21832/22272)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.031% (21959/22400)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.038% (22086/22528)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.036% (22211/22656)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.042% (22338/22784)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.049% (22465/22912)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (22589/23040)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.045% (22715/23168)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.047% (22841/23296)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.045% (22966/23424)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.038% (23090/23552)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.045% (23217/23680)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (23342/23808)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.049% (23469/23936)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.059% (23597/24064)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.065% (23724/24192)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.072% (23851/24320)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.073% (23977/24448)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.071% (24102/24576)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.077% (24229/24704)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (24357/24832)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.085% (24482/24960)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.075% (24605/25088)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.081% (24732/25216)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.086% (24859/25344)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.088% (24985/25472)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.086% (25110/25600)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.088% (25236/25728)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.086% (25361/25856)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.083% (25486/25984)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.089% (25613/26112)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (25738/26240)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.089% (25864/26368)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.094% (25991/26496)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.084% (26114/26624)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.090% (26241/26752)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.077% (26363/26880)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.082% (26490/27008)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (26617/27136)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.096% (26745/27264)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.102% (26872/27392)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.096% (26996/27520)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.094% (27121/27648)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.095% (27247/27776)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.101% (27374/27904)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.102% (27500/28032)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.100% (27625/28160)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (27753/28288)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.107% (27878/28416)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.108% (28004/28544)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.110% (28130/28672)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.115% (28257/28800)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.113% (28382/28928)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.111% (28507/29056)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.098% (28629/29184)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (28756/29312)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.101% (28881/29440)\n",
      "Train Epoch: 68 | Loss: 0.055 | Acc: 98.109% (29009/29568)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.101% (29132/29696)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.106% (29259/29824)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.104% (29384/29952)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (29510/30080)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.090% (29631/30208)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.088% (29756/30336)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.086% (29881/30464)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.088% (30007/30592)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.086% (30132/30720)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (30258/30848)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.089% (30384/30976)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.074% (30505/31104)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.079% (30632/31232)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (30760/31360)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.091% (30887/31488)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.090% (31012/31616)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.091% (31138/31744)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.089% (31263/31872)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.091% (31389/32000)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.083% (31512/32128)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.087% (31639/32256)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.095% (31767/32384)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (31894/32512)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.104% (32021/32640)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (32145/32768)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (32272/32896)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (32400/33024)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (32525/33152)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.101% (32648/33280)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (32773/33408)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.098% (32898/33536)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.102% (33025/33664)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.106% (33152/33792)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.107% (33278/33920)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (33402/34048)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.101% (33527/34176)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (33652/34304)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.104% (33779/34432)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.108% (33906/34560)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.112% (34033/34688)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.116% (34160/34816)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.120% (34287/34944)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.121% (34413/35072)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.116% (34537/35200)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.115% (34662/35328)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.122% (34790/35456)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.117% (34914/35584)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.115% (35039/35712)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (35161/35840)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.107% (35287/35968)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (35412/36096)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.103% (35537/36224)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (35663/36352)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.111% (35791/36480)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.115% (35918/36608)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.114% (36043/36736)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.117% (36170/36864)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.116% (36295/36992)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.117% (36421/37120)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.123% (36549/37248)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.122% (36674/37376)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.123% (36800/37504)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.113% (36922/37632)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (37046/37760)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.108% (37171/37888)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (37297/38016)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (37423/38144)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.111% (37549/38272)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.115% (37676/38400)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.116% (37802/38528)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.112% (37926/38656)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (38051/38784)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (38176/38912)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (38298/39040)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.098% (38423/39168)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.104% (38551/39296)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (38677/39424)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.109% (38804/39552)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.115% (38932/39680)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.113% (39057/39808)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.117% (39184/39936)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.118% (39310/40064)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.122% (39437/40192)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.127% (39565/40320)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.133% (39693/40448)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.134% (39819/40576)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.135% (39945/40704)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.134% (40070/40832)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.132% (40195/40960)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.136% (40322/41088)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.137% (40448/41216)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.138% (40574/41344)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.126% (40695/41472)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.111% (40814/41600)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.114% (40941/41728)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.110% (41065/41856)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.106% (41189/41984)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.105% (41314/42112)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.099% (41437/42240)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.098% (41562/42368)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.096% (41687/42496)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.095% (41812/42624)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.091% (41936/42752)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.088% (42060/42880)\n",
      "Train Epoch: 68 | Loss: 0.056 | Acc: 98.091% (42187/43008)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.090% (42312/43136)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.088% (42437/43264)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.078% (42558/43392)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.070% (42680/43520)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.069% (42805/43648)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.070% (42931/43776)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.073% (43058/43904)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.067% (43181/44032)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.066% (43306/44160)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.069% (43433/44288)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.075% (43561/44416)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.067% (43683/44544)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.070% (43810/44672)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.067% (43934/44800)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.064% (44058/44928)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.065% (44184/45056)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.068% (44311/45184)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.069% (44437/45312)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.063% (44560/45440)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.062% (44685/45568)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.065% (44812/45696)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.069% (44939/45824)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.074% (45067/45952)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.071% (45191/46080)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.065% (45314/46208)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.068% (45441/46336)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.059% (45562/46464)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.060% (45688/46592)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.057% (45812/46720)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.051% (45935/46848)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.050% (46060/46976)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.051% (46186/47104)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (46310/47232)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.047% (46435/47360)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (46561/47488)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.049% (46687/47616)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (46812/47744)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (46935/47872)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.044% (47061/48000)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (47186/48128)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.044% (47312/48256)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (47437/48384)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.042% (47562/48512)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (47688/48640)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (47816/48768)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.053% (47944/48896)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (48067/49024)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.045% (48191/49152)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.048% (48318/49280)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.043% (48441/49408)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.038% (48564/49536)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.035% (48688/49664)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.034% (48813/49792)\n",
      "Train Epoch: 68 | Loss: 0.058 | Acc: 98.033% (48938/49920)\n",
      "Train Epoch: 68 | Loss: 0.057 | Acc: 98.036% (49018/50000)\n",
      "Test Epoch: 68 | Loss: 0.540 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 68 | Loss: 0.438 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 68 | Loss: 0.363 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 68 | Loss: 0.361 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 68 | Loss: 0.349 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 68 | Loss: 0.308 | Acc: 91.500% (549/600)\n",
      "Test Epoch: 68 | Loss: 0.310 | Acc: 91.714% (642/700)\n",
      "Test Epoch: 68 | Loss: 0.356 | Acc: 91.125% (729/800)\n",
      "Test Epoch: 68 | Loss: 0.364 | Acc: 91.111% (820/900)\n",
      "Test Epoch: 68 | Loss: 0.366 | Acc: 91.000% (910/1000)\n",
      "Test Epoch: 68 | Loss: 0.392 | Acc: 90.273% (993/1100)\n",
      "Test Epoch: 68 | Loss: 0.413 | Acc: 90.083% (1081/1200)\n",
      "Test Epoch: 68 | Loss: 0.405 | Acc: 90.308% (1174/1300)\n",
      "Test Epoch: 68 | Loss: 0.399 | Acc: 90.286% (1264/1400)\n",
      "Test Epoch: 68 | Loss: 0.389 | Acc: 90.400% (1356/1500)\n",
      "Test Epoch: 68 | Loss: 0.379 | Acc: 90.562% (1449/1600)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.647% (1541/1700)\n",
      "Test Epoch: 68 | Loss: 0.375 | Acc: 90.778% (1634/1800)\n",
      "Test Epoch: 68 | Loss: 0.374 | Acc: 90.684% (1723/1900)\n",
      "Test Epoch: 68 | Loss: 0.395 | Acc: 90.400% (1808/2000)\n",
      "Test Epoch: 68 | Loss: 0.402 | Acc: 90.048% (1891/2100)\n",
      "Test Epoch: 68 | Loss: 0.402 | Acc: 89.955% (1979/2200)\n",
      "Test Epoch: 68 | Loss: 0.399 | Acc: 89.957% (2069/2300)\n",
      "Test Epoch: 68 | Loss: 0.394 | Acc: 89.917% (2158/2400)\n",
      "Test Epoch: 68 | Loss: 0.402 | Acc: 89.920% (2248/2500)\n",
      "Test Epoch: 68 | Loss: 0.416 | Acc: 89.731% (2333/2600)\n",
      "Test Epoch: 68 | Loss: 0.407 | Acc: 89.926% (2428/2700)\n",
      "Test Epoch: 68 | Loss: 0.408 | Acc: 89.821% (2515/2800)\n",
      "Test Epoch: 68 | Loss: 0.410 | Acc: 89.828% (2605/2900)\n",
      "Test Epoch: 68 | Loss: 0.414 | Acc: 89.733% (2692/3000)\n",
      "Test Epoch: 68 | Loss: 0.415 | Acc: 89.645% (2779/3100)\n",
      "Test Epoch: 68 | Loss: 0.414 | Acc: 89.688% (2870/3200)\n",
      "Test Epoch: 68 | Loss: 0.415 | Acc: 89.515% (2954/3300)\n",
      "Test Epoch: 68 | Loss: 0.411 | Acc: 89.618% (3047/3400)\n",
      "Test Epoch: 68 | Loss: 0.415 | Acc: 89.486% (3132/3500)\n",
      "Test Epoch: 68 | Loss: 0.416 | Acc: 89.583% (3225/3600)\n",
      "Test Epoch: 68 | Loss: 0.424 | Acc: 89.541% (3313/3700)\n",
      "Test Epoch: 68 | Loss: 0.427 | Acc: 89.579% (3404/3800)\n",
      "Test Epoch: 68 | Loss: 0.427 | Acc: 89.538% (3492/3900)\n",
      "Test Epoch: 68 | Loss: 0.425 | Acc: 89.525% (3581/4000)\n",
      "Test Epoch: 68 | Loss: 0.427 | Acc: 89.463% (3668/4100)\n",
      "Test Epoch: 68 | Loss: 0.426 | Acc: 89.524% (3760/4200)\n",
      "Test Epoch: 68 | Loss: 0.418 | Acc: 89.674% (3856/4300)\n",
      "Test Epoch: 68 | Loss: 0.421 | Acc: 89.727% (3948/4400)\n",
      "Test Epoch: 68 | Loss: 0.417 | Acc: 89.844% (4043/4500)\n",
      "Test Epoch: 68 | Loss: 0.415 | Acc: 89.848% (4133/4600)\n",
      "Test Epoch: 68 | Loss: 0.414 | Acc: 89.872% (4224/4700)\n",
      "Test Epoch: 68 | Loss: 0.413 | Acc: 89.854% (4313/4800)\n",
      "Test Epoch: 68 | Loss: 0.411 | Acc: 89.959% (4408/4900)\n",
      "Test Epoch: 68 | Loss: 0.413 | Acc: 89.900% (4495/5000)\n",
      "Test Epoch: 68 | Loss: 0.409 | Acc: 89.980% (4589/5100)\n",
      "Test Epoch: 68 | Loss: 0.409 | Acc: 89.904% (4675/5200)\n",
      "Test Epoch: 68 | Loss: 0.410 | Acc: 89.868% (4763/5300)\n",
      "Test Epoch: 68 | Loss: 0.408 | Acc: 89.889% (4854/5400)\n",
      "Test Epoch: 68 | Loss: 0.405 | Acc: 89.909% (4945/5500)\n",
      "Test Epoch: 68 | Loss: 0.406 | Acc: 89.875% (5033/5600)\n",
      "Test Epoch: 68 | Loss: 0.405 | Acc: 89.877% (5123/5700)\n",
      "Test Epoch: 68 | Loss: 0.402 | Acc: 89.914% (5215/5800)\n",
      "Test Epoch: 68 | Loss: 0.402 | Acc: 89.881% (5303/5900)\n",
      "Test Epoch: 68 | Loss: 0.400 | Acc: 89.883% (5393/6000)\n",
      "Test Epoch: 68 | Loss: 0.400 | Acc: 89.902% (5484/6100)\n",
      "Test Epoch: 68 | Loss: 0.397 | Acc: 89.968% (5578/6200)\n",
      "Test Epoch: 68 | Loss: 0.395 | Acc: 90.016% (5671/6300)\n",
      "Test Epoch: 68 | Loss: 0.392 | Acc: 90.094% (5766/6400)\n",
      "Test Epoch: 68 | Loss: 0.390 | Acc: 90.123% (5858/6500)\n",
      "Test Epoch: 68 | Loss: 0.388 | Acc: 90.091% (5946/6600)\n",
      "Test Epoch: 68 | Loss: 0.387 | Acc: 90.149% (6040/6700)\n",
      "Test Epoch: 68 | Loss: 0.387 | Acc: 90.162% (6131/6800)\n",
      "Test Epoch: 68 | Loss: 0.385 | Acc: 90.188% (6223/6900)\n",
      "Test Epoch: 68 | Loss: 0.385 | Acc: 90.157% (6311/7000)\n",
      "Test Epoch: 68 | Loss: 0.389 | Acc: 90.141% (6400/7100)\n",
      "Test Epoch: 68 | Loss: 0.390 | Acc: 90.153% (6491/7200)\n",
      "Test Epoch: 68 | Loss: 0.389 | Acc: 90.178% (6583/7300)\n",
      "Test Epoch: 68 | Loss: 0.389 | Acc: 90.203% (6675/7400)\n",
      "Test Epoch: 68 | Loss: 0.388 | Acc: 90.240% (6768/7500)\n",
      "Test Epoch: 68 | Loss: 0.387 | Acc: 90.263% (6860/7600)\n",
      "Test Epoch: 68 | Loss: 0.387 | Acc: 90.286% (6952/7700)\n",
      "Test Epoch: 68 | Loss: 0.386 | Acc: 90.282% (7042/7800)\n",
      "Test Epoch: 68 | Loss: 0.386 | Acc: 90.228% (7128/7900)\n",
      "Test Epoch: 68 | Loss: 0.388 | Acc: 90.200% (7216/8000)\n",
      "Test Epoch: 68 | Loss: 0.384 | Acc: 90.259% (7311/8100)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.293% (7404/8200)\n",
      "Test Epoch: 68 | Loss: 0.382 | Acc: 90.289% (7494/8300)\n",
      "Test Epoch: 68 | Loss: 0.382 | Acc: 90.286% (7584/8400)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.247% (7671/8500)\n",
      "Test Epoch: 68 | Loss: 0.385 | Acc: 90.221% (7759/8600)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.230% (7850/8700)\n",
      "Test Epoch: 68 | Loss: 0.384 | Acc: 90.227% (7940/8800)\n",
      "Test Epoch: 68 | Loss: 0.384 | Acc: 90.213% (8029/8900)\n",
      "Test Epoch: 68 | Loss: 0.387 | Acc: 90.144% (8113/9000)\n",
      "Test Epoch: 68 | Loss: 0.386 | Acc: 90.154% (8204/9100)\n",
      "Test Epoch: 68 | Loss: 0.384 | Acc: 90.196% (8298/9200)\n",
      "Test Epoch: 68 | Loss: 0.385 | Acc: 90.204% (8389/9300)\n",
      "Test Epoch: 68 | Loss: 0.384 | Acc: 90.213% (8480/9400)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.232% (8572/9500)\n",
      "Test Epoch: 68 | Loss: 0.383 | Acc: 90.240% (8663/9600)\n",
      "Test Epoch: 68 | Loss: 0.381 | Acc: 90.278% (8757/9700)\n",
      "Test Epoch: 68 | Loss: 0.381 | Acc: 90.306% (8850/9800)\n",
      "Test Epoch: 68 | Loss: 0.382 | Acc: 90.293% (8939/9900)\n",
      "Test Epoch: 68 | Loss: 0.381 | Acc: 90.320% (9032/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Train Epoch: 69 | Loss: 0.039 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 69 | Loss: 0.031 | Acc: 99.219% (254/256)\n",
      "Train Epoch: 69 | Loss: 0.039 | Acc: 98.958% (380/384)\n",
      "Train Epoch: 69 | Loss: 0.039 | Acc: 98.828% (506/512)\n",
      "Train Epoch: 69 | Loss: 0.038 | Acc: 98.906% (633/640)\n",
      "Train Epoch: 69 | Loss: 0.048 | Acc: 98.698% (758/768)\n",
      "Train Epoch: 69 | Loss: 0.043 | Acc: 98.884% (886/896)\n",
      "Train Epoch: 69 | Loss: 0.042 | Acc: 98.926% (1013/1024)\n",
      "Train Epoch: 69 | Loss: 0.046 | Acc: 98.785% (1138/1152)\n",
      "Train Epoch: 69 | Loss: 0.047 | Acc: 98.672% (1263/1280)\n",
      "Train Epoch: 69 | Loss: 0.048 | Acc: 98.651% (1389/1408)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.503% (1513/1536)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.377% (1637/1664)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.270% (1761/1792)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.333% (1888/1920)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.389% (2015/2048)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.392% (2141/2176)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.394% (2267/2304)\n",
      "Train Epoch: 69 | Loss: 0.050 | Acc: 98.438% (2394/2432)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.398% (2519/2560)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.363% (2644/2688)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.260% (2767/2816)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.302% (2894/2944)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.340% (3021/3072)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.312% (3146/3200)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.287% (3271/3328)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.322% (3398/3456)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.354% (3525/3584)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.357% (3651/3712)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.385% (3778/3840)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.387% (3904/3968)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.389% (4030/4096)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.414% (4157/4224)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.415% (4283/4352)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.348% (4406/4480)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.329% (4531/4608)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.332% (4657/4736)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.314% (4782/4864)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.277% (4906/4992)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.281% (5032/5120)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.304% (5159/5248)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.289% (5284/5376)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.274% (5409/5504)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.278% (5535/5632)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.299% (5662/5760)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.302% (5788/5888)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.288% (5913/6016)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.291% (6039/6144)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.278% (6164/6272)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.281% (6290/6400)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.254% (6414/6528)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.287% (6542/6656)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.275% (6667/6784)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.278% (6793/6912)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.295% (6920/7040)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.312% (7047/7168)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.328% (7174/7296)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.357% (7302/7424)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.332% (7426/7552)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.359% (7554/7680)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.386% (7682/7808)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.374% (7807/7936)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.351% (7931/8064)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.328% (8055/8192)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.353% (8183/8320)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.355% (8309/8448)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.356% (8435/8576)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.357% (8561/8704)\n",
      "Train Epoch: 69 | Loss: 0.051 | Acc: 98.336% (8685/8832)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.326% (8810/8960)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.349% (8938/9088)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.340% (9063/9216)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.320% (9187/9344)\n",
      "Train Epoch: 69 | Loss: 0.052 | Acc: 98.311% (9312/9472)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.271% (9434/9600)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.263% (9559/9728)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.245% (9683/9856)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.237% (9808/9984)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.230% (9933/10112)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.232% (10059/10240)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.235% (10185/10368)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.237% (10311/10496)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.259% (10439/10624)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.242% (10563/10752)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.226% (10687/10880)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.238% (10814/11008)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.249% (10941/11136)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.251% (11067/11264)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.244% (11192/11392)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.238% (11317/11520)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.231% (11442/11648)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.225% (11567/11776)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.227% (11693/11904)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.205% (11816/12032)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.215% (11943/12160)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.210% (12068/12288)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.212% (12194/12416)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.230% (12322/12544)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.209% (12445/12672)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.219% (12572/12800)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.213% (12697/12928)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.200% (12821/13056)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.218% (12949/13184)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.212% (13074/13312)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.222% (13201/13440)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.216% (13326/13568)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (13451/13696)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.213% (13577/13824)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (13702/13952)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.224% (13830/14080)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.240% (13958/14208)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.242% (14084/14336)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.244% (14210/14464)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.252% (14337/14592)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.254% (14463/14720)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.262% (14590/14848)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.237% (14712/14976)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.219% (14835/15104)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (14959/15232)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.216% (15086/15360)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.205% (15210/15488)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.201% (15335/15616)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (15462/15744)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.204% (15587/15872)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.219% (15715/16000)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.214% (15840/16128)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.228% (15968/16256)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.224% (16093/16384)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.238% (16221/16512)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.239% (16347/16640)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.247% (16474/16768)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.254% (16601/16896)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.250% (16726/17024)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.251% (16852/17152)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.235% (16975/17280)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.236% (17101/17408)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.227% (17225/17536)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.234% (17352/17664)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.241% (17479/17792)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.253% (17607/17920)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.255% (17733/18048)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.250% (17858/18176)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.246% (17983/18304)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.258% (18111/18432)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.265% (18238/18560)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.266% (18364/18688)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.273% (18491/18816)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.274% (18617/18944)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.270% (18742/19072)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.260% (18866/19200)\n",
      "Train Epoch: 69 | Loss: 0.053 | Acc: 98.262% (18992/19328)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.247% (19115/19456)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.243% (19240/19584)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.240% (19365/19712)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.231% (19489/19840)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.222% (19613/19968)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.229% (19740/20096)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.235% (19867/20224)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.231% (19992/20352)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.232% (20118/20480)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.224% (20242/20608)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.206% (20364/20736)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.207% (20490/20864)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (20616/20992)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.201% (20740/21120)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.193% (20864/21248)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.190% (20989/21376)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.186% (21114/21504)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (21242/21632)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (21366/21760)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.182% (21490/21888)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.183% (21616/22016)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.194% (21744/22144)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.191% (21869/22272)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (21995/22400)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.189% (22120/22528)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.190% (22246/22656)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.183% (22370/22784)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.184% (22496/22912)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.181% (22621/23040)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.179% (22746/23168)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.184% (22873/23296)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.177% (22997/23424)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.174% (23122/23552)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.159% (23244/23680)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.164% (23371/23808)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.162% (23496/23936)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.159% (23621/24064)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.161% (23747/24192)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.162% (23873/24320)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.159% (23998/24448)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.153% (24122/24576)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.158% (24249/24704)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.164% (24376/24832)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.165% (24502/24960)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.162% (24627/25088)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.156% (24751/25216)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.165% (24879/25344)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.163% (25004/25472)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.168% (25131/25600)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.173% (25258/25728)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.175% (25384/25856)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.183% (25512/25984)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.185% (25638/26112)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.186% (25764/26240)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.180% (25888/26368)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.185% (26015/26496)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.193% (26143/26624)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.187% (26267/26752)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.188% (26393/26880)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.186% (26518/27008)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.191% (26645/27136)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (26771/27264)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.186% (26895/27392)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (27022/27520)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (27148/27648)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.196% (27275/27776)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.201% (27402/27904)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.195% (27526/28032)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (27650/28160)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (27776/28288)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.191% (27902/28416)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (28028/28544)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (28153/28672)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.194% (28280/28800)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.196% (28406/28928)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (28532/29056)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.201% (28659/29184)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.199% (28784/29312)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.200% (28910/29440)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (29035/29568)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.195% (29160/29696)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.196% (29286/29824)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (29412/29952)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.198% (29538/30080)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.202% (29665/30208)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.207% (29792/30336)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (29918/30464)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.212% (30045/30592)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.206% (30169/30720)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.214% (30297/30848)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.215% (30423/30976)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.212% (30548/31104)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.217% (30675/31232)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.217% (30801/31360)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.218% (30927/31488)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.216% (31052/31616)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.204% (31174/31744)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.205% (31300/31872)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.206% (31426/32000)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.204% (31551/32128)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.196% (31674/32256)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.197% (31800/32384)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.195% (31925/32512)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.202% (32053/32640)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.199% (32178/32768)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.194% (32302/32896)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.195% (32428/33024)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.184% (32550/33152)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.188% (32677/33280)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.189% (32803/33408)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.193% (32930/33536)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.191% (33055/33664)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (33180/33792)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.187% (33305/33920)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.185% (33430/34048)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.183% (33555/34176)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.181% (33680/34304)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.182% (33806/34432)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.186% (33933/34560)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.190% (34060/34688)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.190% (34186/34816)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.191% (34312/34944)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.184% (34435/35072)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.185% (34561/35200)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.186% (34687/35328)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (34814/35456)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.196% (34942/35584)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.199% (35069/35712)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.198% (35194/35840)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.193% (35318/35968)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.194% (35444/36096)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (35569/36224)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.193% (35695/36352)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.199% (35823/36480)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.194% (35947/36608)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.187% (36070/36736)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.185% (36195/36864)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.186% (36321/36992)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (36448/37120)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.185% (36572/37248)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.191% (36700/37376)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.195% (36827/37504)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.193% (36952/37632)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.199% (37080/37760)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.200% (37206/37888)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.203% (37333/38016)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.202% (37458/38144)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.200% (37583/38272)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.203% (37710/38400)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.206% (37837/38528)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.212% (37965/38656)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.213% (38091/38784)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (38215/38912)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.207% (38340/39040)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.210% (38467/39168)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (38592/39296)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (38718/39424)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.207% (38843/39552)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (38970/39680)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (39095/39808)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.215% (39223/39936)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.220% (39351/40064)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.221% (39477/40192)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.224% (39604/40320)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.227% (39731/40448)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.223% (39855/40576)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.216% (39978/40704)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.215% (40103/40832)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.215% (40229/40960)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (40353/41088)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.214% (40480/41216)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.215% (40606/41344)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.218% (40733/41472)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.224% (40861/41600)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.217% (40984/41728)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (41107/41856)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (41233/41984)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.214% (41360/42112)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.210% (41484/42240)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (41609/42368)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.207% (41734/42496)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (41860/42624)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (41986/42752)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.214% (42114/42880)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.217% (42241/43008)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.210% (42364/43136)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.209% (42489/43264)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.205% (42613/43392)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.203% (42738/43520)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.204% (42864/43648)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.204% (42990/43776)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.198% (43113/43904)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.194% (43237/44032)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (43360/44160)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (43486/44288)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (43611/44416)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (43737/44544)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.191% (43864/44672)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.196% (43992/44800)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (44114/44928)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.187% (44239/45056)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (44367/45184)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (44491/45312)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (44617/45440)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (44743/45568)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.192% (44870/45696)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (44998/45824)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.198% (45124/45952)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.199% (45250/46080)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (45375/46208)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.198% (45501/46336)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.199% (45627/46464)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.197% (45752/46592)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.200% (45879/46720)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.205% (46007/46848)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.205% (46133/46976)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (46260/47104)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (46387/47232)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.209% (46512/47360)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.208% (46637/47488)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.209% (46763/47616)\n",
      "Train Epoch: 69 | Loss: 0.054 | Acc: 98.211% (46890/47744)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.206% (47013/47872)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.200% (47136/48000)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.203% (47263/48128)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.205% (47390/48256)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.206% (47516/48384)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.205% (47641/48512)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.201% (47765/48640)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.200% (47890/48768)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.198% (48015/48896)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.195% (48139/49024)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.193% (48264/49152)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.194% (48390/49280)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (48513/49408)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.189% (48639/49536)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.188% (48764/49664)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.190% (48891/49792)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.193% (49018/49920)\n",
      "Train Epoch: 69 | Loss: 0.055 | Acc: 98.196% (49098/50000)\n",
      "Test Epoch: 69 | Loss: 0.404 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 69 | Loss: 0.345 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 69 | Loss: 0.329 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 69 | Loss: 0.366 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 69 | Loss: 0.388 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 69 | Loss: 0.343 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 69 | Loss: 0.355 | Acc: 91.286% (639/700)\n",
      "Test Epoch: 69 | Loss: 0.395 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 69 | Loss: 0.399 | Acc: 90.222% (812/900)\n",
      "Test Epoch: 69 | Loss: 0.412 | Acc: 90.100% (901/1000)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 89.636% (986/1100)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.667% (1076/1200)\n",
      "Test Epoch: 69 | Loss: 0.436 | Acc: 89.846% (1168/1300)\n",
      "Test Epoch: 69 | Loss: 0.433 | Acc: 90.071% (1261/1400)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 90.200% (1353/1500)\n",
      "Test Epoch: 69 | Loss: 0.414 | Acc: 90.562% (1449/1600)\n",
      "Test Epoch: 69 | Loss: 0.409 | Acc: 90.647% (1541/1700)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 90.444% (1628/1800)\n",
      "Test Epoch: 69 | Loss: 0.422 | Acc: 89.947% (1709/1900)\n",
      "Test Epoch: 69 | Loss: 0.446 | Acc: 89.550% (1791/2000)\n",
      "Test Epoch: 69 | Loss: 0.450 | Acc: 89.333% (1876/2100)\n",
      "Test Epoch: 69 | Loss: 0.451 | Acc: 89.273% (1964/2200)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.348% (2055/2300)\n",
      "Test Epoch: 69 | Loss: 0.439 | Acc: 89.375% (2145/2400)\n",
      "Test Epoch: 69 | Loss: 0.448 | Acc: 89.440% (2236/2500)\n",
      "Test Epoch: 69 | Loss: 0.456 | Acc: 89.423% (2325/2600)\n",
      "Test Epoch: 69 | Loss: 0.445 | Acc: 89.519% (2417/2700)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.571% (2508/2800)\n",
      "Test Epoch: 69 | Loss: 0.446 | Acc: 89.552% (2597/2900)\n",
      "Test Epoch: 69 | Loss: 0.446 | Acc: 89.500% (2685/3000)\n",
      "Test Epoch: 69 | Loss: 0.450 | Acc: 89.355% (2770/3100)\n",
      "Test Epoch: 69 | Loss: 0.447 | Acc: 89.344% (2859/3200)\n",
      "Test Epoch: 69 | Loss: 0.446 | Acc: 89.273% (2946/3300)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.353% (3038/3400)\n",
      "Test Epoch: 69 | Loss: 0.448 | Acc: 89.229% (3123/3500)\n",
      "Test Epoch: 69 | Loss: 0.452 | Acc: 89.250% (3213/3600)\n",
      "Test Epoch: 69 | Loss: 0.459 | Acc: 89.243% (3302/3700)\n",
      "Test Epoch: 69 | Loss: 0.460 | Acc: 89.184% (3389/3800)\n",
      "Test Epoch: 69 | Loss: 0.459 | Acc: 89.256% (3481/3900)\n",
      "Test Epoch: 69 | Loss: 0.461 | Acc: 89.250% (3570/4000)\n",
      "Test Epoch: 69 | Loss: 0.467 | Acc: 89.146% (3655/4100)\n",
      "Test Epoch: 69 | Loss: 0.467 | Acc: 89.143% (3744/4200)\n",
      "Test Epoch: 69 | Loss: 0.461 | Acc: 89.256% (3838/4300)\n",
      "Test Epoch: 69 | Loss: 0.465 | Acc: 89.295% (3929/4400)\n",
      "Test Epoch: 69 | Loss: 0.462 | Acc: 89.378% (4022/4500)\n",
      "Test Epoch: 69 | Loss: 0.463 | Acc: 89.261% (4106/4600)\n",
      "Test Epoch: 69 | Loss: 0.461 | Acc: 89.234% (4194/4700)\n",
      "Test Epoch: 69 | Loss: 0.461 | Acc: 89.250% (4284/4800)\n",
      "Test Epoch: 69 | Loss: 0.456 | Acc: 89.286% (4375/4900)\n",
      "Test Epoch: 69 | Loss: 0.459 | Acc: 89.200% (4460/5000)\n",
      "Test Epoch: 69 | Loss: 0.455 | Acc: 89.275% (4553/5100)\n",
      "Test Epoch: 69 | Loss: 0.457 | Acc: 89.231% (4640/5200)\n",
      "Test Epoch: 69 | Loss: 0.456 | Acc: 89.226% (4729/5300)\n",
      "Test Epoch: 69 | Loss: 0.455 | Acc: 89.222% (4818/5400)\n",
      "Test Epoch: 69 | Loss: 0.451 | Acc: 89.273% (4910/5500)\n",
      "Test Epoch: 69 | Loss: 0.458 | Acc: 89.250% (4998/5600)\n",
      "Test Epoch: 69 | Loss: 0.455 | Acc: 89.298% (5090/5700)\n",
      "Test Epoch: 69 | Loss: 0.452 | Acc: 89.379% (5184/5800)\n",
      "Test Epoch: 69 | Loss: 0.452 | Acc: 89.356% (5272/5900)\n",
      "Test Epoch: 69 | Loss: 0.451 | Acc: 89.350% (5361/6000)\n",
      "Test Epoch: 69 | Loss: 0.451 | Acc: 89.393% (5453/6100)\n",
      "Test Epoch: 69 | Loss: 0.449 | Acc: 89.403% (5543/6200)\n",
      "Test Epoch: 69 | Loss: 0.449 | Acc: 89.413% (5633/6300)\n",
      "Test Epoch: 69 | Loss: 0.445 | Acc: 89.453% (5725/6400)\n",
      "Test Epoch: 69 | Loss: 0.444 | Acc: 89.431% (5813/6500)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.455% (5904/6600)\n",
      "Test Epoch: 69 | Loss: 0.437 | Acc: 89.522% (5998/6700)\n",
      "Test Epoch: 69 | Loss: 0.439 | Acc: 89.500% (6086/6800)\n",
      "Test Epoch: 69 | Loss: 0.438 | Acc: 89.464% (6173/6900)\n",
      "Test Epoch: 69 | Loss: 0.439 | Acc: 89.414% (6259/7000)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.380% (6346/7100)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.417% (6438/7200)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.438% (6529/7300)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.446% (6619/7400)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.453% (6709/7500)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.461% (6799/7600)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.481% (6890/7700)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.474% (6979/7800)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.456% (7067/7900)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.400% (7152/8000)\n",
      "Test Epoch: 69 | Loss: 0.439 | Acc: 89.457% (7246/8100)\n",
      "Test Epoch: 69 | Loss: 0.437 | Acc: 89.500% (7339/8200)\n",
      "Test Epoch: 69 | Loss: 0.438 | Acc: 89.446% (7424/8300)\n",
      "Test Epoch: 69 | Loss: 0.439 | Acc: 89.417% (7511/8400)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.353% (7595/8500)\n",
      "Test Epoch: 69 | Loss: 0.443 | Acc: 89.326% (7682/8600)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.333% (7772/8700)\n",
      "Test Epoch: 69 | Loss: 0.444 | Acc: 89.341% (7862/8800)\n",
      "Test Epoch: 69 | Loss: 0.443 | Acc: 89.326% (7950/8900)\n",
      "Test Epoch: 69 | Loss: 0.445 | Acc: 89.300% (8037/9000)\n",
      "Test Epoch: 69 | Loss: 0.443 | Acc: 89.308% (8127/9100)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.359% (8221/9200)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.355% (8310/9300)\n",
      "Test Epoch: 69 | Loss: 0.443 | Acc: 89.362% (8400/9400)\n",
      "Test Epoch: 69 | Loss: 0.442 | Acc: 89.368% (8490/9500)\n",
      "Test Epoch: 69 | Loss: 0.441 | Acc: 89.406% (8583/9600)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.454% (8677/9700)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.459% (8767/9800)\n",
      "Test Epoch: 69 | Loss: 0.440 | Acc: 89.495% (8860/9900)\n",
      "Test Epoch: 69 | Loss: 0.438 | Acc: 89.530% (8953/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Train Epoch: 70 | Loss: 0.023 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 70 | Loss: 0.066 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 70 | Loss: 0.059 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.242% (503/512)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (630/640)\n",
      "Train Epoch: 70 | Loss: 0.044 | Acc: 98.698% (758/768)\n",
      "Train Epoch: 70 | Loss: 0.046 | Acc: 98.438% (882/896)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.340% (1007/1024)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.177% (1131/1152)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.359% (1259/1280)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.366% (1385/1408)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.438% (1512/1536)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.377% (1637/1664)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.438% (1764/1792)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.542% (1892/1920)\n",
      "Train Epoch: 70 | Loss: 0.047 | Acc: 98.584% (2019/2048)\n",
      "Train Epoch: 70 | Loss: 0.047 | Acc: 98.575% (2145/2176)\n",
      "Train Epoch: 70 | Loss: 0.047 | Acc: 98.611% (2272/2304)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.561% (2397/2432)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.320% (2517/2560)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.363% (2644/2688)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.295% (2768/2816)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.336% (2895/2944)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.340% (3021/3072)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.406% (3149/3200)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.287% (3271/3328)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.293% (3397/3456)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.326% (3524/3584)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.384% (3652/3712)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.333% (3776/3840)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.362% (3903/3968)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.389% (4030/4096)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.319% (4153/4224)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.346% (4280/4352)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.326% (4405/4480)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.329% (4531/4608)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.311% (4656/4736)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.314% (4782/4864)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.277% (4906/4992)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.301% (5033/5120)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.342% (5161/5248)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.344% (5287/5376)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.347% (5413/5504)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.331% (5538/5632)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.333% (5664/5760)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.353% (5791/5888)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.354% (5917/6016)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.389% (6045/6144)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.406% (6172/6272)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (6300/6400)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.453% (6427/6528)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.453% (6553/6656)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.438% (6678/6784)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.423% (6803/6912)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (6930/7040)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (7056/7168)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.451% (7183/7296)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.424% (7307/7424)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.424% (7433/7552)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.411% (7558/7680)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.425% (7685/7808)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.425% (7811/7936)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.450% (7939/8064)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.450% (8065/8192)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.438% (8190/8320)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.449% (8317/8448)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.461% (8444/8576)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.449% (8569/8704)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.415% (8692/8832)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.415% (8818/8960)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.415% (8944/9088)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (9072/9216)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.427% (9197/9344)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.438% (9324/9472)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.427% (9449/9600)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.448% (9577/9728)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.458% (9704/9856)\n",
      "Train Epoch: 70 | Loss: 0.048 | Acc: 98.448% (9829/9984)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.408% (9951/10112)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.398% (10076/10240)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.409% (10203/10368)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.399% (10328/10496)\n",
      "Train Epoch: 70 | Loss: 0.049 | Acc: 98.400% (10454/10624)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.382% (10578/10752)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.355% (10701/10880)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.365% (10828/11008)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.357% (10953/11136)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.331% (11076/11264)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.323% (11201/11392)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.316% (11326/11520)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.326% (11453/11648)\n",
      "Train Epoch: 70 | Loss: 0.050 | Acc: 98.336% (11580/11776)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.320% (11704/11904)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.321% (11830/12032)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.322% (11956/12160)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.324% (12082/12288)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.317% (12207/12416)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.318% (12333/12544)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.327% (12460/12672)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.328% (12586/12800)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.321% (12711/12928)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.307% (12835/13056)\n",
      "Train Epoch: 70 | Loss: 0.051 | Acc: 98.301% (12960/13184)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.280% (13083/13312)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.274% (13208/13440)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.246% (13330/13568)\n",
      "Train Epoch: 70 | Loss: 0.052 | Acc: 98.240% (13455/13696)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.228% (13579/13824)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.215% (13703/13952)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.224% (13830/14080)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.233% (13957/14208)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.221% (14081/14336)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.209% (14205/14464)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.204% (14330/14592)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.207% (14456/14720)\n",
      "Train Epoch: 70 | Loss: 0.053 | Acc: 98.195% (14580/14848)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.177% (14703/14976)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.193% (14831/15104)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.175% (14954/15232)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.184% (15081/15360)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.179% (15206/15488)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.175% (15331/15616)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.183% (15458/15744)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.179% (15583/15872)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.175% (15708/16000)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.183% (15835/16128)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.191% (15962/16256)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.199% (16089/16384)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.207% (16216/16512)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.191% (16339/16640)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.199% (16466/16768)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.195% (16591/16896)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.185% (16715/17024)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.175% (16839/17152)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.160% (16962/17280)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.173% (17090/17408)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.175% (17216/17536)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.171% (17341/17664)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.173% (17467/17792)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (17592/17920)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.183% (17720/18048)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (17845/18176)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.175% (17970/18304)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.161% (18093/18432)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.147% (18216/18560)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.149% (18342/18688)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.151% (18468/18816)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.152% (18594/18944)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.160% (18721/19072)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.161% (18847/19200)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.158% (18972/19328)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.150% (19096/19456)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.146% (19221/19584)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.128% (19343/19712)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.135% (19470/19840)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.142% (19597/19968)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.149% (19724/20096)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.141% (19848/20224)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.138% (19973/20352)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.145% (20100/20480)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.146% (20226/20608)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.158% (20354/20736)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.140% (20476/20864)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.152% (20604/20992)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.153% (20730/21120)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.155% (20856/21248)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.161% (20983/21376)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.163% (21109/21504)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.151% (21232/21632)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.157% (21359/21760)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.150% (21483/21888)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.147% (21608/22016)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.135% (21731/22144)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.137% (21857/22272)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.138% (21983/22400)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.145% (22110/22528)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.151% (22237/22656)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.139% (22360/22784)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.132% (22484/22912)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.129% (22609/23040)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.122% (22733/23168)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.124% (22859/23296)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.126% (22985/23424)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.132% (23112/23552)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.138% (23239/23680)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.143% (23366/23808)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.149% (23493/23936)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.155% (23620/24064)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.152% (23745/24192)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.141% (23868/24320)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.135% (23992/24448)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.136% (24118/24576)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.130% (24242/24704)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.131% (24368/24832)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.129% (24493/24960)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.123% (24617/25088)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.124% (24743/25216)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.126% (24869/25344)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.123% (24994/25472)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.117% (25118/25600)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.119% (25244/25728)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.120% (25370/25856)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.107% (25492/25984)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.097% (25615/26112)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.095% (25740/26240)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.096% (25866/26368)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.102% (25993/26496)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.107% (26120/26624)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.105% (26245/26752)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.103% (26370/26880)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.112% (26498/27008)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.110% (26623/27136)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.111% (26749/27264)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.116% (26876/27392)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.118% (27002/27520)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.123% (27129/27648)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.117% (27253/27776)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.119% (27379/27904)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.124% (27506/28032)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.125% (27632/28160)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.119% (27756/28288)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.121% (27882/28416)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.119% (28007/28544)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.127% (28135/28672)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.132% (28262/28800)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.126% (28386/28928)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.128% (28512/29056)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.133% (28639/29184)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.137% (28766/29312)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.139% (28892/29440)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.136% (29017/29568)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.138% (29143/29696)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.136% (29268/29824)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.127% (29391/29952)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.125% (29516/30080)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.123% (29641/30208)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.118% (29765/30336)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.119% (29891/30464)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.127% (30019/30592)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.122% (30143/30720)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.120% (30268/30848)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.118% (30393/30976)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.126% (30521/31104)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.127% (30647/31232)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.131% (30774/31360)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.136% (30901/31488)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.134% (31026/31616)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.135% (31152/31744)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.136% (31278/31872)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.128% (31401/32000)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.129% (31527/32128)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.121% (31650/32256)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.126% (31777/32384)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.127% (31903/32512)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.128% (32029/32640)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.129% (32155/32768)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.121% (32278/32896)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.120% (32403/33024)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.121% (32529/33152)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.122% (32655/33280)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.111% (32777/33408)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.115% (32904/33536)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.114% (33029/33664)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.112% (33154/33792)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.110% (33279/33920)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.111% (33405/34048)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.107% (33529/34176)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.105% (33654/34304)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.106% (33780/34432)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.111% (33907/34560)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.106% (34031/34688)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.107% (34157/34816)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.111% (34284/34944)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.115% (34411/35072)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.114% (34536/35200)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.109% (34660/35328)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.110% (34786/35456)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.114% (34913/35584)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.113% (35038/35712)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.114% (35164/35840)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.109% (35288/35968)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.108% (35413/36096)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.115% (35541/36224)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.116% (35667/36352)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.111% (35791/36480)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.112% (35917/36608)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.114% (36043/36736)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.115% (36169/36864)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.116% (36295/36992)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.117% (36421/37120)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.123% (36549/37248)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.127% (36676/37376)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.131% (36803/37504)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.132% (36929/37632)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.133% (37055/37760)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.126% (37178/37888)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.122% (37302/38016)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.120% (37427/38144)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.121% (37553/38272)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.122% (37679/38400)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.129% (37807/38528)\n",
      "Train Epoch: 70 | Loss: 0.056 | Acc: 98.130% (37933/38656)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.133% (38060/38784)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.139% (38188/38912)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.143% (38315/39040)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.144% (38441/39168)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.140% (38565/39296)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.143% (38692/39424)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.144% (38818/39552)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.148% (38945/39680)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.154% (39073/39808)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.152% (39198/39936)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.153% (39324/40064)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.156% (39451/40192)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.157% (39577/40320)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.161% (39704/40448)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.161% (39830/40576)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.167% (39958/40704)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (40086/40832)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.169% (40210/40960)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.167% (40335/41088)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.161% (40458/41216)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.164% (40585/41344)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (40713/41472)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (40840/41600)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.174% (40966/41728)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.172% (41091/41856)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.178% (41219/41984)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.176% (41344/42112)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (41471/42240)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.180% (41597/42368)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.176% (41721/42496)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.177% (41847/42624)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.178% (41973/42752)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.172% (42096/42880)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (42221/43008)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (42348/43136)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.176% (42475/43264)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.175% (42600/43392)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (42725/43520)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.169% (42849/43648)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (42976/43776)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.171% (43101/43904)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.174% (43228/44032)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (43353/44160)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.167% (43476/44288)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (43603/44416)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.175% (43731/44544)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.171% (43855/44672)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.174% (43982/44800)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.175% (44108/44928)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.178% (44235/45056)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.174% (44359/45184)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.173% (44484/45312)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.176% (44611/45440)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.174% (44736/45568)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (44864/45696)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.180% (44990/45824)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (45115/45952)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (45241/46080)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.180% (45367/46208)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (45492/46336)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.179% (45618/46464)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.182% (45745/46592)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.176% (45868/46720)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.171% (45991/46848)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.167% (46115/46976)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (46242/47104)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.171% (46368/47232)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.169% (46493/47360)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.166% (46617/47488)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.164% (46742/47616)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.169% (46870/47744)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.170% (46996/47872)\n",
      "Train Epoch: 70 | Loss: 0.054 | Acc: 98.173% (47123/48000)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.172% (47248/48128)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.172% (47374/48256)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.167% (47497/48384)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.159% (47619/48512)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.164% (47747/48640)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.165% (47873/48768)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.159% (47996/48896)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.156% (48120/49024)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.149% (48242/49152)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.147% (48367/49280)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.146% (48492/49408)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.151% (48620/49536)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.154% (48747/49664)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.154% (48873/49792)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.155% (48999/49920)\n",
      "Train Epoch: 70 | Loss: 0.055 | Acc: 98.158% (49079/50000)\n",
      "Test Epoch: 70 | Loss: 0.405 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 70 | Loss: 0.466 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 70 | Loss: 0.374 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 70 | Loss: 0.372 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 70 | Loss: 0.324 | Acc: 90.000% (540/600)\n",
      "Test Epoch: 70 | Loss: 0.317 | Acc: 90.714% (635/700)\n",
      "Test Epoch: 70 | Loss: 0.374 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 90.333% (813/900)\n",
      "Test Epoch: 70 | Loss: 0.357 | Acc: 90.600% (906/1000)\n",
      "Test Epoch: 70 | Loss: 0.368 | Acc: 90.273% (993/1100)\n",
      "Test Epoch: 70 | Loss: 0.400 | Acc: 90.083% (1081/1200)\n",
      "Test Epoch: 70 | Loss: 0.399 | Acc: 90.000% (1170/1300)\n",
      "Test Epoch: 70 | Loss: 0.397 | Acc: 90.286% (1264/1400)\n",
      "Test Epoch: 70 | Loss: 0.397 | Acc: 90.267% (1354/1500)\n",
      "Test Epoch: 70 | Loss: 0.396 | Acc: 90.375% (1446/1600)\n",
      "Test Epoch: 70 | Loss: 0.398 | Acc: 90.529% (1539/1700)\n",
      "Test Epoch: 70 | Loss: 0.408 | Acc: 90.444% (1628/1800)\n",
      "Test Epoch: 70 | Loss: 0.409 | Acc: 90.316% (1716/1900)\n",
      "Test Epoch: 70 | Loss: 0.421 | Acc: 90.000% (1800/2000)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.667% (1883/2100)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.545% (1970/2200)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.696% (2063/2300)\n",
      "Test Epoch: 70 | Loss: 0.441 | Acc: 89.625% (2151/2400)\n",
      "Test Epoch: 70 | Loss: 0.446 | Acc: 89.360% (2234/2500)\n",
      "Test Epoch: 70 | Loss: 0.462 | Acc: 89.154% (2318/2600)\n",
      "Test Epoch: 70 | Loss: 0.462 | Acc: 89.259% (2410/2700)\n",
      "Test Epoch: 70 | Loss: 0.454 | Acc: 89.393% (2503/2800)\n",
      "Test Epoch: 70 | Loss: 0.463 | Acc: 89.345% (2591/2900)\n",
      "Test Epoch: 70 | Loss: 0.462 | Acc: 89.367% (2681/3000)\n",
      "Test Epoch: 70 | Loss: 0.461 | Acc: 89.226% (2766/3100)\n",
      "Test Epoch: 70 | Loss: 0.455 | Acc: 89.219% (2855/3200)\n",
      "Test Epoch: 70 | Loss: 0.457 | Acc: 89.182% (2943/3300)\n",
      "Test Epoch: 70 | Loss: 0.451 | Acc: 89.324% (3037/3400)\n",
      "Test Epoch: 70 | Loss: 0.456 | Acc: 89.229% (3123/3500)\n",
      "Test Epoch: 70 | Loss: 0.460 | Acc: 89.194% (3211/3600)\n",
      "Test Epoch: 70 | Loss: 0.465 | Acc: 89.216% (3301/3700)\n",
      "Test Epoch: 70 | Loss: 0.471 | Acc: 89.211% (3390/3800)\n",
      "Test Epoch: 70 | Loss: 0.468 | Acc: 89.308% (3483/3900)\n",
      "Test Epoch: 70 | Loss: 0.467 | Acc: 89.325% (3573/4000)\n",
      "Test Epoch: 70 | Loss: 0.467 | Acc: 89.293% (3661/4100)\n",
      "Test Epoch: 70 | Loss: 0.466 | Acc: 89.333% (3752/4200)\n",
      "Test Epoch: 70 | Loss: 0.463 | Acc: 89.419% (3845/4300)\n",
      "Test Epoch: 70 | Loss: 0.466 | Acc: 89.500% (3938/4400)\n",
      "Test Epoch: 70 | Loss: 0.463 | Acc: 89.578% (4031/4500)\n",
      "Test Epoch: 70 | Loss: 0.462 | Acc: 89.522% (4118/4600)\n",
      "Test Epoch: 70 | Loss: 0.460 | Acc: 89.532% (4208/4700)\n",
      "Test Epoch: 70 | Loss: 0.463 | Acc: 89.417% (4292/4800)\n",
      "Test Epoch: 70 | Loss: 0.459 | Acc: 89.551% (4388/4900)\n",
      "Test Epoch: 70 | Loss: 0.461 | Acc: 89.500% (4475/5000)\n",
      "Test Epoch: 70 | Loss: 0.455 | Acc: 89.627% (4571/5100)\n",
      "Test Epoch: 70 | Loss: 0.457 | Acc: 89.558% (4657/5200)\n",
      "Test Epoch: 70 | Loss: 0.460 | Acc: 89.453% (4741/5300)\n",
      "Test Epoch: 70 | Loss: 0.459 | Acc: 89.481% (4832/5400)\n",
      "Test Epoch: 70 | Loss: 0.459 | Acc: 89.491% (4922/5500)\n",
      "Test Epoch: 70 | Loss: 0.461 | Acc: 89.554% (5015/5600)\n",
      "Test Epoch: 70 | Loss: 0.459 | Acc: 89.596% (5107/5700)\n",
      "Test Epoch: 70 | Loss: 0.458 | Acc: 89.621% (5198/5800)\n",
      "Test Epoch: 70 | Loss: 0.459 | Acc: 89.593% (5286/5900)\n",
      "Test Epoch: 70 | Loss: 0.457 | Acc: 89.567% (5374/6000)\n",
      "Test Epoch: 70 | Loss: 0.455 | Acc: 89.639% (5468/6100)\n",
      "Test Epoch: 70 | Loss: 0.453 | Acc: 89.661% (5559/6200)\n",
      "Test Epoch: 70 | Loss: 0.450 | Acc: 89.730% (5653/6300)\n",
      "Test Epoch: 70 | Loss: 0.446 | Acc: 89.812% (5748/6400)\n",
      "Test Epoch: 70 | Loss: 0.443 | Acc: 89.785% (5836/6500)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.848% (5930/6600)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.896% (6023/6700)\n",
      "Test Epoch: 70 | Loss: 0.437 | Acc: 89.897% (6113/6800)\n",
      "Test Epoch: 70 | Loss: 0.434 | Acc: 89.928% (6205/6900)\n",
      "Test Epoch: 70 | Loss: 0.437 | Acc: 89.829% (6288/7000)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.803% (6376/7100)\n",
      "Test Epoch: 70 | Loss: 0.443 | Acc: 89.833% (6468/7200)\n",
      "Test Epoch: 70 | Loss: 0.440 | Acc: 89.849% (6559/7300)\n",
      "Test Epoch: 70 | Loss: 0.440 | Acc: 89.824% (6647/7400)\n",
      "Test Epoch: 70 | Loss: 0.440 | Acc: 89.773% (6733/7500)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.750% (6821/7600)\n",
      "Test Epoch: 70 | Loss: 0.444 | Acc: 89.727% (6909/7700)\n",
      "Test Epoch: 70 | Loss: 0.443 | Acc: 89.744% (7000/7800)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.734% (7089/7900)\n",
      "Test Epoch: 70 | Loss: 0.443 | Acc: 89.737% (7179/8000)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.802% (7274/8100)\n",
      "Test Epoch: 70 | Loss: 0.437 | Acc: 89.866% (7369/8200)\n",
      "Test Epoch: 70 | Loss: 0.437 | Acc: 89.880% (7460/8300)\n",
      "Test Epoch: 70 | Loss: 0.437 | Acc: 89.905% (7552/8400)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.824% (7635/8500)\n",
      "Test Epoch: 70 | Loss: 0.443 | Acc: 89.767% (7720/8600)\n",
      "Test Epoch: 70 | Loss: 0.441 | Acc: 89.782% (7811/8700)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.807% (7903/8800)\n",
      "Test Epoch: 70 | Loss: 0.442 | Acc: 89.809% (7993/8900)\n",
      "Test Epoch: 70 | Loss: 0.441 | Acc: 89.833% (8085/9000)\n",
      "Test Epoch: 70 | Loss: 0.440 | Acc: 89.846% (8176/9100)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.870% (8268/9200)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.882% (8359/9300)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.883% (8449/9400)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.853% (8536/9500)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.844% (8625/9600)\n",
      "Test Epoch: 70 | Loss: 0.436 | Acc: 89.897% (8720/9700)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.878% (8808/9800)\n",
      "Test Epoch: 70 | Loss: 0.439 | Acc: 89.869% (8897/9900)\n",
      "Test Epoch: 70 | Loss: 0.438 | Acc: 89.890% (8989/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Train Epoch: 71 | Loss: 0.035 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 71 | Loss: 0.041 | Acc: 98.828% (253/256)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.698% (379/384)\n",
      "Train Epoch: 71 | Loss: 0.044 | Acc: 98.828% (506/512)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.750% (632/640)\n",
      "Train Epoch: 71 | Loss: 0.037 | Acc: 98.958% (760/768)\n",
      "Train Epoch: 71 | Loss: 0.037 | Acc: 98.772% (885/896)\n",
      "Train Epoch: 71 | Loss: 0.037 | Acc: 98.633% (1010/1024)\n",
      "Train Epoch: 71 | Loss: 0.035 | Acc: 98.698% (1137/1152)\n",
      "Train Epoch: 71 | Loss: 0.041 | Acc: 98.594% (1262/1280)\n",
      "Train Epoch: 71 | Loss: 0.041 | Acc: 98.509% (1387/1408)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.503% (1513/1536)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.257% (1635/1664)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.214% (1760/1792)\n",
      "Train Epoch: 71 | Loss: 0.044 | Acc: 98.333% (1888/1920)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.340% (2014/2048)\n",
      "Train Epoch: 71 | Loss: 0.044 | Acc: 98.392% (2141/2176)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.438% (2268/2304)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.520% (2396/2432)\n",
      "Train Epoch: 71 | Loss: 0.040 | Acc: 98.555% (2523/2560)\n",
      "Train Epoch: 71 | Loss: 0.040 | Acc: 98.549% (2649/2688)\n",
      "Train Epoch: 71 | Loss: 0.040 | Acc: 98.580% (2776/2816)\n",
      "Train Epoch: 71 | Loss: 0.040 | Acc: 98.607% (2903/2944)\n",
      "Train Epoch: 71 | Loss: 0.041 | Acc: 98.568% (3028/3072)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.531% (3153/3200)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.558% (3280/3328)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.582% (3407/3456)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.605% (3534/3584)\n",
      "Train Epoch: 71 | Loss: 0.042 | Acc: 98.572% (3659/3712)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.568% (3785/3840)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.538% (3910/3968)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.560% (4037/4096)\n",
      "Train Epoch: 71 | Loss: 0.043 | Acc: 98.532% (4162/4224)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.483% (4286/4352)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.460% (4411/4480)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.438% (4536/4608)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.480% (4664/4736)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.458% (4789/4864)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.458% (4915/4992)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.496% (5043/5120)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.418% (5165/5248)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.419% (5291/5376)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.419% (5417/5504)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.455% (5545/5632)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.490% (5673/5760)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.454% (5797/5888)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.471% (5924/6016)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.470% (6050/6144)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.501% (6178/6272)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.453% (6301/6400)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.407% (6424/6528)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.422% (6551/6656)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.423% (6677/6784)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.452% (6805/6912)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.466% (6932/7040)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.479% (7059/7168)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.479% (7185/7296)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.478% (7311/7424)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.477% (7437/7552)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.464% (7562/7680)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.463% (7688/7808)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.475% (7815/7936)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.500% (7943/8064)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.523% (8071/8192)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.522% (8197/8320)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.520% (8323/8448)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.531% (8450/8576)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.506% (8574/8704)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.505% (8700/8832)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.516% (8827/8960)\n",
      "Train Epoch: 71 | Loss: 0.045 | Acc: 98.515% (8953/9088)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.513% (9079/9216)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.523% (9206/9344)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.511% (9331/9472)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.521% (9458/9600)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.520% (9584/9728)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.519% (9710/9856)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.508% (9835/9984)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.477% (9958/10112)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.457% (10082/10240)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.447% (10207/10368)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.457% (10334/10496)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.475% (10462/10624)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.475% (10588/10752)\n",
      "Train Epoch: 71 | Loss: 0.046 | Acc: 98.483% (10715/10880)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.474% (10840/11008)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.473% (10966/11136)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.464% (11091/11264)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.455% (11216/11392)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.455% (11342/11520)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.455% (11468/11648)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.463% (11595/11776)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.471% (11722/11904)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.446% (11845/12032)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.429% (11969/12160)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.421% (12094/12288)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.413% (12219/12416)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.414% (12345/12544)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.430% (12473/12672)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.430% (12599/12800)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.422% (12724/12928)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.438% (12852/13056)\n",
      "Train Epoch: 71 | Loss: 0.047 | Acc: 98.430% (12977/13184)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.415% (13101/13312)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.393% (13224/13440)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.401% (13351/13568)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.386% (13475/13696)\n",
      "Train Epoch: 71 | Loss: 0.048 | Acc: 98.387% (13601/13824)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.366% (13724/13952)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.359% (13849/14080)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.360% (13975/14208)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.361% (14101/14336)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.375% (14229/14464)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.369% (14354/14592)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.363% (14479/14720)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.357% (14604/14848)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.357% (14730/14976)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.358% (14856/15104)\n",
      "Train Epoch: 71 | Loss: 0.049 | Acc: 98.352% (14981/15232)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.333% (15104/15360)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.341% (15231/15488)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.335% (15356/15616)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.330% (15481/15744)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.330% (15607/15872)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.331% (15733/16000)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.344% (15861/16128)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.339% (15986/16256)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.340% (16112/16384)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.341% (16238/16512)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.341% (16364/16640)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.342% (16490/16768)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.349% (16617/16896)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.349% (16743/17024)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.338% (16867/17152)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.339% (16993/17280)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.340% (17119/17408)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.329% (17243/17536)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.330% (17369/17664)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.331% (17495/17792)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.337% (17622/17920)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.343% (17749/18048)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.344% (17875/18176)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.350% (18002/18304)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.362% (18130/18432)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.367% (18257/18560)\n",
      "Train Epoch: 71 | Loss: 0.050 | Acc: 98.352% (18380/18688)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.337% (18503/18816)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.327% (18627/18944)\n",
      "Train Epoch: 71 | Loss: 0.051 | Acc: 98.312% (18750/19072)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.286% (18871/19200)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.272% (18994/19328)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.278% (19121/19456)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.284% (19248/19584)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.275% (19372/19712)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.276% (19498/19840)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.277% (19624/19968)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.278% (19750/20096)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.269% (19874/20224)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.261% (19998/20352)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.267% (20125/20480)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.277% (20253/20608)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.269% (20377/20736)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.275% (20504/20864)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.266% (20628/20992)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.248% (20750/21120)\n",
      "Train Epoch: 71 | Loss: 0.052 | Acc: 98.249% (20876/21248)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.246% (21001/21376)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.247% (21127/21504)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.248% (21253/21632)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.249% (21379/21760)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.246% (21504/21888)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.233% (21627/22016)\n",
      "Train Epoch: 71 | Loss: 0.053 | Acc: 98.239% (21754/22144)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.226% (21877/22272)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.219% (22001/22400)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.220% (22127/22528)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.221% (22253/22656)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.218% (22378/22784)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.219% (22504/22912)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.216% (22629/23040)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.209% (22753/23168)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.210% (22879/23296)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.207% (23004/23424)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.195% (23127/23552)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.205% (23255/23680)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.211% (23382/23808)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.216% (23509/23936)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.221% (23636/24064)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.214% (23760/24192)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.211% (23885/24320)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.208% (24010/24448)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.218% (24138/24576)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.215% (24263/24704)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.212% (24388/24832)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.209% (24513/24960)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.210% (24639/25088)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (24763/25216)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.205% (24889/25344)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.206% (25015/25472)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.199% (25139/25600)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (25265/25728)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (25389/25856)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.195% (25515/25984)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.196% (25641/26112)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.201% (25768/26240)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.206% (25895/26368)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (26019/26496)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.190% (26142/26624)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.195% (26269/26752)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.203% (26397/26880)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.201% (26522/27008)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.205% (26649/27136)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.203% (26774/27264)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (26899/27392)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.205% (27026/27520)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.202% (27151/27648)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.207% (27278/27776)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.201% (27402/27904)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.206% (27529/28032)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.203% (27654/28160)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.208% (27781/28288)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.209% (27907/28416)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.210% (28033/28544)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.207% (28158/28672)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.205% (28283/28800)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.202% (28408/28928)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.203% (28534/29056)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.208% (28661/29184)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.216% (28789/29312)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.213% (28914/29440)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.191% (29033/29568)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.182% (29156/29696)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.176% (29280/29824)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.180% (29407/29952)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.182% (29533/30080)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.183% (29659/30208)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.187% (29786/30336)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.188% (29912/30464)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.192% (30039/30592)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (30167/30720)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (30294/30848)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.202% (30419/30976)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.196% (30543/31104)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.191% (30667/31232)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.192% (30793/31360)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.187% (30917/31488)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (31045/31616)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.182% (31167/31744)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.186% (31294/31872)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.181% (31418/32000)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.179% (31543/32128)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.183% (31670/32256)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.184% (31796/32384)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.185% (31922/32512)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.189% (32049/32640)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.187% (32174/32768)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.188% (32300/32896)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.189% (32426/33024)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.190% (32552/33152)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.191% (32678/33280)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.195% (32805/33408)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.202% (32933/33536)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (33058/33664)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (33185/33792)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.202% (33310/33920)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.200% (33435/34048)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.200% (33561/34176)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.201% (33687/34304)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.199% (33812/34432)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (33936/34560)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.195% (34062/34688)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.199% (34189/34816)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (34313/34944)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.198% (34440/35072)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.193% (34564/35200)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.186% (34687/35328)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.189% (34814/35456)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.190% (34940/35584)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (35067/35712)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.192% (35192/35840)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.190% (35317/35968)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.191% (35443/36096)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.189% (35568/36224)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.184% (35692/36352)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.188% (35819/36480)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.192% (35946/36608)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.193% (36072/36736)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.196% (36199/36864)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.194% (36324/36992)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.195% (36450/37120)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.188% (36573/37248)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.189% (36699/37376)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.190% (36825/37504)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.193% (36952/37632)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.199% (37080/37760)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.205% (37208/37888)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.203% (37333/38016)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.199% (37457/38144)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.205% (37585/38272)\n",
      "Train Epoch: 71 | Loss: 0.055 | Acc: 98.206% (37711/38400)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.212% (37839/38528)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.212% (37965/38656)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.211% (38090/38784)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.211% (38216/38912)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (38339/39040)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.203% (38464/39168)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.201% (38589/39296)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (38716/39424)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.202% (38841/39552)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.206% (38968/39680)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.204% (39093/39808)\n",
      "Train Epoch: 71 | Loss: 0.054 | Acc: 98.195% (39215/39936)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.344% (40310/40576)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.339% (40435/40704)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.339% (40562/40832)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.338% (40689/40960)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.340% (40817/41088)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.340% (40944/41216)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.335% (41069/41344)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.330% (41194/41472)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.332% (41322/41600)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.334% (41450/41728)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.331% (41576/41856)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.331% (41703/41984)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.328% (41829/42112)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.330% (41957/42240)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.332% (42085/42368)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.332% (42212/42496)\n",
      "Train Epoch: 96 | Loss: 0.021 | Acc: 99.334% (42340/42624)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.331% (42466/42752)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.331% (42593/42880)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.328% (42719/43008)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.328% (42846/43136)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.327% (42973/43264)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.327% (43100/43392)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.329% (43228/43520)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.329% (43355/43648)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.326% (43481/43776)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.324% (43607/43904)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (43733/44032)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (43860/44160)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.323% (43988/44288)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.325% (44116/44416)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.327% (44244/44544)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.326% (44371/44672)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.328% (44499/44800)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.330% (44627/44928)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.332% (44755/45056)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.329% (44881/45184)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.329% (45008/45312)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.327% (45134/45440)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.324% (45260/45568)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.324% (45387/45696)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (45513/45824)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.323% (45641/45952)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.325% (45769/46080)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.325% (45896/46208)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.327% (46024/46336)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.324% (46150/46464)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.324% (46277/46592)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (46403/46720)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (46530/46848)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.321% (46657/46976)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.323% (46785/47104)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.318% (46910/47232)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.318% (47037/47360)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.318% (47164/47488)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.317% (47291/47616)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.315% (47417/47744)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.317% (47545/47872)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.317% (47672/48000)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.316% (47799/48128)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.314% (47925/48256)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.316% (48053/48384)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.312% (48178/48512)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.313% (48306/48640)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.313% (48433/48768)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.309% (48558/48896)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.311% (48686/49024)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.310% (48813/49152)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.308% (48939/49280)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.308% (49066/49408)\n",
      "Train Epoch: 96 | Loss: 0.022 | Acc: 99.310% (49194/49536)\n",
      "Train Epoch: 96 | Loss: 0.023 | Acc: 99.305% (49319/49664)\n",
      "Train Epoch: 96 | Loss: 0.023 | Acc: 99.305% (49446/49792)\n",
      "Train Epoch: 96 | Loss: 0.023 | Acc: 99.305% (49573/49920)\n",
      "Train Epoch: 96 | Loss: 0.023 | Acc: 99.304% (49652/50000)\n",
      "Test Epoch: 96 | Loss: 0.338 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 96 | Loss: 0.359 | Acc: 92.500% (185/200)\n",
      "Test Epoch: 96 | Loss: 0.324 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 96 | Loss: 0.335 | Acc: 92.000% (368/400)\n",
      "Test Epoch: 96 | Loss: 0.315 | Acc: 92.000% (460/500)\n",
      "Test Epoch: 96 | Loss: 0.280 | Acc: 92.667% (556/600)\n",
      "Test Epoch: 96 | Loss: 0.302 | Acc: 92.571% (648/700)\n",
      "Test Epoch: 96 | Loss: 0.329 | Acc: 91.875% (735/800)\n",
      "Test Epoch: 96 | Loss: 0.334 | Acc: 91.889% (827/900)\n",
      "Test Epoch: 96 | Loss: 0.356 | Acc: 91.600% (916/1000)\n",
      "Test Epoch: 96 | Loss: 0.380 | Acc: 91.455% (1006/1100)\n",
      "Test Epoch: 96 | Loss: 0.408 | Acc: 91.167% (1094/1200)\n",
      "Test Epoch: 96 | Loss: 0.400 | Acc: 91.154% (1185/1300)\n",
      "Test Epoch: 96 | Loss: 0.403 | Acc: 90.857% (1272/1400)\n",
      "Test Epoch: 96 | Loss: 0.393 | Acc: 90.800% (1362/1500)\n",
      "Test Epoch: 96 | Loss: 0.392 | Acc: 90.938% (1455/1600)\n",
      "Test Epoch: 96 | Loss: 0.388 | Acc: 91.118% (1549/1700)\n",
      "Test Epoch: 96 | Loss: 0.382 | Acc: 91.167% (1641/1800)\n",
      "Test Epoch: 96 | Loss: 0.394 | Acc: 90.895% (1727/1900)\n",
      "Test Epoch: 96 | Loss: 0.413 | Acc: 90.650% (1813/2000)\n",
      "Test Epoch: 96 | Loss: 0.428 | Acc: 90.333% (1897/2100)\n",
      "Test Epoch: 96 | Loss: 0.428 | Acc: 90.182% (1984/2200)\n",
      "Test Epoch: 96 | Loss: 0.425 | Acc: 90.304% (2077/2300)\n",
      "Test Epoch: 96 | Loss: 0.421 | Acc: 90.333% (2168/2400)\n",
      "Test Epoch: 96 | Loss: 0.433 | Acc: 90.120% (2253/2500)\n",
      "Test Epoch: 96 | Loss: 0.447 | Acc: 89.962% (2339/2600)\n",
      "Test Epoch: 96 | Loss: 0.439 | Acc: 90.111% (2433/2700)\n",
      "Test Epoch: 96 | Loss: 0.437 | Acc: 90.214% (2526/2800)\n",
      "Test Epoch: 96 | Loss: 0.442 | Acc: 90.207% (2616/2900)\n",
      "Test Epoch: 96 | Loss: 0.439 | Acc: 90.267% (2708/3000)\n",
      "Test Epoch: 96 | Loss: 0.438 | Acc: 90.323% (2800/3100)\n",
      "Test Epoch: 96 | Loss: 0.431 | Acc: 90.469% (2895/3200)\n",
      "Test Epoch: 96 | Loss: 0.434 | Acc: 90.303% (2980/3300)\n",
      "Test Epoch: 96 | Loss: 0.431 | Acc: 90.324% (3071/3400)\n",
      "Test Epoch: 96 | Loss: 0.438 | Acc: 90.229% (3158/3500)\n",
      "Test Epoch: 96 | Loss: 0.441 | Acc: 90.278% (3250/3600)\n",
      "Test Epoch: 96 | Loss: 0.449 | Acc: 90.270% (3340/3700)\n",
      "Test Epoch: 96 | Loss: 0.452 | Acc: 90.184% (3427/3800)\n",
      "Test Epoch: 96 | Loss: 0.448 | Acc: 90.256% (3520/3900)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.200% (3608/4000)\n",
      "Test Epoch: 96 | Loss: 0.458 | Acc: 90.146% (3696/4100)\n",
      "Test Epoch: 96 | Loss: 0.458 | Acc: 90.071% (3783/4200)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.209% (3879/4300)\n",
      "Test Epoch: 96 | Loss: 0.452 | Acc: 90.250% (3971/4400)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.311% (4064/4500)\n",
      "Test Epoch: 96 | Loss: 0.448 | Acc: 90.304% (4154/4600)\n",
      "Test Epoch: 96 | Loss: 0.449 | Acc: 90.255% (4242/4700)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.167% (4328/4800)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.245% (4422/4900)\n",
      "Test Epoch: 96 | Loss: 0.456 | Acc: 90.180% (4509/5000)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.255% (4603/5100)\n",
      "Test Epoch: 96 | Loss: 0.455 | Acc: 90.115% (4686/5200)\n",
      "Test Epoch: 96 | Loss: 0.455 | Acc: 90.132% (4777/5300)\n",
      "Test Epoch: 96 | Loss: 0.457 | Acc: 90.167% (4869/5400)\n",
      "Test Epoch: 96 | Loss: 0.458 | Acc: 90.145% (4958/5500)\n",
      "Test Epoch: 96 | Loss: 0.459 | Acc: 90.143% (5048/5600)\n",
      "Test Epoch: 96 | Loss: 0.461 | Acc: 90.158% (5139/5700)\n",
      "Test Epoch: 96 | Loss: 0.458 | Acc: 90.207% (5232/5800)\n",
      "Test Epoch: 96 | Loss: 0.458 | Acc: 90.220% (5323/5900)\n",
      "Test Epoch: 96 | Loss: 0.457 | Acc: 90.217% (5413/6000)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.230% (5504/6100)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.226% (5594/6200)\n",
      "Test Epoch: 96 | Loss: 0.455 | Acc: 90.206% (5683/6300)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.281% (5778/6400)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.262% (5867/6500)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.303% (5960/6600)\n",
      "Test Epoch: 96 | Loss: 0.448 | Acc: 90.313% (6051/6700)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.309% (6141/6800)\n",
      "Test Epoch: 96 | Loss: 0.448 | Acc: 90.348% (6234/6900)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.329% (6323/7000)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.310% (6412/7100)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.264% (6499/7200)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.329% (6594/7300)\n",
      "Test Epoch: 96 | Loss: 0.449 | Acc: 90.365% (6687/7400)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.347% (6776/7500)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.329% (6865/7600)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.351% (6957/7700)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.359% (7048/7800)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.380% (7140/7900)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.338% (7227/8000)\n",
      "Test Epoch: 96 | Loss: 0.447 | Acc: 90.407% (7323/8100)\n",
      "Test Epoch: 96 | Loss: 0.446 | Acc: 90.402% (7413/8200)\n",
      "Test Epoch: 96 | Loss: 0.447 | Acc: 90.386% (7502/8300)\n",
      "Test Epoch: 96 | Loss: 0.448 | Acc: 90.345% (7589/8400)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.271% (7673/8500)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.209% (7758/8600)\n",
      "Test Epoch: 96 | Loss: 0.453 | Acc: 90.207% (7848/8700)\n",
      "Test Epoch: 96 | Loss: 0.455 | Acc: 90.182% (7936/8800)\n",
      "Test Epoch: 96 | Loss: 0.455 | Acc: 90.202% (8028/8900)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.200% (8118/9000)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.209% (8209/9100)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.239% (8302/9200)\n",
      "Test Epoch: 96 | Loss: 0.452 | Acc: 90.215% (8390/9300)\n",
      "Test Epoch: 96 | Loss: 0.454 | Acc: 90.255% (8484/9400)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.295% (8578/9500)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.302% (8669/9600)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.340% (8763/9700)\n",
      "Test Epoch: 96 | Loss: 0.451 | Acc: 90.357% (8855/9800)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.374% (8947/9900)\n",
      "Test Epoch: 96 | Loss: 0.450 | Acc: 90.340% (9034/10000)\n",
      "\n",
      "Epoch: 97\n",
      "Train Epoch: 97 | Loss: 0.018 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 97 | Loss: 0.011 | Acc: 99.609% (255/256)\n",
      "Train Epoch: 97 | Loss: 0.017 | Acc: 99.219% (381/384)\n",
      "Train Epoch: 97 | Loss: 0.017 | Acc: 99.219% (508/512)\n",
      "Train Epoch: 97 | Loss: 0.019 | Acc: 99.219% (635/640)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.219% (762/768)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.107% (888/896)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.219% (1016/1024)\n",
      "Train Epoch: 97 | Loss: 0.026 | Acc: 99.132% (1142/1152)\n",
      "Train Epoch: 97 | Loss: 0.027 | Acc: 99.062% (1268/1280)\n",
      "Train Epoch: 97 | Loss: 0.026 | Acc: 99.148% (1396/1408)\n",
      "Train Epoch: 97 | Loss: 0.027 | Acc: 99.089% (1522/1536)\n",
      "Train Epoch: 97 | Loss: 0.026 | Acc: 99.099% (1649/1664)\n",
      "Train Epoch: 97 | Loss: 0.027 | Acc: 99.051% (1775/1792)\n",
      "Train Epoch: 97 | Loss: 0.026 | Acc: 99.115% (1903/1920)\n",
      "Train Epoch: 97 | Loss: 0.025 | Acc: 99.170% (2031/2048)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.219% (2159/2176)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.175% (2285/2304)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.219% (2413/2432)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.258% (2541/2560)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.256% (2668/2688)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.290% (2796/2816)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.253% (2922/2944)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.251% (3049/3072)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.219% (3175/3200)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.249% (3303/3328)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.248% (3430/3456)\n",
      "Train Epoch: 97 | Loss: 0.025 | Acc: 99.191% (3555/3584)\n",
      "Train Epoch: 97 | Loss: 0.025 | Acc: 99.219% (3683/3712)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.245% (3811/3840)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.244% (3938/3968)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.219% (4064/4096)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.242% (4192/4224)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.242% (4319/4352)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.263% (4447/4480)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.219% (4572/4608)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.219% (4699/4736)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.239% (4827/4864)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.239% (4954/4992)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.199% (5079/5120)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.200% (5206/5248)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.219% (5334/5376)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.182% (5459/5504)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.165% (5585/5632)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.184% (5713/5760)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.185% (5840/5888)\n",
      "Train Epoch: 97 | Loss: 0.024 | Acc: 99.202% (5968/6016)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.219% (6096/6144)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.235% (6224/6272)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.250% (6352/6400)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.249% (6479/6528)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.249% (6606/6656)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.263% (6734/6784)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.262% (6861/6912)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.261% (6988/7040)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.275% (7116/7168)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.274% (7243/7296)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.286% (7371/7424)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.298% (7499/7552)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.310% (7627/7680)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.308% (7754/7808)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.294% (7880/7936)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.268% (8005/8064)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.255% (8131/8192)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.267% (8259/8320)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.278% (8387/8448)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.277% (8514/8576)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.288% (8642/8704)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.298% (8770/8832)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.297% (8897/8960)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.285% (9023/9088)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.295% (9151/9216)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.294% (9278/9344)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.293% (9405/9472)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.302% (9533/9600)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.291% (9659/9728)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.300% (9787/9856)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.309% (9915/9984)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.308% (10042/10112)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.307% (10169/10240)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.315% (10297/10368)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.304% (10423/10496)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.313% (10551/10624)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.302% (10677/10752)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.311% (10805/10880)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.319% (10933/11008)\n",
      "Train Epoch: 97 | Loss: 0.023 | Acc: 99.318% (11060/11136)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.325% (11188/11264)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.324% (11315/11392)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.323% (11442/11520)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.322% (11569/11648)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.329% (11697/11776)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (11825/11904)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.343% (11953/12032)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.350% (12081/12160)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.357% (12209/12288)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.356% (12336/12416)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.338% (12461/12544)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.345% (12589/12672)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.352% (12717/12800)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.358% (12845/12928)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.357% (12972/13056)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.363% (13100/13184)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.354% (13226/13312)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.353% (13353/13440)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.351% (13480/13568)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.350% (13607/13696)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.349% (13734/13824)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.348% (13861/13952)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.354% (13989/14080)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.352% (14116/14208)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.358% (14244/14336)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.364% (14372/14464)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.363% (14499/14592)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.361% (14626/14720)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.367% (14754/14848)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.372% (14882/14976)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.371% (15009/15104)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.376% (15137/15232)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.382% (15265/15360)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.374% (15391/15488)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.372% (15518/15616)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.378% (15646/15744)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.370% (15772/15872)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.375% (15900/16000)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.380% (16028/16128)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.385% (16156/16256)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.377% (16282/16384)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.370% (16408/16512)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.375% (16536/16640)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.380% (16664/16768)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.379% (16791/16896)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.377% (16918/17024)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.376% (17045/17152)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.375% (17172/17280)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.368% (17298/17408)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.373% (17426/17536)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.377% (17554/17664)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.376% (17681/17792)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.369% (17807/17920)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.363% (17933/18048)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.362% (18060/18176)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.366% (18188/18304)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.371% (18316/18432)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.375% (18444/18560)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.363% (18569/18688)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.357% (18695/18816)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.356% (18822/18944)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.350% (18948/19072)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.349% (19075/19200)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.353% (19203/19328)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.358% (19331/19456)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.362% (19459/19584)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.361% (19586/19712)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.360% (19713/19840)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.364% (19841/19968)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.368% (19969/20096)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.367% (20096/20224)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.356% (20221/20352)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.360% (20349/20480)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.355% (20475/20608)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.354% (20602/20736)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.343% (20727/20864)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.347% (20855/20992)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.351% (20983/21120)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.355% (21111/21248)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.350% (21237/21376)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.344% (21363/21504)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.344% (21490/21632)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.347% (21618/21760)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.347% (21745/21888)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.350% (21873/22016)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.354% (22001/22144)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.353% (22128/22272)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.353% (22255/22400)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.356% (22383/22528)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.356% (22510/22656)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.355% (22637/22784)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.358% (22765/22912)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.362% (22893/23040)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.366% (23021/23168)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.365% (23148/23296)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.360% (23274/23424)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.359% (23401/23552)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.362% (23529/23680)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.362% (23656/23808)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.361% (23783/23936)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.352% (23908/24064)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.351% (24035/24192)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.350% (24162/24320)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.350% (24289/24448)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.349% (24416/24576)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.348% (24543/24704)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.348% (24670/24832)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.343% (24796/24960)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.346% (24924/25088)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.342% (25050/25216)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.345% (25178/25344)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.344% (25305/25472)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.340% (25431/25600)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (25556/25728)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (25682/25856)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.319% (25807/25984)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.322% (25935/26112)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.322% (26062/26240)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.325% (26190/26368)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.324% (26317/26496)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (26445/26624)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (26573/26752)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (26701/26880)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (26828/27008)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (26955/27136)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (27083/27264)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (27208/27392)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (27335/27520)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (27462/27648)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (27590/27776)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (27718/27904)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (27846/28032)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (27973/28160)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (28099/28288)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (28226/28416)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (28352/28544)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (28479/28672)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (28607/28800)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (28735/28928)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (28861/29056)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (28989/29184)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (29117/29312)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (29243/29440)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (29371/29568)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (29498/29696)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (29626/29824)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (29751/29952)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (29879/30080)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (30007/30208)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (30134/30336)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (30260/30464)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (30387/30592)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (30515/30720)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (30641/30848)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (30768/30976)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (30896/31104)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (31023/31232)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (31151/31360)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (31278/31488)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (31405/31616)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (31532/31744)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.325% (31657/31872)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.316% (31781/32000)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.315% (31908/32128)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.318% (32036/32256)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.321% (32164/32384)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.320% (32291/32512)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.320% (32418/32640)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.323% (32546/32768)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.325% (32674/32896)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (32802/33024)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.324% (32928/33152)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.321% (33054/33280)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.324% (33182/33408)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.326% (33310/33536)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (33438/33664)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.325% (33564/33792)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (33692/33920)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (33819/34048)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (33946/34176)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (34073/34304)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (34201/34432)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (34329/34560)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.328% (34455/34688)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (34583/34816)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (34710/34944)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (34836/35072)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (34964/35200)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (35092/35328)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (35220/35456)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (35346/35584)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (35473/35712)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (35601/35840)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (35727/35968)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (35854/36096)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (35982/36224)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (36110/36352)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (36238/36480)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (36365/36608)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.339% (36493/36736)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.341% (36621/36864)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.338% (36747/36992)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.340% (36875/37120)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.342% (37003/37248)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.342% (37130/37376)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.344% (37258/37504)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.344% (37385/37632)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.346% (37513/37760)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.345% (37640/37888)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.342% (37766/38016)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.339% (37892/38144)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.339% (38019/38272)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.339% (38146/38400)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.338% (38273/38528)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.340% (38401/38656)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.340% (38528/38784)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.342% (38656/38912)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (38780/39040)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (38904/39168)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (39031/39296)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (39159/39424)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (39287/39552)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (39414/39680)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.327% (39540/39808)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (39668/39936)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.329% (39795/40064)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.331% (39923/40192)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (40051/40320)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (40178/40448)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (40306/40576)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (40433/40704)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (40561/40832)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (40688/40960)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (40814/41088)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (40939/41216)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.330% (41067/41344)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.330% (41194/41472)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.332% (41322/41600)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (41450/41728)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (41577/41856)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.333% (41704/41984)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (41832/42112)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (41959/42240)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (42086/42368)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.332% (42212/42496)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.331% (42339/42624)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.333% (42467/42752)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (42595/42880)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (42722/43008)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (42850/43136)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (42977/43264)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.332% (43102/43392)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.331% (43229/43520)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.333% (43357/43648)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (43485/43776)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (43612/43904)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (43740/44032)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (43867/44160)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.334% (43993/44288)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.336% (44121/44416)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (44248/44544)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.335% (44375/44672)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (44503/44800)\n",
      "Train Epoch: 97 | Loss: 0.021 | Acc: 99.337% (44630/44928)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.332% (44755/45056)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.329% (44881/45184)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (45007/45312)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (45134/45440)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (45261/45568)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (45388/45696)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (45515/45824)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (45643/45952)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.329% (45771/46080)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (45897/46208)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (46024/46336)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (46151/46464)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (46279/46592)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.330% (46407/46720)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.330% (46534/46848)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (46660/46976)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.327% (46787/47104)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.329% (46915/47232)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.326% (47041/47360)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (47169/47488)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.328% (47296/47616)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.330% (47424/47744)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.332% (47552/47872)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.333% (47680/48000)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (47808/48128)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.335% (47935/48256)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.337% (48063/48384)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (48190/48512)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (48317/48640)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (48444/48768)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.337% (48572/48896)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.339% (48700/49024)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.339% (48827/49152)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.338% (48954/49280)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (49080/49408)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (49207/49536)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.336% (49334/49664)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.333% (49460/49792)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.333% (49587/49920)\n",
      "Train Epoch: 97 | Loss: 0.022 | Acc: 99.332% (49666/50000)\n",
      "Test Epoch: 97 | Loss: 0.244 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 97 | Loss: 0.334 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 97 | Loss: 0.336 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 97 | Loss: 0.362 | Acc: 91.250% (365/400)\n",
      "Test Epoch: 97 | Loss: 0.341 | Acc: 91.600% (458/500)\n",
      "Test Epoch: 97 | Loss: 0.296 | Acc: 92.500% (555/600)\n",
      "Test Epoch: 97 | Loss: 0.310 | Acc: 92.429% (647/700)\n",
      "Test Epoch: 97 | Loss: 0.339 | Acc: 91.750% (734/800)\n",
      "Test Epoch: 97 | Loss: 0.351 | Acc: 91.556% (824/900)\n",
      "Test Epoch: 97 | Loss: 0.349 | Acc: 91.500% (915/1000)\n",
      "Test Epoch: 97 | Loss: 0.374 | Acc: 91.182% (1003/1100)\n",
      "Test Epoch: 97 | Loss: 0.408 | Acc: 90.583% (1087/1200)\n",
      "Test Epoch: 97 | Loss: 0.405 | Acc: 90.769% (1180/1300)\n",
      "Test Epoch: 97 | Loss: 0.406 | Acc: 90.714% (1270/1400)\n",
      "Test Epoch: 97 | Loss: 0.399 | Acc: 90.800% (1362/1500)\n",
      "Test Epoch: 97 | Loss: 0.388 | Acc: 91.062% (1457/1600)\n",
      "Test Epoch: 97 | Loss: 0.385 | Acc: 91.118% (1549/1700)\n",
      "Test Epoch: 97 | Loss: 0.379 | Acc: 91.111% (1640/1800)\n",
      "Test Epoch: 97 | Loss: 0.378 | Acc: 90.947% (1728/1900)\n",
      "Test Epoch: 97 | Loss: 0.399 | Acc: 90.700% (1814/2000)\n",
      "Test Epoch: 97 | Loss: 0.408 | Acc: 90.476% (1900/2100)\n",
      "Test Epoch: 97 | Loss: 0.408 | Acc: 90.364% (1988/2200)\n",
      "Test Epoch: 97 | Loss: 0.402 | Acc: 90.522% (2082/2300)\n",
      "Test Epoch: 97 | Loss: 0.396 | Acc: 90.625% (2175/2400)\n",
      "Test Epoch: 97 | Loss: 0.409 | Acc: 90.520% (2263/2500)\n",
      "Test Epoch: 97 | Loss: 0.425 | Acc: 90.346% (2349/2600)\n",
      "Test Epoch: 97 | Loss: 0.414 | Acc: 90.519% (2444/2700)\n",
      "Test Epoch: 97 | Loss: 0.414 | Acc: 90.536% (2535/2800)\n",
      "Test Epoch: 97 | Loss: 0.416 | Acc: 90.586% (2627/2900)\n",
      "Test Epoch: 97 | Loss: 0.415 | Acc: 90.567% (2717/3000)\n",
      "Test Epoch: 97 | Loss: 0.418 | Acc: 90.581% (2808/3100)\n",
      "Test Epoch: 97 | Loss: 0.414 | Acc: 90.688% (2902/3200)\n",
      "Test Epoch: 97 | Loss: 0.418 | Acc: 90.515% (2987/3300)\n",
      "Test Epoch: 97 | Loss: 0.416 | Acc: 90.588% (3080/3400)\n",
      "Test Epoch: 97 | Loss: 0.425 | Acc: 90.457% (3166/3500)\n",
      "Test Epoch: 97 | Loss: 0.427 | Acc: 90.500% (3258/3600)\n",
      "Test Epoch: 97 | Loss: 0.434 | Acc: 90.514% (3349/3700)\n",
      "Test Epoch: 97 | Loss: 0.439 | Acc: 90.447% (3437/3800)\n",
      "Test Epoch: 97 | Loss: 0.436 | Acc: 90.487% (3529/3900)\n",
      "Test Epoch: 97 | Loss: 0.436 | Acc: 90.425% (3617/4000)\n",
      "Test Epoch: 97 | Loss: 0.441 | Acc: 90.293% (3702/4100)\n",
      "Test Epoch: 97 | Loss: 0.441 | Acc: 90.262% (3791/4200)\n",
      "Test Epoch: 97 | Loss: 0.434 | Acc: 90.395% (3887/4300)\n",
      "Test Epoch: 97 | Loss: 0.436 | Acc: 90.477% (3981/4400)\n",
      "Test Epoch: 97 | Loss: 0.433 | Acc: 90.533% (4074/4500)\n",
      "Test Epoch: 97 | Loss: 0.433 | Acc: 90.500% (4163/4600)\n",
      "Test Epoch: 97 | Loss: 0.432 | Acc: 90.532% (4255/4700)\n",
      "Test Epoch: 97 | Loss: 0.433 | Acc: 90.417% (4340/4800)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.551% (4437/4900)\n",
      "Test Epoch: 97 | Loss: 0.433 | Acc: 90.560% (4528/5000)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.627% (4622/5100)\n",
      "Test Epoch: 97 | Loss: 0.431 | Acc: 90.500% (4706/5200)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.547% (4799/5300)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.574% (4891/5400)\n",
      "Test Epoch: 97 | Loss: 0.430 | Acc: 90.545% (4980/5500)\n",
      "Test Epoch: 97 | Loss: 0.431 | Acc: 90.589% (5073/5600)\n",
      "Test Epoch: 97 | Loss: 0.431 | Acc: 90.596% (5164/5700)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.621% (5256/5800)\n",
      "Test Epoch: 97 | Loss: 0.429 | Acc: 90.627% (5347/5900)\n",
      "Test Epoch: 97 | Loss: 0.427 | Acc: 90.600% (5436/6000)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.656% (5530/6100)\n",
      "Test Epoch: 97 | Loss: 0.426 | Acc: 90.645% (5620/6200)\n",
      "Test Epoch: 97 | Loss: 0.426 | Acc: 90.683% (5713/6300)\n",
      "Test Epoch: 97 | Loss: 0.423 | Acc: 90.719% (5806/6400)\n",
      "Test Epoch: 97 | Loss: 0.422 | Acc: 90.723% (5897/6500)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.773% (5991/6600)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.806% (6084/6700)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.794% (6174/6800)\n",
      "Test Epoch: 97 | Loss: 0.419 | Acc: 90.826% (6267/6900)\n",
      "Test Epoch: 97 | Loss: 0.419 | Acc: 90.843% (6359/7000)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.831% (6449/7100)\n",
      "Test Epoch: 97 | Loss: 0.423 | Acc: 90.792% (6537/7200)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.808% (6629/7300)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.797% (6719/7400)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.760% (6807/7500)\n",
      "Test Epoch: 97 | Loss: 0.422 | Acc: 90.750% (6897/7600)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.753% (6988/7700)\n",
      "Test Epoch: 97 | Loss: 0.423 | Acc: 90.769% (7080/7800)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.797% (7173/7900)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.775% (7262/8000)\n",
      "Test Epoch: 97 | Loss: 0.417 | Acc: 90.864% (7360/8100)\n",
      "Test Epoch: 97 | Loss: 0.416 | Acc: 90.890% (7453/8200)\n",
      "Test Epoch: 97 | Loss: 0.418 | Acc: 90.843% (7540/8300)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.798% (7627/8400)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.729% (7712/8500)\n",
      "Test Epoch: 97 | Loss: 0.425 | Acc: 90.709% (7801/8600)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.701% (7891/8700)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.716% (7983/8800)\n",
      "Test Epoch: 97 | Loss: 0.424 | Acc: 90.697% (8072/8900)\n",
      "Test Epoch: 97 | Loss: 0.423 | Acc: 90.711% (8164/9000)\n",
      "Test Epoch: 97 | Loss: 0.423 | Acc: 90.725% (8256/9100)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.772% (8351/9200)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.774% (8442/9300)\n",
      "Test Epoch: 97 | Loss: 0.421 | Acc: 90.766% (8532/9400)\n",
      "Test Epoch: 97 | Loss: 0.420 | Acc: 90.779% (8624/9500)\n",
      "Test Epoch: 97 | Loss: 0.419 | Acc: 90.781% (8715/9600)\n",
      "Test Epoch: 97 | Loss: 0.418 | Acc: 90.804% (8808/9700)\n",
      "Test Epoch: 97 | Loss: 0.418 | Acc: 90.827% (8901/9800)\n",
      "Test Epoch: 97 | Loss: 0.417 | Acc: 90.838% (8993/9900)\n",
      "Test Epoch: 97 | Loss: 0.417 | Acc: 90.840% (9084/10000)\n",
      "\n",
      "Epoch: 98\n",
      "Train Epoch: 98 | Loss: 0.053 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 98 | Loss: 0.041 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 98 | Loss: 0.033 | Acc: 98.698% (379/384)\n",
      "Train Epoch: 98 | Loss: 0.034 | Acc: 98.633% (505/512)\n",
      "Train Epoch: 98 | Loss: 0.031 | Acc: 98.750% (632/640)\n",
      "Train Epoch: 98 | Loss: 0.030 | Acc: 98.828% (759/768)\n",
      "Train Epoch: 98 | Loss: 0.029 | Acc: 98.884% (886/896)\n",
      "Train Epoch: 98 | Loss: 0.028 | Acc: 98.828% (1012/1024)\n",
      "Train Epoch: 98 | Loss: 0.025 | Acc: 98.958% (1140/1152)\n",
      "Train Epoch: 98 | Loss: 0.026 | Acc: 98.906% (1266/1280)\n",
      "Train Epoch: 98 | Loss: 0.024 | Acc: 99.006% (1394/1408)\n",
      "Train Epoch: 98 | Loss: 0.023 | Acc: 99.089% (1522/1536)\n",
      "Train Epoch: 98 | Loss: 0.023 | Acc: 99.099% (1649/1664)\n",
      "Train Epoch: 98 | Loss: 0.023 | Acc: 99.163% (1777/1792)\n",
      "Train Epoch: 98 | Loss: 0.021 | Acc: 99.219% (1905/1920)\n",
      "Train Epoch: 98 | Loss: 0.021 | Acc: 99.268% (2033/2048)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.311% (2161/2176)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.262% (2287/2304)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.301% (2415/2432)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.336% (2543/2560)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.368% (2671/2688)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.361% (2798/2816)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.355% (2925/2944)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.316% (3051/3072)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.312% (3178/3200)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.339% (3306/3328)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.334% (3433/3456)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.330% (3560/3584)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.353% (3688/3712)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.375% (3816/3840)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.395% (3944/3968)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.390% (4071/4096)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.408% (4199/4224)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.426% (4327/4352)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.442% (4455/4480)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.436% (4582/4608)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.409% (4708/4736)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.424% (4836/4864)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.419% (4963/4992)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.414% (5090/5120)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.409% (5217/5248)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.423% (5345/5376)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.419% (5472/5504)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.432% (5600/5632)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.410% (5726/5760)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.423% (5854/5888)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.402% (5980/6016)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.414% (6108/6144)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.410% (6235/6272)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.391% (6361/6400)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.403% (6489/6528)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.414% (6617/6656)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.425% (6745/6784)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.407% (6871/6912)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.418% (6999/7040)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.428% (7127/7168)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.411% (7253/7296)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.421% (7381/7424)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.404% (7507/7552)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.414% (7635/7680)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.398% (7761/7808)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.408% (7889/7936)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.392% (8015/8064)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.402% (8143/8192)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.375% (8268/8320)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.373% (8395/8448)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.382% (8523/8576)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.391% (8651/8704)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.377% (8777/8832)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.375% (8904/8960)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.362% (9030/9088)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.371% (9158/9216)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.379% (9286/9344)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.388% (9414/9472)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.396% (9542/9600)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.404% (9670/9728)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.401% (9797/9856)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.389% (9923/9984)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.397% (10051/10112)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.385% (10177/10240)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.383% (10304/10368)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.390% (10432/10496)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.398% (10560/10624)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.405% (10688/10752)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.403% (10815/10880)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.410% (10943/11008)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.407% (11070/11136)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.414% (11198/11264)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.412% (11325/11392)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.418% (11453/11520)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.425% (11581/11648)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.431% (11709/11776)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.420% (11835/11904)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.410% (11961/12032)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.408% (12088/12160)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.406% (12215/12288)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.412% (12343/12416)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.402% (12469/12544)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.408% (12597/12672)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.414% (12725/12800)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.420% (12853/12928)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.418% (12980/13056)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.416% (13107/13184)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.422% (13235/13312)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.427% (13363/13440)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.432% (13491/13568)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.438% (13619/13696)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.443% (13747/13824)\n",
      "Train Epoch: 98 | Loss: 0.020 | Acc: 99.427% (13872/13952)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.432% (14000/14080)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.437% (14128/14208)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.442% (14256/14336)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.447% (14384/14464)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.452% (14512/14592)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.457% (14640/14720)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.454% (14767/14848)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.459% (14895/14976)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.464% (15023/15104)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.449% (15148/15232)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.447% (15275/15360)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.451% (15403/15488)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.449% (15530/15616)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.447% (15657/15744)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.452% (15785/15872)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.450% (15912/16000)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.448% (16039/16128)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.440% (16165/16256)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.438% (16292/16384)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.443% (16420/16512)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.447% (16548/16640)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.451% (16676/16768)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.455% (16804/16896)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.454% (16931/17024)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.458% (17059/17152)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.462% (17187/17280)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.449% (17312/17408)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.453% (17440/17536)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.457% (17568/17664)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.455% (17695/17792)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.459% (17823/17920)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.463% (17951/18048)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.461% (18078/18176)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.459% (18205/18304)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.463% (18333/18432)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.456% (18459/18560)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.454% (18586/18688)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.453% (18713/18816)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.456% (18841/18944)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.449% (18967/19072)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.453% (19095/19200)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.446% (19221/19328)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.450% (19349/19456)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.449% (19476/19584)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.452% (19604/19712)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.451% (19731/19840)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.454% (19859/19968)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.453% (19986/20096)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.451% (20113/20224)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.450% (20240/20352)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.448% (20367/20480)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.452% (20495/20608)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.455% (20623/20736)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.458% (20751/20864)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.462% (20879/20992)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.465% (21007/21120)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.463% (21134/21248)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.467% (21262/21376)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.470% (21390/21504)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.473% (21518/21632)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.476% (21646/21760)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.479% (21774/21888)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.478% (21901/22016)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.481% (22029/22144)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.484% (22157/22272)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.487% (22285/22400)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.490% (22413/22528)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.492% (22541/22656)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.491% (22668/22784)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.489% (22795/22912)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.488% (22922/23040)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.491% (23050/23168)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.493% (23178/23296)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.496% (23306/23424)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.495% (23433/23552)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.497% (23561/23680)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.496% (23688/23808)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.494% (23815/23936)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.497% (23943/24064)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (24068/24192)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (24195/24320)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (24323/24448)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.491% (24451/24576)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.494% (24579/24704)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.493% (24706/24832)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.495% (24834/24960)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.498% (24962/25088)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.496% (25089/25216)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.491% (25215/25344)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.494% (25343/25472)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.492% (25470/25600)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.495% (25598/25728)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.493% (25725/25856)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.496% (25853/25984)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.494% (25980/26112)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.497% (26108/26240)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.499% (26236/26368)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.502% (26364/26496)\n",
      "Train Epoch: 98 | Loss: 0.018 | Acc: 99.504% (26492/26624)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.499% (26618/26752)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.498% (26745/26880)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.500% (26873/27008)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.499% (27000/27136)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.498% (27127/27264)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.500% (27255/27392)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.499% (27382/27520)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.501% (27510/27648)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.500% (27637/27776)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.495% (27763/27904)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.490% (27889/28032)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (28016/28160)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.491% (28144/28288)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.493% (28272/28416)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (28398/28544)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.491% (28526/28672)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.493% (28654/28800)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.488% (28780/28928)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.484% (28906/29056)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.483% (29033/29184)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (29161/29312)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (29289/29440)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (29417/29568)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (29543/29696)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (29671/29824)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (29798/29952)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.488% (29926/30080)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.484% (30052/30208)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (30180/30336)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (30307/30464)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (30435/30592)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (30562/30720)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.488% (30690/30848)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (30817/30976)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (30944/31104)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (31071/31232)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.483% (31198/31360)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (31326/31488)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.484% (31453/31616)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (31581/31744)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (31709/31872)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.491% (31837/32000)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.490% (31964/32128)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (32090/32256)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (32218/32384)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (32346/32512)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (32472/32640)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (32600/32768)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.483% (32726/32896)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (32854/33024)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (32982/33152)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (33109/33280)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.488% (33237/33408)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.487% (33364/33536)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.489% (33492/33664)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.488% (33619/33792)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.490% (33747/33920)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.486% (33873/34048)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.485% (34000/34176)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.484% (34127/34304)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.474% (34251/34432)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.470% (34377/34560)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.470% (34504/34688)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.466% (34630/34816)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.465% (34757/34944)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.467% (34885/35072)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.466% (35012/35200)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.468% (35140/35328)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.470% (35268/35456)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.469% (35395/35584)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.468% (35522/35712)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.470% (35650/35840)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.472% (35778/35968)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.474% (35906/36096)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.475% (36034/36224)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.475% (36161/36352)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.474% (36288/36480)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.476% (36416/36608)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.477% (36544/36736)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.474% (36670/36864)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.476% (36798/36992)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.475% (36925/37120)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.474% (37052/37248)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.476% (37180/37376)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.477% (37308/37504)\n",
      "Train Epoch: 98 | Loss: 0.019 | Acc: 99.477% (37435/37632)\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "loss_list = []\n",
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch)\n",
    "    loss, acc = test(epoch)\n",
    "    acc_list.append(acc)\n",
    "    loss_list.append(loss)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS-WMnGMEXh8",
    "outputId": "ee80ae44-5881-4700-a1a7-e31df8e8f349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.02\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.conda/envs/default/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(acc_list)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"test_accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf9klEQVR4nO3dd3hUVf4G8PfOTGYmdUJILxB6J4ReRSSIyGL7WVZZRWyrsrsIa0MU2yquu7jqiroWROzKKuqCdKlSA6GT0BPSC+nJJDNzf3/M3JtMMklmkinJ5P08T57HTG6Sk2vIvPM933OOIIqiCCIiIiIvofD0AIiIiIicieGGiIiIvArDDREREXkVhhsiIiLyKgw3RERE5FUYboiIiMirMNwQERGRV1F5egDuZjKZkJWVhcDAQAiC4OnhEBERkR1EUURZWRmio6OhUDRfm+l04SYrKwtxcXGeHgYRERG1QkZGBmJjY5u9ptOFm8DAQADmmxMUFOTh0RAREZE9SktLERcXJz+PN6fThRtpKiooKIjhhoiIqIOxp6WEDcVERETkVRhuiIiIyKsw3BAREZFXYbghIiIir8JwQ0RERF6F4YaIiIi8ikfDzY4dOzBr1ixER0dDEASsWbPG7s/dvXs3VCoVhg0b5rLxERERUcfj0XBTUVGBhIQELF++3KHPKy4uxj333IOpU6e6aGRERETUUXl0E78ZM2ZgxowZDn/eww8/jLvuugtKpdKhag8RERF5vw7Xc/PJJ5/g/PnzeP755+26Xq/Xo7S01OqNiIiIvFeHCjdnzpzB008/jc8//xwqlX1Fp6VLl0Kn08lvPDSTiIjIu3WYcGM0GnHXXXfhxRdfRN++fe3+vEWLFqGkpER+y8jIcOEoiYiIyNM6zMGZZWVlOHjwIA4fPow//elPAACTyQRRFKFSqbBx40Zcc801jT5Po9FAo9G4fHxGk4iCcj2qaoyID/V3+fcjIiIi2zpMuAkKCsKxY8esHnv33XexdetWrF69Gj169PDQyMzyy/QYu3QLlAoBZ1+ZYdeppUREROR8Hg035eXlOHv2rPz+hQsXkJKSgpCQEHTr1g2LFi1CZmYmVq1aBYVCgcGDB1t9fnh4OLRabaPHPcFfowRgruDoDSZofZQeHhEREVHn5NFwc/DgQUyZMkV+f+HChQCAOXPmYOXKlcjOzkZ6erqnhucQP3XdrSzXGxhuiIiIPEQQRVH09CDcqbS0FDqdDiUlJQgKCnLq1x7w3HpU1Rqx44kp6NbVz6lfm4iIqDNz5Pm7w6yW6gj8NebqTbne4OGREBERdV4MN04UYOm7qahhuCEiIvIUhhsnYuWGiIjI8xhunMjf0lRcqTd6eCRERESdF8ONE0nLwStYuSEiIvIYhhsn4rQUERGR5zHcOJE8LcWGYiIiIo9huHGiusoNe26IiIg8heHGiQLYc0NERORxDDdOJFVuGG6IiIg8h+HGifykcMOeGyIiIo9huHGiumkp9twQERF5CsONE0mrpbgUnIiIyHMYbpxI6rnhUnAiIiLPYbhxorqGYk5LEREReQrDjRNJPTecliIiIvIchhsnqr8UXBRFD4+GiIioc2K4cSI/S0OxwSSixmjy8GiIiIg6J4YbJ/JXK+X/Zt8NERGRZzDcOJFKqYDWx3xLuUsxERGRZzDcOJm01w13KSYiIvIMhhsn4/lSREREnsVw42RSuClnzw0REZFHMNw4Wd35UqzcEBEReQLDjZNJy8EZboiIiDyD4cbJAthzQ0RE5FEMN07mL01L1bDnhoiIyBMYbpyM01JERESexXDjZJyWIiIi8iyGGyfjUnAiIiLPYrhxMi4FJyIi8iyGGyfz4/ELREREHsVw42Q8foGIiMizGG6crK6hmD03REREnsBw42R+8j43rNwQERF5AsONk3EpOBERkWcx3DiZP6eliIiIPIrhxskCLKulaowm1BhMHh4NERFR58Nw42RSzw0AVLLvhoiIyO0YbpzMR6mAWmW+reXsuyEiInI7hhsX4HJwIiIiz2G4cQE/NZeDExEReQrDjQtwOTgREZHnMNy4AI9gICIi8hyGGxeQwk05e26IiIjcjuHGBfwtPTdcCk5EROR+DDcuUFe5YbghIiJyN4YbF2BDMRERkecw3LiAvBScPTdERERux3DjAlwtRURE5DkMNy4gT0uxoZiIiMjtGG5cgEvBiYiIPIfhxgXkpeCcliIiInI7hhsX4FJwIiIiz2G4cQF/9twQERF5jEfDzY4dOzBr1ixER0dDEASsWbOm2eu///57TJs2DWFhYQgKCsK4ceOwYcMG9wzWAf4aaVqKPTdERETu5tFwU1FRgYSEBCxfvtyu63fs2IFp06Zh3bp1SE5OxpQpUzBr1iwcPnzYxSN1jL+a01JERESeovLkN58xYwZmzJhh9/Vvvvmm1fuvvvoqfvzxR/z8889ITEx08uhaT1oKrjeYYDCaoFJy9o+IiMhdPBpu2spkMqGsrAwhISFNXqPX66HX6+X3S0tLXT4uqecGMO9SrPNjuCEiInKXDv2s+89//hPl5eW4/fbbm7xm6dKl0Ol08ltcXJzLx6VWKeCjFACwqZiIiMjdOmy4+fLLL/Hiiy/i22+/RXh4eJPXLVq0CCUlJfJbRkaGW8bHIxiIiIg8o0NOS3399dd44IEH8N133yEpKanZazUaDTQajZtGVsdfrUJxZS2biomIiNysw1VuvvrqK8ydOxdfffUVZs6c6enhNEleDl7D5eBERETu5NHKTXl5Oc6ePSu/f+HCBaSkpCAkJATdunXDokWLkJmZiVWrVgEwT0XNmTMHb731FsaMGYOcnBwAgK+vL3Q6nUd+hqZwl2IiIiLP8Gjl5uDBg0hMTJSXcS9cuBCJiYlYsmQJACA7Oxvp6eny9R988AEMBgPmzZuHqKgo+W3+/PkeGX9zAthzQ0RE5BEerdxcffXVEEWxyY+vXLnS6v1t27a5dkBO5Gc5PJPhhoiIyL06XM9NR1F3vhR7boiIiNyJ4cZFOC1FRETkGQw3LsKGYiIiIs9guHERfzVPBiciIvIEhhsXkSs3PH6BiIjIrRhuXITHLxAREXkGw42L+KsZboiIiDyB4cZFpOMXKthzQ0RE5FYMNy4iLwVnzw0REZFbMdy4CHtuiIiIPIPhxkXqem44LUVERORODDcuIvXcVNUaYTQ1fX4WERERORfDjYtI01IA+26IiIjcieHGRTQqBZQKAQD7boiIiNyJ4cZFBEGQj2Bg3w0REZH7MNy4EE8GJyIicj+GGxficnAiIiL3Y7hxIT95Iz9OSxEREbkLw40LBchHMLByQ0RE5C4MNy4kbeRXznBDRETkNgw3LsSeGyIiIvdjuHEh+WRw9twQERG5DcONCwVofAAAZdW1Hh4JERFR58Fw40KRQRoAQFZxlYdHQkRE1Hkw3LhQXIgfACCjiOGGiIjIXRhuXKgu3FRCFHkyOBERkTsw3LhQXBdzuCnTG1BSxb4bIiIid2C4cSFftRKhAea+G05NERERuQfDjYvFhfgCADKuVHp4JERERJ0Dw42LdavXd0NERESux3DjYlLfTTrDDRERkVsw3LhY3bQUe26IiIjcgeHGxaTKzWVWboiIiNyC4cbFpL1uLl+pgsnEvW6IiIhcjeHGxaJ0WigVAmqMJuSWVXt6OERERF6P4cbFVEoFooO1ALjXDRERkTsw3LgBl4MTERG5D8ONG3A5OBERkfsw3LiBfIAmdykmIiJyOYYbN5BXTLHnhoiIyOUYbtwgrot5Iz9OSxEREbkew40bSJWb3LJq6A1GD4+GiIjIuzHcuEFXfzV8fZQQRSCTxzAQERG5FMONGwiCULccnOGGiIjIpRhu3EQ6QJN9N0RERK7FcOMmsTxAk4iIyC0YbtykG/e6ISIicguGGzeRVkxxWoqIiMi1GG7cROq54eGZRERErsVw4ybS+VIlVbUora718GiIiIi8F8ONm/hrVOjqrwbA08GJiIhcieHGjWKlpmKGGyIiIpdhuHEj6Ywp9t0QERG5DsONG3E5OBERkesx3LhRHKeliIiIXM6j4WbHjh2YNWsWoqOjIQgC1qxZ0+LnbNu2DcOHD4dGo0Hv3r2xcuVKl4/TWaQVU9zrhoiIyHU8Gm4qKiqQkJCA5cuX23X9hQsXMHPmTEyZMgUpKSl47LHH8MADD2DDhg0uHqlzSHvdXL5SBVEUPTwaIiIi76Ty5DefMWMGZsyYYff177//Pnr06IFly5YBAAYMGIBdu3bhX//6F6ZPn27zc/R6PfR6vfx+aWlp2wbdBtHBvlAIgN5gQn6ZHuFBWo+NhYiIyFt1qJ6bPXv2ICkpyeqx6dOnY8+ePU1+ztKlS6HT6eS3uLg4Vw+zST5KBaJ0lhVTbComIiJyiQ4VbnJychAREWH1WEREBEpLS1FVZXt59aJFi1BSUiK/ZWRkuGOoTYrtUjc1RURERM7n0Wkpd9BoNNBoNJ4ehiy2ix/2XShiuCEiInKRDlW5iYyMRG5urtVjubm5CAoKgq+vr4dG5Zi6AzQ5LUVEROQKHSrcjBs3Dlu2bLF6bNOmTRg3bpyHRuS4WMtycFZuiIiIXMOj4aa8vBwpKSlISUkBYF7qnZKSgvT0dADmfpl77rlHvv7hhx/G+fPn8eSTT+L06dN499138e2332LBggWeGH6ryEcwsKGYiIjIJTwabg4ePIjExEQkJiYCABYuXIjExEQsWbIEAJCdnS0HHQDo0aMH1q5di02bNiEhIQHLli3DRx991OQy8PZIOjwzq7gKRhP3uiEiInI2Qexku8mVlpZCp9OhpKQEQUFBbv/+RpOIfs/+AoNJxG9PX4Po4I7RK0RERORJjjx/d6ieG2+gVAhyoGHfDRERkfMx3HhA3TEM7LshIiJyNoYbD4gNlk4HZ+WGiIjI2RhuPKBul2LblRtRFFFrNLlzSERERF6D4cYD4iwrpppaDj7/6xSMfmUzCsv1Nj9ORERETWO48YDmzpeqMZiw/ngOrlTWIi233N1DIyIi6vBaFW4yMjJw+fJl+f39+/fjsccewwcffOC0gXkzqXKTXVINQ4Ppp7TcMtRYHqvQG9w+NiIioo6uVeHmrrvuwq+//grAfFL3tGnTsH//fixevBgvvfSSUwfojcICNFCrFDCaRGSXVFt97FhmifzfFTUMN0RERI5qVbg5fvw4Ro8eDQD49ttvMXjwYPz222/44osvsHLlSmeOzyspFAJig20fw3D0cr1woze6dVxERETeoFXhpra2FhqNBgCwefNm3HDDDQCA/v37Izs723mj82IxTfTdHK9Xualk5YaIiMhhrQo3gwYNwvvvv4+dO3di06ZNuO666wAAWVlZ6Nq1q1MH6K1snQ6uNxhxOqdUfr+cPTdEREQOa1W4+fvf/47//Oc/uPrqq3HnnXciISEBAPDTTz/J01XUPHmX4qK6aam0nHLUGuuO+qqs4bQUERGRo1St+aSrr74aBQUFKC0tRZcuXeTHH3roIfj5+TltcN7MVuWmfjMxwMoNERFRa7SqclNVVQW9Xi8Hm0uXLuHNN99EamoqwsPDnTpAbxXXpXFD8bHMYgCAr48SAFDJcENEROSwVoWbG2+8EatWrQIAFBcXY8yYMVi2bBluuukmvPfee04doLeSKjc5pdWoMZj3tZEqNyPjzaGxnKuliIiIHNaqcHPo0CFMmjQJALB69WpERETg0qVLWLVqFd5++22nDtBbhQaoofVRQBSBrOIq6A1GpOaUAQDG9jQ3ZXO1FBERkeNaFW4qKysRGBgIANi4cSNuueUWKBQKjB07FpcuXXLqAL2VIAhWfTepOWWoNYoI9vNBvwjzveUOxURERI5rVbjp3bs31qxZg4yMDGzYsAHXXnstACAvLw9BQUFOHaA3i6t3Ori0ed+QGB38NeY+7wquliIiInJYq8LNkiVL8PjjjyM+Ph6jR4/GuHHjAJirOImJiU4doDeTKjcZVyrlzfvM4cbcUMzKDRERkeNatRT81ltvxcSJE5GdnS3vcQMAU6dOxc033+y0wXm7+qeDn80znwA+NLZe5YbhhoiIyGGtCjcAEBkZicjISPl08NjYWG7g5yDpdPBz+eVyM/HgGB1UCnNBraLGCFEUIQiCx8ZIRETU0bRqWspkMuGll16CTqdD9+7d0b17dwQHB+Pll1+GyWRy9hi9llS5OZ5ZCoNJRIi/GjHBvvK0lNEkQm/g/SQiInJEqyo3ixcvxscff4zXXnsNEyZMAADs2rULL7zwAqqrq/HKK684dZDeKq6L9W7Og2N0EAQBfuq6/y0VegO0lk39iIiIqGWtCjeffvopPvroI/k0cAAYOnQoYmJi8OijjzLc2CnYzwf+aqW8KmpIjHmlmVIhwNdHiapaIyprjOBRpERERPZr1bRUUVER+vfv3+jx/v37o6ioqM2D6iwEQZD7bgBgSEyw/N/S1BTPlyIiInJMq8JNQkIC3nnnnUaPv/POO1arp6hlUt8NAAyJ1cn/La2Y4i7FREREjmnVtNTrr7+OmTNnYvPmzfIeN3v27EFGRgbWrVvn1AF6O2mvm67+akTrtPLjUt8Nz5ciIiJyTKsqN5MnT0ZaWhpuvvlmFBcXo7i4GLfccgtSU1PlM6fIPt27msPNkFid1ZLvAA1PBiciImqNVu9zEx0dzcZhJ7hpWAwuFVbi1hGxVo/XVW4YboiIiBxhd7g5evSo3V906NChrRpMZ9TFX40XbhjU6PEAueeG01JERESOsDvcDBs2DIIgQBTFZq8TBAFGI5+Q28pPzdVSRERErWF3uLlw4YIrx0ENcLUUERFR69gdbrp37+7wF585cyY++ugjREVFOfy5nV3dyeCsghERETmiVaul7LVjxw5UVVW58lt4LamhmCeDExEROcal4YZaT2ooruC0FBERkUMYbtopqaGY01JERESOYbhpp+TKDaeliIiIHMJw0075ydNSrNwQERE5guGmnQqQV0uxckNEROSIVoWbHTt2wGBo/KRrMBiwY8cO+f1nnnkGISEhrR9dJyatluI+N0RERI5pVbiZMmUKioqKGj1eUlKCKVOmyO8vWrQIwcHBrR5cZyb13HCHYiIiIse0KtyIomh1grWksLAQ/v7+bR4U1a2Wqq41wWhq/sgLIiIiquPQqeC33HILAPP5Uffeey80Go38MaPRiKNHj2L8+PHOHWEnJR2/AJj3ugnS+nhwNERERB2HQ+FGp9MBMFduAgMD4evrK39MrVZj7NixePDBB507wk5Ko1JAqRBgNImo1BsZboiIiOzkULj55JNPAADx8fF4/PHHOQXlQoIgwF+tRGm1gX03REREDmhVz82TTz5p1XNz6dIlvPnmm9i4caPTBkY8GZyIiKg1WhVubrzxRqxatQoAUFxcjNGjR2PZsmW48cYb8d577zl1gJ2ZP1dMEREROaxV4ebQoUOYNGkSAGD16tWIjIzEpUuXsGrVKrz99ttOHWBn5m9ZMVXJ86WIiIjs1qpwU1lZicDAQADAxo0bccstt0ChUGDs2LG4dOmSUwfYmfnzZHAiIiKHtSrc9O7dG2vWrEFGRgY2bNiAa6+9FgCQl5eHoKAgpw6wM5N2KebJ4ERERPZrVbhZsmQJHn/8ccTHx2P06NEYN24cAHMVJzEx0akD7Myk86XYUExERGQ/h5aCS2699VZMnDgR2dnZSEhIkB+fOnUqbr75ZqcNrrPzY0MxERGRw1p9KnhkZCQCAwOxadMmVFVVAQBGjRqF/v37O21wnV2AvBSc01JERET2alW4KSwsxNSpU9G3b19cf/31yM7OBgDcf//9+Otf/+rUAXZm0vlSrNwQERHZr1XhZsGCBfDx8UF6ejr8/Pzkx++44w6sX7/e4a+3fPlyxMfHQ6vVYsyYMdi/f3+z17/55pvo168ffH19ERcXhwULFqC6utrh79veyZUbhhsiIiK7tarnZuPGjdiwYQNiY2OtHu/Tp4/DS8G/+eYbLFy4EO+//z7GjBmDN998E9OnT0dqairCw8MbXf/ll1/i6aefxooVKzB+/HikpaXh3nvvhSAIeOONN1rz47Rb0mqpcq6WIiIislurKjcVFRVWFRtJUVGR1Unh9njjjTfw4IMPYu7cuRg4cCDef/99+Pn5YcWKFTav/+233zBhwgTcddddiI+Px7XXXos777yzxWpPR+TP1VJEREQOa1W4mTRpknz8AmA+5NFkMuH111/HlClT7P46NTU1SE5ORlJSUt2AFAokJSVhz549Nj9n/PjxSE5OlsPM+fPnsW7dOlx//fU2r9fr9SgtLbV66yj85X1uGG6IiIjs1appqddffx1Tp07FwYMHUVNTgyeffBInTpxAUVERdu/ebffXKSgogNFoREREhNXjEREROH36tM3Pueuuu1BQUICJEydCFEUYDAY8/PDDeOaZZ2xev3TpUrz44ov2/3DtSN0OxZyWIiIislerKjdBQUE4deoUJk6ciBtvvBEVFRW45ZZbcPjwYfj4+Dh7jFa2bduGV199Fe+++y4OHTqE77//HmvXrsXLL79s8/pFixahpKREfsvIyHDp+JxJmpZi5YaIiMh+rarc9OjRA9nZ2Vi8eLHV44WFhYiNjYXRaF+lITQ0FEqlErm5uVaP5+bmIjIy0ubnPPfcc7j77rvxwAMPAACGDBmCiooKPPTQQ1i8eDEUCuu8ptFoHO4Dai/kyg3DDRERkd1aVbkRRdHm4+Xl5dBqtXZ/HbVajREjRmDLli3yYyaTCVu2bJGPdGiosrKyUYBRKpXNjqujkntuaoxe97MRERG5ikOVm4ULFwIwNxAvWbLEasWU0WjEvn37MGzYMIcGsHDhQsyZMwcjR47E6NGj8eabb6KiogJz584FANxzzz2IiYnB0qVLAQCzZs3CG2+8gcTERIwZMwZnz57Fc889h1mzZskhx1tI01JGkwi9wQStj3f9fERERK7gULg5fPgwAHOF5NixY1Cr1fLH1Go1EhIS8Pjjjzs0gDvuuAP5+flYsmQJcnJyMGzYMKxfv15uMk5PT7eq1Dz77LMQBAHPPvssMjMzERYWhlmzZuGVV15x6Pt2BNI+N4B5aorhhoiIqGWC2Ir5jrlz5+Ktt95CUFCQK8bkUqWlpdDpdCgpKekQ4x/w3HpU1Rqx88kpiAtpvLcQERFRZ+DI83erGoo/+eSTVg2MHOevUaKq1sjzpYiIiOzU6lPByT385ZPBGW6IiIjswXDTzvF8KSIiIscw3LRzAdL5UpyWIiIisgvDTTtXV7lhuCEiIrIHw007FyD33HBaioiIyB4MN+2cn9o8LcXKDRERkX0Ybto5rpYiIiJyDMNNO1d3MjinpYiIiOzBcNPO8WRwIiIixzDctHN1J4Mz3BAREdmD4aadq6vccFqKiIjIHgw37Zy/Wuq5YeWGiIjIHgw37ZxcueE+N0RERHZhuGnn6lZLsXJDRERkD4abdo773BARETmG4aad8+fZUkRERA5huGnnpMpNda0JRpPo4dEQERG1fww37Zx0thTAvW6IiIjswXDTzmlUCigVAgCgknvdEBERtYjhpp0TBEHe64Z9N0RERC1juOkAuGKKiIjIfgw3HYAUbli5ISIiahnDTQcgTUux54aIiKhlDDcdQN0RDKzcEBERtYThpgPwU/NkcCIiInsx3HQAATxfioiIyG4MNx2AH6eliIiI7MZw0wEESOGGlRsiIqIWMdx0ANIRDBU17LkhIiJqCcNNB8DKDRERkf0YbjoArpYiIiKyH8NNB+DP1VJERER2Y7jpAMIDtQCAUzmlqK5l9YaIiKg5DDcdwOgeIYjWaVFcWYv1x3M8PRwiIqJ2jeGmA1AqBPx+dDcAwBf7Lnl4NERERO0bw00HcceoOCgVAg5cvILUnDJPD4eIiKjdYrjpICKCtJg2IAIA8CWrN0RERE1iuOlAZo81T019fygTlTyKgYiIyCaGmw5kQq9QdO/qhzK9AT8fyfL0cIiIiNolhpsORKEQcJfcWJzu4dEQERG1Tww3HcxtI+OgVipw9HIJjl4ubvbao5eLsWLXBVTxTCoiIupEVJ4eADkmxF+N64dEYk1KFr7cl46hscGNrjmbV45lG1Pxi2VPnIwrlXh+1iA3j5SIiMgzGG46oNlju2NNShZ+TMlC7/AAhAVqEBaoQYBGhS/2puO75AyYxLrrv9yXjkeu7iXvdExEROTNGG46oJHdu6BfRCBSc8vwt7WnbF6TNCACT0zvh6e/P4rD6cX4cMd5LJ450M0jJSIicj9BFEWx5cu8R2lpKXQ6HUpKShAUFOTp4bRaak4ZvjuYgdwyPfLLqpFfpkdBeQ0GRQfhr9f2xYjuIQCAX1PzMPeTA/D1UWLnU1MQGqDx8MiJiIgc58jzNys3HVS/yEA8+7uWKzFX9w3D0Fgdjl4uwYc7z2PRjAFuGB0REZHncLWUlxMEAfOn9gEAfLbnEooqajw8IiIiItdiuOkErukfjkHRQaisMeLjXec9PRwiIiKXYrjpBARBwF8s1ZtPf7uE4kpWb4iIyHsx3HQS1w6MwICoIJTrDVix64Knh0NEROQyDDedhCAI+Ms1vQEAn/x2ETUGk4dHRERE5BoMN53I9EGRCA1Qo6zagEPpVzw9HCIiIpdguOlEFAoBE3uHAgB2pOV7eDRERESuwXDTyUzqEwYA2HmmwMMjISIico12EW6WL1+O+Ph4aLVajBkzBvv372/2+uLiYsybNw9RUVHQaDTo27cv1q1b56bRdmyT+pgrN8ezSlBYrvfwaIiIiJzP4+Hmm2++wcKFC/H888/j0KFDSEhIwPTp05GXl2fz+pqaGkybNg0XL17E6tWrkZqaig8//BAxMTFuHnnHFB6kRf/IQIgisOssqzdEROR9PH78whtvvIEHH3wQc+fOBQC8//77WLt2LVasWIGnn3660fUrVqxAUVERfvvtN/j4+AAA4uPjm/z6er0een1dhaK0tNS5P0AHNLlvGE7nlGFHWgFuHMZQSERE3sWjlZuamhokJycjKSlJfkyhUCApKQl79uyx+Tk//fQTxo0bh3nz5iEiIgKDBw/Gq6++CqPRaPP6pUuXQqfTyW9xcXEu+Vk6kqv6Sn03+ehk56YSEVEn4NFwU1BQAKPRiIiICKvHIyIikJOTY/Nzzp8/j9WrV8NoNGLdunV47rnnsGzZMvztb3+zef2iRYtQUlIiv2VkZDj95+hoRnTvAq2PAnlleqTmlnl6OERERE7l8WkpR5lMJoSHh+ODDz6AUqnEiBEjkJmZiX/84x94/vnnG12v0Wig0Wg8MNL2S+ujxNieXbEtNR870vLRP7L5o+OJiIg6Eo9WbkJDQ6FUKpGbm2v1eG5uLiIjI21+TlRUFPr27QulUik/NmDAAOTk5KCmhmcm2YtLwomIyFt5NNyo1WqMGDECW7ZskR8zmUzYsmULxo0bZ/NzJkyYgLNnz8Jkqjs+IC0tDVFRUVCr1S4fs7eY3Ne8JHzfhSJU1djuVyIiIuqIPL4UfOHChfjwww/x6aef4tSpU3jkkUdQUVEhr5665557sGjRIvn6Rx55BEVFRZg/fz7S0tKwdu1avPrqq5g3b56nfoQOqVdYAKJ1WtQYTNh/scjTwyEiInIaj/fc3HHHHcjPz8eSJUuQk5ODYcOGYf369XKTcXp6OhSKugwWFxeHDRs2YMGCBRg6dChiYmIwf/58PPXUU576ETokQRAwqU8YvjmYgR1p+ZhsWUFFRETU0QliJ1sLXFpaCp1Oh5KSEgQFde5G2rVHszHvy0PoGxGAjQsme3o4RERETXLk+dvjlRvynAm9u0IhAGm55bhQUIH8Mj0Op1/B4fRiBPv54PlZg+CrVrb8hYiIiNoRhptOLNhPjaGxwUjJKMaUf25r9PHM4ip8eM9IaH0YcIiIqOPweEMxedaMwXVL7sMDNbhuUCT+ck1v+KmV2HmmAH/8LBl6A1dTERFRx8Gem07OYDQhJaMY0cG+iNJpIQgCAGDv+ULc+8l+VNeacE3/cLz3h+HQqFjBISIiz3Dk+ZuVm05OpVRgZHwIooN95WADAGN7dsWKOaOgUSmw9XQe/vTlYdQYTM18JSIiovaB4YaaNL53KD6aMxJqlQKbTubi0S8OcYqKiIjaPYYbatakPmH44O4RUKsU2HwqFw98epA7GhMRUbvGcEMturpfOD65dxR8fcxNxvd+sh/leoOnh0VERGQTww3ZZULvUHx2/2gEalTYd6EId3+8DyVVtZ4eFhERUSMMN2S3kfEh+OLBMQj288Hh9GLM/mgve3CIiKjdYbghhwyNDcbXD41FsJ8PjmeW4rezhZ4eEhERkRWGG3JY/8ggXNM/HACQklHs2cEQERE1wHBDrTIsLhgAcORysUfHQe2Hwch9kIiofWC4oVaRw01GMTrZJtdkw0s/n8SwlzYhvbDS00MhImK4odbpHxkEtVKBK5W1SC9qn09oheV6nM4p9fQwOoVfU/NQrjdg97kCTw+FiIinglPrqFUKDIwOQkpGMVIyitG9q3+jawxGE45nlSKnpBp5ZdXILa1GQVkNkgZGYNrACJeP8b5PD+LY5WJsf2IK4kL8XP79OitRFJFVXAUAOJ9f7uHREBEx3FAbDIsLlsPNjcNiGn388e+OYE1KVqPH1x3PRvKz06BWua5waDKJOJVVCpMIpOaUMdy4UHFlLfSWc8fO51d4eDRERJyWojaQ+m5srZiqrDHgl+M5AICEWB2uGxSJOeO6o4ufD8qqDdh3wbVLyPPL9aixNLhmlVS59Ht1dvXv7zlWboioHWDlhlpNCjcnskpRYzBZVWJ2nimA3mBCbBdfrJk3QT5xXG8w4esDGdh0MheT+oS5bGyXr9Q94WYWM9y4UnZxtfzfGVeqGv0uEBG5G/8CUat17+oHna8PagymRo27m07mAgCmDYyQg430PgBsPpnr0lVW9QNNVr0nX3K+7NK6+2s0iUgv4tQUEXkWww21miAISKi3JFxiNInYejoPABo1Dk/oHQpfHyWySqpxIst1K5kuX6lbwZXFyo1LZTe4v+fYd0NEHsZwQ21S13dTIj92KP0KiipqEKRVYVR8iNX1Wh8lJvc1T0dtPJHjsnFlXqlfufG+cLPmcCaOZ5a0fKEb5JRYV8bYd0NEnsZwQ20yLE4HAEjJuCI/ttkyJXVN/3D4KBv/iknVnI2W61yh/rRUbmk1ar1o99wjGcV47JsU/P6Dve2in0hqKO4ZZt4OgCumiMjTGG6oTRJigwGYpyJKq2sB1O+3ibT5Odf0D4dSIeB0ThkyXLQBYP3KjUk0BxxvIR15Ua43YNH3xzy+Q7RUuZnYOxRAx97r5mJBBd7ffg7VtTztnqgjY7ihNukaoEFciC8A4GhGCc7ll+N8QQV8lAKu6htq83O6+KsxsnsXAHVByJlEUZQrGmpL5cibmopPZZfJ/70jLR/fJV/22FhEUUS2JdxMkMJNQces3FToDfjDx/vw2i+n8ZON/ZmIqONguKE2GxZnDipHLhfLYWVcr1AEan2a/BxpasoV4eZKZS0qa8yvvAfHBAHwrr4baWXaCEtAfPl/J5Htob18rtTbwG9sz64AzJv6FVXUeGQ8bfHaL6flLQQuFHbMgEZEZgw31GYJsea+m8PpxVZLwJtzrWXKav/FIhRXOveJUJqSCgvUoEdogPkxLwk3JpOI1Bxz5ebVm4cgIS4YZdUGPOOh6SkpNIYGaKDz9UFMsLmK19GainefLcBney/J73tTGCbqjBhuqM2kFVP7LxTiULq5sThpQHizn9Otqx/6RwZaLRt3lsxicx9PTLAvYoK1ANr2ZHX5SiU+2nm+XfRhpBdVorLGCI1KgV5h/vjnrUOhVirwa2o+vj+U6fbxSFNSUTrzfa5rKu444aasuhZPrj4KwLx3E8BwQ9TRMdxQmw2O0UGpEFBabYAoAkNidIjS+bb4ea6ampKmFmK6+CLaUklo7ZNVda0Rc1bsx9/WnsKK3ReavC75UhFueGcXDqdfafIaZziVbZ6S6hcZCJVSgT4RgZif1AcA8OLPJ5Dn5sbpHMt0mBRueoWZK2UdacXUq+tOI7O4CnEhvnjlpiEAvKtHi6gzYrihNtP6KNE/MlB+394Tv6XrtqflO1wV+TEl02oaoT5pCio2uH64ad2T1T83pMqb0q0/3vS+PG9uPoOjl0vwye6Lrfo+9jplmZKqf7//eFVPDI4JQmm1AasPube5OKuJyk1H2chvR1o+vtqfDgD4x60J6BNhDmc5pdUweNH2AUSdDcMNOYU0NQUASQPsCzdDYnSIDNKissaIXWcK7P5eZdW1WPjtETy35jgu2Wj8lCo3sW2s3Ow7X4iP61Vrjl4usfl1rlTU4Ldz5oNAD1wscmnvi1S56R8ZJD+mUirwf8NjLWMuctn3tkVaBh5luc9y5aag/U9LVegNeOq/5umoe8fHY2zPrggL0MBHKcBoEpFXpvfwCImotRhuyCmkcBMT7IsBUYHNX2whCAKuHxIFAHhv+zm7Q8GRjBIYTeZrj1xuvEtvptW0lLmiUKY3yPvw2KNCb8Djq49AFIHfj4prdun6ppO58niyS6qtDu10Nmml1ICoIKvHR/cw7wSdfOmKWysOUthrWLlJL6xs9xsn/nI8B9kl1Yjt4osnr+sHAFAoBEQEtb1Pi4g8i+GGnGJWQjRmj+mGV24ebHVQZkv+OLkntD4KJF+6YndjcfKlur4WW0cQSNNSMcF+8FOr0MXPvCTdkSerV9edQkZRFWKCfbF45gBMH2Re3bXBxpERa49lW71/4KJrqidl1bXIKDL/DA0DZP/IIARqVSjXG6z2wXG1nFJpWspcuYkM0sJPrYTBJCLdRRs0Oos0zXjriFj4qVXy41K1z1tW2BF1Rgw35BRaHyVeuXkIru7X/CqphiKCtJgzPh4A8I8NqTCZWq7eHKrXtHusQeWmXG9ASZW5QhPTxfwkJT1ZZdvZd7M9LR9f7LP0Ydw2FIFaH1w7yDzVtu+C9dL1kspa7D5rnlKTVoi5KtxIS8CjdFoE+6mtPqZUCBhtOcdr34VCl3z/hupv4CdVbgRBQI/Q9n8MQ4XegB1n8gEA1w223kk7po19WtRx6Q1G9lp5CYYb8rhHJvdCoFaF0zll+Plo8zvDmkyi1Yqk45klVoFImpLS+fogQGN+Ne7IK/EKvQFPra7rwxjfy7zrbveu/vLS9S2n6ipMG0/mwGAS0S8iEHeM6gYA2H/BNeHGVjNxfdLU1D4Xff+GiipqUGMwQRAgT+UA9VdMtd++m19T81BjMCG+qx/6RVjfz2gnbB9AnlVYrseRjGKHPie3tBoTXvsVt/1nDwOOF2C4IY8L9lPj4cm9AABvbEprtlfjXH45SqsN0PoooFEpUKY34FK96Y/6e9xIYhxoKt58Khc5pdWICfbFU9f1t/rYtTampn6xTG1cPyRK7ss5l1+BwnLnN6PKzcQN+m0kUrg5cLHIrgpYW0lVm9AADdSquj8ldSum2m+4kaakpg+ObDSN2tbtA8izTCYRf/h4P25cvtuhrRne/fUsCsr1OJxejK8OZLhwhOQODDfULsydEI/QAA0uFVbim2b+sEhTUkNjg+Wm2mP1+m7qr5SSOPJKXDqp/MZh0fBVK60+Nt0yNbXjTD6qaowoqarFTsvUxvVDItHFX40+4eaqxYGLzt/v5nS27WZiyeAYHfzUShRX1iItz/V9Nw2biSU92/leN9W1Rvxq6e+aMTiq0cfZc9OxbTqVK78Q2GjnHlrZJVX4an/d3503NqbK09vUMTHcULvgp1bhz9f0BgC8veUMqmps73tz6FIxAPO5SkNizMc+1G8qrr9SSmLvXjc1BhO2p5rDSpKNvXoGRgUhtosvqmtN2HEmH1tO5aLWKKJPeAD6WKY2RlmqJwed3HdjMok4bZmWGtDEtJSPUiGfN+WqqbH66pqJG4QbqeemnR6guetMASpqjIjSaTHU8jtUnyOVPmpfRFHEu9vOye9LLz5asvzXs6gxmjA6PgR9wgNwpbIW/95yxlXDJDdguKF2487R3RDbxRd5ZXqs/O2izWukys3wbnXhpn5T8WV5pVTjcNPSK/F9FwpRrjcgNECDYbHBjT4uCIJ8JtaGEzlYZ1klNWNI3at/qanX2U3FGVfMxy6oVQq5YdcWuanYDfvdSGGx4W7U0rRUUUWN088Nc4b1lmnF6YMioVA0XtknhbXSagPKHNg+gDxvz7lCHMkolqdJj2eWoqCFKeLLV+qqxX+9ti+e/d1AAMCney7iQjsN6NQyhhtqN9QqBRYk9QUAvL/9XKPqTUllLc7kmfs4ErsFY3C9yo3UY5JpY1pKCjo5pdXyfjS2bLaUsJMGhNt80gPqpqY2n8zFjjTzKqmZ9cKNVLk5nlWKCr2hxZ/ZXlKZvW9EAFTKpv/ZjrGczL3vgms3EwQaH70g8VOrEG15rL3tVFxrNGHzKfP/54arpCSBWh8Eac3N6FJfEXUMUtXmzlFx8vSttJqxKct/PYtao4gJvbtiTM+umNw3DFP6haHWKOLVdadcPmZyDYYbalduSoxBtxA/lFTV4qcj1gdBHs4wV226d/VDaIAGfSICoG7QVFx/jxuJ9a6ztp+sRFGUN+hrboflkfEh6OqvRmm1ATVGE3qG+aOvZct+8/f1RUywL4wmEYfTix2/AU2Q9q6pvzOxLUNjdVCrFCgo17v8VWdWg92J65P6btpbU/G+80UorqxFV381RlmqXLa0te+mutaI1cmXW6wakPMcvVyMXWcLoFIIePCqnriqr3ml4/a0pqem0gsr8d1B85El0gsrAFg8cwCUCgGbTua2GI4uFlTg9fWnkV7Yvvd1ao3iyhqcdUP/nisw3FC7olQImD3GvKR61Z5LVtWHQ5awMKKbua/ER6nAwHpNxdW1RuRbtsyv33OjUAiI1DXfVHwyuxRZJdXQ+igwsU9os+OrH35mDolqtNpmVLyl76UVU1OiKNo8Z6upnYkb0voo5d2iXb0kPKfEds8NUP908LYFLFEUcffH+/C7f+90SlBYf8I8lThtYASUTVTngLb33Xy25xIe/+4Ibn53NzLa+WaG3uLdX81VmxuGRSO2ix+u6hMGANh5pqDJKua/t56BwSTiqr5hGFkv7PYOD8TdY7sDAF7+38kmK74/HL6MmW/vxLvbzuH1Daed+eO0Cw99lozpb+602lvMHjvS8nH5imd/7xluqN25bWQc1CoFTmSVIqXeXhWHLDsTJ1qaZgFYNRVLT0R+aqW8K7EkWie9Erddudl80rx6ZlKfMGh9lDavkUgb+gG2V9tIU1MH7AgXv57Ow4JvUnDnB3sx5Z/bMHDJBvR/bj3+8tVh1BjqlsRLlZummonrG2v5/q5sKjaZxGbDjbP2ujlfUIGdZwpwPLMUD3x60OEDVuszmURsOGGuzk1vYkpK0tbl4L+dM7/azyiqwh3/2YOL7N1wqbN5ZXIv1SOWbSVGxneB1keB/DK93Ixf38WCCnx/2FwdXpDUp9HH50/tA52vD07nlOH/3vsNq5Mvy79/5XoDFn6bggXfHEGFZfp8e1p+uzlypLBcjysVbet3yy/TY/+FIhhNIlbsutDyJ1jsSMvHA58exB3/2Sv/jfAEhhtqd0L81Zg1NBoA5JO/jSZRDjrDuwXL19ZvKs6s10zs6N4lUh/GNDsO/ZzYJxRje4Zg5pAom+doSU29hzOuWAWUhjKLq/Dw58n44XAm9pwvxIWCClRZ/nj+dCQL878+DIPRhHK9QT7KoKk9bqy+fw9z340rw01hRQ1qjI038JNI4eZ4ZkmzfU4tqf8zpGQU47GvU1r99Q6lX0F+mR6BGhUm9Gq6OgfYv8LOFpNJlI8ICQ3QIKukGrf/Zw/O5rWvKTpXKSzXY8upXHx/6HKb/t874r1t5wEA1w6MkFcualRKjLX0oNlaNfXWljMwmkRM6ReGxG5dGn28i78aL94wCCqFgJSMYjz+3RGMfmUznltzHL97eye+P5QJhWCezgrxV6Os2mB1NIynlFTVYvqbOzHjrZ1tejGw62zdPVt/PAe5pS3/W9hzrhAPrjqIGqMJQ2N1CA1Qt/g5rqJq+RIi97t7XHf899Bl/O9oNp6dORB5ZdUo1xvgr1Za7Shbv6n4so1l4JLm9rrJLqnCscwSCAJwzYCWj4/QqJT4+qFxTX68d3gAuvj54EplLY5nlWC4jT+cAPD3X05DbzAhIVaHuRN6IFKnRWSQFmfzyvHoF4fwy/EcLPj2iFwejwjSIMS/5T8Ww7sHQ6UQkFlchYyiSsSF+LX4OY6SXpGZ+5kav0Ya0b0LdL4+yCqpxuZTufLZXI6Sql+T+4Zhz7lCrD+Rg6XrTskrWhwhbdw3dUC41aaDtki/L63puTmTZ95o0k+txP/+PBFzVuxHam4Zfv/BHnz+wJgW+6bau5SMYvx8JAtKhQAfpQAfpQJKQcDZ/HIcTi+2OlOsssaIP1h+f10ls7gKP6aYKzCPTult9bGr+oRhW2o+dqQV4KGresmPH88swRrL5yyc1q/Jr31TYgzG9+6K7w5exlf703H5SpX8gitap8VbdyZiVHwILhVV4PtDmdh6Ok8OVPWZTCLWHsvGgKgg9A4PaPRxZ/ruYIY8hbvnXCGm9HfsSBzJzrS6XiODScSX+9KxYFrfJq8/eLEI9396AHqDCVP7h+Ot3yc2u/jB1Vi5oXYpIVaHITE61BhM+PZghvyKKCEu2OofTP2m4t/Omc9UirHR4Npc5Waz5TiF4d26IDRA0+axC4Igz983NTWVfKkIPx3JgiAAr9w8BDclxmBsz66ID/VH0sAIvDt7OFQKAT8fycKCb1IAtNxMLPFTqzAk1hz6XFW9yZJWStm41wDgq1biLkvv1McOlLQbkvqW7p/YA/+4bSgA4KNdF/BpE1sFNEeqztkTtJrrublSUYOPdp5HeROr4Q5eMo95WFwwInVafPXQWAyKDkJBeQ3u+nCfS3avdqfHvzuCj3ddwAc7zmP5r+fw5uYzWLYpDT+mZMnBRnrF/t9Dl10+nrc3m/tmxvfqKvebSaSm4v0Xi6xWX/59/WmIInBDQrT8b6Up4YFazJvSGzuemIJP7xuNmUOjcPvIWKybP0luSr/GEiC2nLK9aeBney/hz18dxrX/2o5F3x9Fnh1VkNYwmkR8uuei/P7mJsbTElEUseOMOdzcOdr87/jL/elNVqKPZBTj3k8OoLLGiEl9QrF89vAWX0C4GsMNtUuCIMgViy/2XULyxbr9beqr31S81fIP2Xblpumem812rJJyVHP73ZhMIl76+SQA4PYRcXL1qb6kgRF4565EKC0VGKDlZmKr729H343eYMR9Kw/g7o/3OdwrIPfb2JiSkswZFw+VQsD+C0U2T29vSVZxFS5fqYJCAIZ374Ibh8XgienmV9kv/nwCO5pZBdPQpcIKXCyshEohNNswLpF+X3JKGm8f8PqGVPxt7Sm8uSnN5ucetPyuSsdxhPir8eUDY9EnPABFFTX4fG+63eOWlFXXYt/5Qny86wIWfpuCh1YdlJvnbUm+VIS7Ptzb6GDZtsorq8bZvHIIAvDgpB64d3w8Zo/phttHxmJBUl+sum80jjx/LdbNnwSFABxOL3Zpv9HZvHJ8l1y3R01DvcICEK3TosZgkg+U3ZGWj51nCuCjFOTfJ3soFAIm9w3D8ruG4/VbE6wOr53UJwwqhYBz+RW4VGj984qiKFd7TCLw1f4MXP3PbfjXpjSnbhcBmHv4MoqqIM3Kbz2d12Qz9bcHM/Dm5jSbR7WczilDQbkevj5KPDtzAMIDNcgv01sdPSM5mVWKe1bsR7negDE9QvDB3SNb7Ft0B4YbardmJURD5+uDjKIq+UDNEd0bT/FIfTdSY5+tyk1Tr8TL9QbssVR8pg1sXfnWFrmp+OKVRq/UfziciSOXSxCgUeGv05su8143OAr/umMYpEU9tvp7mjLG8v13nS1oct79H+tTsfV0HnaeKZDvgb3qKjdNh5tInRYzh5obrltTvZGC4eAYnXwI6qNX98JtI2JhEoEPd563+2tJQWhE9y4I1Pq0cDUQHqiBUiHAYBKtQoQoitieaq70rT+RY/OJQ6rc1F99o/PzwZ+nmptWP9t70e5eiOLKGsz69y4MeWEj7vhgL17+30l8fygTG0/m4nPLE6Yt72w9i9/OFWL+N4ehN7S+76KhAxfMwW1AZBAWzxyIF24YhFduHoLXb03A/KQ+uKpvGHS+PggP1GKiZbWSNP3T0K4zBbj53d2tCr6SZRtTYRLNL0xGdG+8tF8QBEyqt2rKZBKx9BfzqqZ7xsU7bcpW5+sjV3G2ns6z+tj+C0U4m1cOP7USn8wdhcRuwaisMeKtLWcwddn2RmGoLaSqzT1ju8PXR4nskmqcyCptdF1OSTWe/u9RvLn5DLal5TX6uPTvZWzPEPhrVHL1ZlW9qhBgftFwz4p9KKmqxYjuXbDi3lGNjq3xFIYbard81UrcNiIWAFBrND+JJNZrJpYMaVD5iO3S+A+WtKKnpKrWajphZ1o+aowm9Aj1l5tgnWFQdBDCAjWW5r4d8h46FXqDvGR03pTeCA9sOhwA5rL5B3ePxL3j4x3qWxndoyt0vj7ILK7Ck6uPNnoS3paah4/qBY5fjmfb/bWB5peB13f/xB4AgJ+PZNnVkFifVHWqvx+NIJj3MAHM4cfekCDtdTK5X5hd16uUCkQGNe67OV9QIe/vc/lKVaNVOLml1cgoMlebGv6uzhgciWidFgXlNfgpJcuucXx7MEM+Oy0m2BfTBkZYnXFmS3WtEXstO1Sfz6/A+9vsD4Et2W+pfkiVwebcnGheFPBjSlaj379aownP/HAMh9OLsfSX1m2UdySjGL8cz4EgAE9e13QF5qq+5v/nO9LysSYlE6eySxGoVeFPDfpz2kqammoYbr7cb67U3ZAQjSn9wvH9I+Px7uzhiAvxRU5pNf7cYGVka53NK8POMwVQCMADk3rKFcotpxqHl9XJGZAKNp/taRySd1qmpKRgeNeYblApBBy4eAUnLWEpr6wad3+8HwXlNRgYFYRP5o6Cv6b9tPEy3FC7NrteM2LPMH+rUrCk4bROrI1pKatdZy1PViaTiNXJ5p6ApAHhjVZYtYWPUoFP545Gv4hAFJTX4MFVB/H4d0ewbGMackv16Bbih/smxtv1tZIGRuCFGwY5VOoN0Kiw/C5z385PR7Lwr3pTKPllejz+3REAkHsUNp7IhcGBqansJo5eaGhobDBGxXeBwSQ2etXXEqly03CzvT7hAQgL1KC61mTX/ht6g1Hux5L2PrGHrSb0XWesN3Tb1OBgRmlKql9kUKMKkY9SgTnj4wEAH+063+IO0qJY9/v58k2Dsfvpa/DhPSPxwg2DAJif3G0t9z148Qqqao3wUZp/n5f/erbNS/Il0t5JY+wIN9cOjISvjxIXCipwpMH02A+HM+X+nN1nC3Eiy7HqjSiK+Pt684uEWxJj0Tei6armhN5doRDMjd7SjsOPXt0bXexozneEtBhh3/ki+QVUUUUNfjlmnsqZPcb8t0wQBFw/JArfPDQOwX4+OHq5BK+vt3+PnKZ+bz79zRxSpg6IQFyIH5Is49ly2vp31GQS8c3BukNCt6XlW+3FVFVjlHvdpJ6liCCtvKP3Z3svorS6FveuOID0okp0C/HDyvtGIciOiqg7MdxQu9Yj1B+TLK9Amlp1JDUVA4BaqUBYE03B9XedNZlEPPvjcWw5nQdBAG5IiHH62AdGB+GnP0/AHyf3hCAAq5MvY8Vuc7Xkmev7Q6Nybfl2Yp9QvHrzEADA21vP4ruDGTCZRDyx+ggKymvQLyIQnz8wBl38fFBYUePQpoPZpeYn/OhmpqUkUvXmi33pTR6I2tCVihqk5ZqfkKVNESWCIGBib/PvRMOwYUvyxSuorDEiNEAj92fZw1YTuvSKVlrx0ijcXJICme3f1d+P7gY/tRJpueXY1cLOt8cyS5CWWw6NSoEbEqLlx6N0vugXEQiTCJtfY7tlmuGGhBhM7huGGqMJz6453ubjOIora5Caa65UjbIj3PhrVPKeUGsO101N1RpNeGfrWQDm6RwA+Hin7WnLWqMJ64/nNGrA3XW2AL+dK4RaqcCCaY33qKkv2E+NoZaz4grKaxCl02LuhPgWx++onqH+iO/qhxqjSf69XJ2cgRqjCUNidI0al6ODffGPWxMAmJvkt55uvvlXFEWsOZyJCa9txW3v/2YVSEqra+Xm7bmWAC2tkjp6ucSqarrnfCEyiqoQqFFhdI8QiKL536Zk/8Ui1BhMiNJprarZ94wzf90fDmfigZUHcTK7FKEBanx2/+gWK9CewHBD7d7zswZi5pAoPDy5l82P128qjgrWNnkulNR3c/lKFZ798Ti+3JcOQQCW3ZbQ4oqJ1tKolFg0YwC+/eM4dLPM74/tGdLqpdGOun1UHOZNMd+3Rd8fwxOrj2Jbaj40KgXevjMRARoVpllOQJdeYbak/gZ+kS1UbgBg2sBIxIX4oriyFt8ftm/1jFS16R0egK42wuoES7hpaWt8ANhumb65qm9ok78btjQMN7VGE/aeN1eAnp05AIJgDiDZJXXhR1rVZ6s3DDA/md8+Mg4A8FETT+gS6ViA6YMi5RAgkabXbB0tIJ15dnW/MPztpsHQ+ijw27lC/HDYdu+LvQ5evAJRBHqF+du9qvCmRPOLhp+PZMlN61LVJjRAjf/cPQKAeV8nWxu+PbfmOB7+PBkTX/8Vz/94HNkl5hcmr69PBQD8YWx3m9PQDV1Vr4n8r9f2c0nDqyAIcqDYejoXJpOIr/abKyTSysGGpg2MwL2WMPL4d0eb3PTuTG4Z7vxwLx77JgVZJdU4cPEKZr69ExstDb7fHbyMyhoj+kYEYFwv81L08EAtEiyV2fpTZV9ZpsluTIzGA5YXHt8ezJCneHdafqeu6hNmVc0eFd8F/SMDUV1rwv6LRQjQqLBy7mh079r0Qb6exHBD7V7v8EAsnz282f0hpL4bW83EEunJ6l+b0qyCzS3DY507YBtGxYfgl/mT8O87E/HBPSOdOgXWkr9O64ffDY2CwSTKr+6enTkA/Sy7HUunmq8/kWNz5URDBRV61BpFKARz421LlAoB9443/xFdseuCXd+jqSkpiVS5OZpZgpLK5k/u3p5q6bfpa/+UFNB4hV1KRjHK9QaE+KtxVZ8wuZK4uV4/ldS8ObKZc6vum9ADgmAOJmdybZ/bU11rxE9HzH05t41s/Psp/Szb0/KtKjLZJVVIzS2DIJjvUVyIH+ZPNTet/23tqTbtWitV9qRNIu0xqXcouvqrUVhRg11nClBrNOHfW88AAP54VS+M7dkVo+NDYGiwhBkwr/z52nJad43BhE/3XMLk17fh3pUHcCzT3JAvBfeWTB8cCYVg/jtxc6Lzq7SSqf3NLxR+Tc3Hb+fMG3MGaFRWlbeGFl3fH4Oig1BUUYPHvjkMo0mEKIooqapFWm4Zlv5yCjPe2om954ug9VHgL1P7ILFbMEqrDXjos2S8/L+T+Mxy7+aMj7f625LUYIl6UUUNNlp26f79qG64pn84onVa8/SZpe9O6uWa1Nd6VaEgCPK0qlqpwAd3j7C50rO9YLghrzClv/mPfXNPKtKTVWFFjVuDjcRfo8KshGi3z00rFAL+eVuCXE2YNjDCamO1Cb1CEahVIb9Mj2Q7eljkDfwCbW/gZ8vtI2MRoFHhXH5Fo4ZLW/a30NsRqdOid3gARBHYc77p6k1uaTVO55if7Cc50G8DADENem6kKanxvbpCoRDkitdGS7g5klEMo0lEtE7bbMju1tUP11o+V5qmbGjLqTyUVNUiSqfFeBu7KY+M7wJfHyXyy/Ty0RxA3SqXhNhguafkgUk90C8iEEUVNfjb2lOtnp5ypN9GolIqMMvyxP7D4Uz8cCgTGUVVCA1QY/bYbvL4AOCLvZfkpdHFlTV46r9HAZjD4JcPjMGYHiGoMZrkn/HBST1tVvVsGRStw6aFk/Hlg2OaPVOsrUb3CIG/2vz/5YWfTwAAbkqMbrbRVqNS4t93JsJPrcTe80WY9PetGPT8BiS8uBHX/msH/rP9PAwmEUkDIrBpwWQsnNYX3zw0Tq66fLzrAi4WViJIq2oU3KZatreQVk3+cDgTNUYTBscEYXCMDiqlQq4qfbbnEnJKqpGWa17qb2sX79tGxOKv0/pi5X2jML53y1sqeFK7CDfLly9HfHw8tFotxowZg/3799v1eV9//TUEQcBNN93k2gFSu3dN/wgcWJxk84wYSVyI+QnHE8HG07Q+Sqy6bzT+c/cI/PvORKtXd2qVQn6iXnes5VVTGUWWZeB2TElJArU+8pPZ39efbrZ5uUJvwHFLBaS53g6576aZqSnpiXBojM6u3Z3rk6elLNNOu87UlesByPds7/lClFbX4qA0JdVMwJY8MMm84uu/hzJtbuon7d1yy/AYm0/GGpUS4y3TD/WnpuRVYfWqVD5KBV69ZYjl+13GMz8cd3hfowq9QV6ybc9KqfqkJ9yNJ3Pw1pa6qo2f2vyEP3VABOK7+qG02oDvLI2uL/x0AnllevQM88eT1/XD+N6h+OaP4/DtH8fhmv7hmNQnFPdbQpG9eoUF2LUNQFuoVQo5REvHbdw1uuUdmnuGBeBvNw0GAGSVVKPS0pum8/VBQlwwPrpnJD6aM1Jeuq5WKfDs7wbig7tHyAslzP1c1iFqQFQgonVaVNeasPtsAb62TEndMapumuz2UXHwUQo4lF6M97ebDx8dGqOz2XCtUirw56l9bAbu9sbj4eabb77BwoUL8fzzz+PQoUNISEjA9OnTkZfX/Ku7ixcv4vHHH8ekSZPcNFJq78ICNc1O90ztH4E/jO2GD+4e2amCjcRfo8L0QZE2+w2utxwAuv54y1NT0pkzQx3sU3r06t7o4ueDM3nlVqs1Gjqcbq6AxAT7NlsBqeu7aXqPHltP9vaSwk1xZS1yS6vlFT/SEtteYQHoGeaPWqOI7an58lTayCb6beob2b0LEmLNO3D/Z4f1Uu3c0mo5lN06Iq7Jr1HXd2P+W2mo18jacMn7iO5d8OINgyAI5p6LuZ8cQElV89N59R1KvwKjSURsF1/5vthraKwOPUP9UV1rQmaxddUGME9bSk3nK3ZfxNqj2ViTkgWFALxx+zCr39fRPUKw4t5R+Oz+MfLeR+1N/SNcErsFY2C0fU3stwyPxX8fGY8vHxyDXx+/Gqdeug5Hnr8WP86bgKSBtjcYvXZQJNY/dhX+cetQm5sYCoIgj+dfm9NwJq8cWh8FbhxWN00WHqjFdZZ//ystO387WuVsjzwebt544w08+OCDmDt3LgYOHIj3338ffn5+WLFiRZOfYzQaMXv2bLz44ovo2bOnG0dLHZmvWom/3TREfsVNdSb2CYW/2rzp15HLxU1eZzKJ8r4ZUx3c0Vnn64P5lo3s3tiYhrJq20+u9u6lMqZnCJQKARcKKnD5SmWjjxtNojyVdFUrwk2Q1geBlifQ1cnmQyB7hvlbPblLv0vrT+TgcHoxAPOUUUsEQZDPOvpgx3m8uu6UHCq/P5QJk2gOQD1Cm27WlALbwYtXUK434MjlYpRWG8yv9i2rg+qbMz4eH949En5qJXadLcCt79WtuKnQG5B8qQir9lzED4cvN5q6kqYJHa3aSD/rTfWmSx6e3KtRheH/RsQi2M8H6UWVeOybwwCAR67u1eg4hY5gSr+6cHPXaNuNxE0Z0b0LxvcKRY9Qf7s3w4sO9sVtI+OaXH0p/Ts9nmmuhs4c0nhq/O4G53+15t9Le+PRcFNTU4Pk5GQkJSXJjykUCiQlJWHPnj1Nft5LL72E8PBw3H///S1+D71ej9LSUqs3IrKm9VHKfwR/Od70qqnjWSXIK9PDX63E2J6OP9HNHtsdPUP9UVhRg/e2nbN5zf4WmoklQVof+cnP1qqpo5eLUVJVi0CtqtVPklKQkaZLJjXoM7hWXmmWjXK9AQEald1ngF0/JFLe/v+DHefx568Po7rWiNWWKalbRzRfXeze1bz02GASsedcodw4PbFPaJN9JUkDI/DtH8chMkiLM3nluOGdXZjyz20Y/MIG/N97e7DkxxNY8M0RfH/IemVVa/pt6rs5MQYalQJROq2830t9fmoVZlt6P2qNIvpHBuIvU5tf4t1ehQVq8MfJPTFtYITcb+RJ43p2hV+9oPT70Y2rgaPiu8gHEvurlTY3S+1oPBpuCgoKYDQaERFh/QowIiICOTm2/8Du2rULH3/8MT788EO7vsfSpUuh0+nkt7i4psu8RJ3Z9UPMy9PXHctusulUOmR0Up+wVu3T46NUYNH1AwCY9/ZoWHGpMZjkCsjoHi1XQCbIfTeNp6akKalJfUJbfTqxtI/PxULzOCc2KNcPizMftirN5CV2C7a7YVUQBMyb0hv/uiMBPkoBa49mY9a/d+FcfgW0Pgr56Irm1K2ayrN7Cm5wjA5r5k3AoOggXKmsxYWCCogiEBmklVcdvvDzCXmJe3WtESkZxQAcWylVX1yIH36ZPwk/zpvQZEVizrh4aH0U8FEKeOP2YS7fB8qVFs0YgA/vaR9nLGl9lHJ/Wq8wf5vTpoIgyHv/XDMgwu6FAu1Zh/oJysrKcPfdd+PDDz9EaKh9DU2LFi1CSUmJ/JaR0fRcP1FnNrlvOHx9lLh8pUouYTckLSmdOqD153AlDQjH2J4hqDGY8I8NqVYfO5ZZAr3BhBB/tV3HYUh/tH87W9CoV2h7mnUDcGvUn4JSKoRG1SqlQpB3ggWAkTbON2rJzYmx+PS+0QjUqnDG0oQ6Y3CUXc2vUm/N+uO5OGpp+LXn543UafHdw+Pw7uzh+Oz+0Uh+Ngl7n5mKHx4dj4S4YJRVG/DUf49BFEUcyShGjcGEsEAN4ru2/iymnmEBCG/moNXwIC1+eHQC1sybYHefCtnnvok9EB6owV+v7ddkX+Ido+Lw+f1j8LcbB7t5dK7h0Y6s0NBQKJVK5OZa78yYm5uLyMjGm5ydO3cOFy9exKxZs+THTCZz179KpUJqaip69bLe90Cj0UCjsW+5IFFn5qtW4pr+4Vh7LBs/H81qtLFhdkkVTmSVQhDqdj9tDUEQ8OzMgZj1zi78mJKFmxJjoK814eDFImyzBJJR8V3s2gtoWFww/NRKFFbU4HROmfykWFxZgyOWakNb+gfqh5vEuGCbgWPawAh5PxZ7+m1sGd8rFKsfHo+5n+xHVkl1k5u+NTS2Z1eolQoUWFZc9Y8MRGQL531J/NQqXD/EujqkUiqw7LahuP7tXdiRlo+vD2SgwHJw6OgeIS7fn8mRk+/JfmN7dsX+xUnNXiMIgtws7w08WrlRq9UYMWIEtmzZIj9mMpmwZcsWjBs3rtH1/fv3x7Fjx5CSkiK/3XDDDZgyZQpSUlI45UTURlLj55f70htt+CY1EifGBdu9Q21TBsfocEuiuadk7icH8PDnyfho1wV5+ezMofb1KqhVinonoJuD0YGLRbjrw30wieZzqBxd3VNf/dVaTa0gmdA7FBFBGoQGqNvUANsvMhDrF1yFX+ZParHfSOKnVmFUvem71qwKa6h3eCCeuNbcC/S3/53EWsv2AK3ttyHyBI+vpVu4cCHmzJmDkSNHYvTo0XjzzTdRUVGBuXPnAgDuuecexMTEYOnSpdBqtRg82LpkFhwcDACNHicix03tH46BUUE4mV2KD3aex1PX9Zc/tlmeknLOarMnpvfDltO5KK6sRd+IAIyMD8Go+C4Y3aNrs0vAG5rYJwy/puZj/fEcnMgqxY+WE7eDtCo8+7uBbRpj/WDU1KtarY8S//vzJIgQ23wqcpDWB0FRju3FMrlvmLwc3lmrXO6b2AMbT+bgwMUr8snnrVkpReQpHg83d9xxB/Lz87FkyRLk5ORg2LBhWL9+vdxknJ6eDoWiQ7UGEXVYCoWAhdP64oFVB7Fy90XcP7EHQgM0qKwxyCdrJzkp3ETqtNjx5BSIJkDn1/rN1aS+m0PpxTiUXgxBMG8t/8T0fg5v3NdQzzB/aFQKy/Lqpvf1CbPjGApXuaZ/OF5ddxqBWlWrp8UaUlp2tb7uzZ2oqjVC5+uDvuFNn7xN1N4IYluPiu1gSktLodPpUFJSgqAgzu8SNSSKIm5avhtHLpfggYk98OzvBmLDiRz88bNkxHbxxc4np7j1bKyWiKKIyf/YhvSiSnmzOmeeeXM8swT+GlWze8542uaTuQgJUMvnXTnL53sv4dk1x3FLYgzeuGOYU782kaMcef72eOWGiNoXQRCwYFpf3PvJAXy29xIeuqqnvEoqaUBEuwo2gHm8n98/BpnFVRjb0/lNr+35cEBJUzvYttUfxnbH8G5d0L0Nq6SIPIHzPUTUyOS+YRjRvQv0BhPe+fUstp42N+u2ZQm4K3Xr6odxvbq2u+DlDQZGB7W5l4jI3RhuiKgRQRDw12nms2o+23sJBeV6BGhUGNPKTdyIiNyJ4YaIbBrfOxRje4ZA6sq7qm8o1Cr+ySCi9o9/qYioSQun9ZP/e2p/HjhKRB0DJ1KJqEmje4TgrjHdcDKrFNcOYrghoo6B4YaImvXqzUM8PQQiIodwWoqIiIi8CsMNEREReRWGGyIiIvIqDDdERETkVRhuiIiIyKsw3BAREZFXYbghIiIir8JwQ0RERF6F4YaIiIi8CsMNEREReRWGGyIiIvIqDDdERETkVRhuiIiIyKsw3BAREZFXUXl6AO4miiIAoLS01MMjISIiIntJz9vS83hzOl24KSsrAwDExcV5eCRERETkqLKyMuh0umavEUR7IpAXMZlMyMrKQmBgIARBcOrXLi0tRVxcHDIyMhAUFOTUr03WeK/dh/fafXiv3Yf32n2cda9FUURZWRmio6OhUDTfVdPpKjcKhQKxsbEu/R5BQUH8x+ImvNfuw3vtPrzX7sN77T7OuNctVWwkbCgmIiIir8JwQ0RERF6F4caJNBoNnn/+eWg0Gk8PxevxXrsP77X78F67D++1+3jiXne6hmIiIiLybqzcEBERkVdhuCEiIiKvwnBDREREXoXhhoiIiLwKw42TLF++HPHx8dBqtRgzZgz279/v6SF1eEuXLsWoUaMQGBiI8PBw3HTTTUhNTbW6prq6GvPmzUPXrl0REBCA//u//0Nubq6HRuw9XnvtNQiCgMcee0x+jPfaeTIzM/GHP/wBXbt2ha+vL4YMGYKDBw/KHxdFEUuWLEFUVBR8fX2RlJSEM2fOeHDEHZfRaMRzzz2HHj16wNfXF7169cLLL79sdT4R73fr7NixA7NmzUJ0dDQEQcCaNWusPm7PfS0qKsLs2bMRFBSE4OBg3H///SgvL2/74ERqs6+//lpUq9XiihUrxBMnTogPPvigGBwcLObm5np6aB3a9OnTxU8++UQ8fvy4mJKSIl5//fVit27dxPLycvmahx9+WIyLixO3bNkiHjx4UBw7dqw4fvx4D46649u/f78YHx8vDh06VJw/f778OO+1cxQVFYndu3cX7733XnHfvn3i+fPnxQ0bNohnz56Vr3nttddEnU4nrlmzRjxy5Ih4ww03iD169BCrqqo8OPKO6ZVXXhG7du0q/u9//xMvXLggfvfdd2JAQID41ltvydfwfrfOunXrxMWLF4vff/+9CED84YcfrD5uz3297rrrxISEBHHv3r3izp07xd69e4t33nlnm8fGcOMEo0ePFufNmye/bzQaxejoaHHp0qUeHJX3ycvLEwGI27dvF0VRFIuLi0UfHx/xu+++k685deqUCEDcs2ePp4bZoZWVlYl9+vQRN23aJE6ePFkON7zXzvPUU0+JEydObPLjJpNJjIyMFP/xj3/IjxUXF4sajUb86quv3DFErzJz5kzxvvvus3rslltuEWfPni2KIu+3szQMN/bc15MnT4oAxAMHDsjX/PLLL6IgCGJmZmabxsNpqTaqqalBcnIykpKS5McUCgWSkpKwZ88eD47M+5SUlAAAQkJCAADJycmora21uvf9+/dHt27deO9bad68eZg5c6bVPQV4r53pp59+wsiRI3HbbbchPDwciYmJ+PDDD+WPX7hwATk5OVb3WqfTYcyYMbzXrTB+/Hhs2bIFaWlpAIAjR45g165dmDFjBgDeb1ex577u2bMHwcHBGDlypHxNUlISFAoF9u3b16bv3+kOznS2goICGI1GREREWD0eERGB06dPe2hU3sdkMuGxxx7DhAkTMHjwYABATk4O1Go1goODra6NiIhATk6OB0bZsX399dc4dOgQDhw40OhjvNfOc/78ebz33ntYuHAhnnnmGRw4cAB/+ctfoFarMWfOHPl+2vqbwnvtuKeffhqlpaXo378/lEoljEYjXnnlFcyePRsAeL9dxJ77mpOTg/DwcKuPq1QqhISEtPneM9xQhzBv3jwcP34cu3bt8vRQvFJGRgbmz5+PTZs2QavVeno4Xs1kMmHkyJF49dVXAQCJiYk4fvw43n//fcyZM8fDo/M+3377Lb744gt8+eWXGDRoEFJSUvDYY48hOjqa99uLcVqqjUJDQ6FUKhutGsnNzUVkZKSHRuVd/vSnP+F///sffv31V8TGxsqPR0ZGoqamBsXFxVbX8947Ljk5GXl5eRg+fDhUKhVUKhW2b9+Ot99+GyqVChEREbzXThIVFYWBAwdaPTZgwACkp6cDgHw/+TfFOZ544gk8/fTT+P3vf48hQ4bg7rvvxoIFC7B06VIAvN+uYs99jYyMRF5entXHDQYDioqK2nzvGW7aSK1WY8SIEdiyZYv8mMlkwpYtWzBu3DgPjqzjE0URf/rTn/DDDz9g69at6NGjh9XHR4wYAR8fH6t7n5qaivT0dN57B02dOhXHjh1DSkqK/DZy5EjMnj1b/m/ea+eYMGFCoy0N0tLS0L17dwBAjx49EBkZaXWvS0tLsW/fPt7rVqisrIRCYf1Up1QqYTKZAPB+u4o993XcuHEoLi5GcnKyfM3WrVthMpkwZsyYtg2gTe3IJIqieSm4RqMRV65cKZ48eVJ86KGHxODgYDEnJ8fTQ+vQHnnkEVGn04nbtm0Ts7Oz5bfKykr5mocffljs1q2buHXrVvHgwYPiuHHjxHHjxnlw1N6j/mopUeS9dpb9+/eLKpVKfOWVV8QzZ86IX3zxhejn5yd+/vnn8jWvvfaaGBwcLP7444/i0aNHxRtvvJFLk1tpzpw5YkxMjLwU/PvvvxdDQ0PFJ598Ur6G97t1ysrKxMOHD4uHDx8WAYhvvPGGePjwYfHSpUuiKNp3X6+77joxMTFR3Ldvn7hr1y6xT58+XArenvz73/8Wu3XrJqrVanH06NHi3r17PT2kDg+AzbdPPvlEvqaqqkp89NFHxS5duoh+fn7izTffLGZnZ3tu0F6kYbjhvXaen3/+WRw8eLCo0WjE/v37ix988IHVx00mk/jcc8+JERERokajEadOnSqmpqZ6aLQdW2lpqTh//nyxW7duolarFXv27CkuXrxY1Ov18jW8363z66+/2vwbPWfOHFEU7buvhYWF4p133ikGBASIQUFB4ty5c8WysrI2j00QxXrbNBIRERF1cOy5ISIiIq/CcENEREReheGGiIiIvArDDREREXkVhhsiIiLyKgw3RERE5FUYboiIiMirMNwQERGRV2G4IaJOb9u2bRAEodHBoETUMTHcEBERkVdhuCEiIiKvwnBDRB5nMpmwdOlS9OjRA76+vkhISMDq1asB1E0ZrV27FkOHDoVWq8XYsWNx/Phxq6/x3//+F4MGDYJGo0F8fDyWLVtm9XG9Xo+nnnoKcXFx0Gg06N27Nz7++GOra5KTkzFy5Ej4+flh/PjxSE1Nde0PTkQuwXBDRB63dOlSrFq1Cu+//z5OnDiBBQsW4A9/+AO2b98uX/PEE09g2bJlOHDgAMLCwjBr1izU1tYCMIeS22+/Hb///e9x7NgxvPDCC3juueewcuVK+fPvuecefPXVV3j77bdx6tQp/Oc//0FAQIDVOBYvXoxly5bh4MGDUKlUuO+++9zy8xORc/FUcCLyKL1ej5CQEGzevBnjxo2TH3/ggQdQWVmJhx56CFOmTMHXX3+NO+64AwBQVFSE2NhYrFy5Erfffjtmz56N/Px8bNy4Uf78J598EmvXrsWJEyeQlpaGfv36YdOmTUhKSmo0hm3btmHKlCnYvHkzpk6dCgBYt24dZs6ciaqqKmi1WhffBSJyJlZuiMijzp49i8rKSkybNg0BAQHy26pVq3Du3Dn5uvrBJyQkBP369cOpU6cAAKdOncKECROsvu6ECRNw5swZGI1GpKSkQKlUYvLkyc2OZejQofJ/R0VFAQDy8vLa/DMSkXupPD0AIurcysvLAQBr165FTEyM1cc0Go1VwGktX19fu67z8fGR/1sQBADmfiAi6lhYuSEijxo4cCA0Gg3S09PRu3dvq7e4uDj5ur1798r/feXKFaSlpWHAgAEAgAEDBmD37t1WX3f37t3o27cvlEolhgwZApPJZNXDQ0Tei5UbIvKowMBAPP7441iwYAFMJhMmTpyIkpIS7N69G0FBQejevTsA4KWXXkLXrl0RERGBxYsXIzQ0FDfddBMA4K9//StGjRqFl19+GXfccQf27NmDd955B++++y4AID4+HnPmzMF9992Ht99+GwkJCbh06RLy8vJw++23e+pHJyIXYbghIo97+eWXERYWhqVLl+L8+fMIDg7G8OHD8cwzz8jTQq+99hrmz5+PM2fOYNiwYfj555+hVqsBAMOHD8e3336LJUuW4OWXX0ZUVBReeukl3HvvvfL3eO+99/DMM8/g0UcfRWFhIbp164ZnnnnGEz8uEbkYV0sRUbsmrWS6cuUKgoODPT0cIuoA2HNDREREXoXhhoiIiLwKp6WIiIjIq7ByQ0RERF6F4YaIiIi8CsMNEREReRWGGyIiIvIqDDdERETkVRhuiIiIyKsw3BAREZFXYbghIiIir/L/GO38R6ThFyIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"test_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qj_FyeZtx4p6",
    "outputId": "4db43ded-94d2-4b15-9842-b95e44ea490c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
