{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYXxzqGtjO4o",
    "outputId": "2096968f-00ef-404b-9f60-a9f1f1ef8cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.conda/envs/default/lib/python3.9/site-packages (1.13.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: torchvision in ./.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: torch==1.13.0 in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: requests in ./.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.1)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for os\u001b[0m\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Requirement already satisfied: torchinfo in ./.conda/envs/default/lib/python3.9/site-packages (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "!pip install torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "!pip install os\n",
    "import os\n",
    "!pip install argparse\n",
    "import argparse\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "# from models import *\n",
    "# from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kzYmUhpMhnGU"
   },
   "outputs": [],
   "source": [
    "# !cp drive/MyDrive/utils.py .\n",
    "# !cp drive/MyDrive/ResNet.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "s0H94RJKjX0D"
   },
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true',\n",
    "#                     help='resume from checkpoint')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P98wVKH1jkFQ",
    "outputId": "f76a6c51-769b-47e1-9635-29d2906e4e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.3, hue=0.3),\n",
    "    #transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "    #transforms.GaussianBlur(3, sigma=(0.1, 2.0)),  # augmentation\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "54dc99739b5f4e66886019cd26f3333a",
      "ee770e905eb248b8be2667e66d711dc9",
      "8fe755f3b46f43068ac098adbc75332a",
      "7972acdcd007407090fc1b2b12dcebcb",
      "6ab11b6e072d40a392fdfb60406edc89",
      "9bf986f336904eecb7b929ec3f34d077",
      "e161d1b0132542aeb21ef2b7a24c62dc",
      "80ace7fb1c834f59adc7db9dd690681d",
      "816e32d4bca64a8baae1c0c7a7c39ced",
      "761a17ec6f2a491a8620f6245f2ff26e",
      "e250b821e69349f8a70b7fe6e40b9da2"
     ]
    },
    "id": "ET3HGuTnjX5-",
    "outputId": "42569a46-23f5-429e-cda9-4bca76263d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2) #128\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2) #100\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BCLozv6sxiG",
    "outputId": "f1bbda4a-c909-4b52-ce67-05e0abd0c976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6PkueVcjshd",
    "outputId": "0978e87e-485a-4e69-df58-8466bb2811da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "vZScwCXMjskX"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2zFlIhMQjsox"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(1024*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lkevL8y4kKVI",
    "outputId": "ce7fc7b7-e3ee-4e60-9e47-ba68cfccfa9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [128, 10]                 --\n",
      "├─Conv2d: 1-1                            [128, 64, 32, 32]         1,728\n",
      "├─BatchNorm2d: 1-2                       [128, 64, 32, 32]         128\n",
      "├─Sequential: 1-3                        [128, 64, 32, 32]         --\n",
      "│    └─BasicBlock: 2-1                   [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-1                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-3                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-4             [128, 64, 32, 32]         128\n",
      "│    │    └─Sequential: 3-5              [128, 64, 32, 32]         --\n",
      "│    └─BasicBlock: 2-2                   [128, 64, 32, 32]         --\n",
      "│    │    └─Conv2d: 3-6                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-7             [128, 64, 32, 32]         128\n",
      "│    │    └─Conv2d: 3-8                  [128, 64, 32, 32]         36,864\n",
      "│    │    └─BatchNorm2d: 3-9             [128, 64, 32, 32]         128\n",
      "│    │    └─Sequential: 3-10             [128, 64, 32, 32]         --\n",
      "├─Sequential: 1-4                        [128, 128, 16, 16]        --\n",
      "│    └─BasicBlock: 2-3                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-11                 [128, 128, 16, 16]        73,728\n",
      "│    │    └─BatchNorm2d: 3-12            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-13                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-14            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-15             [128, 128, 16, 16]        8,448\n",
      "│    └─BasicBlock: 2-4                   [128, 128, 16, 16]        --\n",
      "│    │    └─Conv2d: 3-16                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-17            [128, 128, 16, 16]        256\n",
      "│    │    └─Conv2d: 3-18                 [128, 128, 16, 16]        147,456\n",
      "│    │    └─BatchNorm2d: 3-19            [128, 128, 16, 16]        256\n",
      "│    │    └─Sequential: 3-20             [128, 128, 16, 16]        --\n",
      "├─Sequential: 1-5                        [128, 256, 8, 8]          --\n",
      "│    └─BasicBlock: 2-5                   [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-21                 [128, 256, 8, 8]          294,912\n",
      "│    │    └─BatchNorm2d: 3-22            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-23                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-24            [128, 256, 8, 8]          512\n",
      "│    │    └─Sequential: 3-25             [128, 256, 8, 8]          33,280\n",
      "│    └─BasicBlock: 2-6                   [128, 256, 8, 8]          --\n",
      "│    │    └─Conv2d: 3-26                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-27            [128, 256, 8, 8]          512\n",
      "│    │    └─Conv2d: 3-28                 [128, 256, 8, 8]          589,824\n",
      "│    │    └─BatchNorm2d: 3-29            [128, 256, 8, 8]          512\n",
      "│    │    └─Sequential: 3-30             [128, 256, 8, 8]          --\n",
      "├─Linear: 1-6                            [128, 10]                 10,250\n",
      "==========================================================================================\n",
      "Total params: 2,785,354\n",
      "Trainable params: 2,785,354\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 53.92\n",
      "==========================================================================================\n",
      "Input size (MB): 1.57\n",
      "Forward/backward pass size (MB): 1174.42\n",
      "Params size (MB): 11.14\n",
      "Estimated Total Size (MB): 1187.13\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "net = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "print(summary(net,input_size=(128,3,32,32)))#input_size = (batch_size, #channel,imgsize)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wGV6CjKekg_y"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
    "                      #momentum=0.9, weight_decay=6e-4)\n",
    "optimizer = optim.Adam(net.parameters(),lr = 1e-3, weight_decay=6e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "64Oo01YMkhBJ"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "tracc_list = []\n",
    "trloss_list = []\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "        print('Train Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (epoch, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #              % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    tracc_list.append(100.*correct/total)\n",
    "    trloss_list.append(train_loss/(batch_idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "bFiXz9dZkhCt"
   },
   "outputs": [],
   "source": [
    "tacc_list = []\n",
    "tloss_list = []\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "            print('Test Epoch: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                  % (epoch, test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        tacc_list.append(100.*correct/total)\n",
    "        tloss_list.append(test_loss/(batch_idx+1))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzse6BCAlB10",
    "outputId": "b62b417f-0b15-4d26-ed27-31bb30d45e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Epoch: 0 | Loss: 2.543 | Acc: 8.594% (11/128)\n",
      "Train Epoch: 0 | Loss: 2.946 | Acc: 12.500% (32/256)\n",
      "Train Epoch: 0 | Loss: 3.013 | Acc: 11.458% (44/384)\n",
      "Train Epoch: 0 | Loss: 2.908 | Acc: 12.500% (64/512)\n",
      "Train Epoch: 0 | Loss: 2.825 | Acc: 12.500% (80/640)\n",
      "Train Epoch: 0 | Loss: 2.788 | Acc: 12.630% (97/768)\n",
      "Train Epoch: 0 | Loss: 2.726 | Acc: 13.616% (122/896)\n",
      "Train Epoch: 0 | Loss: 2.693 | Acc: 13.574% (139/1024)\n",
      "Train Epoch: 0 | Loss: 2.647 | Acc: 14.323% (165/1152)\n",
      "Train Epoch: 0 | Loss: 2.626 | Acc: 14.688% (188/1280)\n",
      "Train Epoch: 0 | Loss: 2.597 | Acc: 14.702% (207/1408)\n",
      "Train Epoch: 0 | Loss: 2.568 | Acc: 14.714% (226/1536)\n",
      "Train Epoch: 0 | Loss: 2.541 | Acc: 15.084% (251/1664)\n",
      "Train Epoch: 0 | Loss: 2.519 | Acc: 15.402% (276/1792)\n",
      "Train Epoch: 0 | Loss: 2.498 | Acc: 15.625% (300/1920)\n",
      "Train Epoch: 0 | Loss: 2.480 | Acc: 15.576% (319/2048)\n",
      "Train Epoch: 0 | Loss: 2.462 | Acc: 15.993% (348/2176)\n",
      "Train Epoch: 0 | Loss: 2.451 | Acc: 15.799% (364/2304)\n",
      "Train Epoch: 0 | Loss: 2.434 | Acc: 16.118% (392/2432)\n",
      "Train Epoch: 0 | Loss: 2.423 | Acc: 16.016% (410/2560)\n",
      "Train Epoch: 0 | Loss: 2.410 | Acc: 16.220% (436/2688)\n",
      "Train Epoch: 0 | Loss: 2.395 | Acc: 16.477% (464/2816)\n",
      "Train Epoch: 0 | Loss: 2.384 | Acc: 16.814% (495/2944)\n",
      "Train Epoch: 0 | Loss: 2.373 | Acc: 16.764% (515/3072)\n",
      "Train Epoch: 0 | Loss: 2.364 | Acc: 16.875% (540/3200)\n",
      "Train Epoch: 0 | Loss: 2.362 | Acc: 16.827% (560/3328)\n",
      "Train Epoch: 0 | Loss: 2.357 | Acc: 16.782% (580/3456)\n",
      "Train Epoch: 0 | Loss: 2.354 | Acc: 16.908% (606/3584)\n",
      "Train Epoch: 0 | Loss: 2.349 | Acc: 16.864% (626/3712)\n",
      "Train Epoch: 0 | Loss: 2.340 | Acc: 16.927% (650/3840)\n",
      "Train Epoch: 0 | Loss: 2.333 | Acc: 17.162% (681/3968)\n",
      "Train Epoch: 0 | Loss: 2.328 | Acc: 17.188% (704/4096)\n",
      "Train Epoch: 0 | Loss: 2.321 | Acc: 17.306% (731/4224)\n",
      "Train Epoch: 0 | Loss: 2.317 | Acc: 17.325% (754/4352)\n",
      "Train Epoch: 0 | Loss: 2.311 | Acc: 17.433% (781/4480)\n",
      "Train Epoch: 0 | Loss: 2.305 | Acc: 17.600% (811/4608)\n",
      "Train Epoch: 0 | Loss: 2.299 | Acc: 17.779% (842/4736)\n",
      "Train Epoch: 0 | Loss: 2.296 | Acc: 17.907% (871/4864)\n",
      "Train Epoch: 0 | Loss: 2.293 | Acc: 17.909% (894/4992)\n",
      "Train Epoch: 0 | Loss: 2.288 | Acc: 18.047% (924/5120)\n",
      "Train Epoch: 0 | Loss: 2.284 | Acc: 18.045% (947/5248)\n",
      "Train Epoch: 0 | Loss: 2.280 | Acc: 18.155% (976/5376)\n",
      "Train Epoch: 0 | Loss: 2.276 | Acc: 18.205% (1002/5504)\n",
      "Train Epoch: 0 | Loss: 2.270 | Acc: 18.324% (1032/5632)\n",
      "Train Epoch: 0 | Loss: 2.266 | Acc: 18.438% (1062/5760)\n",
      "Train Epoch: 0 | Loss: 2.262 | Acc: 18.512% (1090/5888)\n",
      "Train Epoch: 0 | Loss: 2.259 | Acc: 18.551% (1116/6016)\n",
      "Train Epoch: 0 | Loss: 2.257 | Acc: 18.620% (1144/6144)\n",
      "Train Epoch: 0 | Loss: 2.252 | Acc: 18.814% (1180/6272)\n",
      "Train Epoch: 0 | Loss: 2.249 | Acc: 18.938% (1212/6400)\n",
      "Train Epoch: 0 | Loss: 2.247 | Acc: 18.964% (1238/6528)\n",
      "Train Epoch: 0 | Loss: 2.245 | Acc: 19.081% (1270/6656)\n",
      "Train Epoch: 0 | Loss: 2.241 | Acc: 19.222% (1304/6784)\n",
      "Train Epoch: 0 | Loss: 2.238 | Acc: 19.444% (1344/6912)\n",
      "Train Epoch: 0 | Loss: 2.234 | Acc: 19.588% (1379/7040)\n",
      "Train Epoch: 0 | Loss: 2.229 | Acc: 19.727% (1414/7168)\n",
      "Train Epoch: 0 | Loss: 2.224 | Acc: 19.901% (1452/7296)\n",
      "Train Epoch: 0 | Loss: 2.221 | Acc: 20.043% (1488/7424)\n",
      "Train Epoch: 0 | Loss: 2.218 | Acc: 20.154% (1522/7552)\n",
      "Train Epoch: 0 | Loss: 2.214 | Acc: 20.273% (1557/7680)\n",
      "Train Epoch: 0 | Loss: 2.211 | Acc: 20.338% (1588/7808)\n",
      "Train Epoch: 0 | Loss: 2.209 | Acc: 20.376% (1617/7936)\n",
      "Train Epoch: 0 | Loss: 2.205 | Acc: 20.610% (1662/8064)\n",
      "Train Epoch: 0 | Loss: 2.201 | Acc: 20.679% (1694/8192)\n",
      "Train Epoch: 0 | Loss: 2.197 | Acc: 20.769% (1728/8320)\n",
      "Train Epoch: 0 | Loss: 2.193 | Acc: 20.833% (1760/8448)\n",
      "Train Epoch: 0 | Loss: 2.191 | Acc: 20.954% (1797/8576)\n",
      "Train Epoch: 0 | Loss: 2.188 | Acc: 20.979% (1826/8704)\n",
      "Train Epoch: 0 | Loss: 2.186 | Acc: 20.981% (1853/8832)\n",
      "Train Epoch: 0 | Loss: 2.185 | Acc: 21.016% (1883/8960)\n",
      "Train Epoch: 0 | Loss: 2.182 | Acc: 21.083% (1916/9088)\n",
      "Train Epoch: 0 | Loss: 2.178 | Acc: 21.246% (1958/9216)\n",
      "Train Epoch: 0 | Loss: 2.176 | Acc: 21.286% (1989/9344)\n",
      "Train Epoch: 0 | Loss: 2.175 | Acc: 21.326% (2020/9472)\n",
      "Train Epoch: 0 | Loss: 2.172 | Acc: 21.375% (2052/9600)\n",
      "Train Epoch: 0 | Loss: 2.169 | Acc: 21.474% (2089/9728)\n",
      "Train Epoch: 0 | Loss: 2.166 | Acc: 21.611% (2130/9856)\n",
      "Train Epoch: 0 | Loss: 2.162 | Acc: 21.765% (2173/9984)\n",
      "Train Epoch: 0 | Loss: 2.161 | Acc: 21.776% (2202/10112)\n",
      "Train Epoch: 0 | Loss: 2.157 | Acc: 21.865% (2239/10240)\n",
      "Train Epoch: 0 | Loss: 2.155 | Acc: 21.914% (2272/10368)\n",
      "Train Epoch: 0 | Loss: 2.152 | Acc: 21.961% (2305/10496)\n",
      "Train Epoch: 0 | Loss: 2.150 | Acc: 22.044% (2342/10624)\n",
      "Train Epoch: 0 | Loss: 2.147 | Acc: 22.135% (2380/10752)\n",
      "Train Epoch: 0 | Loss: 2.146 | Acc: 22.197% (2415/10880)\n",
      "Train Epoch: 0 | Loss: 2.143 | Acc: 22.320% (2457/11008)\n",
      "Train Epoch: 0 | Loss: 2.140 | Acc: 22.450% (2500/11136)\n",
      "Train Epoch: 0 | Loss: 2.138 | Acc: 22.585% (2544/11264)\n",
      "Train Epoch: 0 | Loss: 2.134 | Acc: 22.691% (2585/11392)\n",
      "Train Epoch: 0 | Loss: 2.131 | Acc: 22.769% (2623/11520)\n",
      "Train Epoch: 0 | Loss: 2.128 | Acc: 22.879% (2665/11648)\n",
      "Train Epoch: 0 | Loss: 2.126 | Acc: 22.987% (2707/11776)\n",
      "Train Epoch: 0 | Loss: 2.123 | Acc: 23.051% (2744/11904)\n",
      "Train Epoch: 0 | Loss: 2.121 | Acc: 23.063% (2775/12032)\n",
      "Train Epoch: 0 | Loss: 2.120 | Acc: 23.109% (2810/12160)\n",
      "Train Epoch: 0 | Loss: 2.117 | Acc: 23.169% (2847/12288)\n",
      "Train Epoch: 0 | Loss: 2.114 | Acc: 23.260% (2888/12416)\n",
      "Train Epoch: 0 | Loss: 2.112 | Acc: 23.398% (2935/12544)\n",
      "Train Epoch: 0 | Loss: 2.110 | Acc: 23.516% (2980/12672)\n",
      "Train Epoch: 0 | Loss: 2.107 | Acc: 23.531% (3012/12800)\n",
      "Train Epoch: 0 | Loss: 2.105 | Acc: 23.600% (3051/12928)\n",
      "Train Epoch: 0 | Loss: 2.103 | Acc: 23.675% (3091/13056)\n",
      "Train Epoch: 0 | Loss: 2.100 | Acc: 23.726% (3128/13184)\n",
      "Train Epoch: 0 | Loss: 2.098 | Acc: 23.813% (3170/13312)\n",
      "Train Epoch: 0 | Loss: 2.097 | Acc: 23.795% (3198/13440)\n",
      "Train Epoch: 0 | Loss: 2.095 | Acc: 23.843% (3235/13568)\n",
      "Train Epoch: 0 | Loss: 2.093 | Acc: 23.854% (3267/13696)\n",
      "Train Epoch: 0 | Loss: 2.091 | Acc: 23.872% (3300/13824)\n",
      "Train Epoch: 0 | Loss: 2.090 | Acc: 23.911% (3336/13952)\n",
      "Train Epoch: 0 | Loss: 2.087 | Acc: 23.991% (3378/14080)\n",
      "Train Epoch: 0 | Loss: 2.086 | Acc: 24.029% (3414/14208)\n",
      "Train Epoch: 0 | Loss: 2.083 | Acc: 24.149% (3462/14336)\n",
      "Train Epoch: 0 | Loss: 2.081 | Acc: 24.253% (3508/14464)\n",
      "Train Epoch: 0 | Loss: 2.080 | Acc: 24.253% (3539/14592)\n",
      "Train Epoch: 0 | Loss: 2.079 | Acc: 24.321% (3580/14720)\n",
      "Train Epoch: 0 | Loss: 2.077 | Acc: 24.347% (3615/14848)\n",
      "Train Epoch: 0 | Loss: 2.076 | Acc: 24.419% (3657/14976)\n",
      "Train Epoch: 0 | Loss: 2.073 | Acc: 24.537% (3706/15104)\n",
      "Train Epoch: 0 | Loss: 2.072 | Acc: 24.573% (3743/15232)\n",
      "Train Epoch: 0 | Loss: 2.070 | Acc: 24.629% (3783/15360)\n",
      "Train Epoch: 0 | Loss: 2.068 | Acc: 24.684% (3823/15488)\n",
      "Train Epoch: 0 | Loss: 2.067 | Acc: 24.737% (3863/15616)\n",
      "Train Epoch: 0 | Loss: 2.065 | Acc: 24.778% (3901/15744)\n",
      "Train Epoch: 0 | Loss: 2.063 | Acc: 24.849% (3944/15872)\n",
      "Train Epoch: 0 | Loss: 2.062 | Acc: 24.850% (3976/16000)\n",
      "Train Epoch: 0 | Loss: 2.059 | Acc: 24.938% (4022/16128)\n",
      "Train Epoch: 0 | Loss: 2.056 | Acc: 25.068% (4075/16256)\n",
      "Train Epoch: 0 | Loss: 2.055 | Acc: 25.116% (4115/16384)\n",
      "Train Epoch: 0 | Loss: 2.054 | Acc: 25.151% (4153/16512)\n",
      "Train Epoch: 0 | Loss: 2.052 | Acc: 25.198% (4193/16640)\n",
      "Train Epoch: 0 | Loss: 2.049 | Acc: 25.304% (4243/16768)\n",
      "Train Epoch: 0 | Loss: 2.045 | Acc: 25.426% (4296/16896)\n",
      "Train Epoch: 0 | Loss: 2.043 | Acc: 25.470% (4336/17024)\n",
      "Train Epoch: 0 | Loss: 2.042 | Acc: 25.496% (4373/17152)\n",
      "Train Epoch: 0 | Loss: 2.041 | Acc: 25.521% (4410/17280)\n",
      "Train Epoch: 0 | Loss: 2.040 | Acc: 25.528% (4444/17408)\n",
      "Train Epoch: 0 | Loss: 2.038 | Acc: 25.559% (4482/17536)\n",
      "Train Epoch: 0 | Loss: 2.036 | Acc: 25.645% (4530/17664)\n",
      "Train Epoch: 0 | Loss: 2.034 | Acc: 25.697% (4572/17792)\n",
      "Train Epoch: 0 | Loss: 2.032 | Acc: 25.770% (4618/17920)\n",
      "Train Epoch: 0 | Loss: 2.032 | Acc: 25.792% (4655/18048)\n",
      "Train Epoch: 0 | Loss: 2.031 | Acc: 25.836% (4696/18176)\n",
      "Train Epoch: 0 | Loss: 2.029 | Acc: 25.918% (4744/18304)\n",
      "Train Epoch: 0 | Loss: 2.028 | Acc: 25.928% (4779/18432)\n",
      "Train Epoch: 0 | Loss: 2.027 | Acc: 25.986% (4823/18560)\n",
      "Train Epoch: 0 | Loss: 2.025 | Acc: 26.054% (4869/18688)\n",
      "Train Epoch: 0 | Loss: 2.022 | Acc: 26.100% (4911/18816)\n",
      "Train Epoch: 0 | Loss: 2.021 | Acc: 26.156% (4955/18944)\n",
      "Train Epoch: 0 | Loss: 2.019 | Acc: 26.211% (4999/19072)\n",
      "Train Epoch: 0 | Loss: 2.018 | Acc: 26.250% (5040/19200)\n",
      "Train Epoch: 0 | Loss: 2.016 | Acc: 26.314% (5086/19328)\n",
      "Train Epoch: 0 | Loss: 2.014 | Acc: 26.393% (5135/19456)\n",
      "Train Epoch: 0 | Loss: 2.012 | Acc: 26.445% (5179/19584)\n",
      "Train Epoch: 0 | Loss: 2.011 | Acc: 26.491% (5222/19712)\n",
      "Train Epoch: 0 | Loss: 2.009 | Acc: 26.578% (5273/19840)\n",
      "Train Epoch: 0 | Loss: 2.007 | Acc: 26.648% (5321/19968)\n",
      "Train Epoch: 0 | Loss: 2.006 | Acc: 26.697% (5365/20096)\n",
      "Train Epoch: 0 | Loss: 2.004 | Acc: 26.770% (5414/20224)\n",
      "Train Epoch: 0 | Loss: 2.003 | Acc: 26.813% (5457/20352)\n",
      "Train Epoch: 0 | Loss: 2.002 | Acc: 26.851% (5499/20480)\n",
      "Train Epoch: 0 | Loss: 2.000 | Acc: 26.922% (5548/20608)\n",
      "Train Epoch: 0 | Loss: 1.998 | Acc: 26.987% (5596/20736)\n",
      "Train Epoch: 0 | Loss: 1.996 | Acc: 27.075% (5649/20864)\n",
      "Train Epoch: 0 | Loss: 1.994 | Acc: 27.134% (5696/20992)\n",
      "Train Epoch: 0 | Loss: 1.993 | Acc: 27.131% (5730/21120)\n",
      "Train Epoch: 0 | Loss: 1.992 | Acc: 27.203% (5780/21248)\n",
      "Train Epoch: 0 | Loss: 1.990 | Acc: 27.292% (5834/21376)\n",
      "Train Epoch: 0 | Loss: 1.989 | Acc: 27.372% (5886/21504)\n",
      "Train Epoch: 0 | Loss: 1.986 | Acc: 27.436% (5935/21632)\n",
      "Train Epoch: 0 | Loss: 1.984 | Acc: 27.500% (5984/21760)\n",
      "Train Epoch: 0 | Loss: 1.982 | Acc: 27.586% (6038/21888)\n",
      "Train Epoch: 0 | Loss: 1.981 | Acc: 27.630% (6083/22016)\n",
      "Train Epoch: 0 | Loss: 1.979 | Acc: 27.678% (6129/22144)\n",
      "Train Epoch: 0 | Loss: 1.979 | Acc: 27.725% (6175/22272)\n",
      "Train Epoch: 0 | Loss: 1.977 | Acc: 27.777% (6222/22400)\n",
      "Train Epoch: 0 | Loss: 1.975 | Acc: 27.854% (6275/22528)\n",
      "Train Epoch: 0 | Loss: 1.973 | Acc: 27.926% (6327/22656)\n",
      "Train Epoch: 0 | Loss: 1.972 | Acc: 27.945% (6367/22784)\n",
      "Train Epoch: 0 | Loss: 1.971 | Acc: 27.998% (6415/22912)\n",
      "Train Epoch: 0 | Loss: 1.969 | Acc: 28.086% (6471/23040)\n",
      "Train Epoch: 0 | Loss: 1.968 | Acc: 28.160% (6524/23168)\n",
      "Train Epoch: 0 | Loss: 1.967 | Acc: 28.215% (6573/23296)\n",
      "Train Epoch: 0 | Loss: 1.965 | Acc: 28.279% (6624/23424)\n",
      "Train Epoch: 0 | Loss: 1.964 | Acc: 28.333% (6673/23552)\n",
      "Train Epoch: 0 | Loss: 1.962 | Acc: 28.425% (6731/23680)\n",
      "Train Epoch: 0 | Loss: 1.960 | Acc: 28.478% (6780/23808)\n",
      "Train Epoch: 0 | Loss: 1.958 | Acc: 28.559% (6836/23936)\n",
      "Train Epoch: 0 | Loss: 1.956 | Acc: 28.578% (6877/24064)\n",
      "Train Epoch: 0 | Loss: 1.955 | Acc: 28.654% (6932/24192)\n",
      "Train Epoch: 0 | Loss: 1.953 | Acc: 28.721% (6985/24320)\n",
      "Train Epoch: 0 | Loss: 1.951 | Acc: 28.796% (7040/24448)\n",
      "Train Epoch: 0 | Loss: 1.949 | Acc: 28.870% (7095/24576)\n",
      "Train Epoch: 0 | Loss: 1.948 | Acc: 28.902% (7140/24704)\n",
      "Train Epoch: 0 | Loss: 1.946 | Acc: 28.942% (7187/24832)\n",
      "Train Epoch: 0 | Loss: 1.945 | Acc: 29.022% (7244/24960)\n",
      "Train Epoch: 0 | Loss: 1.944 | Acc: 29.046% (7287/25088)\n",
      "Train Epoch: 0 | Loss: 1.944 | Acc: 29.093% (7336/25216)\n",
      "Train Epoch: 0 | Loss: 1.942 | Acc: 29.127% (7382/25344)\n",
      "Train Epoch: 0 | Loss: 1.941 | Acc: 29.181% (7433/25472)\n",
      "Train Epoch: 0 | Loss: 1.939 | Acc: 29.242% (7486/25600)\n",
      "Train Epoch: 0 | Loss: 1.936 | Acc: 29.342% (7549/25728)\n",
      "Train Epoch: 0 | Loss: 1.935 | Acc: 29.386% (7598/25856)\n",
      "Train Epoch: 0 | Loss: 1.933 | Acc: 29.453% (7653/25984)\n",
      "Train Epoch: 0 | Loss: 1.931 | Acc: 29.515% (7707/26112)\n",
      "Train Epoch: 0 | Loss: 1.929 | Acc: 29.604% (7768/26240)\n",
      "Train Epoch: 0 | Loss: 1.927 | Acc: 29.665% (7822/26368)\n",
      "Train Epoch: 0 | Loss: 1.925 | Acc: 29.744% (7881/26496)\n",
      "Train Epoch: 0 | Loss: 1.924 | Acc: 29.766% (7925/26624)\n",
      "Train Epoch: 0 | Loss: 1.923 | Acc: 29.826% (7979/26752)\n",
      "Train Epoch: 0 | Loss: 1.921 | Acc: 29.892% (8035/26880)\n",
      "Train Epoch: 0 | Loss: 1.920 | Acc: 29.950% (8089/27008)\n",
      "Train Epoch: 0 | Loss: 1.919 | Acc: 30.008% (8143/27136)\n",
      "Train Epoch: 0 | Loss: 1.917 | Acc: 30.058% (8195/27264)\n",
      "Train Epoch: 0 | Loss: 1.916 | Acc: 30.089% (8242/27392)\n",
      "Train Epoch: 0 | Loss: 1.915 | Acc: 30.134% (8293/27520)\n",
      "Train Epoch: 0 | Loss: 1.912 | Acc: 30.216% (8354/27648)\n",
      "Train Epoch: 0 | Loss: 1.911 | Acc: 30.274% (8409/27776)\n",
      "Train Epoch: 0 | Loss: 1.909 | Acc: 30.322% (8461/27904)\n",
      "Train Epoch: 0 | Loss: 1.908 | Acc: 30.333% (8503/28032)\n",
      "Train Epoch: 0 | Loss: 1.907 | Acc: 30.387% (8557/28160)\n",
      "Train Epoch: 0 | Loss: 1.906 | Acc: 30.426% (8607/28288)\n",
      "Train Epoch: 0 | Loss: 1.904 | Acc: 30.479% (8661/28416)\n",
      "Train Epoch: 0 | Loss: 1.903 | Acc: 30.546% (8719/28544)\n",
      "Train Epoch: 0 | Loss: 1.902 | Acc: 30.587% (8770/28672)\n",
      "Train Epoch: 0 | Loss: 1.900 | Acc: 30.642% (8825/28800)\n",
      "Train Epoch: 0 | Loss: 1.899 | Acc: 30.700% (8881/28928)\n",
      "Train Epoch: 0 | Loss: 1.898 | Acc: 30.744% (8933/29056)\n",
      "Train Epoch: 0 | Loss: 1.897 | Acc: 30.770% (8980/29184)\n",
      "Train Epoch: 0 | Loss: 1.896 | Acc: 30.841% (9040/29312)\n",
      "Train Epoch: 0 | Loss: 1.894 | Acc: 30.917% (9102/29440)\n",
      "Train Epoch: 0 | Loss: 1.892 | Acc: 31.003% (9167/29568)\n",
      "Train Epoch: 0 | Loss: 1.891 | Acc: 31.055% (9222/29696)\n",
      "Train Epoch: 0 | Loss: 1.890 | Acc: 31.123% (9282/29824)\n",
      "Train Epoch: 0 | Loss: 1.888 | Acc: 31.160% (9333/29952)\n",
      "Train Epoch: 0 | Loss: 1.887 | Acc: 31.247% (9399/30080)\n",
      "Train Epoch: 0 | Loss: 1.885 | Acc: 31.313% (9459/30208)\n",
      "Train Epoch: 0 | Loss: 1.884 | Acc: 31.372% (9517/30336)\n",
      "Train Epoch: 0 | Loss: 1.883 | Acc: 31.381% (9560/30464)\n",
      "Train Epoch: 0 | Loss: 1.882 | Acc: 31.430% (9615/30592)\n",
      "Train Epoch: 0 | Loss: 1.880 | Acc: 31.501% (9677/30720)\n",
      "Train Epoch: 0 | Loss: 1.879 | Acc: 31.561% (9736/30848)\n",
      "Train Epoch: 0 | Loss: 1.877 | Acc: 31.605% (9790/30976)\n",
      "Train Epoch: 0 | Loss: 1.876 | Acc: 31.694% (9858/31104)\n",
      "Train Epoch: 0 | Loss: 1.875 | Acc: 31.733% (9911/31232)\n",
      "Train Epoch: 0 | Loss: 1.873 | Acc: 31.776% (9965/31360)\n",
      "Train Epoch: 0 | Loss: 1.872 | Acc: 31.812% (10017/31488)\n",
      "Train Epoch: 0 | Loss: 1.871 | Acc: 31.867% (10075/31616)\n",
      "Train Epoch: 0 | Loss: 1.870 | Acc: 31.867% (10116/31744)\n",
      "Train Epoch: 0 | Loss: 1.869 | Acc: 31.890% (10164/31872)\n",
      "Train Epoch: 0 | Loss: 1.868 | Acc: 31.931% (10218/32000)\n",
      "Train Epoch: 0 | Loss: 1.867 | Acc: 31.985% (10276/32128)\n",
      "Train Epoch: 0 | Loss: 1.865 | Acc: 32.050% (10338/32256)\n",
      "Train Epoch: 0 | Loss: 1.863 | Acc: 32.118% (10401/32384)\n",
      "Train Epoch: 0 | Loss: 1.862 | Acc: 32.185% (10464/32512)\n",
      "Train Epoch: 0 | Loss: 1.860 | Acc: 32.221% (10517/32640)\n",
      "Train Epoch: 0 | Loss: 1.859 | Acc: 32.278% (10577/32768)\n",
      "Train Epoch: 0 | Loss: 1.857 | Acc: 32.329% (10635/32896)\n",
      "Train Epoch: 0 | Loss: 1.856 | Acc: 32.361% (10687/33024)\n",
      "Train Epoch: 0 | Loss: 1.854 | Acc: 32.408% (10744/33152)\n",
      "Train Epoch: 0 | Loss: 1.853 | Acc: 32.461% (10803/33280)\n",
      "Train Epoch: 0 | Loss: 1.851 | Acc: 32.522% (10865/33408)\n",
      "Train Epoch: 0 | Loss: 1.851 | Acc: 32.547% (10915/33536)\n",
      "Train Epoch: 0 | Loss: 1.849 | Acc: 32.616% (10980/33664)\n",
      "Train Epoch: 0 | Loss: 1.847 | Acc: 32.676% (11042/33792)\n",
      "Train Epoch: 0 | Loss: 1.846 | Acc: 32.727% (11101/33920)\n",
      "Train Epoch: 0 | Loss: 1.844 | Acc: 32.786% (11163/34048)\n",
      "Train Epoch: 0 | Loss: 1.843 | Acc: 32.848% (11226/34176)\n",
      "Train Epoch: 0 | Loss: 1.841 | Acc: 32.888% (11282/34304)\n",
      "Train Epoch: 0 | Loss: 1.840 | Acc: 32.937% (11341/34432)\n",
      "Train Epoch: 0 | Loss: 1.839 | Acc: 32.989% (11401/34560)\n",
      "Train Epoch: 0 | Loss: 1.838 | Acc: 33.040% (11461/34688)\n",
      "Train Epoch: 0 | Loss: 1.837 | Acc: 33.111% (11528/34816)\n",
      "Train Epoch: 0 | Loss: 1.835 | Acc: 33.164% (11589/34944)\n",
      "Train Epoch: 0 | Loss: 1.834 | Acc: 33.217% (11650/35072)\n",
      "Train Epoch: 0 | Loss: 1.833 | Acc: 33.247% (11703/35200)\n",
      "Train Epoch: 0 | Loss: 1.832 | Acc: 33.311% (11768/35328)\n",
      "Train Epoch: 0 | Loss: 1.831 | Acc: 33.334% (11819/35456)\n",
      "Train Epoch: 0 | Loss: 1.829 | Acc: 33.360% (11871/35584)\n",
      "Train Epoch: 0 | Loss: 1.828 | Acc: 33.403% (11929/35712)\n",
      "Train Epoch: 0 | Loss: 1.826 | Acc: 33.465% (11994/35840)\n",
      "Train Epoch: 0 | Loss: 1.825 | Acc: 33.496% (12048/35968)\n",
      "Train Epoch: 0 | Loss: 1.823 | Acc: 33.574% (12119/36096)\n",
      "Train Epoch: 0 | Loss: 1.822 | Acc: 33.594% (12169/36224)\n",
      "Train Epoch: 0 | Loss: 1.821 | Acc: 33.657% (12235/36352)\n",
      "Train Epoch: 0 | Loss: 1.819 | Acc: 33.717% (12300/36480)\n",
      "Train Epoch: 0 | Loss: 1.818 | Acc: 33.769% (12362/36608)\n",
      "Train Epoch: 0 | Loss: 1.817 | Acc: 33.814% (12422/36736)\n",
      "Train Epoch: 0 | Loss: 1.815 | Acc: 33.870% (12486/36864)\n",
      "Train Epoch: 0 | Loss: 1.814 | Acc: 33.905% (12542/36992)\n",
      "Train Epoch: 0 | Loss: 1.812 | Acc: 33.944% (12600/37120)\n",
      "Train Epoch: 0 | Loss: 1.811 | Acc: 33.999% (12664/37248)\n",
      "Train Epoch: 0 | Loss: 1.809 | Acc: 34.051% (12727/37376)\n",
      "Train Epoch: 0 | Loss: 1.808 | Acc: 34.119% (12796/37504)\n",
      "Train Epoch: 0 | Loss: 1.806 | Acc: 34.165% (12857/37632)\n",
      "Train Epoch: 0 | Loss: 1.804 | Acc: 34.237% (12928/37760)\n",
      "Train Epoch: 0 | Loss: 1.803 | Acc: 34.312% (13000/37888)\n",
      "Train Epoch: 0 | Loss: 1.802 | Acc: 34.354% (13060/38016)\n",
      "Train Epoch: 0 | Loss: 1.800 | Acc: 34.393% (13119/38144)\n",
      "Train Epoch: 0 | Loss: 1.800 | Acc: 34.427% (13176/38272)\n",
      "Train Epoch: 0 | Loss: 1.798 | Acc: 34.484% (13242/38400)\n",
      "Train Epoch: 0 | Loss: 1.796 | Acc: 34.557% (13314/38528)\n",
      "Train Epoch: 0 | Loss: 1.795 | Acc: 34.603% (13376/38656)\n",
      "Train Epoch: 0 | Loss: 1.793 | Acc: 34.664% (13444/38784)\n",
      "Train Epoch: 0 | Loss: 1.792 | Acc: 34.722% (13511/38912)\n",
      "Train Epoch: 0 | Loss: 1.791 | Acc: 34.800% (13586/39040)\n",
      "Train Epoch: 0 | Loss: 1.789 | Acc: 34.852% (13651/39168)\n",
      "Train Epoch: 0 | Loss: 1.788 | Acc: 34.892% (13711/39296)\n",
      "Train Epoch: 0 | Loss: 1.788 | Acc: 34.933% (13772/39424)\n",
      "Train Epoch: 0 | Loss: 1.786 | Acc: 35.017% (13850/39552)\n",
      "Train Epoch: 0 | Loss: 1.784 | Acc: 35.071% (13916/39680)\n",
      "Train Epoch: 0 | Loss: 1.783 | Acc: 35.111% (13977/39808)\n",
      "Train Epoch: 0 | Loss: 1.781 | Acc: 35.191% (14054/39936)\n",
      "Train Epoch: 0 | Loss: 1.780 | Acc: 35.244% (14120/40064)\n",
      "Train Epoch: 0 | Loss: 1.779 | Acc: 35.281% (14180/40192)\n",
      "Train Epoch: 0 | Loss: 1.777 | Acc: 35.350% (14253/40320)\n",
      "Train Epoch: 0 | Loss: 1.775 | Acc: 35.399% (14318/40448)\n",
      "Train Epoch: 0 | Loss: 1.774 | Acc: 35.442% (14381/40576)\n",
      "Train Epoch: 0 | Loss: 1.773 | Acc: 35.498% (14449/40704)\n",
      "Train Epoch: 0 | Loss: 1.772 | Acc: 35.555% (14518/40832)\n",
      "Train Epoch: 0 | Loss: 1.771 | Acc: 35.593% (14579/40960)\n",
      "Train Epoch: 0 | Loss: 1.770 | Acc: 35.631% (14640/41088)\n",
      "Train Epoch: 0 | Loss: 1.768 | Acc: 35.707% (14717/41216)\n",
      "Train Epoch: 0 | Loss: 1.766 | Acc: 35.768% (14788/41344)\n",
      "Train Epoch: 0 | Loss: 1.765 | Acc: 35.802% (14848/41472)\n",
      "Train Epoch: 0 | Loss: 1.764 | Acc: 35.856% (14916/41600)\n",
      "Train Epoch: 0 | Loss: 1.762 | Acc: 35.911% (14985/41728)\n",
      "Train Epoch: 0 | Loss: 1.761 | Acc: 35.947% (15046/41856)\n",
      "Train Epoch: 0 | Loss: 1.760 | Acc: 35.997% (15113/41984)\n",
      "Train Epoch: 0 | Loss: 1.759 | Acc: 36.023% (15170/42112)\n",
      "Train Epoch: 0 | Loss: 1.758 | Acc: 36.044% (15225/42240)\n",
      "Train Epoch: 0 | Loss: 1.757 | Acc: 36.089% (15290/42368)\n",
      "Train Epoch: 0 | Loss: 1.756 | Acc: 36.149% (15362/42496)\n",
      "Train Epoch: 0 | Loss: 1.754 | Acc: 36.207% (15433/42624)\n",
      "Train Epoch: 0 | Loss: 1.753 | Acc: 36.265% (15504/42752)\n",
      "Train Epoch: 0 | Loss: 1.751 | Acc: 36.320% (15574/42880)\n",
      "Train Epoch: 0 | Loss: 1.750 | Acc: 36.375% (15644/43008)\n",
      "Train Epoch: 0 | Loss: 1.749 | Acc: 36.403% (15703/43136)\n",
      "Train Epoch: 0 | Loss: 1.748 | Acc: 36.451% (15770/43264)\n",
      "Train Epoch: 0 | Loss: 1.746 | Acc: 36.498% (15837/43392)\n",
      "Train Epoch: 0 | Loss: 1.745 | Acc: 36.540% (15902/43520)\n",
      "Train Epoch: 0 | Loss: 1.744 | Acc: 36.590% (15971/43648)\n",
      "Train Epoch: 0 | Loss: 1.743 | Acc: 36.643% (16041/43776)\n",
      "Train Epoch: 0 | Loss: 1.741 | Acc: 36.687% (16107/43904)\n",
      "Train Epoch: 0 | Loss: 1.741 | Acc: 36.723% (16170/44032)\n",
      "Train Epoch: 0 | Loss: 1.739 | Acc: 36.778% (16241/44160)\n",
      "Train Epoch: 0 | Loss: 1.737 | Acc: 36.834% (16313/44288)\n",
      "Train Epoch: 0 | Loss: 1.736 | Acc: 36.881% (16381/44416)\n",
      "Train Epoch: 0 | Loss: 1.735 | Acc: 36.925% (16448/44544)\n",
      "Train Epoch: 0 | Loss: 1.734 | Acc: 36.969% (16515/44672)\n",
      "Train Epoch: 0 | Loss: 1.733 | Acc: 37.004% (16578/44800)\n",
      "Train Epoch: 0 | Loss: 1.732 | Acc: 37.041% (16642/44928)\n",
      "Train Epoch: 0 | Loss: 1.731 | Acc: 37.085% (16709/45056)\n",
      "Train Epoch: 0 | Loss: 1.730 | Acc: 37.091% (16759/45184)\n",
      "Train Epoch: 0 | Loss: 1.729 | Acc: 37.129% (16824/45312)\n",
      "Train Epoch: 0 | Loss: 1.729 | Acc: 37.148% (16880/45440)\n",
      "Train Epoch: 0 | Loss: 1.728 | Acc: 37.184% (16944/45568)\n",
      "Train Epoch: 0 | Loss: 1.726 | Acc: 37.251% (17022/45696)\n",
      "Train Epoch: 0 | Loss: 1.725 | Acc: 37.299% (17092/45824)\n",
      "Train Epoch: 0 | Loss: 1.724 | Acc: 37.319% (17149/45952)\n",
      "Train Epoch: 0 | Loss: 1.723 | Acc: 37.368% (17219/46080)\n",
      "Train Epoch: 0 | Loss: 1.721 | Acc: 37.409% (17286/46208)\n",
      "Train Epoch: 0 | Loss: 1.720 | Acc: 37.446% (17351/46336)\n",
      "Train Epoch: 0 | Loss: 1.719 | Acc: 37.509% (17428/46464)\n",
      "Train Epoch: 0 | Loss: 1.718 | Acc: 37.549% (17495/46592)\n",
      "Train Epoch: 0 | Loss: 1.717 | Acc: 37.596% (17565/46720)\n",
      "Train Epoch: 0 | Loss: 1.716 | Acc: 37.626% (17627/46848)\n",
      "Train Epoch: 0 | Loss: 1.715 | Acc: 37.660% (17691/46976)\n",
      "Train Epoch: 0 | Loss: 1.713 | Acc: 37.721% (17768/47104)\n",
      "Train Epoch: 0 | Loss: 1.712 | Acc: 37.769% (17839/47232)\n",
      "Train Epoch: 0 | Loss: 1.711 | Acc: 37.817% (17910/47360)\n",
      "Train Epoch: 0 | Loss: 1.709 | Acc: 37.860% (17979/47488)\n",
      "Train Epoch: 0 | Loss: 1.708 | Acc: 37.895% (18044/47616)\n",
      "Train Epoch: 0 | Loss: 1.707 | Acc: 37.952% (18120/47744)\n",
      "Train Epoch: 0 | Loss: 1.706 | Acc: 38.016% (18199/47872)\n",
      "Train Epoch: 0 | Loss: 1.704 | Acc: 38.073% (18275/48000)\n",
      "Train Epoch: 0 | Loss: 1.703 | Acc: 38.130% (18351/48128)\n",
      "Train Epoch: 0 | Loss: 1.702 | Acc: 38.171% (18420/48256)\n",
      "Train Epoch: 0 | Loss: 1.701 | Acc: 38.199% (18482/48384)\n",
      "Train Epoch: 0 | Loss: 1.700 | Acc: 38.230% (18546/48512)\n",
      "Train Epoch: 0 | Loss: 1.699 | Acc: 38.283% (18621/48640)\n",
      "Train Epoch: 0 | Loss: 1.698 | Acc: 38.330% (18693/48768)\n",
      "Train Epoch: 0 | Loss: 1.696 | Acc: 38.377% (18765/48896)\n",
      "Train Epoch: 0 | Loss: 1.695 | Acc: 38.420% (18835/49024)\n",
      "Train Epoch: 0 | Loss: 1.694 | Acc: 38.450% (18899/49152)\n",
      "Train Epoch: 0 | Loss: 1.693 | Acc: 38.502% (18974/49280)\n",
      "Train Epoch: 0 | Loss: 1.691 | Acc: 38.550% (19047/49408)\n",
      "Train Epoch: 0 | Loss: 1.690 | Acc: 38.594% (19118/49536)\n",
      "Train Epoch: 0 | Loss: 1.689 | Acc: 38.644% (19192/49664)\n",
      "Train Epoch: 0 | Loss: 1.687 | Acc: 38.697% (19268/49792)\n",
      "Train Epoch: 0 | Loss: 1.687 | Acc: 38.740% (19339/49920)\n",
      "Train Epoch: 0 | Loss: 1.685 | Acc: 38.766% (19383/50000)\n",
      "Test Epoch: 0 | Loss: 1.351 | Acc: 52.000% (52/100)\n",
      "Test Epoch: 0 | Loss: 1.440 | Acc: 50.500% (101/200)\n",
      "Test Epoch: 0 | Loss: 1.406 | Acc: 52.000% (156/300)\n",
      "Test Epoch: 0 | Loss: 1.411 | Acc: 52.750% (211/400)\n",
      "Test Epoch: 0 | Loss: 1.464 | Acc: 51.200% (256/500)\n",
      "Test Epoch: 0 | Loss: 1.432 | Acc: 51.833% (311/600)\n",
      "Test Epoch: 0 | Loss: 1.463 | Acc: 50.857% (356/700)\n",
      "Test Epoch: 0 | Loss: 1.466 | Acc: 51.250% (410/800)\n",
      "Test Epoch: 0 | Loss: 1.490 | Acc: 50.889% (458/900)\n",
      "Test Epoch: 0 | Loss: 1.472 | Acc: 51.500% (515/1000)\n",
      "Test Epoch: 0 | Loss: 1.453 | Acc: 52.364% (576/1100)\n",
      "Test Epoch: 0 | Loss: 1.473 | Acc: 52.083% (625/1200)\n",
      "Test Epoch: 0 | Loss: 1.468 | Acc: 51.462% (669/1300)\n",
      "Test Epoch: 0 | Loss: 1.473 | Acc: 51.500% (721/1400)\n",
      "Test Epoch: 0 | Loss: 1.461 | Acc: 51.733% (776/1500)\n",
      "Test Epoch: 0 | Loss: 1.470 | Acc: 51.500% (824/1600)\n",
      "Test Epoch: 0 | Loss: 1.474 | Acc: 51.588% (877/1700)\n",
      "Test Epoch: 0 | Loss: 1.480 | Acc: 51.333% (924/1800)\n",
      "Test Epoch: 0 | Loss: 1.479 | Acc: 51.368% (976/1900)\n",
      "Test Epoch: 0 | Loss: 1.490 | Acc: 51.150% (1023/2000)\n",
      "Test Epoch: 0 | Loss: 1.501 | Acc: 50.810% (1067/2100)\n",
      "Test Epoch: 0 | Loss: 1.503 | Acc: 50.636% (1114/2200)\n",
      "Test Epoch: 0 | Loss: 1.509 | Acc: 50.478% (1161/2300)\n",
      "Test Epoch: 0 | Loss: 1.509 | Acc: 50.417% (1210/2400)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 50.440% (1261/2500)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.154% (1304/2600)\n",
      "Test Epoch: 0 | Loss: 1.526 | Acc: 50.148% (1354/2700)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.357% (1410/2800)\n",
      "Test Epoch: 0 | Loss: 1.530 | Acc: 50.276% (1458/2900)\n",
      "Test Epoch: 0 | Loss: 1.531 | Acc: 50.367% (1511/3000)\n",
      "Test Epoch: 0 | Loss: 1.528 | Acc: 50.452% (1564/3100)\n",
      "Test Epoch: 0 | Loss: 1.518 | Acc: 50.688% (1622/3200)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.758% (1675/3300)\n",
      "Test Epoch: 0 | Loss: 1.525 | Acc: 50.676% (1723/3400)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.800% (1778/3500)\n",
      "Test Epoch: 0 | Loss: 1.524 | Acc: 51.000% (1836/3600)\n",
      "Test Epoch: 0 | Loss: 1.524 | Acc: 51.081% (1890/3700)\n",
      "Test Epoch: 0 | Loss: 1.525 | Acc: 51.368% (1952/3800)\n",
      "Test Epoch: 0 | Loss: 1.521 | Acc: 51.282% (2000/3900)\n",
      "Test Epoch: 0 | Loss: 1.520 | Acc: 51.300% (2052/4000)\n",
      "Test Epoch: 0 | Loss: 1.521 | Acc: 51.268% (2102/4100)\n",
      "Test Epoch: 0 | Loss: 1.518 | Acc: 51.476% (2162/4200)\n",
      "Test Epoch: 0 | Loss: 1.511 | Acc: 51.581% (2218/4300)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.727% (2276/4400)\n",
      "Test Epoch: 0 | Loss: 1.504 | Acc: 51.667% (2325/4500)\n",
      "Test Epoch: 0 | Loss: 1.504 | Acc: 51.609% (2374/4600)\n",
      "Test Epoch: 0 | Loss: 1.498 | Acc: 51.766% (2433/4700)\n",
      "Test Epoch: 0 | Loss: 1.495 | Acc: 51.917% (2492/4800)\n",
      "Test Epoch: 0 | Loss: 1.494 | Acc: 51.918% (2544/4900)\n",
      "Test Epoch: 0 | Loss: 1.498 | Acc: 51.800% (2590/5000)\n",
      "Test Epoch: 0 | Loss: 1.499 | Acc: 51.902% (2647/5100)\n",
      "Test Epoch: 0 | Loss: 1.502 | Acc: 51.827% (2695/5200)\n",
      "Test Epoch: 0 | Loss: 1.498 | Acc: 51.906% (2751/5300)\n",
      "Test Epoch: 0 | Loss: 1.503 | Acc: 51.833% (2799/5400)\n",
      "Test Epoch: 0 | Loss: 1.503 | Acc: 51.764% (2847/5500)\n",
      "Test Epoch: 0 | Loss: 1.504 | Acc: 51.857% (2904/5600)\n",
      "Test Epoch: 0 | Loss: 1.504 | Acc: 51.807% (2953/5700)\n",
      "Test Epoch: 0 | Loss: 1.501 | Acc: 51.845% (3007/5800)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.712% (3051/5900)\n",
      "Test Epoch: 0 | Loss: 1.505 | Acc: 51.750% (3105/6000)\n",
      "Test Epoch: 0 | Loss: 1.506 | Acc: 51.721% (3155/6100)\n",
      "Test Epoch: 0 | Loss: 1.506 | Acc: 51.758% (3209/6200)\n",
      "Test Epoch: 0 | Loss: 1.506 | Acc: 51.730% (3259/6300)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.734% (3311/6400)\n",
      "Test Epoch: 0 | Loss: 1.508 | Acc: 51.677% (3359/6500)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.667% (3410/6600)\n",
      "Test Epoch: 0 | Loss: 1.508 | Acc: 51.597% (3457/6700)\n",
      "Test Epoch: 0 | Loss: 1.511 | Acc: 51.441% (3498/6800)\n",
      "Test Epoch: 0 | Loss: 1.510 | Acc: 51.464% (3551/6900)\n",
      "Test Epoch: 0 | Loss: 1.513 | Acc: 51.386% (3597/7000)\n",
      "Test Epoch: 0 | Loss: 1.511 | Acc: 51.352% (3646/7100)\n",
      "Test Epoch: 0 | Loss: 1.508 | Acc: 51.347% (3697/7200)\n",
      "Test Epoch: 0 | Loss: 1.510 | Acc: 51.274% (3743/7300)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.297% (3796/7400)\n",
      "Test Epoch: 0 | Loss: 1.510 | Acc: 51.240% (3843/7500)\n",
      "Test Epoch: 0 | Loss: 1.507 | Acc: 51.329% (3901/7600)\n",
      "Test Epoch: 0 | Loss: 1.509 | Acc: 51.286% (3949/7700)\n",
      "Test Epoch: 0 | Loss: 1.509 | Acc: 51.269% (3999/7800)\n",
      "Test Epoch: 0 | Loss: 1.513 | Acc: 51.228% (4047/7900)\n",
      "Test Epoch: 0 | Loss: 1.518 | Acc: 51.087% (4087/8000)\n",
      "Test Epoch: 0 | Loss: 1.514 | Acc: 51.160% (4144/8100)\n",
      "Test Epoch: 0 | Loss: 1.517 | Acc: 50.951% (4178/8200)\n",
      "Test Epoch: 0 | Loss: 1.520 | Acc: 50.819% (4218/8300)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.714% (4260/8400)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.729% (4312/8500)\n",
      "Test Epoch: 0 | Loss: 1.520 | Acc: 50.733% (4363/8600)\n",
      "Test Epoch: 0 | Loss: 1.521 | Acc: 50.713% (4412/8700)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.693% (4461/8800)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.697% (4512/8900)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.733% (4566/9000)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.758% (4619/9100)\n",
      "Test Epoch: 0 | Loss: 1.521 | Acc: 50.793% (4673/9200)\n",
      "Test Epoch: 0 | Loss: 1.522 | Acc: 50.774% (4722/9300)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.734% (4769/9400)\n",
      "Test Epoch: 0 | Loss: 1.523 | Acc: 50.716% (4818/9500)\n",
      "Test Epoch: 0 | Loss: 1.521 | Acc: 50.792% (4876/9600)\n",
      "Test Epoch: 0 | Loss: 1.518 | Acc: 50.887% (4936/9700)\n",
      "Test Epoch: 0 | Loss: 1.520 | Acc: 50.816% (4980/9800)\n",
      "Test Epoch: 0 | Loss: 1.518 | Acc: 50.859% (5035/9900)\n",
      "Test Epoch: 0 | Loss: 1.519 | Acc: 50.860% (5086/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Train Epoch: 1 | Loss: 1.162 | Acc: 54.688% (70/128)\n",
      "Train Epoch: 1 | Loss: 1.218 | Acc: 55.469% (142/256)\n",
      "Train Epoch: 1 | Loss: 1.177 | Acc: 57.812% (222/384)\n",
      "Train Epoch: 1 | Loss: 1.198 | Acc: 56.641% (290/512)\n",
      "Train Epoch: 1 | Loss: 1.187 | Acc: 56.875% (364/640)\n",
      "Train Epoch: 1 | Loss: 1.208 | Acc: 56.250% (432/768)\n",
      "Train Epoch: 1 | Loss: 1.237 | Acc: 55.134% (494/896)\n",
      "Train Epoch: 1 | Loss: 1.241 | Acc: 54.980% (563/1024)\n",
      "Train Epoch: 1 | Loss: 1.242 | Acc: 55.035% (634/1152)\n",
      "Train Epoch: 1 | Loss: 1.228 | Acc: 55.938% (716/1280)\n",
      "Train Epoch: 1 | Loss: 1.251 | Acc: 55.114% (776/1408)\n",
      "Train Epoch: 1 | Loss: 1.245 | Acc: 55.404% (851/1536)\n",
      "Train Epoch: 1 | Loss: 1.245 | Acc: 55.288% (920/1664)\n",
      "Train Epoch: 1 | Loss: 1.240 | Acc: 55.190% (989/1792)\n",
      "Train Epoch: 1 | Loss: 1.235 | Acc: 55.469% (1065/1920)\n",
      "Train Epoch: 1 | Loss: 1.235 | Acc: 55.469% (1136/2048)\n",
      "Train Epoch: 1 | Loss: 1.235 | Acc: 55.699% (1212/2176)\n",
      "Train Epoch: 1 | Loss: 1.229 | Acc: 55.859% (1287/2304)\n",
      "Train Epoch: 1 | Loss: 1.227 | Acc: 55.839% (1358/2432)\n",
      "Train Epoch: 1 | Loss: 1.224 | Acc: 56.055% (1435/2560)\n",
      "Train Epoch: 1 | Loss: 1.222 | Acc: 56.213% (1511/2688)\n",
      "Train Epoch: 1 | Loss: 1.217 | Acc: 56.286% (1585/2816)\n",
      "Train Epoch: 1 | Loss: 1.213 | Acc: 56.556% (1665/2944)\n",
      "Train Epoch: 1 | Loss: 1.214 | Acc: 56.608% (1739/3072)\n",
      "Train Epoch: 1 | Loss: 1.217 | Acc: 56.688% (1814/3200)\n",
      "Train Epoch: 1 | Loss: 1.213 | Acc: 56.881% (1893/3328)\n",
      "Train Epoch: 1 | Loss: 1.214 | Acc: 56.684% (1959/3456)\n",
      "Train Epoch: 1 | Loss: 1.219 | Acc: 56.250% (2016/3584)\n",
      "Train Epoch: 1 | Loss: 1.214 | Acc: 56.466% (2096/3712)\n",
      "Train Epoch: 1 | Loss: 1.211 | Acc: 56.693% (2177/3840)\n",
      "Train Epoch: 1 | Loss: 1.207 | Acc: 56.905% (2258/3968)\n",
      "Train Epoch: 1 | Loss: 1.202 | Acc: 57.104% (2339/4096)\n",
      "Train Epoch: 1 | Loss: 1.200 | Acc: 57.244% (2418/4224)\n",
      "Train Epoch: 1 | Loss: 1.201 | Acc: 57.284% (2493/4352)\n",
      "Train Epoch: 1 | Loss: 1.204 | Acc: 57.076% (2557/4480)\n",
      "Train Epoch: 1 | Loss: 1.205 | Acc: 57.031% (2628/4608)\n",
      "Train Epoch: 1 | Loss: 1.202 | Acc: 57.116% (2705/4736)\n",
      "Train Epoch: 1 | Loss: 1.200 | Acc: 57.113% (2778/4864)\n",
      "Train Epoch: 1 | Loss: 1.198 | Acc: 57.232% (2857/4992)\n",
      "Train Epoch: 1 | Loss: 1.202 | Acc: 57.090% (2923/5120)\n",
      "Train Epoch: 1 | Loss: 1.202 | Acc: 57.069% (2995/5248)\n",
      "Train Epoch: 1 | Loss: 1.201 | Acc: 57.031% (3066/5376)\n",
      "Train Epoch: 1 | Loss: 1.199 | Acc: 57.158% (3146/5504)\n",
      "Train Epoch: 1 | Loss: 1.199 | Acc: 57.085% (3215/5632)\n",
      "Train Epoch: 1 | Loss: 1.198 | Acc: 57.135% (3291/5760)\n",
      "Train Epoch: 1 | Loss: 1.201 | Acc: 57.031% (3358/5888)\n",
      "Train Epoch: 1 | Loss: 1.198 | Acc: 57.114% (3436/6016)\n",
      "Train Epoch: 1 | Loss: 1.199 | Acc: 57.031% (3504/6144)\n",
      "Train Epoch: 1 | Loss: 1.203 | Acc: 56.936% (3571/6272)\n",
      "Train Epoch: 1 | Loss: 1.202 | Acc: 57.000% (3648/6400)\n",
      "Train Epoch: 1 | Loss: 1.203 | Acc: 57.077% (3726/6528)\n",
      "Train Epoch: 1 | Loss: 1.203 | Acc: 57.091% (3800/6656)\n",
      "Train Epoch: 1 | Loss: 1.201 | Acc: 57.134% (3876/6784)\n",
      "Train Epoch: 1 | Loss: 1.199 | Acc: 57.292% (3960/6912)\n",
      "Train Epoch: 1 | Loss: 1.197 | Acc: 57.372% (4039/7040)\n",
      "Train Epoch: 1 | Loss: 1.195 | Acc: 57.520% (4123/7168)\n",
      "Train Epoch: 1 | Loss: 1.194 | Acc: 57.538% (4198/7296)\n",
      "Train Epoch: 1 | Loss: 1.190 | Acc: 57.745% (4287/7424)\n",
      "Train Epoch: 1 | Loss: 1.188 | Acc: 57.865% (4370/7552)\n",
      "Train Epoch: 1 | Loss: 1.187 | Acc: 57.904% (4447/7680)\n",
      "Train Epoch: 1 | Loss: 1.188 | Acc: 57.877% (4519/7808)\n",
      "Train Epoch: 1 | Loss: 1.186 | Acc: 57.951% (4599/7936)\n",
      "Train Epoch: 1 | Loss: 1.186 | Acc: 57.974% (4675/8064)\n",
      "Train Epoch: 1 | Loss: 1.187 | Acc: 57.971% (4749/8192)\n",
      "Train Epoch: 1 | Loss: 1.186 | Acc: 58.041% (4829/8320)\n",
      "Train Epoch: 1 | Loss: 1.185 | Acc: 58.026% (4902/8448)\n",
      "Train Epoch: 1 | Loss: 1.185 | Acc: 57.987% (4973/8576)\n",
      "Train Epoch: 1 | Loss: 1.183 | Acc: 58.088% (5056/8704)\n",
      "Train Epoch: 1 | Loss: 1.183 | Acc: 58.084% (5130/8832)\n",
      "Train Epoch: 1 | Loss: 1.183 | Acc: 58.147% (5210/8960)\n",
      "Train Epoch: 1 | Loss: 1.182 | Acc: 58.143% (5284/9088)\n",
      "Train Epoch: 1 | Loss: 1.180 | Acc: 58.268% (5370/9216)\n",
      "Train Epoch: 1 | Loss: 1.179 | Acc: 58.305% (5448/9344)\n",
      "Train Epoch: 1 | Loss: 1.180 | Acc: 58.330% (5525/9472)\n",
      "Train Epoch: 1 | Loss: 1.180 | Acc: 58.365% (5603/9600)\n",
      "Train Epoch: 1 | Loss: 1.177 | Acc: 58.470% (5688/9728)\n",
      "Train Epoch: 1 | Loss: 1.176 | Acc: 58.452% (5761/9856)\n",
      "Train Epoch: 1 | Loss: 1.178 | Acc: 58.373% (5828/9984)\n",
      "Train Epoch: 1 | Loss: 1.177 | Acc: 58.347% (5900/10112)\n",
      "Train Epoch: 1 | Loss: 1.176 | Acc: 58.350% (5975/10240)\n",
      "Train Epoch: 1 | Loss: 1.175 | Acc: 58.372% (6052/10368)\n",
      "Train Epoch: 1 | Loss: 1.174 | Acc: 58.403% (6130/10496)\n",
      "Train Epoch: 1 | Loss: 1.173 | Acc: 58.387% (6203/10624)\n",
      "Train Epoch: 1 | Loss: 1.173 | Acc: 58.380% (6277/10752)\n",
      "Train Epoch: 1 | Loss: 1.172 | Acc: 58.447% (6359/10880)\n",
      "Train Epoch: 1 | Loss: 1.170 | Acc: 58.503% (6440/11008)\n",
      "Train Epoch: 1 | Loss: 1.170 | Acc: 58.495% (6514/11136)\n",
      "Train Epoch: 1 | Loss: 1.169 | Acc: 58.558% (6596/11264)\n",
      "Train Epoch: 1 | Loss: 1.171 | Acc: 58.497% (6664/11392)\n",
      "Train Epoch: 1 | Loss: 1.168 | Acc: 58.585% (6749/11520)\n",
      "Train Epoch: 1 | Loss: 1.166 | Acc: 58.654% (6832/11648)\n",
      "Train Epoch: 1 | Loss: 1.166 | Acc: 58.696% (6912/11776)\n",
      "Train Epoch: 1 | Loss: 1.166 | Acc: 58.686% (6986/11904)\n",
      "Train Epoch: 1 | Loss: 1.166 | Acc: 58.718% (7065/12032)\n",
      "Train Epoch: 1 | Loss: 1.165 | Acc: 58.766% (7146/12160)\n",
      "Train Epoch: 1 | Loss: 1.163 | Acc: 58.854% (7232/12288)\n",
      "Train Epoch: 1 | Loss: 1.163 | Acc: 58.900% (7313/12416)\n",
      "Train Epoch: 1 | Loss: 1.162 | Acc: 58.937% (7393/12544)\n",
      "Train Epoch: 1 | Loss: 1.161 | Acc: 58.949% (7470/12672)\n",
      "Train Epoch: 1 | Loss: 1.161 | Acc: 58.977% (7549/12800)\n",
      "Train Epoch: 1 | Loss: 1.161 | Acc: 59.011% (7629/12928)\n",
      "Train Epoch: 1 | Loss: 1.159 | Acc: 59.053% (7710/13056)\n",
      "Train Epoch: 1 | Loss: 1.157 | Acc: 59.125% (7795/13184)\n",
      "Train Epoch: 1 | Loss: 1.158 | Acc: 59.090% (7866/13312)\n",
      "Train Epoch: 1 | Loss: 1.156 | Acc: 59.159% (7951/13440)\n",
      "Train Epoch: 1 | Loss: 1.157 | Acc: 59.147% (8025/13568)\n",
      "Train Epoch: 1 | Loss: 1.156 | Acc: 59.185% (8106/13696)\n",
      "Train Epoch: 1 | Loss: 1.155 | Acc: 59.238% (8189/13824)\n",
      "Train Epoch: 1 | Loss: 1.156 | Acc: 59.203% (8260/13952)\n",
      "Train Epoch: 1 | Loss: 1.155 | Acc: 59.190% (8334/14080)\n",
      "Train Epoch: 1 | Loss: 1.156 | Acc: 59.115% (8399/14208)\n",
      "Train Epoch: 1 | Loss: 1.154 | Acc: 59.180% (8484/14336)\n",
      "Train Epoch: 1 | Loss: 1.154 | Acc: 59.161% (8557/14464)\n",
      "Train Epoch: 1 | Loss: 1.152 | Acc: 59.231% (8643/14592)\n",
      "Train Epoch: 1 | Loss: 1.151 | Acc: 59.280% (8726/14720)\n",
      "Train Epoch: 1 | Loss: 1.151 | Acc: 59.254% (8798/14848)\n",
      "Train Epoch: 1 | Loss: 1.150 | Acc: 59.355% (8889/14976)\n",
      "Train Epoch: 1 | Loss: 1.150 | Acc: 59.342% (8963/15104)\n",
      "Train Epoch: 1 | Loss: 1.150 | Acc: 59.336% (9038/15232)\n",
      "Train Epoch: 1 | Loss: 1.150 | Acc: 59.303% (9109/15360)\n",
      "Train Epoch: 1 | Loss: 1.149 | Acc: 59.310% (9186/15488)\n",
      "Train Epoch: 1 | Loss: 1.148 | Acc: 59.369% (9271/15616)\n",
      "Train Epoch: 1 | Loss: 1.148 | Acc: 59.375% (9348/15744)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.407% (9429/15872)\n",
      "Train Epoch: 1 | Loss: 1.148 | Acc: 59.344% (9495/16000)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.406% (9581/16128)\n",
      "Train Epoch: 1 | Loss: 1.148 | Acc: 59.375% (9652/16256)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.418% (9735/16384)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.436% (9814/16512)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.483% (9898/16640)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.488% (9975/16768)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.517% (10056/16896)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.569% (10141/17024)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.550% (10214/17152)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.560% (10292/17280)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.501% (10358/17408)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.489% (10432/17536)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.449% (10501/17664)\n",
      "Train Epoch: 1 | Loss: 1.147 | Acc: 59.454% (10578/17792)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.470% (10657/17920)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.486% (10736/18048)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.540% (10822/18176)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.544% (10899/18304)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.549% (10976/18432)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.542% (11051/18560)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.541% (11127/18688)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.487% (11193/18816)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.496% (11271/18944)\n",
      "Train Epoch: 1 | Loss: 1.146 | Acc: 59.485% (11345/19072)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.542% (11432/19200)\n",
      "Train Epoch: 1 | Loss: 1.145 | Acc: 59.561% (11512/19328)\n",
      "Train Epoch: 1 | Loss: 1.144 | Acc: 59.596% (11595/19456)\n",
      "Train Epoch: 1 | Loss: 1.144 | Acc: 59.595% (11671/19584)\n",
      "Train Epoch: 1 | Loss: 1.143 | Acc: 59.679% (11764/19712)\n",
      "Train Epoch: 1 | Loss: 1.141 | Acc: 59.713% (11847/19840)\n",
      "Train Epoch: 1 | Loss: 1.142 | Acc: 59.650% (11911/19968)\n",
      "Train Epoch: 1 | Loss: 1.142 | Acc: 59.669% (11991/20096)\n",
      "Train Epoch: 1 | Loss: 1.141 | Acc: 59.711% (12076/20224)\n",
      "Train Epoch: 1 | Loss: 1.141 | Acc: 59.680% (12146/20352)\n",
      "Train Epoch: 1 | Loss: 1.141 | Acc: 59.678% (12222/20480)\n",
      "Train Epoch: 1 | Loss: 1.140 | Acc: 59.739% (12311/20608)\n",
      "Train Epoch: 1 | Loss: 1.140 | Acc: 59.766% (12393/20736)\n",
      "Train Epoch: 1 | Loss: 1.139 | Acc: 59.754% (12467/20864)\n",
      "Train Epoch: 1 | Loss: 1.138 | Acc: 59.808% (12555/20992)\n",
      "Train Epoch: 1 | Loss: 1.138 | Acc: 59.782% (12626/21120)\n",
      "Train Epoch: 1 | Loss: 1.137 | Acc: 59.817% (12710/21248)\n",
      "Train Epoch: 1 | Loss: 1.136 | Acc: 59.894% (12803/21376)\n",
      "Train Epoch: 1 | Loss: 1.136 | Acc: 59.887% (12878/21504)\n",
      "Train Epoch: 1 | Loss: 1.136 | Acc: 59.847% (12946/21632)\n",
      "Train Epoch: 1 | Loss: 1.135 | Acc: 59.894% (13033/21760)\n",
      "Train Epoch: 1 | Loss: 1.134 | Acc: 59.932% (13118/21888)\n",
      "Train Epoch: 1 | Loss: 1.133 | Acc: 59.961% (13201/22016)\n",
      "Train Epoch: 1 | Loss: 1.133 | Acc: 59.967% (13279/22144)\n",
      "Train Epoch: 1 | Loss: 1.133 | Acc: 59.959% (13354/22272)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 59.991% (13438/22400)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 60.010% (13519/22528)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 59.984% (13590/22656)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 60.011% (13673/22784)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 59.982% (13743/22912)\n",
      "Train Epoch: 1 | Loss: 1.132 | Acc: 59.983% (13820/23040)\n",
      "Train Epoch: 1 | Loss: 1.131 | Acc: 60.031% (13908/23168)\n",
      "Train Epoch: 1 | Loss: 1.131 | Acc: 60.045% (13988/23296)\n",
      "Train Epoch: 1 | Loss: 1.131 | Acc: 60.020% (14059/23424)\n",
      "Train Epoch: 1 | Loss: 1.131 | Acc: 60.037% (14140/23552)\n",
      "Train Epoch: 1 | Loss: 1.130 | Acc: 60.072% (14225/23680)\n",
      "Train Epoch: 1 | Loss: 1.130 | Acc: 60.106% (14310/23808)\n",
      "Train Epoch: 1 | Loss: 1.130 | Acc: 60.085% (14382/23936)\n",
      "Train Epoch: 1 | Loss: 1.129 | Acc: 60.106% (14464/24064)\n",
      "Train Epoch: 1 | Loss: 1.129 | Acc: 60.082% (14535/24192)\n",
      "Train Epoch: 1 | Loss: 1.129 | Acc: 60.115% (14620/24320)\n",
      "Train Epoch: 1 | Loss: 1.128 | Acc: 60.128% (14700/24448)\n",
      "Train Epoch: 1 | Loss: 1.128 | Acc: 60.140% (14780/24576)\n",
      "Train Epoch: 1 | Loss: 1.128 | Acc: 60.148% (14859/24704)\n",
      "Train Epoch: 1 | Loss: 1.127 | Acc: 60.144% (14935/24832)\n",
      "Train Epoch: 1 | Loss: 1.127 | Acc: 60.140% (15011/24960)\n",
      "Train Epoch: 1 | Loss: 1.126 | Acc: 60.164% (15094/25088)\n",
      "Train Epoch: 1 | Loss: 1.127 | Acc: 60.172% (15173/25216)\n",
      "Train Epoch: 1 | Loss: 1.127 | Acc: 60.180% (15252/25344)\n",
      "Train Epoch: 1 | Loss: 1.126 | Acc: 60.203% (15335/25472)\n",
      "Train Epoch: 1 | Loss: 1.126 | Acc: 60.199% (15411/25600)\n",
      "Train Epoch: 1 | Loss: 1.126 | Acc: 60.199% (15488/25728)\n",
      "Train Epoch: 1 | Loss: 1.126 | Acc: 60.199% (15565/25856)\n",
      "Train Epoch: 1 | Loss: 1.125 | Acc: 60.214% (15646/25984)\n",
      "Train Epoch: 1 | Loss: 1.125 | Acc: 60.218% (15724/26112)\n",
      "Train Epoch: 1 | Loss: 1.124 | Acc: 60.217% (15801/26240)\n",
      "Train Epoch: 1 | Loss: 1.123 | Acc: 60.247% (15886/26368)\n",
      "Train Epoch: 1 | Loss: 1.124 | Acc: 60.232% (15959/26496)\n",
      "Train Epoch: 1 | Loss: 1.124 | Acc: 60.220% (16033/26624)\n",
      "Train Epoch: 1 | Loss: 1.124 | Acc: 60.235% (16114/26752)\n",
      "Train Epoch: 1 | Loss: 1.123 | Acc: 60.238% (16192/26880)\n",
      "Train Epoch: 1 | Loss: 1.122 | Acc: 60.293% (16284/27008)\n",
      "Train Epoch: 1 | Loss: 1.121 | Acc: 60.311% (16366/27136)\n",
      "Train Epoch: 1 | Loss: 1.122 | Acc: 60.288% (16437/27264)\n",
      "Train Epoch: 1 | Loss: 1.121 | Acc: 60.306% (16519/27392)\n",
      "Train Epoch: 1 | Loss: 1.121 | Acc: 60.298% (16594/27520)\n",
      "Train Epoch: 1 | Loss: 1.121 | Acc: 60.290% (16669/27648)\n",
      "Train Epoch: 1 | Loss: 1.121 | Acc: 60.275% (16742/27776)\n",
      "Train Epoch: 1 | Loss: 1.120 | Acc: 60.296% (16825/27904)\n",
      "Train Epoch: 1 | Loss: 1.119 | Acc: 60.338% (16914/28032)\n",
      "Train Epoch: 1 | Loss: 1.119 | Acc: 60.344% (16993/28160)\n",
      "Train Epoch: 1 | Loss: 1.118 | Acc: 60.375% (17079/28288)\n",
      "Train Epoch: 1 | Loss: 1.119 | Acc: 60.353% (17150/28416)\n",
      "Train Epoch: 1 | Loss: 1.118 | Acc: 60.377% (17234/28544)\n",
      "Train Epoch: 1 | Loss: 1.118 | Acc: 60.411% (17321/28672)\n",
      "Train Epoch: 1 | Loss: 1.117 | Acc: 60.434% (17405/28800)\n",
      "Train Epoch: 1 | Loss: 1.116 | Acc: 60.471% (17493/28928)\n",
      "Train Epoch: 1 | Loss: 1.116 | Acc: 60.456% (17566/29056)\n",
      "Train Epoch: 1 | Loss: 1.116 | Acc: 60.465% (17646/29184)\n",
      "Train Epoch: 1 | Loss: 1.115 | Acc: 60.494% (17732/29312)\n",
      "Train Epoch: 1 | Loss: 1.115 | Acc: 60.482% (17806/29440)\n",
      "Train Epoch: 1 | Loss: 1.114 | Acc: 60.501% (17889/29568)\n",
      "Train Epoch: 1 | Loss: 1.114 | Acc: 60.510% (17969/29696)\n",
      "Train Epoch: 1 | Loss: 1.113 | Acc: 60.515% (18048/29824)\n",
      "Train Epoch: 1 | Loss: 1.113 | Acc: 60.537% (18132/29952)\n",
      "Train Epoch: 1 | Loss: 1.112 | Acc: 60.572% (18220/30080)\n",
      "Train Epoch: 1 | Loss: 1.112 | Acc: 60.567% (18296/30208)\n",
      "Train Epoch: 1 | Loss: 1.111 | Acc: 60.621% (18390/30336)\n",
      "Train Epoch: 1 | Loss: 1.110 | Acc: 60.629% (18470/30464)\n",
      "Train Epoch: 1 | Loss: 1.110 | Acc: 60.643% (18552/30592)\n",
      "Train Epoch: 1 | Loss: 1.109 | Acc: 60.661% (18635/30720)\n",
      "Train Epoch: 1 | Loss: 1.110 | Acc: 60.681% (18719/30848)\n",
      "Train Epoch: 1 | Loss: 1.108 | Acc: 60.705% (18804/30976)\n",
      "Train Epoch: 1 | Loss: 1.108 | Acc: 60.741% (18893/31104)\n",
      "Train Epoch: 1 | Loss: 1.107 | Acc: 60.745% (18972/31232)\n",
      "Train Epoch: 1 | Loss: 1.107 | Acc: 60.762% (19055/31360)\n",
      "Train Epoch: 1 | Loss: 1.106 | Acc: 60.788% (19141/31488)\n",
      "Train Epoch: 1 | Loss: 1.105 | Acc: 60.805% (19224/31616)\n",
      "Train Epoch: 1 | Loss: 1.105 | Acc: 60.840% (19313/31744)\n",
      "Train Epoch: 1 | Loss: 1.104 | Acc: 60.865% (19399/31872)\n",
      "Train Epoch: 1 | Loss: 1.104 | Acc: 60.897% (19487/32000)\n",
      "Train Epoch: 1 | Loss: 1.103 | Acc: 60.916% (19571/32128)\n",
      "Train Epoch: 1 | Loss: 1.103 | Acc: 60.913% (19648/32256)\n",
      "Train Epoch: 1 | Loss: 1.103 | Acc: 60.891% (19719/32384)\n",
      "Train Epoch: 1 | Loss: 1.103 | Acc: 60.907% (19802/32512)\n",
      "Train Epoch: 1 | Loss: 1.102 | Acc: 60.944% (19892/32640)\n",
      "Train Epoch: 1 | Loss: 1.101 | Acc: 60.965% (19977/32768)\n",
      "Train Epoch: 1 | Loss: 1.101 | Acc: 60.977% (20059/32896)\n",
      "Train Epoch: 1 | Loss: 1.101 | Acc: 61.013% (20149/33024)\n",
      "Train Epoch: 1 | Loss: 1.100 | Acc: 61.019% (20229/33152)\n",
      "Train Epoch: 1 | Loss: 1.100 | Acc: 61.058% (20320/33280)\n",
      "Train Epoch: 1 | Loss: 1.100 | Acc: 61.036% (20391/33408)\n",
      "Train Epoch: 1 | Loss: 1.100 | Acc: 61.057% (20476/33536)\n",
      "Train Epoch: 1 | Loss: 1.099 | Acc: 61.059% (20555/33664)\n",
      "Train Epoch: 1 | Loss: 1.099 | Acc: 61.083% (20641/33792)\n",
      "Train Epoch: 1 | Loss: 1.098 | Acc: 61.106% (20727/33920)\n",
      "Train Epoch: 1 | Loss: 1.098 | Acc: 61.114% (20808/34048)\n",
      "Train Epoch: 1 | Loss: 1.098 | Acc: 61.119% (20888/34176)\n",
      "Train Epoch: 1 | Loss: 1.097 | Acc: 61.130% (20970/34304)\n",
      "Train Epoch: 1 | Loss: 1.096 | Acc: 61.138% (21051/34432)\n",
      "Train Epoch: 1 | Loss: 1.097 | Acc: 61.126% (21125/34560)\n",
      "Train Epoch: 1 | Loss: 1.096 | Acc: 61.165% (21217/34688)\n",
      "Train Epoch: 1 | Loss: 1.096 | Acc: 61.164% (21295/34816)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.175% (21377/34944)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.191% (21461/35072)\n",
      "Train Epoch: 1 | Loss: 1.096 | Acc: 61.188% (21538/35200)\n",
      "Train Epoch: 1 | Loss: 1.096 | Acc: 61.187% (21616/35328)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.183% (21693/35456)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.202% (21778/35584)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.184% (21850/35712)\n",
      "Train Epoch: 1 | Loss: 1.095 | Acc: 61.219% (21941/35840)\n",
      "Train Epoch: 1 | Loss: 1.094 | Acc: 61.224% (22021/35968)\n",
      "Train Epoch: 1 | Loss: 1.094 | Acc: 61.245% (22107/36096)\n",
      "Train Epoch: 1 | Loss: 1.093 | Acc: 61.260% (22191/36224)\n",
      "Train Epoch: 1 | Loss: 1.093 | Acc: 61.259% (22269/36352)\n",
      "Train Epoch: 1 | Loss: 1.093 | Acc: 61.275% (22353/36480)\n",
      "Train Epoch: 1 | Loss: 1.092 | Acc: 61.320% (22448/36608)\n",
      "Train Epoch: 1 | Loss: 1.091 | Acc: 61.338% (22533/36736)\n",
      "Train Epoch: 1 | Loss: 1.091 | Acc: 61.358% (22619/36864)\n",
      "Train Epoch: 1 | Loss: 1.091 | Acc: 61.362% (22699/36992)\n",
      "Train Epoch: 1 | Loss: 1.090 | Acc: 61.377% (22783/37120)\n",
      "Train Epoch: 1 | Loss: 1.090 | Acc: 61.405% (22872/37248)\n",
      "Train Epoch: 1 | Loss: 1.090 | Acc: 61.430% (22960/37376)\n",
      "Train Epoch: 1 | Loss: 1.089 | Acc: 61.457% (23049/37504)\n",
      "Train Epoch: 1 | Loss: 1.089 | Acc: 61.456% (23127/37632)\n",
      "Train Epoch: 1 | Loss: 1.089 | Acc: 61.483% (23216/37760)\n",
      "Train Epoch: 1 | Loss: 1.088 | Acc: 61.508% (23304/37888)\n",
      "Train Epoch: 1 | Loss: 1.087 | Acc: 61.527% (23390/38016)\n",
      "Train Epoch: 1 | Loss: 1.087 | Acc: 61.522% (23467/38144)\n",
      "Train Epoch: 1 | Loss: 1.087 | Acc: 61.541% (23553/38272)\n",
      "Train Epoch: 1 | Loss: 1.086 | Acc: 61.560% (23639/38400)\n",
      "Train Epoch: 1 | Loss: 1.085 | Acc: 61.597% (23732/38528)\n",
      "Train Epoch: 1 | Loss: 1.084 | Acc: 61.633% (23825/38656)\n",
      "Train Epoch: 1 | Loss: 1.085 | Acc: 61.621% (23899/38784)\n",
      "Train Epoch: 1 | Loss: 1.084 | Acc: 61.634% (23983/38912)\n",
      "Train Epoch: 1 | Loss: 1.084 | Acc: 61.632% (24061/39040)\n",
      "Train Epoch: 1 | Loss: 1.083 | Acc: 61.660% (24151/39168)\n",
      "Train Epoch: 1 | Loss: 1.084 | Acc: 61.647% (24225/39296)\n",
      "Train Epoch: 1 | Loss: 1.083 | Acc: 61.665% (24311/39424)\n",
      "Train Epoch: 1 | Loss: 1.083 | Acc: 61.676% (24394/39552)\n",
      "Train Epoch: 1 | Loss: 1.082 | Acc: 61.694% (24480/39680)\n",
      "Train Epoch: 1 | Loss: 1.082 | Acc: 61.701% (24562/39808)\n",
      "Train Epoch: 1 | Loss: 1.082 | Acc: 61.699% (24640/39936)\n",
      "Train Epoch: 1 | Loss: 1.081 | Acc: 61.721% (24728/40064)\n",
      "Train Epoch: 1 | Loss: 1.081 | Acc: 61.724% (24808/40192)\n",
      "Train Epoch: 1 | Loss: 1.081 | Acc: 61.719% (24885/40320)\n",
      "Train Epoch: 1 | Loss: 1.081 | Acc: 61.726% (24967/40448)\n",
      "Train Epoch: 1 | Loss: 1.080 | Acc: 61.748% (25055/40576)\n",
      "Train Epoch: 1 | Loss: 1.080 | Acc: 61.743% (25132/40704)\n",
      "Train Epoch: 1 | Loss: 1.080 | Acc: 61.751% (25214/40832)\n",
      "Train Epoch: 1 | Loss: 1.080 | Acc: 61.772% (25302/40960)\n",
      "Train Epoch: 1 | Loss: 1.079 | Acc: 61.784% (25386/41088)\n",
      "Train Epoch: 1 | Loss: 1.079 | Acc: 61.784% (25465/41216)\n",
      "Train Epoch: 1 | Loss: 1.079 | Acc: 61.784% (25544/41344)\n",
      "Train Epoch: 1 | Loss: 1.079 | Acc: 61.801% (25630/41472)\n",
      "Train Epoch: 1 | Loss: 1.078 | Acc: 61.805% (25711/41600)\n",
      "Train Epoch: 1 | Loss: 1.078 | Acc: 61.800% (25788/41728)\n",
      "Train Epoch: 1 | Loss: 1.078 | Acc: 61.802% (25868/41856)\n",
      "Train Epoch: 1 | Loss: 1.078 | Acc: 61.814% (25952/41984)\n",
      "Train Epoch: 1 | Loss: 1.078 | Acc: 61.823% (26035/42112)\n",
      "Train Epoch: 1 | Loss: 1.077 | Acc: 61.868% (26133/42240)\n",
      "Train Epoch: 1 | Loss: 1.076 | Acc: 61.891% (26222/42368)\n",
      "Train Epoch: 1 | Loss: 1.075 | Acc: 61.921% (26314/42496)\n",
      "Train Epoch: 1 | Loss: 1.075 | Acc: 61.925% (26395/42624)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 61.962% (26490/42752)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 61.966% (26571/42880)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 61.986% (26659/43008)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 61.995% (26742/43136)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 62.012% (26829/43264)\n",
      "Train Epoch: 1 | Loss: 1.073 | Acc: 62.025% (26914/43392)\n",
      "Train Epoch: 1 | Loss: 1.072 | Acc: 62.043% (27001/43520)\n",
      "Train Epoch: 1 | Loss: 1.072 | Acc: 62.065% (27090/43648)\n",
      "Train Epoch: 1 | Loss: 1.071 | Acc: 62.066% (27170/43776)\n",
      "Train Epoch: 1 | Loss: 1.071 | Acc: 62.074% (27253/43904)\n",
      "Train Epoch: 1 | Loss: 1.071 | Acc: 62.075% (27333/44032)\n",
      "Train Epoch: 1 | Loss: 1.070 | Acc: 62.122% (27433/44160)\n",
      "Train Epoch: 1 | Loss: 1.069 | Acc: 62.134% (27518/44288)\n",
      "Train Epoch: 1 | Loss: 1.069 | Acc: 62.153% (27606/44416)\n",
      "Train Epoch: 1 | Loss: 1.068 | Acc: 62.165% (27691/44544)\n",
      "Train Epoch: 1 | Loss: 1.068 | Acc: 62.184% (27779/44672)\n",
      "Train Epoch: 1 | Loss: 1.067 | Acc: 62.208% (27869/44800)\n",
      "Train Epoch: 1 | Loss: 1.067 | Acc: 62.220% (27954/44928)\n",
      "Train Epoch: 1 | Loss: 1.067 | Acc: 62.218% (28033/45056)\n",
      "Train Epoch: 1 | Loss: 1.066 | Acc: 62.239% (28122/45184)\n",
      "Train Epoch: 1 | Loss: 1.066 | Acc: 62.246% (28205/45312)\n",
      "Train Epoch: 1 | Loss: 1.065 | Acc: 62.265% (28293/45440)\n",
      "Train Epoch: 1 | Loss: 1.065 | Acc: 62.281% (28380/45568)\n",
      "Train Epoch: 1 | Loss: 1.064 | Acc: 62.286% (28462/45696)\n",
      "Train Epoch: 1 | Loss: 1.064 | Acc: 62.295% (28546/45824)\n",
      "Train Epoch: 1 | Loss: 1.064 | Acc: 62.308% (28632/45952)\n",
      "Train Epoch: 1 | Loss: 1.063 | Acc: 62.329% (28721/46080)\n",
      "Train Epoch: 1 | Loss: 1.063 | Acc: 62.338% (28805/46208)\n",
      "Train Epoch: 1 | Loss: 1.063 | Acc: 62.340% (28886/46336)\n",
      "Train Epoch: 1 | Loss: 1.062 | Acc: 62.356% (28973/46464)\n",
      "Train Epoch: 1 | Loss: 1.062 | Acc: 62.376% (29062/46592)\n",
      "Train Epoch: 1 | Loss: 1.061 | Acc: 62.406% (29156/46720)\n",
      "Train Epoch: 1 | Loss: 1.061 | Acc: 62.425% (29245/46848)\n",
      "Train Epoch: 1 | Loss: 1.061 | Acc: 62.430% (29327/46976)\n",
      "Train Epoch: 1 | Loss: 1.060 | Acc: 62.458% (29420/47104)\n",
      "Train Epoch: 1 | Loss: 1.059 | Acc: 62.489% (29515/47232)\n",
      "Train Epoch: 1 | Loss: 1.059 | Acc: 62.515% (29607/47360)\n",
      "Train Epoch: 1 | Loss: 1.058 | Acc: 62.542% (29700/47488)\n",
      "Train Epoch: 1 | Loss: 1.058 | Acc: 62.546% (29782/47616)\n",
      "Train Epoch: 1 | Loss: 1.057 | Acc: 62.561% (29869/47744)\n",
      "Train Epoch: 1 | Loss: 1.057 | Acc: 62.571% (29954/47872)\n",
      "Train Epoch: 1 | Loss: 1.057 | Acc: 62.587% (30042/48000)\n",
      "Train Epoch: 1 | Loss: 1.056 | Acc: 62.602% (30129/48128)\n",
      "Train Epoch: 1 | Loss: 1.056 | Acc: 62.610% (30213/48256)\n",
      "Train Epoch: 1 | Loss: 1.056 | Acc: 62.616% (30296/48384)\n",
      "Train Epoch: 1 | Loss: 1.056 | Acc: 62.615% (30376/48512)\n",
      "Train Epoch: 1 | Loss: 1.055 | Acc: 62.642% (30469/48640)\n",
      "Train Epoch: 1 | Loss: 1.055 | Acc: 62.656% (30556/48768)\n",
      "Train Epoch: 1 | Loss: 1.055 | Acc: 62.660% (30638/48896)\n",
      "Train Epoch: 1 | Loss: 1.054 | Acc: 62.675% (30726/49024)\n",
      "Train Epoch: 1 | Loss: 1.054 | Acc: 62.695% (30816/49152)\n",
      "Train Epoch: 1 | Loss: 1.054 | Acc: 62.703% (30900/49280)\n",
      "Train Epoch: 1 | Loss: 1.053 | Acc: 62.710% (30984/49408)\n",
      "Train Epoch: 1 | Loss: 1.053 | Acc: 62.742% (31080/49536)\n",
      "Train Epoch: 1 | Loss: 1.053 | Acc: 62.760% (31169/49664)\n",
      "Train Epoch: 1 | Loss: 1.052 | Acc: 62.765% (31252/49792)\n",
      "Train Epoch: 1 | Loss: 1.052 | Acc: 62.752% (31326/49920)\n",
      "Train Epoch: 1 | Loss: 1.053 | Acc: 62.752% (31376/50000)\n",
      "Test Epoch: 1 | Loss: 0.818 | Acc: 72.000% (72/100)\n",
      "Test Epoch: 1 | Loss: 0.848 | Acc: 70.000% (140/200)\n",
      "Test Epoch: 1 | Loss: 0.814 | Acc: 71.000% (213/300)\n",
      "Test Epoch: 1 | Loss: 0.834 | Acc: 69.500% (278/400)\n",
      "Test Epoch: 1 | Loss: 0.850 | Acc: 68.600% (343/500)\n",
      "Test Epoch: 1 | Loss: 0.824 | Acc: 69.000% (414/600)\n",
      "Test Epoch: 1 | Loss: 0.824 | Acc: 68.571% (480/700)\n",
      "Test Epoch: 1 | Loss: 0.852 | Acc: 67.125% (537/800)\n",
      "Test Epoch: 1 | Loss: 0.864 | Acc: 67.222% (605/900)\n",
      "Test Epoch: 1 | Loss: 0.861 | Acc: 67.800% (678/1000)\n",
      "Test Epoch: 1 | Loss: 0.851 | Acc: 68.364% (752/1100)\n",
      "Test Epoch: 1 | Loss: 0.848 | Acc: 68.667% (824/1200)\n",
      "Test Epoch: 1 | Loss: 0.844 | Acc: 68.769% (894/1300)\n",
      "Test Epoch: 1 | Loss: 0.851 | Acc: 68.714% (962/1400)\n",
      "Test Epoch: 1 | Loss: 0.847 | Acc: 68.800% (1032/1500)\n",
      "Test Epoch: 1 | Loss: 0.859 | Acc: 68.375% (1094/1600)\n",
      "Test Epoch: 1 | Loss: 0.852 | Acc: 68.529% (1165/1700)\n",
      "Test Epoch: 1 | Loss: 0.854 | Acc: 68.500% (1233/1800)\n",
      "Test Epoch: 1 | Loss: 0.851 | Acc: 68.632% (1304/1900)\n",
      "Test Epoch: 1 | Loss: 0.862 | Acc: 68.450% (1369/2000)\n",
      "Test Epoch: 1 | Loss: 0.864 | Acc: 68.095% (1430/2100)\n",
      "Test Epoch: 1 | Loss: 0.875 | Acc: 68.000% (1496/2200)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 68.043% (1565/2300)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 67.875% (1629/2400)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 67.840% (1696/2500)\n",
      "Test Epoch: 1 | Loss: 0.887 | Acc: 67.692% (1760/2600)\n",
      "Test Epoch: 1 | Loss: 0.884 | Acc: 67.741% (1829/2700)\n",
      "Test Epoch: 1 | Loss: 0.884 | Acc: 67.786% (1898/2800)\n",
      "Test Epoch: 1 | Loss: 0.892 | Acc: 67.690% (1963/2900)\n",
      "Test Epoch: 1 | Loss: 0.890 | Acc: 67.933% (2038/3000)\n",
      "Test Epoch: 1 | Loss: 0.891 | Acc: 67.935% (2106/3100)\n",
      "Test Epoch: 1 | Loss: 0.887 | Acc: 67.938% (2174/3200)\n",
      "Test Epoch: 1 | Loss: 0.887 | Acc: 67.939% (2242/3300)\n",
      "Test Epoch: 1 | Loss: 0.891 | Acc: 67.853% (2307/3400)\n",
      "Test Epoch: 1 | Loss: 0.893 | Acc: 67.771% (2372/3500)\n",
      "Test Epoch: 1 | Loss: 0.892 | Acc: 67.917% (2445/3600)\n",
      "Test Epoch: 1 | Loss: 0.890 | Acc: 67.919% (2513/3700)\n",
      "Test Epoch: 1 | Loss: 0.891 | Acc: 67.974% (2583/3800)\n",
      "Test Epoch: 1 | Loss: 0.889 | Acc: 68.026% (2653/3900)\n",
      "Test Epoch: 1 | Loss: 0.889 | Acc: 68.100% (2724/4000)\n",
      "Test Epoch: 1 | Loss: 0.888 | Acc: 68.244% (2798/4100)\n",
      "Test Epoch: 1 | Loss: 0.888 | Acc: 68.310% (2869/4200)\n",
      "Test Epoch: 1 | Loss: 0.883 | Acc: 68.581% (2949/4300)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.773% (3026/4400)\n",
      "Test Epoch: 1 | Loss: 0.879 | Acc: 68.822% (3097/4500)\n",
      "Test Epoch: 1 | Loss: 0.878 | Acc: 68.826% (3166/4600)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 68.915% (3239/4700)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 68.979% (3311/4800)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.082% (3385/4900)\n",
      "Test Epoch: 1 | Loss: 0.879 | Acc: 69.040% (3452/5000)\n",
      "Test Epoch: 1 | Loss: 0.878 | Acc: 69.098% (3524/5100)\n",
      "Test Epoch: 1 | Loss: 0.879 | Acc: 69.038% (3590/5200)\n",
      "Test Epoch: 1 | Loss: 0.879 | Acc: 68.962% (3655/5300)\n",
      "Test Epoch: 1 | Loss: 0.882 | Acc: 68.963% (3724/5400)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.964% (3793/5500)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 68.982% (3863/5600)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 69.018% (3934/5700)\n",
      "Test Epoch: 1 | Loss: 0.878 | Acc: 69.086% (4007/5800)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.949% (4068/5900)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.950% (4137/6000)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.967% (4207/6100)\n",
      "Test Epoch: 1 | Loss: 0.881 | Acc: 68.919% (4273/6200)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 68.968% (4345/6300)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 69.047% (4419/6400)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.031% (4487/6500)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 68.970% (4552/6600)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 68.955% (4620/6700)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 68.956% (4689/6800)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 68.913% (4755/6900)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 68.871% (4821/7000)\n",
      "Test Epoch: 1 | Loss: 0.880 | Acc: 68.972% (4897/7100)\n",
      "Test Epoch: 1 | Loss: 0.878 | Acc: 69.042% (4971/7200)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 69.096% (5044/7300)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.162% (5118/7400)\n",
      "Test Epoch: 1 | Loss: 0.878 | Acc: 69.107% (5183/7500)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.158% (5256/7600)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.156% (5325/7700)\n",
      "Test Epoch: 1 | Loss: 0.874 | Acc: 69.154% (5394/7800)\n",
      "Test Epoch: 1 | Loss: 0.875 | Acc: 69.152% (5463/7900)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.200% (5536/8000)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.321% (5615/8100)\n",
      "Test Epoch: 1 | Loss: 0.871 | Acc: 69.378% (5689/8200)\n",
      "Test Epoch: 1 | Loss: 0.871 | Acc: 69.398% (5760/8300)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.310% (5822/8400)\n",
      "Test Epoch: 1 | Loss: 0.874 | Acc: 69.318% (5892/8500)\n",
      "Test Epoch: 1 | Loss: 0.874 | Acc: 69.372% (5966/8600)\n",
      "Test Epoch: 1 | Loss: 0.875 | Acc: 69.287% (6028/8700)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.273% (6096/8800)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.270% (6165/8900)\n",
      "Test Epoch: 1 | Loss: 0.877 | Acc: 69.289% (6236/9000)\n",
      "Test Epoch: 1 | Loss: 0.876 | Acc: 69.308% (6307/9100)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.435% (6388/9200)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.409% (6455/9300)\n",
      "Test Epoch: 1 | Loss: 0.874 | Acc: 69.447% (6528/9400)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.463% (6599/9500)\n",
      "Test Epoch: 1 | Loss: 0.872 | Acc: 69.490% (6671/9600)\n",
      "Test Epoch: 1 | Loss: 0.871 | Acc: 69.567% (6748/9700)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.510% (6812/9800)\n",
      "Test Epoch: 1 | Loss: 0.873 | Acc: 69.465% (6877/9900)\n",
      "Test Epoch: 1 | Loss: 0.874 | Acc: 69.470% (6947/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Train Epoch: 2 | Loss: 0.898 | Acc: 74.219% (95/128)\n",
      "Train Epoch: 2 | Loss: 0.908 | Acc: 70.312% (180/256)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 70.052% (269/384)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 69.531% (356/512)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.219% (443/640)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 69.531% (534/768)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.978% (627/896)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 70.312% (720/1024)\n",
      "Train Epoch: 2 | Loss: 0.898 | Acc: 69.184% (797/1152)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 69.062% (884/1280)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.673% (981/1408)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 69.466% (1067/1536)\n",
      "Train Epoch: 2 | Loss: 0.908 | Acc: 69.171% (1151/1664)\n",
      "Train Epoch: 2 | Loss: 0.921 | Acc: 68.806% (1233/1792)\n",
      "Train Epoch: 2 | Loss: 0.928 | Acc: 68.542% (1316/1920)\n",
      "Train Epoch: 2 | Loss: 0.924 | Acc: 68.701% (1407/2048)\n",
      "Train Epoch: 2 | Loss: 0.925 | Acc: 68.474% (1490/2176)\n",
      "Train Epoch: 2 | Loss: 0.925 | Acc: 68.229% (1572/2304)\n",
      "Train Epoch: 2 | Loss: 0.920 | Acc: 68.298% (1661/2432)\n",
      "Train Epoch: 2 | Loss: 0.919 | Acc: 68.164% (1745/2560)\n",
      "Train Epoch: 2 | Loss: 0.908 | Acc: 68.527% (1842/2688)\n",
      "Train Epoch: 2 | Loss: 0.908 | Acc: 68.537% (1930/2816)\n",
      "Train Epoch: 2 | Loss: 0.900 | Acc: 68.954% (2030/2944)\n",
      "Train Epoch: 2 | Loss: 0.901 | Acc: 68.815% (2114/3072)\n",
      "Train Epoch: 2 | Loss: 0.899 | Acc: 68.781% (2201/3200)\n",
      "Train Epoch: 2 | Loss: 0.901 | Acc: 68.720% (2287/3328)\n",
      "Train Epoch: 2 | Loss: 0.905 | Acc: 68.576% (2370/3456)\n",
      "Train Epoch: 2 | Loss: 0.901 | Acc: 68.834% (2467/3584)\n",
      "Train Epoch: 2 | Loss: 0.899 | Acc: 68.939% (2559/3712)\n",
      "Train Epoch: 2 | Loss: 0.898 | Acc: 68.828% (2643/3840)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.952% (2736/3968)\n",
      "Train Epoch: 2 | Loss: 0.899 | Acc: 68.823% (2819/4096)\n",
      "Train Epoch: 2 | Loss: 0.900 | Acc: 68.797% (2906/4224)\n",
      "Train Epoch: 2 | Loss: 0.902 | Acc: 68.635% (2987/4352)\n",
      "Train Epoch: 2 | Loss: 0.901 | Acc: 68.527% (3070/4480)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.837% (3172/4608)\n",
      "Train Epoch: 2 | Loss: 0.896 | Acc: 68.898% (3263/4736)\n",
      "Train Epoch: 2 | Loss: 0.896 | Acc: 68.771% (3345/4864)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.650% (3427/4992)\n",
      "Train Epoch: 2 | Loss: 0.897 | Acc: 68.633% (3514/5120)\n",
      "Train Epoch: 2 | Loss: 0.894 | Acc: 68.712% (3606/5248)\n",
      "Train Epoch: 2 | Loss: 0.894 | Acc: 68.731% (3695/5376)\n",
      "Train Epoch: 2 | Loss: 0.894 | Acc: 68.623% (3777/5504)\n",
      "Train Epoch: 2 | Loss: 0.896 | Acc: 68.448% (3855/5632)\n",
      "Train Epoch: 2 | Loss: 0.897 | Acc: 68.403% (3940/5760)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.563% (4037/5888)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.517% (4122/6016)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.522% (4210/6144)\n",
      "Train Epoch: 2 | Loss: 0.896 | Acc: 68.543% (4299/6272)\n",
      "Train Epoch: 2 | Loss: 0.895 | Acc: 68.688% (4396/6400)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.781% (4490/6528)\n",
      "Train Epoch: 2 | Loss: 0.894 | Acc: 68.750% (4576/6656)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.927% (4676/6784)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 68.996% (4769/6912)\n",
      "Train Epoch: 2 | Loss: 0.889 | Acc: 68.949% (4854/7040)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.931% (4941/7168)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.956% (5031/7296)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 69.006% (5123/7424)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.094% (5218/7552)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.036% (5302/7680)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.121% (5397/7808)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.128% (5486/7936)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.060% (5569/8064)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.141% (5664/8192)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 69.135% (5752/8320)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.105% (5838/8448)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 69.111% (5927/8576)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 69.129% (6017/8704)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 69.112% (6104/8832)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.085% (6190/8960)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.058% (6276/9088)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.945% (6354/9216)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.889% (6437/9344)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.887% (6525/9472)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.906% (6615/9600)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.873% (6700/9728)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.862% (6787/9856)\n",
      "Train Epoch: 2 | Loss: 0.894 | Acc: 68.820% (6871/9984)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.849% (6962/10112)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.867% (7052/10240)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.866% (7140/10368)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.941% (7236/10496)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.966% (7327/10624)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.927% (7411/10752)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.989% (7506/10880)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.950% (7590/11008)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.939% (7677/11136)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 68.963% (7768/11264)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.952% (7855/11392)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 69.010% (7950/11520)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.990% (8036/11648)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 69.013% (8127/11776)\n",
      "Train Epoch: 2 | Loss: 0.889 | Acc: 69.019% (8216/11904)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 69.008% (8303/12032)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.939% (8383/12160)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.929% (8470/12288)\n",
      "Train Epoch: 2 | Loss: 0.893 | Acc: 68.879% (8552/12416)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.886% (8641/12544)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.892% (8730/12672)\n",
      "Train Epoch: 2 | Loss: 0.892 | Acc: 68.945% (8825/12800)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 69.013% (8922/12928)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.964% (9004/13056)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 69.008% (9098/13184)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.983% (9183/13312)\n",
      "Train Epoch: 2 | Loss: 0.891 | Acc: 68.988% (9272/13440)\n",
      "Train Epoch: 2 | Loss: 0.890 | Acc: 69.052% (9369/13568)\n",
      "Train Epoch: 2 | Loss: 0.889 | Acc: 69.086% (9462/13696)\n",
      "Train Epoch: 2 | Loss: 0.889 | Acc: 69.090% (9551/13824)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 69.108% (9642/13952)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 69.098% (9729/14080)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.179% (9829/14208)\n",
      "Train Epoch: 2 | Loss: 0.888 | Acc: 69.120% (9909/14336)\n",
      "Train Epoch: 2 | Loss: 0.889 | Acc: 69.116% (9997/14464)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.195% (10097/14592)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.192% (10185/14720)\n",
      "Train Epoch: 2 | Loss: 0.887 | Acc: 69.221% (10278/14848)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 69.237% (10369/14976)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.227% (10456/15104)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.236% (10546/15232)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.232% (10634/15360)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.228% (10722/15488)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.198% (10806/15616)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.245% (10902/15744)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.235% (10989/15872)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.231% (11077/16000)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.240% (11167/16128)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.242% (11256/16256)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.269% (11349/16384)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.325% (11447/16512)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.357% (11541/16640)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.364% (11631/16768)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.342% (11716/16896)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.384% (11812/17024)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.397% (11903/17152)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.381% (11989/17280)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.382% (12078/17408)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.349% (12161/17536)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.322% (12245/17664)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.295% (12329/17792)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.235% (12407/17920)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.204% (12490/18048)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.212% (12580/18176)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.182% (12663/18304)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.206% (12756/18432)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.192% (12842/18560)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.199% (12932/18688)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.202% (13021/18816)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.230% (13115/18944)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.217% (13201/19072)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.188% (13284/19200)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.210% (13377/19328)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.192% (13462/19456)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.194% (13551/19584)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.176% (13636/19712)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.173% (13724/19840)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.186% (13815/19968)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.203% (13907/20096)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.210% (13997/20224)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.187% (14081/20352)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.219% (14176/20480)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.196% (14260/20608)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.218% (14353/20736)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.239% (14446/20864)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.245% (14536/20992)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.257% (14627/21120)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.230% (14710/21248)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.237% (14800/21376)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.275% (14897/21504)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.254% (14981/21632)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.269% (15073/21760)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.289% (15166/21888)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.291% (15255/22016)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.287% (15343/22144)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.329% (15441/22272)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.330% (15530/22400)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.327% (15618/22528)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.315% (15704/22656)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.338% (15798/22784)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.326% (15884/22912)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.323% (15972/23040)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.354% (16068/23168)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.312% (16147/23296)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.318% (16237/23424)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.255% (16311/23552)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.236% (16395/23680)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.262% (16490/23808)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.243% (16574/23936)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.245% (16663/24064)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.225% (16747/24192)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.264% (16845/24320)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.253% (16931/24448)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.287% (17028/24576)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.260% (17110/24704)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.257% (17198/24832)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.239% (17282/24960)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.232% (17369/25088)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.246% (17461/25216)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.212% (17541/25344)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.182% (17622/25472)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.211% (17718/25600)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.166% (17795/25728)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.137% (17876/25856)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.131% (17963/25984)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.098% (18043/26112)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.150% (18145/26240)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.171% (18239/26368)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.173% (18328/26496)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.167% (18415/26624)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.142% (18497/26752)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.118% (18579/26880)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.109% (18665/27008)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.119% (18756/27136)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.106% (18841/27264)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.133% (18937/27392)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.095% (19015/27520)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.076% (19098/27648)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.056% (19181/27776)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.044% (19266/27904)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.043% (19354/28032)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.016% (19435/28160)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.994% (19517/28288)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.010% (19610/28416)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 68.985% (19691/28544)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 68.970% (19775/28672)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.983% (19867/28800)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 69.013% (19964/28928)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.998% (20048/29056)\n",
      "Train Epoch: 2 | Loss: 0.886 | Acc: 68.976% (20130/29184)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.989% (20222/29312)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.971% (20305/29440)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.970% (20393/29568)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.982% (20485/29696)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.975% (20571/29824)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.954% (20653/29952)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 68.966% (20745/30080)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 68.972% (20835/30208)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 68.961% (20920/30336)\n",
      "Train Epoch: 2 | Loss: 0.885 | Acc: 68.967% (21010/30464)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.008% (21111/30592)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.007% (21199/30720)\n",
      "Train Epoch: 2 | Loss: 0.884 | Acc: 69.013% (21289/30848)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.021% (21380/30976)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.033% (21472/31104)\n",
      "Train Epoch: 2 | Loss: 0.883 | Acc: 69.032% (21560/31232)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.037% (21650/31360)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.036% (21738/31488)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.050% (21831/31616)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.046% (21918/31744)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.057% (22010/31872)\n",
      "Train Epoch: 2 | Loss: 0.882 | Acc: 69.059% (22099/32000)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.064% (22189/32128)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.091% (22286/32256)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.083% (22372/32384)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.085% (22461/32512)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.096% (22553/32640)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.107% (22645/32768)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.100% (22731/32896)\n",
      "Train Epoch: 2 | Loss: 0.881 | Acc: 69.107% (22822/33024)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.124% (22916/33152)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.165% (23018/33280)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.157% (23104/33408)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.153% (23191/33536)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.133% (23273/33664)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.138% (23363/33792)\n",
      "Train Epoch: 2 | Loss: 0.880 | Acc: 69.145% (23454/33920)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.170% (23551/34048)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.192% (23647/34176)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.214% (23743/34304)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.218% (23833/34432)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.201% (23916/34560)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.197% (24003/34688)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.166% (24081/34816)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.151% (24164/34944)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.146% (24251/35072)\n",
      "Train Epoch: 2 | Loss: 0.879 | Acc: 69.170% (24348/35200)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.183% (24441/35328)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.198% (24535/35456)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.200% (24624/35584)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.209% (24716/35712)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.213% (24806/35840)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.214% (24895/35968)\n",
      "Train Epoch: 2 | Loss: 0.878 | Acc: 69.207% (24981/36096)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.205% (25069/36224)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.215% (25161/36352)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.224% (25253/36480)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.220% (25340/36608)\n",
      "Train Epoch: 2 | Loss: 0.877 | Acc: 69.232% (25433/36736)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.244% (25526/36864)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.264% (25622/36992)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.267% (25712/37120)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.247% (25793/37248)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.240% (25879/37376)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.246% (25970/37504)\n",
      "Train Epoch: 2 | Loss: 0.876 | Acc: 69.260% (26064/37632)\n",
      "Train Epoch: 2 | Loss: 0.875 | Acc: 69.285% (26162/37760)\n",
      "Train Epoch: 2 | Loss: 0.875 | Acc: 69.304% (26258/37888)\n",
      "Train Epoch: 2 | Loss: 0.875 | Acc: 69.297% (26344/38016)\n",
      "Train Epoch: 2 | Loss: 0.874 | Acc: 69.303% (26435/38144)\n",
      "Train Epoch: 2 | Loss: 0.874 | Acc: 69.314% (26528/38272)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.336% (26625/38400)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.360% (26723/38528)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.368% (26815/38656)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.366% (26903/38784)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.367% (26992/38912)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.383% (27087/39040)\n",
      "Train Epoch: 2 | Loss: 0.873 | Acc: 69.401% (27183/39168)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.414% (27277/39296)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.430% (27372/39424)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.440% (27465/39552)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.433% (27551/39680)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.426% (27637/39808)\n",
      "Train Epoch: 2 | Loss: 0.872 | Acc: 69.436% (27730/39936)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.469% (27832/40064)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.442% (27910/40192)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.447% (28001/40320)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.437% (28086/40448)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.438% (28175/40576)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.443% (28266/40704)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.450% (28358/40832)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.475% (28457/40960)\n",
      "Train Epoch: 2 | Loss: 0.871 | Acc: 69.468% (28543/41088)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.473% (28634/41216)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.493% (28731/41344)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.481% (28815/41472)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.488% (28907/41600)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.486% (28995/41728)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.498% (29089/41856)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.505% (29181/41984)\n",
      "Train Epoch: 2 | Loss: 0.870 | Acc: 69.508% (29271/42112)\n",
      "Train Epoch: 2 | Loss: 0.869 | Acc: 69.524% (29367/42240)\n",
      "Train Epoch: 2 | Loss: 0.868 | Acc: 69.548% (29466/42368)\n",
      "Train Epoch: 2 | Loss: 0.868 | Acc: 69.559% (29560/42496)\n",
      "Train Epoch: 2 | Loss: 0.868 | Acc: 69.562% (29650/42624)\n",
      "Train Epoch: 2 | Loss: 0.868 | Acc: 69.569% (29742/42752)\n",
      "Train Epoch: 2 | Loss: 0.867 | Acc: 69.580% (29836/42880)\n",
      "Train Epoch: 2 | Loss: 0.867 | Acc: 69.582% (29926/43008)\n",
      "Train Epoch: 2 | Loss: 0.867 | Acc: 69.605% (30025/43136)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.614% (30118/43264)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.614% (30207/43392)\n",
      "Train Epoch: 2 | Loss: 0.867 | Acc: 69.609% (30294/43520)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.614% (30385/43648)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.625% (30479/43776)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.634% (30572/43904)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.645% (30666/44032)\n",
      "Train Epoch: 2 | Loss: 0.866 | Acc: 69.651% (30758/44160)\n",
      "Train Epoch: 2 | Loss: 0.865 | Acc: 69.674% (30857/44288)\n",
      "Train Epoch: 2 | Loss: 0.865 | Acc: 69.689% (30953/44416)\n",
      "Train Epoch: 2 | Loss: 0.865 | Acc: 69.711% (31052/44544)\n",
      "Train Epoch: 2 | Loss: 0.865 | Acc: 69.695% (31134/44672)\n",
      "Train Epoch: 2 | Loss: 0.864 | Acc: 69.728% (31238/44800)\n",
      "Train Epoch: 2 | Loss: 0.864 | Acc: 69.738% (31332/44928)\n",
      "Train Epoch: 2 | Loss: 0.864 | Acc: 69.747% (31425/45056)\n",
      "Train Epoch: 2 | Loss: 0.864 | Acc: 69.753% (31517/45184)\n",
      "Train Epoch: 2 | Loss: 0.863 | Acc: 69.765% (31612/45312)\n",
      "Train Epoch: 2 | Loss: 0.863 | Acc: 69.769% (31703/45440)\n",
      "Train Epoch: 2 | Loss: 0.862 | Acc: 69.814% (31813/45568)\n",
      "Train Epoch: 2 | Loss: 0.862 | Acc: 69.820% (31905/45696)\n",
      "Train Epoch: 2 | Loss: 0.862 | Acc: 69.832% (32000/45824)\n",
      "Train Epoch: 2 | Loss: 0.862 | Acc: 69.827% (32087/45952)\n",
      "Train Epoch: 2 | Loss: 0.861 | Acc: 69.839% (32182/46080)\n",
      "Train Epoch: 2 | Loss: 0.861 | Acc: 69.839% (32271/46208)\n",
      "Train Epoch: 2 | Loss: 0.861 | Acc: 69.855% (32368/46336)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.863% (32461/46464)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.862% (32550/46592)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.874% (32645/46720)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.864% (32730/46848)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.865% (32820/46976)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.877% (32915/47104)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.889% (33010/47232)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.907% (33108/47360)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.887% (33188/47488)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.890% (33279/47616)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.871% (33359/47744)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.880% (33453/47872)\n",
      "Train Epoch: 2 | Loss: 0.860 | Acc: 69.873% (33539/48000)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.887% (33635/48128)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.896% (33729/48256)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.899% (33820/48384)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.917% (33918/48512)\n",
      "Train Epoch: 2 | Loss: 0.859 | Acc: 69.934% (34016/48640)\n",
      "Train Epoch: 2 | Loss: 0.858 | Acc: 69.958% (34117/48768)\n",
      "Train Epoch: 2 | Loss: 0.857 | Acc: 69.967% (34211/48896)\n",
      "Train Epoch: 2 | Loss: 0.858 | Acc: 69.968% (34301/49024)\n",
      "Train Epoch: 2 | Loss: 0.857 | Acc: 69.993% (34403/49152)\n",
      "Train Epoch: 2 | Loss: 0.857 | Acc: 70.010% (34501/49280)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.019% (34595/49408)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.026% (34688/49536)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.029% (34779/49664)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.013% (34861/49792)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.024% (34956/49920)\n",
      "Train Epoch: 2 | Loss: 0.856 | Acc: 70.040% (35020/50000)\n",
      "Test Epoch: 2 | Loss: 0.646 | Acc: 79.000% (79/100)\n",
      "Test Epoch: 2 | Loss: 0.716 | Acc: 76.000% (152/200)\n",
      "Test Epoch: 2 | Loss: 0.735 | Acc: 74.000% (222/300)\n",
      "Test Epoch: 2 | Loss: 0.722 | Acc: 74.750% (299/400)\n",
      "Test Epoch: 2 | Loss: 0.724 | Acc: 74.800% (374/500)\n",
      "Test Epoch: 2 | Loss: 0.686 | Acc: 75.833% (455/600)\n",
      "Test Epoch: 2 | Loss: 0.693 | Acc: 75.571% (529/700)\n",
      "Test Epoch: 2 | Loss: 0.718 | Acc: 74.750% (598/800)\n",
      "Test Epoch: 2 | Loss: 0.728 | Acc: 74.333% (669/900)\n",
      "Test Epoch: 2 | Loss: 0.737 | Acc: 74.000% (740/1000)\n",
      "Test Epoch: 2 | Loss: 0.737 | Acc: 74.000% (814/1100)\n",
      "Test Epoch: 2 | Loss: 0.742 | Acc: 73.833% (886/1200)\n",
      "Test Epoch: 2 | Loss: 0.734 | Acc: 73.769% (959/1300)\n",
      "Test Epoch: 2 | Loss: 0.732 | Acc: 74.000% (1036/1400)\n",
      "Test Epoch: 2 | Loss: 0.729 | Acc: 74.000% (1110/1500)\n",
      "Test Epoch: 2 | Loss: 0.738 | Acc: 73.812% (1181/1600)\n",
      "Test Epoch: 2 | Loss: 0.734 | Acc: 74.176% (1261/1700)\n",
      "Test Epoch: 2 | Loss: 0.736 | Acc: 74.000% (1332/1800)\n",
      "Test Epoch: 2 | Loss: 0.737 | Acc: 74.053% (1407/1900)\n",
      "Test Epoch: 2 | Loss: 0.752 | Acc: 73.750% (1475/2000)\n",
      "Test Epoch: 2 | Loss: 0.756 | Acc: 73.524% (1544/2100)\n",
      "Test Epoch: 2 | Loss: 0.762 | Acc: 73.545% (1618/2200)\n",
      "Test Epoch: 2 | Loss: 0.760 | Acc: 73.652% (1694/2300)\n",
      "Test Epoch: 2 | Loss: 0.759 | Acc: 73.625% (1767/2400)\n",
      "Test Epoch: 2 | Loss: 0.762 | Acc: 73.400% (1835/2500)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 72.846% (1894/2600)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 72.741% (1964/2700)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 72.714% (2036/2800)\n",
      "Test Epoch: 2 | Loss: 0.785 | Acc: 72.724% (2109/2900)\n",
      "Test Epoch: 2 | Loss: 0.783 | Acc: 72.933% (2188/3000)\n",
      "Test Epoch: 2 | Loss: 0.783 | Acc: 72.935% (2261/3100)\n",
      "Test Epoch: 2 | Loss: 0.781 | Acc: 72.875% (2332/3200)\n",
      "Test Epoch: 2 | Loss: 0.784 | Acc: 72.818% (2403/3300)\n",
      "Test Epoch: 2 | Loss: 0.789 | Acc: 72.559% (2467/3400)\n",
      "Test Epoch: 2 | Loss: 0.795 | Acc: 72.371% (2533/3500)\n",
      "Test Epoch: 2 | Loss: 0.792 | Acc: 72.444% (2608/3600)\n",
      "Test Epoch: 2 | Loss: 0.795 | Acc: 72.378% (2678/3700)\n",
      "Test Epoch: 2 | Loss: 0.795 | Acc: 72.368% (2750/3800)\n",
      "Test Epoch: 2 | Loss: 0.790 | Acc: 72.615% (2832/3900)\n",
      "Test Epoch: 2 | Loss: 0.786 | Acc: 72.650% (2906/4000)\n",
      "Test Epoch: 2 | Loss: 0.785 | Acc: 72.707% (2981/4100)\n",
      "Test Epoch: 2 | Loss: 0.784 | Acc: 72.810% (3058/4200)\n",
      "Test Epoch: 2 | Loss: 0.781 | Acc: 72.930% (3136/4300)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 73.023% (3213/4400)\n",
      "Test Epoch: 2 | Loss: 0.778 | Acc: 72.933% (3282/4500)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 72.870% (3352/4600)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.936% (3428/4700)\n",
      "Test Epoch: 2 | Loss: 0.781 | Acc: 72.833% (3496/4800)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 72.898% (3572/4900)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.820% (3641/5000)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.000% (3723/5100)\n",
      "Test Epoch: 2 | Loss: 0.778 | Acc: 73.058% (3799/5200)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.075% (3873/5300)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.037% (3944/5400)\n",
      "Test Epoch: 2 | Loss: 0.778 | Acc: 73.018% (4016/5500)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.946% (4085/5600)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.877% (4154/5700)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 72.948% (4231/5800)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 72.797% (4295/5900)\n",
      "Test Epoch: 2 | Loss: 0.783 | Acc: 72.650% (4359/6000)\n",
      "Test Epoch: 2 | Loss: 0.782 | Acc: 72.705% (4435/6100)\n",
      "Test Epoch: 2 | Loss: 0.782 | Acc: 72.645% (4504/6200)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.810% (4587/6300)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 72.859% (4663/6400)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.785% (4731/6500)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.758% (4802/6600)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 72.776% (4876/6700)\n",
      "Test Epoch: 2 | Loss: 0.778 | Acc: 72.765% (4948/6800)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 72.841% (5026/6900)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 72.757% (5093/7000)\n",
      "Test Epoch: 2 | Loss: 0.778 | Acc: 72.817% (5170/7100)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 72.833% (5244/7200)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 72.973% (5327/7300)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 73.027% (5404/7400)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.027% (5477/7500)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 73.066% (5553/7600)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.091% (5628/7700)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 73.128% (5704/7800)\n",
      "Test Epoch: 2 | Loss: 0.774 | Acc: 73.177% (5781/7900)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.075% (5846/8000)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.099% (5921/8100)\n",
      "Test Epoch: 2 | Loss: 0.774 | Acc: 73.134% (5997/8200)\n",
      "Test Epoch: 2 | Loss: 0.774 | Acc: 73.108% (6068/8300)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.083% (6139/8400)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.071% (6211/8500)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.116% (6288/8600)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.092% (6359/8700)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 73.091% (6432/8800)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 73.112% (6507/8900)\n",
      "Test Epoch: 2 | Loss: 0.782 | Acc: 73.089% (6578/9000)\n",
      "Test Epoch: 2 | Loss: 0.783 | Acc: 73.088% (6651/9100)\n",
      "Test Epoch: 2 | Loss: 0.781 | Acc: 73.130% (6728/9200)\n",
      "Test Epoch: 2 | Loss: 0.781 | Acc: 73.140% (6802/9300)\n",
      "Test Epoch: 2 | Loss: 0.780 | Acc: 73.138% (6875/9400)\n",
      "Test Epoch: 2 | Loss: 0.779 | Acc: 73.126% (6947/9500)\n",
      "Test Epoch: 2 | Loss: 0.777 | Acc: 73.167% (7024/9600)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 73.206% (7101/9700)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.184% (7172/9800)\n",
      "Test Epoch: 2 | Loss: 0.776 | Acc: 73.152% (7242/9900)\n",
      "Test Epoch: 2 | Loss: 0.775 | Acc: 73.220% (7322/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Train Epoch: 3 | Loss: 0.682 | Acc: 78.906% (101/128)\n",
      "Train Epoch: 3 | Loss: 0.694 | Acc: 77.344% (198/256)\n",
      "Train Epoch: 3 | Loss: 0.767 | Acc: 73.698% (283/384)\n",
      "Train Epoch: 3 | Loss: 0.788 | Acc: 72.656% (372/512)\n",
      "Train Epoch: 3 | Loss: 0.796 | Acc: 72.031% (461/640)\n",
      "Train Epoch: 3 | Loss: 0.812 | Acc: 72.005% (553/768)\n",
      "Train Epoch: 3 | Loss: 0.811 | Acc: 72.210% (647/896)\n",
      "Train Epoch: 3 | Loss: 0.792 | Acc: 72.461% (742/1024)\n",
      "Train Epoch: 3 | Loss: 0.781 | Acc: 73.003% (841/1152)\n",
      "Train Epoch: 3 | Loss: 0.787 | Acc: 73.047% (935/1280)\n",
      "Train Epoch: 3 | Loss: 0.775 | Acc: 73.793% (1039/1408)\n",
      "Train Epoch: 3 | Loss: 0.777 | Acc: 73.828% (1134/1536)\n",
      "Train Epoch: 3 | Loss: 0.772 | Acc: 74.219% (1235/1664)\n",
      "Train Epoch: 3 | Loss: 0.780 | Acc: 73.884% (1324/1792)\n",
      "Train Epoch: 3 | Loss: 0.791 | Acc: 73.490% (1411/1920)\n",
      "Train Epoch: 3 | Loss: 0.785 | Acc: 73.682% (1509/2048)\n",
      "Train Epoch: 3 | Loss: 0.785 | Acc: 73.897% (1608/2176)\n",
      "Train Epoch: 3 | Loss: 0.787 | Acc: 73.828% (1701/2304)\n",
      "Train Epoch: 3 | Loss: 0.785 | Acc: 73.849% (1796/2432)\n",
      "Train Epoch: 3 | Loss: 0.777 | Acc: 73.984% (1894/2560)\n",
      "Train Epoch: 3 | Loss: 0.781 | Acc: 73.735% (1982/2688)\n",
      "Train Epoch: 3 | Loss: 0.788 | Acc: 73.615% (2073/2816)\n",
      "Train Epoch: 3 | Loss: 0.779 | Acc: 73.811% (2173/2944)\n",
      "Train Epoch: 3 | Loss: 0.776 | Acc: 73.893% (2270/3072)\n",
      "Train Epoch: 3 | Loss: 0.771 | Acc: 73.969% (2367/3200)\n",
      "Train Epoch: 3 | Loss: 0.772 | Acc: 73.918% (2460/3328)\n",
      "Train Epoch: 3 | Loss: 0.772 | Acc: 73.987% (2557/3456)\n",
      "Train Epoch: 3 | Loss: 0.772 | Acc: 73.996% (2652/3584)\n",
      "Train Epoch: 3 | Loss: 0.770 | Acc: 74.030% (2748/3712)\n",
      "Train Epoch: 3 | Loss: 0.770 | Acc: 74.141% (2847/3840)\n",
      "Train Epoch: 3 | Loss: 0.768 | Acc: 74.143% (2942/3968)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.341% (3045/4096)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.479% (3146/4224)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.426% (3239/4352)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.442% (3335/4480)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.371% (3427/4608)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.345% (3521/4736)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.424% (3620/4864)\n",
      "Train Epoch: 3 | Loss: 0.753 | Acc: 74.559% (3722/4992)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.629% (3821/5120)\n",
      "Train Epoch: 3 | Loss: 0.749 | Acc: 74.867% (3929/5248)\n",
      "Train Epoch: 3 | Loss: 0.747 | Acc: 74.963% (4030/5376)\n",
      "Train Epoch: 3 | Loss: 0.748 | Acc: 74.927% (4124/5504)\n",
      "Train Epoch: 3 | Loss: 0.748 | Acc: 74.893% (4218/5632)\n",
      "Train Epoch: 3 | Loss: 0.750 | Acc: 74.774% (4307/5760)\n",
      "Train Epoch: 3 | Loss: 0.747 | Acc: 74.796% (4404/5888)\n",
      "Train Epoch: 3 | Loss: 0.747 | Acc: 74.734% (4496/6016)\n",
      "Train Epoch: 3 | Loss: 0.746 | Acc: 74.788% (4595/6144)\n",
      "Train Epoch: 3 | Loss: 0.746 | Acc: 74.857% (4695/6272)\n",
      "Train Epoch: 3 | Loss: 0.747 | Acc: 74.844% (4790/6400)\n",
      "Train Epoch: 3 | Loss: 0.748 | Acc: 74.770% (4881/6528)\n",
      "Train Epoch: 3 | Loss: 0.750 | Acc: 74.715% (4973/6656)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.617% (5062/6784)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.696% (5163/6912)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.616% (5253/7040)\n",
      "Train Epoch: 3 | Loss: 0.753 | Acc: 74.595% (5347/7168)\n",
      "Train Epoch: 3 | Loss: 0.753 | Acc: 74.616% (5444/7296)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.529% (5533/7424)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.404% (5619/7552)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.362% (5711/7680)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.296% (5801/7808)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.269% (5894/7936)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.219% (5985/8064)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.207% (6079/8192)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.147% (6169/8320)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.242% (6272/8448)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.195% (6363/8576)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.207% (6459/8704)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.355% (6567/8832)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.375% (6664/8960)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.296% (6752/9088)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.371% (6854/9216)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.283% (6941/9344)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.240% (7032/9472)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.250% (7128/9600)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.322% (7230/9728)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.371% (7330/9856)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.319% (7420/9984)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.288% (7512/10112)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.268% (7605/10240)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.228% (7696/10368)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.238% (7792/10496)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.247% (7888/10624)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.293% (7988/10752)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.320% (8086/10880)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.228% (8171/11008)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.183% (8261/11136)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.263% (8365/11264)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.271% (8461/11392)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.340% (8564/11520)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.313% (8656/11648)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.295% (8749/11776)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.269% (8841/11904)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.269% (8936/12032)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.235% (9027/12160)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.251% (9124/12288)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.259% (9220/12416)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.267% (9316/12544)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.203% (9403/12672)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.203% (9498/12800)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.172% (9589/12928)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.180% (9685/13056)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.143% (9775/13184)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.204% (9878/13312)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.211% (9974/13440)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.233% (10072/13568)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.241% (10168/13696)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.248% (10264/13824)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.276% (10363/13952)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.304% (10462/14080)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.345% (10563/14208)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.302% (10652/14336)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.274% (10743/14464)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.253% (10835/14592)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.226% (10926/14720)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.178% (11014/14848)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.219% (11115/14976)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.245% (11214/15104)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.232% (11307/15232)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.212% (11399/15360)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.199% (11492/15488)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.168% (11582/15616)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.149% (11674/15744)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.124% (11765/15872)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.138% (11862/16000)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.213% (11969/16128)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.194% (12061/16256)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.164% (12151/16384)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.158% (12245/16512)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.159% (12340/16640)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.129% (12430/16768)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 74.130% (12525/16896)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.048% (12606/17024)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 74.026% (12697/17152)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.034% (12793/17280)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.029% (12887/17408)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 74.013% (12979/17536)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 73.975% (13067/17664)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 73.994% (13165/17792)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 74.012% (13263/17920)\n",
      "Train Epoch: 3 | Loss: 0.766 | Acc: 74.025% (13360/18048)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.065% (13462/18176)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 74.017% (13548/18304)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.964% (13633/18432)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.966% (13728/18560)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.978% (13825/18688)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.990% (13922/18816)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.965% (14012/18944)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.967% (14107/19072)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.969% (14202/19200)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.945% (14292/19328)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.962% (14390/19456)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.989% (14490/19584)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.006% (14588/19712)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.997% (14681/19840)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.978% (14772/19968)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.995% (14870/20096)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.957% (14957/20224)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.949% (15050/20352)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.926% (15140/20480)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.966% (15243/20608)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.963% (15337/20736)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.936% (15426/20864)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.914% (15516/20992)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.887% (15605/21120)\n",
      "Train Epoch: 3 | Loss: 0.765 | Acc: 73.927% (15708/21248)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.961% (15810/21376)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.033% (15920/21504)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.034% (16015/21632)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.026% (16108/21760)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.977% (16192/21888)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.973% (16286/22016)\n",
      "Train Epoch: 3 | Loss: 0.764 | Acc: 73.970% (16380/22144)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.985% (16478/22272)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.987% (16573/22400)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.983% (16667/22528)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.967% (16758/22656)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 73.977% (16855/22784)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.014% (16958/22912)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.019% (17054/23040)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.025% (17150/23168)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.017% (17243/23296)\n",
      "Train Epoch: 3 | Loss: 0.763 | Acc: 74.005% (17335/23424)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.006% (17430/23552)\n",
      "Train Epoch: 3 | Loss: 0.762 | Acc: 74.041% (17533/23680)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 74.084% (17638/23808)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.102% (17737/23936)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 74.123% (17837/24064)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.136% (17935/24192)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.149% (18033/24320)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.174% (18134/24448)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.215% (18239/24576)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.207% (18332/24704)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.203% (18426/24832)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.219% (18525/24960)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.227% (18622/25088)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.187% (18707/25216)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.195% (18804/25344)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.191% (18898/25472)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.180% (18990/25600)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.192% (19088/25728)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.172% (19178/25856)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.161% (19270/25984)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.180% (19370/26112)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.162% (19460/26240)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.173% (19558/26368)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.177% (19654/26496)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.189% (19752/26624)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.151% (19837/26752)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.141% (19929/26880)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.137% (20023/27008)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.156% (20123/27136)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.189% (20227/27264)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.190% (20322/27392)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.168% (20411/27520)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.154% (20502/27648)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.176% (20603/27776)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.169% (20696/27904)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.194% (20798/28032)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.190% (20892/28160)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.187% (20986/28288)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.166% (21075/28416)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.163% (21169/28544)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.159% (21263/28672)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.163% (21359/28800)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.150% (21450/28928)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.129% (21539/29056)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.140% (21637/29184)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.144% (21733/29312)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.134% (21825/29440)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.141% (21922/29568)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.131% (22014/29696)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.125% (22107/29824)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.122% (22201/29952)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.096% (22288/30080)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.093% (22382/30208)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.090% (22476/30336)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.107% (22576/30464)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.095% (22667/30592)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.079% (22757/30720)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.109% (22861/30848)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.103% (22954/30976)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.081% (23042/31104)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.087% (23139/31232)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.110% (23241/31360)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.130% (23342/31488)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.130% (23437/31616)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.131% (23532/31744)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.143% (23631/31872)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.109% (23715/32000)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.119% (23813/32128)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.116% (23907/32256)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.126% (24005/32384)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.130% (24101/32512)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.139% (24199/32640)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.118% (24287/32768)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.109% (24379/32896)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.110% (24474/33024)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.134% (24577/33152)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.141% (24674/33280)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.144% (24770/33408)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.135% (24862/33536)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.153% (24963/33664)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.145% (25055/33792)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.116% (25140/33920)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.110% (25233/34048)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.116% (25330/34176)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.102% (25420/34304)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.105% (25516/34432)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.083% (25603/34560)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.092% (25701/34688)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.104% (25800/34816)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.101% (25894/34944)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.108% (25991/35072)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.085% (26078/35200)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.072% (26168/35328)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.089% (26269/35456)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.075% (26359/35584)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.059% (26448/35712)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 74.051% (26540/35840)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.032% (26628/35968)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.036% (26724/36096)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.012% (26810/36224)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.023% (26909/36352)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.010% (26999/36480)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.008% (27093/36608)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.001% (27185/36736)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 74.007% (27282/36864)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.973% (27364/36992)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.960% (27454/37120)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.972% (27553/37248)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.967% (27646/37376)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.957% (27737/37504)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.937% (27824/37632)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.930% (27916/37760)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.910% (28003/37888)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.932% (28106/38016)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.923% (28197/38144)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.929% (28294/38272)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.935% (28391/38400)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.925% (28482/38528)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.916% (28573/38656)\n",
      "Train Epoch: 3 | Loss: 0.761 | Acc: 73.927% (28672/38784)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.964% (28781/38912)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.952% (28871/39040)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.961% (28969/39168)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.959% (29063/39296)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.952% (29155/39424)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.946% (29247/39552)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.926% (29334/39680)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.950% (29438/39808)\n",
      "Train Epoch: 3 | Loss: 0.760 | Acc: 73.963% (29538/39936)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.977% (29638/40064)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.970% (29730/40192)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.981% (29829/40320)\n",
      "Train Epoch: 3 | Loss: 0.759 | Acc: 73.989% (29927/40448)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.999% (30026/40576)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.998% (30120/40704)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.991% (30212/40832)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.999% (30310/40960)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.995% (30403/41088)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.998% (30499/41216)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.991% (30591/41344)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.992% (30686/41472)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.995% (30782/41600)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.986% (30873/41728)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.987% (30968/41856)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.978% (31059/41984)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 73.984% (31156/42112)\n",
      "Train Epoch: 3 | Loss: 0.758 | Acc: 73.965% (31243/42240)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 73.983% (31345/42368)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 73.990% (31443/42496)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.005% (31544/42624)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.013% (31642/42752)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.025% (31742/42880)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.009% (31830/43008)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.012% (31926/43136)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.004% (32017/43264)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.016% (32117/43392)\n",
      "Train Epoch: 3 | Loss: 0.757 | Acc: 74.028% (32217/43520)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.038% (32316/43648)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.041% (32412/43776)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.039% (32506/43904)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.035% (32599/44032)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.044% (32698/44160)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.072% (32805/44288)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.068% (32898/44416)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.073% (32995/44544)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.087% (33096/44672)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.103% (33198/44800)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.096% (33290/44928)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.097% (33385/45056)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.082% (33473/45184)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.091% (33572/45312)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.098% (33670/45440)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.078% (33756/45568)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.083% (33853/45696)\n",
      "Train Epoch: 3 | Loss: 0.756 | Acc: 74.077% (33945/45824)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.082% (34042/45952)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.071% (34132/46080)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.069% (34226/46208)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.068% (34320/46336)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.059% (34411/46464)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.069% (34510/46592)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.073% (34607/46720)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.071% (34701/46848)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.065% (34793/46976)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.081% (34895/47104)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.083% (34991/47232)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.096% (35092/47360)\n",
      "Train Epoch: 3 | Loss: 0.755 | Acc: 74.092% (35185/47488)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.095% (35281/47616)\n",
      "Train Epoch: 3 | Loss: 0.754 | Acc: 74.108% (35382/47744)\n",
      "Train Epoch: 3 | Loss: 0.753 | Acc: 74.129% (35487/47872)\n",
      "Train Epoch: 3 | Loss: 0.753 | Acc: 74.154% (35594/48000)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.175% (35699/48128)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.179% (35796/48256)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.190% (35896/48384)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.204% (35998/48512)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.221% (36101/48640)\n",
      "Train Epoch: 3 | Loss: 0.752 | Acc: 74.215% (36193/48768)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.239% (36300/48896)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.253% (36402/49024)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.266% (36503/49152)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.274% (36602/49280)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.271% (36696/49408)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.267% (36789/49536)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.273% (36887/49664)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.271% (36981/49792)\n",
      "Train Epoch: 3 | Loss: 0.751 | Acc: 74.281% (37081/49920)\n",
      "Train Epoch: 3 | Loss: 0.750 | Acc: 74.286% (37143/50000)\n",
      "Test Epoch: 3 | Loss: 0.994 | Acc: 68.000% (68/100)\n",
      "Test Epoch: 3 | Loss: 0.924 | Acc: 67.500% (135/200)\n",
      "Test Epoch: 3 | Loss: 0.925 | Acc: 68.667% (206/300)\n",
      "Test Epoch: 3 | Loss: 0.897 | Acc: 69.000% (276/400)\n",
      "Test Epoch: 3 | Loss: 0.918 | Acc: 67.400% (337/500)\n",
      "Test Epoch: 3 | Loss: 0.889 | Acc: 67.833% (407/600)\n",
      "Test Epoch: 3 | Loss: 0.893 | Acc: 67.857% (475/700)\n",
      "Test Epoch: 3 | Loss: 0.941 | Acc: 66.500% (532/800)\n",
      "Test Epoch: 3 | Loss: 0.959 | Acc: 66.222% (596/900)\n",
      "Test Epoch: 3 | Loss: 0.955 | Acc: 66.500% (665/1000)\n",
      "Test Epoch: 3 | Loss: 0.958 | Acc: 67.091% (738/1100)\n",
      "Test Epoch: 3 | Loss: 0.964 | Acc: 67.083% (805/1200)\n",
      "Test Epoch: 3 | Loss: 0.958 | Acc: 67.538% (878/1300)\n",
      "Test Epoch: 3 | Loss: 0.953 | Acc: 67.286% (942/1400)\n",
      "Test Epoch: 3 | Loss: 0.971 | Acc: 66.800% (1002/1500)\n",
      "Test Epoch: 3 | Loss: 0.983 | Acc: 66.250% (1060/1600)\n",
      "Test Epoch: 3 | Loss: 0.974 | Acc: 66.765% (1135/1700)\n",
      "Test Epoch: 3 | Loss: 0.981 | Acc: 66.389% (1195/1800)\n",
      "Test Epoch: 3 | Loss: 0.978 | Acc: 66.842% (1270/1900)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 66.750% (1335/2000)\n",
      "Test Epoch: 3 | Loss: 0.998 | Acc: 66.190% (1390/2100)\n",
      "Test Epoch: 3 | Loss: 1.002 | Acc: 66.273% (1458/2200)\n",
      "Test Epoch: 3 | Loss: 0.999 | Acc: 66.261% (1524/2300)\n",
      "Test Epoch: 3 | Loss: 0.998 | Acc: 66.292% (1591/2400)\n",
      "Test Epoch: 3 | Loss: 0.998 | Acc: 66.200% (1655/2500)\n",
      "Test Epoch: 3 | Loss: 1.011 | Acc: 66.000% (1716/2600)\n",
      "Test Epoch: 3 | Loss: 1.010 | Acc: 65.889% (1779/2700)\n",
      "Test Epoch: 3 | Loss: 1.009 | Acc: 65.857% (1844/2800)\n",
      "Test Epoch: 3 | Loss: 1.013 | Acc: 65.828% (1909/2900)\n",
      "Test Epoch: 3 | Loss: 1.004 | Acc: 65.867% (1976/3000)\n",
      "Test Epoch: 3 | Loss: 1.004 | Acc: 65.935% (2044/3100)\n",
      "Test Epoch: 3 | Loss: 0.994 | Acc: 66.125% (2116/3200)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 66.121% (2182/3300)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 66.059% (2246/3400)\n",
      "Test Epoch: 3 | Loss: 1.004 | Acc: 65.886% (2306/3500)\n",
      "Test Epoch: 3 | Loss: 1.003 | Acc: 65.861% (2371/3600)\n",
      "Test Epoch: 3 | Loss: 1.003 | Acc: 65.784% (2434/3700)\n",
      "Test Epoch: 3 | Loss: 1.001 | Acc: 65.763% (2499/3800)\n",
      "Test Epoch: 3 | Loss: 0.998 | Acc: 65.795% (2566/3900)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 65.850% (2634/4000)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 65.854% (2700/4100)\n",
      "Test Epoch: 3 | Loss: 0.995 | Acc: 65.881% (2767/4200)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 66.023% (2839/4300)\n",
      "Test Epoch: 3 | Loss: 0.988 | Acc: 66.114% (2909/4400)\n",
      "Test Epoch: 3 | Loss: 0.985 | Acc: 66.267% (2982/4500)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 66.174% (3044/4600)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 66.043% (3104/4700)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 66.083% (3172/4800)\n",
      "Test Epoch: 3 | Loss: 0.988 | Acc: 66.204% (3244/4900)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 66.120% (3306/5000)\n",
      "Test Epoch: 3 | Loss: 0.991 | Acc: 66.078% (3370/5100)\n",
      "Test Epoch: 3 | Loss: 0.991 | Acc: 66.038% (3434/5200)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 66.000% (3498/5300)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.981% (3563/5400)\n",
      "Test Epoch: 3 | Loss: 0.991 | Acc: 65.982% (3629/5500)\n",
      "Test Epoch: 3 | Loss: 0.994 | Acc: 65.839% (3687/5600)\n",
      "Test Epoch: 3 | Loss: 0.995 | Acc: 65.719% (3746/5700)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 65.810% (3817/5800)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.746% (3879/5900)\n",
      "Test Epoch: 3 | Loss: 0.998 | Acc: 65.617% (3937/6000)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 65.672% (4006/6100)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 65.613% (4068/6200)\n",
      "Test Epoch: 3 | Loss: 0.996 | Acc: 65.698% (4139/6300)\n",
      "Test Epoch: 3 | Loss: 0.995 | Acc: 65.766% (4209/6400)\n",
      "Test Epoch: 3 | Loss: 0.996 | Acc: 65.754% (4274/6500)\n",
      "Test Epoch: 3 | Loss: 0.996 | Acc: 65.682% (4335/6600)\n",
      "Test Epoch: 3 | Loss: 0.995 | Acc: 65.701% (4402/6700)\n",
      "Test Epoch: 3 | Loss: 0.994 | Acc: 65.750% (4471/6800)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.812% (4541/6900)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 65.800% (4606/7000)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 65.845% (4675/7100)\n",
      "Test Epoch: 3 | Loss: 0.994 | Acc: 65.736% (4733/7200)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 65.740% (4799/7300)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 65.784% (4868/7400)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.720% (4929/7500)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 65.829% (5003/7600)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 65.870% (5072/7700)\n",
      "Test Epoch: 3 | Loss: 0.991 | Acc: 65.808% (5133/7800)\n",
      "Test Epoch: 3 | Loss: 0.987 | Acc: 65.886% (5205/7900)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 65.912% (5273/8000)\n",
      "Test Epoch: 3 | Loss: 0.988 | Acc: 65.864% (5335/8100)\n",
      "Test Epoch: 3 | Loss: 0.987 | Acc: 65.854% (5400/8200)\n",
      "Test Epoch: 3 | Loss: 0.985 | Acc: 65.916% (5471/8300)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 65.845% (5531/8400)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 65.847% (5597/8500)\n",
      "Test Epoch: 3 | Loss: 0.991 | Acc: 65.849% (5663/8600)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 65.793% (5724/8700)\n",
      "Test Epoch: 3 | Loss: 0.995 | Acc: 65.761% (5787/8800)\n",
      "Test Epoch: 3 | Loss: 0.996 | Acc: 65.809% (5857/8900)\n",
      "Test Epoch: 3 | Loss: 0.997 | Acc: 65.822% (5924/9000)\n",
      "Test Epoch: 3 | Loss: 0.996 | Acc: 65.857% (5993/9100)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.935% (6066/9200)\n",
      "Test Epoch: 3 | Loss: 0.993 | Acc: 65.978% (6136/9300)\n",
      "Test Epoch: 3 | Loss: 0.992 | Acc: 66.011% (6205/9400)\n",
      "Test Epoch: 3 | Loss: 0.990 | Acc: 66.095% (6279/9500)\n",
      "Test Epoch: 3 | Loss: 0.989 | Acc: 66.104% (6346/9600)\n",
      "Test Epoch: 3 | Loss: 0.986 | Acc: 66.186% (6420/9700)\n",
      "Test Epoch: 3 | Loss: 0.986 | Acc: 66.194% (6487/9800)\n",
      "Test Epoch: 3 | Loss: 0.988 | Acc: 66.071% (6541/9900)\n",
      "Test Epoch: 3 | Loss: 0.987 | Acc: 66.080% (6608/10000)\n",
      "\n",
      "Epoch: 4\n",
      "Train Epoch: 4 | Loss: 0.648 | Acc: 77.344% (99/128)\n",
      "Train Epoch: 4 | Loss: 0.715 | Acc: 75.781% (194/256)\n",
      "Train Epoch: 4 | Loss: 0.712 | Acc: 76.823% (295/384)\n",
      "Train Epoch: 4 | Loss: 0.728 | Acc: 75.781% (388/512)\n",
      "Train Epoch: 4 | Loss: 0.717 | Acc: 75.625% (484/640)\n",
      "Train Epoch: 4 | Loss: 0.730 | Acc: 74.479% (572/768)\n",
      "Train Epoch: 4 | Loss: 0.742 | Acc: 74.107% (664/896)\n",
      "Train Epoch: 4 | Loss: 0.764 | Acc: 73.340% (751/1024)\n",
      "Train Epoch: 4 | Loss: 0.751 | Acc: 74.045% (853/1152)\n",
      "Train Epoch: 4 | Loss: 0.739 | Acc: 74.453% (953/1280)\n",
      "Train Epoch: 4 | Loss: 0.736 | Acc: 74.503% (1049/1408)\n",
      "Train Epoch: 4 | Loss: 0.734 | Acc: 74.674% (1147/1536)\n",
      "Train Epoch: 4 | Loss: 0.735 | Acc: 74.459% (1239/1664)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.833% (1341/1792)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.792% (1436/1920)\n",
      "Train Epoch: 4 | Loss: 0.719 | Acc: 75.000% (1536/2048)\n",
      "Train Epoch: 4 | Loss: 0.716 | Acc: 74.954% (1631/2176)\n",
      "Train Epoch: 4 | Loss: 0.719 | Acc: 74.783% (1723/2304)\n",
      "Train Epoch: 4 | Loss: 0.714 | Acc: 74.959% (1823/2432)\n",
      "Train Epoch: 4 | Loss: 0.712 | Acc: 74.961% (1919/2560)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 74.926% (2014/2688)\n",
      "Train Epoch: 4 | Loss: 0.712 | Acc: 74.964% (2111/2816)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.034% (2209/2944)\n",
      "Train Epoch: 4 | Loss: 0.713 | Acc: 75.065% (2306/3072)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.281% (2409/3200)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.270% (2505/3328)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.318% (2603/3456)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.251% (2697/3584)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.350% (2797/3712)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.339% (2893/3840)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.252% (2986/3968)\n",
      "Train Epoch: 4 | Loss: 0.715 | Acc: 75.024% (3073/4096)\n",
      "Train Epoch: 4 | Loss: 0.716 | Acc: 74.905% (3164/4224)\n",
      "Train Epoch: 4 | Loss: 0.718 | Acc: 74.747% (3253/4352)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.397% (3333/4480)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.457% (3431/4608)\n",
      "Train Epoch: 4 | Loss: 0.727 | Acc: 74.409% (3524/4736)\n",
      "Train Epoch: 4 | Loss: 0.725 | Acc: 74.527% (3625/4864)\n",
      "Train Epoch: 4 | Loss: 0.726 | Acc: 74.419% (3715/4992)\n",
      "Train Epoch: 4 | Loss: 0.727 | Acc: 74.395% (3809/5120)\n",
      "Train Epoch: 4 | Loss: 0.727 | Acc: 74.409% (3905/5248)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.572% (4009/5376)\n",
      "Train Epoch: 4 | Loss: 0.725 | Acc: 74.546% (4103/5504)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.627% (4203/5632)\n",
      "Train Epoch: 4 | Loss: 0.727 | Acc: 74.514% (4292/5760)\n",
      "Train Epoch: 4 | Loss: 0.727 | Acc: 74.541% (4389/5888)\n",
      "Train Epoch: 4 | Loss: 0.725 | Acc: 74.568% (4486/6016)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.577% (4582/6144)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.570% (4677/6272)\n",
      "Train Epoch: 4 | Loss: 0.725 | Acc: 74.438% (4764/6400)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.479% (4862/6528)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.579% (4964/6656)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.631% (5063/6784)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.667% (5161/6912)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.616% (5253/7040)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.679% (5353/7168)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.616% (5444/7296)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.677% (5544/7424)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.629% (5636/7552)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.740% (5740/7680)\n",
      "Train Epoch: 4 | Loss: 0.719 | Acc: 74.859% (5845/7808)\n",
      "Train Epoch: 4 | Loss: 0.719 | Acc: 74.824% (5938/7936)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.727% (6026/8064)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.695% (6119/8192)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.712% (6216/8320)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.645% (6306/8448)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.697% (6406/8576)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.759% (6507/8704)\n",
      "Train Epoch: 4 | Loss: 0.720 | Acc: 74.841% (6610/8832)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.788% (6701/8960)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.758% (6794/9088)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.729% (6887/9216)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.754% (6985/9344)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.757% (7081/9472)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.729% (7174/9600)\n",
      "Train Epoch: 4 | Loss: 0.725 | Acc: 74.620% (7259/9728)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.665% (7359/9856)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.780% (7466/9984)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.753% (7559/10112)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.707% (7650/10240)\n",
      "Train Epoch: 4 | Loss: 0.724 | Acc: 74.653% (7740/10368)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.705% (7841/10496)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.718% (7938/10624)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.749% (8037/10752)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.724% (8130/10880)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.682% (8221/11008)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.686% (8317/11136)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.672% (8411/11264)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.710% (8511/11392)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.783% (8615/11520)\n",
      "Train Epoch: 4 | Loss: 0.722 | Acc: 74.768% (8709/11648)\n",
      "Train Epoch: 4 | Loss: 0.723 | Acc: 74.745% (8802/11776)\n",
      "Train Epoch: 4 | Loss: 0.721 | Acc: 74.807% (8905/11904)\n",
      "Train Epoch: 4 | Loss: 0.718 | Acc: 74.925% (9015/12032)\n",
      "Train Epoch: 4 | Loss: 0.716 | Acc: 75.000% (9120/12160)\n",
      "Train Epoch: 4 | Loss: 0.716 | Acc: 75.033% (9220/12288)\n",
      "Train Epoch: 4 | Loss: 0.717 | Acc: 75.024% (9315/12416)\n",
      "Train Epoch: 4 | Loss: 0.718 | Acc: 75.008% (9409/12544)\n",
      "Train Epoch: 4 | Loss: 0.717 | Acc: 75.055% (9511/12672)\n",
      "Train Epoch: 4 | Loss: 0.715 | Acc: 75.125% (9616/12800)\n",
      "Train Epoch: 4 | Loss: 0.715 | Acc: 75.101% (9709/12928)\n",
      "Train Epoch: 4 | Loss: 0.716 | Acc: 75.084% (9803/13056)\n",
      "Train Epoch: 4 | Loss: 0.715 | Acc: 75.137% (9906/13184)\n",
      "Train Epoch: 4 | Loss: 0.714 | Acc: 75.180% (10008/13312)\n",
      "Train Epoch: 4 | Loss: 0.714 | Acc: 75.156% (10101/13440)\n",
      "Train Epoch: 4 | Loss: 0.714 | Acc: 75.192% (10202/13568)\n",
      "Train Epoch: 4 | Loss: 0.713 | Acc: 75.226% (10303/13696)\n",
      "Train Epoch: 4 | Loss: 0.713 | Acc: 75.253% (10403/13824)\n",
      "Train Epoch: 4 | Loss: 0.712 | Acc: 75.294% (10505/13952)\n",
      "Train Epoch: 4 | Loss: 0.712 | Acc: 75.227% (10592/14080)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.267% (10694/14208)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.321% (10798/14336)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.325% (10895/14464)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.356% (10996/14592)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.319% (11087/14720)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.370% (11191/14848)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.341% (11283/14976)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.331% (11378/15104)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.302% (11470/15232)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.260% (11560/15360)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.239% (11653/15488)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.263% (11753/15616)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.210% (11841/15744)\n",
      "Train Epoch: 4 | Loss: 0.711 | Acc: 75.221% (11939/15872)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.213% (12034/16000)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.254% (12137/16128)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.228% (12229/16256)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.208% (12322/16384)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.218% (12420/16512)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.258% (12523/16640)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.245% (12617/16768)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.266% (12717/16896)\n",
      "Train Epoch: 4 | Loss: 0.710 | Acc: 75.241% (12809/17024)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.262% (12909/17152)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.284% (13009/17280)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.287% (13106/17408)\n",
      "Train Epoch: 4 | Loss: 0.709 | Acc: 75.234% (13193/17536)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.232% (13289/17664)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.225% (13384/17792)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.262% (13487/17920)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.266% (13584/18048)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.314% (13689/18176)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.300% (13783/18304)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.271% (13874/18432)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.291% (13974/18560)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.235% (14060/18688)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.244% (14158/18816)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.259% (14257/18944)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.273% (14356/19072)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.260% (14450/19200)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.259% (14546/19328)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.272% (14645/19456)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.260% (14739/19584)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.299% (14843/19712)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.297% (14939/19840)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.326% (15041/19968)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.343% (15141/20096)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.415% (15252/20224)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.413% (15348/20352)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.410% (15444/20480)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.388% (15536/20608)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.381% (15631/20736)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.359% (15723/20864)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.410% (15830/20992)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.417% (15928/21120)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.424% (16026/21248)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.444% (16127/21376)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.456% (16226/21504)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.485% (16329/21632)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.492% (16427/21760)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.471% (16519/21888)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.468% (16615/22016)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.470% (16712/22144)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.458% (16806/22272)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.478% (16907/22400)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.457% (16999/22528)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.415% (17086/22656)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.369% (17172/22784)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.345% (17263/22912)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.347% (17360/23040)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.358% (17459/23168)\n",
      "Train Epoch: 4 | Loss: 0.708 | Acc: 75.369% (17558/23296)\n",
      "Train Epoch: 4 | Loss: 0.707 | Acc: 75.397% (17661/23424)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.425% (17764/23552)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.389% (17852/23680)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.399% (17951/23808)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.414% (18051/23936)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.411% (18147/24064)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.422% (18246/24192)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.415% (18341/24320)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.434% (18442/24448)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.464% (18546/24576)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.466% (18643/24704)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.467% (18740/24832)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.497% (18844/24960)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.482% (18937/25088)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.492% (19036/25216)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.481% (19130/25344)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.483% (19227/25472)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.457% (19317/25600)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.494% (19423/25728)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.495% (19520/25856)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.493% (19616/25984)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.471% (19707/26112)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.450% (19798/26240)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.448% (19894/26368)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.464% (19995/26496)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.443% (20086/26624)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.430% (20179/26752)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.446% (20280/26880)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.426% (20371/27008)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.409% (20463/27136)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.374% (20550/27264)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.361% (20643/27392)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.367% (20741/27520)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.344% (20831/27648)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.331% (20924/27776)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.333% (21021/27904)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.328% (21116/28032)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.344% (21217/28160)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.368% (21320/28288)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.398% (21425/28416)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.420% (21528/28544)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.436% (21629/28672)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.434% (21725/28800)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.422% (21818/28928)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.444% (21921/29056)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.442% (22017/29184)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.413% (22105/29312)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.418% (22203/29440)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.402% (22295/29568)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.421% (22397/29696)\n",
      "Train Epoch: 4 | Loss: 0.706 | Acc: 75.436% (22498/29824)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.441% (22596/29952)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.445% (22694/30080)\n",
      "Train Epoch: 4 | Loss: 0.705 | Acc: 75.470% (22798/30208)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.488% (22900/30336)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.509% (23003/30464)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.526% (23105/30592)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.531% (23203/30720)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.538% (23302/30848)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.497% (23386/30976)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.505% (23485/31104)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.490% (23577/31232)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.507% (23679/31360)\n",
      "Train Epoch: 4 | Loss: 0.704 | Acc: 75.530% (23783/31488)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.541% (23883/31616)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.526% (23975/31744)\n",
      "Train Epoch: 4 | Loss: 0.703 | Acc: 75.533% (24074/31872)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.559% (24179/32000)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.585% (24284/32128)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.598% (24385/32256)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.608% (24485/32384)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.621% (24586/32512)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.625% (24684/32640)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.641% (24786/32768)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.657% (24888/32896)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.648% (24982/33024)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.652% (25080/33152)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.646% (25175/33280)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.641% (25270/33408)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.653% (25371/33536)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.668% (25473/33664)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.666% (25569/33792)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.646% (25659/33920)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.664% (25762/34048)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.650% (25854/34176)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.659% (25954/34304)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.651% (26048/34432)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.663% (26149/34560)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.675% (26250/34688)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.684% (26350/34816)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.693% (26450/34944)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.681% (26543/35072)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.665% (26634/35200)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.682% (26737/35328)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.666% (26828/35456)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.666% (26925/35584)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.689% (27030/35712)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.689% (27127/35840)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.667% (27216/35968)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.643% (27304/36096)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.627% (27395/36224)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.624% (27491/36352)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.636% (27592/36480)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.656% (27696/36608)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.661% (27795/36736)\n",
      "Train Epoch: 4 | Loss: 0.702 | Acc: 75.665% (27893/36864)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.676% (27994/36992)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.687% (28095/37120)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.695% (28195/37248)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.693% (28291/37376)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.720% (28398/37504)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.720% (28495/37632)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.723% (28593/37760)\n",
      "Train Epoch: 4 | Loss: 0.701 | Acc: 75.718% (28688/37888)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.731% (28790/38016)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.747% (28893/38144)\n",
      "Train Epoch: 4 | Loss: 0.700 | Acc: 75.755% (28993/38272)\n",
      "Train Epoch: 4 | Loss: 0.699 | Acc: 75.773% (29097/38400)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.802% (29205/38528)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.802% (29302/38656)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.810% (29402/38784)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.804% (29497/38912)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.825% (29602/39040)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.832% (29702/39168)\n",
      "Train Epoch: 4 | Loss: 0.698 | Acc: 75.835% (29800/39296)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.845% (29901/39424)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.839% (29996/39552)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.839% (30093/39680)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.847% (30193/39808)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.846% (30290/39936)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.836% (30383/40064)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.841% (30482/40192)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.846% (30581/40320)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.850% (30680/40448)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.868% (30784/40576)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.882% (30887/40704)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.889% (30987/40832)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.859% (31072/40960)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.866% (31172/41088)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.852% (31263/41216)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.863% (31365/41344)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.858% (31460/41472)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.870% (31562/41600)\n",
      "Train Epoch: 4 | Loss: 0.697 | Acc: 75.863% (31656/41728)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.891% (31765/41856)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.905% (31868/41984)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.898% (31962/42112)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.926% (32071/42240)\n",
      "Train Epoch: 4 | Loss: 0.696 | Acc: 75.942% (32175/42368)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.960% (32280/42496)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.955% (32375/42624)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.954% (32472/42752)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.954% (32569/42880)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.956% (32667/43008)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.964% (32768/43136)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.968% (32867/43264)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.973% (32966/43392)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.983% (33068/43520)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.983% (33165/43648)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.989% (33265/43776)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.991% (33363/43904)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.004% (33466/44032)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.005% (33564/44160)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.007% (33662/44288)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.995% (33754/44416)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.986% (33847/44544)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.976% (33940/44672)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.984% (34041/44800)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 75.986% (34139/44928)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.981% (34234/45056)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.972% (34327/45184)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.982% (34429/45312)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.968% (34520/45440)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.970% (34618/45568)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 75.991% (34725/45696)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 75.995% (34824/45824)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.001% (34924/45952)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.998% (35020/46080)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.015% (35125/46208)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.010% (35220/46336)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.007% (35316/46464)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.013% (35416/46592)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.002% (35508/46720)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 75.993% (35601/46848)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.007% (35705/46976)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.002% (35800/47104)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.001% (35897/47232)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.001% (35994/47360)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.004% (36093/47488)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.004% (36190/47616)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.016% (36293/47744)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.021% (36393/47872)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.015% (36487/48000)\n",
      "Train Epoch: 4 | Loss: 0.695 | Acc: 76.012% (36583/48128)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.032% (36690/48256)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.040% (36791/48384)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.060% (36898/48512)\n",
      "Train Epoch: 4 | Loss: 0.694 | Acc: 76.067% (36999/48640)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.085% (37105/48768)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.098% (37209/48896)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.104% (37309/49024)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.113% (37411/49152)\n",
      "Train Epoch: 4 | Loss: 0.692 | Acc: 76.132% (37518/49280)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.115% (37607/49408)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.104% (37699/49536)\n",
      "Train Epoch: 4 | Loss: 0.693 | Acc: 76.107% (37798/49664)\n",
      "Train Epoch: 4 | Loss: 0.692 | Acc: 76.115% (37899/49792)\n",
      "Train Epoch: 4 | Loss: 0.692 | Acc: 76.140% (38009/49920)\n",
      "Train Epoch: 4 | Loss: 0.691 | Acc: 76.154% (38077/50000)\n",
      "Test Epoch: 4 | Loss: 0.742 | Acc: 75.000% (75/100)\n",
      "Test Epoch: 4 | Loss: 0.826 | Acc: 72.500% (145/200)\n",
      "Test Epoch: 4 | Loss: 0.808 | Acc: 71.667% (215/300)\n",
      "Test Epoch: 4 | Loss: 0.824 | Acc: 71.000% (284/400)\n",
      "Test Epoch: 4 | Loss: 0.832 | Acc: 70.200% (351/500)\n",
      "Test Epoch: 4 | Loss: 0.776 | Acc: 71.500% (429/600)\n",
      "Test Epoch: 4 | Loss: 0.764 | Acc: 72.000% (504/700)\n",
      "Test Epoch: 4 | Loss: 0.799 | Acc: 71.750% (574/800)\n",
      "Test Epoch: 4 | Loss: 0.816 | Acc: 71.556% (644/900)\n",
      "Test Epoch: 4 | Loss: 0.806 | Acc: 72.100% (721/1000)\n",
      "Test Epoch: 4 | Loss: 0.799 | Acc: 72.727% (800/1100)\n",
      "Test Epoch: 4 | Loss: 0.790 | Acc: 73.083% (877/1200)\n",
      "Test Epoch: 4 | Loss: 0.798 | Acc: 73.231% (952/1300)\n",
      "Test Epoch: 4 | Loss: 0.804 | Acc: 72.786% (1019/1400)\n",
      "Test Epoch: 4 | Loss: 0.802 | Acc: 73.067% (1096/1500)\n",
      "Test Epoch: 4 | Loss: 0.817 | Acc: 72.625% (1162/1600)\n",
      "Test Epoch: 4 | Loss: 0.817 | Acc: 73.000% (1241/1700)\n",
      "Test Epoch: 4 | Loss: 0.819 | Acc: 72.500% (1305/1800)\n",
      "Test Epoch: 4 | Loss: 0.821 | Acc: 72.737% (1382/1900)\n",
      "Test Epoch: 4 | Loss: 0.825 | Acc: 72.750% (1455/2000)\n",
      "Test Epoch: 4 | Loss: 0.828 | Acc: 72.619% (1525/2100)\n",
      "Test Epoch: 4 | Loss: 0.831 | Acc: 72.591% (1597/2200)\n",
      "Test Epoch: 4 | Loss: 0.838 | Acc: 72.391% (1665/2300)\n",
      "Test Epoch: 4 | Loss: 0.837 | Acc: 72.333% (1736/2400)\n",
      "Test Epoch: 4 | Loss: 0.840 | Acc: 72.360% (1809/2500)\n",
      "Test Epoch: 4 | Loss: 0.849 | Acc: 72.192% (1877/2600)\n",
      "Test Epoch: 4 | Loss: 0.848 | Acc: 72.037% (1945/2700)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.036% (2017/2800)\n",
      "Test Epoch: 4 | Loss: 0.853 | Acc: 72.103% (2091/2900)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.200% (2166/3000)\n",
      "Test Epoch: 4 | Loss: 0.851 | Acc: 72.355% (2243/3100)\n",
      "Test Epoch: 4 | Loss: 0.850 | Acc: 72.469% (2319/3200)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.424% (2390/3300)\n",
      "Test Epoch: 4 | Loss: 0.855 | Acc: 72.294% (2458/3400)\n",
      "Test Epoch: 4 | Loss: 0.857 | Acc: 72.314% (2531/3500)\n",
      "Test Epoch: 4 | Loss: 0.856 | Acc: 72.361% (2605/3600)\n",
      "Test Epoch: 4 | Loss: 0.857 | Acc: 72.324% (2676/3700)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.421% (2752/3800)\n",
      "Test Epoch: 4 | Loss: 0.849 | Acc: 72.564% (2830/3900)\n",
      "Test Epoch: 4 | Loss: 0.845 | Acc: 72.625% (2905/4000)\n",
      "Test Epoch: 4 | Loss: 0.849 | Acc: 72.610% (2977/4100)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.595% (3049/4200)\n",
      "Test Epoch: 4 | Loss: 0.849 | Acc: 72.558% (3120/4300)\n",
      "Test Epoch: 4 | Loss: 0.848 | Acc: 72.614% (3195/4400)\n",
      "Test Epoch: 4 | Loss: 0.847 | Acc: 72.556% (3265/4500)\n",
      "Test Epoch: 4 | Loss: 0.851 | Acc: 72.457% (3333/4600)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.362% (3401/4700)\n",
      "Test Epoch: 4 | Loss: 0.852 | Acc: 72.312% (3471/4800)\n",
      "Test Epoch: 4 | Loss: 0.851 | Acc: 72.265% (3541/4900)\n",
      "Test Epoch: 4 | Loss: 0.858 | Acc: 72.120% (3606/5000)\n",
      "Test Epoch: 4 | Loss: 0.856 | Acc: 72.176% (3681/5100)\n",
      "Test Epoch: 4 | Loss: 0.858 | Acc: 72.135% (3751/5200)\n",
      "Test Epoch: 4 | Loss: 0.861 | Acc: 72.000% (3816/5300)\n",
      "Test Epoch: 4 | Loss: 0.862 | Acc: 72.019% (3889/5400)\n",
      "Test Epoch: 4 | Loss: 0.863 | Acc: 71.891% (3954/5500)\n",
      "Test Epoch: 4 | Loss: 0.865 | Acc: 71.839% (4023/5600)\n",
      "Test Epoch: 4 | Loss: 0.866 | Acc: 71.754% (4090/5700)\n",
      "Test Epoch: 4 | Loss: 0.862 | Acc: 71.931% (4172/5800)\n",
      "Test Epoch: 4 | Loss: 0.865 | Acc: 71.898% (4242/5900)\n",
      "Test Epoch: 4 | Loss: 0.870 | Acc: 71.833% (4310/6000)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 71.803% (4380/6100)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 71.726% (4447/6200)\n",
      "Test Epoch: 4 | Loss: 0.871 | Acc: 71.825% (4525/6300)\n",
      "Test Epoch: 4 | Loss: 0.868 | Acc: 71.891% (4601/6400)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 71.908% (4674/6500)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 71.879% (4744/6600)\n",
      "Test Epoch: 4 | Loss: 0.866 | Acc: 71.970% (4822/6700)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 71.912% (4890/6800)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 72.000% (4968/6900)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 71.843% (5029/7000)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 71.887% (5104/7100)\n",
      "Test Epoch: 4 | Loss: 0.870 | Acc: 71.931% (5179/7200)\n",
      "Test Epoch: 4 | Loss: 0.868 | Acc: 72.000% (5256/7300)\n",
      "Test Epoch: 4 | Loss: 0.867 | Acc: 72.041% (5331/7400)\n",
      "Test Epoch: 4 | Loss: 0.870 | Acc: 72.000% (5400/7500)\n",
      "Test Epoch: 4 | Loss: 0.868 | Acc: 72.026% (5474/7600)\n",
      "Test Epoch: 4 | Loss: 0.871 | Acc: 71.922% (5538/7700)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 71.859% (5605/7800)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 71.861% (5677/7900)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 71.800% (5744/8000)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 71.877% (5822/8100)\n",
      "Test Epoch: 4 | Loss: 0.869 | Acc: 71.817% (5889/8200)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 71.831% (5962/8300)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 71.821% (6033/8400)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 71.788% (6102/8500)\n",
      "Test Epoch: 4 | Loss: 0.875 | Acc: 71.826% (6177/8600)\n",
      "Test Epoch: 4 | Loss: 0.878 | Acc: 71.805% (6247/8700)\n",
      "Test Epoch: 4 | Loss: 0.877 | Acc: 71.841% (6322/8800)\n",
      "Test Epoch: 4 | Loss: 0.877 | Acc: 71.876% (6397/8900)\n",
      "Test Epoch: 4 | Loss: 0.877 | Acc: 71.867% (6468/9000)\n",
      "Test Epoch: 4 | Loss: 0.877 | Acc: 71.879% (6541/9100)\n",
      "Test Epoch: 4 | Loss: 0.874 | Acc: 71.989% (6623/9200)\n",
      "Test Epoch: 4 | Loss: 0.873 | Acc: 72.022% (6698/9300)\n",
      "Test Epoch: 4 | Loss: 0.874 | Acc: 72.011% (6769/9400)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 72.063% (6846/9500)\n",
      "Test Epoch: 4 | Loss: 0.868 | Acc: 72.188% (6930/9600)\n",
      "Test Epoch: 4 | Loss: 0.866 | Acc: 72.258% (7009/9700)\n",
      "Test Epoch: 4 | Loss: 0.870 | Acc: 72.214% (7077/9800)\n",
      "Test Epoch: 4 | Loss: 0.871 | Acc: 72.172% (7145/9900)\n",
      "Test Epoch: 4 | Loss: 0.872 | Acc: 72.150% (7215/10000)\n",
      "\n",
      "Epoch: 5\n",
      "Train Epoch: 5 | Loss: 0.609 | Acc: 81.250% (104/128)\n",
      "Train Epoch: 5 | Loss: 0.602 | Acc: 78.516% (201/256)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 76.562% (294/384)\n",
      "Train Epoch: 5 | Loss: 0.691 | Acc: 75.781% (388/512)\n",
      "Train Epoch: 5 | Loss: 0.665 | Acc: 77.031% (493/640)\n",
      "Train Epoch: 5 | Loss: 0.665 | Acc: 76.953% (591/768)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.344% (693/896)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.441% (793/1024)\n",
      "Train Epoch: 5 | Loss: 0.634 | Acc: 78.038% (899/1152)\n",
      "Train Epoch: 5 | Loss: 0.633 | Acc: 77.734% (995/1280)\n",
      "Train Epoch: 5 | Loss: 0.611 | Acc: 78.835% (1110/1408)\n",
      "Train Epoch: 5 | Loss: 0.609 | Acc: 78.711% (1209/1536)\n",
      "Train Epoch: 5 | Loss: 0.601 | Acc: 78.966% (1314/1664)\n",
      "Train Epoch: 5 | Loss: 0.604 | Acc: 79.018% (1416/1792)\n",
      "Train Epoch: 5 | Loss: 0.609 | Acc: 78.802% (1513/1920)\n",
      "Train Epoch: 5 | Loss: 0.608 | Acc: 78.857% (1615/2048)\n",
      "Train Epoch: 5 | Loss: 0.608 | Acc: 78.768% (1714/2176)\n",
      "Train Epoch: 5 | Loss: 0.608 | Acc: 78.689% (1813/2304)\n",
      "Train Epoch: 5 | Loss: 0.620 | Acc: 78.331% (1905/2432)\n",
      "Train Epoch: 5 | Loss: 0.617 | Acc: 78.516% (2010/2560)\n",
      "Train Epoch: 5 | Loss: 0.626 | Acc: 78.237% (2103/2688)\n",
      "Train Epoch: 5 | Loss: 0.625 | Acc: 78.267% (2204/2816)\n",
      "Train Epoch: 5 | Loss: 0.630 | Acc: 78.227% (2303/2944)\n",
      "Train Epoch: 5 | Loss: 0.633 | Acc: 78.353% (2407/3072)\n",
      "Train Epoch: 5 | Loss: 0.636 | Acc: 78.188% (2502/3200)\n",
      "Train Epoch: 5 | Loss: 0.633 | Acc: 78.215% (2603/3328)\n",
      "Train Epoch: 5 | Loss: 0.633 | Acc: 78.241% (2704/3456)\n",
      "Train Epoch: 5 | Loss: 0.630 | Acc: 78.348% (2808/3584)\n",
      "Train Epoch: 5 | Loss: 0.633 | Acc: 78.260% (2905/3712)\n",
      "Train Epoch: 5 | Loss: 0.634 | Acc: 78.125% (3000/3840)\n",
      "Train Epoch: 5 | Loss: 0.636 | Acc: 78.125% (3100/3968)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 78.076% (3198/4096)\n",
      "Train Epoch: 5 | Loss: 0.636 | Acc: 78.196% (3303/4224)\n",
      "Train Epoch: 5 | Loss: 0.639 | Acc: 77.941% (3392/4352)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.679% (3480/4480)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.821% (3586/4608)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.407% (3666/4736)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.549% (3772/4864)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.644% (3876/4992)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.773% (3982/5120)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.782% (4082/5248)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.772% (4181/5376)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.852% (4285/5504)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.805% (4382/5632)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.795% (4481/5760)\n",
      "Train Epoch: 5 | Loss: 0.639 | Acc: 77.921% (4588/5888)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.826% (4682/6016)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.767% (4778/6144)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.695% (4873/6272)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.766% (4977/6400)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.819% (5080/6528)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.779% (5177/6656)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.712% (5272/6784)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.604% (5364/6912)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.685% (5469/7040)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.637% (5565/7168)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.700% (5669/7296)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.694% (5768/7424)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.728% (5870/7552)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.721% (5969/7680)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.690% (6066/7808)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.608% (6159/7936)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.505% (6250/8064)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.515% (6350/8192)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.380% (6438/8320)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.415% (6540/8448)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.437% (6641/8576)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.378% (6735/8704)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.366% (6833/8832)\n",
      "Train Epoch: 5 | Loss: 0.658 | Acc: 77.277% (6924/8960)\n",
      "Train Epoch: 5 | Loss: 0.657 | Acc: 77.344% (7029/9088)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.431% (7136/9216)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.397% (7232/9344)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.449% (7336/9472)\n",
      "Train Epoch: 5 | Loss: 0.657 | Acc: 77.406% (7431/9600)\n",
      "Train Epoch: 5 | Loss: 0.657 | Acc: 77.436% (7533/9728)\n",
      "Train Epoch: 5 | Loss: 0.657 | Acc: 77.435% (7632/9856)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.464% (7734/9984)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.482% (7835/10112)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.510% (7937/10240)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.498% (8035/10368)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.458% (8130/10496)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.457% (8229/10624)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.418% (8324/10752)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.445% (8426/10880)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.453% (8526/11008)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.460% (8626/11136)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.406% (8719/11264)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.388% (8816/11392)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.352% (8911/11520)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.412% (9017/11648)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.420% (9117/11776)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.411% (9215/11904)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.394% (9312/12032)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.352% (9406/12160)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.344% (9504/12288)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.344% (9603/12416)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.304% (9697/12544)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.304% (9796/12672)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.305% (9895/12800)\n",
      "Train Epoch: 5 | Loss: 0.655 | Acc: 77.243% (9986/12928)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.237% (10084/13056)\n",
      "Train Epoch: 5 | Loss: 0.656 | Acc: 77.245% (10184/13184)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.306% (10291/13312)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.277% (10386/13440)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.300% (10488/13568)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.263% (10582/13696)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.329% (10690/13824)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.337% (10790/13952)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.415% (10900/14080)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.414% (10999/14208)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.434% (11101/14336)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.468% (11205/14464)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.481% (11306/14592)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.439% (11399/14720)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.445% (11499/14848)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.451% (11599/14976)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.496% (11705/15104)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.554% (11813/15232)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.539% (11910/15360)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.499% (12003/15488)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.440% (12093/15616)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.452% (12194/15744)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.482% (12298/15872)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.469% (12395/16000)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.443% (12490/16128)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.424% (12586/16256)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.423% (12685/16384)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.416% (12783/16512)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.380% (12876/16640)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.409% (12980/16768)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.456% (13087/16896)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.438% (13183/17024)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.379% (13272/17152)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.384% (13372/17280)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.384% (13471/17408)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.389% (13571/17536)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.361% (13665/17664)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.372% (13766/17792)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.372% (13865/17920)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.410% (13971/18048)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.426% (14073/18176)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.448% (14176/18304)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.469% (14279/18432)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.484% (14381/18560)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.451% (14474/18688)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.423% (14568/18816)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.428% (14668/18944)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.391% (14760/19072)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.380% (14857/19200)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.339% (14948/19328)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.354% (15050/19456)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.344% (15147/19584)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.323% (15242/19712)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.329% (15342/19840)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.314% (15438/19968)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.314% (15537/20096)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.329% (15639/20224)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.334% (15739/20352)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.344% (15840/20480)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.363% (15943/20608)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.339% (16037/20736)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.363% (16141/20864)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.344% (16236/20992)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.348% (16336/21120)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.316% (16428/21248)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.306% (16525/21376)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.297% (16622/21504)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.316% (16725/21632)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.344% (16830/21760)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.344% (16929/21888)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.339% (17027/22016)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.321% (17122/22144)\n",
      "Train Epoch: 5 | Loss: 0.654 | Acc: 77.335% (17224/22272)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.375% (17332/22400)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.388% (17434/22528)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.375% (17530/22656)\n",
      "Train Epoch: 5 | Loss: 0.653 | Acc: 77.388% (17632/22784)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.405% (17735/22912)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.431% (17840/23040)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.456% (17945/23168)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.464% (18046/23296)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.455% (18143/23424)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.429% (18236/23552)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.420% (18333/23680)\n",
      "Train Epoch: 5 | Loss: 0.652 | Acc: 77.411% (18430/23808)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.423% (18532/23936)\n",
      "Train Epoch: 5 | Loss: 0.651 | Acc: 77.448% (18637/24064)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.459% (18739/24192)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.451% (18836/24320)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.479% (18942/24448)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.498% (19046/24576)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.514% (19149/24704)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.537% (19254/24832)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.540% (19354/24960)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.575% (19462/25088)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.570% (19560/25216)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.541% (19652/25344)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.524% (19747/25472)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.559% (19855/25600)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.558% (19954/25728)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.537% (20048/25856)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.486% (20134/25984)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.474% (20230/26112)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.481% (20331/26240)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.476% (20429/26368)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.483% (20530/26496)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.479% (20628/26624)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.452% (20720/26752)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.422% (20811/26880)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.422% (20910/27008)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.425% (21010/27136)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.417% (21107/27264)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.420% (21207/27392)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.420% (21306/27520)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.391% (21397/27648)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.427% (21506/27776)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.433% (21607/27904)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.426% (21704/28032)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.408% (21798/28160)\n",
      "Train Epoch: 5 | Loss: 0.650 | Acc: 77.432% (21904/28288)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.449% (22008/28416)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.473% (22114/28544)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.497% (22220/28672)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.507% (22322/28800)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.503% (22420/28928)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.485% (22514/29056)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.519% (22623/29184)\n",
      "Train Epoch: 5 | Loss: 0.649 | Acc: 77.514% (22721/29312)\n",
      "Train Epoch: 5 | Loss: 0.648 | Acc: 77.548% (22830/29440)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.570% (22936/29568)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.576% (23037/29696)\n",
      "Train Epoch: 5 | Loss: 0.647 | Acc: 77.578% (23137/29824)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.601% (23243/29952)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.610% (23345/30080)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.619% (23447/30208)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.640% (23553/30336)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.603% (23641/30464)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.609% (23742/30592)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.594% (23837/30720)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.606% (23940/30848)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.583% (24032/30976)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.614% (24141/31104)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.629% (24245/31232)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.647% (24350/31360)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.645% (24449/31488)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.638% (24546/31616)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.646% (24648/31744)\n",
      "Train Epoch: 5 | Loss: 0.646 | Acc: 77.636% (24744/31872)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.653% (24849/32000)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.664% (24952/32128)\n",
      "Train Epoch: 5 | Loss: 0.645 | Acc: 77.691% (25060/32256)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.696% (25161/32384)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.694% (25260/32512)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.690% (25358/32640)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.689% (25457/32768)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.681% (25554/32896)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.680% (25653/33024)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.706% (25761/33152)\n",
      "Train Epoch: 5 | Loss: 0.644 | Acc: 77.701% (25859/33280)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.709% (25961/33408)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.719% (26064/33536)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.727% (26166/33664)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.746% (26272/33792)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.768% (26379/33920)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.755% (26474/34048)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.762% (26576/34176)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.737% (26667/34304)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.750% (26771/34432)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.737% (26866/34560)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.747% (26969/34688)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.746% (27068/34816)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.742% (27166/34944)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.732% (27262/35072)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.744% (27366/35200)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.726% (27459/35328)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.739% (27563/35456)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.748% (27666/35584)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.767% (27772/35712)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.787% (27879/35840)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.791% (27980/35968)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.773% (28073/36096)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.750% (28164/36224)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.726% (28255/36352)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.725% (28354/36480)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.718% (28451/36608)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.717% (28550/36736)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.724% (28652/36864)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.706% (28745/36992)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.713% (28847/37120)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.714% (28947/37248)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.734% (29054/37376)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.738% (29155/37504)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.740% (29255/37632)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.754% (29360/37760)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.745% (29456/37888)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.744% (29555/38016)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.753% (29658/38144)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.759% (29760/38272)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.760% (29860/38400)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.746% (29954/38528)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.747% (30054/38656)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.751% (30155/38784)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.750% (30254/38912)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.766% (30360/39040)\n",
      "Train Epoch: 5 | Loss: 0.643 | Acc: 77.768% (30460/39168)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.779% (30564/39296)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.785% (30666/39424)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.791% (30768/39552)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.795% (30869/39680)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.783% (30964/39808)\n",
      "Train Epoch: 5 | Loss: 0.642 | Acc: 77.787% (31065/39936)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.815% (31176/40064)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.821% (31278/40192)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.812% (31374/40320)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.821% (31477/40448)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.822% (31577/40576)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.828% (31679/40704)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.824% (31777/40832)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.820% (31875/40960)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.823% (31976/41088)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.812% (32071/41216)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.823% (32175/41344)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.826% (32276/41472)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.844% (32383/41600)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.842% (32482/41728)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.860% (32589/41856)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.877% (32696/41984)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.852% (32785/42112)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.857% (32887/42240)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.872% (32993/42368)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.866% (33090/42496)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.874% (33193/42624)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.858% (33286/42752)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.866% (33389/42880)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.876% (33493/43008)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.870% (33590/43136)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.873% (33691/43264)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.867% (33788/43392)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.858% (33884/43520)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.871% (33989/43648)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.869% (34088/43776)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.870% (34188/43904)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.857% (34282/44032)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.849% (34378/44160)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.845% (34476/44288)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.857% (34581/44416)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.876% (34689/44544)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.903% (34801/44672)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.900% (34899/44800)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.905% (35001/44928)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.916% (35106/45056)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.910% (35203/45184)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.915% (35305/45312)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.909% (35402/45440)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.908% (35501/45568)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.915% (35604/45696)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.898% (35696/45824)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.894% (35794/45952)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.901% (35897/46080)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.900% (35996/46208)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.916% (36103/46336)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.914% (36202/46464)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.940% (36314/46592)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.935% (36411/46720)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.939% (36513/46848)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.933% (36610/46976)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.940% (36713/47104)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.943% (36814/47232)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.954% (36919/47360)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.948% (37016/47488)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.951% (37117/47616)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.932% (37208/47744)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.924% (37304/47872)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.931% (37407/48000)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.928% (37505/48128)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.920% (37601/48256)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.912% (37697/48384)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.919% (37800/48512)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.924% (37902/48640)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.922% (38001/48768)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.923% (38101/48896)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.913% (38196/49024)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.915% (38297/49152)\n",
      "Train Epoch: 5 | Loss: 0.641 | Acc: 77.914% (38396/49280)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.921% (38499/49408)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.919% (38598/49536)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.914% (38695/49664)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.922% (38799/49792)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.925% (38900/49920)\n",
      "Train Epoch: 5 | Loss: 0.640 | Acc: 77.934% (38967/50000)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 79.000% (79/100)\n",
      "Test Epoch: 5 | Loss: 0.774 | Acc: 76.500% (153/200)\n",
      "Test Epoch: 5 | Loss: 0.732 | Acc: 75.667% (227/300)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.250% (305/400)\n",
      "Test Epoch: 5 | Loss: 0.678 | Acc: 76.600% (383/500)\n",
      "Test Epoch: 5 | Loss: 0.640 | Acc: 77.333% (464/600)\n",
      "Test Epoch: 5 | Loss: 0.635 | Acc: 77.714% (544/700)\n",
      "Test Epoch: 5 | Loss: 0.668 | Acc: 76.250% (610/800)\n",
      "Test Epoch: 5 | Loss: 0.699 | Acc: 75.556% (680/900)\n",
      "Test Epoch: 5 | Loss: 0.684 | Acc: 76.300% (763/1000)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.545% (842/1100)\n",
      "Test Epoch: 5 | Loss: 0.693 | Acc: 76.417% (917/1200)\n",
      "Test Epoch: 5 | Loss: 0.688 | Acc: 76.846% (999/1300)\n",
      "Test Epoch: 5 | Loss: 0.690 | Acc: 76.714% (1074/1400)\n",
      "Test Epoch: 5 | Loss: 0.682 | Acc: 76.867% (1153/1500)\n",
      "Test Epoch: 5 | Loss: 0.696 | Acc: 76.250% (1220/1600)\n",
      "Test Epoch: 5 | Loss: 0.699 | Acc: 76.294% (1297/1700)\n",
      "Test Epoch: 5 | Loss: 0.696 | Acc: 76.389% (1375/1800)\n",
      "Test Epoch: 5 | Loss: 0.697 | Acc: 76.368% (1451/1900)\n",
      "Test Epoch: 5 | Loss: 0.701 | Acc: 76.300% (1526/2000)\n",
      "Test Epoch: 5 | Loss: 0.702 | Acc: 76.048% (1597/2100)\n",
      "Test Epoch: 5 | Loss: 0.704 | Acc: 76.045% (1673/2200)\n",
      "Test Epoch: 5 | Loss: 0.704 | Acc: 75.870% (1745/2300)\n",
      "Test Epoch: 5 | Loss: 0.705 | Acc: 75.958% (1823/2400)\n",
      "Test Epoch: 5 | Loss: 0.703 | Acc: 76.000% (1900/2500)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.769% (1970/2600)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.741% (2045/2700)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.750% (2121/2800)\n",
      "Test Epoch: 5 | Loss: 0.708 | Acc: 75.862% (2200/2900)\n",
      "Test Epoch: 5 | Loss: 0.702 | Acc: 75.967% (2279/3000)\n",
      "Test Epoch: 5 | Loss: 0.708 | Acc: 75.839% (2351/3100)\n",
      "Test Epoch: 5 | Loss: 0.703 | Acc: 75.875% (2428/3200)\n",
      "Test Epoch: 5 | Loss: 0.704 | Acc: 75.848% (2503/3300)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.529% (2568/3400)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.543% (2644/3500)\n",
      "Test Epoch: 5 | Loss: 0.716 | Acc: 75.556% (2720/3600)\n",
      "Test Epoch: 5 | Loss: 0.719 | Acc: 75.622% (2798/3700)\n",
      "Test Epoch: 5 | Loss: 0.717 | Acc: 75.711% (2877/3800)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.846% (2958/3900)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.850% (3034/4000)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.780% (3107/4100)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.833% (3185/4200)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.977% (3267/4300)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.955% (3342/4400)\n",
      "Test Epoch: 5 | Loss: 0.706 | Acc: 76.022% (3421/4500)\n",
      "Test Epoch: 5 | Loss: 0.705 | Acc: 76.065% (3499/4600)\n",
      "Test Epoch: 5 | Loss: 0.706 | Acc: 75.957% (3570/4700)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.896% (3643/4800)\n",
      "Test Epoch: 5 | Loss: 0.706 | Acc: 75.980% (3723/4900)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.940% (3797/5000)\n",
      "Test Epoch: 5 | Loss: 0.708 | Acc: 75.980% (3875/5100)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.885% (3946/5200)\n",
      "Test Epoch: 5 | Loss: 0.711 | Acc: 75.774% (4016/5300)\n",
      "Test Epoch: 5 | Loss: 0.711 | Acc: 75.778% (4092/5400)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.691% (4163/5500)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.714% (4240/5600)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.667% (4313/5700)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.776% (4395/5800)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.661% (4464/5900)\n",
      "Test Epoch: 5 | Loss: 0.717 | Acc: 75.633% (4538/6000)\n",
      "Test Epoch: 5 | Loss: 0.716 | Acc: 75.639% (4614/6100)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.597% (4687/6200)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.698% (4769/6300)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.688% (4844/6400)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.600% (4914/6500)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.515% (4984/6600)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.597% (5065/6700)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.632% (5143/6800)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.667% (5221/6900)\n",
      "Test Epoch: 5 | Loss: 0.716 | Acc: 75.600% (5292/7000)\n",
      "Test Epoch: 5 | Loss: 0.716 | Acc: 75.620% (5369/7100)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.639% (5446/7200)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.671% (5524/7300)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.703% (5602/7400)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.733% (5680/7500)\n",
      "Test Epoch: 5 | Loss: 0.711 | Acc: 75.776% (5759/7600)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.779% (5835/7700)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.744% (5908/7800)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.772% (5986/7900)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.787% (6063/8000)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.864% (6145/8100)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.866% (6221/8200)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.880% (6298/8300)\n",
      "Test Epoch: 5 | Loss: 0.709 | Acc: 75.821% (6369/8400)\n",
      "Test Epoch: 5 | Loss: 0.711 | Acc: 75.800% (6443/8500)\n",
      "Test Epoch: 5 | Loss: 0.712 | Acc: 75.802% (6519/8600)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.793% (6594/8700)\n",
      "Test Epoch: 5 | Loss: 0.713 | Acc: 75.773% (6668/8800)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.775% (6744/8900)\n",
      "Test Epoch: 5 | Loss: 0.715 | Acc: 75.778% (6820/9000)\n",
      "Test Epoch: 5 | Loss: 0.714 | Acc: 75.780% (6896/9100)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.870% (6980/9200)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.903% (7059/9300)\n",
      "Test Epoch: 5 | Loss: 0.710 | Acc: 75.862% (7131/9400)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.926% (7213/9500)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.885% (7285/9600)\n",
      "Test Epoch: 5 | Loss: 0.706 | Acc: 75.948% (7367/9700)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.898% (7438/9800)\n",
      "Test Epoch: 5 | Loss: 0.708 | Acc: 75.869% (7511/9900)\n",
      "Test Epoch: 5 | Loss: 0.707 | Acc: 75.870% (7587/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Train Epoch: 6 | Loss: 0.536 | Acc: 83.594% (107/128)\n",
      "Train Epoch: 6 | Loss: 0.549 | Acc: 82.422% (211/256)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 80.469% (309/384)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 80.469% (412/512)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 80.312% (514/640)\n",
      "Train Epoch: 6 | Loss: 0.562 | Acc: 80.990% (622/768)\n",
      "Train Epoch: 6 | Loss: 0.569 | Acc: 80.469% (721/896)\n",
      "Train Epoch: 6 | Loss: 0.561 | Acc: 80.664% (826/1024)\n",
      "Train Epoch: 6 | Loss: 0.565 | Acc: 79.948% (921/1152)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 80.000% (1024/1280)\n",
      "Train Epoch: 6 | Loss: 0.562 | Acc: 80.398% (1132/1408)\n",
      "Train Epoch: 6 | Loss: 0.560 | Acc: 80.469% (1236/1536)\n",
      "Train Epoch: 6 | Loss: 0.570 | Acc: 80.108% (1333/1664)\n",
      "Train Epoch: 6 | Loss: 0.571 | Acc: 80.190% (1437/1792)\n",
      "Train Epoch: 6 | Loss: 0.566 | Acc: 80.417% (1544/1920)\n",
      "Train Epoch: 6 | Loss: 0.563 | Acc: 80.322% (1645/2048)\n",
      "Train Epoch: 6 | Loss: 0.571 | Acc: 80.101% (1743/2176)\n",
      "Train Epoch: 6 | Loss: 0.573 | Acc: 80.165% (1847/2304)\n",
      "Train Epoch: 6 | Loss: 0.575 | Acc: 80.181% (1950/2432)\n",
      "Train Epoch: 6 | Loss: 0.571 | Acc: 80.117% (2051/2560)\n",
      "Train Epoch: 6 | Loss: 0.564 | Acc: 80.543% (2165/2688)\n",
      "Train Epoch: 6 | Loss: 0.569 | Acc: 80.362% (2263/2816)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 80.095% (2358/2944)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 80.078% (2460/3072)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 79.906% (2557/3200)\n",
      "Train Epoch: 6 | Loss: 0.571 | Acc: 80.138% (2667/3328)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 80.035% (2766/3456)\n",
      "Train Epoch: 6 | Loss: 0.573 | Acc: 80.162% (2873/3584)\n",
      "Train Epoch: 6 | Loss: 0.571 | Acc: 80.199% (2977/3712)\n",
      "Train Epoch: 6 | Loss: 0.568 | Acc: 80.260% (3082/3840)\n",
      "Train Epoch: 6 | Loss: 0.565 | Acc: 80.418% (3191/3968)\n",
      "Train Epoch: 6 | Loss: 0.567 | Acc: 80.200% (3285/4096)\n",
      "Train Epoch: 6 | Loss: 0.566 | Acc: 80.185% (3387/4224)\n",
      "Train Epoch: 6 | Loss: 0.566 | Acc: 80.216% (3491/4352)\n",
      "Train Epoch: 6 | Loss: 0.568 | Acc: 80.223% (3594/4480)\n",
      "Train Epoch: 6 | Loss: 0.567 | Acc: 80.295% (3700/4608)\n",
      "Train Epoch: 6 | Loss: 0.564 | Acc: 80.427% (3809/4736)\n",
      "Train Epoch: 6 | Loss: 0.569 | Acc: 80.243% (3903/4864)\n",
      "Train Epoch: 6 | Loss: 0.566 | Acc: 80.308% (4009/4992)\n",
      "Train Epoch: 6 | Loss: 0.574 | Acc: 80.020% (4097/5120)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 79.897% (4193/5248)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 79.929% (4297/5376)\n",
      "Train Epoch: 6 | Loss: 0.575 | Acc: 80.033% (4405/5504)\n",
      "Train Epoch: 6 | Loss: 0.573 | Acc: 80.078% (4510/5632)\n",
      "Train Epoch: 6 | Loss: 0.573 | Acc: 80.035% (4610/5760)\n",
      "Train Epoch: 6 | Loss: 0.573 | Acc: 79.993% (4710/5888)\n",
      "Train Epoch: 6 | Loss: 0.575 | Acc: 79.920% (4808/6016)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 79.932% (4911/6144)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 80.054% (5021/6272)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 80.047% (5123/6400)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 80.040% (5225/6528)\n",
      "Train Epoch: 6 | Loss: 0.576 | Acc: 80.063% (5329/6656)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 79.953% (5424/6784)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 79.948% (5526/6912)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 79.972% (5630/7040)\n",
      "Train Epoch: 6 | Loss: 0.577 | Acc: 80.036% (5737/7168)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 79.989% (5836/7296)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 79.997% (5939/7424)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 79.939% (6037/7552)\n",
      "Train Epoch: 6 | Loss: 0.582 | Acc: 79.961% (6141/7680)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 79.995% (6246/7808)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 80.066% (6354/7936)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 80.047% (6455/8064)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 80.029% (6556/8192)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 80.024% (6658/8320)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 80.031% (6761/8448)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 80.072% (6867/8576)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 80.032% (6966/8704)\n",
      "Train Epoch: 6 | Loss: 0.582 | Acc: 79.971% (7063/8832)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 80.056% (7173/8960)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 80.073% (7277/9088)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 80.100% (7382/9216)\n",
      "Train Epoch: 6 | Loss: 0.578 | Acc: 80.083% (7483/9344)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 80.068% (7584/9472)\n",
      "Train Epoch: 6 | Loss: 0.579 | Acc: 80.052% (7685/9600)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 79.986% (7781/9728)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 79.961% (7881/9856)\n",
      "Train Epoch: 6 | Loss: 0.580 | Acc: 79.968% (7984/9984)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 79.945% (8084/10112)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 79.932% (8185/10240)\n",
      "Train Epoch: 6 | Loss: 0.583 | Acc: 79.890% (8283/10368)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 79.954% (8392/10496)\n",
      "Train Epoch: 6 | Loss: 0.581 | Acc: 79.904% (8489/10624)\n",
      "Train Epoch: 6 | Loss: 0.582 | Acc: 79.920% (8593/10752)\n",
      "Train Epoch: 6 | Loss: 0.583 | Acc: 79.899% (8693/10880)\n",
      "Train Epoch: 6 | Loss: 0.584 | Acc: 79.887% (8794/11008)\n",
      "Train Epoch: 6 | Loss: 0.584 | Acc: 79.912% (8899/11136)\n",
      "Train Epoch: 6 | Loss: 0.584 | Acc: 79.901% (9000/11264)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.854% (9097/11392)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.896% (9204/11520)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.842% (9300/11648)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.806% (9398/11776)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.755% (9494/11904)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.771% (9598/12032)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.794% (9703/12160)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.867% (9814/12288)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.913% (9922/12416)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.959% (10030/12544)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.948% (10131/12672)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.898% (10227/12800)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.850% (10323/12928)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.864% (10427/13056)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.870% (10530/13184)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.890% (10635/13312)\n",
      "Train Epoch: 6 | Loss: 0.584 | Acc: 79.933% (10743/13440)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.953% (10848/13568)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.936% (10948/13696)\n",
      "Train Epoch: 6 | Loss: 0.585 | Acc: 79.926% (11049/13824)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.867% (11143/13952)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.865% (11245/14080)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.863% (11347/14208)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.876% (11451/14336)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.860% (11551/14464)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.879% (11656/14592)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.844% (11753/14720)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.782% (11846/14848)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.734% (11941/14976)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.754% (12046/15104)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.773% (12151/15232)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.733% (12247/15360)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.726% (12348/15488)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.713% (12448/15616)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.726% (12552/15744)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.763% (12660/15872)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.769% (12763/16000)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.681% (12851/16128)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.688% (12954/16256)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.712% (13060/16384)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.700% (13160/16512)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.688% (13260/16640)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.658% (13357/16768)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.664% (13460/16896)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.652% (13560/17024)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.653% (13662/17152)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.670% (13767/17280)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.647% (13865/17408)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.642% (13966/17536)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.637% (14067/17664)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.626% (14167/17792)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.637% (14271/17920)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.627% (14371/18048)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.621% (14472/18176)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.655% (14580/18304)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.688% (14688/18432)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.698% (14792/18560)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.730% (14900/18688)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.703% (14997/18816)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.719% (15102/18944)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.719% (15204/19072)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.708% (15304/19200)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.724% (15409/19328)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.713% (15509/19456)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.718% (15612/19584)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.698% (15710/19712)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.667% (15806/19840)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.652% (15905/19968)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.658% (16008/20096)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.643% (16107/20224)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.574% (16195/20352)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.575% (16297/20480)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.610% (16406/20608)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.630% (16512/20736)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.664% (16621/20864)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.654% (16721/20992)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.669% (16826/21120)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.673% (16929/21248)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.702% (17037/21376)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.706% (17140/21504)\n",
      "Train Epoch: 6 | Loss: 0.586 | Acc: 79.683% (17237/21632)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.642% (17330/21760)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.651% (17434/21888)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.647% (17535/22016)\n",
      "Train Epoch: 6 | Loss: 0.587 | Acc: 79.638% (17635/22144)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.616% (17732/22272)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.616% (17834/22400)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.577% (17927/22528)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.568% (18027/22656)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.578% (18131/22784)\n",
      "Train Epoch: 6 | Loss: 0.588 | Acc: 79.578% (18233/22912)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.549% (18328/23040)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.545% (18429/23168)\n",
      "Train Epoch: 6 | Loss: 0.589 | Acc: 79.546% (18531/23296)\n",
      "Train Epoch: 6 | Loss: 0.590 | Acc: 79.517% (18626/23424)\n",
      "Train Epoch: 6 | Loss: 0.590 | Acc: 79.479% (18719/23552)\n",
      "Train Epoch: 6 | Loss: 0.590 | Acc: 79.485% (18822/23680)\n",
      "Train Epoch: 6 | Loss: 0.591 | Acc: 79.456% (18917/23808)\n",
      "Train Epoch: 6 | Loss: 0.591 | Acc: 79.458% (19019/23936)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.405% (19108/24064)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.398% (19208/24192)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.416% (19314/24320)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.413% (19415/24448)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.423% (19519/24576)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.416% (19619/24704)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.406% (19718/24832)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.383% (19814/24960)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.389% (19917/25088)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.398% (20021/25216)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.419% (20128/25344)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.424% (20231/25472)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.434% (20335/25600)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.447% (20440/25728)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.428% (20537/25856)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.426% (20638/25984)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.408% (20735/26112)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.417% (20839/26240)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.399% (20936/26368)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.389% (21035/26496)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.413% (21143/26624)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.426% (21248/26752)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.431% (21351/26880)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.410% (21447/27008)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.411% (21549/27136)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.420% (21653/27264)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.417% (21754/27392)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.415% (21855/27520)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.405% (21954/27648)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.396% (22053/27776)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.404% (22157/27904)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.402% (22258/28032)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.400% (22359/28160)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.383% (22456/28288)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.424% (22569/28416)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.428% (22672/28544)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.443% (22778/28672)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.448% (22881/28800)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.449% (22983/28928)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.447% (23084/29056)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.431% (23181/29184)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.401% (23274/29312)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.365% (23365/29440)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.363% (23466/29568)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.368% (23569/29696)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.376% (23673/29824)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.400% (23782/29952)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.415% (23888/30080)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.413% (23989/30208)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.420% (24093/30336)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.412% (24192/30464)\n",
      "Train Epoch: 6 | Loss: 0.592 | Acc: 79.406% (24292/30592)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.382% (24386/30720)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.376% (24486/30848)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.378% (24588/30976)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.379% (24690/31104)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.355% (24784/31232)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.356% (24886/31360)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.354% (24987/31488)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.362% (25091/31616)\n",
      "Train Epoch: 6 | Loss: 0.593 | Acc: 79.395% (25203/31744)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.364% (25295/31872)\n",
      "Train Epoch: 6 | Loss: 0.594 | Acc: 79.372% (25399/32000)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.364% (25498/32128)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.362% (25599/32256)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.357% (25699/32384)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.346% (25797/32512)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.357% (25902/32640)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.352% (26002/32768)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.356% (26105/32896)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.348% (26204/33024)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.335% (26301/33152)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.333% (26402/33280)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.319% (26499/33408)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.333% (26605/33536)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.340% (26709/33664)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.338% (26810/33792)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.334% (26910/33920)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.335% (27012/34048)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.316% (27107/34176)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.311% (27207/34304)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.307% (27307/34432)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.288% (27402/34560)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.275% (27499/34688)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.271% (27599/34816)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.270% (27700/34944)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.274% (27803/35072)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.295% (27912/35200)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.274% (28006/35328)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.267% (28105/35456)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.263% (28205/35584)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.259% (28305/35712)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.289% (28417/35840)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.282% (28516/35968)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.275% (28615/36096)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.276% (28717/36224)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.258% (28812/36352)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.279% (28921/36480)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.272% (29020/36608)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.287% (29127/36736)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.283% (29227/36864)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.293% (29332/36992)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.275% (29427/37120)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.271% (29527/37248)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.267% (29627/37376)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.266% (29728/37504)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.262% (29828/37632)\n",
      "Train Epoch: 6 | Loss: 0.595 | Acc: 79.256% (29927/37760)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.236% (30021/37888)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.219% (30116/38016)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.210% (30214/38144)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.202% (30312/38272)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.185% (30407/38400)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.181% (30507/38528)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.173% (30605/38656)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.185% (30711/38784)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.148% (30798/38912)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.132% (30893/39040)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.139% (30997/39168)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.123% (31092/39296)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.122% (31193/39424)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.121% (31294/39552)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.128% (31398/39680)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.132% (31501/39808)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.134% (31603/39936)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.136% (31705/40064)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.125% (31802/40192)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.122% (31902/40320)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.124% (32004/40448)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.135% (32110/40576)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.127% (32208/40704)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.119% (32306/40832)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.106% (32402/40960)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.103% (32502/41088)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.122% (32611/41216)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.119% (32711/41344)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.116% (32811/41472)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.123% (32915/41600)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.120% (33015/41728)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.116% (33115/41856)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.104% (33211/41984)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.115% (33317/42112)\n",
      "Train Epoch: 6 | Loss: 0.598 | Acc: 79.134% (33426/42240)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.152% (33535/42368)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.156% (33638/42496)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.150% (33737/42624)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.150% (33838/42752)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.153% (33941/42880)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.148% (34040/43008)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.145% (34140/43136)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.151% (34244/43264)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.162% (34350/43392)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.161% (34451/43520)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.177% (34559/43648)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.180% (34662/43776)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.175% (34761/43904)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.183% (34866/44032)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.176% (34964/44160)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.179% (35067/44288)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.172% (35165/44416)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.162% (35262/44544)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.159% (35362/44672)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.161% (35464/44800)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.169% (35569/44928)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.170% (35671/45056)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.176% (35775/45184)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.182% (35879/45312)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.188% (35983/45440)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.194% (36087/45568)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.199% (36191/45696)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.199% (36292/45824)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.187% (36388/45952)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.178% (36485/46080)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.175% (36585/46208)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.187% (36692/46336)\n",
      "Train Epoch: 6 | Loss: 0.597 | Acc: 79.192% (36796/46464)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.196% (36899/46592)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.199% (37002/46720)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.214% (37110/46848)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.219% (37214/46976)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.225% (37318/47104)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.224% (37419/47232)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.242% (37529/47360)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.241% (37630/47488)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.246% (37734/47616)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.241% (37833/47744)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.232% (37930/47872)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.229% (38030/48000)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.222% (38128/48128)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.232% (38234/48256)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.229% (38334/48384)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.238% (38440/48512)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.239% (38542/48640)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.232% (38640/48768)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.238% (38744/48896)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.235% (38844/49024)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.230% (38943/49152)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.227% (39043/49280)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.238% (39150/49408)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.245% (39255/49536)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.238% (39353/49664)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.252% (39461/49792)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.251% (39562/49920)\n",
      "Train Epoch: 6 | Loss: 0.596 | Acc: 79.256% (39628/50000)\n",
      "Test Epoch: 6 | Loss: 0.705 | Acc: 80.000% (80/100)\n",
      "Test Epoch: 6 | Loss: 0.696 | Acc: 80.500% (161/200)\n",
      "Test Epoch: 6 | Loss: 0.654 | Acc: 80.000% (240/300)\n",
      "Test Epoch: 6 | Loss: 0.648 | Acc: 79.500% (318/400)\n",
      "Test Epoch: 6 | Loss: 0.639 | Acc: 80.400% (402/500)\n",
      "Test Epoch: 6 | Loss: 0.606 | Acc: 81.000% (486/600)\n",
      "Test Epoch: 6 | Loss: 0.594 | Acc: 81.429% (570/700)\n",
      "Test Epoch: 6 | Loss: 0.642 | Acc: 79.625% (637/800)\n",
      "Test Epoch: 6 | Loss: 0.656 | Acc: 78.556% (707/900)\n",
      "Test Epoch: 6 | Loss: 0.677 | Acc: 78.500% (785/1000)\n",
      "Test Epoch: 6 | Loss: 0.683 | Acc: 78.455% (863/1100)\n",
      "Test Epoch: 6 | Loss: 0.689 | Acc: 78.083% (937/1200)\n",
      "Test Epoch: 6 | Loss: 0.678 | Acc: 78.154% (1016/1300)\n",
      "Test Epoch: 6 | Loss: 0.673 | Acc: 78.357% (1097/1400)\n",
      "Test Epoch: 6 | Loss: 0.664 | Acc: 78.467% (1177/1500)\n",
      "Test Epoch: 6 | Loss: 0.678 | Acc: 78.312% (1253/1600)\n",
      "Test Epoch: 6 | Loss: 0.674 | Acc: 78.235% (1330/1700)\n",
      "Test Epoch: 6 | Loss: 0.676 | Acc: 77.889% (1402/1800)\n",
      "Test Epoch: 6 | Loss: 0.675 | Acc: 77.842% (1479/1900)\n",
      "Test Epoch: 6 | Loss: 0.691 | Acc: 77.350% (1547/2000)\n",
      "Test Epoch: 6 | Loss: 0.684 | Acc: 77.619% (1630/2100)\n",
      "Test Epoch: 6 | Loss: 0.689 | Acc: 77.318% (1701/2200)\n",
      "Test Epoch: 6 | Loss: 0.693 | Acc: 77.348% (1779/2300)\n",
      "Test Epoch: 6 | Loss: 0.698 | Acc: 77.167% (1852/2400)\n",
      "Test Epoch: 6 | Loss: 0.712 | Acc: 76.760% (1919/2500)\n",
      "Test Epoch: 6 | Loss: 0.732 | Acc: 76.500% (1989/2600)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.741% (2072/2700)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.714% (2148/2800)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.724% (2225/2900)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.800% (2304/3000)\n",
      "Test Epoch: 6 | Loss: 0.728 | Acc: 76.839% (2382/3100)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.844% (2459/3200)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.818% (2535/3300)\n",
      "Test Epoch: 6 | Loss: 0.730 | Acc: 76.735% (2609/3400)\n",
      "Test Epoch: 6 | Loss: 0.736 | Acc: 76.571% (2680/3500)\n",
      "Test Epoch: 6 | Loss: 0.736 | Acc: 76.556% (2756/3600)\n",
      "Test Epoch: 6 | Loss: 0.738 | Acc: 76.514% (2831/3700)\n",
      "Test Epoch: 6 | Loss: 0.741 | Acc: 76.421% (2904/3800)\n",
      "Test Epoch: 6 | Loss: 0.737 | Acc: 76.564% (2986/3900)\n",
      "Test Epoch: 6 | Loss: 0.734 | Acc: 76.775% (3071/4000)\n",
      "Test Epoch: 6 | Loss: 0.736 | Acc: 76.756% (3147/4100)\n",
      "Test Epoch: 6 | Loss: 0.739 | Acc: 76.643% (3219/4200)\n",
      "Test Epoch: 6 | Loss: 0.732 | Acc: 76.837% (3304/4300)\n",
      "Test Epoch: 6 | Loss: 0.730 | Acc: 76.909% (3384/4400)\n",
      "Test Epoch: 6 | Loss: 0.728 | Acc: 76.956% (3463/4500)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.957% (3540/4600)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.936% (3616/4700)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.771% (3685/4800)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.653% (3756/4900)\n",
      "Test Epoch: 6 | Loss: 0.729 | Acc: 76.540% (3827/5000)\n",
      "Test Epoch: 6 | Loss: 0.723 | Acc: 76.725% (3913/5100)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.750% (3991/5200)\n",
      "Test Epoch: 6 | Loss: 0.723 | Acc: 76.792% (4070/5300)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 76.944% (4155/5400)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 76.836% (4226/5500)\n",
      "Test Epoch: 6 | Loss: 0.724 | Acc: 76.804% (4301/5600)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.772% (4376/5700)\n",
      "Test Epoch: 6 | Loss: 0.724 | Acc: 76.862% (4458/5800)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.780% (4530/5900)\n",
      "Test Epoch: 6 | Loss: 0.729 | Acc: 76.767% (4606/6000)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.770% (4683/6100)\n",
      "Test Epoch: 6 | Loss: 0.726 | Acc: 76.806% (4762/6200)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.810% (4839/6300)\n",
      "Test Epoch: 6 | Loss: 0.722 | Acc: 76.922% (4923/6400)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 77.000% (5005/6500)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 77.000% (5082/6600)\n",
      "Test Epoch: 6 | Loss: 0.718 | Acc: 77.030% (5161/6700)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.029% (5238/6800)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.029% (5315/6900)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 77.014% (5391/7000)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 77.000% (5467/7100)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 76.986% (5543/7200)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.041% (5624/7300)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.000% (5698/7400)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 76.973% (5773/7500)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.013% (5853/7600)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 76.987% (5928/7700)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 77.026% (6008/7800)\n",
      "Test Epoch: 6 | Loss: 0.718 | Acc: 77.000% (6083/7900)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 76.963% (6157/8000)\n",
      "Test Epoch: 6 | Loss: 0.718 | Acc: 77.037% (6240/8100)\n",
      "Test Epoch: 6 | Loss: 0.717 | Acc: 76.976% (6312/8200)\n",
      "Test Epoch: 6 | Loss: 0.717 | Acc: 76.988% (6390/8300)\n",
      "Test Epoch: 6 | Loss: 0.716 | Acc: 76.988% (6467/8400)\n",
      "Test Epoch: 6 | Loss: 0.717 | Acc: 76.965% (6542/8500)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 76.907% (6614/8600)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 76.897% (6690/8700)\n",
      "Test Epoch: 6 | Loss: 0.723 | Acc: 76.841% (6762/8800)\n",
      "Test Epoch: 6 | Loss: 0.724 | Acc: 76.742% (6830/8900)\n",
      "Test Epoch: 6 | Loss: 0.725 | Acc: 76.700% (6903/9000)\n",
      "Test Epoch: 6 | Loss: 0.727 | Acc: 76.692% (6979/9100)\n",
      "Test Epoch: 6 | Loss: 0.724 | Acc: 76.772% (7063/9200)\n",
      "Test Epoch: 6 | Loss: 0.723 | Acc: 76.763% (7139/9300)\n",
      "Test Epoch: 6 | Loss: 0.723 | Acc: 76.819% (7221/9400)\n",
      "Test Epoch: 6 | Loss: 0.722 | Acc: 76.832% (7299/9500)\n",
      "Test Epoch: 6 | Loss: 0.721 | Acc: 76.833% (7376/9600)\n",
      "Test Epoch: 6 | Loss: 0.719 | Acc: 76.887% (7458/9700)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 76.786% (7525/9800)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 76.747% (7598/9900)\n",
      "Test Epoch: 6 | Loss: 0.720 | Acc: 76.770% (7677/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Epoch: 7 | Loss: 0.547 | Acc: 81.250% (104/128)\n",
      "Train Epoch: 7 | Loss: 0.553 | Acc: 81.250% (208/256)\n",
      "Train Epoch: 7 | Loss: 0.543 | Acc: 83.073% (319/384)\n",
      "Train Epoch: 7 | Loss: 0.587 | Acc: 81.836% (419/512)\n",
      "Train Epoch: 7 | Loss: 0.581 | Acc: 81.719% (523/640)\n",
      "Train Epoch: 7 | Loss: 0.556 | Acc: 82.682% (635/768)\n",
      "Train Epoch: 7 | Loss: 0.546 | Acc: 82.812% (742/896)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 81.543% (835/1024)\n",
      "Train Epoch: 7 | Loss: 0.559 | Acc: 81.858% (943/1152)\n",
      "Train Epoch: 7 | Loss: 0.557 | Acc: 81.875% (1048/1280)\n",
      "Train Epoch: 7 | Loss: 0.553 | Acc: 81.747% (1151/1408)\n",
      "Train Epoch: 7 | Loss: 0.561 | Acc: 81.185% (1247/1536)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.070% (1349/1664)\n",
      "Train Epoch: 7 | Loss: 0.557 | Acc: 81.306% (1457/1792)\n",
      "Train Epoch: 7 | Loss: 0.557 | Acc: 81.354% (1562/1920)\n",
      "Train Epoch: 7 | Loss: 0.557 | Acc: 81.250% (1664/2048)\n",
      "Train Epoch: 7 | Loss: 0.558 | Acc: 81.204% (1767/2176)\n",
      "Train Epoch: 7 | Loss: 0.558 | Acc: 81.120% (1869/2304)\n",
      "Train Epoch: 7 | Loss: 0.561 | Acc: 80.921% (1968/2432)\n",
      "Train Epoch: 7 | Loss: 0.558 | Acc: 80.938% (2072/2560)\n",
      "Train Epoch: 7 | Loss: 0.559 | Acc: 80.952% (2176/2688)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.037% (2282/2816)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 81.114% (2388/2944)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 81.087% (2491/3072)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 81.156% (2597/3200)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 81.040% (2697/3328)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 81.019% (2800/3456)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.971% (2902/3584)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.927% (3004/3712)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.885% (3106/3840)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.746% (3204/3968)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.713% (3306/4096)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.611% (3405/4224)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.515% (3504/4352)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.446% (3604/4480)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.512% (3710/4608)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.553% (3815/4736)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.551% (3918/4864)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.569% (4022/4992)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.508% (4122/5120)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.545% (4227/5248)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.376% (4321/5376)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.451% (4428/5504)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.398% (4528/5632)\n",
      "Train Epoch: 7 | Loss: 0.574 | Acc: 80.382% (4630/5760)\n",
      "Train Epoch: 7 | Loss: 0.576 | Acc: 80.282% (4727/5888)\n",
      "Train Epoch: 7 | Loss: 0.574 | Acc: 80.386% (4836/6016)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.420% (4941/6144)\n",
      "Train Epoch: 7 | Loss: 0.574 | Acc: 80.373% (5041/6272)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.422% (5147/6400)\n",
      "Train Epoch: 7 | Loss: 0.575 | Acc: 80.438% (5251/6528)\n",
      "Train Epoch: 7 | Loss: 0.576 | Acc: 80.394% (5351/6656)\n",
      "Train Epoch: 7 | Loss: 0.576 | Acc: 80.366% (5452/6784)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.411% (5558/6912)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.554% (5671/7040)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.525% (5772/7168)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.482% (5872/7296)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.590% (5983/7424)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.588% (6086/7552)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.612% (6191/7680)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.699% (6301/7808)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.721% (6406/7936)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.766% (6513/8064)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.835% (6622/8192)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.853% (6727/8320)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.871% (6832/8448)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 80.982% (6945/8576)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.009% (7051/8704)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.990% (7153/8832)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.993% (7257/8960)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.052% (7366/9088)\n",
      "Train Epoch: 7 | Loss: 0.559 | Acc: 81.174% (7481/9216)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.036% (7572/9344)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.944% (7667/9472)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.938% (7770/9600)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.993% (7879/9728)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.996% (7983/9856)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.060% (8093/9984)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.032% (8194/10112)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 81.045% (8299/10240)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.970% (8395/10368)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.888% (8490/10496)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.892% (8594/10624)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 80.934% (8702/10752)\n",
      "Train Epoch: 7 | Loss: 0.560 | Acc: 80.983% (8811/10880)\n",
      "Train Epoch: 7 | Loss: 0.562 | Acc: 80.896% (8905/11008)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.873% (9006/11136)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.886% (9111/11264)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.925% (9219/11392)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.938% (9324/11520)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.924% (9426/11648)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.936% (9531/11776)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.922% (9633/11904)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.884% (9732/12032)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.888% (9836/12160)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.851% (9935/12288)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.839% (10037/12416)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.843% (10141/12544)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.863% (10247/12672)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.898% (10355/12800)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.910% (10460/12928)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.882% (10560/13056)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.894% (10665/13184)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.904% (10770/13312)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.878% (10870/13440)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.926% (10980/13568)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.914% (11082/13696)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.932% (11188/13824)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.949% (11294/13952)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.987% (11403/14080)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.990% (11507/14208)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 81.006% (11613/14336)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.980% (11713/14464)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.996% (11819/14592)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 81.005% (11924/14720)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.987% (12025/14848)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.970% (12126/14976)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.965% (12229/15104)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.941% (12329/15232)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.951% (12434/15360)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.966% (12540/15488)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.943% (12640/15616)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.939% (12743/15744)\n",
      "Train Epoch: 7 | Loss: 0.563 | Acc: 80.948% (12848/15872)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.912% (12946/16000)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.909% (13049/16128)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.912% (13153/16256)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.902% (13255/16384)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.893% (13357/16512)\n",
      "Train Epoch: 7 | Loss: 0.566 | Acc: 80.853% (13454/16640)\n",
      "Train Epoch: 7 | Loss: 0.564 | Acc: 80.910% (13567/16768)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.877% (13665/16896)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.874% (13768/17024)\n",
      "Train Epoch: 7 | Loss: 0.565 | Acc: 80.877% (13872/17152)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.845% (13970/17280)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.825% (14070/17408)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.777% (14165/17536)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.757% (14265/17664)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.733% (14364/17792)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.692% (14460/17920)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.668% (14559/18048)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.689% (14666/18176)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.660% (14764/18304)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.691% (14873/18432)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.738% (14985/18560)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.731% (15087/18688)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.761% (15196/18816)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.722% (15292/18944)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.731% (15397/19072)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.714% (15497/19200)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.769% (15611/19328)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.762% (15713/19456)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.770% (15818/19584)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.753% (15918/19712)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.746% (16020/19840)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.734% (16121/19968)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.713% (16220/20096)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.686% (16318/20224)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.690% (16422/20352)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.698% (16527/20480)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.697% (16630/20608)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.671% (16728/20736)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.637% (16824/20864)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.621% (16924/20992)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.649% (17033/21120)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.643% (17135/21248)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.618% (17233/21376)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.645% (17342/21504)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.672% (17451/21632)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.676% (17555/21760)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.674% (17658/21888)\n",
      "Train Epoch: 7 | Loss: 0.567 | Acc: 80.664% (17759/22016)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.645% (17858/22144)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.644% (17961/22272)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.634% (18062/22400)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.629% (18164/22528)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.610% (18263/22656)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.605% (18365/22784)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.626% (18473/22912)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.642% (18580/23040)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.663% (18688/23168)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.658% (18790/23296)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.652% (18892/23424)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.651% (18995/23552)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.671% (19103/23680)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.670% (19206/23808)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.669% (19309/23936)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.664% (19411/24064)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.675% (19517/24192)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.670% (19619/24320)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.657% (19719/24448)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.627% (19815/24576)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.614% (19915/24704)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.602% (20015/24832)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.601% (20118/24960)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.580% (20216/25088)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.544% (20310/25216)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.536% (20411/25344)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.520% (20510/25472)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.512% (20611/25600)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.508% (20713/25728)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.500% (20814/25856)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.469% (20909/25984)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.461% (21010/26112)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.446% (21109/26240)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.446% (21212/26368)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.439% (21313/26496)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.439% (21416/26624)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.465% (21526/26752)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.465% (21629/26880)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.450% (21728/27008)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.439% (21828/27136)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.454% (21935/27264)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.458% (22039/27392)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.498% (22153/27520)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.501% (22257/27648)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.480% (22354/27776)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.494% (22461/27904)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.479% (22560/28032)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.490% (22666/28160)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.483% (22767/28288)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.448% (22860/28416)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.455% (22965/28544)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.458% (23069/28672)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.486% (23180/28800)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.493% (23285/28928)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.510% (23393/29056)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.482% (23488/29184)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.472% (23588/29312)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.455% (23686/29440)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.459% (23790/29568)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.455% (23892/29696)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.429% (23987/29824)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.439% (24093/29952)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.436% (24195/30080)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.449% (24302/30208)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.456% (24407/30336)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.446% (24507/30464)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.456% (24613/30592)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.479% (24723/30720)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.472% (24824/30848)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.478% (24929/30976)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.482% (25033/31104)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.456% (25128/31232)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.440% (25226/31360)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.447% (25331/31488)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.459% (25438/31616)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.475% (25546/31744)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.481% (25651/31872)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.500% (25760/32000)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.453% (25848/32128)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.444% (25948/32256)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.441% (26050/32384)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.435% (26151/32512)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.426% (26251/32640)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.417% (26351/32768)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.429% (26458/32896)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.411% (26555/33024)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.405% (26656/33152)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.406% (26759/33280)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.382% (26854/33408)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.367% (26952/33536)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.371% (27056/33664)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.356% (27154/33792)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.380% (27265/33920)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.372% (27365/34048)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.360% (27464/34176)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.367% (27569/34304)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.385% (27678/34432)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.356% (27771/34560)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.351% (27872/34688)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.360% (27978/34816)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.357% (28080/34944)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.369% (28187/35072)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.369% (28290/35200)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.358% (28389/35328)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.356% (28491/35456)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.362% (28596/35584)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.354% (28696/35712)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.382% (28809/35840)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.371% (28908/35968)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.372% (29011/36096)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.361% (29110/36224)\n",
      "Train Epoch: 7 | Loss: 0.573 | Acc: 80.372% (29217/36352)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.392% (29327/36480)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.411% (29437/36608)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.412% (29540/36736)\n",
      "Train Epoch: 7 | Loss: 0.572 | Acc: 80.409% (29642/36864)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.420% (29749/36992)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.423% (29853/37120)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.426% (29957/37248)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.410% (30054/37376)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.423% (30162/37504)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.437% (30270/37632)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.429% (30370/37760)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.434% (30475/37888)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.437% (30579/38016)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.453% (30688/38144)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.469% (30797/38272)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.469% (30900/38400)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.466% (31002/38528)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.464% (31104/38656)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.456% (31204/38784)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.458% (31308/38912)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.466% (31414/39040)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.484% (31524/39168)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.489% (31629/39296)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.487% (31731/39424)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.479% (31831/39552)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.491% (31939/39680)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.486% (32040/39808)\n",
      "Train Epoch: 7 | Loss: 0.571 | Acc: 80.471% (32137/39936)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.481% (32244/40064)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.501% (32355/40192)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.496% (32456/40320)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.496% (32559/40448)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.488% (32659/40576)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.483% (32760/40704)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.469% (32857/40832)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.481% (32965/40960)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.481% (33068/41088)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.486% (33173/41216)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.498% (33281/41344)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.495% (33383/41472)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.486% (33482/41600)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.493% (33588/41728)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.471% (33682/41856)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.478% (33788/41984)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.490% (33896/42112)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.488% (33998/42240)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.497% (34105/42368)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.504% (34211/42496)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.513% (34318/42624)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.509% (34419/42752)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.511% (34523/42880)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.513% (34627/43008)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.506% (34727/43136)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.515% (34834/43264)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.524% (34941/43392)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.531% (35047/43520)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.515% (35143/43648)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.524% (35250/43776)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.544% (35362/43904)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.526% (35457/44032)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.537% (35565/44160)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.525% (35663/44288)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.523% (35765/44416)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.525% (35869/44544)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.522% (35971/44672)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.513% (36070/44800)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.495% (36165/44928)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.500% (36270/45056)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.486% (36367/45184)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.489% (36471/45312)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.484% (36572/45440)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.499% (36682/45568)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.508% (36789/45696)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.499% (36888/45824)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.508% (36995/45952)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.523% (37105/46080)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.514% (37204/46208)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.527% (37313/46336)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.516% (37411/46464)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.507% (37510/46592)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.501% (37610/46720)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.520% (37722/46848)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.513% (37822/46976)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.511% (37924/47104)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.511% (38027/47232)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.503% (38126/47360)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.496% (38226/47488)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.494% (38328/47616)\n",
      "Train Epoch: 7 | Loss: 0.570 | Acc: 80.492% (38430/47744)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.508% (38541/47872)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.500% (38640/48000)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.508% (38747/48128)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.514% (38853/48256)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.510% (38954/48384)\n",
      "Train Epoch: 7 | Loss: 0.569 | Acc: 80.518% (39061/48512)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.537% (39173/48640)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.520% (39268/48768)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.532% (39377/48896)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.542% (39485/49024)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.544% (39589/49152)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.540% (39690/49280)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.546% (39796/49408)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.549% (39901/49536)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.537% (39998/49664)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.527% (40096/49792)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.523% (40197/49920)\n",
      "Train Epoch: 7 | Loss: 0.568 | Acc: 80.534% (40267/50000)\n",
      "Test Epoch: 7 | Loss: 0.558 | Acc: 82.000% (82/100)\n",
      "Test Epoch: 7 | Loss: 0.515 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 7 | Loss: 0.510 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 7 | Loss: 0.526 | Acc: 83.250% (333/400)\n",
      "Test Epoch: 7 | Loss: 0.516 | Acc: 83.400% (417/500)\n",
      "Test Epoch: 7 | Loss: 0.508 | Acc: 83.333% (500/600)\n",
      "Test Epoch: 7 | Loss: 0.516 | Acc: 83.286% (583/700)\n",
      "Test Epoch: 7 | Loss: 0.561 | Acc: 81.750% (654/800)\n",
      "Test Epoch: 7 | Loss: 0.580 | Acc: 81.000% (729/900)\n",
      "Test Epoch: 7 | Loss: 0.595 | Acc: 80.700% (807/1000)\n",
      "Test Epoch: 7 | Loss: 0.605 | Acc: 80.636% (887/1100)\n",
      "Test Epoch: 7 | Loss: 0.606 | Acc: 80.583% (967/1200)\n",
      "Test Epoch: 7 | Loss: 0.603 | Acc: 80.615% (1048/1300)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.857% (1132/1400)\n",
      "Test Epoch: 7 | Loss: 0.585 | Acc: 80.933% (1214/1500)\n",
      "Test Epoch: 7 | Loss: 0.596 | Acc: 80.688% (1291/1600)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 81.118% (1379/1700)\n",
      "Test Epoch: 7 | Loss: 0.599 | Acc: 80.611% (1451/1800)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.737% (1534/1900)\n",
      "Test Epoch: 7 | Loss: 0.603 | Acc: 80.450% (1609/2000)\n",
      "Test Epoch: 7 | Loss: 0.599 | Acc: 80.524% (1691/2100)\n",
      "Test Epoch: 7 | Loss: 0.597 | Acc: 80.409% (1769/2200)\n",
      "Test Epoch: 7 | Loss: 0.600 | Acc: 80.348% (1848/2300)\n",
      "Test Epoch: 7 | Loss: 0.599 | Acc: 80.417% (1930/2400)\n",
      "Test Epoch: 7 | Loss: 0.606 | Acc: 80.080% (2002/2500)\n",
      "Test Epoch: 7 | Loss: 0.613 | Acc: 80.038% (2081/2600)\n",
      "Test Epoch: 7 | Loss: 0.609 | Acc: 80.111% (2163/2700)\n",
      "Test Epoch: 7 | Loss: 0.607 | Acc: 80.143% (2244/2800)\n",
      "Test Epoch: 7 | Loss: 0.605 | Acc: 80.207% (2326/2900)\n",
      "Test Epoch: 7 | Loss: 0.602 | Acc: 80.167% (2405/3000)\n",
      "Test Epoch: 7 | Loss: 0.602 | Acc: 80.226% (2487/3100)\n",
      "Test Epoch: 7 | Loss: 0.596 | Acc: 80.375% (2572/3200)\n",
      "Test Epoch: 7 | Loss: 0.599 | Acc: 80.303% (2650/3300)\n",
      "Test Epoch: 7 | Loss: 0.602 | Acc: 79.971% (2719/3400)\n",
      "Test Epoch: 7 | Loss: 0.607 | Acc: 79.771% (2792/3500)\n",
      "Test Epoch: 7 | Loss: 0.606 | Acc: 79.806% (2873/3600)\n",
      "Test Epoch: 7 | Loss: 0.609 | Acc: 79.703% (2949/3700)\n",
      "Test Epoch: 7 | Loss: 0.609 | Acc: 79.684% (3028/3800)\n",
      "Test Epoch: 7 | Loss: 0.605 | Acc: 79.821% (3113/3900)\n",
      "Test Epoch: 7 | Loss: 0.603 | Acc: 79.825% (3193/4000)\n",
      "Test Epoch: 7 | Loss: 0.601 | Acc: 79.805% (3272/4100)\n",
      "Test Epoch: 7 | Loss: 0.604 | Acc: 79.786% (3351/4200)\n",
      "Test Epoch: 7 | Loss: 0.600 | Acc: 79.953% (3438/4300)\n",
      "Test Epoch: 7 | Loss: 0.598 | Acc: 80.114% (3525/4400)\n",
      "Test Epoch: 7 | Loss: 0.597 | Acc: 80.133% (3606/4500)\n",
      "Test Epoch: 7 | Loss: 0.597 | Acc: 80.109% (3685/4600)\n",
      "Test Epoch: 7 | Loss: 0.595 | Acc: 80.149% (3767/4700)\n",
      "Test Epoch: 7 | Loss: 0.596 | Acc: 80.083% (3844/4800)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.184% (3929/4900)\n",
      "Test Epoch: 7 | Loss: 0.595 | Acc: 80.140% (4007/5000)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.216% (4091/5100)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.096% (4165/5200)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.132% (4247/5300)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.074% (4324/5400)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.055% (4403/5500)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.161% (4489/5600)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.070% (4564/5700)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.172% (4650/5800)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.102% (4726/5900)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.100% (4806/6000)\n",
      "Test Epoch: 7 | Loss: 0.595 | Acc: 80.115% (4887/6100)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.161% (4970/6200)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.159% (5050/6300)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.219% (5134/6400)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.169% (5211/6500)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.091% (5286/6600)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.149% (5370/6700)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.162% (5451/6800)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.174% (5532/6900)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.071% (5605/7000)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.127% (5689/7100)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.208% (5775/7200)\n",
      "Test Epoch: 7 | Loss: 0.589 | Acc: 80.288% (5861/7300)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.297% (5942/7400)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.213% (6016/7500)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.197% (6095/7600)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.169% (6173/7700)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.154% (6252/7800)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.152% (6332/7900)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.112% (6409/8000)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.198% (6496/8100)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.244% (6580/8200)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.241% (6660/8300)\n",
      "Test Epoch: 7 | Loss: 0.589 | Acc: 80.321% (6747/8400)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.176% (6815/8500)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.244% (6901/8600)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.253% (6982/8700)\n",
      "Test Epoch: 7 | Loss: 0.592 | Acc: 80.227% (7060/8800)\n",
      "Test Epoch: 7 | Loss: 0.593 | Acc: 80.213% (7139/8900)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.244% (7222/9000)\n",
      "Test Epoch: 7 | Loss: 0.594 | Acc: 80.209% (7299/9100)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.293% (7387/9200)\n",
      "Test Epoch: 7 | Loss: 0.591 | Acc: 80.280% (7466/9300)\n",
      "Test Epoch: 7 | Loss: 0.590 | Acc: 80.330% (7551/9400)\n",
      "Test Epoch: 7 | Loss: 0.589 | Acc: 80.337% (7632/9500)\n",
      "Test Epoch: 7 | Loss: 0.589 | Acc: 80.333% (7712/9600)\n",
      "Test Epoch: 7 | Loss: 0.586 | Acc: 80.423% (7801/9700)\n",
      "Test Epoch: 7 | Loss: 0.588 | Acc: 80.367% (7876/9800)\n",
      "Test Epoch: 7 | Loss: 0.588 | Acc: 80.374% (7957/9900)\n",
      "Test Epoch: 7 | Loss: 0.588 | Acc: 80.380% (8038/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "Train Epoch: 8 | Loss: 0.507 | Acc: 86.719% (111/128)\n",
      "Train Epoch: 8 | Loss: 0.449 | Acc: 86.328% (221/256)\n",
      "Train Epoch: 8 | Loss: 0.490 | Acc: 85.417% (328/384)\n",
      "Train Epoch: 8 | Loss: 0.511 | Acc: 83.398% (427/512)\n",
      "Train Epoch: 8 | Loss: 0.532 | Acc: 81.406% (521/640)\n",
      "Train Epoch: 8 | Loss: 0.525 | Acc: 82.031% (630/768)\n",
      "Train Epoch: 8 | Loss: 0.524 | Acc: 82.143% (736/896)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.738% (837/1024)\n",
      "Train Epoch: 8 | Loss: 0.534 | Acc: 81.858% (943/1152)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.562% (1044/1280)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.605% (1149/1408)\n",
      "Train Epoch: 8 | Loss: 0.555 | Acc: 80.794% (1241/1536)\n",
      "Train Epoch: 8 | Loss: 0.563 | Acc: 80.950% (1347/1664)\n",
      "Train Epoch: 8 | Loss: 0.558 | Acc: 80.971% (1451/1792)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.302% (1561/1920)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.445% (1668/2048)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.572% (1775/2176)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.337% (1874/2304)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.209% (1975/2432)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.211% (2079/2560)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.324% (2186/2688)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.392% (2292/2816)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.352% (2395/2944)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.250% (2496/3072)\n",
      "Train Epoch: 8 | Loss: 0.538 | Acc: 81.219% (2599/3200)\n",
      "Train Epoch: 8 | Loss: 0.538 | Acc: 81.190% (2702/3328)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.221% (2807/3456)\n",
      "Train Epoch: 8 | Loss: 0.533 | Acc: 81.362% (2916/3584)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.304% (3018/3712)\n",
      "Train Epoch: 8 | Loss: 0.534 | Acc: 81.380% (3125/3840)\n",
      "Train Epoch: 8 | Loss: 0.533 | Acc: 81.477% (3233/3968)\n",
      "Train Epoch: 8 | Loss: 0.531 | Acc: 81.421% (3335/4096)\n",
      "Train Epoch: 8 | Loss: 0.531 | Acc: 81.416% (3439/4224)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.641% (3553/4352)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.540% (3653/4480)\n",
      "Train Epoch: 8 | Loss: 0.524 | Acc: 81.554% (3758/4608)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.398% (3855/4736)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.394% (3959/4864)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.370% (4062/4992)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.348% (4165/5120)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.364% (4270/5248)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.362% (4374/5376)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.377% (4479/5504)\n",
      "Train Epoch: 8 | Loss: 0.529 | Acc: 81.286% (4578/5632)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.337% (4685/5760)\n",
      "Train Epoch: 8 | Loss: 0.530 | Acc: 81.369% (4791/5888)\n",
      "Train Epoch: 8 | Loss: 0.530 | Acc: 81.433% (4899/6016)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.592% (5013/6144)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.617% (5119/6272)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.609% (5223/6400)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.602% (5327/6528)\n",
      "Train Epoch: 8 | Loss: 0.525 | Acc: 81.701% (5438/6656)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.692% (5542/6784)\n",
      "Train Epoch: 8 | Loss: 0.523 | Acc: 81.814% (5655/6912)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.847% (5762/7040)\n",
      "Train Epoch: 8 | Loss: 0.523 | Acc: 81.738% (5859/7168)\n",
      "Train Epoch: 8 | Loss: 0.523 | Acc: 81.757% (5965/7296)\n",
      "Train Epoch: 8 | Loss: 0.524 | Acc: 81.695% (6065/7424)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.766% (6175/7552)\n",
      "Train Epoch: 8 | Loss: 0.521 | Acc: 81.836% (6285/7680)\n",
      "Train Epoch: 8 | Loss: 0.521 | Acc: 81.865% (6392/7808)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.830% (6494/7936)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.808% (6597/8064)\n",
      "Train Epoch: 8 | Loss: 0.521 | Acc: 81.885% (6708/8192)\n",
      "Train Epoch: 8 | Loss: 0.521 | Acc: 81.935% (6817/8320)\n",
      "Train Epoch: 8 | Loss: 0.520 | Acc: 81.937% (6922/8448)\n",
      "Train Epoch: 8 | Loss: 0.519 | Acc: 81.985% (7031/8576)\n",
      "Train Epoch: 8 | Loss: 0.520 | Acc: 81.974% (7135/8704)\n",
      "Train Epoch: 8 | Loss: 0.519 | Acc: 81.952% (7238/8832)\n",
      "Train Epoch: 8 | Loss: 0.521 | Acc: 81.842% (7333/8960)\n",
      "Train Epoch: 8 | Loss: 0.523 | Acc: 81.778% (7432/9088)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.793% (7538/9216)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.742% (7638/9344)\n",
      "Train Epoch: 8 | Loss: 0.522 | Acc: 81.778% (7746/9472)\n",
      "Train Epoch: 8 | Loss: 0.523 | Acc: 81.781% (7851/9600)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.651% (7943/9728)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.585% (8041/9856)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.591% (8146/9984)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.646% (8256/10112)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.660% (8362/10240)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.665% (8467/10368)\n",
      "Train Epoch: 8 | Loss: 0.526 | Acc: 81.679% (8573/10496)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.702% (8680/10624)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.687% (8783/10752)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.664% (8885/10880)\n",
      "Train Epoch: 8 | Loss: 0.528 | Acc: 81.650% (8988/11008)\n",
      "Train Epoch: 8 | Loss: 0.530 | Acc: 81.591% (9086/11136)\n",
      "Train Epoch: 8 | Loss: 0.529 | Acc: 81.650% (9197/11264)\n",
      "Train Epoch: 8 | Loss: 0.527 | Acc: 81.680% (9305/11392)\n",
      "Train Epoch: 8 | Loss: 0.529 | Acc: 81.649% (9406/11520)\n",
      "Train Epoch: 8 | Loss: 0.530 | Acc: 81.611% (9506/11648)\n",
      "Train Epoch: 8 | Loss: 0.531 | Acc: 81.573% (9606/11776)\n",
      "Train Epoch: 8 | Loss: 0.532 | Acc: 81.536% (9706/11904)\n",
      "Train Epoch: 8 | Loss: 0.532 | Acc: 81.533% (9810/12032)\n",
      "Train Epoch: 8 | Loss: 0.533 | Acc: 81.439% (9903/12160)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.396% (10002/12288)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.363% (10102/12416)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.386% (10209/12544)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.384% (10313/12672)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.422% (10422/12800)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.443% (10529/12928)\n",
      "Train Epoch: 8 | Loss: 0.534 | Acc: 81.441% (10633/13056)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.424% (10735/13184)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.438% (10841/13312)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.421% (10943/13440)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.420% (11047/13568)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.433% (11153/13696)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.424% (11256/13824)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.379% (11354/13952)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.413% (11463/14080)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.454% (11573/14208)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.473% (11680/14336)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.457% (11782/14464)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.421% (11881/14592)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.461% (11991/14720)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.479% (12098/14848)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.437% (12196/14976)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.442% (12301/15104)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.486% (12412/15232)\n",
      "Train Epoch: 8 | Loss: 0.536 | Acc: 81.497% (12518/15360)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.547% (12630/15488)\n",
      "Train Epoch: 8 | Loss: 0.535 | Acc: 81.525% (12731/15616)\n",
      "Train Epoch: 8 | Loss: 0.537 | Acc: 81.472% (12827/15744)\n",
      "Train Epoch: 8 | Loss: 0.538 | Acc: 81.445% (12927/15872)\n",
      "Train Epoch: 8 | Loss: 0.538 | Acc: 81.475% (13036/16000)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.479% (13141/16128)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.478% (13245/16256)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.470% (13348/16384)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.426% (13445/16512)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.454% (13554/16640)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.411% (13651/16768)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.422% (13757/16896)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.420% (13861/17024)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.413% (13964/17152)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.400% (14066/17280)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.394% (14169/17408)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.410% (14276/17536)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.352% (14370/17664)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.374% (14478/17792)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.395% (14586/17920)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.366% (14685/18048)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.355% (14787/18176)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.381% (14896/18304)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.364% (14997/18432)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.342% (15097/18560)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.282% (15190/18688)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.298% (15297/18816)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.276% (15397/18944)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.292% (15504/19072)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.276% (15605/19200)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.312% (15716/19328)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.260% (15810/19456)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.311% (15924/19584)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.296% (16025/19712)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.275% (16125/19840)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.245% (16223/19968)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.255% (16329/20096)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.245% (16431/20224)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.225% (16531/20352)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.235% (16637/20480)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.240% (16742/20608)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.240% (16846/20736)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.236% (16949/20864)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.231% (17052/20992)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.226% (17155/21120)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.226% (17259/21248)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.231% (17364/21376)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.236% (17469/21504)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.273% (17581/21632)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.278% (17686/21760)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.287% (17792/21888)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.291% (17897/22016)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.282% (17999/22144)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.263% (18099/22272)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.263% (18203/22400)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.299% (18315/22528)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.290% (18417/22656)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.294% (18522/22784)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.302% (18628/22912)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.289% (18729/23040)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.306% (18837/23168)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.323% (18945/23296)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.318% (19048/23424)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.326% (19154/23552)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.318% (19256/23680)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.351% (19368/23808)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.329% (19467/23936)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.333% (19572/24064)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.324% (19674/24192)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.336% (19781/24320)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.348% (19888/24448)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.319% (19985/24576)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.307% (20086/24704)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.294% (20187/24832)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.302% (20293/24960)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.330% (20404/25088)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.306% (20502/25216)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.309% (20607/25344)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.297% (20708/25472)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.277% (20807/25600)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.266% (20908/25728)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.273% (21014/25856)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.292% (21123/25984)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.288% (21226/26112)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.300% (21333/26240)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.284% (21433/26368)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.284% (21537/26496)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.291% (21643/26624)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.284% (21745/26752)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.287% (21850/26880)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.283% (21953/27008)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.298% (22061/27136)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.290% (22163/27264)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.279% (22264/27392)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.275% (22367/27520)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.304% (22479/27648)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.333% (22591/27776)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.347% (22699/27904)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.353% (22805/28032)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.364% (22912/28160)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.367% (23017/28288)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.373% (23123/28416)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.348% (23220/28544)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.362% (23328/28672)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.354% (23430/28800)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.368% (23538/28928)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.377% (23645/29056)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.387% (23752/29184)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.397% (23859/29312)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.423% (23971/29440)\n",
      "Train Epoch: 8 | Loss: 0.539 | Acc: 81.409% (24071/29568)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.408% (24175/29696)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.387% (24273/29824)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.384% (24376/29952)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.383% (24480/30080)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.406% (24591/30208)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.388% (24690/30336)\n",
      "Train Epoch: 8 | Loss: 0.540 | Acc: 81.414% (24802/30464)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.397% (24901/30592)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.396% (25005/30720)\n",
      "Train Epoch: 8 | Loss: 0.541 | Acc: 81.389% (25107/30848)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.379% (25208/30976)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.385% (25314/31104)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.378% (25416/31232)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.365% (25516/31360)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.368% (25621/31488)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.351% (25720/31616)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.345% (25822/31744)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.303% (25913/31872)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.294% (26014/32000)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.287% (26116/32128)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.293% (26222/32256)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.284% (26323/32384)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.278% (26425/32512)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.275% (26528/32640)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.259% (26627/32768)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.244% (26726/32896)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.235% (26827/33024)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.217% (26925/33152)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.229% (27033/33280)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.238% (27140/33408)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.229% (27241/33536)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.214% (27340/33664)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.229% (27449/33792)\n",
      "Train Epoch: 8 | Loss: 0.546 | Acc: 81.232% (27554/33920)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.250% (27664/34048)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.279% (27778/34176)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.276% (27881/34304)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.279% (27986/34432)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.267% (28086/34560)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.282% (28195/34688)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.287% (28301/34816)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.290% (28406/34944)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.307% (28516/35072)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.318% (28624/35200)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.298% (28721/35328)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.289% (28822/35456)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.284% (28924/35584)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.300% (29034/35712)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.295% (29136/35840)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.278% (29234/35968)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.292% (29343/36096)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.297% (29449/36224)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.316% (29560/36352)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.313% (29663/36480)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.302% (29763/36608)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.315% (29872/36736)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.318% (29977/36864)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.318% (30081/36992)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.320% (30186/37120)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.322% (30291/37248)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.317% (30393/37376)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.317% (30497/37504)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.314% (30600/37632)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.308% (30702/37760)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.298% (30802/37888)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.311% (30911/38016)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.308% (31014/38144)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.302% (31116/38272)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.312% (31224/38400)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.299% (31323/38528)\n",
      "Train Epoch: 8 | Loss: 0.545 | Acc: 81.294% (31425/38656)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.302% (31532/38784)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.296% (31634/38912)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.314% (31745/39040)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.286% (31838/39168)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.291% (31944/39296)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.296% (32050/39424)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.313% (32161/39552)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.323% (32269/39680)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.335% (32378/39808)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.343% (32485/39936)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.352% (32593/40064)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.357% (32699/40192)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.354% (32802/40320)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.359% (32908/40448)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.354% (33010/40576)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.353% (33114/40704)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.353% (33218/40832)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.360% (33325/40960)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.367% (33432/41088)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.364% (33535/41216)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.361% (33638/41344)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.380% (33750/41472)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.392% (33859/41600)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.389% (33962/41728)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.389% (34066/41856)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.393% (34172/41984)\n",
      "Train Epoch: 8 | Loss: 0.542 | Acc: 81.388% (34274/42112)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.383% (34376/42240)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.359% (34470/42368)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.363% (34576/42496)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.367% (34682/42624)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.369% (34787/42752)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.367% (34890/42880)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.366% (34994/43008)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.380% (35104/43136)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.370% (35204/43264)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.365% (35306/43392)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.374% (35414/43520)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.371% (35517/43648)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.364% (35618/43776)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.359% (35720/43904)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.366% (35827/44032)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.365% (35931/44160)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.367% (36036/44288)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.354% (36134/44416)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.335% (36230/44544)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.333% (36333/44672)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.319% (36431/44800)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.326% (36538/44928)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.323% (36641/45056)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.341% (36753/45184)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.338% (36856/45312)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.334% (36958/45440)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.329% (37060/45568)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.322% (37161/45696)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.331% (37269/45824)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.359% (37386/45952)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.361% (37491/46080)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.360% (37595/46208)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.362% (37700/46336)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.373% (37809/46464)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.402% (37927/46592)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.391% (38026/46720)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.399% (38134/46848)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.393% (38235/46976)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.380% (38333/47104)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.386% (38440/47232)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.391% (38547/47360)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.391% (38651/47488)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.384% (38752/47616)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.376% (38852/47744)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.386% (38961/47872)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.373% (39059/48000)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.366% (39160/48128)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.358% (39260/48256)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.360% (39365/48384)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.365% (39472/48512)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.357% (39572/48640)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.338% (39667/48768)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.344% (39774/48896)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.362% (39887/49024)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.370% (39995/49152)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.358% (40093/49280)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.363% (40200/49408)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.361% (40303/49536)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.363% (40408/49664)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.377% (40519/49792)\n",
      "Train Epoch: 8 | Loss: 0.544 | Acc: 81.374% (40622/49920)\n",
      "Train Epoch: 8 | Loss: 0.543 | Acc: 81.372% (40686/50000)\n",
      "Test Epoch: 8 | Loss: 0.584 | Acc: 80.000% (80/100)\n",
      "Test Epoch: 8 | Loss: 0.486 | Acc: 82.000% (164/200)\n",
      "Test Epoch: 8 | Loss: 0.504 | Acc: 81.667% (245/300)\n",
      "Test Epoch: 8 | Loss: 0.516 | Acc: 81.500% (326/400)\n",
      "Test Epoch: 8 | Loss: 0.512 | Acc: 81.800% (409/500)\n",
      "Test Epoch: 8 | Loss: 0.495 | Acc: 82.500% (495/600)\n",
      "Test Epoch: 8 | Loss: 0.507 | Acc: 81.429% (570/700)\n",
      "Test Epoch: 8 | Loss: 0.541 | Acc: 80.125% (641/800)\n",
      "Test Epoch: 8 | Loss: 0.566 | Acc: 79.333% (714/900)\n",
      "Test Epoch: 8 | Loss: 0.575 | Acc: 79.300% (793/1000)\n",
      "Test Epoch: 8 | Loss: 0.581 | Acc: 79.364% (873/1100)\n",
      "Test Epoch: 8 | Loss: 0.581 | Acc: 79.667% (956/1200)\n",
      "Test Epoch: 8 | Loss: 0.580 | Acc: 79.385% (1032/1300)\n",
      "Test Epoch: 8 | Loss: 0.579 | Acc: 79.357% (1111/1400)\n",
      "Test Epoch: 8 | Loss: 0.583 | Acc: 79.467% (1192/1500)\n",
      "Test Epoch: 8 | Loss: 0.586 | Acc: 79.312% (1269/1600)\n",
      "Test Epoch: 8 | Loss: 0.581 | Acc: 79.706% (1355/1700)\n",
      "Test Epoch: 8 | Loss: 0.581 | Acc: 79.722% (1435/1800)\n",
      "Test Epoch: 8 | Loss: 0.574 | Acc: 80.000% (1520/1900)\n",
      "Test Epoch: 8 | Loss: 0.576 | Acc: 79.950% (1599/2000)\n",
      "Test Epoch: 8 | Loss: 0.577 | Acc: 79.810% (1676/2100)\n",
      "Test Epoch: 8 | Loss: 0.576 | Acc: 79.818% (1756/2200)\n",
      "Test Epoch: 8 | Loss: 0.581 | Acc: 79.783% (1835/2300)\n",
      "Test Epoch: 8 | Loss: 0.580 | Acc: 79.917% (1918/2400)\n",
      "Test Epoch: 8 | Loss: 0.592 | Acc: 79.640% (1991/2500)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.385% (2064/2600)\n",
      "Test Epoch: 8 | Loss: 0.596 | Acc: 79.593% (2149/2700)\n",
      "Test Epoch: 8 | Loss: 0.592 | Acc: 79.643% (2230/2800)\n",
      "Test Epoch: 8 | Loss: 0.595 | Acc: 79.655% (2310/2900)\n",
      "Test Epoch: 8 | Loss: 0.595 | Acc: 79.700% (2391/3000)\n",
      "Test Epoch: 8 | Loss: 0.594 | Acc: 79.613% (2468/3100)\n",
      "Test Epoch: 8 | Loss: 0.594 | Acc: 79.500% (2544/3200)\n",
      "Test Epoch: 8 | Loss: 0.593 | Acc: 79.485% (2623/3300)\n",
      "Test Epoch: 8 | Loss: 0.597 | Acc: 79.294% (2696/3400)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.257% (2774/3500)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.417% (2859/3600)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.432% (2939/3700)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.474% (3020/3800)\n",
      "Test Epoch: 8 | Loss: 0.600 | Acc: 79.590% (3104/3900)\n",
      "Test Epoch: 8 | Loss: 0.599 | Acc: 79.575% (3183/4000)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.488% (3259/4100)\n",
      "Test Epoch: 8 | Loss: 0.599 | Acc: 79.643% (3345/4200)\n",
      "Test Epoch: 8 | Loss: 0.596 | Acc: 79.767% (3430/4300)\n",
      "Test Epoch: 8 | Loss: 0.594 | Acc: 79.886% (3515/4400)\n",
      "Test Epoch: 8 | Loss: 0.593 | Acc: 79.867% (3594/4500)\n",
      "Test Epoch: 8 | Loss: 0.595 | Acc: 79.783% (3670/4600)\n",
      "Test Epoch: 8 | Loss: 0.595 | Acc: 79.681% (3745/4700)\n",
      "Test Epoch: 8 | Loss: 0.599 | Acc: 79.583% (3820/4800)\n",
      "Test Epoch: 8 | Loss: 0.597 | Acc: 79.633% (3902/4900)\n",
      "Test Epoch: 8 | Loss: 0.599 | Acc: 79.540% (3977/5000)\n",
      "Test Epoch: 8 | Loss: 0.595 | Acc: 79.588% (4059/5100)\n",
      "Test Epoch: 8 | Loss: 0.597 | Acc: 79.519% (4135/5200)\n",
      "Test Epoch: 8 | Loss: 0.597 | Acc: 79.528% (4215/5300)\n",
      "Test Epoch: 8 | Loss: 0.596 | Acc: 79.574% (4297/5400)\n",
      "Test Epoch: 8 | Loss: 0.599 | Acc: 79.491% (4372/5500)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.411% (4447/5600)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.509% (4532/5700)\n",
      "Test Epoch: 8 | Loss: 0.598 | Acc: 79.655% (4620/5800)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.492% (4690/5900)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.517% (4771/6000)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.508% (4850/6100)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.452% (4926/6200)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.476% (5007/6300)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.609% (5095/6400)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.538% (5170/6500)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.591% (5253/6600)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.657% (5337/6700)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.632% (5415/6800)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.565% (5490/6900)\n",
      "Test Epoch: 8 | Loss: 0.606 | Acc: 79.514% (5566/7000)\n",
      "Test Epoch: 8 | Loss: 0.608 | Acc: 79.479% (5643/7100)\n",
      "Test Epoch: 8 | Loss: 0.607 | Acc: 79.444% (5720/7200)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.575% (5809/7300)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.568% (5888/7400)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.560% (5967/7500)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.605% (6050/7600)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.636% (6132/7700)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.679% (6215/7800)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.671% (6294/7900)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.688% (6375/8000)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.679% (6454/8100)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.646% (6531/8200)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.639% (6610/8300)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.595% (6686/8400)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.494% (6757/8500)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.465% (6834/8600)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.414% (6909/8700)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.409% (6988/8800)\n",
      "Test Epoch: 8 | Loss: 0.606 | Acc: 79.393% (7066/8900)\n",
      "Test Epoch: 8 | Loss: 0.607 | Acc: 79.433% (7149/9000)\n",
      "Test Epoch: 8 | Loss: 0.606 | Acc: 79.440% (7229/9100)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.500% (7314/9200)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.473% (7391/9300)\n",
      "Test Epoch: 8 | Loss: 0.605 | Acc: 79.457% (7469/9400)\n",
      "Test Epoch: 8 | Loss: 0.604 | Acc: 79.484% (7551/9500)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.510% (7633/9600)\n",
      "Test Epoch: 8 | Loss: 0.601 | Acc: 79.577% (7719/9700)\n",
      "Test Epoch: 8 | Loss: 0.602 | Acc: 79.520% (7793/9800)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.475% (7868/9900)\n",
      "Test Epoch: 8 | Loss: 0.603 | Acc: 79.490% (7949/10000)\n",
      "\n",
      "Epoch: 9\n",
      "Train Epoch: 9 | Loss: 0.648 | Acc: 75.781% (97/128)\n",
      "Train Epoch: 9 | Loss: 0.580 | Acc: 79.688% (204/256)\n",
      "Train Epoch: 9 | Loss: 0.541 | Acc: 82.031% (315/384)\n",
      "Train Epoch: 9 | Loss: 0.566 | Acc: 81.250% (416/512)\n",
      "Train Epoch: 9 | Loss: 0.535 | Acc: 82.656% (529/640)\n",
      "Train Epoch: 9 | Loss: 0.528 | Acc: 82.943% (637/768)\n",
      "Train Epoch: 9 | Loss: 0.534 | Acc: 82.366% (738/896)\n",
      "Train Epoch: 9 | Loss: 0.537 | Acc: 82.227% (842/1024)\n",
      "Train Epoch: 9 | Loss: 0.544 | Acc: 81.944% (944/1152)\n",
      "Train Epoch: 9 | Loss: 0.535 | Acc: 82.578% (1057/1280)\n",
      "Train Epoch: 9 | Loss: 0.524 | Acc: 83.026% (1169/1408)\n",
      "Train Epoch: 9 | Loss: 0.520 | Acc: 83.008% (1275/1536)\n",
      "Train Epoch: 9 | Loss: 0.523 | Acc: 82.632% (1375/1664)\n",
      "Train Epoch: 9 | Loss: 0.520 | Acc: 82.757% (1483/1792)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.917% (1592/1920)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 83.057% (1701/2048)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.410% (1815/2176)\n",
      "Train Epoch: 9 | Loss: 0.501 | Acc: 83.594% (1926/2304)\n",
      "Train Epoch: 9 | Loss: 0.501 | Acc: 83.553% (2032/2432)\n",
      "Train Epoch: 9 | Loss: 0.497 | Acc: 83.750% (2144/2560)\n",
      "Train Epoch: 9 | Loss: 0.492 | Acc: 84.003% (2258/2688)\n",
      "Train Epoch: 9 | Loss: 0.495 | Acc: 83.878% (2362/2816)\n",
      "Train Epoch: 9 | Loss: 0.498 | Acc: 83.832% (2468/2944)\n",
      "Train Epoch: 9 | Loss: 0.496 | Acc: 83.789% (2574/3072)\n",
      "Train Epoch: 9 | Loss: 0.499 | Acc: 83.719% (2679/3200)\n",
      "Train Epoch: 9 | Loss: 0.498 | Acc: 83.714% (2786/3328)\n",
      "Train Epoch: 9 | Loss: 0.500 | Acc: 83.709% (2893/3456)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 83.510% (2993/3584)\n",
      "Train Epoch: 9 | Loss: 0.503 | Acc: 83.432% (3097/3712)\n",
      "Train Epoch: 9 | Loss: 0.499 | Acc: 83.464% (3205/3840)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 83.014% (3294/3968)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.154% (3406/4096)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 83.262% (3517/4224)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.157% (3619/4352)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 83.326% (3733/4480)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.095% (3829/4608)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.129% (3937/4736)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 83.018% (4038/4864)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.093% (4148/4992)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 83.105% (4255/5120)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 83.136% (4363/5248)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 83.110% (4468/5376)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 83.140% (4576/5504)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 83.132% (4682/5632)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.160% (4790/5760)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.982% (4886/5888)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.912% (4988/6016)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.894% (5093/6144)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.892% (5199/6272)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.969% (5310/6400)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.012% (5419/6528)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.008% (5525/6656)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.960% (5628/6784)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.899% (5730/6912)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.855% (5833/7040)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.910% (5943/7168)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.922% (6050/7296)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.839% (6150/7424)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.879% (6259/7552)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.878% (6365/7680)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.864% (6470/7808)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.838% (6574/7936)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.949% (6689/8064)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 83.008% (6800/8192)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.981% (6904/8320)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.824% (6997/8448)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.906% (7110/8576)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.916% (7217/8704)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.926% (7324/8832)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.935% (7431/8960)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.923% (7536/9088)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.943% (7644/9216)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.005% (7756/9344)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.981% (7860/9472)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.979% (7966/9600)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.936% (8068/9728)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.944% (8175/9856)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.923% (8279/9984)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.832% (8376/10112)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.812% (8480/10240)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.793% (8584/10368)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.889% (8700/10496)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.916% (8809/10624)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.933% (8917/10752)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.950% (9025/10880)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.985% (9135/11008)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.992% (9242/11136)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.079% (9358/11264)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.032% (9459/11392)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.073% (9570/11520)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.984% (9666/11648)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.016% (9776/11776)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.031% (9884/11904)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.995% (9986/12032)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 83.002% (10093/12160)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.967% (10195/12288)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.974% (10302/12416)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.948% (10405/12544)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.994% (10517/12672)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.977% (10621/12800)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.998% (10730/12928)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 83.027% (10840/13056)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.972% (10939/13184)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.955% (11043/13312)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.917% (11144/13440)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.916% (11250/13568)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.922% (11357/13696)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.899% (11460/13824)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.884% (11564/13952)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.855% (11666/14080)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.876% (11775/14208)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.785% (11868/14336)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.826% (11980/14464)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.833% (12087/14592)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.833% (12193/14720)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.826% (12298/14848)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.839% (12406/14976)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.852% (12514/15104)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.826% (12616/15232)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.839% (12724/15360)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.851% (12832/15488)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.889% (12944/15616)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.857% (13045/15744)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.882% (13155/15872)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.862% (13258/16000)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.881% (13367/16128)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.905% (13477/16256)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.874% (13578/16384)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.867% (13683/16512)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.849% (13786/16640)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.842% (13891/16768)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.889% (14005/16896)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 82.906% (14114/17024)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 82.906% (14220/17152)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 82.922% (14329/17280)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 82.910% (14433/17408)\n",
      "Train Epoch: 9 | Loss: 0.505 | Acc: 82.915% (14540/17536)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 82.892% (14642/17664)\n",
      "Train Epoch: 9 | Loss: 0.506 | Acc: 82.880% (14746/17792)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.868% (14850/17920)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.885% (14959/18048)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.835% (15056/18176)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.862% (15167/18304)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.861% (15273/18432)\n",
      "Train Epoch: 9 | Loss: 0.507 | Acc: 82.888% (15384/18560)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.839% (15481/18688)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.828% (15585/18816)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.818% (15689/18944)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.786% (15789/19072)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.755% (15889/19200)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.761% (15996/19328)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.746% (16099/19456)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.726% (16201/19584)\n",
      "Train Epoch: 9 | Loss: 0.508 | Acc: 82.767% (16315/19712)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.697% (16407/19840)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.707% (16515/19968)\n",
      "Train Epoch: 9 | Loss: 0.509 | Acc: 82.698% (16619/20096)\n",
      "Train Epoch: 9 | Loss: 0.510 | Acc: 82.689% (16723/20224)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.665% (16824/20352)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.661% (16929/20480)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.643% (17031/20608)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.605% (17129/20736)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.621% (17238/20864)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.612% (17342/20992)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.590% (17443/21120)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.572% (17545/21248)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.555% (17647/21376)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.566% (17755/21504)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.540% (17855/21632)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.551% (17963/21760)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.543% (18067/21888)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.549% (18174/22016)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.555% (18281/22144)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.557% (18387/22272)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.571% (18496/22400)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.555% (18598/22528)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.534% (18699/22656)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.540% (18806/22784)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.559% (18916/22912)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.565% (19023/23040)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.566% (19129/23168)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.568% (19235/23296)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.569% (19341/23424)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.549% (19442/23552)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.500% (19536/23680)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.485% (19638/23808)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.503% (19748/23936)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.517% (19857/24064)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.486% (19955/24192)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.479% (20059/24320)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.514% (20173/24448)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.507% (20277/24576)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.481% (20376/24704)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.490% (20484/24832)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.496% (20591/24960)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.526% (20704/25088)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.483% (20799/25216)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.481% (20904/25344)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.471% (21007/25472)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.461% (21110/25600)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.478% (21220/25728)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.491% (21329/25856)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.524% (21443/25984)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.518% (21547/26112)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.504% (21649/26240)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.513% (21757/26368)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.511% (21862/26496)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.489% (21962/26624)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.495% (22069/26752)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.504% (22177/26880)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.501% (22282/27008)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.470% (22379/27136)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.438% (22476/27264)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.466% (22589/27392)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.453% (22691/27520)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.458% (22798/27648)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.467% (22906/27776)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.458% (23009/27904)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.466% (23117/28032)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.468% (23223/28160)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.431% (23318/28288)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.432% (23424/28416)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.441% (23532/28544)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.439% (23637/28672)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.455% (23747/28800)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.422% (23843/28928)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.406% (23944/29056)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.405% (24049/29184)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.355% (24140/29312)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.340% (24241/29440)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.322% (24341/29568)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.317% (24445/29696)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.313% (24549/29824)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.348% (24665/29952)\n",
      "Train Epoch: 9 | Loss: 0.517 | Acc: 82.340% (24768/30080)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.359% (24879/30208)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.358% (24984/30336)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.369% (25093/30464)\n",
      "Train Epoch: 9 | Loss: 0.516 | Acc: 82.365% (25197/30592)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.370% (25304/30720)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.378% (25412/30848)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.406% (25526/30976)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.391% (25627/31104)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.393% (25733/31232)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.385% (25836/31360)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.396% (25945/31488)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.398% (26051/31616)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.400% (26157/31744)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.401% (26263/31872)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.394% (26366/32000)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.392% (26471/32128)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.397% (26578/32256)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.408% (26687/32384)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.422% (26797/32512)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.423% (26903/32640)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.440% (27014/32768)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.463% (27127/32896)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.492% (27242/33024)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.505% (27352/33152)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.518% (27462/33280)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.519% (27568/33408)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.502% (27668/33536)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.507% (27775/33664)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.487% (27874/33792)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.485% (27979/33920)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.492% (28087/34048)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.514% (28200/34176)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.506% (28303/34304)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.508% (28409/34432)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.506% (28514/34560)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.507% (28620/34688)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.499% (28723/34816)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.486% (28824/34944)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.493% (28932/35072)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.474% (29031/35200)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.462% (29132/35328)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.437% (29229/35456)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.467% (29345/35584)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.476% (29454/35712)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.472% (29558/35840)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.457% (29658/35968)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.475% (29770/36096)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.454% (29868/36224)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.471% (29980/36352)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.459% (30081/36480)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.455% (30185/36608)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.461% (30293/36736)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.463% (30399/36864)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.472% (30508/36992)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.492% (30621/37120)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.501% (30730/37248)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.483% (30829/37376)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.469% (30929/37504)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.459% (31031/37632)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.450% (31133/37760)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.459% (31242/37888)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.452% (31345/38016)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.451% (31450/38144)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.449% (31555/38272)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.440% (31657/38400)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.439% (31762/38528)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.445% (31870/38656)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.459% (31981/38784)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.468% (32090/38912)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.464% (32194/39040)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.460% (32298/39168)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.451% (32400/39296)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.462% (32510/39424)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.484% (32624/39552)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.480% (32728/39680)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.491% (32838/39808)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.505% (32949/39936)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.515% (33059/40064)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.484% (33152/40192)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.495% (33262/40320)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.508% (33373/40448)\n",
      "Train Epoch: 9 | Loss: 0.511 | Acc: 82.534% (33489/40576)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.525% (33591/40704)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.528% (33698/40832)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.532% (33805/40960)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.520% (33906/41088)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.509% (34007/41216)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.508% (34112/41344)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.477% (34205/41472)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.476% (34310/41600)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.489% (34421/41728)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.473% (34520/41856)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.450% (34616/41984)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.449% (34721/42112)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.446% (34825/42240)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.440% (34928/42368)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.450% (35038/42496)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.461% (35148/42624)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.478% (35261/42752)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.470% (35363/42880)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.464% (35466/43008)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.476% (35577/43136)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.470% (35680/43264)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.462% (35782/43392)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.438% (35877/43520)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.418% (35974/43648)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.431% (36085/43776)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.428% (36189/43904)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.426% (36294/44032)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.432% (36402/44160)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.426% (36505/44288)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.405% (36601/44416)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.420% (36713/44544)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.421% (36819/44672)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.426% (36927/44800)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.423% (37031/44928)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.411% (37131/45056)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.421% (37241/45184)\n",
      "Train Epoch: 9 | Loss: 0.512 | Acc: 82.417% (37345/45312)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.405% (37445/45440)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.391% (37544/45568)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.388% (37648/45696)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.376% (37748/45824)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.382% (37856/45952)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.389% (37965/46080)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.373% (38063/46208)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.370% (38167/46336)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.367% (38271/46464)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.364% (38375/46592)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.365% (38481/46720)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.383% (38595/46848)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.385% (38701/46976)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.377% (38803/47104)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.370% (38905/47232)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.386% (39018/47360)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.391% (39126/47488)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.401% (39236/47616)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.398% (39340/47744)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.386% (39440/47872)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.371% (39538/48000)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.372% (39644/48128)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.371% (39749/48256)\n",
      "Train Epoch: 9 | Loss: 0.513 | Acc: 82.370% (39854/48384)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.357% (39953/48512)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.362% (40061/48640)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.349% (40160/48768)\n",
      "Train Epoch: 9 | Loss: 0.514 | Acc: 82.344% (40263/48896)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.327% (40360/49024)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.328% (40466/49152)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.321% (40568/49280)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.329% (40677/49408)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.326% (40781/49536)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.327% (40887/49664)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.324% (40991/49792)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.328% (41098/49920)\n",
      "Train Epoch: 9 | Loss: 0.515 | Acc: 82.330% (41165/50000)\n",
      "Test Epoch: 9 | Loss: 0.581 | Acc: 81.000% (81/100)\n",
      "Test Epoch: 9 | Loss: 0.559 | Acc: 80.000% (160/200)\n",
      "Test Epoch: 9 | Loss: 0.590 | Acc: 78.667% (236/300)\n",
      "Test Epoch: 9 | Loss: 0.578 | Acc: 79.250% (317/400)\n",
      "Test Epoch: 9 | Loss: 0.567 | Acc: 79.600% (398/500)\n",
      "Test Epoch: 9 | Loss: 0.527 | Acc: 81.333% (488/600)\n",
      "Test Epoch: 9 | Loss: 0.543 | Acc: 81.143% (568/700)\n",
      "Test Epoch: 9 | Loss: 0.571 | Acc: 80.250% (642/800)\n",
      "Test Epoch: 9 | Loss: 0.594 | Acc: 79.333% (714/900)\n",
      "Test Epoch: 9 | Loss: 0.603 | Acc: 79.300% (793/1000)\n",
      "Test Epoch: 9 | Loss: 0.603 | Acc: 79.273% (872/1100)\n",
      "Test Epoch: 9 | Loss: 0.598 | Acc: 79.500% (954/1200)\n",
      "Test Epoch: 9 | Loss: 0.601 | Acc: 79.615% (1035/1300)\n",
      "Test Epoch: 9 | Loss: 0.600 | Acc: 79.500% (1113/1400)\n",
      "Test Epoch: 9 | Loss: 0.607 | Acc: 79.467% (1192/1500)\n",
      "Test Epoch: 9 | Loss: 0.610 | Acc: 79.000% (1264/1600)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.000% (1343/1700)\n",
      "Test Epoch: 9 | Loss: 0.622 | Acc: 78.833% (1419/1800)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.105% (1503/1900)\n",
      "Test Epoch: 9 | Loss: 0.617 | Acc: 79.150% (1583/2000)\n",
      "Test Epoch: 9 | Loss: 0.619 | Acc: 79.048% (1660/2100)\n",
      "Test Epoch: 9 | Loss: 0.628 | Acc: 78.909% (1736/2200)\n",
      "Test Epoch: 9 | Loss: 0.631 | Acc: 78.652% (1809/2300)\n",
      "Test Epoch: 9 | Loss: 0.629 | Acc: 78.750% (1890/2400)\n",
      "Test Epoch: 9 | Loss: 0.631 | Acc: 78.840% (1971/2500)\n",
      "Test Epoch: 9 | Loss: 0.643 | Acc: 78.654% (2045/2600)\n",
      "Test Epoch: 9 | Loss: 0.638 | Acc: 78.963% (2132/2700)\n",
      "Test Epoch: 9 | Loss: 0.644 | Acc: 78.893% (2209/2800)\n",
      "Test Epoch: 9 | Loss: 0.647 | Acc: 78.828% (2286/2900)\n",
      "Test Epoch: 9 | Loss: 0.650 | Acc: 78.867% (2366/3000)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.839% (2444/3100)\n",
      "Test Epoch: 9 | Loss: 0.647 | Acc: 78.938% (2526/3200)\n",
      "Test Epoch: 9 | Loss: 0.646 | Acc: 79.000% (2607/3300)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 78.912% (2683/3400)\n",
      "Test Epoch: 9 | Loss: 0.657 | Acc: 78.800% (2758/3500)\n",
      "Test Epoch: 9 | Loss: 0.656 | Acc: 78.861% (2839/3600)\n",
      "Test Epoch: 9 | Loss: 0.656 | Acc: 78.784% (2915/3700)\n",
      "Test Epoch: 9 | Loss: 0.658 | Acc: 78.711% (2991/3800)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.897% (3077/3900)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.950% (3158/4000)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 79.000% (3239/4100)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 79.000% (3318/4200)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 79.140% (3403/4300)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 79.182% (3484/4400)\n",
      "Test Epoch: 9 | Loss: 0.646 | Acc: 79.200% (3564/4500)\n",
      "Test Epoch: 9 | Loss: 0.645 | Acc: 79.239% (3645/4600)\n",
      "Test Epoch: 9 | Loss: 0.642 | Acc: 79.277% (3726/4700)\n",
      "Test Epoch: 9 | Loss: 0.643 | Acc: 79.312% (3807/4800)\n",
      "Test Epoch: 9 | Loss: 0.642 | Acc: 79.286% (3885/4900)\n",
      "Test Epoch: 9 | Loss: 0.647 | Acc: 79.060% (3953/5000)\n",
      "Test Epoch: 9 | Loss: 0.645 | Acc: 79.098% (4034/5100)\n",
      "Test Epoch: 9 | Loss: 0.645 | Acc: 79.115% (4114/5200)\n",
      "Test Epoch: 9 | Loss: 0.644 | Acc: 79.113% (4193/5300)\n",
      "Test Epoch: 9 | Loss: 0.643 | Acc: 79.130% (4273/5400)\n",
      "Test Epoch: 9 | Loss: 0.646 | Acc: 79.109% (4351/5500)\n",
      "Test Epoch: 9 | Loss: 0.650 | Acc: 79.036% (4426/5600)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.982% (4502/5700)\n",
      "Test Epoch: 9 | Loss: 0.651 | Acc: 79.017% (4583/5800)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.966% (4659/5900)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.883% (4733/6000)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.902% (4813/6100)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.919% (4893/6200)\n",
      "Test Epoch: 9 | Loss: 0.655 | Acc: 78.889% (4970/6300)\n",
      "Test Epoch: 9 | Loss: 0.655 | Acc: 78.938% (5052/6400)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.954% (5132/6500)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.955% (5211/6600)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 78.970% (5291/6700)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.926% (5367/6800)\n",
      "Test Epoch: 9 | Loss: 0.651 | Acc: 78.957% (5448/6900)\n",
      "Test Epoch: 9 | Loss: 0.655 | Acc: 78.829% (5518/7000)\n",
      "Test Epoch: 9 | Loss: 0.656 | Acc: 78.831% (5597/7100)\n",
      "Test Epoch: 9 | Loss: 0.656 | Acc: 78.792% (5673/7200)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.863% (5757/7300)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.892% (5838/7400)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.867% (5915/7500)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.947% (6000/7600)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.974% (6081/7700)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.936% (6157/7800)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.924% (6235/7900)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.925% (6314/8000)\n",
      "Test Epoch: 9 | Loss: 0.650 | Acc: 78.975% (6397/8100)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 78.927% (6472/8200)\n",
      "Test Epoch: 9 | Loss: 0.648 | Acc: 78.964% (6554/8300)\n",
      "Test Epoch: 9 | Loss: 0.647 | Acc: 78.976% (6634/8400)\n",
      "Test Epoch: 9 | Loss: 0.650 | Acc: 78.871% (6704/8500)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.895% (6785/8600)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.851% (6860/8700)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.807% (6935/8800)\n",
      "Test Epoch: 9 | Loss: 0.654 | Acc: 78.843% (7017/8900)\n",
      "Test Epoch: 9 | Loss: 0.653 | Acc: 78.867% (7098/9000)\n",
      "Test Epoch: 9 | Loss: 0.655 | Acc: 78.802% (7171/9100)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.891% (7258/9200)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.914% (7339/9300)\n",
      "Test Epoch: 9 | Loss: 0.652 | Acc: 78.851% (7412/9400)\n",
      "Test Epoch: 9 | Loss: 0.650 | Acc: 78.863% (7492/9500)\n",
      "Test Epoch: 9 | Loss: 0.648 | Acc: 78.927% (7577/9600)\n",
      "Test Epoch: 9 | Loss: 0.646 | Acc: 78.990% (7662/9700)\n",
      "Test Epoch: 9 | Loss: 0.648 | Acc: 78.959% (7738/9800)\n",
      "Test Epoch: 9 | Loss: 0.649 | Acc: 78.929% (7814/9900)\n",
      "Test Epoch: 9 | Loss: 0.648 | Acc: 78.940% (7894/10000)\n",
      "\n",
      "Epoch: 10\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 82.812% (106/128)\n",
      "Train Epoch: 10 | Loss: 0.504 | Acc: 80.469% (206/256)\n",
      "Train Epoch: 10 | Loss: 0.514 | Acc: 81.250% (312/384)\n",
      "Train Epoch: 10 | Loss: 0.520 | Acc: 81.250% (416/512)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.031% (525/640)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 81.901% (629/768)\n",
      "Train Epoch: 10 | Loss: 0.502 | Acc: 81.250% (728/896)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 81.445% (834/1024)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 81.337% (937/1152)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 81.719% (1046/1280)\n",
      "Train Epoch: 10 | Loss: 0.505 | Acc: 81.321% (1145/1408)\n",
      "Train Epoch: 10 | Loss: 0.507 | Acc: 81.576% (1253/1536)\n",
      "Train Epoch: 10 | Loss: 0.518 | Acc: 81.611% (1358/1664)\n",
      "Train Epoch: 10 | Loss: 0.516 | Acc: 81.975% (1469/1792)\n",
      "Train Epoch: 10 | Loss: 0.511 | Acc: 82.292% (1580/1920)\n",
      "Train Epoch: 10 | Loss: 0.509 | Acc: 82.324% (1686/2048)\n",
      "Train Epoch: 10 | Loss: 0.513 | Acc: 82.353% (1792/2176)\n",
      "Train Epoch: 10 | Loss: 0.505 | Acc: 82.726% (1906/2304)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 82.936% (2017/2432)\n",
      "Train Epoch: 10 | Loss: 0.505 | Acc: 82.852% (2121/2560)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 82.961% (2230/2688)\n",
      "Train Epoch: 10 | Loss: 0.507 | Acc: 82.919% (2335/2816)\n",
      "Train Epoch: 10 | Loss: 0.507 | Acc: 83.016% (2444/2944)\n",
      "Train Epoch: 10 | Loss: 0.504 | Acc: 83.138% (2554/3072)\n",
      "Train Epoch: 10 | Loss: 0.508 | Acc: 83.094% (2659/3200)\n",
      "Train Epoch: 10 | Loss: 0.511 | Acc: 83.023% (2763/3328)\n",
      "Train Epoch: 10 | Loss: 0.508 | Acc: 83.102% (2872/3456)\n",
      "Train Epoch: 10 | Loss: 0.504 | Acc: 83.231% (2983/3584)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 83.217% (3089/3712)\n",
      "Train Epoch: 10 | Loss: 0.502 | Acc: 83.177% (3194/3840)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 83.241% (3303/3968)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 83.350% (3414/4096)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 83.404% (3523/4224)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 83.387% (3629/4352)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 83.326% (3733/4480)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 83.398% (3843/4608)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 83.298% (3945/4736)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 83.326% (4053/4864)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 83.273% (4157/4992)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 83.379% (4269/5120)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 83.346% (4374/5248)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 83.259% (4476/5376)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 83.176% (4578/5504)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 83.203% (4686/5632)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 83.056% (4784/5760)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 82.948% (4884/5888)\n",
      "Train Epoch: 10 | Loss: 0.505 | Acc: 82.846% (4984/6016)\n",
      "Train Epoch: 10 | Loss: 0.503 | Acc: 82.910% (5094/6144)\n",
      "Train Epoch: 10 | Loss: 0.503 | Acc: 82.860% (5197/6272)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.969% (5310/6400)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.920% (5413/6528)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 83.008% (5525/6656)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.048% (5634/6784)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.030% (5739/6912)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.040% (5846/7040)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.147% (5960/7168)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.087% (6062/7296)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.136% (6172/7424)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.223% (6285/7552)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.177% (6388/7680)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.081% (6487/7808)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.090% (6594/7936)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.197% (6709/8064)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.154% (6812/8192)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.125% (6916/8320)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.191% (7028/8448)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.279% (7142/8576)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.307% (7251/8704)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.277% (7355/8832)\n",
      "Train Epoch: 10 | Loss: 0.489 | Acc: 83.315% (7465/8960)\n",
      "Train Epoch: 10 | Loss: 0.489 | Acc: 83.275% (7568/9088)\n",
      "Train Epoch: 10 | Loss: 0.487 | Acc: 83.301% (7677/9216)\n",
      "Train Epoch: 10 | Loss: 0.487 | Acc: 83.315% (7785/9344)\n",
      "Train Epoch: 10 | Loss: 0.487 | Acc: 83.319% (7892/9472)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.260% (7993/9600)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.244% (8098/9728)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.157% (8196/9856)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.223% (8309/9984)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.208% (8414/10112)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.203% (8520/10240)\n",
      "Train Epoch: 10 | Loss: 0.489 | Acc: 83.314% (8638/10368)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.270% (8740/10496)\n",
      "Train Epoch: 10 | Loss: 0.489 | Acc: 83.293% (8849/10624)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.268% (8953/10752)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.235% (9056/10880)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.221% (9161/11008)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.208% (9266/11136)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.185% (9370/11264)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.190% (9477/11392)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.238% (9589/11520)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.276% (9700/11648)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.288% (9808/11776)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.258% (9911/11904)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.286% (10021/12032)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.240% (10122/12160)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.252% (10230/12288)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.272% (10339/12416)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.211% (10438/12544)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.199% (10543/12672)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.148% (10643/12800)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.075% (10740/12928)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.119% (10852/13056)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.131% (10960/13184)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.120% (11065/13312)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.170% (11178/13440)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.122% (11278/13568)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.053% (11375/13696)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.066% (11483/13824)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.092% (11593/13952)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.111% (11702/14080)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.066% (11802/14208)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.057% (11907/14336)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.048% (12012/14464)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.100% (12126/14592)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.145% (12239/14720)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.176% (12350/14848)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.173% (12456/14976)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.150% (12559/15104)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.141% (12664/15232)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.138% (12770/15360)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.090% (12869/15488)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.056% (12970/15616)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 83.035% (13073/15744)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 83.027% (13178/15872)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.994% (13279/16000)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.955% (13379/16128)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.948% (13484/16256)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.971% (13594/16384)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.976% (13701/16512)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.981% (13808/16640)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 83.003% (13918/16768)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 83.008% (14025/16896)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.971% (14125/17024)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.958% (14229/17152)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.951% (14334/17280)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.910% (14433/17408)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.909% (14539/17536)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.920% (14647/17664)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.902% (14750/17792)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.902% (14856/17920)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.907% (14963/18048)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.868% (15062/18176)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.916% (15177/18304)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.916% (15283/18432)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.888% (15384/18560)\n",
      "Train Epoch: 10 | Loss: 0.501 | Acc: 82.887% (15490/18688)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.876% (15594/18816)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.871% (15699/18944)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.923% (15815/19072)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.917% (15920/19200)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.885% (16020/19328)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.895% (16128/19456)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.879% (16231/19584)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.904% (16342/19712)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.898% (16447/19840)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.923% (16558/19968)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.922% (16664/20096)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.902% (16766/20224)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.906% (16873/20352)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.896% (16977/20480)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.885% (17081/20608)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.870% (17184/20736)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.846% (17285/20864)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.860% (17394/20992)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.850% (17498/21120)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.860% (17606/21248)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.850% (17710/21376)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.873% (17821/21504)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.886% (17930/21632)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.895% (18038/21760)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.895% (18144/21888)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.844% (18239/22016)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.835% (18343/22144)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.835% (18449/22272)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.848% (18558/22400)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.852% (18665/22528)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.861% (18773/22656)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.848% (18876/22784)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.843% (18981/22912)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.795% (19076/23040)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.782% (19179/23168)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.761% (19280/23296)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.766% (19387/23424)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.774% (19495/23552)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.787% (19604/23680)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.779% (19708/23808)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.804% (19820/23936)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.792% (19923/24064)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.792% (20029/24192)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.763% (20128/24320)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.755% (20232/24448)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.764% (20340/24576)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.784% (20451/24704)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.788% (20558/24832)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.788% (20664/24960)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.765% (20764/25088)\n",
      "Train Epoch: 10 | Loss: 0.500 | Acc: 82.769% (20871/25216)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.801% (20985/25344)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.828% (21098/25472)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.812% (21200/25600)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.816% (21307/25728)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.824% (21415/25856)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.843% (21526/25984)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.851% (21634/26112)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.862% (21743/26240)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.862% (21849/26368)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.880% (21960/26496)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.865% (22062/26624)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.895% (22176/26752)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.883% (22279/26880)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.864% (22380/27008)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.875% (22489/27136)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.864% (22592/27264)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.893% (22706/27392)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.874% (22807/27520)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.860% (22909/27648)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.834% (23008/27776)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.802% (23105/27904)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.788% (23207/28032)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.805% (23318/28160)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.802% (23423/28288)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.781% (23523/28416)\n",
      "Train Epoch: 10 | Loss: 0.499 | Acc: 82.763% (23624/28544)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.785% (23736/28672)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.809% (23849/28800)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.826% (23960/28928)\n",
      "Train Epoch: 10 | Loss: 0.498 | Acc: 82.826% (24066/29056)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.816% (24169/29184)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.836% (24281/29312)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.846% (24390/29440)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.833% (24492/29568)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.839% (24600/29696)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.843% (24707/29824)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.859% (24818/29952)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.876% (24929/30080)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.875% (25035/30208)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.882% (25143/30336)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.895% (25253/30464)\n",
      "Train Epoch: 10 | Loss: 0.497 | Acc: 82.862% (25349/30592)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.887% (25463/30720)\n",
      "Train Epoch: 10 | Loss: 0.496 | Acc: 82.900% (25573/30848)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.935% (25690/30976)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.925% (25793/31104)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.944% (25905/31232)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.966% (26018/31360)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.987% (26131/31488)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.996% (26240/31616)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.992% (26345/31744)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.994% (26452/31872)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.994% (26558/32000)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.996% (26665/32128)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.995% (26771/32256)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.998% (26878/32384)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.985% (26980/32512)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.006% (27093/32640)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.020% (27204/32768)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.016% (27309/32896)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.006% (27412/33024)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.009% (27519/33152)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.996% (27621/33280)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.986% (27724/33408)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.985% (27830/33536)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.997% (27940/33664)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.999% (28047/33792)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.004% (28155/33920)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.006% (28262/34048)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.997% (28365/34176)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.973% (28463/34304)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.981% (28572/34432)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.969% (28674/34560)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.974% (28782/34688)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.962% (28884/34816)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.967% (28992/34944)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.955% (29094/35072)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.952% (29199/35200)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.931% (29298/35328)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.928% (29403/35456)\n",
      "Train Epoch: 10 | Loss: 0.495 | Acc: 82.945% (29515/35584)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.941% (29620/35712)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.949% (29729/35840)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.940% (29832/35968)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.943% (29939/36096)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.942% (30045/36224)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.934% (30148/36352)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.930% (30253/36480)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.941% (30363/36608)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.938% (30468/36736)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.945% (30577/36864)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.923% (30675/36992)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.939% (30787/37120)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.947% (30896/37248)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.973% (31012/37376)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.983% (31122/37504)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.996% (31233/37632)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.977% (31332/37760)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.981% (31440/37888)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.976% (31544/38016)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 82.978% (31651/38144)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.993% (31763/38272)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 82.997% (31871/38400)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.007% (31981/38528)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.007% (32087/38656)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.016% (32197/38784)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.023% (32306/38912)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.033% (32416/39040)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.032% (32522/39168)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.036% (32630/39296)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.038% (32737/39424)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.027% (32839/39552)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.037% (32949/39680)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.044% (33058/39808)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.025% (33157/39936)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.010% (33257/40064)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.021% (33368/40192)\n",
      "Train Epoch: 10 | Loss: 0.494 | Acc: 83.031% (33478/40320)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.040% (33588/40448)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.054% (33700/40576)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.068% (33812/40704)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.079% (33923/40832)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.086% (34032/40960)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.083% (34137/41088)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.067% (34237/41216)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.071% (34345/41344)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.068% (34450/41472)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.075% (34559/41600)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.088% (34671/41728)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.104% (34784/41856)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.103% (34890/41984)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.097% (34994/42112)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.092% (35098/42240)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.098% (35207/42368)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.093% (35311/42496)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.094% (35418/42624)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.098% (35526/42752)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.109% (35637/42880)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.105% (35742/43008)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.114% (35852/43136)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.115% (35959/43264)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.128% (36071/43392)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.125% (36176/43520)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.106% (36274/43648)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.103% (36379/43776)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.093% (36481/43904)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.108% (36594/44032)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.096% (36695/44160)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.099% (36803/44288)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.103% (36911/44416)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.100% (37016/44544)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.104% (37124/44672)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.100% (37229/44800)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.084% (37328/44928)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.077% (37431/45056)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.080% (37539/45184)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.080% (37645/45312)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.088% (37755/45440)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.096% (37865/45568)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.093% (37970/45696)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.105% (38082/45824)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.113% (38192/45952)\n",
      "Train Epoch: 10 | Loss: 0.493 | Acc: 83.121% (38302/46080)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.137% (38416/46208)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.143% (38525/46336)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.150% (38635/46464)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.143% (38738/46592)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.149% (38847/46720)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.150% (38954/46848)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.136% (39054/46976)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.148% (39166/47104)\n",
      "Train Epoch: 10 | Loss: 0.492 | Acc: 83.166% (39281/47232)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.180% (39394/47360)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.183% (39502/47488)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.174% (39604/47616)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.179% (39713/47744)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.170% (39815/47872)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.175% (39924/48000)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.189% (40037/48128)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.200% (40149/48256)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.216% (40263/48384)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.223% (40373/48512)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.213% (40475/48640)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.204% (40577/48768)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.224% (40693/48896)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.220% (40798/49024)\n",
      "Train Epoch: 10 | Loss: 0.490 | Acc: 83.217% (40903/49152)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.202% (41002/49280)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.185% (41100/49408)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.196% (41212/49536)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.179% (41310/49664)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.172% (41413/49792)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.185% (41526/49920)\n",
      "Train Epoch: 10 | Loss: 0.491 | Acc: 83.178% (41589/50000)\n",
      "Test Epoch: 10 | Loss: 0.553 | Acc: 80.000% (80/100)\n",
      "Test Epoch: 10 | Loss: 0.479 | Acc: 82.500% (165/200)\n",
      "Test Epoch: 10 | Loss: 0.507 | Acc: 82.667% (248/300)\n",
      "Test Epoch: 10 | Loss: 0.512 | Acc: 82.250% (329/400)\n",
      "Test Epoch: 10 | Loss: 0.520 | Acc: 81.600% (408/500)\n",
      "Test Epoch: 10 | Loss: 0.477 | Acc: 83.333% (500/600)\n",
      "Test Epoch: 10 | Loss: 0.477 | Acc: 83.143% (582/700)\n",
      "Test Epoch: 10 | Loss: 0.502 | Acc: 82.375% (659/800)\n",
      "Test Epoch: 10 | Loss: 0.534 | Acc: 81.333% (732/900)\n",
      "Test Epoch: 10 | Loss: 0.532 | Acc: 81.500% (815/1000)\n",
      "Test Epoch: 10 | Loss: 0.555 | Acc: 80.636% (887/1100)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.167% (962/1200)\n",
      "Test Epoch: 10 | Loss: 0.558 | Acc: 80.538% (1047/1300)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.714% (1130/1400)\n",
      "Test Epoch: 10 | Loss: 0.547 | Acc: 80.600% (1209/1500)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.625% (1290/1600)\n",
      "Test Epoch: 10 | Loss: 0.546 | Acc: 80.824% (1374/1700)\n",
      "Test Epoch: 10 | Loss: 0.547 | Acc: 80.833% (1455/1800)\n",
      "Test Epoch: 10 | Loss: 0.542 | Acc: 81.158% (1542/1900)\n",
      "Test Epoch: 10 | Loss: 0.552 | Acc: 80.950% (1619/2000)\n",
      "Test Epoch: 10 | Loss: 0.553 | Acc: 80.810% (1697/2100)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.909% (1780/2200)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.739% (1857/2300)\n",
      "Test Epoch: 10 | Loss: 0.551 | Acc: 80.833% (1940/2400)\n",
      "Test Epoch: 10 | Loss: 0.555 | Acc: 80.960% (2024/2500)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.692% (2098/2600)\n",
      "Test Epoch: 10 | Loss: 0.566 | Acc: 80.667% (2178/2700)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.607% (2257/2800)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.690% (2340/2900)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.633% (2419/3000)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.484% (2495/3100)\n",
      "Test Epoch: 10 | Loss: 0.576 | Acc: 80.562% (2578/3200)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.545% (2658/3300)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.500% (2737/3400)\n",
      "Test Epoch: 10 | Loss: 0.583 | Acc: 80.343% (2812/3500)\n",
      "Test Epoch: 10 | Loss: 0.584 | Acc: 80.361% (2893/3600)\n",
      "Test Epoch: 10 | Loss: 0.587 | Acc: 80.270% (2970/3700)\n",
      "Test Epoch: 10 | Loss: 0.586 | Acc: 80.237% (3049/3800)\n",
      "Test Epoch: 10 | Loss: 0.582 | Acc: 80.359% (3134/3900)\n",
      "Test Epoch: 10 | Loss: 0.581 | Acc: 80.425% (3217/4000)\n",
      "Test Epoch: 10 | Loss: 0.581 | Acc: 80.439% (3298/4100)\n",
      "Test Epoch: 10 | Loss: 0.582 | Acc: 80.405% (3377/4200)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.535% (3463/4300)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.591% (3546/4400)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.600% (3627/4500)\n",
      "Test Epoch: 10 | Loss: 0.579 | Acc: 80.543% (3705/4600)\n",
      "Test Epoch: 10 | Loss: 0.577 | Acc: 80.553% (3786/4700)\n",
      "Test Epoch: 10 | Loss: 0.578 | Acc: 80.583% (3868/4800)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.694% (3954/4900)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.720% (4036/5000)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.745% (4118/5100)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.769% (4200/5200)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.792% (4282/5300)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.815% (4364/5400)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.818% (4445/5500)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.732% (4521/5600)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.737% (4602/5700)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.810% (4687/5800)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.797% (4767/5900)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.717% (4843/6000)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.754% (4926/6100)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.774% (5008/6200)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.698% (5084/6300)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.828% (5173/6400)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.831% (5254/6500)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.894% (5339/6600)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.955% (5424/6700)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 80.971% (5506/6800)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.855% (5579/6900)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.843% (5659/7000)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.831% (5739/7100)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.806% (5818/7200)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.808% (5899/7300)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.784% (5978/7400)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.787% (6059/7500)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.776% (6139/7600)\n",
      "Test Epoch: 10 | Loss: 0.575 | Acc: 80.753% (6218/7700)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.821% (6304/7800)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.785% (6382/7900)\n",
      "Test Epoch: 10 | Loss: 0.574 | Acc: 80.737% (6459/8000)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.790% (6544/8100)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.805% (6626/8200)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.795% (6706/8300)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.857% (6792/8400)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.835% (6871/8500)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.791% (6948/8600)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.724% (7023/8700)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.750% (7106/8800)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.764% (7188/8900)\n",
      "Test Epoch: 10 | Loss: 0.573 | Acc: 80.767% (7269/9000)\n",
      "Test Epoch: 10 | Loss: 0.572 | Acc: 80.813% (7354/9100)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.870% (7440/9200)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.871% (7521/9300)\n",
      "Test Epoch: 10 | Loss: 0.571 | Acc: 80.862% (7601/9400)\n",
      "Test Epoch: 10 | Loss: 0.570 | Acc: 80.916% (7687/9500)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.938% (7770/9600)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.979% (7855/9700)\n",
      "Test Epoch: 10 | Loss: 0.567 | Acc: 80.969% (7935/9800)\n",
      "Test Epoch: 10 | Loss: 0.568 | Acc: 80.919% (8011/9900)\n",
      "Test Epoch: 10 | Loss: 0.569 | Acc: 80.920% (8092/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 11\n",
      "Train Epoch: 11 | Loss: 0.554 | Acc: 82.812% (106/128)\n",
      "Train Epoch: 11 | Loss: 0.520 | Acc: 82.812% (212/256)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 84.375% (324/384)\n",
      "Train Epoch: 11 | Loss: 0.487 | Acc: 83.984% (430/512)\n",
      "Train Epoch: 11 | Loss: 0.505 | Acc: 83.438% (534/640)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.984% (645/768)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.147% (745/896)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.398% (854/1024)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.767% (965/1152)\n",
      "Train Epoch: 11 | Loss: 0.482 | Acc: 83.750% (1072/1280)\n",
      "Train Epoch: 11 | Loss: 0.488 | Acc: 83.523% (1176/1408)\n",
      "Train Epoch: 11 | Loss: 0.485 | Acc: 83.464% (1282/1536)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.714% (1393/1664)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.817% (1502/1792)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.750% (1608/1920)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.789% (1716/2048)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.824% (1824/2176)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 83.507% (1924/2304)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.347% (2027/2432)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.203% (2130/2560)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 83.036% (2232/2688)\n",
      "Train Epoch: 11 | Loss: 0.490 | Acc: 83.132% (2341/2816)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.084% (2446/2944)\n",
      "Train Epoch: 11 | Loss: 0.496 | Acc: 83.008% (2550/3072)\n",
      "Train Epoch: 11 | Loss: 0.493 | Acc: 83.094% (2659/3200)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.053% (2764/3328)\n",
      "Train Epoch: 11 | Loss: 0.495 | Acc: 82.957% (2867/3456)\n",
      "Train Epoch: 11 | Loss: 0.498 | Acc: 82.757% (2966/3584)\n",
      "Train Epoch: 11 | Loss: 0.499 | Acc: 82.812% (3074/3712)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.151% (3193/3840)\n",
      "Train Epoch: 11 | Loss: 0.498 | Acc: 83.090% (3297/3968)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.228% (3409/4096)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.144% (3512/4224)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.088% (3616/4352)\n",
      "Train Epoch: 11 | Loss: 0.492 | Acc: 83.192% (3727/4480)\n",
      "Train Epoch: 11 | Loss: 0.494 | Acc: 83.181% (3833/4608)\n",
      "Train Epoch: 11 | Loss: 0.489 | Acc: 83.340% (3947/4736)\n",
      "Train Epoch: 11 | Loss: 0.487 | Acc: 83.368% (4055/4864)\n",
      "Train Epoch: 11 | Loss: 0.485 | Acc: 83.393% (4163/4992)\n",
      "Train Epoch: 11 | Loss: 0.486 | Acc: 83.379% (4269/5120)\n",
      "Train Epoch: 11 | Loss: 0.483 | Acc: 83.403% (4377/5248)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.519% (4490/5376)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.539% (4598/5504)\n",
      "Train Epoch: 11 | Loss: 0.482 | Acc: 83.505% (4703/5632)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.576% (4814/5760)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.526% (4918/5888)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.660% (5033/6016)\n",
      "Train Epoch: 11 | Loss: 0.481 | Acc: 83.643% (5139/6144)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.721% (5251/6272)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.844% (5366/6400)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.869% (5475/6528)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.849% (5581/6656)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.726% (5680/6784)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.898% (5799/6912)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.835% (5902/7040)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.789% (6006/7168)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.786% (6113/7296)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.863% (6226/7424)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.872% (6334/7552)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.906% (6444/7680)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.927% (6553/7808)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.871% (6656/7936)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.891% (6765/8064)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 84.033% (6884/8192)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.918% (6982/8320)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.866% (7085/8448)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.827% (7189/8576)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.869% (7300/8704)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.752% (7397/8832)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.783% (7507/8960)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.825% (7618/9088)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.822% (7725/9216)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.872% (7837/9344)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.868% (7944/9472)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.875% (8052/9600)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.882% (8160/9728)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.929% (8272/9856)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.884% (8375/9984)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.831% (8477/10112)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.809% (8582/10240)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.787% (8687/10368)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.765% (8792/10496)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.773% (8900/10624)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.724% (9002/10752)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.750% (9112/10880)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.803% (9225/11008)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.818% (9334/11136)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.816% (9441/11264)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.822% (9549/11392)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.776% (9651/11520)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.774% (9758/11648)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.849% (9874/11776)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.812% (9977/11904)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.893% (10094/12032)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.824% (10193/12160)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.805% (10298/12288)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.787% (10403/12416)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.777% (10509/12544)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.799% (10619/12672)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.766% (10722/12800)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.764% (10829/12928)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.755% (10935/13056)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.768% (11044/13184)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.782% (11153/13312)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.780% (11260/13440)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.815% (11372/13568)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.776% (11474/13696)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.767% (11580/13824)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.716% (11680/13952)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.693% (11784/14080)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.699% (11892/14208)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.670% (11995/14336)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.649% (12099/14464)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.649% (12206/14592)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.668% (12316/14720)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.634% (12418/14848)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.640% (12526/14976)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.653% (12635/15104)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.666% (12744/15232)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.717% (12859/15360)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.697% (12963/15488)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.690% (13069/15616)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.695% (13177/15744)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.663% (13279/15872)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.675% (13388/16000)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.693% (13498/16128)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.711% (13608/16256)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.740% (13720/16384)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.757% (13830/16512)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.780% (13941/16640)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.761% (14045/16768)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.748% (14150/16896)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.752% (14258/17024)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.745% (14364/17152)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.767% (14475/17280)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.755% (14580/17408)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.748% (14686/17536)\n",
      "Train Epoch: 11 | Loss: 0.468 | Acc: 83.764% (14796/17664)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.729% (14897/17792)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.722% (15003/17920)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.743% (15114/18048)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.753% (15223/18176)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.703% (15321/18304)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.675% (15423/18432)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.669% (15529/18560)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.679% (15638/18688)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.668% (15743/18816)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.726% (15861/18944)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.720% (15967/19072)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.750% (16080/19200)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.770% (16191/19328)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.717% (16288/19456)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.716% (16395/19584)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.690% (16497/19712)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.690% (16604/19840)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.704% (16714/19968)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.708% (16822/20096)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.707% (16929/20224)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.731% (17041/20352)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.755% (17153/20480)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.783% (17266/20608)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.772% (17371/20736)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.771% (17478/20864)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.751% (17581/20992)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.750% (17688/21120)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.721% (17789/21248)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.687% (17889/21376)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.687% (17996/21504)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.677% (18101/21632)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.663% (18205/21760)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.676% (18315/21888)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.671% (18421/22016)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.666% (18527/22144)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.688% (18639/22272)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.670% (18742/22400)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.691% (18854/22528)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.686% (18960/22656)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.651% (19059/22784)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.633% (19162/22912)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.602% (19262/23040)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.585% (19365/23168)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.589% (19473/23296)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.594% (19581/23424)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.581% (19685/23552)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.526% (19779/23680)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.548% (19891/23808)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.556% (20000/23936)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.573% (20111/24064)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.581% (20220/24192)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.594% (20330/24320)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.594% (20437/24448)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.622% (20551/24576)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.618% (20657/24704)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.626% (20766/24832)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.626% (20873/24960)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.650% (20986/25088)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.645% (21092/25216)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.649% (21200/25344)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.649% (21307/25472)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.660% (21417/25600)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.675% (21528/25728)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.690% (21639/25856)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.686% (21745/25984)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.651% (21843/26112)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.678% (21957/26240)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.677% (22064/26368)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.684% (22173/26496)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.703% (22285/26624)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.721% (22397/26752)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.720% (22504/26880)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.749% (22619/27008)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.730% (22721/27136)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.748% (22833/27264)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.769% (22946/27392)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.761% (23051/27520)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.771% (23161/27648)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.770% (23268/27776)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.784% (23379/27904)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.797% (23490/28032)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.810% (23601/28160)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.813% (23709/28288)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.798% (23812/28416)\n",
      "Train Epoch: 11 | Loss: 0.469 | Acc: 83.793% (23918/28544)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.747% (24012/28672)\n",
      "Train Epoch: 11 | Loss: 0.470 | Acc: 83.743% (24118/28800)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.722% (24219/28928)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.694% (24318/29056)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.703% (24428/29184)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.696% (24533/29312)\n",
      "Train Epoch: 11 | Loss: 0.471 | Acc: 83.702% (24642/29440)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.678% (24742/29568)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.644% (24839/29696)\n",
      "Train Epoch: 11 | Loss: 0.472 | Acc: 83.634% (24943/29824)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.614% (25044/29952)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.617% (25152/30080)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.620% (25260/30208)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.627% (25369/30336)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.627% (25476/30464)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.633% (25585/30592)\n",
      "Train Epoch: 11 | Loss: 0.473 | Acc: 83.633% (25692/30720)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.607% (25791/30848)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.584% (25891/30976)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.591% (26000/31104)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.603% (26111/31232)\n",
      "Train Epoch: 11 | Loss: 0.474 | Acc: 83.610% (26220/31360)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.584% (26319/31488)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.575% (26423/31616)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.572% (26529/31744)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.597% (26644/31872)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.591% (26749/32000)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.578% (26852/32128)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.557% (26952/32256)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.541% (27054/32384)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.532% (27158/32512)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.514% (27259/32640)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.514% (27366/32768)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.524% (27476/32896)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.536% (27587/33024)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.497% (27681/33152)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.519% (27795/33280)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.513% (27900/33408)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.525% (28011/33536)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.519% (28116/33664)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.532% (28227/33792)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.541% (28337/33920)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.544% (28445/34048)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.538% (28550/34176)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.533% (28655/34304)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.533% (28762/34432)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.545% (28873/34560)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.556% (28984/34688)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.551% (29089/34816)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.554% (29197/34944)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.565% (29308/35072)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.577% (29419/35200)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.580% (29527/35328)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.577% (29633/35456)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.591% (29745/35584)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.597% (29854/35712)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.585% (29957/35840)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.588% (30065/35968)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.591% (30173/36096)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.602% (30284/36224)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.610% (30394/36352)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.605% (30499/36480)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.602% (30605/36608)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.618% (30718/36736)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.621% (30826/36864)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.626% (30935/36992)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.631% (31044/37120)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.626% (31149/37248)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.623% (31255/37376)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.650% (31372/37504)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.647% (31478/37632)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.647% (31585/37760)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.633% (31687/37888)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.638% (31796/38016)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.651% (31908/38144)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.651% (32015/38272)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.651% (32122/38400)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.643% (32226/38528)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.653% (32337/38656)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.650% (32443/38784)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.650% (32550/38912)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.653% (32658/39040)\n",
      "Train Epoch: 11 | Loss: 0.475 | Acc: 83.655% (32766/39168)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.632% (32864/39296)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.632% (32971/39424)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.632% (33078/39552)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.629% (33184/39680)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.604% (33281/39808)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.599% (33386/39936)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.609% (33497/40064)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.604% (33602/40192)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.596% (33706/40320)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.594% (33812/40448)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.606% (33924/40576)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.608% (34032/40704)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.606% (34138/40832)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.601% (34243/40960)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.603% (34351/41088)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.630% (34469/41216)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.628% (34575/41344)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.637% (34686/41472)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.637% (34793/41600)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.642% (34902/41728)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.625% (35002/41856)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.615% (35105/41984)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.627% (35217/42112)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.636% (35328/42240)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.648% (35440/42368)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.653% (35549/42496)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.636% (35649/42624)\n",
      "Train Epoch: 11 | Loss: 0.476 | Acc: 83.619% (35749/42752)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.605% (35850/42880)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.591% (35951/43008)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.587% (36056/43136)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.578% (36159/43264)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.573% (36264/43392)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.564% (36367/43520)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.562% (36473/43648)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.557% (36578/43776)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.562% (36687/43904)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.560% (36793/44032)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.530% (36887/44160)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.526% (36992/44288)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.528% (37100/44416)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.531% (37208/44544)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.531% (37315/44672)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.533% (37423/44800)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.525% (37526/44928)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.549% (37644/45056)\n",
      "Train Epoch: 11 | Loss: 0.477 | Acc: 83.556% (37754/45184)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.552% (37859/45312)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.537% (37959/45440)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.537% (38066/45568)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.532% (38171/45696)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.528% (38276/45824)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.533% (38385/45952)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.533% (38492/46080)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.540% (38602/46208)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.538% (38708/46336)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.533% (38813/46464)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.519% (38913/46592)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.523% (39022/46720)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.511% (39123/46848)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.498% (39224/46976)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.500% (39332/47104)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.486% (39432/47232)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.490% (39541/47360)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.497% (39651/47488)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.489% (39754/47616)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.495% (39864/47744)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.500% (39973/47872)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.490% (40075/48000)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.492% (40183/48128)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.480% (40284/48256)\n",
      "Train Epoch: 11 | Loss: 0.478 | Acc: 83.468% (40385/48384)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.445% (40481/48512)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.425% (40578/48640)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.428% (40686/48768)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.440% (40799/48896)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.439% (40905/49024)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.441% (41013/49152)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.433% (41116/49280)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.426% (41219/49408)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.414% (41320/49536)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.421% (41430/49664)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.433% (41543/49792)\n",
      "Train Epoch: 11 | Loss: 0.479 | Acc: 83.427% (41647/49920)\n",
      "Train Epoch: 11 | Loss: 0.480 | Acc: 83.420% (41710/50000)\n",
      "Test Epoch: 11 | Loss: 0.618 | Acc: 82.000% (82/100)\n",
      "Test Epoch: 11 | Loss: 0.686 | Acc: 79.500% (159/200)\n",
      "Test Epoch: 11 | Loss: 0.679 | Acc: 79.000% (237/300)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.000% (312/400)\n",
      "Test Epoch: 11 | Loss: 0.684 | Acc: 78.400% (392/500)\n",
      "Test Epoch: 11 | Loss: 0.627 | Acc: 80.167% (481/600)\n",
      "Test Epoch: 11 | Loss: 0.627 | Acc: 79.714% (558/700)\n",
      "Test Epoch: 11 | Loss: 0.654 | Acc: 79.375% (635/800)\n",
      "Test Epoch: 11 | Loss: 0.683 | Acc: 78.333% (705/900)\n",
      "Test Epoch: 11 | Loss: 0.688 | Acc: 78.400% (784/1000)\n",
      "Test Epoch: 11 | Loss: 0.698 | Acc: 78.091% (859/1100)\n",
      "Test Epoch: 11 | Loss: 0.697 | Acc: 78.250% (939/1200)\n",
      "Test Epoch: 11 | Loss: 0.681 | Acc: 78.385% (1019/1300)\n",
      "Test Epoch: 11 | Loss: 0.681 | Acc: 78.214% (1095/1400)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.333% (1175/1500)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.562% (1257/1600)\n",
      "Test Epoch: 11 | Loss: 0.666 | Acc: 79.000% (1343/1700)\n",
      "Test Epoch: 11 | Loss: 0.661 | Acc: 78.944% (1421/1800)\n",
      "Test Epoch: 11 | Loss: 0.659 | Acc: 78.947% (1500/1900)\n",
      "Test Epoch: 11 | Loss: 0.663 | Acc: 78.750% (1575/2000)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.571% (1650/2100)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.591% (1729/2200)\n",
      "Test Epoch: 11 | Loss: 0.675 | Acc: 78.609% (1808/2300)\n",
      "Test Epoch: 11 | Loss: 0.669 | Acc: 78.792% (1891/2400)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.800% (1970/2500)\n",
      "Test Epoch: 11 | Loss: 0.682 | Acc: 78.692% (2046/2600)\n",
      "Test Epoch: 11 | Loss: 0.681 | Acc: 78.704% (2125/2700)\n",
      "Test Epoch: 11 | Loss: 0.680 | Acc: 78.714% (2204/2800)\n",
      "Test Epoch: 11 | Loss: 0.681 | Acc: 78.862% (2287/2900)\n",
      "Test Epoch: 11 | Loss: 0.681 | Acc: 78.800% (2364/3000)\n",
      "Test Epoch: 11 | Loss: 0.683 | Acc: 78.710% (2440/3100)\n",
      "Test Epoch: 11 | Loss: 0.682 | Acc: 78.812% (2522/3200)\n",
      "Test Epoch: 11 | Loss: 0.682 | Acc: 78.818% (2601/3300)\n",
      "Test Epoch: 11 | Loss: 0.680 | Acc: 78.794% (2679/3400)\n",
      "Test Epoch: 11 | Loss: 0.679 | Acc: 78.829% (2759/3500)\n",
      "Test Epoch: 11 | Loss: 0.679 | Acc: 78.889% (2840/3600)\n",
      "Test Epoch: 11 | Loss: 0.680 | Acc: 78.811% (2916/3700)\n",
      "Test Epoch: 11 | Loss: 0.685 | Acc: 78.711% (2991/3800)\n",
      "Test Epoch: 11 | Loss: 0.678 | Acc: 78.949% (3079/3900)\n",
      "Test Epoch: 11 | Loss: 0.677 | Acc: 78.900% (3156/4000)\n",
      "Test Epoch: 11 | Loss: 0.674 | Acc: 78.951% (3237/4100)\n",
      "Test Epoch: 11 | Loss: 0.675 | Acc: 78.833% (3311/4200)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.907% (3393/4300)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.932% (3473/4400)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.956% (3553/4500)\n",
      "Test Epoch: 11 | Loss: 0.668 | Acc: 78.935% (3631/4600)\n",
      "Test Epoch: 11 | Loss: 0.667 | Acc: 78.936% (3710/4700)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.854% (3785/4800)\n",
      "Test Epoch: 11 | Loss: 0.667 | Acc: 78.959% (3869/4900)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.860% (3943/5000)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.882% (4023/5100)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.962% (4106/5200)\n",
      "Test Epoch: 11 | Loss: 0.668 | Acc: 78.925% (4183/5300)\n",
      "Test Epoch: 11 | Loss: 0.667 | Acc: 78.963% (4264/5400)\n",
      "Test Epoch: 11 | Loss: 0.667 | Acc: 79.018% (4346/5500)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.982% (4423/5600)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.930% (4499/5700)\n",
      "Test Epoch: 11 | Loss: 0.667 | Acc: 79.034% (4584/5800)\n",
      "Test Epoch: 11 | Loss: 0.669 | Acc: 78.983% (4660/5900)\n",
      "Test Epoch: 11 | Loss: 0.669 | Acc: 79.017% (4741/6000)\n",
      "Test Epoch: 11 | Loss: 0.669 | Acc: 78.967% (4817/6100)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.919% (4893/6200)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.857% (4968/6300)\n",
      "Test Epoch: 11 | Loss: 0.665 | Acc: 78.953% (5053/6400)\n",
      "Test Epoch: 11 | Loss: 0.666 | Acc: 78.938% (5131/6500)\n",
      "Test Epoch: 11 | Loss: 0.665 | Acc: 78.894% (5207/6600)\n",
      "Test Epoch: 11 | Loss: 0.665 | Acc: 78.925% (5288/6700)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.868% (5363/6800)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.884% (5443/6900)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.800% (5516/7000)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.873% (5600/7100)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.875% (5679/7200)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 78.918% (5761/7300)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.946% (5842/7400)\n",
      "Test Epoch: 11 | Loss: 0.670 | Acc: 78.880% (5916/7500)\n",
      "Test Epoch: 11 | Loss: 0.669 | Acc: 78.961% (6001/7600)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.883% (6074/7700)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.859% (6151/7800)\n",
      "Test Epoch: 11 | Loss: 0.674 | Acc: 78.848% (6229/7900)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.825% (6306/8000)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.827% (6385/8100)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.841% (6465/8200)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.819% (6542/8300)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.810% (6620/8400)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.788% (6697/8500)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.837% (6780/8600)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.816% (6857/8700)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.841% (6938/8800)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.865% (7019/8900)\n",
      "Test Epoch: 11 | Loss: 0.677 | Acc: 78.878% (7099/9000)\n",
      "Test Epoch: 11 | Loss: 0.679 | Acc: 78.813% (7172/9100)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.891% (7258/9200)\n",
      "Test Epoch: 11 | Loss: 0.676 | Acc: 78.935% (7341/9300)\n",
      "Test Epoch: 11 | Loss: 0.675 | Acc: 78.904% (7417/9400)\n",
      "Test Epoch: 11 | Loss: 0.674 | Acc: 78.937% (7499/9500)\n",
      "Test Epoch: 11 | Loss: 0.673 | Acc: 78.969% (7581/9600)\n",
      "Test Epoch: 11 | Loss: 0.671 | Acc: 79.031% (7666/9700)\n",
      "Test Epoch: 11 | Loss: 0.672 | Acc: 78.980% (7740/9800)\n",
      "Test Epoch: 11 | Loss: 0.675 | Acc: 78.929% (7814/9900)\n",
      "Test Epoch: 11 | Loss: 0.675 | Acc: 78.950% (7895/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Train Epoch: 12 | Loss: 0.438 | Acc: 86.719% (111/128)\n",
      "Train Epoch: 12 | Loss: 0.471 | Acc: 83.203% (213/256)\n",
      "Train Epoch: 12 | Loss: 0.426 | Acc: 84.896% (326/384)\n",
      "Train Epoch: 12 | Loss: 0.403 | Acc: 85.547% (438/512)\n",
      "Train Epoch: 12 | Loss: 0.424 | Acc: 84.688% (542/640)\n",
      "Train Epoch: 12 | Loss: 0.418 | Acc: 84.896% (652/768)\n",
      "Train Epoch: 12 | Loss: 0.403 | Acc: 85.826% (769/896)\n",
      "Train Epoch: 12 | Loss: 0.416 | Acc: 85.352% (874/1024)\n",
      "Train Epoch: 12 | Loss: 0.425 | Acc: 84.722% (976/1152)\n",
      "Train Epoch: 12 | Loss: 0.435 | Acc: 84.688% (1084/1280)\n",
      "Train Epoch: 12 | Loss: 0.440 | Acc: 84.517% (1190/1408)\n",
      "Train Epoch: 12 | Loss: 0.448 | Acc: 84.115% (1292/1536)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 83.894% (1396/1664)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.096% (1507/1792)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.167% (1616/1920)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.082% (1722/2048)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.099% (1830/2176)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.201% (1940/2304)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.211% (2048/2432)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 83.984% (2150/2560)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.115% (2261/2688)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.091% (2368/2816)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.103% (2476/2944)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.342% (2591/3072)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.281% (2697/3200)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.465% (2811/3328)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.375% (2916/3456)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.403% (3025/3584)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.321% (3130/3712)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.479% (3244/3840)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.526% (3354/3968)\n",
      "Train Epoch: 12 | Loss: 0.449 | Acc: 84.521% (3462/4096)\n",
      "Train Epoch: 12 | Loss: 0.449 | Acc: 84.517% (3570/4224)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.352% (3671/4352)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.397% (3781/4480)\n",
      "Train Epoch: 12 | Loss: 0.448 | Acc: 84.570% (3897/4608)\n",
      "Train Epoch: 12 | Loss: 0.448 | Acc: 84.671% (4010/4736)\n",
      "Train Epoch: 12 | Loss: 0.448 | Acc: 84.581% (4114/4864)\n",
      "Train Epoch: 12 | Loss: 0.449 | Acc: 84.495% (4218/4992)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.395% (4321/5120)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.375% (4428/5248)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.338% (4534/5376)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.339% (4642/5504)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.411% (4754/5632)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.392% (4861/5760)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.375% (4968/5888)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.441% (5080/6016)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.440% (5188/6144)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.487% (5299/6272)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.484% (5407/6400)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.436% (5512/6528)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.420% (5619/6656)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.449% (5729/6784)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.505% (5841/6912)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.531% (5951/7040)\n",
      "Train Epoch: 12 | Loss: 0.449 | Acc: 84.542% (6060/7168)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.581% (6171/7296)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.564% (6278/7424)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.507% (6382/7552)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.427% (6484/7680)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.477% (6596/7808)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.526% (6708/7936)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.549% (6818/8064)\n",
      "Train Epoch: 12 | Loss: 0.450 | Acc: 84.570% (6928/8192)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.591% (7038/8320)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.612% (7148/8448)\n",
      "Train Epoch: 12 | Loss: 0.452 | Acc: 84.503% (7247/8576)\n",
      "Train Epoch: 12 | Loss: 0.451 | Acc: 84.536% (7358/8704)\n",
      "Train Epoch: 12 | Loss: 0.453 | Acc: 84.454% (7459/8832)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.386% (7561/8960)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.441% (7674/9088)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.429% (7781/9216)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.450% (7891/9344)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.417% (7996/9472)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.438% (8106/9600)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.457% (8216/9728)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.476% (8326/9856)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.475% (8434/9984)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.434% (8538/10112)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.453% (8648/10240)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.462% (8757/10368)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.499% (8869/10496)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.526% (8980/10624)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.552% (9091/10752)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.540% (9198/10880)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.557% (9308/11008)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.519% (9412/11136)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.535% (9522/11264)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.533% (9630/11392)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.549% (9740/11520)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.538% (9847/11648)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.528% (9954/11776)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.484% (10057/11904)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.466% (10163/12032)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.441% (10268/12160)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.440% (10376/12288)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.480% (10489/12416)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.431% (10591/12544)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.493% (10707/12672)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.492% (10815/12800)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.483% (10922/12928)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.467% (11028/13056)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.451% (11134/13184)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.375% (11232/13312)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.420% (11346/13440)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.456% (11459/13568)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.419% (11562/13696)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.462% (11676/13824)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.432% (11780/13952)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.489% (11896/14080)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.488% (12004/14208)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.466% (12109/14336)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.506% (12223/14464)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.485% (12328/14592)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.518% (12441/14720)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.496% (12546/14848)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.502% (12655/14976)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.521% (12766/15104)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.559% (12880/15232)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.499% (12979/15360)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.530% (13092/15488)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.535% (13201/15616)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.521% (13307/15744)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.495% (13411/15872)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.500% (13520/16000)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.487% (13626/16128)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.516% (13739/16256)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.515% (13847/16384)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.539% (13959/16512)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.495% (14060/16640)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.512% (14171/16768)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.529% (14282/16896)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.551% (14394/17024)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.550% (14502/17152)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.566% (14613/17280)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.582% (14724/17408)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.552% (14827/17536)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.573% (14939/17664)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.572% (15047/17792)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.570% (15155/17920)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.574% (15264/18048)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.579% (15373/18176)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.566% (15479/18304)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.565% (15587/18432)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.601% (15702/18560)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.605% (15811/18688)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.609% (15920/18816)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.607% (16028/18944)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.590% (16133/19072)\n",
      "Train Epoch: 12 | Loss: 0.454 | Acc: 84.589% (16241/19200)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.566% (16345/19328)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.545% (16449/19456)\n",
      "Train Epoch: 12 | Loss: 0.455 | Acc: 84.549% (16558/19584)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.512% (16659/19712)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.531% (16771/19840)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.515% (16876/19968)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.504% (16982/20096)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.499% (17089/20224)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.488% (17195/20352)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.497% (17305/20480)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.501% (17414/20608)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.486% (17519/20736)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.466% (17623/20864)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.466% (17731/20992)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.474% (17841/21120)\n",
      "Train Epoch: 12 | Loss: 0.456 | Acc: 84.450% (17944/21248)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.459% (18054/21376)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.449% (18160/21504)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.430% (18264/21632)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.430% (18372/21760)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.430% (18480/21888)\n",
      "Train Epoch: 12 | Loss: 0.457 | Acc: 84.443% (18591/22016)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.434% (18697/22144)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.397% (18797/22272)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.406% (18907/22400)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.411% (19016/22528)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.388% (19119/22656)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.379% (19225/22784)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.358% (19328/22912)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.362% (19437/23040)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.362% (19545/23168)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.362% (19653/23296)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.375% (19764/23424)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.350% (19866/23552)\n",
      "Train Epoch: 12 | Loss: 0.458 | Acc: 84.358% (19976/23680)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.304% (20071/23808)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.300% (20178/23936)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.296% (20285/24064)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.313% (20397/24192)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.334% (20510/24320)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.338% (20619/24448)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.342% (20728/24576)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.339% (20835/24704)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.319% (20938/24832)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.295% (21040/24960)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.279% (21144/25088)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.276% (21251/25216)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.284% (21361/25344)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.281% (21468/25472)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.266% (21572/25600)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.289% (21686/25728)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.278% (21791/25856)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.286% (21901/25984)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.291% (22010/26112)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.276% (22114/26240)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.257% (22217/26368)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.262% (22326/26496)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.251% (22431/26624)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.259% (22541/26752)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.249% (22646/26880)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.257% (22756/27008)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.253% (22863/27136)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.250% (22970/27264)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.222% (23070/27392)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.175% (23165/27520)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.194% (23278/27648)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.195% (23386/27776)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.214% (23499/27904)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.204% (23604/28032)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.208% (23713/28160)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.227% (23826/28288)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.224% (23933/28416)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.221% (24040/28544)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.235% (24152/28672)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.233% (24259/28800)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.213% (24361/28928)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.227% (24473/29056)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.228% (24581/29184)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.256% (24697/29312)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.270% (24809/29440)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.257% (24913/29568)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.277% (25027/29696)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.295% (25140/29824)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.282% (25244/29952)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.309% (25360/30080)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.299% (25465/30208)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.289% (25570/30336)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.306% (25683/30464)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.326% (25797/30592)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.313% (25901/30720)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.310% (26008/30848)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.294% (26111/30976)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.301% (26221/31104)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.289% (26325/31232)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.289% (26433/31360)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.299% (26544/31488)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.277% (26645/31616)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.277% (26753/31744)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.281% (26862/31872)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.263% (26964/32000)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.260% (27071/32128)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.270% (27182/32256)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.282% (27294/32384)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.298% (27407/32512)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.308% (27518/32640)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.332% (27634/32768)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.323% (27739/32896)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.311% (27843/33024)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.300% (27947/33152)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.309% (28058/33280)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.294% (28161/33408)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.292% (28268/33536)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.277% (28371/33664)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.295% (28485/33792)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.278% (28587/33920)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.284% (28697/34048)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.270% (28800/34176)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.273% (28909/34304)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.282% (29020/34432)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.297% (29133/34560)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.303% (29243/34688)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.306% (29352/34816)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.301% (29458/34944)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.292% (29563/35072)\n",
      "Train Epoch: 12 | Loss: 0.459 | Acc: 84.312% (29678/35200)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.290% (29778/35328)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.276% (29881/35456)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.282% (29991/35584)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.294% (30103/35712)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.291% (30210/35840)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.278% (30313/35968)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.286% (30424/36096)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.281% (30530/36224)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.287% (30640/36352)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.276% (30744/36480)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.277% (30852/36608)\n",
      "Train Epoch: 12 | Loss: 0.460 | Acc: 84.285% (30963/36736)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.256% (31060/36864)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.248% (31165/36992)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.238% (31269/37120)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.227% (31373/37248)\n",
      "Train Epoch: 12 | Loss: 0.461 | Acc: 84.239% (31485/37376)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.226% (31588/37504)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.216% (31692/37632)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.213% (31799/37760)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.217% (31908/37888)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.207% (32012/38016)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.197% (32116/38144)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.210% (32229/38272)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.201% (32333/38400)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.217% (32447/38528)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.217% (32555/38656)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.213% (32661/38784)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.208% (32767/38912)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.211% (32876/39040)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.209% (32983/39168)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.207% (33090/39296)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.203% (33196/39424)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.211% (33307/39552)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.209% (33414/39680)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.209% (33522/39808)\n",
      "Train Epoch: 12 | Loss: 0.462 | Acc: 84.197% (33625/39936)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.178% (33725/40064)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.183% (33835/40192)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.182% (33942/40320)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.160% (34041/40448)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.148% (34144/40576)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.164% (34258/40704)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.167% (34367/40832)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.167% (34475/40960)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.175% (34586/41088)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.161% (34688/41216)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.165% (34797/41344)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.168% (34906/41472)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.161% (35011/41600)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.164% (35120/41728)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.153% (35223/41856)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.153% (35331/41984)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.157% (35440/42112)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.164% (35551/42240)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.163% (35658/42368)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.177% (35772/42496)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.185% (35883/42624)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.174% (35986/42752)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.179% (36096/42880)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.177% (36203/43008)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.185% (36314/43136)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.185% (36422/43264)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.200% (36536/43392)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.189% (36639/43520)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.192% (36748/43648)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.192% (36856/43776)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.204% (36969/43904)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.211% (37080/44032)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.203% (37184/44160)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.210% (37295/44288)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.217% (37406/44416)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.207% (37509/44544)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.198% (37613/44672)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.201% (37722/44800)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.206% (37832/44928)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.200% (37937/45056)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.200% (38045/45184)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.190% (38148/45312)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.184% (38253/45440)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.191% (38364/45568)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.191% (38472/45696)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.194% (38581/45824)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.197% (38690/45952)\n",
      "Train Epoch: 12 | Loss: 0.463 | Acc: 84.173% (38787/46080)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.174% (38895/46208)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.159% (38996/46336)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.155% (39102/46464)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.156% (39210/46592)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.152% (39316/46720)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.140% (39418/46848)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.143% (39527/46976)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.129% (39628/47104)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.134% (39738/47232)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.126% (39842/47360)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.118% (39946/47488)\n",
      "Train Epoch: 12 | Loss: 0.464 | Acc: 84.115% (40052/47616)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.109% (40157/47744)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.103% (40262/47872)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.104% (40370/48000)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.103% (40477/48128)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.099% (40583/48256)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.104% (40693/48384)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.101% (40799/48512)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.085% (40899/48640)\n",
      "Train Epoch: 12 | Loss: 0.465 | Acc: 84.080% (41004/48768)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.070% (41107/48896)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.063% (41211/49024)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.062% (41318/49152)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.060% (41425/49280)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.057% (41531/49408)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.052% (41636/49536)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.067% (41751/49664)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.060% (41855/49792)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.034% (41950/49920)\n",
      "Train Epoch: 12 | Loss: 0.466 | Acc: 84.028% (42014/50000)\n",
      "Test Epoch: 12 | Loss: 0.628 | Acc: 81.000% (81/100)\n",
      "Test Epoch: 12 | Loss: 0.537 | Acc: 83.500% (167/200)\n",
      "Test Epoch: 12 | Loss: 0.491 | Acc: 84.667% (254/300)\n",
      "Test Epoch: 12 | Loss: 0.493 | Acc: 83.250% (333/400)\n",
      "Test Epoch: 12 | Loss: 0.488 | Acc: 83.000% (415/500)\n",
      "Test Epoch: 12 | Loss: 0.463 | Acc: 83.500% (501/600)\n",
      "Test Epoch: 12 | Loss: 0.477 | Acc: 83.000% (581/700)\n",
      "Test Epoch: 12 | Loss: 0.499 | Acc: 82.375% (659/800)\n",
      "Test Epoch: 12 | Loss: 0.509 | Acc: 81.778% (736/900)\n",
      "Test Epoch: 12 | Loss: 0.519 | Acc: 81.600% (816/1000)\n",
      "Test Epoch: 12 | Loss: 0.534 | Acc: 81.364% (895/1100)\n",
      "Test Epoch: 12 | Loss: 0.537 | Acc: 81.083% (973/1200)\n",
      "Test Epoch: 12 | Loss: 0.528 | Acc: 81.154% (1055/1300)\n",
      "Test Epoch: 12 | Loss: 0.521 | Acc: 81.500% (1141/1400)\n",
      "Test Epoch: 12 | Loss: 0.518 | Acc: 81.667% (1225/1500)\n",
      "Test Epoch: 12 | Loss: 0.526 | Acc: 81.562% (1305/1600)\n",
      "Test Epoch: 12 | Loss: 0.525 | Acc: 81.882% (1392/1700)\n",
      "Test Epoch: 12 | Loss: 0.536 | Acc: 81.611% (1469/1800)\n",
      "Test Epoch: 12 | Loss: 0.534 | Acc: 81.789% (1554/1900)\n",
      "Test Epoch: 12 | Loss: 0.544 | Acc: 81.500% (1630/2000)\n",
      "Test Epoch: 12 | Loss: 0.542 | Acc: 81.524% (1712/2100)\n",
      "Test Epoch: 12 | Loss: 0.539 | Acc: 81.727% (1798/2200)\n",
      "Test Epoch: 12 | Loss: 0.542 | Acc: 81.522% (1875/2300)\n",
      "Test Epoch: 12 | Loss: 0.542 | Acc: 81.583% (1958/2400)\n",
      "Test Epoch: 12 | Loss: 0.544 | Acc: 81.600% (2040/2500)\n",
      "Test Epoch: 12 | Loss: 0.553 | Acc: 81.538% (2120/2600)\n",
      "Test Epoch: 12 | Loss: 0.552 | Acc: 81.519% (2201/2700)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.536% (2283/2800)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.552% (2365/2900)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.467% (2444/3000)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.419% (2524/3100)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.500% (2608/3200)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.485% (2689/3300)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.324% (2765/3400)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.200% (2842/3500)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.028% (2917/3600)\n",
      "Test Epoch: 12 | Loss: 0.566 | Acc: 80.946% (2995/3700)\n",
      "Test Epoch: 12 | Loss: 0.568 | Acc: 80.974% (3077/3800)\n",
      "Test Epoch: 12 | Loss: 0.565 | Acc: 81.128% (3164/3900)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.175% (3247/4000)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.146% (3327/4100)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.143% (3408/4200)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.302% (3496/4300)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.386% (3581/4400)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.489% (3667/4500)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.370% (3743/4600)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.298% (3821/4700)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.271% (3901/4800)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.327% (3985/4900)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.280% (4064/5000)\n",
      "Test Epoch: 12 | Loss: 0.555 | Acc: 81.333% (4148/5100)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.269% (4226/5200)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.132% (4300/5300)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.167% (4383/5400)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.073% (4459/5500)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.071% (4540/5600)\n",
      "Test Epoch: 12 | Loss: 0.563 | Acc: 81.035% (4619/5700)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.155% (4707/5800)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.085% (4784/5900)\n",
      "Test Epoch: 12 | Loss: 0.564 | Acc: 81.050% (4863/6000)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.033% (4943/6100)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.097% (5028/6200)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.143% (5112/6300)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.203% (5197/6400)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.138% (5274/6500)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.182% (5358/6600)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.299% (5447/6700)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.265% (5526/6800)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.246% (5606/6900)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.186% (5683/7000)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.183% (5764/7100)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.222% (5848/7200)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.247% (5931/7300)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.270% (6014/7400)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.227% (6092/7500)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.211% (6172/7600)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.143% (6248/7700)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.179% (6332/7800)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.177% (6413/7900)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.150% (6492/8000)\n",
      "Test Epoch: 12 | Loss: 0.557 | Acc: 81.210% (6578/8100)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.256% (6663/8200)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.253% (6744/8300)\n",
      "Test Epoch: 12 | Loss: 0.555 | Acc: 81.250% (6825/8400)\n",
      "Test Epoch: 12 | Loss: 0.556 | Acc: 81.235% (6905/8500)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.163% (6980/8600)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.172% (7062/8700)\n",
      "Test Epoch: 12 | Loss: 0.559 | Acc: 81.148% (7141/8800)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.056% (7214/8900)\n",
      "Test Epoch: 12 | Loss: 0.562 | Acc: 81.033% (7293/9000)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.011% (7372/9100)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.022% (7454/9200)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 80.989% (7532/9300)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.021% (7616/9400)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.042% (7699/9500)\n",
      "Test Epoch: 12 | Loss: 0.561 | Acc: 81.031% (7779/9600)\n",
      "Test Epoch: 12 | Loss: 0.558 | Acc: 81.103% (7867/9700)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.051% (7943/9800)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.030% (8022/9900)\n",
      "Test Epoch: 12 | Loss: 0.560 | Acc: 81.050% (8105/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 13\n",
      "Train Epoch: 13 | Loss: 0.468 | Acc: 83.594% (107/128)\n",
      "Train Epoch: 13 | Loss: 0.400 | Acc: 85.938% (220/256)\n",
      "Train Epoch: 13 | Loss: 0.386 | Acc: 86.719% (333/384)\n",
      "Train Epoch: 13 | Loss: 0.359 | Acc: 87.500% (448/512)\n",
      "Train Epoch: 13 | Loss: 0.361 | Acc: 87.656% (561/640)\n",
      "Train Epoch: 13 | Loss: 0.372 | Acc: 87.240% (670/768)\n",
      "Train Epoch: 13 | Loss: 0.385 | Acc: 86.607% (776/896)\n",
      "Train Epoch: 13 | Loss: 0.392 | Acc: 86.035% (881/1024)\n",
      "Train Epoch: 13 | Loss: 0.407 | Acc: 85.590% (986/1152)\n",
      "Train Epoch: 13 | Loss: 0.406 | Acc: 85.938% (1100/1280)\n",
      "Train Epoch: 13 | Loss: 0.412 | Acc: 85.724% (1207/1408)\n",
      "Train Epoch: 13 | Loss: 0.406 | Acc: 85.872% (1319/1536)\n",
      "Train Epoch: 13 | Loss: 0.405 | Acc: 85.877% (1429/1664)\n",
      "Train Epoch: 13 | Loss: 0.403 | Acc: 85.882% (1539/1792)\n",
      "Train Epoch: 13 | Loss: 0.403 | Acc: 85.833% (1648/1920)\n",
      "Train Epoch: 13 | Loss: 0.407 | Acc: 85.889% (1759/2048)\n",
      "Train Epoch: 13 | Loss: 0.416 | Acc: 85.478% (1860/2176)\n",
      "Train Epoch: 13 | Loss: 0.422 | Acc: 85.243% (1964/2304)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 84.992% (2067/2432)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.000% (2176/2560)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.045% (2286/2688)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.979% (2393/2816)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.156% (2507/2944)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.254% (2619/3072)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 85.188% (2726/3200)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 85.156% (2834/3328)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.272% (2947/3456)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.324% (3058/3584)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.372% (3169/3712)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.391% (3279/3840)\n",
      "Train Epoch: 13 | Loss: 0.426 | Acc: 85.534% (3394/3968)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.376% (3497/4096)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.298% (3603/4224)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.340% (3714/4352)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.246% (3819/4480)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.286% (3930/4608)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.346% (4042/4736)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.403% (4154/4864)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.417% (4264/4992)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.371% (4371/5120)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.271% (4475/5248)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.212% (4581/5376)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.138% (4686/5504)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.174% (4797/5632)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.069% (4900/5760)\n",
      "Train Epoch: 13 | Loss: 0.430 | Acc: 85.156% (5014/5888)\n",
      "Train Epoch: 13 | Loss: 0.429 | Acc: 85.173% (5124/6016)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.945% (5219/6144)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.917% (5326/6272)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.953% (5437/6400)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.896% (5542/6528)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.886% (5650/6656)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.802% (5753/6784)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.650% (5851/6912)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.688% (5962/7040)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.738% (6074/7168)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.690% (6179/7296)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.725% (6290/7424)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.878% (6410/7552)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.779% (6511/7680)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.798% (6621/7808)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.740% (6725/7936)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.710% (6831/8064)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.778% (6945/8192)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.856% (7060/8320)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.860% (7169/8448)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.806% (7273/8576)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.743% (7376/8704)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.715% (7482/8832)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.766% (7595/8960)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.749% (7702/9088)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.776% (7813/9216)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.771% (7921/9344)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.734% (8026/9472)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.740% (8135/9600)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.714% (8241/9728)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.700% (8348/9856)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.706% (8457/9984)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.731% (8568/10112)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.785% (8682/10240)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.790% (8791/10368)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.708% (8891/10496)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.733% (9002/10624)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.766% (9114/10752)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.779% (9224/10880)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.829% (9338/11008)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.806% (9444/11136)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.819% (9554/11264)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.796% (9660/11392)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.844% (9774/11520)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.899% (9889/11648)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.918% (10000/11776)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.946% (10112/11904)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.948% (10221/12032)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.901% (10324/12160)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.912% (10434/12288)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.882% (10539/12416)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.949% (10656/12544)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.943% (10764/12672)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.016% (10882/12800)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.009% (10990/12928)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.980% (11095/13056)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.951% (11200/13184)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.953% (11309/13312)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.933% (11415/13440)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.920% (11522/13568)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 84.974% (11638/13696)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.983% (11748/13824)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.977% (11856/13952)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.000% (11968/14080)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.023% (12080/14208)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.961% (12180/14336)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.032% (12299/14464)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.060% (12412/14592)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.041% (12518/14720)\n",
      "Train Epoch: 13 | Loss: 0.431 | Acc: 85.042% (12627/14848)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.989% (12728/14976)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.004% (12839/15104)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 84.999% (12947/15232)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.013% (13058/15360)\n",
      "Train Epoch: 13 | Loss: 0.432 | Acc: 85.040% (13171/15488)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.035% (13279/15616)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.010% (13384/15744)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 84.992% (13490/15872)\n",
      "Train Epoch: 13 | Loss: 0.433 | Acc: 85.019% (13603/16000)\n",
      "Train Epoch: 13 | Loss: 0.434 | Acc: 85.014% (13711/16128)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.984% (13815/16256)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.991% (13925/16384)\n",
      "Train Epoch: 13 | Loss: 0.435 | Acc: 84.969% (14030/16512)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.916% (14130/16640)\n",
      "Train Epoch: 13 | Loss: 0.436 | Acc: 84.936% (14242/16768)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.931% (14350/16896)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.927% (14458/17024)\n",
      "Train Epoch: 13 | Loss: 0.437 | Acc: 84.900% (14562/17152)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.838% (14660/17280)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.840% (14769/17408)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.860% (14881/17536)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.856% (14989/17664)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.853% (15097/17792)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.849% (15205/17920)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.874% (15318/18048)\n",
      "Train Epoch: 13 | Loss: 0.438 | Acc: 84.843% (15421/18176)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.834% (15528/18304)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.825% (15635/18432)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.795% (15738/18560)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.798% (15847/18688)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.805% (15957/18816)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.829% (16070/18944)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.831% (16179/19072)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.807% (16283/19200)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.779% (16386/19328)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.745% (16488/19456)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.722% (16592/19584)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.745% (16705/19712)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.728% (16810/19840)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.766% (16926/19968)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.768% (17035/20096)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.800% (17150/20224)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.812% (17261/20352)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.810% (17369/20480)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.812% (17478/20608)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.828% (17590/20736)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.830% (17699/20864)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.861% (17814/20992)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.839% (17918/21120)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.864% (18032/21248)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.862% (18140/21376)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.873% (18251/21504)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.860% (18357/21632)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.862% (18466/21760)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.832% (18568/21888)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.843% (18679/22016)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.831% (18785/22144)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.860% (18900/22272)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.875% (19012/22400)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.885% (19123/22528)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.878% (19230/22656)\n",
      "Train Epoch: 13 | Loss: 0.439 | Acc: 84.884% (19340/22784)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.825% (19435/22912)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.831% (19545/23040)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.828% (19653/23168)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.826% (19761/23296)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.832% (19871/23424)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.817% (19976/23552)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.810% (20083/23680)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.816% (20193/23808)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.801% (20298/23936)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.828% (20413/24064)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.821% (20520/24192)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.819% (20628/24320)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.837% (20741/24448)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.851% (20853/24576)\n",
      "Train Epoch: 13 | Loss: 0.440 | Acc: 84.820% (20954/24704)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.790% (21055/24832)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.788% (21163/24960)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.794% (21273/25088)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.795% (21382/25216)\n",
      "Train Epoch: 13 | Loss: 0.441 | Acc: 84.797% (21491/25344)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.772% (21593/25472)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.770% (21701/25600)\n",
      "Train Epoch: 13 | Loss: 0.442 | Acc: 84.752% (21805/25728)\n",
      "Train Epoch: 13 | Loss: 0.443 | Acc: 84.735% (21909/25856)\n",
      "Train Epoch: 13 | Loss: 0.443 | Acc: 84.741% (22019/25984)\n",
      "Train Epoch: 13 | Loss: 0.443 | Acc: 84.754% (22131/26112)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.745% (22237/26240)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.735% (22343/26368)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.722% (22448/26496)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.724% (22557/26624)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.719% (22664/26752)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.728% (22775/26880)\n",
      "Train Epoch: 13 | Loss: 0.443 | Acc: 84.745% (22888/27008)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.740% (22995/27136)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.716% (23097/27264)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.718% (23206/27392)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.717% (23314/27520)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.715% (23422/27648)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.699% (23526/27776)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.730% (23643/27904)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.725% (23750/28032)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.723% (23858/28160)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.725% (23967/28288)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.730% (24077/28416)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.750% (24191/28544)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.741% (24297/28672)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.750% (24408/28800)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.773% (24523/28928)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.785% (24635/29056)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.755% (24735/29184)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.747% (24841/29312)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.732% (24945/29440)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.754% (25060/29568)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.762% (25171/29696)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.757% (25278/29824)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.759% (25387/29952)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.754% (25494/30080)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.756% (25603/30208)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.761% (25713/30336)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.759% (25821/30464)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.767% (25932/30592)\n",
      "Train Epoch: 13 | Loss: 0.444 | Acc: 84.779% (26044/30720)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.764% (26148/30848)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.753% (26253/30976)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.722% (26352/31104)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.740% (26466/31232)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.739% (26574/31360)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.737% (26682/31488)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.758% (26797/31616)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.766% (26908/31744)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.752% (27012/31872)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.756% (27122/32000)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.739% (27225/32128)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.744% (27335/32256)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.749% (27445/32384)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.750% (27554/32512)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.767% (27668/32640)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.784% (27782/32768)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.785% (27891/32896)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.781% (27998/33024)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.764% (28101/33152)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.754% (28206/33280)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.764% (28318/33408)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.766% (28427/33536)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.776% (28539/33664)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.772% (28646/33792)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.767% (28753/33920)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.771% (28863/34048)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.770% (28971/34176)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.760% (29076/34304)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.779% (29191/34432)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.786% (29302/34560)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.770% (29405/34688)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.737% (29502/34816)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.738% (29611/34944)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.757% (29726/35072)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.739% (29828/35200)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.749% (29940/35328)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.747% (30048/35456)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.732% (30151/35584)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.747% (30265/35712)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.741% (30371/35840)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.723% (30473/35968)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.730% (30584/36096)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.723% (30690/36224)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.722% (30798/36352)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.720% (30906/36480)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.736% (31020/36608)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.734% (31128/36736)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.728% (31234/36864)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.726% (31342/36992)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.725% (31450/37120)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.737% (31563/37248)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.744% (31674/37376)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.732% (31778/37504)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.723% (31883/37632)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.714% (31988/37760)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.702% (32092/37888)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.722% (32208/38016)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.724% (32317/38144)\n",
      "Train Epoch: 13 | Loss: 0.445 | Acc: 84.728% (32427/38272)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.714% (32530/38400)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.707% (32636/38528)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.693% (32739/38656)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.690% (32846/38784)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.681% (32951/38912)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.677% (33058/39040)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.674% (33165/39168)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.665% (33270/39296)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.669% (33380/39424)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.676% (33491/39552)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.657% (33592/39680)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.649% (33697/39808)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.648% (33805/39936)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.637% (33909/40064)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.629% (34014/40192)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.608% (34114/40320)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.612% (34224/40448)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.589% (34323/40576)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.591% (34432/40704)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.588% (34539/40832)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.578% (34643/40960)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.575% (34750/41088)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.586% (34863/41216)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.576% (34967/41344)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.580% (35077/41472)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.577% (35184/41600)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.579% (35293/41728)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.566% (35396/41856)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.570% (35506/41984)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.565% (35612/42112)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.564% (35720/42240)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.564% (35828/42368)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.566% (35937/42496)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.577% (36050/42624)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.578% (36159/42752)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.569% (36263/42880)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.561% (36368/43008)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.551% (36472/43136)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.560% (36584/43264)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.550% (36688/43392)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.540% (36792/43520)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.547% (36903/43648)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.542% (37009/43776)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.532% (37113/43904)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.534% (37222/44032)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.538% (37332/44160)\n",
      "Train Epoch: 13 | Loss: 0.449 | Acc: 84.542% (37442/44288)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.564% (37560/44416)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.564% (37668/44544)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.576% (37782/44672)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.574% (37889/44800)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.582% (38001/44928)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.590% (38113/45056)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.587% (38220/45184)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.582% (38326/45312)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.580% (38433/45440)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.588% (38545/45568)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.589% (38654/45696)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.587% (38761/45824)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.580% (38866/45952)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.581% (38975/46080)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.583% (39084/46208)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.586% (39194/46336)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.595% (39306/46464)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.605% (39419/46592)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.628% (39538/46720)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.625% (39645/46848)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.618% (39750/46976)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.613% (39856/47104)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.623% (39969/47232)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.643% (40087/47360)\n",
      "Train Epoch: 13 | Loss: 0.448 | Acc: 84.649% (40198/47488)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.673% (40318/47616)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.672% (40426/47744)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.674% (40535/47872)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.673% (40643/48000)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.674% (40752/48128)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.682% (40864/48256)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.681% (40972/48384)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.692% (41086/48512)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.696% (41196/48640)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.691% (41302/48768)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.702% (41416/48896)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.705% (41526/49024)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.709% (41636/49152)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.698% (41739/49280)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.689% (41843/49408)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.690% (41952/49536)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.683% (42057/49664)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.688% (42168/49792)\n",
      "Train Epoch: 13 | Loss: 0.446 | Acc: 84.696% (42280/49920)\n",
      "Train Epoch: 13 | Loss: 0.447 | Acc: 84.682% (42341/50000)\n",
      "Test Epoch: 13 | Loss: 0.455 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 13 | Loss: 0.443 | Acc: 86.500% (173/200)\n",
      "Test Epoch: 13 | Loss: 0.485 | Acc: 84.000% (252/300)\n",
      "Test Epoch: 13 | Loss: 0.489 | Acc: 83.750% (335/400)\n",
      "Test Epoch: 13 | Loss: 0.488 | Acc: 83.800% (419/500)\n",
      "Test Epoch: 13 | Loss: 0.463 | Acc: 84.000% (504/600)\n",
      "Test Epoch: 13 | Loss: 0.480 | Acc: 83.714% (586/700)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 82.625% (661/800)\n",
      "Test Epoch: 13 | Loss: 0.519 | Acc: 82.444% (742/900)\n",
      "Test Epoch: 13 | Loss: 0.520 | Acc: 82.500% (825/1000)\n",
      "Test Epoch: 13 | Loss: 0.518 | Acc: 82.909% (912/1100)\n",
      "Test Epoch: 13 | Loss: 0.521 | Acc: 83.167% (998/1200)\n",
      "Test Epoch: 13 | Loss: 0.515 | Acc: 83.308% (1083/1300)\n",
      "Test Epoch: 13 | Loss: 0.501 | Acc: 83.643% (1171/1400)\n",
      "Test Epoch: 13 | Loss: 0.499 | Acc: 83.467% (1252/1500)\n",
      "Test Epoch: 13 | Loss: 0.505 | Acc: 83.375% (1334/1600)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.118% (1413/1700)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.167% (1497/1800)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.158% (1580/1900)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.100% (1662/2000)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.095% (1745/2100)\n",
      "Test Epoch: 13 | Loss: 0.514 | Acc: 82.909% (1824/2200)\n",
      "Test Epoch: 13 | Loss: 0.523 | Acc: 82.870% (1906/2300)\n",
      "Test Epoch: 13 | Loss: 0.518 | Acc: 83.000% (1992/2400)\n",
      "Test Epoch: 13 | Loss: 0.520 | Acc: 82.840% (2071/2500)\n",
      "Test Epoch: 13 | Loss: 0.528 | Acc: 82.654% (2149/2600)\n",
      "Test Epoch: 13 | Loss: 0.523 | Acc: 82.778% (2235/2700)\n",
      "Test Epoch: 13 | Loss: 0.521 | Acc: 82.786% (2318/2800)\n",
      "Test Epoch: 13 | Loss: 0.520 | Acc: 82.862% (2403/2900)\n",
      "Test Epoch: 13 | Loss: 0.519 | Acc: 82.933% (2488/3000)\n",
      "Test Epoch: 13 | Loss: 0.524 | Acc: 82.935% (2571/3100)\n",
      "Test Epoch: 13 | Loss: 0.520 | Acc: 83.094% (2659/3200)\n",
      "Test Epoch: 13 | Loss: 0.519 | Acc: 83.091% (2742/3300)\n",
      "Test Epoch: 13 | Loss: 0.522 | Acc: 83.000% (2822/3400)\n",
      "Test Epoch: 13 | Loss: 0.526 | Acc: 83.000% (2905/3500)\n",
      "Test Epoch: 13 | Loss: 0.526 | Acc: 83.083% (2991/3600)\n",
      "Test Epoch: 13 | Loss: 0.527 | Acc: 83.081% (3074/3700)\n",
      "Test Epoch: 13 | Loss: 0.528 | Acc: 82.947% (3152/3800)\n",
      "Test Epoch: 13 | Loss: 0.524 | Acc: 83.026% (3238/3900)\n",
      "Test Epoch: 13 | Loss: 0.521 | Acc: 83.125% (3325/4000)\n",
      "Test Epoch: 13 | Loss: 0.521 | Acc: 83.122% (3408/4100)\n",
      "Test Epoch: 13 | Loss: 0.520 | Acc: 83.095% (3490/4200)\n",
      "Test Epoch: 13 | Loss: 0.518 | Acc: 83.233% (3579/4300)\n",
      "Test Epoch: 13 | Loss: 0.515 | Acc: 83.341% (3667/4400)\n",
      "Test Epoch: 13 | Loss: 0.512 | Acc: 83.333% (3750/4500)\n",
      "Test Epoch: 13 | Loss: 0.512 | Acc: 83.348% (3834/4600)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.404% (3920/4700)\n",
      "Test Epoch: 13 | Loss: 0.512 | Acc: 83.312% (3999/4800)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.306% (4082/4900)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.260% (4163/5000)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.353% (4251/5100)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.308% (4332/5200)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.283% (4414/5300)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.333% (4500/5400)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.291% (4581/5500)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.321% (4666/5600)\n",
      "Test Epoch: 13 | Loss: 0.515 | Acc: 83.246% (4745/5700)\n",
      "Test Epoch: 13 | Loss: 0.511 | Acc: 83.328% (4833/5800)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.237% (4911/5900)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.200% (4992/6000)\n",
      "Test Epoch: 13 | Loss: 0.513 | Acc: 83.197% (5075/6100)\n",
      "Test Epoch: 13 | Loss: 0.511 | Acc: 83.226% (5160/6200)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.317% (5249/6300)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.359% (5335/6400)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.385% (5420/6500)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.364% (5502/6600)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.478% (5593/6700)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.397% (5671/6800)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.420% (5756/6900)\n",
      "Test Epoch: 13 | Loss: 0.510 | Acc: 83.343% (5834/7000)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.423% (5923/7100)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.444% (6008/7200)\n",
      "Test Epoch: 13 | Loss: 0.504 | Acc: 83.562% (6100/7300)\n",
      "Test Epoch: 13 | Loss: 0.502 | Acc: 83.622% (6188/7400)\n",
      "Test Epoch: 13 | Loss: 0.502 | Acc: 83.560% (6267/7500)\n",
      "Test Epoch: 13 | Loss: 0.504 | Acc: 83.513% (6347/7600)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.468% (6427/7700)\n",
      "Test Epoch: 13 | Loss: 0.506 | Acc: 83.538% (6516/7800)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.494% (6596/7900)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.513% (6681/8000)\n",
      "Test Epoch: 13 | Loss: 0.506 | Acc: 83.593% (6771/8100)\n",
      "Test Epoch: 13 | Loss: 0.504 | Acc: 83.634% (6858/8200)\n",
      "Test Epoch: 13 | Loss: 0.504 | Acc: 83.627% (6941/8300)\n",
      "Test Epoch: 13 | Loss: 0.503 | Acc: 83.679% (7029/8400)\n",
      "Test Epoch: 13 | Loss: 0.505 | Acc: 83.624% (7108/8500)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.593% (7189/8600)\n",
      "Test Epoch: 13 | Loss: 0.505 | Acc: 83.632% (7276/8700)\n",
      "Test Epoch: 13 | Loss: 0.506 | Acc: 83.636% (7360/8800)\n",
      "Test Epoch: 13 | Loss: 0.506 | Acc: 83.618% (7442/8900)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.522% (7517/9000)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.473% (7596/9100)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.554% (7687/9200)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.538% (7769/9300)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.553% (7854/9400)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.547% (7937/9500)\n",
      "Test Epoch: 13 | Loss: 0.507 | Acc: 83.562% (8022/9600)\n",
      "Test Epoch: 13 | Loss: 0.506 | Acc: 83.588% (8108/9700)\n",
      "Test Epoch: 13 | Loss: 0.508 | Acc: 83.500% (8183/9800)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.485% (8265/9900)\n",
      "Test Epoch: 13 | Loss: 0.509 | Acc: 83.490% (8349/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 14\n",
      "Train Epoch: 14 | Loss: 0.334 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 14 | Loss: 0.336 | Acc: 88.281% (226/256)\n",
      "Train Epoch: 14 | Loss: 0.393 | Acc: 86.979% (334/384)\n",
      "Train Epoch: 14 | Loss: 0.409 | Acc: 85.352% (437/512)\n",
      "Train Epoch: 14 | Loss: 0.426 | Acc: 85.156% (545/640)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.635% (650/768)\n",
      "Train Epoch: 14 | Loss: 0.453 | Acc: 84.375% (756/896)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.277% (863/1024)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.549% (974/1152)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.766% (1085/1280)\n",
      "Train Epoch: 14 | Loss: 0.424 | Acc: 85.369% (1202/1408)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 84.961% (1305/1536)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 84.856% (1412/1664)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.542% (1515/1792)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.323% (1619/1920)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.570% (1732/2048)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 84.926% (1848/2176)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.026% (1959/2304)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.115% (2070/2432)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.195% (2181/2560)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.156% (2289/2688)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.014% (2394/2816)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.190% (2508/2944)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.286% (2620/3072)\n",
      "Train Epoch: 14 | Loss: 0.428 | Acc: 85.406% (2733/3200)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.126% (2833/3328)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.809% (2931/3456)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.849% (3041/3584)\n",
      "Train Epoch: 14 | Loss: 0.440 | Acc: 84.833% (3149/3712)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.714% (3253/3840)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.728% (3362/3968)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.741% (3471/4096)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.777% (3581/4224)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.743% (3688/4352)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.888% (3803/4480)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.896% (3912/4608)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.093% (4030/4736)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.033% (4136/4864)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.016% (4244/4992)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.020% (4353/5120)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.080% (4465/5248)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.026% (4571/5376)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.047% (4681/5504)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.837% (4778/5632)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.774% (4883/5760)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.766% (4991/5888)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.707% (5096/6016)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.668% (5202/6144)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.726% (5314/6272)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.750% (5424/6400)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.712% (5530/6528)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.766% (5642/6656)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.655% (5743/6784)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.635% (5850/6912)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.702% (5963/7040)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.612% (6065/7168)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.581% (6171/7296)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.564% (6278/7424)\n",
      "Train Epoch: 14 | Loss: 0.449 | Acc: 84.481% (6380/7552)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.557% (6494/7680)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.644% (6609/7808)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.539% (6709/7936)\n",
      "Train Epoch: 14 | Loss: 0.449 | Acc: 84.437% (6809/8064)\n",
      "Train Epoch: 14 | Loss: 0.448 | Acc: 84.424% (6916/8192)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 84.483% (7029/8320)\n",
      "Train Epoch: 14 | Loss: 0.448 | Acc: 84.482% (7137/8448)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.527% (7249/8576)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 84.536% (7358/8704)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 84.590% (7471/8832)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.688% (7588/8960)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.661% (7694/9088)\n",
      "Train Epoch: 14 | Loss: 0.444 | Acc: 84.701% (7806/9216)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.707% (7915/9344)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.671% (8020/9472)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.740% (8135/9600)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.694% (8239/9728)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.730% (8351/9856)\n",
      "Train Epoch: 14 | Loss: 0.441 | Acc: 84.746% (8461/9984)\n",
      "Train Epoch: 14 | Loss: 0.444 | Acc: 84.632% (8558/10112)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.668% (8670/10240)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.645% (8776/10368)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.585% (8878/10496)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.591% (8987/10624)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.580% (9094/10752)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 84.522% (9196/10880)\n",
      "Train Epoch: 14 | Loss: 0.447 | Acc: 84.493% (9301/11008)\n",
      "Train Epoch: 14 | Loss: 0.446 | Acc: 84.564% (9417/11136)\n",
      "Train Epoch: 14 | Loss: 0.444 | Acc: 84.632% (9533/11264)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.612% (9639/11392)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.644% (9751/11520)\n",
      "Train Epoch: 14 | Loss: 0.445 | Acc: 84.633% (9858/11648)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.681% (9972/11776)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.694% (10082/11904)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.741% (10196/12032)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.786% (10310/12160)\n",
      "Train Epoch: 14 | Loss: 0.441 | Acc: 84.806% (10421/12288)\n",
      "Train Epoch: 14 | Loss: 0.441 | Acc: 84.794% (10528/12416)\n",
      "Train Epoch: 14 | Loss: 0.441 | Acc: 84.782% (10635/12544)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.746% (10739/12672)\n",
      "Train Epoch: 14 | Loss: 0.443 | Acc: 84.750% (10848/12800)\n",
      "Train Epoch: 14 | Loss: 0.442 | Acc: 84.808% (10964/12928)\n",
      "Train Epoch: 14 | Loss: 0.440 | Acc: 84.865% (11080/13056)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.876% (11190/13184)\n",
      "Train Epoch: 14 | Loss: 0.439 | Acc: 84.886% (11300/13312)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.918% (11413/13440)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.972% (11529/13568)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.988% (11640/13696)\n",
      "Train Epoch: 14 | Loss: 0.438 | Acc: 84.961% (11745/13824)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.963% (11854/13952)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 84.986% (11966/14080)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.980% (12074/14208)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.017% (12188/14336)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.011% (12296/14464)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 84.999% (12403/14592)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 84.993% (12511/14720)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.981% (12618/14848)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.983% (12727/14976)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.958% (12832/15104)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 84.992% (12946/15232)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.007% (13057/15360)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.014% (13167/15488)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.022% (13277/15616)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.048% (13390/15744)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.043% (13498/15872)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.031% (13605/16000)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.001% (13709/16128)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.015% (13820/16256)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.052% (13935/16384)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.090% (14050/16512)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.102% (14161/16640)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.109% (14271/16768)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.079% (14375/16896)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.086% (14485/17024)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.098% (14596/17152)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.110% (14707/17280)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.133% (14820/17408)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.145% (14931/17536)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.151% (15041/17664)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.184% (15156/17792)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.151% (15259/17920)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.129% (15364/18048)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.096% (15467/18176)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.085% (15574/18304)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.086% (15683/18432)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.108% (15796/18560)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.081% (15900/18688)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.087% (16010/18816)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.067% (16115/18944)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.088% (16228/19072)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.078% (16335/19200)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.063% (16441/19328)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.084% (16554/19456)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.064% (16659/19584)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.111% (16777/19712)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.121% (16888/19840)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.146% (17002/19968)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.156% (17113/20096)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.136% (17218/20224)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.161% (17332/20352)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.176% (17444/20480)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.181% (17554/20608)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.166% (17660/20736)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.156% (17767/20864)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.132% (17871/20992)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.137% (17981/21120)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.133% (18089/21248)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.156% (18203/21376)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.138% (18308/21504)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.147% (18419/21632)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.170% (18533/21760)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.184% (18645/21888)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.179% (18753/22016)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.174% (18861/22144)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.206% (18977/22272)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.205% (19086/22400)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.218% (19198/22528)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.231% (19310/22656)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.248% (19423/22784)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.270% (19537/22912)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.269% (19646/23040)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.268% (19755/23168)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.272% (19865/23296)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.263% (19972/23424)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.271% (20083/23552)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.245% (20186/23680)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.253% (20297/23808)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.219% (20398/23936)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.223% (20508/24064)\n",
      "Train Epoch: 14 | Loss: 0.429 | Acc: 85.251% (20624/24192)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.214% (20724/24320)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.234% (20838/24448)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.217% (20943/24576)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.217% (21052/24704)\n",
      "Train Epoch: 14 | Loss: 0.430 | Acc: 85.209% (21159/24832)\n",
      "Train Epoch: 14 | Loss: 0.431 | Acc: 85.176% (21260/24960)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.164% (21366/25088)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.144% (21470/25216)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.117% (21572/25344)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.113% (21680/25472)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.109% (21788/25600)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.086% (21891/25728)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.114% (22007/25856)\n",
      "Train Epoch: 14 | Loss: 0.432 | Acc: 85.110% (22115/25984)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.080% (22216/26112)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.088% (22327/26240)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.065% (22430/26368)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.085% (22544/26496)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.089% (22654/26624)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.085% (22762/26752)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.063% (22865/26880)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.053% (22971/27008)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.038% (23076/27136)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.061% (23191/27264)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.069% (23302/27392)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.058% (23408/27520)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.012% (23504/27648)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.027% (23617/27776)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.042% (23730/27904)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.063% (23845/28032)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.067% (23955/28160)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.075% (24066/28288)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.075% (24175/28416)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.065% (24281/28544)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.093% (24398/28672)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.080% (24503/28800)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.080% (24612/28928)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.067% (24717/29056)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.071% (24827/29184)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.074% (24937/29312)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.068% (25044/29440)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.085% (25158/29568)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.092% (25269/29696)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.103% (25381/29824)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.110% (25492/29952)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.110% (25601/30080)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.087% (25703/30208)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.113% (25820/30336)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.100% (25925/30464)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.094% (26032/30592)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.094% (26141/30720)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.104% (26253/30848)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.121% (26367/30976)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.124% (26477/31104)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.089% (26575/31232)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.080% (26681/31360)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.096% (26795/31488)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.090% (26902/31616)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.106% (27016/31744)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.097% (27122/31872)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.094% (27230/32000)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.100% (27341/32128)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.094% (27448/32256)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.101% (27559/32384)\n",
      "Train Epoch: 14 | Loss: 0.433 | Acc: 85.107% (27670/32512)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.107% (27779/32640)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.114% (27890/32768)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.108% (27997/32896)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.129% (28113/33024)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.117% (28218/33152)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.081% (28315/33280)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.072% (28421/33408)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.076% (28531/33536)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.088% (28644/33664)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.094% (28755/33792)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.094% (28864/33920)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.100% (28975/34048)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.115% (29089/34176)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.113% (29197/34304)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.127% (29311/34432)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.142% (29425/34560)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.125% (29528/34688)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.125% (29637/34816)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.119% (29744/34944)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.122% (29854/35072)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.116% (29961/35200)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.111% (30068/35328)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.108% (30176/35456)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.108% (30285/35584)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.117% (30397/35712)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.112% (30504/35840)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.117% (30615/35968)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.123% (30726/36096)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.123% (30835/36224)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.129% (30946/36352)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.123% (31053/36480)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.113% (31158/36608)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.118% (31269/36736)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.121% (31379/36864)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.113% (31485/36992)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.100% (31589/37120)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.105% (31700/37248)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.108% (31810/37376)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.100% (31916/37504)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.095% (32023/37632)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.109% (32137/37760)\n",
      "Train Epoch: 14 | Loss: 0.434 | Acc: 85.106% (32245/37888)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.088% (32347/38016)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.091% (32457/38144)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.096% (32568/38272)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.099% (32678/38400)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.104% (32789/38528)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.102% (32897/38656)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.112% (33010/38784)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.115% (33120/38912)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.123% (33232/39040)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.115% (33338/39168)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.121% (33449/39296)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.128% (33561/39424)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.131% (33671/39552)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.116% (33774/39680)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.114% (33882/39808)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.101% (33986/39936)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.076% (34085/40064)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.092% (34200/40192)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.089% (34308/40320)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.104% (34423/40448)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.107% (34533/40576)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.124% (34649/40704)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.134% (34762/40832)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.115% (34863/40960)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.110% (34970/41088)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.113% (35080/41216)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.093% (35181/41344)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.091% (35289/41472)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.096% (35400/41600)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.113% (35516/41728)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.104% (35621/41856)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.099% (35728/41984)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.109% (35841/42112)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.114% (35952/42240)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.123% (36065/42368)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.130% (36177/42496)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.133% (36287/42624)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.140% (36399/42752)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.133% (36505/42880)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.131% (36613/43008)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.126% (36720/43136)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.124% (36828/43264)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.117% (36934/43392)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.122% (37045/43520)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.115% (37151/43648)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.111% (37258/43776)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.108% (37366/43904)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.090% (37467/44032)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.093% (37577/44160)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.104% (37691/44288)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.113% (37804/44416)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.120% (37916/44544)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.132% (38030/44672)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.132% (38139/44800)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.136% (38250/44928)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.127% (38355/45056)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.116% (38459/45184)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.112% (38566/45312)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.106% (38672/45440)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.110% (38783/45568)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.106% (38890/45696)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.128% (39009/45824)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.141% (39124/45952)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.135% (39230/46080)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.143% (39343/46208)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.152% (39456/46336)\n",
      "Train Epoch: 14 | Loss: 0.435 | Acc: 85.150% (39564/46464)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.139% (39668/46592)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.133% (39774/46720)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.120% (39877/46848)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.122% (39987/46976)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.112% (40091/47104)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.105% (40197/47232)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.108% (40307/47360)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.120% (40422/47488)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.114% (40528/47616)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.108% (40634/47744)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.104% (40741/47872)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.121% (40858/48000)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.106% (40960/48128)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.104% (41068/48256)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.092% (41171/48384)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.084% (41276/48512)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.090% (41388/48640)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.109% (41506/48768)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.111% (41616/48896)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.113% (41726/49024)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.122% (41839/49152)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.101% (41938/49280)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.104% (42048/49408)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.106% (42158/49536)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.106% (42267/49664)\n",
      "Train Epoch: 14 | Loss: 0.436 | Acc: 85.118% (42382/49792)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.108% (42486/49920)\n",
      "Train Epoch: 14 | Loss: 0.437 | Acc: 85.106% (42553/50000)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 14 | Loss: 0.425 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 14 | Loss: 0.420 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 14 | Loss: 0.420 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 14 | Loss: 0.421 | Acc: 87.000% (435/500)\n",
      "Test Epoch: 14 | Loss: 0.413 | Acc: 86.667% (520/600)\n",
      "Test Epoch: 14 | Loss: 0.421 | Acc: 86.143% (603/700)\n",
      "Test Epoch: 14 | Loss: 0.441 | Acc: 85.250% (682/800)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.889% (764/900)\n",
      "Test Epoch: 14 | Loss: 0.452 | Acc: 85.000% (850/1000)\n",
      "Test Epoch: 14 | Loss: 0.454 | Acc: 85.000% (935/1100)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.667% (1016/1200)\n",
      "Test Epoch: 14 | Loss: 0.449 | Acc: 84.846% (1103/1300)\n",
      "Test Epoch: 14 | Loss: 0.444 | Acc: 85.000% (1190/1400)\n",
      "Test Epoch: 14 | Loss: 0.441 | Acc: 85.067% (1276/1500)\n",
      "Test Epoch: 14 | Loss: 0.441 | Acc: 84.938% (1359/1600)\n",
      "Test Epoch: 14 | Loss: 0.445 | Acc: 85.059% (1446/1700)\n",
      "Test Epoch: 14 | Loss: 0.449 | Acc: 84.722% (1525/1800)\n",
      "Test Epoch: 14 | Loss: 0.449 | Acc: 84.789% (1611/1900)\n",
      "Test Epoch: 14 | Loss: 0.455 | Acc: 84.750% (1695/2000)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.429% (1773/2100)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.182% (1852/2200)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.130% (1935/2300)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.042% (2017/2400)\n",
      "Test Epoch: 14 | Loss: 0.462 | Acc: 84.080% (2102/2500)\n",
      "Test Epoch: 14 | Loss: 0.467 | Acc: 83.962% (2183/2600)\n",
      "Test Epoch: 14 | Loss: 0.466 | Acc: 84.037% (2269/2700)\n",
      "Test Epoch: 14 | Loss: 0.464 | Acc: 84.000% (2352/2800)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.034% (2437/2900)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.067% (2522/3000)\n",
      "Test Epoch: 14 | Loss: 0.469 | Acc: 83.935% (2602/3100)\n",
      "Test Epoch: 14 | Loss: 0.466 | Acc: 84.031% (2689/3200)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.000% (2772/3300)\n",
      "Test Epoch: 14 | Loss: 0.463 | Acc: 84.118% (2860/3400)\n",
      "Test Epoch: 14 | Loss: 0.467 | Acc: 84.114% (2944/3500)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.194% (3031/3600)\n",
      "Test Epoch: 14 | Loss: 0.466 | Acc: 84.162% (3114/3700)\n",
      "Test Epoch: 14 | Loss: 0.468 | Acc: 84.079% (3195/3800)\n",
      "Test Epoch: 14 | Loss: 0.464 | Acc: 84.154% (3282/3900)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.200% (3368/4000)\n",
      "Test Epoch: 14 | Loss: 0.465 | Acc: 84.171% (3451/4100)\n",
      "Test Epoch: 14 | Loss: 0.466 | Acc: 84.190% (3536/4200)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.372% (3628/4300)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.455% (3716/4400)\n",
      "Test Epoch: 14 | Loss: 0.455 | Acc: 84.556% (3805/4500)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.500% (3887/4600)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.553% (3974/4700)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.521% (4057/4800)\n",
      "Test Epoch: 14 | Loss: 0.455 | Acc: 84.612% (4146/4900)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.520% (4226/5000)\n",
      "Test Epoch: 14 | Loss: 0.459 | Acc: 84.451% (4307/5100)\n",
      "Test Epoch: 14 | Loss: 0.459 | Acc: 84.365% (4387/5200)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.415% (4474/5300)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.426% (4559/5400)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.418% (4643/5500)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.393% (4726/5600)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.386% (4810/5700)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.397% (4895/5800)\n",
      "Test Epoch: 14 | Loss: 0.461 | Acc: 84.373% (4978/5900)\n",
      "Test Epoch: 14 | Loss: 0.462 | Acc: 84.317% (5059/6000)\n",
      "Test Epoch: 14 | Loss: 0.461 | Acc: 84.328% (5144/6100)\n",
      "Test Epoch: 14 | Loss: 0.461 | Acc: 84.242% (5223/6200)\n",
      "Test Epoch: 14 | Loss: 0.461 | Acc: 84.286% (5310/6300)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.422% (5403/6400)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.385% (5485/6500)\n",
      "Test Epoch: 14 | Loss: 0.459 | Acc: 84.394% (5570/6600)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.433% (5657/6700)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.353% (5736/6800)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.435% (5826/6900)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.371% (5906/7000)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.394% (5992/7100)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.333% (6072/7200)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.384% (6160/7300)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.405% (6246/7400)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.387% (6329/7500)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.368% (6412/7600)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.377% (6497/7700)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.410% (6584/7800)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.405% (6668/7900)\n",
      "Test Epoch: 14 | Loss: 0.459 | Acc: 84.362% (6749/8000)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.420% (6838/8100)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.439% (6924/8200)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.434% (7008/8300)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.440% (7093/8400)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.412% (7175/8500)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.360% (7255/8600)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.333% (7337/8700)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.318% (7420/8800)\n",
      "Test Epoch: 14 | Loss: 0.460 | Acc: 84.337% (7506/8900)\n",
      "Test Epoch: 14 | Loss: 0.462 | Acc: 84.300% (7587/9000)\n",
      "Test Epoch: 14 | Loss: 0.461 | Acc: 84.275% (7669/9100)\n",
      "Test Epoch: 14 | Loss: 0.459 | Acc: 84.370% (7762/9200)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.344% (7844/9300)\n",
      "Test Epoch: 14 | Loss: 0.458 | Acc: 84.330% (7927/9400)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.295% (8008/9500)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.292% (8092/9600)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.351% (8182/9700)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.357% (8267/9800)\n",
      "Test Epoch: 14 | Loss: 0.457 | Acc: 84.323% (8348/9900)\n",
      "Test Epoch: 14 | Loss: 0.456 | Acc: 84.350% (8435/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 15\n",
      "Train Epoch: 15 | Loss: 0.491 | Acc: 85.938% (110/128)\n",
      "Train Epoch: 15 | Loss: 0.436 | Acc: 86.328% (221/256)\n",
      "Train Epoch: 15 | Loss: 0.412 | Acc: 86.198% (331/384)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.742% (439/512)\n",
      "Train Epoch: 15 | Loss: 0.418 | Acc: 85.938% (550/640)\n",
      "Train Epoch: 15 | Loss: 0.415 | Acc: 86.068% (661/768)\n",
      "Train Epoch: 15 | Loss: 0.415 | Acc: 86.384% (774/896)\n",
      "Train Epoch: 15 | Loss: 0.418 | Acc: 85.352% (874/1024)\n",
      "Train Epoch: 15 | Loss: 0.431 | Acc: 85.156% (981/1152)\n",
      "Train Epoch: 15 | Loss: 0.416 | Acc: 85.703% (1097/1280)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 86.151% (1213/1408)\n",
      "Train Epoch: 15 | Loss: 0.406 | Acc: 86.133% (1323/1536)\n",
      "Train Epoch: 15 | Loss: 0.409 | Acc: 86.178% (1434/1664)\n",
      "Train Epoch: 15 | Loss: 0.410 | Acc: 85.993% (1541/1792)\n",
      "Train Epoch: 15 | Loss: 0.408 | Acc: 85.990% (1651/1920)\n",
      "Train Epoch: 15 | Loss: 0.411 | Acc: 85.938% (1760/2048)\n",
      "Train Epoch: 15 | Loss: 0.418 | Acc: 85.570% (1862/2176)\n",
      "Train Epoch: 15 | Loss: 0.419 | Acc: 85.547% (1971/2304)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.444% (2078/2432)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.352% (2185/2560)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.454% (2297/2688)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.582% (2410/2816)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.700% (2523/2944)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.547% (2628/3072)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.375% (2732/3200)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.517% (2846/3328)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.590% (2958/3456)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.603% (3068/3584)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.506% (3174/3712)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.495% (3283/3840)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.711% (3401/3968)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.791% (3514/4096)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.677% (3619/4224)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.570% (3724/4352)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.737% (3841/4480)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.677% (3948/4608)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.536% (4051/4736)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.444% (4156/4864)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.397% (4263/4992)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.371% (4371/5120)\n",
      "Train Epoch: 15 | Loss: 0.432 | Acc: 85.385% (4481/5248)\n",
      "Train Epoch: 15 | Loss: 0.432 | Acc: 85.398% (4591/5376)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.483% (4705/5504)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.458% (4813/5632)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.486% (4924/5760)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.513% (5035/5888)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.555% (5147/6016)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.531% (5255/6144)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.443% (5359/6272)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.375% (5464/6400)\n",
      "Train Epoch: 15 | Loss: 0.432 | Acc: 85.371% (5573/6528)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.442% (5687/6656)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.540% (5803/6784)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.547% (5913/6912)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.568% (6024/7040)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.547% (6132/7168)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.581% (6244/7296)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.655% (6359/7424)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.633% (6467/7552)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.651% (6578/7680)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.758% (6696/7808)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.698% (6801/7936)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.627% (6905/8064)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.657% (7017/8192)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.661% (7127/8320)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.594% (7231/8448)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.564% (7338/8576)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.558% (7447/8704)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.496% (7551/8832)\n",
      "Train Epoch: 15 | Loss: 0.431 | Acc: 85.446% (7656/8960)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.530% (7773/9088)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.503% (7880/9216)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.499% (7989/9344)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.505% (8099/9472)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.521% (8210/9600)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.444% (8312/9728)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.450% (8422/9856)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.447% (8531/9984)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.433% (8639/10112)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.371% (8742/10240)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.417% (8856/10368)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.433% (8967/10496)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.420% (9075/10624)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.435% (9186/10752)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.349% (9286/10880)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.356% (9396/11008)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.372% (9507/11136)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.414% (9621/11264)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.411% (9730/11392)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.434% (9842/11520)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.457% (9954/11648)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.453% (10063/11776)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.408% (10167/11904)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.397% (10275/12032)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.337% (10377/12160)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.335% (10486/12288)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.333% (10595/12416)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.371% (10709/12544)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.456% (10829/12672)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.453% (10938/12800)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.450% (11047/12928)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.463% (11158/13056)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.414% (11261/13184)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.404% (11369/13312)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.387% (11476/13440)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.370% (11583/13568)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.346% (11689/13696)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.380% (11803/13824)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.400% (11915/13952)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.419% (12027/14080)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.381% (12131/14208)\n",
      "Train Epoch: 15 | Loss: 0.430 | Acc: 85.338% (12234/14336)\n",
      "Train Epoch: 15 | Loss: 0.429 | Acc: 85.371% (12348/14464)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.417% (12464/14592)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.476% (12582/14720)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.486% (12693/14848)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.490% (12803/14976)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.534% (12919/15104)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.537% (13029/15232)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.599% (13148/15360)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.569% (13253/15488)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.547% (13359/15616)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.582% (13474/15744)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.578% (13583/15872)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.638% (13702/16000)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.696% (13821/16128)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.704% (13932/16256)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.675% (14037/16384)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.677% (14147/16512)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.685% (14258/16640)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.693% (14369/16768)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.671% (14475/16896)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.685% (14587/17024)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.687% (14697/17152)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.689% (14807/17280)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.690% (14917/17408)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.709% (15030/17536)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.694% (15137/17664)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.707% (15249/17792)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.681% (15354/17920)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.672% (15462/18048)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.662% (15570/18176)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.664% (15680/18304)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.688% (15794/18432)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.690% (15904/18560)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.718% (16019/18688)\n",
      "Train Epoch: 15 | Loss: 0.420 | Acc: 85.714% (16128/18816)\n",
      "Train Epoch: 15 | Loss: 0.420 | Acc: 85.726% (16240/18944)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.702% (16345/19072)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.719% (16458/19200)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.710% (16566/19328)\n",
      "Train Epoch: 15 | Loss: 0.420 | Acc: 85.696% (16673/19456)\n",
      "Train Epoch: 15 | Loss: 0.420 | Acc: 85.703% (16784/19584)\n",
      "Train Epoch: 15 | Loss: 0.420 | Acc: 85.679% (16889/19712)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.640% (16991/19840)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.647% (17102/19968)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.634% (17209/20096)\n",
      "Train Epoch: 15 | Loss: 0.421 | Acc: 85.666% (17325/20224)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.638% (17429/20352)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.630% (17537/20480)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.608% (17642/20608)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.605% (17751/20736)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.597% (17859/20864)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.599% (17969/20992)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.592% (18077/21120)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.599% (18188/21248)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.610% (18300/21376)\n",
      "Train Epoch: 15 | Loss: 0.422 | Acc: 85.612% (18410/21504)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.600% (18517/21632)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.588% (18624/21760)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.572% (18730/21888)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.570% (18839/22016)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.545% (18943/22144)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.529% (19049/22272)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.518% (19156/22400)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.489% (19259/22528)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.470% (19364/22656)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.481% (19476/22784)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.444% (19577/22912)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.456% (19689/23040)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.476% (19803/23168)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.444% (19905/23296)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.429% (20011/23424)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.436% (20122/23552)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.422% (20228/23680)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.421% (20337/23808)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.436% (20450/23936)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.468% (20567/24064)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.466% (20676/24192)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.489% (20791/24320)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.512% (20906/24448)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.522% (21018/24576)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.533% (21130/24704)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.539% (21241/24832)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.517% (21345/24960)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.523% (21456/25088)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.541% (21570/25216)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.535% (21678/25344)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.545% (21790/25472)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.547% (21900/25600)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.533% (22006/25728)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.543% (22118/25856)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.537% (22226/25984)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.509% (22328/26112)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.522% (22441/26240)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.539% (22555/26368)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.530% (22662/26496)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.528% (22771/26624)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.534% (22882/26752)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.502% (22983/26880)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.493% (23090/27008)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.503% (23202/27136)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.512% (23314/27264)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.510% (23423/27392)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.527% (23537/27520)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.525% (23646/27648)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.523% (23755/27776)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.515% (23862/27904)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.531% (23976/28032)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.522% (24083/28160)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.517% (24191/28288)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.505% (24297/28416)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.493% (24403/28544)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.495% (24513/28672)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.497% (24623/28800)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.495% (24732/28928)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.494% (24841/29056)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.489% (24949/29184)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.494% (25060/29312)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.489% (25168/29440)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.501% (25281/29568)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.486% (25386/29696)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.475% (25492/29824)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.463% (25598/29952)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.459% (25706/30080)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.464% (25817/30208)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.473% (25929/30336)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.494% (26045/30464)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.490% (26153/30592)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (26262/30720)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.467% (26365/30848)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.476% (26477/30976)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.494% (26592/31104)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.524% (26711/31232)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.533% (26823/31360)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.528% (26931/31488)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.523% (27039/31616)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.534% (27152/31744)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.517% (27256/31872)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.500% (27360/32000)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.499% (27469/32128)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (27575/32256)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.496% (27687/32384)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (27794/32512)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.509% (27910/32640)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.507% (28019/32768)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.506% (28128/32896)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.495% (28234/33024)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.476% (28337/33152)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.493% (28452/33280)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.489% (28560/33408)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.505% (28675/33536)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.489% (28779/33664)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.491% (28889/33792)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.498% (29001/33920)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.509% (29114/34048)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.513% (29225/34176)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.515% (29335/34304)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.508% (29442/34432)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.483% (29543/34560)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.476% (29650/34688)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.472% (29758/34816)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.485% (29872/34944)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.470% (29976/35072)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.477% (30088/35200)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.487% (30201/35328)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.492% (30312/35456)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (30420/35584)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.478% (30526/35712)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (30639/35840)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.487% (30748/35968)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.475% (30853/36096)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.465% (30959/36224)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.475% (31072/36352)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.469% (31179/36480)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.454% (31283/36608)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.439% (31387/36736)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.457% (31503/36864)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.478% (31620/36992)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.488% (31733/37120)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.478% (31839/37248)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.480% (31949/37376)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.484% (32060/37504)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.483% (32169/37632)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.471% (32274/37760)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.481% (32387/37888)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.482% (32497/38016)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.471% (32602/38144)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.465% (32709/38272)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.469% (32820/38400)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.475% (32932/38528)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.480% (33043/38656)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.494% (33158/38784)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.490% (33266/38912)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.482% (33372/39040)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.486% (33483/39168)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.482% (33591/39296)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.486% (33702/39424)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.470% (33805/39552)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.469% (33914/39680)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.455% (34018/39808)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.452% (34126/39936)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.461% (34239/40064)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.455% (34346/40192)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.466% (34460/40320)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.448% (34562/40448)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.440% (34668/40576)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.434% (34775/40704)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.445% (34889/40832)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.461% (35005/40960)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.468% (35117/41088)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.462% (35224/41216)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.461% (35333/41344)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.458% (35441/41472)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.471% (35556/41600)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.473% (35666/41728)\n",
      "Train Epoch: 15 | Loss: 0.423 | Acc: 85.481% (35779/41856)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.475% (35886/41984)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.460% (35989/42112)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.450% (36094/42240)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.461% (36208/42368)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.469% (36321/42496)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.466% (36429/42624)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.465% (36538/42752)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.473% (36651/42880)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.463% (36756/43008)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.455% (36862/43136)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.464% (36975/43264)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.444% (37076/43392)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.443% (37185/43520)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.438% (37292/43648)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.442% (37403/43776)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.446% (37514/43904)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.449% (37625/44032)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.444% (37732/44160)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.445% (37842/44288)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.426% (37943/44416)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.414% (38047/44544)\n",
      "Train Epoch: 15 | Loss: 0.424 | Acc: 85.420% (38159/44672)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.406% (38262/44800)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.399% (38368/44928)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.389% (38473/45056)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.393% (38584/45184)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.379% (38687/45312)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.383% (38798/45440)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.387% (38909/45568)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.362% (39007/45696)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.368% (39119/45824)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.370% (39229/45952)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.373% (39340/46080)\n",
      "Train Epoch: 15 | Loss: 0.425 | Acc: 85.379% (39452/46208)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.361% (39553/46336)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.356% (39660/46464)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.360% (39771/46592)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.353% (39877/46720)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.342% (39981/46848)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.339% (40089/46976)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.332% (40195/47104)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.313% (40295/47232)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.327% (40411/47360)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.327% (40520/47488)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.328% (40630/47616)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.336% (40743/47744)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.340% (40854/47872)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.342% (40964/48000)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.347% (41076/48128)\n",
      "Train Epoch: 15 | Loss: 0.426 | Acc: 85.357% (41190/48256)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.344% (41293/48384)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.350% (41405/48512)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.339% (41509/48640)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.339% (41618/48768)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.338% (41727/48896)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.332% (41833/49024)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.333% (41943/49152)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.337% (42054/49280)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.322% (42156/49408)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.330% (42269/49536)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.329% (42378/49664)\n",
      "Train Epoch: 15 | Loss: 0.427 | Acc: 85.321% (42483/49792)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.317% (42590/49920)\n",
      "Train Epoch: 15 | Loss: 0.428 | Acc: 85.314% (42657/50000)\n",
      "Test Epoch: 15 | Loss: 0.499 | Acc: 82.000% (82/100)\n",
      "Test Epoch: 15 | Loss: 0.507 | Acc: 82.500% (165/200)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 82.333% (247/300)\n",
      "Test Epoch: 15 | Loss: 0.466 | Acc: 82.750% (331/400)\n",
      "Test Epoch: 15 | Loss: 0.461 | Acc: 82.800% (414/500)\n",
      "Test Epoch: 15 | Loss: 0.430 | Acc: 84.167% (505/600)\n",
      "Test Epoch: 15 | Loss: 0.444 | Acc: 83.571% (585/700)\n",
      "Test Epoch: 15 | Loss: 0.458 | Acc: 83.250% (666/800)\n",
      "Test Epoch: 15 | Loss: 0.466 | Acc: 83.444% (751/900)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 83.100% (831/1000)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.364% (917/1100)\n",
      "Test Epoch: 15 | Loss: 0.495 | Acc: 83.250% (999/1200)\n",
      "Test Epoch: 15 | Loss: 0.489 | Acc: 83.000% (1079/1300)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.214% (1165/1400)\n",
      "Test Epoch: 15 | Loss: 0.476 | Acc: 83.667% (1255/1500)\n",
      "Test Epoch: 15 | Loss: 0.479 | Acc: 83.688% (1339/1600)\n",
      "Test Epoch: 15 | Loss: 0.478 | Acc: 83.706% (1423/1700)\n",
      "Test Epoch: 15 | Loss: 0.473 | Acc: 83.667% (1506/1800)\n",
      "Test Epoch: 15 | Loss: 0.471 | Acc: 83.632% (1589/1900)\n",
      "Test Epoch: 15 | Loss: 0.478 | Acc: 83.350% (1667/2000)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.143% (1746/2100)\n",
      "Test Epoch: 15 | Loss: 0.474 | Acc: 83.455% (1836/2200)\n",
      "Test Epoch: 15 | Loss: 0.471 | Acc: 83.435% (1919/2300)\n",
      "Test Epoch: 15 | Loss: 0.472 | Acc: 83.292% (1999/2400)\n",
      "Test Epoch: 15 | Loss: 0.474 | Acc: 83.240% (2081/2500)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.154% (2162/2600)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.222% (2247/2700)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.250% (2331/2800)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.345% (2417/2900)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.300% (2499/3000)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.323% (2583/3100)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.375% (2668/3200)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.303% (2749/3300)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.206% (2829/3400)\n",
      "Test Epoch: 15 | Loss: 0.487 | Acc: 83.086% (2908/3500)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.306% (2999/3600)\n",
      "Test Epoch: 15 | Loss: 0.491 | Acc: 83.189% (3078/3700)\n",
      "Test Epoch: 15 | Loss: 0.494 | Acc: 83.000% (3154/3800)\n",
      "Test Epoch: 15 | Loss: 0.491 | Acc: 83.103% (3241/3900)\n",
      "Test Epoch: 15 | Loss: 0.487 | Acc: 83.225% (3329/4000)\n",
      "Test Epoch: 15 | Loss: 0.487 | Acc: 83.268% (3414/4100)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.238% (3496/4200)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.256% (3580/4300)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.250% (3663/4400)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.356% (3751/4500)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.391% (3836/4600)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 83.426% (3921/4700)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.354% (4001/4800)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.449% (4089/4900)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.440% (4172/5000)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.490% (4258/5100)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.385% (4336/5200)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.396% (4420/5300)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.426% (4505/5400)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.382% (4586/5500)\n",
      "Test Epoch: 15 | Loss: 0.487 | Acc: 83.375% (4669/5600)\n",
      "Test Epoch: 15 | Loss: 0.490 | Acc: 83.316% (4749/5700)\n",
      "Test Epoch: 15 | Loss: 0.489 | Acc: 83.293% (4831/5800)\n",
      "Test Epoch: 15 | Loss: 0.491 | Acc: 83.271% (4913/5900)\n",
      "Test Epoch: 15 | Loss: 0.491 | Acc: 83.250% (4995/6000)\n",
      "Test Epoch: 15 | Loss: 0.490 | Acc: 83.246% (5078/6100)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.258% (5162/6200)\n",
      "Test Epoch: 15 | Loss: 0.487 | Acc: 83.302% (5248/6300)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.344% (5334/6400)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.323% (5416/6500)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.258% (5495/6600)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.313% (5582/6700)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.294% (5664/6800)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.333% (5750/6900)\n",
      "Test Epoch: 15 | Loss: 0.488 | Acc: 83.314% (5832/7000)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.310% (5915/7100)\n",
      "Test Epoch: 15 | Loss: 0.486 | Acc: 83.306% (5998/7200)\n",
      "Test Epoch: 15 | Loss: 0.485 | Acc: 83.342% (6084/7300)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.365% (6169/7400)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.400% (6255/7500)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.368% (6336/7600)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.390% (6421/7700)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.423% (6507/7800)\n",
      "Test Epoch: 15 | Loss: 0.484 | Acc: 83.405% (6589/7900)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.475% (6678/8000)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.494% (6763/8100)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.463% (6844/8200)\n",
      "Test Epoch: 15 | Loss: 0.480 | Acc: 83.518% (6932/8300)\n",
      "Test Epoch: 15 | Loss: 0.480 | Acc: 83.548% (7018/8400)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 83.506% (7098/8500)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.465% (7178/8600)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.540% (7268/8700)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.477% (7346/8800)\n",
      "Test Epoch: 15 | Loss: 0.482 | Acc: 83.528% (7434/8900)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.478% (7513/9000)\n",
      "Test Epoch: 15 | Loss: 0.483 | Acc: 83.484% (7597/9100)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 83.587% (7690/9200)\n",
      "Test Epoch: 15 | Loss: 0.481 | Acc: 83.570% (7772/9300)\n",
      "Test Epoch: 15 | Loss: 0.480 | Acc: 83.564% (7855/9400)\n",
      "Test Epoch: 15 | Loss: 0.479 | Acc: 83.611% (7943/9500)\n",
      "Test Epoch: 15 | Loss: 0.478 | Acc: 83.573% (8023/9600)\n",
      "Test Epoch: 15 | Loss: 0.477 | Acc: 83.608% (8110/9700)\n",
      "Test Epoch: 15 | Loss: 0.476 | Acc: 83.633% (8196/9800)\n",
      "Test Epoch: 15 | Loss: 0.476 | Acc: 83.606% (8277/9900)\n",
      "Test Epoch: 15 | Loss: 0.475 | Acc: 83.630% (8363/10000)\n",
      "\n",
      "Epoch: 16\n",
      "Train Epoch: 16 | Loss: 0.414 | Acc: 83.594% (107/128)\n",
      "Train Epoch: 16 | Loss: 0.426 | Acc: 84.375% (216/256)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.198% (331/384)\n",
      "Train Epoch: 16 | Loss: 0.426 | Acc: 85.547% (438/512)\n",
      "Train Epoch: 16 | Loss: 0.431 | Acc: 85.156% (545/640)\n",
      "Train Epoch: 16 | Loss: 0.417 | Acc: 86.198% (662/768)\n",
      "Train Epoch: 16 | Loss: 0.428 | Acc: 85.826% (769/896)\n",
      "Train Epoch: 16 | Loss: 0.428 | Acc: 85.352% (874/1024)\n",
      "Train Epoch: 16 | Loss: 0.427 | Acc: 85.243% (982/1152)\n",
      "Train Epoch: 16 | Loss: 0.421 | Acc: 85.625% (1096/1280)\n",
      "Train Epoch: 16 | Loss: 0.417 | Acc: 85.653% (1206/1408)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 85.872% (1319/1536)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.697% (1426/1664)\n",
      "Train Epoch: 16 | Loss: 0.421 | Acc: 85.268% (1528/1792)\n",
      "Train Epoch: 16 | Loss: 0.418 | Acc: 85.625% (1644/1920)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.791% (1757/2048)\n",
      "Train Epoch: 16 | Loss: 0.413 | Acc: 85.570% (1862/2176)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 85.807% (1977/2304)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 85.938% (2090/2432)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.016% (2202/2560)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.012% (2312/2688)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.222% (2428/2816)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.277% (2540/2944)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.100% (2645/3072)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.125% (2756/3200)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 85.968% (2861/3328)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 85.938% (2970/3456)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 85.993% (3082/3584)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.153% (3198/3712)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.172% (3309/3840)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.215% (3421/3968)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.328% (3536/4096)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.269% (3644/4224)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.236% (3753/4352)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.451% (3873/4480)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.350% (3979/4608)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.360% (4090/4736)\n",
      "Train Epoch: 16 | Loss: 0.388 | Acc: 86.308% (4198/4864)\n",
      "Train Epoch: 16 | Loss: 0.390 | Acc: 86.278% (4307/4992)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.211% (4414/5120)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.223% (4525/5248)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.217% (4635/5376)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.246% (4747/5504)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.257% (4858/5632)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.285% (4970/5760)\n",
      "Train Epoch: 16 | Loss: 0.389 | Acc: 86.430% (5089/5888)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.353% (5195/6016)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.377% (5307/6144)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.352% (5416/6272)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.344% (5526/6400)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.382% (5639/6528)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.403% (5751/6656)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.380% (5860/6784)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.372% (5970/6912)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.406% (6083/7040)\n",
      "Train Epoch: 16 | Loss: 0.391 | Acc: 86.440% (6196/7168)\n",
      "Train Epoch: 16 | Loss: 0.392 | Acc: 86.404% (6304/7296)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.288% (6406/7424)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.229% (6512/7552)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.211% (6621/7680)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.219% (6732/7808)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.265% (6846/7936)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.260% (6956/8064)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.255% (7066/8192)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.298% (7180/8320)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.328% (7293/8448)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.381% (7408/8576)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.305% (7512/8704)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.345% (7626/8832)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.384% (7740/8960)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.400% (7852/9088)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.458% (7968/9216)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.440% (8077/9344)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.413% (8185/9472)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.344% (8289/9600)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.328% (8398/9728)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.353% (8511/9856)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.388% (8625/9984)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.383% (8735/10112)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.338% (8841/10240)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.333% (8951/10368)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.319% (9060/10496)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.323% (9171/10624)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.328% (9282/10752)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.342% (9394/10880)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.328% (9503/11008)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.386% (9620/11136)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.381% (9730/11264)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.412% (9844/11392)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.432% (9957/11520)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.410% (10065/11648)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.396% (10174/11776)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.433% (10289/11904)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.353% (10390/12032)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.316% (10496/12160)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.328% (10608/12288)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.340% (10720/12416)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.312% (10827/12544)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.293% (10935/12672)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.312% (11048/12800)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.301% (11157/12928)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.320% (11270/13056)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.332% (11382/13184)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.343% (11494/13312)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.354% (11606/13440)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.365% (11718/13568)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.324% (11823/13696)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.364% (11939/13824)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.360% (12049/13952)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.342% (12157/14080)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.346% (12268/14208)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.356% (12380/14336)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.352% (12490/14464)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.335% (12598/14592)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.365% (12713/14720)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.362% (12823/14848)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.318% (12927/14976)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.295% (13034/15104)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.318% (13148/15232)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.328% (13260/15360)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.325% (13370/15488)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.379% (13489/15616)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.395% (13602/15744)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.372% (13709/15872)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.362% (13818/16000)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.378% (13931/16128)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.399% (14045/16256)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.407% (14157/16384)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.386% (14264/16512)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.412% (14379/16640)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.427% (14492/16768)\n",
      "Train Epoch: 16 | Loss: 0.393 | Acc: 86.435% (14604/16896)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.425% (14713/17024)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.416% (14822/17152)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.447% (14938/17280)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.420% (15044/17408)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.388% (15149/17536)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.379% (15258/17664)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.376% (15368/17792)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.373% (15478/17920)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.375% (15589/18048)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.389% (15702/18176)\n",
      "Train Epoch: 16 | Loss: 0.394 | Acc: 86.424% (15819/18304)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.420% (15929/18432)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.390% (16034/18560)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.398% (16146/18688)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.389% (16255/18816)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.381% (16364/18944)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.367% (16472/19072)\n",
      "Train Epoch: 16 | Loss: 0.395 | Acc: 86.375% (16584/19200)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.367% (16693/19328)\n",
      "Train Epoch: 16 | Loss: 0.396 | Acc: 86.333% (16797/19456)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.326% (16906/19584)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.318% (17015/19712)\n",
      "Train Epoch: 16 | Loss: 0.397 | Acc: 86.290% (17120/19840)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.248% (17222/19968)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.226% (17328/20096)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.214% (17436/20224)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.222% (17548/20352)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.216% (17657/20480)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.204% (17765/20608)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.222% (17879/20736)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.220% (17989/20864)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.242% (18104/20992)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.231% (18212/21120)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.187% (18313/21248)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.167% (18419/21376)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.147% (18525/21504)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.159% (18638/21632)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.176% (18752/21760)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.161% (18859/21888)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.160% (18969/22016)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.168% (19081/22144)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.171% (19192/22272)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.192% (19307/22400)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.222% (19424/22528)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.189% (19527/22656)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.196% (19639/22784)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.204% (19751/22912)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.198% (19860/23040)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.222% (19976/23168)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.221% (20086/23296)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.194% (20190/23424)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.226% (20308/23552)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.237% (20421/23680)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.265% (20538/23808)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.280% (20652/23936)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.287% (20764/24064)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.276% (20872/24192)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.271% (20981/24320)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.261% (21089/24448)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.263% (21200/24576)\n",
      "Train Epoch: 16 | Loss: 0.398 | Acc: 86.261% (21310/24704)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.236% (21414/24832)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.230% (21523/24960)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.252% (21639/25088)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.255% (21750/25216)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.245% (21858/25344)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.232% (21965/25472)\n",
      "Train Epoch: 16 | Loss: 0.399 | Acc: 86.207% (22069/25600)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.186% (22174/25728)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.189% (22285/25856)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.188% (22395/25984)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.167% (22500/26112)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.159% (22608/26240)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.173% (22722/26368)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.160% (22829/26496)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.170% (22942/26624)\n",
      "Train Epoch: 16 | Loss: 0.400 | Acc: 86.166% (23051/26752)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.146% (23156/26880)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.149% (23267/27008)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.151% (23378/27136)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.161% (23491/27264)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.149% (23598/27392)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.145% (23707/27520)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.144% (23817/27648)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.157% (23931/27776)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.163% (24043/27904)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.166% (24154/28032)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.154% (24261/28160)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.167% (24375/28288)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.159% (24483/28416)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.144% (24589/28544)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.168% (24706/28672)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.184% (24821/28800)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.179% (24930/28928)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.182% (25041/29056)\n",
      "Train Epoch: 16 | Loss: 0.401 | Acc: 86.181% (25151/29184)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.169% (25258/29312)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.141% (25360/29440)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.157% (25475/29568)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.150% (25583/29696)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.149% (25693/29824)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.171% (25810/29952)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.164% (25918/30080)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.139% (26021/30208)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.142% (26132/30336)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.151% (26245/30464)\n",
      "Train Epoch: 16 | Loss: 0.402 | Acc: 86.147% (26354/30592)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.113% (26454/30720)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.119% (26566/30848)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.115% (26675/30976)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.095% (26779/31104)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.085% (26886/31232)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.078% (26994/31360)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.087% (27107/31488)\n",
      "Train Epoch: 16 | Loss: 0.403 | Acc: 86.083% (27216/31616)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.067% (27321/31744)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.063% (27430/31872)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.056% (27538/32000)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.050% (27646/32128)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.058% (27759/32256)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.042% (27864/32384)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.036% (27972/32512)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.036% (28082/32640)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.044% (28195/32768)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.050% (28307/32896)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.053% (28418/33024)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.061% (28531/33152)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.058% (28640/33280)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.051% (28748/33408)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.045% (28856/33536)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.041% (28965/33664)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.044% (29076/33792)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.044% (29186/33920)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.040% (29295/34048)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.040% (29405/34176)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.031% (29512/34304)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.022% (29619/34432)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.010% (29725/34560)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.018% (29838/34688)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.004% (29943/34816)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.026% (30061/34944)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.049% (30179/35072)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.062% (30294/35200)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.062% (30404/35328)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.059% (30513/35456)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.061% (30624/35584)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.064% (30735/35712)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.066% (30846/35840)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.071% (30958/35968)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.073% (31069/36096)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.070% (31178/36224)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.083% (31293/36352)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.086% (31404/36480)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.093% (31517/36608)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.079% (31622/36736)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.092% (31737/36864)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.078% (31842/36992)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.064% (31947/37120)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.082% (32064/37248)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.087% (32176/37376)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.111% (32295/37504)\n",
      "Train Epoch: 16 | Loss: 0.404 | Acc: 86.116% (32407/37632)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.091% (32508/37760)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.088% (32617/37888)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.087% (32727/38016)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.074% (32832/38144)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.079% (32944/38272)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.076% (33053/38400)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.067% (33160/38528)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.075% (33273/38656)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.087% (33388/38784)\n",
      "Train Epoch: 16 | Loss: 0.405 | Acc: 86.084% (33497/38912)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.071% (33602/39040)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.060% (33708/39168)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.060% (33818/39296)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.072% (33933/39424)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.074% (34044/39552)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.076% (34155/39680)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.073% (34264/39808)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.075% (34375/39936)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.070% (34483/40064)\n",
      "Train Epoch: 16 | Loss: 0.406 | Acc: 86.067% (34592/40192)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.062% (34700/40320)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.059% (34809/40448)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.051% (34916/40576)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.048% (35025/40704)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.045% (35134/40832)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.045% (35244/40960)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.066% (35363/41088)\n",
      "Train Epoch: 16 | Loss: 0.407 | Acc: 86.054% (35468/41216)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.049% (35576/41344)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.036% (35681/41472)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.031% (35789/41600)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.053% (35908/41728)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.055% (36019/41856)\n",
      "Train Epoch: 16 | Loss: 0.408 | Acc: 86.047% (36126/41984)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.023% (36226/42112)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.030% (36339/42240)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.037% (36452/42368)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.034% (36561/42496)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.027% (36668/42624)\n",
      "Train Epoch: 16 | Loss: 0.409 | Acc: 86.012% (36772/42752)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.989% (36872/42880)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.993% (36984/43008)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.986% (37091/43136)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.993% (37204/43264)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.995% (37315/43392)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.004% (37429/43520)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.013% (37543/43648)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.015% (37654/43776)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.013% (37763/43904)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.017% (37875/44032)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.024% (37988/44160)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.012% (38093/44288)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 86.012% (38203/44416)\n",
      "Train Epoch: 16 | Loss: 0.410 | Acc: 85.989% (38303/44544)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.978% (38408/44672)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.967% (38513/44800)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.969% (38624/44928)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.960% (38730/45056)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.964% (38842/45184)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.964% (38952/45312)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.955% (39058/45440)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.942% (39162/45568)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.933% (39268/45696)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.931% (39377/45824)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.916% (39480/45952)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.909% (39587/46080)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.918% (39701/46208)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.927% (39815/46336)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.933% (39928/46464)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.944% (40043/46592)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.952% (40157/46720)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.957% (40269/46848)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.965% (40383/46976)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.969% (40495/47104)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.980% (40610/47232)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.978% (40719/47360)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.990% (40835/47488)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.982% (40941/47616)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.975% (41048/47744)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.977% (41159/47872)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.973% (41267/48000)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.952% (41367/48128)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.958% (41480/48256)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.956% (41589/48384)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.958% (41700/48512)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.962% (41812/48640)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.952% (41917/48768)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.940% (42021/48896)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.942% (42132/49024)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.954% (42248/49152)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.968% (42365/49280)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.960% (42471/49408)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.960% (42581/49536)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.970% (42696/49664)\n",
      "Train Epoch: 16 | Loss: 0.411 | Acc: 85.962% (42802/49792)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.956% (42909/49920)\n",
      "Train Epoch: 16 | Loss: 0.412 | Acc: 85.954% (42977/50000)\n",
      "Test Epoch: 16 | Loss: 0.417 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 16 | Loss: 0.433 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 16 | Loss: 0.416 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 16 | Loss: 0.403 | Acc: 86.750% (347/400)\n",
      "Test Epoch: 16 | Loss: 0.397 | Acc: 87.000% (435/500)\n",
      "Test Epoch: 16 | Loss: 0.371 | Acc: 87.833% (527/600)\n",
      "Test Epoch: 16 | Loss: 0.377 | Acc: 88.143% (617/700)\n",
      "Test Epoch: 16 | Loss: 0.409 | Acc: 87.000% (696/800)\n",
      "Test Epoch: 16 | Loss: 0.409 | Acc: 87.111% (784/900)\n",
      "Test Epoch: 16 | Loss: 0.410 | Acc: 86.800% (868/1000)\n",
      "Test Epoch: 16 | Loss: 0.415 | Acc: 86.455% (951/1100)\n",
      "Test Epoch: 16 | Loss: 0.414 | Acc: 86.250% (1035/1200)\n",
      "Test Epoch: 16 | Loss: 0.409 | Acc: 86.231% (1121/1300)\n",
      "Test Epoch: 16 | Loss: 0.409 | Acc: 86.286% (1208/1400)\n",
      "Test Epoch: 16 | Loss: 0.413 | Acc: 86.067% (1291/1500)\n",
      "Test Epoch: 16 | Loss: 0.421 | Acc: 85.562% (1369/1600)\n",
      "Test Epoch: 16 | Loss: 0.417 | Acc: 85.647% (1456/1700)\n",
      "Test Epoch: 16 | Loss: 0.425 | Acc: 85.278% (1535/1800)\n",
      "Test Epoch: 16 | Loss: 0.428 | Acc: 85.105% (1617/1900)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 84.900% (1698/2000)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 84.857% (1782/2100)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 84.727% (1864/2200)\n",
      "Test Epoch: 16 | Loss: 0.439 | Acc: 84.348% (1940/2300)\n",
      "Test Epoch: 16 | Loss: 0.436 | Acc: 84.583% (2030/2400)\n",
      "Test Epoch: 16 | Loss: 0.442 | Acc: 84.400% (2110/2500)\n",
      "Test Epoch: 16 | Loss: 0.448 | Acc: 84.269% (2191/2600)\n",
      "Test Epoch: 16 | Loss: 0.445 | Acc: 84.444% (2280/2700)\n",
      "Test Epoch: 16 | Loss: 0.445 | Acc: 84.464% (2365/2800)\n",
      "Test Epoch: 16 | Loss: 0.445 | Acc: 84.586% (2453/2900)\n",
      "Test Epoch: 16 | Loss: 0.443 | Acc: 84.767% (2543/3000)\n",
      "Test Epoch: 16 | Loss: 0.444 | Acc: 84.806% (2629/3100)\n",
      "Test Epoch: 16 | Loss: 0.441 | Acc: 84.812% (2714/3200)\n",
      "Test Epoch: 16 | Loss: 0.439 | Acc: 84.939% (2803/3300)\n",
      "Test Epoch: 16 | Loss: 0.440 | Acc: 84.912% (2887/3400)\n",
      "Test Epoch: 16 | Loss: 0.446 | Acc: 84.743% (2966/3500)\n",
      "Test Epoch: 16 | Loss: 0.447 | Acc: 84.750% (3051/3600)\n",
      "Test Epoch: 16 | Loss: 0.448 | Acc: 84.703% (3134/3700)\n",
      "Test Epoch: 16 | Loss: 0.449 | Acc: 84.658% (3217/3800)\n",
      "Test Epoch: 16 | Loss: 0.445 | Acc: 84.769% (3306/3900)\n",
      "Test Epoch: 16 | Loss: 0.444 | Acc: 84.800% (3392/4000)\n",
      "Test Epoch: 16 | Loss: 0.446 | Acc: 84.732% (3474/4100)\n",
      "Test Epoch: 16 | Loss: 0.446 | Acc: 84.762% (3560/4200)\n",
      "Test Epoch: 16 | Loss: 0.441 | Acc: 84.953% (3653/4300)\n",
      "Test Epoch: 16 | Loss: 0.438 | Acc: 85.023% (3741/4400)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.156% (3832/4500)\n",
      "Test Epoch: 16 | Loss: 0.436 | Acc: 85.152% (3917/4600)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.128% (4001/4700)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 85.042% (4082/4800)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.143% (4172/4900)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 85.040% (4252/5000)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 85.020% (4336/5100)\n",
      "Test Epoch: 16 | Loss: 0.438 | Acc: 85.096% (4425/5200)\n",
      "Test Epoch: 16 | Loss: 0.438 | Acc: 85.057% (4508/5300)\n",
      "Test Epoch: 16 | Loss: 0.440 | Acc: 85.000% (4590/5400)\n",
      "Test Epoch: 16 | Loss: 0.441 | Acc: 84.945% (4672/5500)\n",
      "Test Epoch: 16 | Loss: 0.440 | Acc: 85.036% (4762/5600)\n",
      "Test Epoch: 16 | Loss: 0.443 | Acc: 84.912% (4840/5700)\n",
      "Test Epoch: 16 | Loss: 0.442 | Acc: 84.966% (4928/5800)\n",
      "Test Epoch: 16 | Loss: 0.443 | Acc: 84.932% (5011/5900)\n",
      "Test Epoch: 16 | Loss: 0.443 | Acc: 84.933% (5096/6000)\n",
      "Test Epoch: 16 | Loss: 0.441 | Acc: 84.967% (5183/6100)\n",
      "Test Epoch: 16 | Loss: 0.440 | Acc: 84.935% (5266/6200)\n",
      "Test Epoch: 16 | Loss: 0.438 | Acc: 85.016% (5356/6300)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.094% (5446/6400)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.092% (5531/6500)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.076% (5615/6600)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.149% (5705/6700)\n",
      "Test Epoch: 16 | Loss: 0.433 | Acc: 85.176% (5792/6800)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.203% (5879/6900)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.129% (5959/7000)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.099% (6042/7100)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.111% (6128/7200)\n",
      "Test Epoch: 16 | Loss: 0.431 | Acc: 85.219% (6221/7300)\n",
      "Test Epoch: 16 | Loss: 0.431 | Acc: 85.230% (6307/7400)\n",
      "Test Epoch: 16 | Loss: 0.431 | Acc: 85.187% (6389/7500)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.132% (6470/7600)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.078% (6551/7700)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.103% (6638/7800)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.101% (6723/7900)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.088% (6807/8000)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.148% (6897/8100)\n",
      "Test Epoch: 16 | Loss: 0.431 | Acc: 85.159% (6983/8200)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.181% (7070/8300)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.143% (7152/8400)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.059% (7230/8500)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.023% (7312/8600)\n",
      "Test Epoch: 16 | Loss: 0.434 | Acc: 85.034% (7398/8700)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.057% (7485/8800)\n",
      "Test Epoch: 16 | Loss: 0.436 | Acc: 85.022% (7567/8900)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 85.000% (7650/9000)\n",
      "Test Epoch: 16 | Loss: 0.437 | Acc: 84.978% (7733/9100)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.065% (7826/9200)\n",
      "Test Epoch: 16 | Loss: 0.436 | Acc: 85.065% (7911/9300)\n",
      "Test Epoch: 16 | Loss: 0.435 | Acc: 85.106% (8000/9400)\n",
      "Test Epoch: 16 | Loss: 0.433 | Acc: 85.147% (8089/9500)\n",
      "Test Epoch: 16 | Loss: 0.432 | Acc: 85.208% (8180/9600)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.289% (8273/9700)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.296% (8359/9800)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.303% (8445/9900)\n",
      "Test Epoch: 16 | Loss: 0.430 | Acc: 85.320% (8532/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 17\n",
      "Train Epoch: 17 | Loss: 0.446 | Acc: 83.594% (107/128)\n",
      "Train Epoch: 17 | Loss: 0.497 | Acc: 82.422% (211/256)\n",
      "Train Epoch: 17 | Loss: 0.423 | Acc: 84.896% (326/384)\n",
      "Train Epoch: 17 | Loss: 0.429 | Acc: 85.352% (437/512)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 87.188% (558/640)\n",
      "Train Epoch: 17 | Loss: 0.392 | Acc: 87.500% (672/768)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.830% (778/896)\n",
      "Train Epoch: 17 | Loss: 0.386 | Acc: 87.305% (894/1024)\n",
      "Train Epoch: 17 | Loss: 0.389 | Acc: 86.979% (1002/1152)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.953% (1113/1280)\n",
      "Train Epoch: 17 | Loss: 0.388 | Acc: 87.145% (1227/1408)\n",
      "Train Epoch: 17 | Loss: 0.383 | Acc: 87.240% (1340/1536)\n",
      "Train Epoch: 17 | Loss: 0.381 | Acc: 87.440% (1455/1664)\n",
      "Train Epoch: 17 | Loss: 0.383 | Acc: 87.277% (1564/1792)\n",
      "Train Epoch: 17 | Loss: 0.382 | Acc: 87.344% (1677/1920)\n",
      "Train Epoch: 17 | Loss: 0.381 | Acc: 87.402% (1790/2048)\n",
      "Train Epoch: 17 | Loss: 0.380 | Acc: 87.316% (1900/2176)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.283% (2011/2304)\n",
      "Train Epoch: 17 | Loss: 0.380 | Acc: 87.048% (2117/2432)\n",
      "Train Epoch: 17 | Loss: 0.385 | Acc: 86.797% (2222/2560)\n",
      "Train Epoch: 17 | Loss: 0.380 | Acc: 86.979% (2338/2688)\n",
      "Train Epoch: 17 | Loss: 0.378 | Acc: 87.038% (2451/2816)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.092% (2564/2944)\n",
      "Train Epoch: 17 | Loss: 0.384 | Acc: 86.849% (2668/3072)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.000% (2784/3200)\n",
      "Train Epoch: 17 | Loss: 0.375 | Acc: 87.200% (2902/3328)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.326% (3018/3456)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.249% (3127/3584)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.284% (3240/3712)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.448% (3358/3840)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.525% (3473/3968)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.476% (3583/4096)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.618% (3701/4224)\n",
      "Train Epoch: 17 | Loss: 0.366 | Acc: 87.661% (3815/4352)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.589% (3924/4480)\n",
      "Train Epoch: 17 | Loss: 0.374 | Acc: 87.305% (4023/4608)\n",
      "Train Epoch: 17 | Loss: 0.376 | Acc: 87.310% (4135/4736)\n",
      "Train Epoch: 17 | Loss: 0.377 | Acc: 87.233% (4243/4864)\n",
      "Train Epoch: 17 | Loss: 0.376 | Acc: 87.260% (4356/4992)\n",
      "Train Epoch: 17 | Loss: 0.375 | Acc: 87.227% (4466/5120)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.290% (4581/5248)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.333% (4695/5376)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.300% (4805/5504)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.429% (4924/5632)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.413% (5035/5760)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.500% (5152/5888)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.483% (5263/6016)\n",
      "Train Epoch: 17 | Loss: 0.368 | Acc: 87.467% (5374/6144)\n",
      "Train Epoch: 17 | Loss: 0.367 | Acc: 87.532% (5490/6272)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.344% (5590/6400)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.377% (5704/6528)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.365% (5815/6656)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.338% (5925/6784)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.370% (6039/6912)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.429% (6155/7040)\n",
      "Train Epoch: 17 | Loss: 0.371 | Acc: 87.472% (6270/7168)\n",
      "Train Epoch: 17 | Loss: 0.373 | Acc: 87.404% (6377/7296)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.473% (6494/7424)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.526% (6610/7552)\n",
      "Train Epoch: 17 | Loss: 0.370 | Acc: 87.461% (6717/7680)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.423% (6826/7808)\n",
      "Train Epoch: 17 | Loss: 0.372 | Acc: 87.412% (6937/7936)\n",
      "Train Epoch: 17 | Loss: 0.374 | Acc: 87.388% (7047/8064)\n",
      "Train Epoch: 17 | Loss: 0.376 | Acc: 87.256% (7148/8192)\n",
      "Train Epoch: 17 | Loss: 0.377 | Acc: 87.260% (7260/8320)\n",
      "Train Epoch: 17 | Loss: 0.378 | Acc: 87.240% (7370/8448)\n",
      "Train Epoch: 17 | Loss: 0.378 | Acc: 87.232% (7481/8576)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.213% (7591/8704)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.217% (7703/8832)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.243% (7817/8960)\n",
      "Train Epoch: 17 | Loss: 0.379 | Acc: 87.225% (7927/9088)\n",
      "Train Epoch: 17 | Loss: 0.381 | Acc: 87.153% (8032/9216)\n",
      "Train Epoch: 17 | Loss: 0.383 | Acc: 87.115% (8140/9344)\n",
      "Train Epoch: 17 | Loss: 0.383 | Acc: 87.088% (8249/9472)\n",
      "Train Epoch: 17 | Loss: 0.384 | Acc: 87.021% (8354/9600)\n",
      "Train Epoch: 17 | Loss: 0.386 | Acc: 86.945% (8458/9728)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.962% (8571/9856)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.939% (8680/9984)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.917% (8789/10112)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.914% (8900/10240)\n",
      "Train Epoch: 17 | Loss: 0.386 | Acc: 86.960% (9016/10368)\n",
      "Train Epoch: 17 | Loss: 0.386 | Acc: 86.938% (9125/10496)\n",
      "Train Epoch: 17 | Loss: 0.387 | Acc: 86.869% (9229/10624)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 86.802% (9333/10752)\n",
      "Train Epoch: 17 | Loss: 0.389 | Acc: 86.811% (9445/10880)\n",
      "Train Epoch: 17 | Loss: 0.389 | Acc: 86.810% (9556/11008)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 86.782% (9664/11136)\n",
      "Train Epoch: 17 | Loss: 0.392 | Acc: 86.728% (9769/11264)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 86.771% (9885/11392)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 86.745% (9993/11520)\n",
      "Train Epoch: 17 | Loss: 0.391 | Acc: 86.719% (10101/11648)\n",
      "Train Epoch: 17 | Loss: 0.390 | Acc: 86.702% (10210/11776)\n",
      "Train Epoch: 17 | Loss: 0.391 | Acc: 86.685% (10319/11904)\n",
      "Train Epoch: 17 | Loss: 0.391 | Acc: 86.686% (10430/12032)\n",
      "Train Epoch: 17 | Loss: 0.392 | Acc: 86.686% (10541/12160)\n",
      "Train Epoch: 17 | Loss: 0.393 | Acc: 86.670% (10650/12288)\n",
      "Train Epoch: 17 | Loss: 0.393 | Acc: 86.687% (10763/12416)\n",
      "Train Epoch: 17 | Loss: 0.393 | Acc: 86.679% (10873/12544)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.632% (10978/12672)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.664% (11093/12800)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.618% (11198/12928)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.642% (11312/13056)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.590% (11416/13184)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.553% (11522/13312)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.548% (11632/13440)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.564% (11745/13568)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.638% (11866/13696)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.646% (11978/13824)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.640% (12088/13952)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.612% (12195/14080)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.662% (12313/14208)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.649% (12422/14336)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.684% (12538/14464)\n",
      "Train Epoch: 17 | Loss: 0.393 | Acc: 86.684% (12649/14592)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.617% (12750/14720)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.624% (12862/14848)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.599% (12969/14976)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.566% (13075/15104)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.601% (13191/15232)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.589% (13300/15360)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.583% (13410/15488)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.591% (13522/15616)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.592% (13633/15744)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.580% (13742/15872)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.569% (13851/16000)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.576% (13963/16128)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.590% (14076/16256)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.572% (14184/16384)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.561% (14293/16512)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.544% (14401/16640)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.540% (14511/16768)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.529% (14620/16896)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.519% (14729/17024)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.515% (14839/17152)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.510% (14949/17280)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.489% (15056/17408)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.496% (15168/17536)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.509% (15281/17664)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.488% (15388/17792)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.479% (15497/17920)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.508% (15613/18048)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.460% (15715/18176)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.446% (15823/18304)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.437% (15932/18432)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.455% (16046/18560)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.435% (16153/18688)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.437% (16264/18816)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.439% (16375/18944)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.441% (16486/19072)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.453% (16599/19200)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.465% (16712/19328)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.457% (16821/19456)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.453% (16931/19584)\n",
      "Train Epoch: 17 | Loss: 0.393 | Acc: 86.460% (17043/19712)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.431% (17148/19840)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.423% (17257/19968)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.455% (17374/20096)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.437% (17481/20224)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.453% (17595/20352)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.445% (17704/20480)\n",
      "Train Epoch: 17 | Loss: 0.394 | Acc: 86.457% (17817/20608)\n",
      "Train Epoch: 17 | Loss: 0.395 | Acc: 86.410% (17918/20736)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.369% (18020/20864)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.352% (18127/20992)\n",
      "Train Epoch: 17 | Loss: 0.396 | Acc: 86.349% (18237/21120)\n",
      "Train Epoch: 17 | Loss: 0.397 | Acc: 86.333% (18344/21248)\n",
      "Train Epoch: 17 | Loss: 0.397 | Acc: 86.321% (18452/21376)\n",
      "Train Epoch: 17 | Loss: 0.397 | Acc: 86.314% (18561/21504)\n",
      "Train Epoch: 17 | Loss: 0.398 | Acc: 86.280% (18664/21632)\n",
      "Train Epoch: 17 | Loss: 0.397 | Acc: 86.282% (18775/21760)\n",
      "Train Epoch: 17 | Loss: 0.398 | Acc: 86.294% (18888/21888)\n",
      "Train Epoch: 17 | Loss: 0.398 | Acc: 86.287% (18997/22016)\n",
      "Train Epoch: 17 | Loss: 0.398 | Acc: 86.281% (19106/22144)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.252% (19210/22272)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.228% (19315/22400)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.230% (19426/22528)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.238% (19538/22656)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.236% (19648/22784)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.230% (19757/22912)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.246% (19871/23040)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.235% (19979/23168)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.234% (20089/23296)\n",
      "Train Epoch: 17 | Loss: 0.399 | Acc: 86.253% (20204/23424)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.239% (20311/23552)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.246% (20423/23680)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.232% (20530/23808)\n",
      "Train Epoch: 17 | Loss: 0.401 | Acc: 86.213% (20636/23936)\n",
      "Train Epoch: 17 | Loss: 0.401 | Acc: 86.224% (20749/24064)\n",
      "Train Epoch: 17 | Loss: 0.400 | Acc: 86.243% (20864/24192)\n",
      "Train Epoch: 17 | Loss: 0.401 | Acc: 86.217% (20968/24320)\n",
      "Train Epoch: 17 | Loss: 0.401 | Acc: 86.220% (21079/24448)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.214% (21188/24576)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.197% (21294/24704)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.175% (21399/24832)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.166% (21507/24960)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.185% (21622/25088)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.183% (21732/25216)\n",
      "Train Epoch: 17 | Loss: 0.402 | Acc: 86.174% (21840/25344)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.157% (21946/25472)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.156% (22056/25600)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.167% (22169/25728)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.166% (22279/25856)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.161% (22388/25984)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.167% (22500/26112)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.162% (22609/26240)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.169% (22721/26368)\n",
      "Train Epoch: 17 | Loss: 0.403 | Acc: 86.160% (22829/26496)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.137% (22933/26624)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.117% (23038/26752)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.124% (23150/26880)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.126% (23261/27008)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.096% (23363/27136)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.088% (23471/27264)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.109% (23587/27392)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.105% (23696/27520)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.093% (23803/27648)\n",
      "Train Epoch: 17 | Loss: 0.404 | Acc: 86.100% (23915/27776)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.070% (24017/27904)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.066% (24126/28032)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.062% (24235/28160)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.061% (24345/28288)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.075% (24459/28416)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.032% (24557/28544)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.039% (24669/28672)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.038% (24779/28800)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.041% (24890/28928)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.020% (24994/29056)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.033% (25108/29184)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.040% (25220/29312)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.046% (25332/29440)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.056% (25445/29568)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.065% (25558/29696)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.078% (25672/29824)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.081% (25783/29952)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.110% (25902/30080)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.116% (26014/30208)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.112% (26123/30336)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.118% (26235/30464)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.137% (26351/30592)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.139% (26462/30720)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.132% (26570/30848)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.138% (26682/30976)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.140% (26793/31104)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.114% (26895/31232)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.148% (27016/31360)\n",
      "Train Epoch: 17 | Loss: 0.405 | Acc: 86.147% (27126/31488)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.118% (27227/31616)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.133% (27342/31744)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.110% (27445/31872)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.091% (27549/32000)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.084% (27657/32128)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.074% (27764/32256)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.073% (27874/32384)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.061% (27980/32512)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.057% (28089/32640)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.038% (28193/32768)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.044% (28305/32896)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.062% (28421/33024)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.067% (28533/33152)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.076% (28646/33280)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.093% (28762/33408)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.087% (28870/33536)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.101% (28985/33664)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.121% (29102/33792)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.120% (29212/33920)\n",
      "Train Epoch: 17 | Loss: 0.406 | Acc: 86.137% (29328/34048)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.107% (29428/34176)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.080% (29529/34304)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.089% (29642/34432)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.062% (29743/34560)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.064% (29854/34688)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.067% (29965/34816)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.061% (30073/34944)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.049% (30179/35072)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.045% (30288/35200)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.031% (30393/35328)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.047% (30509/35456)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.058% (30623/35584)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.030% (30723/35712)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.007% (30825/35840)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.996% (30931/35968)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.990% (31039/36096)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.993% (31150/36224)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.987% (31258/36352)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.990% (31369/36480)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.989% (31479/36608)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.986% (31588/36736)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.989% (31699/36864)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.994% (31811/36992)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.994% (31921/37120)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.986% (32028/37248)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.996% (32142/37376)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.017% (32260/37504)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.015% (32369/37632)\n",
      "Train Epoch: 17 | Loss: 0.407 | Acc: 86.022% (32482/37760)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.011% (32588/37888)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.019% (32701/38016)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 86.006% (32806/38144)\n",
      "Train Epoch: 17 | Loss: 0.408 | Acc: 85.977% (32905/38272)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.964% (33010/38400)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.953% (33116/38528)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.950% (33225/38656)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.943% (33332/38784)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.940% (33441/38912)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.945% (33553/39040)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.943% (33662/39168)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.930% (33767/39296)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.925% (33875/39424)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.935% (33989/39552)\n",
      "Train Epoch: 17 | Loss: 0.409 | Acc: 85.945% (34103/39680)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.927% (34206/39808)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.925% (34315/39936)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.913% (34420/40064)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.915% (34531/40192)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.908% (34638/40320)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.910% (34749/40448)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.913% (34860/40576)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.898% (34964/40704)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.893% (35072/40832)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.879% (35176/40960)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.877% (35285/41088)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.896% (35403/41216)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.879% (35506/41344)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.877% (35615/41472)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.885% (35728/41600)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.887% (35839/41728)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.890% (35950/41856)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.887% (36059/41984)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.888% (36169/42112)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.878% (36275/42240)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.886% (36388/42368)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.865% (36489/42496)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.869% (36601/42624)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.863% (36708/42752)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.861% (36817/42880)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.847% (36921/43008)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.852% (37033/43136)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.852% (37143/43264)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.852% (37253/43392)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.848% (37361/43520)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.839% (37467/43648)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.823% (37570/43776)\n",
      "Train Epoch: 17 | Loss: 0.412 | Acc: 85.812% (37675/43904)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.826% (37791/44032)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.820% (37898/44160)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.820% (38008/44288)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.814% (38115/44416)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.821% (38228/44544)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.826% (38340/44672)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.821% (38448/44800)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.817% (38556/44928)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.824% (38669/45056)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.827% (38780/45184)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.834% (38893/45312)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.830% (39001/45440)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.828% (39110/45568)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.819% (39216/45696)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.813% (39323/45824)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.820% (39436/45952)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.825% (39548/46080)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.808% (39650/46208)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.804% (39758/46336)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.798% (39865/46464)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.813% (39982/46592)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.815% (40093/46720)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.816% (40203/46848)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.829% (40319/46976)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.816% (40423/47104)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.821% (40535/47232)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.828% (40648/47360)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.830% (40759/47488)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.843% (40875/47616)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.843% (40985/47744)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.833% (41090/47872)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.827% (41197/48000)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.819% (41303/48128)\n",
      "Train Epoch: 17 | Loss: 0.411 | Acc: 85.819% (41413/48256)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.834% (41530/48384)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.824% (41635/48512)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.839% (41752/48640)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.835% (41860/48768)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.837% (41971/48896)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.840% (42082/49024)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.836% (42190/49152)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.838% (42301/49280)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.834% (42409/49408)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.839% (42521/49536)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.847% (42635/49664)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.859% (42751/49792)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.855% (42859/49920)\n",
      "Train Epoch: 17 | Loss: 0.410 | Acc: 85.864% (42932/50000)\n",
      "Test Epoch: 17 | Loss: 0.502 | Acc: 82.000% (82/100)\n",
      "Test Epoch: 17 | Loss: 0.455 | Acc: 85.000% (170/200)\n",
      "Test Epoch: 17 | Loss: 0.433 | Acc: 84.333% (253/300)\n",
      "Test Epoch: 17 | Loss: 0.432 | Acc: 84.750% (339/400)\n",
      "Test Epoch: 17 | Loss: 0.421 | Acc: 85.000% (425/500)\n",
      "Test Epoch: 17 | Loss: 0.386 | Acc: 86.167% (517/600)\n",
      "Test Epoch: 17 | Loss: 0.387 | Acc: 86.143% (603/700)\n",
      "Test Epoch: 17 | Loss: 0.414 | Acc: 85.000% (680/800)\n",
      "Test Epoch: 17 | Loss: 0.440 | Acc: 84.222% (758/900)\n",
      "Test Epoch: 17 | Loss: 0.443 | Acc: 84.100% (841/1000)\n",
      "Test Epoch: 17 | Loss: 0.443 | Acc: 84.364% (928/1100)\n",
      "Test Epoch: 17 | Loss: 0.458 | Acc: 84.083% (1009/1200)\n",
      "Test Epoch: 17 | Loss: 0.449 | Acc: 84.308% (1096/1300)\n",
      "Test Epoch: 17 | Loss: 0.443 | Acc: 84.786% (1187/1400)\n",
      "Test Epoch: 17 | Loss: 0.443 | Acc: 84.800% (1272/1500)\n",
      "Test Epoch: 17 | Loss: 0.446 | Acc: 84.688% (1355/1600)\n",
      "Test Epoch: 17 | Loss: 0.444 | Acc: 84.882% (1443/1700)\n",
      "Test Epoch: 17 | Loss: 0.455 | Acc: 84.556% (1522/1800)\n",
      "Test Epoch: 17 | Loss: 0.451 | Acc: 84.632% (1608/1900)\n",
      "Test Epoch: 17 | Loss: 0.451 | Acc: 84.600% (1692/2000)\n",
      "Test Epoch: 17 | Loss: 0.450 | Acc: 84.667% (1778/2100)\n",
      "Test Epoch: 17 | Loss: 0.453 | Acc: 84.773% (1865/2200)\n",
      "Test Epoch: 17 | Loss: 0.456 | Acc: 84.739% (1949/2300)\n",
      "Test Epoch: 17 | Loss: 0.454 | Acc: 84.958% (2039/2400)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.880% (2122/2500)\n",
      "Test Epoch: 17 | Loss: 0.475 | Acc: 84.808% (2205/2600)\n",
      "Test Epoch: 17 | Loss: 0.471 | Acc: 84.926% (2293/2700)\n",
      "Test Epoch: 17 | Loss: 0.469 | Acc: 84.964% (2379/2800)\n",
      "Test Epoch: 17 | Loss: 0.471 | Acc: 85.000% (2465/2900)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.967% (2549/3000)\n",
      "Test Epoch: 17 | Loss: 0.472 | Acc: 85.032% (2636/3100)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 85.125% (2724/3200)\n",
      "Test Epoch: 17 | Loss: 0.474 | Acc: 85.030% (2806/3300)\n",
      "Test Epoch: 17 | Loss: 0.475 | Acc: 84.912% (2887/3400)\n",
      "Test Epoch: 17 | Loss: 0.480 | Acc: 84.800% (2968/3500)\n",
      "Test Epoch: 17 | Loss: 0.481 | Acc: 84.806% (3053/3600)\n",
      "Test Epoch: 17 | Loss: 0.480 | Acc: 84.919% (3142/3700)\n",
      "Test Epoch: 17 | Loss: 0.481 | Acc: 84.921% (3227/3800)\n",
      "Test Epoch: 17 | Loss: 0.478 | Acc: 84.897% (3311/3900)\n",
      "Test Epoch: 17 | Loss: 0.478 | Acc: 84.825% (3393/4000)\n",
      "Test Epoch: 17 | Loss: 0.476 | Acc: 84.805% (3477/4100)\n",
      "Test Epoch: 17 | Loss: 0.477 | Acc: 84.810% (3562/4200)\n",
      "Test Epoch: 17 | Loss: 0.472 | Acc: 84.953% (3653/4300)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 85.091% (3744/4400)\n",
      "Test Epoch: 17 | Loss: 0.467 | Acc: 85.178% (3833/4500)\n",
      "Test Epoch: 17 | Loss: 0.467 | Acc: 85.109% (3915/4600)\n",
      "Test Epoch: 17 | Loss: 0.469 | Acc: 84.957% (3993/4700)\n",
      "Test Epoch: 17 | Loss: 0.469 | Acc: 84.896% (4075/4800)\n",
      "Test Epoch: 17 | Loss: 0.467 | Acc: 84.898% (4160/4900)\n",
      "Test Epoch: 17 | Loss: 0.469 | Acc: 84.900% (4245/5000)\n",
      "Test Epoch: 17 | Loss: 0.468 | Acc: 84.941% (4332/5100)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.885% (4414/5200)\n",
      "Test Epoch: 17 | Loss: 0.468 | Acc: 84.925% (4501/5300)\n",
      "Test Epoch: 17 | Loss: 0.468 | Acc: 84.926% (4586/5400)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.909% (4670/5500)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.911% (4755/5600)\n",
      "Test Epoch: 17 | Loss: 0.472 | Acc: 84.877% (4838/5700)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.931% (4926/5800)\n",
      "Test Epoch: 17 | Loss: 0.471 | Acc: 84.864% (5007/5900)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.850% (5091/6000)\n",
      "Test Epoch: 17 | Loss: 0.469 | Acc: 84.803% (5173/6100)\n",
      "Test Epoch: 17 | Loss: 0.470 | Acc: 84.758% (5255/6200)\n",
      "Test Epoch: 17 | Loss: 0.468 | Acc: 84.857% (5346/6300)\n",
      "Test Epoch: 17 | Loss: 0.464 | Acc: 84.984% (5439/6400)\n",
      "Test Epoch: 17 | Loss: 0.465 | Acc: 84.969% (5523/6500)\n",
      "Test Epoch: 17 | Loss: 0.465 | Acc: 84.955% (5607/6600)\n",
      "Test Epoch: 17 | Loss: 0.462 | Acc: 85.030% (5697/6700)\n",
      "Test Epoch: 17 | Loss: 0.465 | Acc: 84.912% (5774/6800)\n",
      "Test Epoch: 17 | Loss: 0.465 | Acc: 84.971% (5863/6900)\n",
      "Test Epoch: 17 | Loss: 0.466 | Acc: 84.900% (5943/7000)\n",
      "Test Epoch: 17 | Loss: 0.466 | Acc: 84.930% (6030/7100)\n",
      "Test Epoch: 17 | Loss: 0.465 | Acc: 84.944% (6116/7200)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.986% (6204/7300)\n",
      "Test Epoch: 17 | Loss: 0.461 | Acc: 85.054% (6294/7400)\n",
      "Test Epoch: 17 | Loss: 0.461 | Acc: 85.053% (6379/7500)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 85.053% (6464/7600)\n",
      "Test Epoch: 17 | Loss: 0.462 | Acc: 85.000% (6545/7700)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 85.038% (6633/7800)\n",
      "Test Epoch: 17 | Loss: 0.461 | Acc: 85.000% (6715/7900)\n",
      "Test Epoch: 17 | Loss: 0.461 | Acc: 85.000% (6800/8000)\n",
      "Test Epoch: 17 | Loss: 0.459 | Acc: 85.062% (6890/8100)\n",
      "Test Epoch: 17 | Loss: 0.459 | Acc: 85.061% (6975/8200)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 85.036% (7058/8300)\n",
      "Test Epoch: 17 | Loss: 0.459 | Acc: 85.024% (7142/8400)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 84.941% (7220/8500)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.907% (7302/8600)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.897% (7386/8700)\n",
      "Test Epoch: 17 | Loss: 0.462 | Acc: 84.875% (7469/8800)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.876% (7554/8900)\n",
      "Test Epoch: 17 | Loss: 0.464 | Acc: 84.867% (7638/9000)\n",
      "Test Epoch: 17 | Loss: 0.464 | Acc: 84.901% (7726/9100)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.913% (7812/9200)\n",
      "Test Epoch: 17 | Loss: 0.464 | Acc: 84.892% (7895/9300)\n",
      "Test Epoch: 17 | Loss: 0.463 | Acc: 84.894% (7980/9400)\n",
      "Test Epoch: 17 | Loss: 0.462 | Acc: 84.895% (8065/9500)\n",
      "Test Epoch: 17 | Loss: 0.461 | Acc: 84.927% (8153/9600)\n",
      "Test Epoch: 17 | Loss: 0.459 | Acc: 84.990% (8244/9700)\n",
      "Test Epoch: 17 | Loss: 0.459 | Acc: 85.010% (8331/9800)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 84.960% (8411/9900)\n",
      "Test Epoch: 17 | Loss: 0.460 | Acc: 84.940% (8494/10000)\n",
      "\n",
      "Epoch: 18\n",
      "Train Epoch: 18 | Loss: 0.563 | Acc: 80.469% (103/128)\n",
      "Train Epoch: 18 | Loss: 0.452 | Acc: 84.375% (216/256)\n",
      "Train Epoch: 18 | Loss: 0.384 | Acc: 87.240% (335/384)\n",
      "Train Epoch: 18 | Loss: 0.410 | Acc: 86.328% (442/512)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.875% (556/640)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.979% (668/768)\n",
      "Train Epoch: 18 | Loss: 0.377 | Acc: 87.277% (782/896)\n",
      "Train Epoch: 18 | Loss: 0.379 | Acc: 87.012% (891/1024)\n",
      "Train Epoch: 18 | Loss: 0.371 | Acc: 87.500% (1008/1152)\n",
      "Train Epoch: 18 | Loss: 0.373 | Acc: 87.500% (1120/1280)\n",
      "Train Epoch: 18 | Loss: 0.371 | Acc: 87.358% (1230/1408)\n",
      "Train Epoch: 18 | Loss: 0.381 | Acc: 86.784% (1333/1536)\n",
      "Train Epoch: 18 | Loss: 0.382 | Acc: 86.839% (1445/1664)\n",
      "Train Epoch: 18 | Loss: 0.380 | Acc: 86.886% (1557/1792)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.771% (1666/1920)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.279% (1767/2048)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.213% (1876/2176)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.285% (1988/2304)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.143% (2095/2432)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.094% (2204/2560)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.086% (2314/2688)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.080% (2424/2816)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.277% (2540/2944)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.198% (2648/3072)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.125% (2756/3200)\n",
      "Train Epoch: 18 | Loss: 0.402 | Acc: 85.998% (2862/3328)\n",
      "Train Epoch: 18 | Loss: 0.403 | Acc: 85.966% (2971/3456)\n",
      "Train Epoch: 18 | Loss: 0.403 | Acc: 85.854% (3077/3584)\n",
      "Train Epoch: 18 | Loss: 0.404 | Acc: 85.803% (3185/3712)\n",
      "Train Epoch: 18 | Loss: 0.401 | Acc: 85.964% (3301/3840)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.013% (3413/3968)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.060% (3525/4096)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.198% (3641/4224)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.190% (3751/4352)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.183% (3861/4480)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.089% (3967/4608)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.128% (4079/4736)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.164% (4191/4864)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.318% (4309/4992)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.270% (4417/5120)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.338% (4531/5248)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.384% (4644/5376)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.392% (4755/5504)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.506% (4872/5632)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.476% (4981/5760)\n",
      "Train Epoch: 18 | Loss: 0.384 | Acc: 86.515% (5094/5888)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.536% (5206/6016)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.442% (5311/6144)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.496% (5425/6272)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.562% (5540/6400)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.535% (5649/6528)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.493% (5757/6656)\n",
      "Train Epoch: 18 | Loss: 0.389 | Acc: 86.498% (5868/6784)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.531% (5981/6912)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.562% (6094/7040)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.565% (6205/7168)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.541% (6314/7296)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.490% (6421/7424)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.361% (6522/7552)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.302% (6628/7680)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.322% (6740/7808)\n",
      "Train Epoch: 18 | Loss: 0.389 | Acc: 86.353% (6853/7936)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.434% (6970/8064)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.462% (7083/8192)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.370% (7186/8320)\n",
      "Train Epoch: 18 | Loss: 0.389 | Acc: 86.375% (7297/8448)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.462% (7415/8576)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.500% (7529/8704)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.515% (7641/8832)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.529% (7753/8960)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.565% (7867/9088)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.610% (7982/9216)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.633% (8095/9344)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.666% (8209/9472)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.677% (8321/9600)\n",
      "Train Epoch: 18 | Loss: 0.385 | Acc: 86.657% (8430/9728)\n",
      "Train Epoch: 18 | Loss: 0.384 | Acc: 86.688% (8544/9856)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.609% (8647/9984)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.640% (8761/10112)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.631% (8871/10240)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.642% (8983/10368)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.652% (9095/10496)\n",
      "Train Epoch: 18 | Loss: 0.386 | Acc: 86.672% (9208/10624)\n",
      "Train Epoch: 18 | Loss: 0.387 | Acc: 86.654% (9317/10752)\n",
      "Train Epoch: 18 | Loss: 0.388 | Acc: 86.654% (9428/10880)\n",
      "Train Epoch: 18 | Loss: 0.389 | Acc: 86.637% (9537/11008)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.575% (9641/11136)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.586% (9753/11264)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.570% (9862/11392)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.597% (9976/11520)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.564% (10083/11648)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.557% (10193/11776)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.559% (10304/11904)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.519% (10410/12032)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.538% (10523/12160)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.491% (10628/12288)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.437% (10732/12416)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.472% (10847/12544)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.490% (10960/12672)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.531% (11076/12800)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.533% (11187/12928)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.497% (11293/13056)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.537% (11409/13184)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.523% (11518/13312)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.503% (11626/13440)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.505% (11737/13568)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.544% (11853/13696)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.538% (11963/13824)\n",
      "Train Epoch: 18 | Loss: 0.389 | Acc: 86.568% (12078/13952)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.555% (12187/14080)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.557% (12298/14208)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.544% (12407/14336)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.498% (12511/14464)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.479% (12619/14592)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.501% (12733/14720)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.503% (12844/14848)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.485% (12952/14976)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.480% (13062/15104)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.502% (13176/15232)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.530% (13291/15360)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.544% (13404/15488)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.520% (13511/15616)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.477% (13615/15744)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.467% (13724/15872)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.506% (13841/16000)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.477% (13947/16128)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.460% (14055/16256)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.475% (14168/16384)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.483% (14280/16512)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.412% (14379/16640)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.403% (14488/16768)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.446% (14606/16896)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.472% (14721/17024)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.486% (14834/17152)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.505% (14948/17280)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.500% (15058/17408)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.508% (15170/17536)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.487% (15277/17664)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.500% (15390/17792)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.529% (15506/17920)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.475% (15607/18048)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.433% (15710/18176)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.462% (15826/18304)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.464% (15937/18432)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.439% (16043/18560)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.408% (16148/18688)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.432% (16263/18816)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.471% (16381/18944)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.488% (16495/19072)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.500% (16608/19200)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.501% (16719/19328)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.482% (16826/19456)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.515% (16943/19584)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.490% (17049/19712)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.517% (17165/19840)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.518% (17276/19968)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.495% (17382/20096)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.521% (17498/20224)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.547% (17614/20352)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.548% (17725/20480)\n",
      "Train Epoch: 18 | Loss: 0.390 | Acc: 86.563% (17839/20608)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.531% (17943/20736)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.508% (18049/20864)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.523% (18163/20992)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.510% (18271/21120)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.512% (18382/21248)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.513% (18493/21376)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.514% (18604/21504)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.520% (18716/21632)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.540% (18831/21760)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.531% (18940/21888)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.519% (19048/22016)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.516% (19158/22144)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.499% (19265/22272)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.451% (19365/22400)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.475% (19481/22528)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.463% (19589/22656)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.477% (19703/22784)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.474% (19813/22912)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.471% (19923/23040)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.464% (20032/23168)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.487% (20148/23296)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.492% (20260/23424)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.502% (20373/23552)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.499% (20483/23680)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.488% (20591/23808)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.493% (20703/23936)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.490% (20813/24064)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.491% (20924/24192)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.505% (21038/24320)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.502% (21148/24448)\n",
      "Train Epoch: 18 | Loss: 0.391 | Acc: 86.519% (21263/24576)\n",
      "Train Epoch: 18 | Loss: 0.392 | Acc: 86.484% (21365/24704)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.473% (21473/24832)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.454% (21579/24960)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.440% (21686/25088)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.413% (21790/25216)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.423% (21903/25344)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.432% (22016/25472)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.410% (22121/25600)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.400% (22229/25728)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.382% (22335/25856)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.399% (22450/25984)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.412% (22564/26112)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.418% (22676/26240)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.393% (22780/26368)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.405% (22894/26496)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.388% (23000/26624)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.371% (23106/26752)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.380% (23219/26880)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.374% (23328/27008)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.369% (23437/27136)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.345% (23541/27264)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.357% (23655/27392)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.352% (23764/27520)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.350% (23874/27648)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.355% (23986/27776)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.378% (24103/27904)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.369% (24211/28032)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.367% (24321/28160)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.365% (24431/28288)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.360% (24540/28416)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.361% (24651/28544)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.373% (24765/28672)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.385% (24879/28800)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.338% (24976/28928)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.344% (25088/29056)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.352% (25201/29184)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.361% (25314/29312)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.379% (25430/29440)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.394% (25545/29568)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.399% (25657/29696)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.394% (25766/29824)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.408% (25881/29952)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.376% (25982/30080)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.371% (26091/30208)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.353% (26196/30336)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.368% (26311/30464)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.366% (26421/30592)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.354% (26528/30720)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.349% (26637/30848)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.341% (26745/30976)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.339% (26855/31104)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.338% (26965/31232)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.362% (27083/31360)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.357% (27192/31488)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.380% (27310/31616)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.369% (27417/31744)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.377% (27530/31872)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.394% (27646/32000)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.389% (27755/32128)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.421% (27876/32256)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.385% (27975/32384)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.383% (28085/32512)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.376% (28193/32640)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.389% (28308/32768)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.378% (28415/32896)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.392% (28530/33024)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.393% (28641/33152)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.388% (28750/33280)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.407% (28867/33408)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.418% (28981/33536)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.428% (29095/33664)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.426% (29205/33792)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.430% (29317/33920)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.422% (29425/34048)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.423% (29536/34176)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.433% (29650/34304)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.449% (29766/34432)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.447% (29876/34560)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.448% (29987/34688)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.434% (30093/34816)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.438% (30205/34944)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.454% (30321/35072)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.435% (30425/35200)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.419% (30530/35328)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.431% (30645/35456)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.424% (30753/35584)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.430% (30866/35712)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.426% (30975/35840)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.432% (31088/35968)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.436% (31200/36096)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.451% (31316/36224)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.460% (31430/36352)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.445% (31535/36480)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.446% (31646/36608)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.449% (31758/36736)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.453% (31870/36864)\n",
      "Train Epoch: 18 | Loss: 0.393 | Acc: 86.451% (31980/36992)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.436% (32085/37120)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.440% (32197/37248)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.440% (32308/37376)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.436% (32417/37504)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.458% (32536/37632)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.457% (32646/37760)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.455% (32756/37888)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.437% (32860/38016)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.438% (32971/38144)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.444% (33084/38272)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.427% (33188/38400)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.433% (33301/38528)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.450% (33418/38656)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.430% (33521/38784)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.421% (33628/38912)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.432% (33743/39040)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.438% (33856/39168)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.441% (33968/39296)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.435% (34076/39424)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.428% (34184/39552)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.431% (34296/39680)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.445% (34412/39808)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.451% (34525/39936)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.442% (34632/40064)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.450% (34746/40192)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.431% (34849/40320)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.427% (34958/40448)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.423% (35067/40576)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.429% (35180/40704)\n",
      "Train Epoch: 18 | Loss: 0.394 | Acc: 86.432% (35292/40832)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.433% (35403/40960)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.422% (35509/41088)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.418% (35618/41216)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.424% (35731/41344)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.425% (35842/41472)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.430% (35955/41600)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.429% (36065/41728)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.425% (36174/41856)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.407% (36277/41984)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.405% (36387/42112)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.411% (36500/42240)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.398% (36605/42368)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.410% (36721/42496)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.411% (36832/42624)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.417% (36945/42752)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.423% (37058/42880)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.410% (37163/43008)\n",
      "Train Epoch: 18 | Loss: 0.395 | Acc: 86.406% (37272/43136)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.393% (37377/43264)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.389% (37486/43392)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.388% (37596/43520)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.382% (37704/43648)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.378% (37813/43776)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.379% (37924/43904)\n",
      "Train Epoch: 18 | Loss: 0.396 | Acc: 86.371% (38031/44032)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.345% (38130/44160)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.337% (38237/44288)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.332% (38345/44416)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.328% (38454/44544)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.329% (38565/44672)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.342% (38681/44800)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.338% (38790/44928)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.335% (38899/45056)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.329% (39007/45184)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.330% (39118/45312)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.329% (39228/45440)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.313% (39331/45568)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.303% (39437/45696)\n",
      "Train Epoch: 18 | Loss: 0.397 | Acc: 86.311% (39551/45824)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.284% (39649/45952)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.280% (39758/46080)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.288% (39872/46208)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.289% (39983/46336)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.284% (40091/46464)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.279% (40199/46592)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.289% (40314/46720)\n",
      "Train Epoch: 18 | Loss: 0.398 | Acc: 86.292% (40426/46848)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.293% (40537/46976)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.286% (40644/47104)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.283% (40753/47232)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.294% (40869/47360)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.289% (40977/47488)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.282% (41084/47616)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.279% (41193/47744)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.291% (41309/47872)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.281% (41415/48000)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.278% (41524/48128)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.284% (41637/48256)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.283% (41747/48384)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.278% (41855/48512)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.275% (41964/48640)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.270% (42072/48768)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.265% (42180/48896)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.256% (42286/49024)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.237% (42387/49152)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.240% (42499/49280)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.231% (42605/49408)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.226% (42713/49536)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.231% (42826/49664)\n",
      "Train Epoch: 18 | Loss: 0.400 | Acc: 86.241% (42941/49792)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.252% (43057/49920)\n",
      "Train Epoch: 18 | Loss: 0.399 | Acc: 86.256% (43128/50000)\n",
      "Test Epoch: 18 | Loss: 0.398 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 18 | Loss: 0.432 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 18 | Loss: 0.405 | Acc: 87.000% (261/300)\n",
      "Test Epoch: 18 | Loss: 0.384 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 18 | Loss: 0.381 | Acc: 87.400% (437/500)\n",
      "Test Epoch: 18 | Loss: 0.347 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 18 | Loss: 0.359 | Acc: 88.286% (618/700)\n",
      "Test Epoch: 18 | Loss: 0.390 | Acc: 87.500% (700/800)\n",
      "Test Epoch: 18 | Loss: 0.405 | Acc: 86.778% (781/900)\n",
      "Test Epoch: 18 | Loss: 0.404 | Acc: 86.900% (869/1000)\n",
      "Test Epoch: 18 | Loss: 0.408 | Acc: 86.818% (955/1100)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.833% (1042/1200)\n",
      "Test Epoch: 18 | Loss: 0.401 | Acc: 86.769% (1128/1300)\n",
      "Test Epoch: 18 | Loss: 0.397 | Acc: 86.786% (1215/1400)\n",
      "Test Epoch: 18 | Loss: 0.395 | Acc: 86.667% (1300/1500)\n",
      "Test Epoch: 18 | Loss: 0.399 | Acc: 86.500% (1384/1600)\n",
      "Test Epoch: 18 | Loss: 0.402 | Acc: 86.471% (1470/1700)\n",
      "Test Epoch: 18 | Loss: 0.403 | Acc: 86.278% (1553/1800)\n",
      "Test Epoch: 18 | Loss: 0.398 | Acc: 86.474% (1643/1900)\n",
      "Test Epoch: 18 | Loss: 0.402 | Acc: 86.300% (1726/2000)\n",
      "Test Epoch: 18 | Loss: 0.402 | Acc: 86.238% (1811/2100)\n",
      "Test Epoch: 18 | Loss: 0.402 | Acc: 86.227% (1897/2200)\n",
      "Test Epoch: 18 | Loss: 0.404 | Acc: 86.174% (1982/2300)\n",
      "Test Epoch: 18 | Loss: 0.401 | Acc: 86.208% (2069/2400)\n",
      "Test Epoch: 18 | Loss: 0.408 | Acc: 86.240% (2156/2500)\n",
      "Test Epoch: 18 | Loss: 0.415 | Acc: 86.154% (2240/2600)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.259% (2329/2700)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.214% (2414/2800)\n",
      "Test Epoch: 18 | Loss: 0.413 | Acc: 86.138% (2498/2900)\n",
      "Test Epoch: 18 | Loss: 0.413 | Acc: 86.133% (2584/3000)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 86.065% (2668/3100)\n",
      "Test Epoch: 18 | Loss: 0.414 | Acc: 86.156% (2757/3200)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.242% (2846/3300)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.059% (2926/3400)\n",
      "Test Epoch: 18 | Loss: 0.413 | Acc: 86.029% (3011/3500)\n",
      "Test Epoch: 18 | Loss: 0.414 | Acc: 86.111% (3100/3600)\n",
      "Test Epoch: 18 | Loss: 0.415 | Acc: 85.946% (3180/3700)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 85.921% (3265/3800)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 85.923% (3351/3900)\n",
      "Test Epoch: 18 | Loss: 0.418 | Acc: 86.000% (3440/4000)\n",
      "Test Epoch: 18 | Loss: 0.423 | Acc: 85.878% (3521/4100)\n",
      "Test Epoch: 18 | Loss: 0.424 | Acc: 85.881% (3607/4200)\n",
      "Test Epoch: 18 | Loss: 0.419 | Acc: 86.000% (3698/4300)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 86.000% (3784/4400)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 86.000% (3870/4500)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 85.913% (3952/4600)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 85.894% (4037/4700)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 85.875% (4122/4800)\n",
      "Test Epoch: 18 | Loss: 0.414 | Acc: 85.980% (4213/4900)\n",
      "Test Epoch: 18 | Loss: 0.418 | Acc: 85.940% (4297/5000)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 86.000% (4386/5100)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 86.077% (4476/5200)\n",
      "Test Epoch: 18 | Loss: 0.416 | Acc: 86.057% (4561/5300)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 86.111% (4650/5400)\n",
      "Test Epoch: 18 | Loss: 0.417 | Acc: 86.127% (4737/5500)\n",
      "Test Epoch: 18 | Loss: 0.420 | Acc: 86.036% (4818/5600)\n",
      "Test Epoch: 18 | Loss: 0.421 | Acc: 85.965% (4900/5700)\n",
      "Test Epoch: 18 | Loss: 0.420 | Acc: 85.966% (4986/5800)\n",
      "Test Epoch: 18 | Loss: 0.421 | Acc: 85.881% (5067/5900)\n",
      "Test Epoch: 18 | Loss: 0.422 | Acc: 85.833% (5150/6000)\n",
      "Test Epoch: 18 | Loss: 0.420 | Acc: 85.934% (5242/6100)\n",
      "Test Epoch: 18 | Loss: 0.419 | Acc: 85.919% (5327/6200)\n",
      "Test Epoch: 18 | Loss: 0.419 | Acc: 85.905% (5412/6300)\n",
      "Test Epoch: 18 | Loss: 0.415 | Acc: 86.047% (5507/6400)\n",
      "Test Epoch: 18 | Loss: 0.414 | Acc: 86.077% (5595/6500)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.106% (5683/6600)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.164% (5773/6700)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.132% (5857/6800)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.159% (5945/6900)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.057% (6024/7000)\n",
      "Test Epoch: 18 | Loss: 0.413 | Acc: 86.042% (6109/7100)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.028% (6194/7200)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.082% (6284/7300)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.108% (6372/7400)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.093% (6457/7500)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.145% (6547/7600)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.156% (6634/7700)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.167% (6721/7800)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.241% (6813/7900)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.237% (6899/8000)\n",
      "Test Epoch: 18 | Loss: 0.407 | Acc: 86.321% (6992/8100)\n",
      "Test Epoch: 18 | Loss: 0.406 | Acc: 86.341% (7080/8200)\n",
      "Test Epoch: 18 | Loss: 0.406 | Acc: 86.289% (7162/8300)\n",
      "Test Epoch: 18 | Loss: 0.406 | Acc: 86.262% (7246/8400)\n",
      "Test Epoch: 18 | Loss: 0.406 | Acc: 86.212% (7328/8500)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.151% (7409/8600)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.138% (7494/8700)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.148% (7581/8800)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.169% (7669/8900)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.144% (7753/9000)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.165% (7841/9100)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.250% (7935/9200)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.247% (8021/9300)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.234% (8106/9400)\n",
      "Test Epoch: 18 | Loss: 0.412 | Acc: 86.232% (8192/9500)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.271% (8282/9600)\n",
      "Test Epoch: 18 | Loss: 0.409 | Acc: 86.330% (8374/9700)\n",
      "Test Epoch: 18 | Loss: 0.410 | Acc: 86.337% (8461/9800)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.303% (8544/9900)\n",
      "Test Epoch: 18 | Loss: 0.411 | Acc: 86.290% (8629/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      "Train Epoch: 19 | Loss: 0.530 | Acc: 82.031% (105/128)\n",
      "Train Epoch: 19 | Loss: 0.496 | Acc: 82.812% (212/256)\n",
      "Train Epoch: 19 | Loss: 0.466 | Acc: 83.333% (320/384)\n",
      "Train Epoch: 19 | Loss: 0.418 | Acc: 84.570% (433/512)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 85.625% (548/640)\n",
      "Train Epoch: 19 | Loss: 0.370 | Acc: 86.458% (664/768)\n",
      "Train Epoch: 19 | Loss: 0.369 | Acc: 86.719% (777/896)\n",
      "Train Epoch: 19 | Loss: 0.371 | Acc: 86.523% (886/1024)\n",
      "Train Epoch: 19 | Loss: 0.369 | Acc: 87.066% (1003/1152)\n",
      "Train Epoch: 19 | Loss: 0.368 | Acc: 87.188% (1116/1280)\n",
      "Train Epoch: 19 | Loss: 0.368 | Acc: 87.216% (1228/1408)\n",
      "Train Epoch: 19 | Loss: 0.371 | Acc: 87.305% (1341/1536)\n",
      "Train Epoch: 19 | Loss: 0.372 | Acc: 87.200% (1451/1664)\n",
      "Train Epoch: 19 | Loss: 0.366 | Acc: 87.333% (1565/1792)\n",
      "Train Epoch: 19 | Loss: 0.372 | Acc: 87.031% (1671/1920)\n",
      "Train Epoch: 19 | Loss: 0.371 | Acc: 87.109% (1784/2048)\n",
      "Train Epoch: 19 | Loss: 0.372 | Acc: 87.086% (1895/2176)\n",
      "Train Epoch: 19 | Loss: 0.367 | Acc: 87.283% (2011/2304)\n",
      "Train Epoch: 19 | Loss: 0.368 | Acc: 87.212% (2121/2432)\n",
      "Train Epoch: 19 | Loss: 0.375 | Acc: 86.992% (2227/2560)\n",
      "Train Epoch: 19 | Loss: 0.375 | Acc: 86.979% (2338/2688)\n",
      "Train Epoch: 19 | Loss: 0.377 | Acc: 87.074% (2452/2816)\n",
      "Train Epoch: 19 | Loss: 0.376 | Acc: 87.024% (2562/2944)\n",
      "Train Epoch: 19 | Loss: 0.374 | Acc: 87.077% (2675/3072)\n",
      "Train Epoch: 19 | Loss: 0.376 | Acc: 86.969% (2783/3200)\n",
      "Train Epoch: 19 | Loss: 0.374 | Acc: 87.019% (2896/3328)\n",
      "Train Epoch: 19 | Loss: 0.374 | Acc: 87.008% (3007/3456)\n",
      "Train Epoch: 19 | Loss: 0.375 | Acc: 86.970% (3117/3584)\n",
      "Train Epoch: 19 | Loss: 0.372 | Acc: 87.096% (3233/3712)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 86.719% (3330/3840)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.895% (3448/3968)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.890% (3559/4096)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 86.861% (3669/4224)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 86.972% (3785/4352)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 86.987% (3897/4480)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.892% (4004/4608)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.740% (4108/4736)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.801% (4222/4864)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.679% (4327/4992)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.641% (4436/5120)\n",
      "Train Epoch: 19 | Loss: 0.395 | Acc: 86.566% (4543/5248)\n",
      "Train Epoch: 19 | Loss: 0.397 | Acc: 86.477% (4649/5376)\n",
      "Train Epoch: 19 | Loss: 0.397 | Acc: 86.519% (4762/5504)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.523% (4873/5632)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.580% (4987/5760)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.515% (5094/5888)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.536% (5206/6016)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.507% (5315/6144)\n",
      "Train Epoch: 19 | Loss: 0.398 | Acc: 86.527% (5427/6272)\n",
      "Train Epoch: 19 | Loss: 0.396 | Acc: 86.562% (5540/6400)\n",
      "Train Epoch: 19 | Loss: 0.395 | Acc: 86.581% (5652/6528)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.644% (5767/6656)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.675% (5880/6784)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.632% (5988/6912)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.662% (6101/7040)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.635% (6210/7168)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.609% (6319/7296)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.651% (6433/7424)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.666% (6545/7552)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.758% (6663/7680)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.770% (6775/7808)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.681% (6879/7936)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.669% (6989/8064)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.670% (7100/8192)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.707% (7214/8320)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.766% (7330/8448)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.777% (7442/8576)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.788% (7554/8704)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.787% (7665/8832)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.797% (7777/8960)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.818% (7890/9088)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.871% (8006/9216)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.869% (8117/9344)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.814% (8223/9472)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.865% (8339/9600)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.863% (8450/9728)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.891% (8564/9856)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.889% (8675/9984)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.936% (8791/10112)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 86.914% (8900/10240)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.979% (9018/10368)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 86.995% (9131/10496)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 87.001% (9243/10624)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.914% (9345/10752)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.893% (9454/10880)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.891% (9565/11008)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.979% (9686/11136)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.994% (9799/11264)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.017% (9913/11392)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.997% (10022/11520)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.062% (10141/11648)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 87.050% (10251/11776)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.004% (10357/11904)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 87.018% (10470/12032)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.056% (10586/12160)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.077% (10700/12288)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.138% (10819/12416)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.117% (10928/12544)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.129% (11041/12672)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.164% (11157/12800)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.136% (11265/12928)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.140% (11377/13056)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.121% (11486/13184)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.087% (11593/13312)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.098% (11706/13440)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.073% (11814/13568)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.055% (11923/13696)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.059% (12035/13824)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.099% (12152/13952)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.131% (12268/14080)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.071% (12371/14208)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.033% (12477/14336)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.071% (12594/14464)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.082% (12707/14592)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.126% (12825/14720)\n",
      "Train Epoch: 19 | Loss: 0.379 | Acc: 87.157% (12941/14848)\n",
      "Train Epoch: 19 | Loss: 0.379 | Acc: 87.166% (13054/14976)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.162% (13165/15104)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.119% (13270/15232)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.135% (13384/15360)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.177% (13502/15488)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.167% (13612/15616)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.163% (13723/15744)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.198% (13840/15872)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.188% (13950/16000)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.128% (14052/16128)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.106% (14160/16256)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.097% (14270/16384)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.131% (14387/16512)\n",
      "Train Epoch: 19 | Loss: 0.380 | Acc: 87.157% (14503/16640)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.130% (14610/16768)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.098% (14716/16896)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.112% (14830/17024)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.109% (14941/17152)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.112% (15053/17280)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.109% (15164/17408)\n",
      "Train Epoch: 19 | Loss: 0.381 | Acc: 87.089% (15272/17536)\n",
      "Train Epoch: 19 | Loss: 0.382 | Acc: 87.070% (15380/17664)\n",
      "Train Epoch: 19 | Loss: 0.383 | Acc: 87.033% (15485/17792)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.015% (15593/17920)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.023% (15706/18048)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.021% (15817/18176)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.019% (15928/18304)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.033% (16042/18432)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.020% (16151/18560)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.008% (16260/18688)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 87.011% (16372/18816)\n",
      "Train Epoch: 19 | Loss: 0.384 | Acc: 86.988% (16479/18944)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 86.986% (16590/19072)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 86.964% (16697/19200)\n",
      "Train Epoch: 19 | Loss: 0.385 | Acc: 86.941% (16804/19328)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.940% (16915/19456)\n",
      "Train Epoch: 19 | Loss: 0.386 | Acc: 86.892% (17017/19584)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.846% (17119/19712)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.835% (17228/19840)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.874% (17347/19968)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.848% (17453/20096)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.842% (17563/20224)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.822% (17670/20352)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.831% (17783/20480)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.845% (17897/20608)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.873% (18014/20736)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.853% (18121/20864)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.876% (18237/20992)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.870% (18347/21120)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.869% (18458/21248)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.864% (18568/21376)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.877% (18682/21504)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.867% (18791/21632)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.880% (18905/21760)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.906% (19022/21888)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.891% (19130/22016)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.845% (19231/22144)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.844% (19342/22272)\n",
      "Train Epoch: 19 | Loss: 0.387 | Acc: 86.844% (19453/22400)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.834% (19562/22528)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.829% (19672/22656)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.837% (19785/22784)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.832% (19895/22912)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.793% (19997/23040)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.792% (20108/23168)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.762% (20212/23296)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.774% (20326/23424)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.804% (20444/23552)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.816% (20558/23680)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.828% (20672/23808)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.815% (20780/23936)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.814% (20891/24064)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.806% (21000/24192)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.752% (21098/24320)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.776% (21215/24448)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.755% (21321/24576)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.771% (21436/24704)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.767% (21546/24832)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.771% (21658/24960)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.747% (21763/25088)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.766% (21879/25216)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.766% (21990/25344)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.766% (22101/25472)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.766% (22212/25600)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.746% (22318/25728)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.738% (22427/25856)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.723% (22534/25984)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.723% (22645/26112)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.734% (22759/26240)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.757% (22876/26368)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.764% (22989/26496)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.756% (23098/26624)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.767% (23212/26752)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.760% (23321/26880)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.748% (23429/27008)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.745% (23539/27136)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.763% (23655/27264)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.766% (23767/27392)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.781% (23882/27520)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.773% (23991/27648)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.758% (24098/27776)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.747% (24206/27904)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.740% (24315/28032)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.744% (24427/28160)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.754% (24541/28288)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.754% (24652/28416)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.757% (24764/28544)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.761% (24876/28672)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.753% (24985/28800)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.736% (25091/28928)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.743% (25204/29056)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.722% (25309/29184)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.732% (25423/29312)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.722% (25531/29440)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.726% (25643/29568)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.702% (25747/29696)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.689% (25854/29824)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.675% (25961/29952)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.682% (26074/30080)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.699% (26190/30208)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.702% (26302/30336)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.715% (26417/30464)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.709% (26526/30592)\n",
      "Train Epoch: 19 | Loss: 0.388 | Acc: 86.722% (26641/30720)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.712% (26749/30848)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.690% (26853/30976)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.690% (26964/31104)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.687% (27074/31232)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.677% (27182/31360)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.665% (27289/31488)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.671% (27402/31616)\n",
      "Train Epoch: 19 | Loss: 0.389 | Acc: 86.678% (27515/31744)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.672% (27624/31872)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.656% (27730/32000)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.635% (27834/32128)\n",
      "Train Epoch: 19 | Loss: 0.390 | Acc: 86.638% (27946/32256)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.620% (28051/32384)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.626% (28164/32512)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.599% (28266/32640)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.591% (28374/32768)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.585% (28483/32896)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.555% (28584/33024)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (28690/33152)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.550% (28804/33280)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.539% (28911/33408)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.543% (29023/33536)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.549% (29136/33664)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.553% (29248/33792)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.565% (29363/33920)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.587% (29481/34048)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.581% (29590/34176)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.579% (29700/34304)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.582% (29812/34432)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.586% (29924/34560)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.595% (30038/34688)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.595% (30149/34816)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.599% (30261/34944)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.588% (30368/35072)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.580% (30476/35200)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.589% (30590/35328)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.595% (30703/35456)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.581% (30809/35584)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.598% (30926/35712)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.582% (31031/35840)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.610% (31152/35968)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.597% (31258/36096)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.611% (31374/36224)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.625% (31490/36352)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.631% (31603/36480)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.640% (31717/36608)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.623% (31822/36736)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.637% (31938/36864)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.621% (32043/36992)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.624% (32155/37120)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.619% (32264/37248)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.612% (32372/37376)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.625% (32488/37504)\n",
      "Train Epoch: 19 | Loss: 0.391 | Acc: 86.626% (32599/37632)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.610% (32704/37760)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.595% (32809/37888)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.579% (32914/38016)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.585% (33027/38144)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.588% (33139/38272)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.596% (33253/38400)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.602% (33366/38528)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.605% (33478/38656)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.580% (33579/38784)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.565% (33684/38912)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.565% (33795/39040)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.553% (33901/39168)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.556% (34013/39296)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.549% (34121/39424)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.552% (34233/39552)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.555% (34345/39680)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.560% (34458/39808)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.558% (34568/39936)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.554% (34677/40064)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.540% (34782/40192)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.550% (34897/40320)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.553% (35009/40448)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.539% (35114/40576)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.534% (35223/40704)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.547% (35339/40832)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.543% (35448/40960)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.558% (35565/41088)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.551% (35673/41216)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.554% (35785/41344)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.562% (35899/41472)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.560% (36009/41600)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (36112/41728)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.544% (36224/41856)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.554% (36339/41984)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.550% (36448/42112)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.534% (36552/42240)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.532% (36662/42368)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.547% (36779/42496)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.533% (36884/42624)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.529% (36993/42752)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.535% (37106/42880)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.533% (37216/43008)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.531% (37326/43136)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.534% (37438/43264)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.534% (37549/43392)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.530% (37658/43520)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.540% (37773/43648)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (37884/43776)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.537% (37993/43904)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.539% (38105/44032)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.542% (38217/44160)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.543% (38328/44288)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (38438/44416)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.535% (38546/44544)\n",
      "Train Epoch: 19 | Loss: 0.394 | Acc: 86.520% (38650/44672)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.538% (38769/44800)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.543% (38882/44928)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.548% (38995/45056)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.546% (39105/45184)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.540% (39213/45312)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.540% (39324/45440)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.532% (39431/45568)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.539% (39545/45696)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.542% (39657/45824)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.536% (39765/45952)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (39878/46080)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.541% (39989/46208)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.542% (40100/46336)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.549% (40214/46464)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.562% (40331/46592)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.571% (40446/46720)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.569% (40556/46848)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.570% (40667/46976)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.574% (40780/47104)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.585% (40896/47232)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.582% (41005/47360)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.580% (41115/47488)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.565% (41219/47616)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.553% (41324/47744)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.554% (41435/47872)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.567% (41552/48000)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.567% (41663/48128)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.567% (41774/48256)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.570% (41886/48384)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.558% (41991/48512)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.567% (42106/48640)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.575% (42221/48768)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.586% (42337/48896)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.576% (42443/49024)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.580% (42556/49152)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.575% (42664/49280)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.579% (42777/49408)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.581% (42889/49536)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.578% (42998/49664)\n",
      "Train Epoch: 19 | Loss: 0.392 | Acc: 86.576% (43108/49792)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.571% (43216/49920)\n",
      "Train Epoch: 19 | Loss: 0.393 | Acc: 86.572% (43286/50000)\n",
      "Test Epoch: 19 | Loss: 0.485 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 19 | Loss: 0.484 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 19 | Loss: 0.467 | Acc: 85.333% (256/300)\n",
      "Test Epoch: 19 | Loss: 0.447 | Acc: 86.000% (344/400)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 86.000% (430/500)\n",
      "Test Epoch: 19 | Loss: 0.405 | Acc: 86.667% (520/600)\n",
      "Test Epoch: 19 | Loss: 0.410 | Acc: 86.714% (607/700)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 85.500% (684/800)\n",
      "Test Epoch: 19 | Loss: 0.451 | Acc: 85.333% (768/900)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.600% (856/1000)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 85.545% (941/1100)\n",
      "Test Epoch: 19 | Loss: 0.443 | Acc: 85.250% (1023/1200)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 85.615% (1113/1300)\n",
      "Test Epoch: 19 | Loss: 0.430 | Acc: 85.786% (1201/1400)\n",
      "Test Epoch: 19 | Loss: 0.422 | Acc: 85.800% (1287/1500)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.562% (1369/1600)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 85.765% (1458/1700)\n",
      "Test Epoch: 19 | Loss: 0.430 | Acc: 85.833% (1545/1800)\n",
      "Test Epoch: 19 | Loss: 0.429 | Acc: 85.895% (1632/1900)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.750% (1715/2000)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.619% (1798/2100)\n",
      "Test Epoch: 19 | Loss: 0.428 | Acc: 85.818% (1888/2200)\n",
      "Test Epoch: 19 | Loss: 0.429 | Acc: 85.652% (1970/2300)\n",
      "Test Epoch: 19 | Loss: 0.425 | Acc: 85.958% (2063/2400)\n",
      "Test Epoch: 19 | Loss: 0.427 | Acc: 85.920% (2148/2500)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.769% (2230/2600)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 85.815% (2317/2700)\n",
      "Test Epoch: 19 | Loss: 0.429 | Acc: 85.750% (2401/2800)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.724% (2486/2900)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 85.767% (2573/3000)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.677% (2656/3100)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.656% (2741/3200)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.606% (2825/3300)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.559% (2909/3400)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.343% (2987/3500)\n",
      "Test Epoch: 19 | Loss: 0.438 | Acc: 85.333% (3072/3600)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.243% (3154/3700)\n",
      "Test Epoch: 19 | Loss: 0.441 | Acc: 85.184% (3237/3800)\n",
      "Test Epoch: 19 | Loss: 0.438 | Acc: 85.231% (3324/3900)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.275% (3411/4000)\n",
      "Test Epoch: 19 | Loss: 0.440 | Acc: 85.244% (3495/4100)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.286% (3582/4200)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.372% (3671/4300)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.341% (3755/4400)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.422% (3844/4500)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.283% (3923/4600)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.340% (4011/4700)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.271% (4093/4800)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.347% (4182/4900)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.320% (4266/5000)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.275% (4349/5100)\n",
      "Test Epoch: 19 | Loss: 0.443 | Acc: 85.231% (4432/5200)\n",
      "Test Epoch: 19 | Loss: 0.444 | Acc: 85.208% (4516/5300)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.241% (4603/5400)\n",
      "Test Epoch: 19 | Loss: 0.443 | Acc: 85.145% (4683/5500)\n",
      "Test Epoch: 19 | Loss: 0.446 | Acc: 85.071% (4764/5600)\n",
      "Test Epoch: 19 | Loss: 0.445 | Acc: 85.175% (4855/5700)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.224% (4943/5800)\n",
      "Test Epoch: 19 | Loss: 0.444 | Acc: 85.153% (5024/5900)\n",
      "Test Epoch: 19 | Loss: 0.443 | Acc: 85.133% (5108/6000)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.230% (5199/6100)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.194% (5282/6200)\n",
      "Test Epoch: 19 | Loss: 0.441 | Acc: 85.238% (5370/6300)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.328% (5461/6400)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.277% (5543/6500)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.273% (5628/6600)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.269% (5713/6700)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.176% (5792/6800)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.203% (5879/6900)\n",
      "Test Epoch: 19 | Loss: 0.440 | Acc: 85.186% (5963/7000)\n",
      "Test Epoch: 19 | Loss: 0.442 | Acc: 85.169% (6047/7100)\n",
      "Test Epoch: 19 | Loss: 0.441 | Acc: 85.222% (6136/7200)\n",
      "Test Epoch: 19 | Loss: 0.441 | Acc: 85.274% (6225/7300)\n",
      "Test Epoch: 19 | Loss: 0.440 | Acc: 85.270% (6310/7400)\n",
      "Test Epoch: 19 | Loss: 0.440 | Acc: 85.307% (6398/7500)\n",
      "Test Epoch: 19 | Loss: 0.438 | Acc: 85.329% (6485/7600)\n",
      "Test Epoch: 19 | Loss: 0.440 | Acc: 85.273% (6566/7700)\n",
      "Test Epoch: 19 | Loss: 0.438 | Acc: 85.359% (6658/7800)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.367% (6744/7900)\n",
      "Test Epoch: 19 | Loss: 0.439 | Acc: 85.350% (6828/8000)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.420% (6919/8100)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.415% (7004/8200)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.434% (7091/8300)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.476% (7180/8400)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.494% (7267/8500)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.465% (7350/8600)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.506% (7439/8700)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.534% (7527/8800)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.528% (7612/8900)\n",
      "Test Epoch: 19 | Loss: 0.437 | Acc: 85.500% (7695/9000)\n",
      "Test Epoch: 19 | Loss: 0.436 | Acc: 85.516% (7782/9100)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.565% (7872/9200)\n",
      "Test Epoch: 19 | Loss: 0.435 | Acc: 85.570% (7958/9300)\n",
      "Test Epoch: 19 | Loss: 0.434 | Acc: 85.617% (8048/9400)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 85.653% (8137/9500)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 85.635% (8221/9600)\n",
      "Test Epoch: 19 | Loss: 0.431 | Acc: 85.680% (8311/9700)\n",
      "Test Epoch: 19 | Loss: 0.430 | Acc: 85.714% (8400/9800)\n",
      "Test Epoch: 19 | Loss: 0.433 | Acc: 85.636% (8478/9900)\n",
      "Test Epoch: 19 | Loss: 0.432 | Acc: 85.640% (8564/10000)\n",
      "\n",
      "Epoch: 20\n",
      "Train Epoch: 20 | Loss: 0.525 | Acc: 82.031% (105/128)\n",
      "Train Epoch: 20 | Loss: 0.464 | Acc: 84.375% (216/256)\n",
      "Train Epoch: 20 | Loss: 0.455 | Acc: 84.115% (323/384)\n",
      "Train Epoch: 20 | Loss: 0.457 | Acc: 83.984% (430/512)\n",
      "Train Epoch: 20 | Loss: 0.423 | Acc: 85.625% (548/640)\n",
      "Train Epoch: 20 | Loss: 0.407 | Acc: 86.328% (663/768)\n",
      "Train Epoch: 20 | Loss: 0.389 | Acc: 86.942% (779/896)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.012% (891/1024)\n",
      "Train Epoch: 20 | Loss: 0.389 | Acc: 86.892% (1001/1152)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.875% (1112/1280)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.003% (1225/1408)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 87.044% (1337/1536)\n",
      "Train Epoch: 20 | Loss: 0.380 | Acc: 87.200% (1451/1664)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.388% (1566/1792)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.396% (1678/1920)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.549% (1793/2048)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.546% (1905/2176)\n",
      "Train Epoch: 20 | Loss: 0.369 | Acc: 87.674% (2020/2304)\n",
      "Train Epoch: 20 | Loss: 0.361 | Acc: 88.035% (2141/2432)\n",
      "Train Epoch: 20 | Loss: 0.354 | Acc: 88.320% (2261/2560)\n",
      "Train Epoch: 20 | Loss: 0.365 | Acc: 87.909% (2363/2688)\n",
      "Train Epoch: 20 | Loss: 0.367 | Acc: 87.820% (2473/2816)\n",
      "Train Epoch: 20 | Loss: 0.364 | Acc: 87.874% (2587/2944)\n",
      "Train Epoch: 20 | Loss: 0.361 | Acc: 88.021% (2704/3072)\n",
      "Train Epoch: 20 | Loss: 0.359 | Acc: 88.031% (2817/3200)\n",
      "Train Epoch: 20 | Loss: 0.361 | Acc: 87.951% (2927/3328)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 88.079% (3044/3456)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 88.058% (3156/3584)\n",
      "Train Epoch: 20 | Loss: 0.354 | Acc: 88.039% (3268/3712)\n",
      "Train Epoch: 20 | Loss: 0.352 | Acc: 88.125% (3384/3840)\n",
      "Train Epoch: 20 | Loss: 0.352 | Acc: 88.206% (3500/3968)\n",
      "Train Epoch: 20 | Loss: 0.353 | Acc: 88.184% (3612/4096)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 88.068% (3720/4224)\n",
      "Train Epoch: 20 | Loss: 0.358 | Acc: 88.028% (3831/4352)\n",
      "Train Epoch: 20 | Loss: 0.356 | Acc: 88.103% (3947/4480)\n",
      "Train Epoch: 20 | Loss: 0.353 | Acc: 88.173% (4063/4608)\n",
      "Train Epoch: 20 | Loss: 0.352 | Acc: 88.133% (4174/4736)\n",
      "Train Epoch: 20 | Loss: 0.352 | Acc: 88.055% (4283/4864)\n",
      "Train Epoch: 20 | Loss: 0.354 | Acc: 87.961% (4391/4992)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 87.871% (4499/5120)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 87.900% (4613/5248)\n",
      "Train Epoch: 20 | Loss: 0.356 | Acc: 87.909% (4726/5376)\n",
      "Train Epoch: 20 | Loss: 0.358 | Acc: 87.900% (4838/5504)\n",
      "Train Epoch: 20 | Loss: 0.358 | Acc: 87.891% (4950/5632)\n",
      "Train Epoch: 20 | Loss: 0.358 | Acc: 87.865% (5061/5760)\n",
      "Train Epoch: 20 | Loss: 0.357 | Acc: 87.874% (5174/5888)\n",
      "Train Epoch: 20 | Loss: 0.358 | Acc: 87.816% (5283/6016)\n",
      "Train Epoch: 20 | Loss: 0.362 | Acc: 87.679% (5387/6144)\n",
      "Train Epoch: 20 | Loss: 0.360 | Acc: 87.803% (5507/6272)\n",
      "Train Epoch: 20 | Loss: 0.359 | Acc: 87.828% (5621/6400)\n",
      "Train Epoch: 20 | Loss: 0.359 | Acc: 87.868% (5736/6528)\n",
      "Train Epoch: 20 | Loss: 0.359 | Acc: 87.861% (5848/6656)\n",
      "Train Epoch: 20 | Loss: 0.360 | Acc: 87.824% (5958/6784)\n",
      "Train Epoch: 20 | Loss: 0.362 | Acc: 87.688% (6061/6912)\n",
      "Train Epoch: 20 | Loss: 0.362 | Acc: 87.656% (6171/7040)\n",
      "Train Epoch: 20 | Loss: 0.363 | Acc: 87.570% (6277/7168)\n",
      "Train Epoch: 20 | Loss: 0.363 | Acc: 87.541% (6387/7296)\n",
      "Train Epoch: 20 | Loss: 0.363 | Acc: 87.581% (6502/7424)\n",
      "Train Epoch: 20 | Loss: 0.363 | Acc: 87.593% (6615/7552)\n",
      "Train Epoch: 20 | Loss: 0.368 | Acc: 87.396% (6712/7680)\n",
      "Train Epoch: 20 | Loss: 0.368 | Acc: 87.449% (6828/7808)\n",
      "Train Epoch: 20 | Loss: 0.369 | Acc: 87.437% (6939/7936)\n",
      "Train Epoch: 20 | Loss: 0.368 | Acc: 87.500% (7056/8064)\n",
      "Train Epoch: 20 | Loss: 0.367 | Acc: 87.524% (7170/8192)\n",
      "Train Epoch: 20 | Loss: 0.368 | Acc: 87.488% (7279/8320)\n",
      "Train Epoch: 20 | Loss: 0.369 | Acc: 87.441% (7387/8448)\n",
      "Train Epoch: 20 | Loss: 0.369 | Acc: 87.418% (7497/8576)\n",
      "Train Epoch: 20 | Loss: 0.369 | Acc: 87.443% (7611/8704)\n",
      "Train Epoch: 20 | Loss: 0.370 | Acc: 87.398% (7719/8832)\n",
      "Train Epoch: 20 | Loss: 0.370 | Acc: 87.411% (7832/8960)\n",
      "Train Epoch: 20 | Loss: 0.371 | Acc: 87.401% (7943/9088)\n",
      "Train Epoch: 20 | Loss: 0.371 | Acc: 87.370% (8052/9216)\n",
      "Train Epoch: 20 | Loss: 0.370 | Acc: 87.414% (8168/9344)\n",
      "Train Epoch: 20 | Loss: 0.371 | Acc: 87.384% (8277/9472)\n",
      "Train Epoch: 20 | Loss: 0.370 | Acc: 87.375% (8388/9600)\n",
      "Train Epoch: 20 | Loss: 0.371 | Acc: 87.356% (8498/9728)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.287% (8603/9856)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.350% (8721/9984)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.371% (8835/10112)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.314% (8941/10240)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.297% (9051/10368)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.319% (9165/10496)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.312% (9276/10624)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.230% (9379/10752)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.224% (9490/10880)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.200% (9599/11008)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.240% (9715/11136)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.260% (9829/11264)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.272% (9942/11392)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.292% (10056/11520)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.311% (10170/11648)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.271% (10277/11776)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.282% (10390/11904)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.359% (10511/12032)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.360% (10623/12160)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.337% (10732/12288)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.347% (10845/12416)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.309% (10952/12544)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.318% (11065/12672)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.297% (11174/12800)\n",
      "Train Epoch: 20 | Loss: 0.371 | Acc: 87.338% (11291/12928)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.309% (11399/13056)\n",
      "Train Epoch: 20 | Loss: 0.372 | Acc: 87.280% (11507/13184)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.267% (11617/13312)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.188% (11718/13440)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.154% (11825/13568)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.135% (11934/13696)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.117% (12043/13824)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.070% (12148/13952)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.053% (12257/14080)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.071% (12371/14208)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.088% (12485/14336)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.113% (12600/14464)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.089% (12708/14592)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.113% (12823/14720)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.103% (12933/14848)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.126% (13048/14976)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.136% (13161/15104)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.139% (13273/15232)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.155% (13387/15360)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.184% (13503/15488)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.186% (13615/15616)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.182% (13726/15744)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.179% (13837/15872)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.188% (13950/16000)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.165% (14058/16128)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.149% (14167/16256)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.152% (14279/16384)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.155% (14391/16512)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.157% (14503/16640)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.172% (14617/16768)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.169% (14728/16896)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.189% (14843/17024)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.214% (14959/17152)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.222% (15072/17280)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.224% (15184/17408)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.215% (15294/17536)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.206% (15404/17664)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.219% (15518/17792)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.227% (15631/17920)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.217% (15741/18048)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.230% (15855/18176)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.276% (15975/18304)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.278% (16087/18432)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.279% (16199/18560)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.281% (16311/18688)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.298% (16426/18816)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.299% (16538/18944)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.306% (16651/19072)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.286% (16759/19200)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.314% (16876/19328)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.325% (16990/19456)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.337% (17104/19584)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.322% (17213/19712)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.334% (17327/19840)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.300% (17432/19968)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.281% (17540/20096)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.268% (17649/20224)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.259% (17759/20352)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.246% (17868/20480)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.257% (17982/20608)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.288% (18100/20736)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.270% (18208/20864)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.295% (18325/20992)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.273% (18432/21120)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.251% (18539/21248)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.257% (18652/21376)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.277% (18768/21504)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.292% (18883/21632)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.289% (18994/21760)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.272% (19102/21888)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.282% (19216/22016)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.265% (19324/22144)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.276% (19438/22272)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.272% (19549/22400)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.247% (19655/22528)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.240% (19765/22656)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.259% (19881/22784)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.264% (19994/22912)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.274% (20108/23040)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.284% (20222/23168)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.277% (20332/23296)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.274% (20443/23424)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.279% (20556/23552)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.285% (20669/23680)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.290% (20782/23808)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.279% (20891/23936)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.280% (21003/24064)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.285% (21116/24192)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.274% (21225/24320)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.283% (21339/24448)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.301% (21455/24576)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.310% (21569/24704)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.307% (21680/24832)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.308% (21792/24960)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.329% (21909/25088)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.306% (22015/25216)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.318% (22130/25344)\n",
      "Train Epoch: 20 | Loss: 0.373 | Acc: 87.319% (22242/25472)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.305% (22350/25600)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.290% (22458/25728)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.291% (22570/25856)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.296% (22683/25984)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.286% (22792/26112)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.283% (22903/26240)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.299% (23019/26368)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.277% (23125/26496)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.245% (23228/26624)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.220% (23333/26752)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.243% (23451/26880)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.252% (23565/27008)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.268% (23681/27136)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.265% (23792/27264)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.263% (23903/27392)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.253% (24012/27520)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.250% (24123/27648)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.252% (24235/27776)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.260% (24349/27904)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.254% (24459/28032)\n",
      "Train Epoch: 20 | Loss: 0.374 | Acc: 87.262% (24573/28160)\n",
      "Train Epoch: 20 | Loss: 0.375 | Acc: 87.245% (24680/28288)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.211% (24782/28416)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.216% (24895/28544)\n",
      "Train Epoch: 20 | Loss: 0.376 | Acc: 87.217% (25007/28672)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.201% (25114/28800)\n",
      "Train Epoch: 20 | Loss: 0.377 | Acc: 87.172% (25217/28928)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.146% (25321/29056)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.157% (25436/29184)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.138% (25542/29312)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.154% (25658/29440)\n",
      "Train Epoch: 20 | Loss: 0.378 | Acc: 87.148% (25768/29568)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.106% (25867/29696)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.098% (25976/29824)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.106% (26090/29952)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.091% (26197/30080)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.090% (26308/30208)\n",
      "Train Epoch: 20 | Loss: 0.379 | Acc: 87.088% (26419/30336)\n",
      "Train Epoch: 20 | Loss: 0.380 | Acc: 87.067% (26524/30464)\n",
      "Train Epoch: 20 | Loss: 0.380 | Acc: 87.069% (26636/30592)\n",
      "Train Epoch: 20 | Loss: 0.380 | Acc: 87.067% (26747/30720)\n",
      "Train Epoch: 20 | Loss: 0.380 | Acc: 87.056% (26855/30848)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.035% (26960/30976)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.021% (27067/31104)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.033% (27182/31232)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.050% (27299/31360)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.052% (27411/31488)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.041% (27519/31616)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.046% (27632/31744)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.033% (27739/31872)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.044% (27854/32000)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.042% (27965/32128)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.023% (28070/32256)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.021% (28181/32384)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.005% (28287/32512)\n",
      "Train Epoch: 20 | Loss: 0.381 | Acc: 87.019% (28403/32640)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.006% (28510/32768)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.011% (28623/32896)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 86.994% (28729/33024)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.002% (28843/33152)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.010% (28957/33280)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 87.015% (29070/33408)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 86.984% (29171/33536)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.974% (29279/33664)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.944% (29380/33792)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.949% (29493/33920)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.936% (29600/34048)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.941% (29713/34176)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.943% (29825/34304)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.919% (29928/34432)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.924% (30041/34560)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.921% (30151/34688)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.926% (30264/34816)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.931% (30377/34944)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.933% (30489/35072)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.949% (30606/35200)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 86.957% (30720/35328)\n",
      "Train Epoch: 20 | Loss: 0.382 | Acc: 86.970% (30836/35456)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.938% (30936/35584)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.937% (31047/35712)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.934% (31157/35840)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.913% (31261/35968)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.902% (31368/36096)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.890% (31475/36224)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.892% (31587/36352)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.894% (31699/36480)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.902% (31813/36608)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.888% (31919/36736)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.900% (32035/36864)\n",
      "Train Epoch: 20 | Loss: 0.383 | Acc: 86.908% (32149/36992)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.883% (32251/37120)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.877% (32360/37248)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.866% (32467/37376)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.884% (32585/37504)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.876% (32693/37632)\n",
      "Train Epoch: 20 | Loss: 0.384 | Acc: 86.867% (32801/37760)\n",
      "Train Epoch: 20 | Loss: 0.385 | Acc: 86.861% (32910/37888)\n",
      "Train Epoch: 20 | Loss: 0.385 | Acc: 86.866% (33023/38016)\n",
      "Train Epoch: 20 | Loss: 0.385 | Acc: 86.842% (33125/38144)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.828% (33231/38272)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.833% (33344/38400)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.828% (33453/38528)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.809% (33557/38656)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.796% (33663/38784)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.814% (33781/38912)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.819% (33894/39040)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.800% (33998/39168)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.808% (34112/39296)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.813% (34225/39424)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.815% (34337/39552)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.799% (34442/39680)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.802% (34554/39808)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.804% (34666/39936)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.804% (34777/40064)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.788% (34882/40192)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.786% (34992/40320)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.790% (35105/40448)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.800% (35220/40576)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.805% (35333/40704)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.795% (35440/40832)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.804% (35555/40960)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.811% (35669/41088)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.809% (35779/41216)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.791% (35883/41344)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.786% (35992/41472)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.779% (36100/41600)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.771% (36208/41728)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.750% (36310/41856)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.747% (36420/41984)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.754% (36534/42112)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.768% (36651/42240)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.785% (36769/42368)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.775% (36876/42496)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.773% (36986/42624)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.768% (37095/42752)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.765% (37205/42880)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.772% (37319/43008)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.760% (37425/43136)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.749% (37531/43264)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.767% (37650/43392)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.767% (37761/43520)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.783% (37879/43648)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.780% (37989/43776)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.780% (38100/43904)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.776% (38209/44032)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.775% (38320/44160)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.782% (38434/44288)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.791% (38549/44416)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.797% (38663/44544)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.804% (38777/44672)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.795% (38884/44800)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.803% (38999/44928)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.808% (39112/45056)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.816% (39227/45184)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.811% (39336/45312)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.822% (39452/45440)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.818% (39561/45568)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.828% (39677/45696)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.839% (39793/45824)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.838% (39904/45952)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.821% (40007/46080)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.816% (40116/46208)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.809% (40224/46336)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.811% (40336/46464)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.811% (40447/46592)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.821% (40563/46720)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.823% (40675/46848)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.823% (40786/46976)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.827% (40899/47104)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.820% (41007/47232)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.818% (41117/47360)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.826% (41232/47488)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.822% (41341/47616)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.811% (41447/47744)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.815% (41560/47872)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.815% (41671/48000)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.810% (41780/48128)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.810% (41891/48256)\n",
      "Train Epoch: 20 | Loss: 0.388 | Acc: 86.816% (42005/48384)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.830% (42123/48512)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.819% (42229/48640)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.815% (42338/48768)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.821% (42452/48896)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.831% (42568/49024)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.827% (42677/49152)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.832% (42791/49280)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.828% (42900/49408)\n",
      "Train Epoch: 20 | Loss: 0.387 | Acc: 86.836% (43015/49536)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.848% (43132/49664)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.863% (43251/49792)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.857% (43359/49920)\n",
      "Train Epoch: 20 | Loss: 0.386 | Acc: 86.864% (43432/50000)\n",
      "Test Epoch: 20 | Loss: 0.554 | Acc: 77.000% (77/100)\n",
      "Test Epoch: 20 | Loss: 0.526 | Acc: 81.000% (162/200)\n",
      "Test Epoch: 20 | Loss: 0.485 | Acc: 82.333% (247/300)\n",
      "Test Epoch: 20 | Loss: 0.477 | Acc: 83.250% (333/400)\n",
      "Test Epoch: 20 | Loss: 0.450 | Acc: 84.200% (421/500)\n",
      "Test Epoch: 20 | Loss: 0.422 | Acc: 85.000% (510/600)\n",
      "Test Epoch: 20 | Loss: 0.416 | Acc: 85.571% (599/700)\n",
      "Test Epoch: 20 | Loss: 0.447 | Acc: 84.750% (678/800)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.444% (760/900)\n",
      "Test Epoch: 20 | Loss: 0.465 | Acc: 84.200% (842/1000)\n",
      "Test Epoch: 20 | Loss: 0.469 | Acc: 84.091% (925/1100)\n",
      "Test Epoch: 20 | Loss: 0.473 | Acc: 84.333% (1012/1200)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.385% (1097/1300)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 84.429% (1182/1400)\n",
      "Test Epoch: 20 | Loss: 0.456 | Acc: 84.533% (1268/1500)\n",
      "Test Epoch: 20 | Loss: 0.453 | Acc: 84.438% (1351/1600)\n",
      "Test Epoch: 20 | Loss: 0.449 | Acc: 84.882% (1443/1700)\n",
      "Test Epoch: 20 | Loss: 0.449 | Acc: 84.833% (1527/1800)\n",
      "Test Epoch: 20 | Loss: 0.447 | Acc: 85.053% (1616/1900)\n",
      "Test Epoch: 20 | Loss: 0.447 | Acc: 85.100% (1702/2000)\n",
      "Test Epoch: 20 | Loss: 0.454 | Acc: 84.952% (1784/2100)\n",
      "Test Epoch: 20 | Loss: 0.454 | Acc: 84.864% (1867/2200)\n",
      "Test Epoch: 20 | Loss: 0.457 | Acc: 84.739% (1949/2300)\n",
      "Test Epoch: 20 | Loss: 0.461 | Acc: 84.542% (2029/2400)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.440% (2111/2500)\n",
      "Test Epoch: 20 | Loss: 0.472 | Acc: 84.346% (2193/2600)\n",
      "Test Epoch: 20 | Loss: 0.471 | Acc: 84.481% (2281/2700)\n",
      "Test Epoch: 20 | Loss: 0.477 | Acc: 84.500% (2366/2800)\n",
      "Test Epoch: 20 | Loss: 0.475 | Acc: 84.621% (2454/2900)\n",
      "Test Epoch: 20 | Loss: 0.471 | Acc: 84.767% (2543/3000)\n",
      "Test Epoch: 20 | Loss: 0.471 | Acc: 84.710% (2626/3100)\n",
      "Test Epoch: 20 | Loss: 0.469 | Acc: 84.812% (2714/3200)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 85.000% (2805/3300)\n",
      "Test Epoch: 20 | Loss: 0.461 | Acc: 85.059% (2892/3400)\n",
      "Test Epoch: 20 | Loss: 0.462 | Acc: 85.029% (2976/3500)\n",
      "Test Epoch: 20 | Loss: 0.463 | Acc: 85.056% (3062/3600)\n",
      "Test Epoch: 20 | Loss: 0.465 | Acc: 85.000% (3145/3700)\n",
      "Test Epoch: 20 | Loss: 0.467 | Acc: 84.921% (3227/3800)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 85.026% (3316/3900)\n",
      "Test Epoch: 20 | Loss: 0.465 | Acc: 85.025% (3401/4000)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 85.049% (3487/4100)\n",
      "Test Epoch: 20 | Loss: 0.463 | Acc: 84.976% (3569/4200)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 85.093% (3659/4300)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 85.159% (3747/4400)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 85.200% (3834/4500)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 85.196% (3919/4600)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 85.149% (4002/4700)\n",
      "Test Epoch: 20 | Loss: 0.462 | Acc: 85.000% (4080/4800)\n",
      "Test Epoch: 20 | Loss: 0.461 | Acc: 84.959% (4163/4900)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.880% (4244/5000)\n",
      "Test Epoch: 20 | Loss: 0.462 | Acc: 84.922% (4331/5100)\n",
      "Test Epoch: 20 | Loss: 0.464 | Acc: 84.846% (4412/5200)\n",
      "Test Epoch: 20 | Loss: 0.465 | Acc: 84.792% (4494/5300)\n",
      "Test Epoch: 20 | Loss: 0.466 | Acc: 84.778% (4578/5400)\n",
      "Test Epoch: 20 | Loss: 0.467 | Acc: 84.636% (4655/5500)\n",
      "Test Epoch: 20 | Loss: 0.469 | Acc: 84.679% (4742/5600)\n",
      "Test Epoch: 20 | Loss: 0.470 | Acc: 84.667% (4826/5700)\n",
      "Test Epoch: 20 | Loss: 0.470 | Acc: 84.690% (4912/5800)\n",
      "Test Epoch: 20 | Loss: 0.472 | Acc: 84.610% (4992/5900)\n",
      "Test Epoch: 20 | Loss: 0.470 | Acc: 84.683% (5081/6000)\n",
      "Test Epoch: 20 | Loss: 0.468 | Acc: 84.754% (5170/6100)\n",
      "Test Epoch: 20 | Loss: 0.467 | Acc: 84.774% (5256/6200)\n",
      "Test Epoch: 20 | Loss: 0.463 | Acc: 84.825% (5344/6300)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.906% (5434/6400)\n",
      "Test Epoch: 20 | Loss: 0.461 | Acc: 84.892% (5518/6500)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.894% (5603/6600)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 84.970% (5693/6700)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.926% (5775/6800)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.899% (5858/6900)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.886% (5942/7000)\n",
      "Test Epoch: 20 | Loss: 0.461 | Acc: 84.845% (6024/7100)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.875% (6111/7200)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.932% (6200/7300)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 84.959% (6287/7400)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 85.013% (6376/7500)\n",
      "Test Epoch: 20 | Loss: 0.457 | Acc: 85.013% (6461/7600)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.948% (6541/7700)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 85.013% (6631/7800)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 85.013% (6716/7900)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.963% (6797/8000)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 85.000% (6885/8100)\n",
      "Test Epoch: 20 | Loss: 0.456 | Acc: 85.024% (6972/8200)\n",
      "Test Epoch: 20 | Loss: 0.455 | Acc: 85.012% (7056/8300)\n",
      "Test Epoch: 20 | Loss: 0.453 | Acc: 85.107% (7149/8400)\n",
      "Test Epoch: 20 | Loss: 0.454 | Acc: 85.047% (7229/8500)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.988% (7309/8600)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 85.046% (7399/8700)\n",
      "Test Epoch: 20 | Loss: 0.457 | Acc: 85.045% (7484/8800)\n",
      "Test Epoch: 20 | Loss: 0.457 | Acc: 85.022% (7567/8900)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.989% (7649/9000)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.967% (7732/9100)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 85.011% (7821/9200)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.925% (7898/9300)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.915% (7982/9400)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.863% (8062/9500)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.875% (8148/9600)\n",
      "Test Epoch: 20 | Loss: 0.458 | Acc: 84.907% (8236/9700)\n",
      "Test Epoch: 20 | Loss: 0.459 | Acc: 84.888% (8319/9800)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.818% (8397/9900)\n",
      "Test Epoch: 20 | Loss: 0.460 | Acc: 84.840% (8484/10000)\n",
      "\n",
      "Epoch: 21\n",
      "Train Epoch: 21 | Loss: 0.454 | Acc: 81.250% (104/128)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 84.766% (217/256)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 85.938% (330/384)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 86.523% (443/512)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.031% (557/640)\n",
      "Train Epoch: 21 | Loss: 0.375 | Acc: 87.109% (669/768)\n",
      "Train Epoch: 21 | Loss: 0.391 | Acc: 87.054% (780/896)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 87.012% (891/1024)\n",
      "Train Epoch: 21 | Loss: 0.384 | Acc: 86.285% (994/1152)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 86.797% (1111/1280)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.287% (1229/1408)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.305% (1341/1536)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.740% (1460/1664)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.723% (1572/1792)\n",
      "Train Epoch: 21 | Loss: 0.351 | Acc: 87.865% (1687/1920)\n",
      "Train Epoch: 21 | Loss: 0.347 | Acc: 87.939% (1801/2048)\n",
      "Train Epoch: 21 | Loss: 0.345 | Acc: 88.097% (1917/2176)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.717% (2021/2304)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.706% (2133/2432)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.695% (2245/2560)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.872% (2362/2688)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.820% (2473/2816)\n",
      "Train Epoch: 21 | Loss: 0.352 | Acc: 87.806% (2585/2944)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.565% (2690/3072)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.500% (2800/3200)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.380% (2908/3328)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.355% (3019/3456)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.500% (3136/3584)\n",
      "Train Epoch: 21 | Loss: 0.349 | Acc: 87.689% (3255/3712)\n",
      "Train Epoch: 21 | Loss: 0.350 | Acc: 87.656% (3366/3840)\n",
      "Train Epoch: 21 | Loss: 0.352 | Acc: 87.576% (3475/3968)\n",
      "Train Epoch: 21 | Loss: 0.354 | Acc: 87.500% (3584/4096)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.524% (3697/4224)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.592% (3812/4352)\n",
      "Train Epoch: 21 | Loss: 0.351 | Acc: 87.634% (3926/4480)\n",
      "Train Epoch: 21 | Loss: 0.349 | Acc: 87.695% (4041/4608)\n",
      "Train Epoch: 21 | Loss: 0.346 | Acc: 87.774% (4157/4736)\n",
      "Train Epoch: 21 | Loss: 0.345 | Acc: 87.808% (4271/4864)\n",
      "Train Epoch: 21 | Loss: 0.348 | Acc: 87.700% (4378/4992)\n",
      "Train Epoch: 21 | Loss: 0.348 | Acc: 87.715% (4491/5120)\n",
      "Train Epoch: 21 | Loss: 0.347 | Acc: 87.824% (4609/5248)\n",
      "Train Epoch: 21 | Loss: 0.347 | Acc: 87.779% (4719/5376)\n",
      "Train Epoch: 21 | Loss: 0.346 | Acc: 87.845% (4835/5504)\n",
      "Train Epoch: 21 | Loss: 0.347 | Acc: 87.749% (4942/5632)\n",
      "Train Epoch: 21 | Loss: 0.346 | Acc: 87.795% (5057/5760)\n",
      "Train Epoch: 21 | Loss: 0.347 | Acc: 87.755% (5167/5888)\n",
      "Train Epoch: 21 | Loss: 0.348 | Acc: 87.733% (5278/6016)\n",
      "Train Epoch: 21 | Loss: 0.350 | Acc: 87.630% (5384/6144)\n",
      "Train Epoch: 21 | Loss: 0.352 | Acc: 87.612% (5495/6272)\n",
      "Train Epoch: 21 | Loss: 0.350 | Acc: 87.688% (5612/6400)\n",
      "Train Epoch: 21 | Loss: 0.351 | Acc: 87.638% (5721/6528)\n",
      "Train Epoch: 21 | Loss: 0.352 | Acc: 87.605% (5831/6656)\n",
      "Train Epoch: 21 | Loss: 0.350 | Acc: 87.618% (5944/6784)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.529% (6050/6912)\n",
      "Train Epoch: 21 | Loss: 0.354 | Acc: 87.514% (6161/7040)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.430% (6267/7168)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.418% (6378/7296)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.406% (6489/7424)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.487% (6607/7552)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.539% (6723/7680)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.474% (6830/7808)\n",
      "Train Epoch: 21 | Loss: 0.354 | Acc: 87.513% (6945/7936)\n",
      "Train Epoch: 21 | Loss: 0.353 | Acc: 87.562% (7061/8064)\n",
      "Train Epoch: 21 | Loss: 0.355 | Acc: 87.476% (7166/8192)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.452% (7276/8320)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.464% (7389/8448)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.465% (7501/8576)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.466% (7613/8704)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.455% (7724/8832)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.478% (7838/8960)\n",
      "Train Epoch: 21 | Loss: 0.358 | Acc: 87.445% (7947/9088)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.435% (8058/9216)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.457% (8172/9344)\n",
      "Train Epoch: 21 | Loss: 0.358 | Acc: 87.479% (8286/9472)\n",
      "Train Epoch: 21 | Loss: 0.358 | Acc: 87.490% (8399/9600)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.521% (8514/9728)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.571% (8631/9856)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.570% (8743/9984)\n",
      "Train Epoch: 21 | Loss: 0.356 | Acc: 87.619% (8860/10112)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.578% (8968/10240)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.606% (9083/10368)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.605% (9195/10496)\n",
      "Train Epoch: 21 | Loss: 0.357 | Acc: 87.594% (9306/10624)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.574% (9416/10752)\n",
      "Train Epoch: 21 | Loss: 0.358 | Acc: 87.601% (9531/10880)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.618% (9645/11008)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.572% (9752/11136)\n",
      "Train Epoch: 21 | Loss: 0.360 | Acc: 87.527% (9859/11264)\n",
      "Train Epoch: 21 | Loss: 0.360 | Acc: 87.526% (9971/11392)\n",
      "Train Epoch: 21 | Loss: 0.360 | Acc: 87.500% (10080/11520)\n",
      "Train Epoch: 21 | Loss: 0.360 | Acc: 87.509% (10193/11648)\n",
      "Train Epoch: 21 | Loss: 0.359 | Acc: 87.534% (10308/11776)\n",
      "Train Epoch: 21 | Loss: 0.360 | Acc: 87.500% (10416/11904)\n",
      "Train Epoch: 21 | Loss: 0.361 | Acc: 87.450% (10522/12032)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.426% (10631/12160)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.435% (10744/12288)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.371% (10848/12416)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.428% (10967/12544)\n",
      "Train Epoch: 21 | Loss: 0.362 | Acc: 87.437% (11080/12672)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.406% (11188/12800)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.338% (11291/12928)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.377% (11408/13056)\n",
      "Train Epoch: 21 | Loss: 0.363 | Acc: 87.409% (11524/13184)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.387% (11633/13312)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.374% (11743/13440)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.389% (11857/13568)\n",
      "Train Epoch: 21 | Loss: 0.364 | Acc: 87.427% (11974/13696)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.391% (12081/13824)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.335% (12185/13952)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.337% (12297/14080)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.310% (12405/14208)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.319% (12518/14336)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.341% (12633/14464)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.370% (12749/14592)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.337% (12856/14720)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.325% (12966/14848)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.333% (13079/14976)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.354% (13194/15104)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.356% (13306/15232)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.331% (13414/15360)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.313% (13523/15488)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.353% (13641/15616)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.348% (13752/15744)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.368% (13867/15872)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.344% (13975/16000)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.364% (14090/16128)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.340% (14198/16256)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.347% (14311/16384)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.324% (14419/16512)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.326% (14531/16640)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.297% (14638/16768)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.299% (14750/16896)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.294% (14861/17024)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.296% (14973/17152)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.303% (15086/17280)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.322% (15201/17408)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.295% (15308/17536)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.313% (15423/17664)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.309% (15534/17792)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.333% (15650/17920)\n",
      "Train Epoch: 21 | Loss: 0.365 | Acc: 87.334% (15762/18048)\n",
      "Train Epoch: 21 | Loss: 0.366 | Acc: 87.318% (15871/18176)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.314% (15982/18304)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.294% (16090/18432)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.301% (16203/18560)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.286% (16312/18688)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.298% (16426/18816)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.305% (16539/18944)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.316% (16653/19072)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.318% (16765/19200)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.309% (16875/19328)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.305% (16986/19456)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.265% (17090/19584)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.287% (17206/19712)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.293% (17319/19840)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.290% (17430/19968)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.311% (17546/20096)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.282% (17652/20224)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.279% (17763/20352)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.261% (17871/20480)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.238% (17978/20608)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.240% (18090/20736)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.203% (18194/20864)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.209% (18307/20992)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.221% (18421/21120)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.246% (18538/21248)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.243% (18649/21376)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.263% (18765/21504)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.264% (18877/21632)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.256% (18987/21760)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.230% (19093/21888)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.214% (19201/22016)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.202% (19310/22144)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.204% (19422/22272)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.210% (19535/22400)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.229% (19651/22528)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.222% (19761/22656)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.219% (19872/22784)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.208% (19981/22912)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.192% (20089/23040)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.185% (20199/23168)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.187% (20311/23296)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.188% (20423/23424)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.216% (20541/23552)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.234% (20657/23680)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.265% (20776/23808)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.262% (20887/23936)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.271% (21001/24064)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.277% (21114/24192)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.270% (21224/24320)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.246% (21330/24448)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.268% (21447/24576)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.273% (21560/24704)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.274% (21672/24832)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.272% (21783/24960)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.281% (21897/25088)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.266% (22005/25216)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.271% (22118/25344)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.268% (22229/25472)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.273% (22342/25600)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.282% (22456/25728)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.280% (22567/25856)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.284% (22680/25984)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.293% (22794/26112)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.290% (22905/26240)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.272% (23012/26368)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.251% (23118/26496)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.241% (23227/26624)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.250% (23341/26752)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.236% (23449/26880)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.237% (23561/27008)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.224% (23669/27136)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.232% (23783/27264)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.230% (23894/27392)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.249% (24011/27520)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.250% (24123/27648)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.252% (24235/27776)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.242% (24344/27904)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.232% (24453/28032)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.227% (24563/28160)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.214% (24671/28288)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.204% (24780/28416)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.216% (24895/28544)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.228% (25010/28672)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.229% (25122/28800)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.227% (25233/28928)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.228% (25345/29056)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.226% (25456/29184)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.210% (25563/29312)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.201% (25672/29440)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.223% (25790/29568)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.254% (25911/29696)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.262% (26025/29824)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.270% (26139/29952)\n",
      "Train Epoch: 21 | Loss: 0.367 | Acc: 87.257% (26247/30080)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.219% (26347/30208)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.217% (26458/30336)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.218% (26570/30464)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.242% (26689/30592)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.249% (26803/30720)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.247% (26914/30848)\n",
      "Train Epoch: 21 | Loss: 0.368 | Acc: 87.251% (27027/30976)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.246% (27137/31104)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.228% (27243/31232)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.242% (27359/31360)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.243% (27471/31488)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.237% (27581/31616)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.235% (27692/31744)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.224% (27800/31872)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.219% (27910/32000)\n",
      "Train Epoch: 21 | Loss: 0.369 | Acc: 87.214% (28020/32128)\n",
      "Train Epoch: 21 | Loss: 0.370 | Acc: 87.199% (28127/32256)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.170% (28229/32384)\n",
      "Train Epoch: 21 | Loss: 0.371 | Acc: 87.162% (28338/32512)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.151% (28446/32640)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.158% (28560/32768)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.147% (28668/32896)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.143% (28778/33024)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.141% (28889/33152)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.136% (28999/33280)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.150% (29115/33408)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.142% (29224/33536)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.132% (29332/33664)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.136% (29445/33792)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.134% (29556/33920)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.139% (29669/34048)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.143% (29782/34176)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.147% (29895/34304)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.122% (29998/34432)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.130% (30112/34560)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.143% (30228/34688)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.118% (30331/34816)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.111% (30440/34944)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.095% (30546/35072)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.091% (30656/35200)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.104% (30772/35328)\n",
      "Train Epoch: 21 | Loss: 0.372 | Acc: 87.102% (30883/35456)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.087% (30989/35584)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.080% (31098/35712)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.084% (31211/35840)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.080% (31321/35968)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.071% (31429/36096)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.083% (31545/36224)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.065% (31650/36352)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.067% (31762/36480)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.066% (31873/36608)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.062% (31983/36736)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.050% (32090/36864)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.070% (32209/36992)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.077% (32323/37120)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.081% (32436/37248)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.080% (32547/37376)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.079% (32658/37504)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.062% (32763/37632)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.063% (32875/37760)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.059% (32985/37888)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.074% (33102/38016)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.070% (33212/38144)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.061% (33320/38272)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.044% (33425/38400)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.046% (33537/38528)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.045% (33648/38656)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.059% (33765/38784)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.058% (33876/38912)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.062% (33989/39040)\n",
      "Train Epoch: 21 | Loss: 0.373 | Acc: 87.058% (34099/39168)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.042% (34204/39296)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.038% (34314/39424)\n",
      "Train Epoch: 21 | Loss: 0.374 | Acc: 87.040% (34426/39552)\n",
      "Train Epoch: 21 | Loss: 0.375 | Acc: 87.026% (34532/39680)\n",
      "Train Epoch: 21 | Loss: 0.375 | Acc: 87.005% (34635/39808)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 87.009% (34748/39936)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 87.001% (34856/40064)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 87.002% (34968/40192)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.999% (35078/40320)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.993% (35187/40448)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.968% (35288/40576)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.977% (35403/40704)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.973% (35513/40832)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.982% (35628/40960)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.996% (35745/41088)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.990% (35854/41216)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.980% (35961/41344)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.979% (36072/41472)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.981% (36184/41600)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.980% (36295/41728)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.960% (36398/41856)\n",
      "Train Epoch: 21 | Loss: 0.376 | Acc: 86.971% (36514/41984)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.959% (36620/42112)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.948% (36727/42240)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.936% (36833/42368)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.945% (36948/42496)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.939% (37057/42624)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.920% (37160/42752)\n",
      "Train Epoch: 21 | Loss: 0.377 | Acc: 86.929% (37275/42880)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.905% (37376/43008)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.897% (37484/43136)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.906% (37599/43264)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.908% (37711/43392)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.919% (37827/43520)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.932% (37944/43648)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.931% (38055/43776)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.926% (38164/43904)\n",
      "Train Epoch: 21 | Loss: 0.378 | Acc: 86.916% (38271/44032)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.916% (38382/44160)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.899% (38486/44288)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.906% (38600/44416)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.912% (38714/44544)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.909% (38824/44672)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.920% (38940/44800)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.917% (39050/44928)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.921% (39163/45056)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.920% (39274/45184)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.928% (39389/45312)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.919% (39496/45440)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.929% (39612/45568)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.924% (39721/45696)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.926% (39833/45824)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.921% (39942/45952)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.927% (40056/46080)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.911% (40160/46208)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.926% (40278/46336)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.915% (40384/46464)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.918% (40497/46592)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.918% (40608/46720)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.924% (40722/46848)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.917% (40830/46976)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.908% (40937/47104)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.909% (41049/47232)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.911% (41161/47360)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.910% (41272/47488)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.904% (41380/47616)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.901% (41490/47744)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.896% (41599/47872)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.894% (41709/48000)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.900% (41823/48128)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.899% (41934/48256)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.907% (42049/48384)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.908% (42161/48512)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.916% (42276/48640)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.901% (42380/48768)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.901% (42491/48896)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.908% (42606/49024)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.910% (42718/49152)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.916% (42832/49280)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.919% (42945/49408)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.927% (43060/49536)\n",
      "Train Epoch: 21 | Loss: 0.379 | Acc: 86.928% (43172/49664)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.916% (43277/49792)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.921% (43391/49920)\n",
      "Train Epoch: 21 | Loss: 0.380 | Acc: 86.914% (43457/50000)\n",
      "Test Epoch: 21 | Loss: 0.492 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 21 | Loss: 0.462 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 21 | Loss: 0.401 | Acc: 86.667% (260/300)\n",
      "Test Epoch: 21 | Loss: 0.397 | Acc: 85.750% (343/400)\n",
      "Test Epoch: 21 | Loss: 0.383 | Acc: 86.600% (433/500)\n",
      "Test Epoch: 21 | Loss: 0.360 | Acc: 87.000% (522/600)\n",
      "Test Epoch: 21 | Loss: 0.367 | Acc: 86.857% (608/700)\n",
      "Test Epoch: 21 | Loss: 0.402 | Acc: 85.625% (685/800)\n",
      "Test Epoch: 21 | Loss: 0.407 | Acc: 85.556% (770/900)\n",
      "Test Epoch: 21 | Loss: 0.413 | Acc: 85.700% (857/1000)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 85.545% (941/1100)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 85.667% (1028/1200)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 85.538% (1112/1300)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 85.571% (1198/1400)\n",
      "Test Epoch: 21 | Loss: 0.410 | Acc: 85.533% (1283/1500)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 85.312% (1365/1600)\n",
      "Test Epoch: 21 | Loss: 0.417 | Acc: 85.412% (1452/1700)\n",
      "Test Epoch: 21 | Loss: 0.423 | Acc: 85.389% (1537/1800)\n",
      "Test Epoch: 21 | Loss: 0.425 | Acc: 85.211% (1619/1900)\n",
      "Test Epoch: 21 | Loss: 0.426 | Acc: 85.300% (1706/2000)\n",
      "Test Epoch: 21 | Loss: 0.423 | Acc: 85.381% (1793/2100)\n",
      "Test Epoch: 21 | Loss: 0.419 | Acc: 85.500% (1881/2200)\n",
      "Test Epoch: 21 | Loss: 0.418 | Acc: 85.609% (1969/2300)\n",
      "Test Epoch: 21 | Loss: 0.416 | Acc: 85.500% (2052/2400)\n",
      "Test Epoch: 21 | Loss: 0.423 | Acc: 85.280% (2132/2500)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.846% (2206/2600)\n",
      "Test Epoch: 21 | Loss: 0.432 | Acc: 84.963% (2294/2700)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.000% (2380/2800)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 85.000% (2465/2900)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.967% (2549/3000)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.903% (2632/3100)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.875% (2716/3200)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.818% (2799/3300)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.735% (2881/3400)\n",
      "Test Epoch: 21 | Loss: 0.439 | Acc: 84.686% (2964/3500)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.722% (3050/3600)\n",
      "Test Epoch: 21 | Loss: 0.439 | Acc: 84.649% (3132/3700)\n",
      "Test Epoch: 21 | Loss: 0.439 | Acc: 84.658% (3217/3800)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.667% (3302/3900)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.825% (3393/4000)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.854% (3479/4100)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.857% (3564/4200)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.000% (3655/4300)\n",
      "Test Epoch: 21 | Loss: 0.431 | Acc: 85.136% (3746/4400)\n",
      "Test Epoch: 21 | Loss: 0.430 | Acc: 85.200% (3834/4500)\n",
      "Test Epoch: 21 | Loss: 0.430 | Acc: 85.239% (3921/4600)\n",
      "Test Epoch: 21 | Loss: 0.428 | Acc: 85.234% (4006/4700)\n",
      "Test Epoch: 21 | Loss: 0.431 | Acc: 85.083% (4084/4800)\n",
      "Test Epoch: 21 | Loss: 0.429 | Acc: 85.143% (4172/4900)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.980% (4249/5000)\n",
      "Test Epoch: 21 | Loss: 0.431 | Acc: 85.059% (4338/5100)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 84.923% (4416/5200)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 84.830% (4496/5300)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 84.889% (4584/5400)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.855% (4667/5500)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.786% (4748/5600)\n",
      "Test Epoch: 21 | Loss: 0.440 | Acc: 84.684% (4827/5700)\n",
      "Test Epoch: 21 | Loss: 0.439 | Acc: 84.724% (4914/5800)\n",
      "Test Epoch: 21 | Loss: 0.442 | Acc: 84.746% (5000/5900)\n",
      "Test Epoch: 21 | Loss: 0.443 | Acc: 84.700% (5082/6000)\n",
      "Test Epoch: 21 | Loss: 0.444 | Acc: 84.689% (5166/6100)\n",
      "Test Epoch: 21 | Loss: 0.444 | Acc: 84.726% (5253/6200)\n",
      "Test Epoch: 21 | Loss: 0.443 | Acc: 84.746% (5339/6300)\n",
      "Test Epoch: 21 | Loss: 0.441 | Acc: 84.828% (5429/6400)\n",
      "Test Epoch: 21 | Loss: 0.440 | Acc: 84.862% (5516/6500)\n",
      "Test Epoch: 21 | Loss: 0.439 | Acc: 84.833% (5599/6600)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.881% (5687/6700)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.868% (5771/6800)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.928% (5860/6900)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.857% (5940/7000)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.901% (6028/7100)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.847% (6109/7200)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.932% (6200/7300)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 84.973% (6288/7400)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.973% (6373/7500)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.934% (6455/7600)\n",
      "Test Epoch: 21 | Loss: 0.438 | Acc: 84.909% (6538/7700)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.962% (6627/7800)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 85.025% (6717/7900)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 85.013% (6801/8000)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 85.074% (6891/8100)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 85.012% (6971/8200)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.988% (7054/8300)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 85.000% (7140/8400)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.976% (7223/8500)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.930% (7304/8600)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.931% (7389/8700)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.909% (7472/8800)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.933% (7559/8900)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.911% (7642/9000)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.879% (7724/9100)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 84.967% (7817/9200)\n",
      "Test Epoch: 21 | Loss: 0.437 | Acc: 84.946% (7900/9300)\n",
      "Test Epoch: 21 | Loss: 0.436 | Acc: 84.968% (7987/9400)\n",
      "Test Epoch: 21 | Loss: 0.435 | Acc: 85.011% (8076/9500)\n",
      "Test Epoch: 21 | Loss: 0.434 | Acc: 85.052% (8165/9600)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.093% (8254/9700)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.082% (8338/9800)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.111% (8426/9900)\n",
      "Test Epoch: 21 | Loss: 0.433 | Acc: 85.110% (8511/10000)\n",
      "\n",
      "Epoch: 22\n",
      "Train Epoch: 22 | Loss: 0.255 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 22 | Loss: 0.315 | Acc: 87.500% (224/256)\n",
      "Train Epoch: 22 | Loss: 0.354 | Acc: 86.458% (332/384)\n",
      "Train Epoch: 22 | Loss: 0.331 | Acc: 87.891% (450/512)\n",
      "Train Epoch: 22 | Loss: 0.346 | Acc: 87.031% (557/640)\n",
      "Train Epoch: 22 | Loss: 0.358 | Acc: 86.849% (667/768)\n",
      "Train Epoch: 22 | Loss: 0.353 | Acc: 87.388% (783/896)\n",
      "Train Epoch: 22 | Loss: 0.351 | Acc: 87.598% (897/1024)\n",
      "Train Epoch: 22 | Loss: 0.349 | Acc: 87.587% (1009/1152)\n",
      "Train Epoch: 22 | Loss: 0.349 | Acc: 87.734% (1123/1280)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.642% (1234/1408)\n",
      "Train Epoch: 22 | Loss: 0.363 | Acc: 87.370% (1342/1536)\n",
      "Train Epoch: 22 | Loss: 0.362 | Acc: 87.560% (1457/1664)\n",
      "Train Epoch: 22 | Loss: 0.358 | Acc: 87.835% (1574/1792)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.708% (1684/1920)\n",
      "Train Epoch: 22 | Loss: 0.352 | Acc: 87.842% (1799/2048)\n",
      "Train Epoch: 22 | Loss: 0.353 | Acc: 87.822% (1911/2176)\n",
      "Train Epoch: 22 | Loss: 0.358 | Acc: 87.630% (2019/2304)\n",
      "Train Epoch: 22 | Loss: 0.355 | Acc: 87.623% (2131/2432)\n",
      "Train Epoch: 22 | Loss: 0.354 | Acc: 87.656% (2244/2560)\n",
      "Train Epoch: 22 | Loss: 0.355 | Acc: 87.537% (2353/2688)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.500% (2464/2816)\n",
      "Train Epoch: 22 | Loss: 0.354 | Acc: 87.704% (2582/2944)\n",
      "Train Epoch: 22 | Loss: 0.353 | Acc: 87.695% (2694/3072)\n",
      "Train Epoch: 22 | Loss: 0.350 | Acc: 87.781% (2809/3200)\n",
      "Train Epoch: 22 | Loss: 0.347 | Acc: 87.921% (2926/3328)\n",
      "Train Epoch: 22 | Loss: 0.347 | Acc: 87.963% (3040/3456)\n",
      "Train Epoch: 22 | Loss: 0.343 | Acc: 88.142% (3159/3584)\n",
      "Train Epoch: 22 | Loss: 0.340 | Acc: 88.227% (3275/3712)\n",
      "Train Epoch: 22 | Loss: 0.341 | Acc: 88.255% (3389/3840)\n",
      "Train Epoch: 22 | Loss: 0.341 | Acc: 88.306% (3504/3968)\n",
      "Train Epoch: 22 | Loss: 0.342 | Acc: 88.208% (3613/4096)\n",
      "Train Epoch: 22 | Loss: 0.344 | Acc: 88.163% (3724/4224)\n",
      "Train Epoch: 22 | Loss: 0.344 | Acc: 88.166% (3837/4352)\n",
      "Train Epoch: 22 | Loss: 0.346 | Acc: 88.058% (3945/4480)\n",
      "Train Epoch: 22 | Loss: 0.344 | Acc: 88.173% (4063/4608)\n",
      "Train Epoch: 22 | Loss: 0.343 | Acc: 88.218% (4178/4736)\n",
      "Train Epoch: 22 | Loss: 0.342 | Acc: 88.281% (4294/4864)\n",
      "Train Epoch: 22 | Loss: 0.344 | Acc: 88.241% (4405/4992)\n",
      "Train Epoch: 22 | Loss: 0.341 | Acc: 88.340% (4523/5120)\n",
      "Train Epoch: 22 | Loss: 0.342 | Acc: 88.357% (4637/5248)\n",
      "Train Epoch: 22 | Loss: 0.346 | Acc: 88.188% (4741/5376)\n",
      "Train Epoch: 22 | Loss: 0.349 | Acc: 88.081% (4848/5504)\n",
      "Train Epoch: 22 | Loss: 0.349 | Acc: 88.139% (4964/5632)\n",
      "Train Epoch: 22 | Loss: 0.349 | Acc: 88.160% (5078/5760)\n",
      "Train Epoch: 22 | Loss: 0.351 | Acc: 88.111% (5188/5888)\n",
      "Train Epoch: 22 | Loss: 0.354 | Acc: 87.949% (5291/6016)\n",
      "Train Epoch: 22 | Loss: 0.357 | Acc: 87.891% (5400/6144)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.883% (5512/6272)\n",
      "Train Epoch: 22 | Loss: 0.357 | Acc: 87.844% (5622/6400)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.929% (5740/6528)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.921% (5852/6656)\n",
      "Train Epoch: 22 | Loss: 0.356 | Acc: 87.898% (5963/6784)\n",
      "Train Epoch: 22 | Loss: 0.357 | Acc: 87.833% (6071/6912)\n",
      "Train Epoch: 22 | Loss: 0.359 | Acc: 87.756% (6178/7040)\n",
      "Train Epoch: 22 | Loss: 0.357 | Acc: 87.863% (6298/7168)\n",
      "Train Epoch: 22 | Loss: 0.358 | Acc: 87.829% (6408/7296)\n",
      "Train Epoch: 22 | Loss: 0.360 | Acc: 87.742% (6514/7424)\n",
      "Train Epoch: 22 | Loss: 0.362 | Acc: 87.659% (6620/7552)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.552% (6724/7680)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.564% (6837/7808)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.563% (6949/7936)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.599% (7064/8064)\n",
      "Train Epoch: 22 | Loss: 0.363 | Acc: 87.683% (7183/8192)\n",
      "Train Epoch: 22 | Loss: 0.362 | Acc: 87.716% (7298/8320)\n",
      "Train Epoch: 22 | Loss: 0.363 | Acc: 87.689% (7408/8448)\n",
      "Train Epoch: 22 | Loss: 0.363 | Acc: 87.663% (7518/8576)\n",
      "Train Epoch: 22 | Loss: 0.362 | Acc: 87.649% (7629/8704)\n",
      "Train Epoch: 22 | Loss: 0.363 | Acc: 87.659% (7742/8832)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.522% (7842/8960)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.533% (7955/9088)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.533% (8067/9216)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.564% (8182/9344)\n",
      "Train Epoch: 22 | Loss: 0.364 | Acc: 87.616% (8299/9472)\n",
      "Train Epoch: 22 | Loss: 0.364 | Acc: 87.646% (8414/9600)\n",
      "Train Epoch: 22 | Loss: 0.364 | Acc: 87.644% (8526/9728)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.601% (8634/9856)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.560% (8742/9984)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.530% (8851/10112)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.578% (8968/10240)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.548% (9077/10368)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.510% (9185/10496)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.472% (9293/10624)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.491% (9407/10752)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.500% (9520/10880)\n",
      "Train Epoch: 22 | Loss: 0.364 | Acc: 87.555% (9638/11008)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.536% (9748/11136)\n",
      "Train Epoch: 22 | Loss: 0.365 | Acc: 87.562% (9863/11264)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.500% (9968/11392)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.465% (10076/11520)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.431% (10184/11648)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.458% (10299/11776)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.466% (10412/11904)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.483% (10526/12032)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.508% (10641/12160)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.508% (10753/12288)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.532% (10868/12416)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.444% (10969/12544)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.390% (11074/12672)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.422% (11190/12800)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.446% (11305/12928)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.454% (11418/13056)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.485% (11534/13184)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.485% (11646/13312)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.440% (11752/13440)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.426% (11862/13568)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.456% (11978/13696)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.457% (12090/13824)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.471% (12204/13952)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.486% (12318/14080)\n",
      "Train Epoch: 22 | Loss: 0.366 | Acc: 87.486% (12430/14208)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.479% (12541/14336)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.459% (12650/14464)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.452% (12761/14592)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.432% (12870/14720)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.406% (12978/14848)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.380% (13086/14976)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.374% (13197/15104)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.382% (13310/15232)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.370% (13420/15360)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.326% (13525/15488)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.289% (13631/15616)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.284% (13742/15744)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.286% (13854/15872)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.219% (13955/16000)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.221% (14067/16128)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.211% (14177/16256)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.238% (14293/16384)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.240% (14405/16512)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.224% (14514/16640)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.255% (14631/16768)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.228% (14738/16896)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.218% (14848/17024)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.243% (14964/17152)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.251% (15077/17280)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.236% (15186/17408)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.255% (15301/17536)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.240% (15410/17664)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.202% (15515/17792)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.215% (15629/17920)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.256% (15748/18048)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.263% (15861/18176)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.227% (15966/18304)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.229% (16078/18432)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.214% (16187/18560)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.238% (16303/18688)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.261% (16419/18816)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.284% (16535/18944)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.264% (16643/19072)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.286% (16759/19200)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.278% (16869/19328)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.274% (16980/19456)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.280% (17093/19584)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.302% (17209/19712)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.278% (17316/19840)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.260% (17424/19968)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.246% (17533/20096)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.263% (17648/20224)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.274% (17762/20352)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.295% (17878/20480)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.291% (17989/20608)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.322% (18107/20736)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.303% (18215/20864)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.314% (18329/20992)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.311% (18440/21120)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.321% (18554/21248)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.322% (18666/21376)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.333% (18780/21504)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.352% (18896/21632)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.335% (19004/21760)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.308% (19110/21888)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.323% (19225/22016)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.355% (19344/22144)\n",
      "Train Epoch: 22 | Loss: 0.367 | Acc: 87.379% (19461/22272)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.393% (19576/22400)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.402% (19690/22528)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.407% (19803/22656)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.430% (19920/22784)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.413% (20028/22912)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.396% (20136/23040)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.388% (20246/23168)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.397% (20360/23296)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.385% (20469/23424)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.339% (20570/23552)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.344% (20683/23680)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.340% (20794/23808)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.337% (20905/23936)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.342% (21018/24064)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.355% (21133/24192)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.360% (21246/24320)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.365% (21359/24448)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.354% (21468/24576)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.375% (21585/24704)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.379% (21698/24832)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.408% (21817/24960)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.376% (21921/25088)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.373% (22032/25216)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.386% (22147/25344)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.406% (22264/25472)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.371% (22367/25600)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.372% (22479/25728)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.365% (22589/25856)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.373% (22703/25984)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.374% (22815/26112)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.389% (22931/26240)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.367% (23037/26368)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.357% (23146/26496)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.365% (23260/26624)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.380% (23376/26752)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.385% (23489/26880)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.370% (23597/27008)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.378% (23711/27136)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.372% (23821/27264)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.358% (23929/27392)\n",
      "Train Epoch: 22 | Loss: 0.368 | Acc: 87.376% (24046/27520)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.348% (24150/27648)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.331% (24257/27776)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.314% (24364/27904)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.311% (24475/28032)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.312% (24587/28160)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.288% (24692/28288)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.292% (24805/28416)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.286% (24915/28544)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.319% (25036/28672)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.309% (25145/28800)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.320% (25260/28928)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.345% (25379/29056)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.346% (25491/29184)\n",
      "Train Epoch: 22 | Loss: 0.369 | Acc: 87.360% (25607/29312)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.361% (25719/29440)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.351% (25828/29568)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.342% (25937/29696)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.342% (26049/29824)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.323% (26155/29952)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.320% (26266/30080)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.315% (26376/30208)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.315% (26488/30336)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.313% (26599/30464)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.337% (26718/30592)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.331% (26828/30720)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.338% (26942/30848)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.335% (27053/30976)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.326% (27162/31104)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.327% (27274/31232)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.325% (27385/31360)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.300% (27489/31488)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.310% (27604/31616)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.308% (27715/31744)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.309% (27827/31872)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.303% (27937/32000)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.307% (28050/32128)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.308% (28162/32256)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.305% (28273/32384)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.306% (28385/32512)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.325% (28503/32640)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.338% (28619/32768)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.327% (28727/32896)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.318% (28836/33024)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.301% (28942/33152)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.281% (29047/33280)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.273% (29156/33408)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.264% (29265/33536)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.268% (29378/33664)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.284% (29495/33792)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.282% (29606/33920)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.283% (29718/34048)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.295% (29834/34176)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.287% (29943/34304)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.271% (30049/34432)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.274% (30162/34560)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.269% (30272/34688)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.279% (30387/34816)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.260% (30492/34944)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.266% (30606/35072)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.284% (30724/35200)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.288% (30837/35328)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.303% (30954/35456)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.312% (31069/35584)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.298% (31176/35712)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.291% (31285/35840)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.305% (31402/35968)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.309% (31515/36096)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.304% (31625/36224)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.294% (31733/36352)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.303% (31848/36480)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.287% (31954/36608)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.290% (32067/36736)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.288% (32178/36864)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.284% (32288/36992)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.287% (32401/37120)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.296% (32516/37248)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.297% (32628/37376)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.300% (32741/37504)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.298% (32852/37632)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.307% (32967/37760)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.297% (33075/37888)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.311% (33192/38016)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.309% (33303/38144)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.325% (33421/38272)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.341% (33539/38400)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.342% (33651/38528)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.345% (33764/38656)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.343% (33875/38784)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.341% (33986/38912)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.341% (34098/39040)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.344% (34211/39168)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.345% (34323/39296)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.345% (34435/39424)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.356% (34551/39552)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.346% (34659/39680)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.347% (34771/39808)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.332% (34877/39936)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.335% (34990/40064)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.333% (35101/40192)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.336% (35214/40320)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.347% (35330/40448)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.342% (35440/40576)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.335% (35549/40704)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.321% (35655/40832)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.319% (35766/40960)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.325% (35880/41088)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.330% (35994/41216)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.328% (36105/41344)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.331% (36218/41472)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.339% (36333/41600)\n",
      "Train Epoch: 22 | Loss: 0.370 | Acc: 87.349% (36449/41728)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.326% (36551/41856)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.314% (36658/41984)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.315% (36770/42112)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.322% (36885/42240)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.314% (36993/42368)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.307% (37102/42496)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.291% (37207/42624)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.299% (37322/42752)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.295% (37432/42880)\n",
      "Train Epoch: 22 | Loss: 0.371 | Acc: 87.293% (37543/43008)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.264% (37642/43136)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.269% (37756/43264)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.263% (37865/43392)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.254% (37973/43520)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.232% (38075/43648)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.235% (38188/43776)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.220% (38293/43904)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.218% (38404/44032)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.224% (38518/44160)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.220% (38628/44288)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.232% (38745/44416)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.244% (38862/44544)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.254% (38978/44672)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.263% (39094/44800)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.264% (39206/44928)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.249% (39311/45056)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.261% (39428/45184)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.257% (39538/45312)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.245% (39644/45440)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.241% (39754/45568)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.233% (39862/45696)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.232% (39973/45824)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.219% (40079/45952)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.229% (40195/46080)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.232% (40308/46208)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.232% (40420/46336)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.237% (40534/46464)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.238% (40646/46592)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.232% (40755/46720)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.246% (40873/46848)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.253% (40988/46976)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.243% (41095/47104)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.223% (41197/47232)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.221% (41308/47360)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.224% (41421/47488)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.233% (41537/47616)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.236% (41650/47744)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.233% (41760/47872)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.227% (41869/48000)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.238% (41986/48128)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.241% (42099/48256)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.242% (42211/48384)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.246% (42325/48512)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.247% (42437/48640)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.233% (42542/48768)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.240% (42657/48896)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.237% (42767/49024)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.242% (42881/49152)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.238% (42991/49280)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.243% (43105/49408)\n",
      "Train Epoch: 22 | Loss: 0.372 | Acc: 87.242% (43216/49536)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.230% (43322/49664)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.227% (43432/49792)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.222% (43541/49920)\n",
      "Train Epoch: 22 | Loss: 0.373 | Acc: 87.218% (43609/50000)\n",
      "Test Epoch: 22 | Loss: 0.453 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 22 | Loss: 0.363 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 22 | Loss: 0.371 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 22 | Loss: 0.363 | Acc: 88.400% (442/500)\n",
      "Test Epoch: 22 | Loss: 0.330 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 22 | Loss: 0.328 | Acc: 89.571% (627/700)\n",
      "Test Epoch: 22 | Loss: 0.356 | Acc: 88.250% (706/800)\n",
      "Test Epoch: 22 | Loss: 0.381 | Acc: 87.333% (786/900)\n",
      "Test Epoch: 22 | Loss: 0.388 | Acc: 87.200% (872/1000)\n",
      "Test Epoch: 22 | Loss: 0.385 | Acc: 87.273% (960/1100)\n",
      "Test Epoch: 22 | Loss: 0.399 | Acc: 86.583% (1039/1200)\n",
      "Test Epoch: 22 | Loss: 0.399 | Acc: 86.385% (1123/1300)\n",
      "Test Epoch: 22 | Loss: 0.393 | Acc: 86.857% (1216/1400)\n",
      "Test Epoch: 22 | Loss: 0.387 | Acc: 87.067% (1306/1500)\n",
      "Test Epoch: 22 | Loss: 0.393 | Acc: 86.875% (1390/1600)\n",
      "Test Epoch: 22 | Loss: 0.392 | Acc: 86.941% (1478/1700)\n",
      "Test Epoch: 22 | Loss: 0.395 | Acc: 86.889% (1564/1800)\n",
      "Test Epoch: 22 | Loss: 0.396 | Acc: 86.895% (1651/1900)\n",
      "Test Epoch: 22 | Loss: 0.411 | Acc: 86.550% (1731/2000)\n",
      "Test Epoch: 22 | Loss: 0.409 | Acc: 86.571% (1818/2100)\n",
      "Test Epoch: 22 | Loss: 0.408 | Acc: 86.591% (1905/2200)\n",
      "Test Epoch: 22 | Loss: 0.407 | Acc: 86.696% (1994/2300)\n",
      "Test Epoch: 22 | Loss: 0.404 | Acc: 86.792% (2083/2400)\n",
      "Test Epoch: 22 | Loss: 0.405 | Acc: 86.760% (2169/2500)\n",
      "Test Epoch: 22 | Loss: 0.415 | Acc: 86.654% (2253/2600)\n",
      "Test Epoch: 22 | Loss: 0.413 | Acc: 86.741% (2342/2700)\n",
      "Test Epoch: 22 | Loss: 0.416 | Acc: 86.750% (2429/2800)\n",
      "Test Epoch: 22 | Loss: 0.421 | Acc: 86.690% (2514/2900)\n",
      "Test Epoch: 22 | Loss: 0.422 | Acc: 86.633% (2599/3000)\n",
      "Test Epoch: 22 | Loss: 0.428 | Acc: 86.419% (2679/3100)\n",
      "Test Epoch: 22 | Loss: 0.431 | Acc: 86.406% (2765/3200)\n",
      "Test Epoch: 22 | Loss: 0.429 | Acc: 86.545% (2856/3300)\n",
      "Test Epoch: 22 | Loss: 0.428 | Acc: 86.500% (2941/3400)\n",
      "Test Epoch: 22 | Loss: 0.433 | Acc: 86.314% (3021/3500)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 86.250% (3105/3600)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.162% (3188/3700)\n",
      "Test Epoch: 22 | Loss: 0.441 | Acc: 86.053% (3270/3800)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.077% (3357/3900)\n",
      "Test Epoch: 22 | Loss: 0.441 | Acc: 86.200% (3448/4000)\n",
      "Test Epoch: 22 | Loss: 0.444 | Acc: 86.024% (3527/4100)\n",
      "Test Epoch: 22 | Loss: 0.448 | Acc: 86.000% (3612/4200)\n",
      "Test Epoch: 22 | Loss: 0.444 | Acc: 86.047% (3700/4300)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.205% (3793/4400)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.267% (3882/4500)\n",
      "Test Epoch: 22 | Loss: 0.442 | Acc: 86.130% (3962/4600)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 86.234% (4053/4700)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 86.208% (4138/4800)\n",
      "Test Epoch: 22 | Loss: 0.435 | Acc: 86.388% (4233/4900)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 86.280% (4314/5000)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 86.353% (4404/5100)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.365% (4491/5200)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.321% (4575/5300)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 86.407% (4666/5400)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.327% (4748/5500)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.250% (4830/5600)\n",
      "Test Epoch: 22 | Loss: 0.441 | Acc: 86.175% (4912/5700)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.190% (4999/5800)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.169% (5084/5900)\n",
      "Test Epoch: 22 | Loss: 0.442 | Acc: 86.033% (5162/6000)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.098% (5252/6100)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.081% (5337/6200)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.127% (5426/6300)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.219% (5518/6400)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.185% (5602/6500)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.167% (5687/6600)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 86.224% (5777/6700)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.147% (5858/6800)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 86.159% (5945/6900)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 86.129% (6029/7000)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.085% (6112/7100)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.028% (6194/7200)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 86.027% (6280/7300)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.014% (6365/7400)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 85.973% (6448/7500)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 85.961% (6533/7600)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 85.948% (6618/7700)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 85.987% (6707/7800)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 86.038% (6797/7900)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 86.013% (6881/8000)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 86.000% (6966/8100)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 85.988% (7051/8200)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 85.964% (7135/8300)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.976% (7222/8400)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.976% (7308/8500)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 85.930% (7390/8600)\n",
      "Test Epoch: 22 | Loss: 0.439 | Acc: 85.954% (7478/8700)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 85.943% (7563/8800)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 85.899% (7645/8900)\n",
      "Test Epoch: 22 | Loss: 0.440 | Acc: 85.822% (7724/9000)\n",
      "Test Epoch: 22 | Loss: 0.438 | Acc: 85.791% (7807/9100)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.826% (7896/9200)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 85.828% (7982/9300)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.851% (8070/9400)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.874% (8158/9500)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.885% (8245/9600)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.938% (8336/9700)\n",
      "Test Epoch: 22 | Loss: 0.436 | Acc: 85.898% (8418/9800)\n",
      "Test Epoch: 22 | Loss: 0.437 | Acc: 85.899% (8504/9900)\n",
      "Test Epoch: 22 | Loss: 0.435 | Acc: 85.940% (8594/10000)\n",
      "\n",
      "Epoch: 23\n",
      "Train Epoch: 23 | Loss: 0.294 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 23 | Loss: 0.344 | Acc: 87.891% (225/256)\n",
      "Train Epoch: 23 | Loss: 0.370 | Acc: 87.240% (335/384)\n",
      "Train Epoch: 23 | Loss: 0.368 | Acc: 87.500% (448/512)\n",
      "Train Epoch: 23 | Loss: 0.368 | Acc: 87.500% (560/640)\n",
      "Train Epoch: 23 | Loss: 0.374 | Acc: 86.849% (667/768)\n",
      "Train Epoch: 23 | Loss: 0.378 | Acc: 86.942% (779/896)\n",
      "Train Epoch: 23 | Loss: 0.374 | Acc: 87.012% (891/1024)\n",
      "Train Epoch: 23 | Loss: 0.370 | Acc: 87.500% (1008/1152)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.969% (1126/1280)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.784% (1236/1408)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 88.281% (1356/1536)\n",
      "Train Epoch: 23 | Loss: 0.354 | Acc: 88.582% (1474/1664)\n",
      "Train Epoch: 23 | Loss: 0.353 | Acc: 88.504% (1586/1792)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.490% (1699/1920)\n",
      "Train Epoch: 23 | Loss: 0.347 | Acc: 88.477% (1812/2048)\n",
      "Train Epoch: 23 | Loss: 0.346 | Acc: 88.465% (1925/2176)\n",
      "Train Epoch: 23 | Loss: 0.355 | Acc: 87.977% (2027/2304)\n",
      "Train Epoch: 23 | Loss: 0.354 | Acc: 88.117% (2143/2432)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 88.203% (2258/2560)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.393% (2376/2688)\n",
      "Train Epoch: 23 | Loss: 0.344 | Acc: 88.565% (2494/2816)\n",
      "Train Epoch: 23 | Loss: 0.342 | Acc: 88.553% (2607/2944)\n",
      "Train Epoch: 23 | Loss: 0.347 | Acc: 88.477% (2718/3072)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 88.500% (2832/3200)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 88.431% (2943/3328)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.397% (3055/3456)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.337% (3166/3584)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.362% (3280/3712)\n",
      "Train Epoch: 23 | Loss: 0.345 | Acc: 88.464% (3397/3840)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.407% (3508/3968)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 88.281% (3616/4096)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 88.163% (3724/4224)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 88.120% (3835/4352)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.192% (3951/4480)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.173% (4063/4608)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.176% (4176/4736)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 88.137% (4287/4864)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 88.061% (4396/4992)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.105% (4511/5120)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.129% (4625/5248)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.039% (4733/5376)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 88.027% (4845/5504)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.068% (4960/5632)\n",
      "Train Epoch: 23 | Loss: 0.347 | Acc: 88.160% (5078/5760)\n",
      "Train Epoch: 23 | Loss: 0.347 | Acc: 88.111% (5188/5888)\n",
      "Train Epoch: 23 | Loss: 0.346 | Acc: 88.148% (5303/6016)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.118% (5414/6144)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 88.074% (5524/6272)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.188% (5644/6400)\n",
      "Train Epoch: 23 | Loss: 0.345 | Acc: 88.327% (5766/6528)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 88.161% (5868/6656)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 88.045% (5973/6784)\n",
      "Train Epoch: 23 | Loss: 0.353 | Acc: 87.977% (6081/6912)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 87.955% (6192/7040)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 88.002% (6308/7168)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.939% (6416/7296)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.891% (6525/7424)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 87.831% (6633/7552)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.812% (6744/7680)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.756% (6852/7808)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.828% (6970/7936)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.909% (7089/8064)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.927% (7203/8192)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.909% (7314/8320)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.938% (7429/8448)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 87.861% (7535/8576)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.833% (7645/8704)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 87.840% (7758/8832)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.902% (7876/8960)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.874% (7986/9088)\n",
      "Train Epoch: 23 | Loss: 0.347 | Acc: 87.901% (8101/9216)\n",
      "Train Epoch: 23 | Loss: 0.348 | Acc: 87.853% (8209/9344)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.774% (8314/9472)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.708% (8420/9600)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.736% (8535/9728)\n",
      "Train Epoch: 23 | Loss: 0.349 | Acc: 87.774% (8651/9856)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.760% (8762/9984)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.727% (8871/10112)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.783% (8989/10240)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.809% (9104/10368)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.795% (9215/10496)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.782% (9326/10624)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.788% (9439/10752)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.785% (9551/10880)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.691% (9653/11008)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.751% (9772/11136)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.766% (9886/11264)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.798% (10002/11392)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.786% (10113/11520)\n",
      "Train Epoch: 23 | Loss: 0.350 | Acc: 87.792% (10226/11648)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.789% (10338/11776)\n",
      "Train Epoch: 23 | Loss: 0.351 | Acc: 87.794% (10451/11904)\n",
      "Train Epoch: 23 | Loss: 0.352 | Acc: 87.808% (10565/12032)\n",
      "Train Epoch: 23 | Loss: 0.353 | Acc: 87.780% (10674/12160)\n",
      "Train Epoch: 23 | Loss: 0.353 | Acc: 87.760% (10784/12288)\n",
      "Train Epoch: 23 | Loss: 0.354 | Acc: 87.750% (10895/12416)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.707% (11002/12544)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.697% (11113/12672)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.727% (11229/12800)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.732% (11342/12928)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.699% (11450/13056)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.728% (11566/13184)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.725% (11678/13312)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.738% (11792/13440)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.728% (11903/13568)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.741% (12017/13696)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.724% (12127/13824)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.715% (12238/13952)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.706% (12349/14080)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.746% (12467/14208)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.779% (12584/14336)\n",
      "Train Epoch: 23 | Loss: 0.356 | Acc: 87.790% (12698/14464)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.767% (12807/14592)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.738% (12915/14720)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.722% (13025/14848)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.740% (13140/14976)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.692% (13245/15104)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.704% (13359/15232)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.695% (13470/15360)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.674% (13579/15488)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.711% (13697/15616)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.697% (13807/15744)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.714% (13922/15872)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.713% (14034/16000)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.736% (14150/16128)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.740% (14263/16256)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.720% (14372/16384)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.706% (14482/16512)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.728% (14598/16640)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.745% (14713/16768)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.725% (14822/16896)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.753% (14939/17024)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.739% (15049/17152)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.737% (15161/17280)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.695% (15266/17408)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.694% (15378/17536)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.681% (15488/17664)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.708% (15605/17792)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.718% (15719/17920)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.716% (15831/18048)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.720% (15944/18176)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.740% (16060/18304)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.733% (16171/18432)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.699% (16277/18560)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.725% (16394/18688)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.691% (16500/18816)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.706% (16615/18944)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.725% (16731/19072)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.714% (16841/19200)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.728% (16956/19328)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.726% (17068/19456)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.704% (17176/19584)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.744% (17296/19712)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.722% (17404/19840)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.715% (17515/19968)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.744% (17633/20096)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.747% (17746/20224)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.760% (17861/20352)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.788% (17979/20480)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.781% (18090/20608)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.780% (18202/20736)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.797% (18318/20864)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.791% (18429/20992)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.798% (18543/21120)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.796% (18655/21248)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.790% (18766/21376)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.798% (18880/21504)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.805% (18994/21632)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.808% (19107/21760)\n",
      "Train Epoch: 23 | Loss: 0.357 | Acc: 87.824% (19223/21888)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.791% (19328/22016)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.753% (19432/22144)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.774% (19549/22272)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.781% (19663/22400)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.780% (19775/22528)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.796% (19891/22656)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.803% (20005/22784)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.792% (20115/22912)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.782% (20225/23040)\n",
      "Train Epoch: 23 | Loss: 0.358 | Acc: 87.776% (20336/23168)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.740% (20440/23296)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.718% (20547/23424)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.670% (20648/23552)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.660% (20758/23680)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.647% (20867/23808)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.675% (20986/23936)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.658% (21094/24064)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.645% (21203/24192)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.640% (21314/24320)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.655% (21430/24448)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.659% (21543/24576)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.642% (21651/24704)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.649% (21765/24832)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.648% (21877/24960)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.671% (21995/25088)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.682% (22110/25216)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.682% (22222/25344)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.669% (22331/25472)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.684% (22447/25600)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.687% (22560/25728)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.697% (22675/25856)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.716% (22792/25984)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.734% (22909/26112)\n",
      "Train Epoch: 23 | Loss: 0.359 | Acc: 87.706% (23014/26240)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.671% (23117/26368)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.670% (23229/26496)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.662% (23339/26624)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.672% (23454/26752)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.693% (23572/26880)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.678% (23680/27008)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.695% (23797/27136)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.691% (23908/27264)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.679% (24017/27392)\n",
      "Train Epoch: 23 | Loss: 0.360 | Acc: 87.689% (24132/27520)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.677% (24241/27648)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.687% (24356/27776)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.661% (24461/27904)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.678% (24578/28032)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.667% (24687/28160)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.638% (24791/28288)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.658% (24909/28416)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.668% (25024/28544)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.667% (25136/28672)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.663% (25247/28800)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.645% (25354/28928)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.658% (25470/29056)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.640% (25577/29184)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.640% (25689/29312)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.643% (25802/29440)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.635% (25912/29568)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.611% (26017/29696)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.614% (26130/29824)\n",
      "Train Epoch: 23 | Loss: 0.361 | Acc: 87.630% (26247/29952)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.636% (26361/30080)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.646% (26476/30208)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.629% (26583/30336)\n",
      "Train Epoch: 23 | Loss: 0.362 | Acc: 87.621% (26693/30464)\n",
      "Train Epoch: 23 | Loss: 0.363 | Acc: 87.605% (26800/30592)\n",
      "Train Epoch: 23 | Loss: 0.363 | Acc: 87.598% (26910/30720)\n",
      "Train Epoch: 23 | Loss: 0.363 | Acc: 87.591% (27020/30848)\n",
      "Train Epoch: 23 | Loss: 0.363 | Acc: 87.568% (27125/30976)\n",
      "Train Epoch: 23 | Loss: 0.364 | Acc: 87.551% (27232/31104)\n",
      "Train Epoch: 23 | Loss: 0.363 | Acc: 87.564% (27348/31232)\n",
      "Train Epoch: 23 | Loss: 0.364 | Acc: 87.548% (27455/31360)\n",
      "Train Epoch: 23 | Loss: 0.364 | Acc: 87.529% (27561/31488)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.522% (27671/31616)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.525% (27784/31744)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.522% (27895/31872)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.519% (28006/32000)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.522% (28119/32128)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.497% (28223/32256)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.500% (28336/32384)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.482% (28442/32512)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.472% (28551/32640)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.482% (28666/32768)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.467% (28773/32896)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.452% (28880/33024)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.452% (28992/33152)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.434% (29098/33280)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.437% (29211/33408)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.449% (29327/33536)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.447% (29438/33664)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.470% (29558/33792)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.465% (29668/33920)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.465% (29780/34048)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.447% (29886/34176)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.433% (29993/34304)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.442% (30108/34432)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.445% (30221/34560)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.425% (30326/34688)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.434% (30441/34816)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.431% (30552/34944)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.437% (30666/35072)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.432% (30776/35200)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.435% (30889/35328)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.441% (31003/35456)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.438% (31114/35584)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.430% (31223/35712)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.416% (31330/35840)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.425% (31445/35968)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.417% (31554/36096)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.428% (31670/36224)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.437% (31785/36352)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.440% (31898/36480)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.434% (32008/36608)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.446% (32124/36736)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.448% (32237/36864)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.441% (32346/36992)\n",
      "Train Epoch: 23 | Loss: 0.367 | Acc: 87.441% (32458/37120)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.444% (32571/37248)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.449% (32685/37376)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.463% (32802/37504)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.471% (32917/37632)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.452% (33022/37760)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.442% (33130/37888)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.439% (33241/38016)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.421% (33346/38144)\n",
      "Train Epoch: 23 | Loss: 0.367 | Acc: 87.411% (33454/38272)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.424% (33571/38400)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.438% (33688/38528)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.446% (33803/38656)\n",
      "Train Epoch: 23 | Loss: 0.367 | Acc: 87.428% (33908/38784)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.449% (34028/38912)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.454% (34142/39040)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.462% (34257/39168)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.457% (34367/39296)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.452% (34477/39424)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.462% (34593/39552)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.462% (34705/39680)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.482% (34825/39808)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.480% (34936/39936)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.485% (35050/40064)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.495% (35166/40192)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.490% (35276/40320)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.475% (35382/40448)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.485% (35498/40576)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.490% (35612/40704)\n",
      "Train Epoch: 23 | Loss: 0.364 | Acc: 87.493% (35725/40832)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.490% (35836/40960)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.483% (35945/41088)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.490% (36060/41216)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.476% (36166/41344)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.452% (36268/41472)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.457% (36382/41600)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.440% (36487/41728)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.428% (36594/41856)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.431% (36707/41984)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.434% (36820/42112)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.436% (36933/42240)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.448% (37050/42368)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.436% (37157/42496)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.432% (37267/42624)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.442% (37383/42752)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.442% (37495/42880)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.440% (37606/43008)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.440% (37718/43136)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.449% (37834/43264)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.463% (37952/43392)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.459% (38062/43520)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.450% (38170/43648)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.447% (38281/43776)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.441% (38390/43904)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.432% (38498/44032)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.437% (38612/44160)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.432% (38722/44288)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.448% (38841/44416)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.444% (38951/44544)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.449% (39065/44672)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.451% (39178/44800)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.473% (39300/44928)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.464% (39408/45056)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.460% (39518/45184)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.462% (39631/45312)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.454% (39739/45440)\n",
      "Train Epoch: 23 | Loss: 0.365 | Acc: 87.460% (39854/45568)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.454% (39963/45696)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.459% (40077/45824)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.446% (40183/45952)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.446% (40295/46080)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.452% (40410/46208)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.457% (40524/46336)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.466% (40640/46464)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.464% (40751/46592)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.476% (40869/46720)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.481% (40983/46848)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.474% (41092/46976)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.470% (41202/47104)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.466% (41312/47232)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.473% (41427/47360)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.481% (41543/47488)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.481% (41655/47616)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.485% (41769/47744)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.481% (41879/47872)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.481% (41991/48000)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.471% (42098/48128)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.477% (42213/48256)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.490% (42331/48384)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.492% (42444/48512)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.486% (42553/48640)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.482% (42663/48768)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.473% (42771/48896)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.478% (42885/49024)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.465% (42991/49152)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.468% (43104/49280)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.472% (43218/49408)\n",
      "Train Epoch: 23 | Loss: 0.367 | Acc: 87.462% (43325/49536)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.468% (43440/49664)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.458% (43547/49792)\n",
      "Train Epoch: 23 | Loss: 0.367 | Acc: 87.442% (43651/49920)\n",
      "Train Epoch: 23 | Loss: 0.366 | Acc: 87.446% (43723/50000)\n",
      "Test Epoch: 23 | Loss: 0.353 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 23 | Loss: 0.464 | Acc: 83.500% (167/200)\n",
      "Test Epoch: 23 | Loss: 0.433 | Acc: 84.000% (252/300)\n",
      "Test Epoch: 23 | Loss: 0.457 | Acc: 83.750% (335/400)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 84.400% (422/500)\n",
      "Test Epoch: 23 | Loss: 0.405 | Acc: 85.167% (511/600)\n",
      "Test Epoch: 23 | Loss: 0.400 | Acc: 86.000% (602/700)\n",
      "Test Epoch: 23 | Loss: 0.427 | Acc: 85.250% (682/800)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 85.556% (770/900)\n",
      "Test Epoch: 23 | Loss: 0.428 | Acc: 86.000% (860/1000)\n",
      "Test Epoch: 23 | Loss: 0.427 | Acc: 86.273% (949/1100)\n",
      "Test Epoch: 23 | Loss: 0.420 | Acc: 86.333% (1036/1200)\n",
      "Test Epoch: 23 | Loss: 0.417 | Acc: 86.308% (1122/1300)\n",
      "Test Epoch: 23 | Loss: 0.408 | Acc: 86.571% (1212/1400)\n",
      "Test Epoch: 23 | Loss: 0.415 | Acc: 86.467% (1297/1500)\n",
      "Test Epoch: 23 | Loss: 0.414 | Acc: 86.375% (1382/1600)\n",
      "Test Epoch: 23 | Loss: 0.409 | Acc: 86.765% (1475/1700)\n",
      "Test Epoch: 23 | Loss: 0.419 | Acc: 86.444% (1556/1800)\n",
      "Test Epoch: 23 | Loss: 0.418 | Acc: 86.421% (1642/1900)\n",
      "Test Epoch: 23 | Loss: 0.423 | Acc: 86.400% (1728/2000)\n",
      "Test Epoch: 23 | Loss: 0.425 | Acc: 86.286% (1812/2100)\n",
      "Test Epoch: 23 | Loss: 0.425 | Acc: 86.364% (1900/2200)\n",
      "Test Epoch: 23 | Loss: 0.431 | Acc: 86.217% (1983/2300)\n",
      "Test Epoch: 23 | Loss: 0.427 | Acc: 86.333% (2072/2400)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.280% (2157/2500)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.038% (2237/2600)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.037% (2323/2700)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.000% (2408/2800)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.034% (2495/2900)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 86.133% (2584/3000)\n",
      "Test Epoch: 23 | Loss: 0.446 | Acc: 85.903% (2663/3100)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.844% (2747/3200)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 85.970% (2837/3300)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 85.912% (2921/3400)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 85.771% (3002/3500)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.778% (3088/3600)\n",
      "Test Epoch: 23 | Loss: 0.445 | Acc: 85.757% (3173/3700)\n",
      "Test Epoch: 23 | Loss: 0.445 | Acc: 85.816% (3261/3800)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.949% (3352/3900)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.075% (3443/4000)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.049% (3528/4100)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.095% (3616/4200)\n",
      "Test Epoch: 23 | Loss: 0.436 | Acc: 86.209% (3707/4300)\n",
      "Test Epoch: 23 | Loss: 0.436 | Acc: 86.250% (3795/4400)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.356% (3886/4500)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.348% (3972/4600)\n",
      "Test Epoch: 23 | Loss: 0.432 | Acc: 86.383% (4060/4700)\n",
      "Test Epoch: 23 | Loss: 0.435 | Acc: 86.333% (4144/4800)\n",
      "Test Epoch: 23 | Loss: 0.431 | Acc: 86.449% (4236/4900)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.380% (4319/5000)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.333% (4403/5100)\n",
      "Test Epoch: 23 | Loss: 0.435 | Acc: 86.269% (4486/5200)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.283% (4573/5300)\n",
      "Test Epoch: 23 | Loss: 0.434 | Acc: 86.315% (4661/5400)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 86.145% (4738/5500)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 86.071% (4820/5600)\n",
      "Test Epoch: 23 | Loss: 0.445 | Acc: 86.018% (4903/5700)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 86.103% (4994/5800)\n",
      "Test Epoch: 23 | Loss: 0.444 | Acc: 86.102% (5080/5900)\n",
      "Test Epoch: 23 | Loss: 0.444 | Acc: 86.117% (5167/6000)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.197% (5258/6100)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.210% (5345/6200)\n",
      "Test Epoch: 23 | Loss: 0.438 | Acc: 86.302% (5437/6300)\n",
      "Test Epoch: 23 | Loss: 0.436 | Acc: 86.328% (5525/6400)\n",
      "Test Epoch: 23 | Loss: 0.438 | Acc: 86.262% (5607/6500)\n",
      "Test Epoch: 23 | Loss: 0.436 | Acc: 86.348% (5699/6600)\n",
      "Test Epoch: 23 | Loss: 0.433 | Acc: 86.403% (5789/6700)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 86.235% (5864/6800)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 86.246% (5951/6900)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.100% (6027/7000)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 86.070% (6111/7100)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.986% (6191/7200)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.986% (6277/7300)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.027% (6366/7400)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.973% (6448/7500)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 86.000% (6536/7600)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.896% (6614/7700)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.885% (6699/7800)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.886% (6785/7900)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.888% (6871/8000)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 85.975% (6964/8100)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 85.951% (7048/8200)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 85.916% (7131/8300)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 85.929% (7218/8400)\n",
      "Test Epoch: 23 | Loss: 0.439 | Acc: 85.918% (7303/8500)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.860% (7384/8600)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.874% (7471/8700)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.864% (7556/8800)\n",
      "Test Epoch: 23 | Loss: 0.442 | Acc: 85.854% (7641/8900)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.833% (7725/9000)\n",
      "Test Epoch: 23 | Loss: 0.443 | Acc: 85.846% (7812/9100)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 85.913% (7904/9200)\n",
      "Test Epoch: 23 | Loss: 0.441 | Acc: 85.946% (7993/9300)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 85.915% (8076/9400)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 85.926% (8163/9500)\n",
      "Test Epoch: 23 | Loss: 0.440 | Acc: 85.906% (8247/9600)\n",
      "Test Epoch: 23 | Loss: 0.437 | Acc: 86.000% (8342/9700)\n",
      "Test Epoch: 23 | Loss: 0.438 | Acc: 86.000% (8428/9800)\n",
      "Test Epoch: 23 | Loss: 0.438 | Acc: 85.970% (8511/9900)\n",
      "Test Epoch: 23 | Loss: 0.438 | Acc: 85.980% (8598/10000)\n",
      "\n",
      "Epoch: 24\n",
      "Train Epoch: 24 | Loss: 0.542 | Acc: 81.250% (104/128)\n",
      "Train Epoch: 24 | Loss: 0.434 | Acc: 86.328% (221/256)\n",
      "Train Epoch: 24 | Loss: 0.398 | Acc: 86.719% (333/384)\n",
      "Train Epoch: 24 | Loss: 0.385 | Acc: 87.305% (447/512)\n",
      "Train Epoch: 24 | Loss: 0.378 | Acc: 87.500% (560/640)\n",
      "Train Epoch: 24 | Loss: 0.372 | Acc: 87.760% (674/768)\n",
      "Train Epoch: 24 | Loss: 0.372 | Acc: 87.612% (785/896)\n",
      "Train Epoch: 24 | Loss: 0.377 | Acc: 87.305% (894/1024)\n",
      "Train Epoch: 24 | Loss: 0.379 | Acc: 87.153% (1004/1152)\n",
      "Train Epoch: 24 | Loss: 0.369 | Acc: 87.656% (1122/1280)\n",
      "Train Epoch: 24 | Loss: 0.373 | Acc: 87.358% (1230/1408)\n",
      "Train Epoch: 24 | Loss: 0.374 | Acc: 87.500% (1344/1536)\n",
      "Train Epoch: 24 | Loss: 0.373 | Acc: 87.500% (1456/1664)\n",
      "Train Epoch: 24 | Loss: 0.366 | Acc: 87.891% (1575/1792)\n",
      "Train Epoch: 24 | Loss: 0.366 | Acc: 87.865% (1687/1920)\n",
      "Train Epoch: 24 | Loss: 0.366 | Acc: 87.646% (1795/2048)\n",
      "Train Epoch: 24 | Loss: 0.363 | Acc: 87.776% (1910/2176)\n",
      "Train Epoch: 24 | Loss: 0.365 | Acc: 87.500% (2016/2304)\n",
      "Train Epoch: 24 | Loss: 0.363 | Acc: 87.664% (2132/2432)\n",
      "Train Epoch: 24 | Loss: 0.363 | Acc: 87.734% (2246/2560)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.798% (2360/2688)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.784% (2472/2816)\n",
      "Train Epoch: 24 | Loss: 0.359 | Acc: 87.806% (2585/2944)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 88.021% (2704/3072)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 88.000% (2816/3200)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 88.101% (2932/3328)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 88.079% (3044/3456)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 88.170% (3160/3584)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 88.227% (3275/3712)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.255% (3389/3840)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.306% (3504/3968)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.354% (3619/4096)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.423% (3735/4224)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.396% (3847/4352)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.393% (3960/4480)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.216% (4065/4608)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.302% (4182/4736)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.240% (4292/4864)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.221% (4404/4992)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.262% (4519/5120)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.243% (4631/5248)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.188% (4741/5376)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.154% (4852/5504)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.192% (4967/5632)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.194% (5080/5760)\n",
      "Train Epoch: 24 | Loss: 0.342 | Acc: 88.298% (5199/5888)\n",
      "Train Epoch: 24 | Loss: 0.341 | Acc: 88.348% (5315/6016)\n",
      "Train Epoch: 24 | Loss: 0.341 | Acc: 88.346% (5428/6144)\n",
      "Train Epoch: 24 | Loss: 0.341 | Acc: 88.361% (5542/6272)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.234% (5647/6400)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.251% (5761/6528)\n",
      "Train Epoch: 24 | Loss: 0.342 | Acc: 88.281% (5876/6656)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.281% (5989/6784)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.252% (6100/6912)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.182% (6208/7040)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.211% (6323/7168)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.158% (6432/7296)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.173% (6546/7424)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.122% (6655/7552)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.151% (6770/7680)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.064% (6876/7808)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.117% (6993/7936)\n",
      "Train Epoch: 24 | Loss: 0.342 | Acc: 88.157% (7109/8064)\n",
      "Train Epoch: 24 | Loss: 0.342 | Acc: 88.208% (7226/8192)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.137% (7333/8320)\n",
      "Train Epoch: 24 | Loss: 0.343 | Acc: 88.151% (7447/8448)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.083% (7554/8576)\n",
      "Train Epoch: 24 | Loss: 0.344 | Acc: 88.063% (7665/8704)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.021% (7774/8832)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 87.980% (7883/8960)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.929% (7991/9088)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.858% (8097/9216)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.864% (8210/9344)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.838% (8320/9472)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.854% (8434/9600)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.860% (8547/9728)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.835% (8657/9856)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.851% (8771/9984)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.945% (8893/10112)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 87.969% (9008/10240)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.963% (9120/10368)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.929% (9229/10496)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.886% (9337/10624)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.919% (9453/10752)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.904% (9564/10880)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.900% (9676/11008)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.868% (9785/11136)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.837% (9894/11264)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.807% (10003/11392)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.821% (10117/11520)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.800% (10227/11648)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.780% (10337/11776)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.760% (10447/11904)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.741% (10557/12032)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.738% (10669/12160)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.687% (10775/12288)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.701% (10889/12416)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.651% (10995/12544)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.650% (11107/12672)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.648% (11219/12800)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.701% (11338/12928)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.691% (11449/13056)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.705% (11563/13184)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.740% (11680/13312)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.731% (11791/13440)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.706% (11900/13568)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.712% (12013/13696)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.717% (12126/13824)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.715% (12238/13952)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.720% (12351/14080)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.704% (12461/14208)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.737% (12578/14336)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.742% (12691/14464)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.740% (12803/14592)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.745% (12916/14720)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.756% (13030/14848)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.727% (13138/14976)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.725% (13250/15104)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.763% (13368/15232)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.780% (13483/15360)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.778% (13595/15488)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.782% (13708/15616)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.767% (13818/15744)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.784% (13933/15872)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.756% (14041/16000)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.760% (14154/16128)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.771% (14268/16256)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.769% (14380/16384)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.736% (14487/16512)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.746% (14601/16640)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.750% (14714/16768)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.784% (14832/16896)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.805% (14948/17024)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.826% (15064/17152)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.812% (15174/17280)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.845% (15292/17408)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.854% (15406/17536)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.885% (15524/17664)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.893% (15638/17792)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.902% (15752/17920)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.932% (15870/18048)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.962% (15988/18176)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.953% (16099/18304)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.956% (16212/18432)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.958% (16325/18560)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.971% (16440/18688)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.005% (16559/18816)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.012% (16673/18944)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.019% (16787/19072)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.057% (16907/19200)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.090% (17026/19328)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.112% (17143/19456)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.123% (17258/19584)\n",
      "Train Epoch: 24 | Loss: 0.345 | Acc: 88.104% (17367/19712)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.095% (17478/19840)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.056% (17583/19968)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.032% (17691/20096)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.014% (17800/20224)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.021% (17914/20352)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.052% (18033/20480)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.043% (18144/20608)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.040% (18256/20736)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.051% (18371/20864)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.048% (18483/20992)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.021% (18590/21120)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.022% (18703/21248)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.024% (18816/21376)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.007% (18925/21504)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.990% (19034/21632)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.969% (19142/21760)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.971% (19255/21888)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.963% (19366/22016)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.961% (19478/22144)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.945% (19587/22272)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.973% (19706/22400)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.975% (19819/22528)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.959% (19928/22656)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.987% (20047/22784)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.984% (20159/22912)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.964% (20267/23040)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.979% (20383/23168)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.011% (20503/23296)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.991% (20611/23424)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.993% (20724/23552)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 87.998% (20838/23680)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.033% (20959/23808)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.031% (21071/23936)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.015% (21180/24064)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.021% (21294/24192)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.022% (21407/24320)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.991% (21512/24448)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.992% (21625/24576)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 87.998% (21739/24704)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.003% (21853/24832)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.029% (21972/24960)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.010% (22080/25088)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.020% (22195/25216)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.009% (22305/25344)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.010% (22418/25472)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.000% (22528/25600)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.032% (22649/25728)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.034% (22762/25856)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.046% (22878/25984)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.051% (22992/26112)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.034% (23100/26240)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.057% (23219/26368)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.043% (23328/26496)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.045% (23441/26624)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.064% (23559/26752)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.088% (23678/26880)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.092% (23792/27008)\n",
      "Train Epoch: 24 | Loss: 0.346 | Acc: 88.101% (23907/27136)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.109% (24022/27264)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.110% (24135/27392)\n",
      "Train Epoch: 24 | Loss: 0.347 | Acc: 88.103% (24246/27520)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.082% (24353/27648)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.076% (24464/27776)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.063% (24573/27904)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.046% (24681/28032)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.054% (24796/28160)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.055% (24909/28288)\n",
      "Train Epoch: 24 | Loss: 0.348 | Acc: 88.035% (25016/28416)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.008% (25121/28544)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.995% (25230/28672)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 87.997% (25343/28800)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.008% (25459/28928)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.009% (25572/29056)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.024% (25689/29184)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.032% (25804/29312)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.023% (25914/29440)\n",
      "Train Epoch: 24 | Loss: 0.349 | Acc: 88.017% (26025/29568)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 88.002% (26133/29696)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.990% (26242/29824)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.971% (26349/29952)\n",
      "Train Epoch: 24 | Loss: 0.350 | Acc: 87.982% (26465/30080)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.973% (26575/30208)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.978% (26689/30336)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.966% (26798/30464)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.954% (26907/30592)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.946% (27017/30720)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.947% (27130/30848)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.946% (27242/30976)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.953% (27357/31104)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.942% (27466/31232)\n",
      "Train Epoch: 24 | Loss: 0.351 | Acc: 87.950% (27581/31360)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.919% (27684/31488)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.924% (27798/31616)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.922% (27910/31744)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.930% (28025/31872)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.912% (28132/32000)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.923% (28248/32128)\n",
      "Train Epoch: 24 | Loss: 0.352 | Acc: 87.922% (28360/32256)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.905% (28467/32384)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.897% (28577/32512)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.898% (28690/32640)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.885% (28798/32768)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.880% (28909/32896)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.882% (29022/33024)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.877% (29133/33152)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.879% (29246/33280)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.886% (29361/33408)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.882% (29472/33536)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.883% (29585/33664)\n",
      "Train Epoch: 24 | Loss: 0.353 | Acc: 87.885% (29698/33792)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.886% (29811/33920)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.876% (29920/34048)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.845% (30022/34176)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.838% (30132/34304)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.840% (30245/34432)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.836% (30356/34560)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.843% (30471/34688)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.833% (30580/34816)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.823% (30689/34944)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.828% (30803/35072)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.835% (30918/35200)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.831% (31029/35328)\n",
      "Train Epoch: 24 | Loss: 0.354 | Acc: 87.822% (31138/35456)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.809% (31246/35584)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.808% (31358/35712)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.807% (31470/35840)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.786% (31575/35968)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.796% (31691/36096)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.779% (31797/36224)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.767% (31905/36352)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.771% (32019/36480)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.757% (32126/36608)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.742% (32233/36736)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.744% (32346/36864)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.751% (32461/36992)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.737% (32568/37120)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.744% (32683/37248)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.754% (32799/37376)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.759% (32913/37504)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.768% (33029/37632)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.781% (33146/37760)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.772% (33255/37888)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.776% (33369/38016)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.773% (33480/38144)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.780% (33595/38272)\n",
      "Train Epoch: 24 | Loss: 0.355 | Acc: 87.763% (33701/38400)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.754% (33810/38528)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.735% (33915/38656)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.729% (34025/38784)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.724% (34135/38912)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.728% (34249/39040)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.732% (34363/39168)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.744% (34480/39296)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.746% (34593/39424)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.750% (34707/39552)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.752% (34820/39680)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.751% (34932/39808)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.743% (35041/39936)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.752% (35157/40064)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.744% (35266/40192)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.748% (35380/40320)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.765% (35499/40448)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.761% (35610/40576)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.760% (35722/40704)\n",
      "Train Epoch: 24 | Loss: 0.356 | Acc: 87.752% (35831/40832)\n",
      "Train Epoch: 24 | Loss: 0.357 | Acc: 87.744% (35940/40960)\n",
      "Train Epoch: 24 | Loss: 0.357 | Acc: 87.748% (36054/41088)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.735% (36161/41216)\n",
      "Train Epoch: 24 | Loss: 0.357 | Acc: 87.742% (36276/41344)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.731% (36384/41472)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.731% (36496/41600)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.725% (36606/41728)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.710% (36712/41856)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.710% (36824/41984)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.716% (36939/42112)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.713% (37050/42240)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.712% (37162/42368)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.712% (37274/42496)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.709% (37385/42624)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.706% (37496/42752)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.703% (37607/42880)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.707% (37721/43008)\n",
      "Train Epoch: 24 | Loss: 0.358 | Acc: 87.713% (37836/43136)\n",
      "Train Epoch: 24 | Loss: 0.359 | Acc: 87.706% (37945/43264)\n",
      "Train Epoch: 24 | Loss: 0.359 | Acc: 87.689% (38050/43392)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.672% (38155/43520)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.679% (38270/43648)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.662% (38375/43776)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.657% (38485/43904)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.661% (38599/44032)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.645% (38704/44160)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.633% (38811/44288)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.635% (38924/44416)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.628% (39033/44544)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.634% (39148/44672)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.627% (39257/44800)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.634% (39372/44928)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.624% (39480/45056)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.617% (39589/45184)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.610% (39698/45312)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.621% (39815/45440)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.612% (39923/45568)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.616% (40037/45696)\n",
      "Train Epoch: 24 | Loss: 0.360 | Acc: 87.631% (40156/45824)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.613% (40260/45952)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.606% (40369/46080)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.606% (40481/46208)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.597% (40589/46336)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.597% (40701/46464)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.597% (40813/46592)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.594% (40924/46720)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.594% (41036/46848)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.604% (41153/46976)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.604% (41265/47104)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.604% (41377/47232)\n",
      "Train Epoch: 24 | Loss: 0.361 | Acc: 87.608% (41491/47360)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.610% (41604/47488)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.605% (41714/47616)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.590% (41819/47744)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.590% (41931/47872)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.588% (42042/48000)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.585% (42153/48128)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.593% (42269/48256)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.587% (42378/48384)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.595% (42494/48512)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.584% (42601/48640)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.594% (42718/48768)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.598% (42832/48896)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.600% (42945/49024)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.594% (43054/49152)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.601% (43170/49280)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.587% (43275/49408)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.597% (43392/49536)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.597% (43504/49664)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.608% (43622/49792)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.606% (43733/49920)\n",
      "Train Epoch: 24 | Loss: 0.362 | Acc: 87.600% (43800/50000)\n",
      "Test Epoch: 24 | Loss: 0.378 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 86.500% (173/200)\n",
      "Test Epoch: 24 | Loss: 0.400 | Acc: 87.000% (261/300)\n",
      "Test Epoch: 24 | Loss: 0.387 | Acc: 86.500% (346/400)\n",
      "Test Epoch: 24 | Loss: 0.370 | Acc: 86.400% (432/500)\n",
      "Test Epoch: 24 | Loss: 0.358 | Acc: 87.000% (522/600)\n",
      "Test Epoch: 24 | Loss: 0.380 | Acc: 85.857% (601/700)\n",
      "Test Epoch: 24 | Loss: 0.416 | Acc: 85.000% (680/800)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 84.778% (763/900)\n",
      "Test Epoch: 24 | Loss: 0.423 | Acc: 85.000% (850/1000)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.000% (935/1100)\n",
      "Test Epoch: 24 | Loss: 0.446 | Acc: 84.833% (1018/1200)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 85.077% (1106/1300)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 85.214% (1193/1400)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 85.133% (1277/1500)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.125% (1362/1600)\n",
      "Test Epoch: 24 | Loss: 0.433 | Acc: 85.294% (1450/1700)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 85.389% (1537/1800)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 85.368% (1622/1900)\n",
      "Test Epoch: 24 | Loss: 0.423 | Acc: 85.350% (1707/2000)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 85.000% (1785/2100)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 85.045% (1871/2200)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 85.000% (1955/2300)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 85.000% (2040/2400)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 85.080% (2127/2500)\n",
      "Test Epoch: 24 | Loss: 0.439 | Acc: 85.000% (2210/2600)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 85.185% (2300/2700)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 85.143% (2384/2800)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.138% (2469/2900)\n",
      "Test Epoch: 24 | Loss: 0.441 | Acc: 85.200% (2556/3000)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 85.097% (2638/3100)\n",
      "Test Epoch: 24 | Loss: 0.443 | Acc: 85.125% (2724/3200)\n",
      "Test Epoch: 24 | Loss: 0.442 | Acc: 85.121% (2809/3300)\n",
      "Test Epoch: 24 | Loss: 0.441 | Acc: 85.088% (2893/3400)\n",
      "Test Epoch: 24 | Loss: 0.445 | Acc: 84.886% (2971/3500)\n",
      "Test Epoch: 24 | Loss: 0.442 | Acc: 85.083% (3063/3600)\n",
      "Test Epoch: 24 | Loss: 0.442 | Acc: 85.108% (3149/3700)\n",
      "Test Epoch: 24 | Loss: 0.442 | Acc: 85.026% (3231/3800)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 85.077% (3318/3900)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 85.075% (3403/4000)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 85.049% (3487/4100)\n",
      "Test Epoch: 24 | Loss: 0.440 | Acc: 85.071% (3573/4200)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 85.209% (3664/4300)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.273% (3752/4400)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.289% (3838/4500)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.261% (3922/4600)\n",
      "Test Epoch: 24 | Loss: 0.432 | Acc: 85.319% (4010/4700)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 85.188% (4089/4800)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 85.265% (4178/4900)\n",
      "Test Epoch: 24 | Loss: 0.437 | Acc: 85.220% (4261/5000)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 85.235% (4347/5100)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 85.192% (4430/5200)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.151% (4513/5300)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 85.222% (4602/5400)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.200% (4686/5500)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.286% (4776/5600)\n",
      "Test Epoch: 24 | Loss: 0.438 | Acc: 85.298% (4862/5700)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.414% (4954/5800)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.407% (5039/5900)\n",
      "Test Epoch: 24 | Loss: 0.436 | Acc: 85.317% (5119/6000)\n",
      "Test Epoch: 24 | Loss: 0.435 | Acc: 85.279% (5202/6100)\n",
      "Test Epoch: 24 | Loss: 0.434 | Acc: 85.306% (5289/6200)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 85.397% (5380/6300)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 85.438% (5468/6400)\n",
      "Test Epoch: 24 | Loss: 0.431 | Acc: 85.415% (5552/6500)\n",
      "Test Epoch: 24 | Loss: 0.430 | Acc: 85.500% (5643/6600)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 85.567% (5733/6700)\n",
      "Test Epoch: 24 | Loss: 0.427 | Acc: 85.574% (5819/6800)\n",
      "Test Epoch: 24 | Loss: 0.426 | Acc: 85.594% (5906/6900)\n",
      "Test Epoch: 24 | Loss: 0.428 | Acc: 85.571% (5990/7000)\n",
      "Test Epoch: 24 | Loss: 0.429 | Acc: 85.606% (6078/7100)\n",
      "Test Epoch: 24 | Loss: 0.429 | Acc: 85.625% (6165/7200)\n",
      "Test Epoch: 24 | Loss: 0.425 | Acc: 85.712% (6257/7300)\n",
      "Test Epoch: 24 | Loss: 0.423 | Acc: 85.797% (6349/7400)\n",
      "Test Epoch: 24 | Loss: 0.422 | Acc: 85.827% (6437/7500)\n",
      "Test Epoch: 24 | Loss: 0.422 | Acc: 85.842% (6524/7600)\n",
      "Test Epoch: 24 | Loss: 0.424 | Acc: 85.805% (6607/7700)\n",
      "Test Epoch: 24 | Loss: 0.422 | Acc: 85.808% (6693/7800)\n",
      "Test Epoch: 24 | Loss: 0.422 | Acc: 85.810% (6779/7900)\n",
      "Test Epoch: 24 | Loss: 0.421 | Acc: 85.862% (6869/8000)\n",
      "Test Epoch: 24 | Loss: 0.418 | Acc: 85.938% (6961/8100)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 85.951% (7048/8200)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 85.928% (7132/8300)\n",
      "Test Epoch: 24 | Loss: 0.416 | Acc: 85.976% (7222/8400)\n",
      "Test Epoch: 24 | Loss: 0.418 | Acc: 85.906% (7302/8500)\n",
      "Test Epoch: 24 | Loss: 0.419 | Acc: 85.895% (7387/8600)\n",
      "Test Epoch: 24 | Loss: 0.418 | Acc: 85.931% (7476/8700)\n",
      "Test Epoch: 24 | Loss: 0.418 | Acc: 85.898% (7559/8800)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 85.933% (7648/8900)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 85.956% (7736/9000)\n",
      "Test Epoch: 24 | Loss: 0.417 | Acc: 85.923% (7819/9100)\n",
      "Test Epoch: 24 | Loss: 0.415 | Acc: 86.011% (7913/9200)\n",
      "Test Epoch: 24 | Loss: 0.415 | Acc: 86.000% (7998/9300)\n",
      "Test Epoch: 24 | Loss: 0.415 | Acc: 86.021% (8086/9400)\n",
      "Test Epoch: 24 | Loss: 0.414 | Acc: 86.042% (8174/9500)\n",
      "Test Epoch: 24 | Loss: 0.414 | Acc: 86.083% (8264/9600)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.134% (8355/9700)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.112% (8439/9800)\n",
      "Test Epoch: 24 | Loss: 0.414 | Acc: 86.071% (8521/9900)\n",
      "Test Epoch: 24 | Loss: 0.413 | Acc: 86.120% (8612/10000)\n",
      "\n",
      "Epoch: 25\n",
      "Train Epoch: 25 | Loss: 0.296 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 25 | Loss: 0.281 | Acc: 89.453% (229/256)\n",
      "Train Epoch: 25 | Loss: 0.330 | Acc: 88.281% (339/384)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.891% (450/512)\n",
      "Train Epoch: 25 | Loss: 0.389 | Acc: 87.031% (557/640)\n",
      "Train Epoch: 25 | Loss: 0.397 | Acc: 86.458% (664/768)\n",
      "Train Epoch: 25 | Loss: 0.395 | Acc: 86.049% (771/896)\n",
      "Train Epoch: 25 | Loss: 0.383 | Acc: 86.621% (887/1024)\n",
      "Train Epoch: 25 | Loss: 0.375 | Acc: 86.892% (1001/1152)\n",
      "Train Epoch: 25 | Loss: 0.379 | Acc: 86.875% (1112/1280)\n",
      "Train Epoch: 25 | Loss: 0.383 | Acc: 86.932% (1224/1408)\n",
      "Train Epoch: 25 | Loss: 0.375 | Acc: 87.305% (1341/1536)\n",
      "Train Epoch: 25 | Loss: 0.369 | Acc: 87.500% (1456/1664)\n",
      "Train Epoch: 25 | Loss: 0.369 | Acc: 87.333% (1565/1792)\n",
      "Train Epoch: 25 | Loss: 0.371 | Acc: 87.083% (1672/1920)\n",
      "Train Epoch: 25 | Loss: 0.369 | Acc: 87.207% (1786/2048)\n",
      "Train Epoch: 25 | Loss: 0.368 | Acc: 87.316% (1900/2176)\n",
      "Train Epoch: 25 | Loss: 0.366 | Acc: 87.326% (2012/2304)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.418% (2126/2432)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.422% (2238/2560)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.388% (2349/2688)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.536% (2465/2816)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.670% (2581/2944)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.695% (2694/3072)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 87.719% (2807/3200)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.500% (2912/3328)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.645% (3029/3456)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.556% (3138/3584)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 87.689% (3255/3712)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.760% (3370/3840)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.651% (3478/3968)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.549% (3586/4096)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.571% (3699/4224)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.592% (3812/4352)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.500% (3920/4480)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.543% (4034/4608)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.606% (4149/4736)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.685% (4265/4864)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.660% (4376/4992)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.773% (4494/5120)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.710% (4603/5248)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.723% (4716/5376)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.773% (4831/5504)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.749% (4942/5632)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.760% (5055/5760)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.806% (5170/5888)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.733% (5278/6016)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.809% (5395/6144)\n",
      "Train Epoch: 25 | Loss: 0.351 | Acc: 87.899% (5513/6272)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.766% (5617/6400)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.791% (5731/6528)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.725% (5839/6656)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.751% (5953/6784)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.804% (6069/6912)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.812% (6182/7040)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.863% (6298/7168)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.802% (6406/7296)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.796% (6518/7424)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.765% (6628/7552)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.799% (6743/7680)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.769% (6853/7808)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.790% (6967/7936)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.822% (7082/8064)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.830% (7195/8192)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.861% (7310/8320)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.843% (7421/8448)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.838% (7533/8576)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.810% (7643/8704)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.851% (7759/8832)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.868% (7873/8960)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.918% (7990/9088)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.934% (8104/9216)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.928% (8216/9344)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.922% (8328/9472)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.885% (8437/9600)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.880% (8549/9728)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.916% (8665/9856)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.901% (8776/9984)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.925% (8891/10112)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.910% (9002/10240)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.886% (9112/10368)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.843% (9220/10496)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.886% (9337/10624)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.900% (9451/10752)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.895% (9563/10880)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.918% (9678/11008)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.985% (9798/11136)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.917% (9903/11264)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.956% (10020/11392)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.986% (10136/11520)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.964% (10246/11648)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 88.010% (10364/11776)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.987% (10474/11904)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.965% (10584/12032)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.993% (10700/12160)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 88.021% (10816/12288)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.983% (10924/12416)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 88.002% (11039/12544)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 88.013% (11153/12672)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 88.000% (11264/12800)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 88.003% (11377/12928)\n",
      "Train Epoch: 25 | Loss: 0.351 | Acc: 87.998% (11489/13056)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 87.978% (11599/13184)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.921% (11704/13312)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.939% (11819/13440)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.920% (11929/13568)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.894% (12038/13696)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.891% (12150/13824)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.887% (12262/13952)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.884% (12374/14080)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.859% (12483/14208)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.842% (12593/14336)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.860% (12708/14464)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.843% (12818/14592)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.826% (12928/14720)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.857% (13045/14848)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.874% (13160/14976)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.891% (13275/15104)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.894% (13388/15232)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.891% (13500/15360)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.881% (13611/15488)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.897% (13726/15616)\n",
      "Train Epoch: 25 | Loss: 0.352 | Acc: 87.919% (13842/15744)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.859% (13945/15872)\n",
      "Train Epoch: 25 | Loss: 0.353 | Acc: 87.862% (14058/16000)\n",
      "Train Epoch: 25 | Loss: 0.354 | Acc: 87.829% (14165/16128)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.777% (14269/16256)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.799% (14385/16384)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.779% (14494/16512)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.800% (14610/16640)\n",
      "Train Epoch: 25 | Loss: 0.355 | Acc: 87.822% (14726/16768)\n",
      "Train Epoch: 25 | Loss: 0.356 | Acc: 87.814% (14837/16896)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.782% (14944/17024)\n",
      "Train Epoch: 25 | Loss: 0.357 | Acc: 87.786% (15057/17152)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.755% (15164/17280)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.747% (15275/17408)\n",
      "Train Epoch: 25 | Loss: 0.358 | Acc: 87.711% (15381/17536)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.687% (15489/17664)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.629% (15591/17792)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.600% (15698/17920)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.550% (15801/18048)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.550% (15913/18176)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.544% (16024/18304)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.522% (16132/18432)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.538% (16247/18560)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.537% (16359/18688)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.553% (16474/18816)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.511% (16578/18944)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.521% (16692/19072)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.526% (16805/19200)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.479% (16908/19328)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.490% (17022/19456)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.526% (17141/19584)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.541% (17256/19712)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.555% (17371/19840)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.570% (17486/19968)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.595% (17603/20096)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.619% (17720/20224)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.584% (17825/20352)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.568% (17934/20480)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.578% (18048/20608)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.592% (18163/20736)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.577% (18272/20864)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.591% (18387/20992)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.557% (18492/21120)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.580% (18609/21248)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.575% (18720/21376)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.533% (18823/21504)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.565% (18942/21632)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.555% (19052/21760)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.587% (19171/21888)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.600% (19286/22016)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.581% (19394/22144)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.599% (19510/22272)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.607% (19624/22400)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.593% (19733/22528)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.593% (19845/22656)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.597% (19958/22784)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.609% (20073/22912)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.582% (20179/23040)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.586% (20292/23168)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.573% (20401/23296)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.577% (20514/23424)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.576% (20626/23552)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.568% (20736/23680)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.567% (20848/23808)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.550% (20956/23936)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.562% (21071/24064)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.570% (21185/24192)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.566% (21296/24320)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.549% (21404/24448)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.533% (21512/24576)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.536% (21625/24704)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.540% (21738/24832)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.520% (21845/24960)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.524% (21958/25088)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.524% (22070/25216)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.520% (22181/25344)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.524% (22294/25472)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.535% (22409/25600)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.554% (22526/25728)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.531% (22632/25856)\n",
      "Train Epoch: 25 | Loss: 0.364 | Acc: 87.535% (22745/25984)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.561% (22864/26112)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.584% (22982/26240)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.599% (23098/26368)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.594% (23209/26496)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.579% (23317/26624)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.593% (23433/26752)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.597% (23546/26880)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.607% (23661/27008)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.581% (23766/27136)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.570% (23875/27264)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.566% (23986/27392)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.573% (24100/27520)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.561% (24209/27648)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.568% (24323/27776)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.568% (24435/27904)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.564% (24546/28032)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.557% (24656/28160)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.564% (24770/28288)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.588% (24889/28416)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.595% (25003/28544)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.619% (25122/28672)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.615% (25233/28800)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.624% (25348/28928)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.620% (25459/29056)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.606% (25567/29184)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.619% (25683/29312)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.609% (25792/29440)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.622% (25908/29568)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.638% (26025/29696)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.644% (26139/29824)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.630% (26247/29952)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.616% (26355/30080)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.606% (26464/30208)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.596% (26573/30336)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.589% (26683/30464)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.585% (26794/30592)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.572% (26902/30720)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.558% (27010/30848)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.558% (27122/30976)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.574% (27239/31104)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.580% (27353/31232)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.573% (27463/31360)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.592% (27581/31488)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.592% (27693/31616)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.598% (27807/31744)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.604% (27921/31872)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.609% (28035/32000)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.612% (28148/32128)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.633% (28267/32256)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.611% (28372/32384)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.589% (28477/32512)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.595% (28591/32640)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.573% (28696/32768)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.570% (28807/32896)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.579% (28922/33024)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.578% (29034/33152)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.581% (29147/33280)\n",
      "Train Epoch: 25 | Loss: 0.363 | Acc: 87.581% (29259/33408)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.589% (29374/33536)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.601% (29490/33664)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.612% (29606/33792)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.615% (29719/33920)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.626% (29835/34048)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.626% (29947/34176)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.617% (30056/34304)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.619% (30169/34432)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.630% (30285/34560)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.633% (30398/34688)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.638% (30512/34816)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.635% (30623/34944)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.617% (30729/35072)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.628% (30845/35200)\n",
      "Train Epoch: 25 | Loss: 0.362 | Acc: 87.625% (30956/35328)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.647% (31076/35456)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.635% (31184/35584)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.634% (31296/35712)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.640% (31410/35840)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.642% (31523/35968)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.652% (31639/36096)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.663% (31755/36224)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.679% (31873/36352)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.681% (31986/36480)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.683% (32099/36608)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.696% (32216/36736)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.682% (32323/36864)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.687% (32437/36992)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.672% (32544/37120)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.672% (32656/37248)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.671% (32768/37376)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.689% (32887/37504)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.691% (33000/37632)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.696% (33114/37760)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.698% (33227/37888)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.705% (33342/38016)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.712% (33457/38144)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.712% (33569/38272)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.714% (33682/38400)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.684% (33783/38528)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.668% (33889/38656)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.678% (34005/38784)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.693% (34123/38912)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.692% (34235/39040)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.704% (34352/39168)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.714% (34468/39296)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.718% (34582/39424)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.720% (34695/39552)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.729% (34811/39680)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.724% (34921/39808)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.723% (35033/39936)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.735% (35150/40064)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.736% (35263/40192)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.723% (35370/40320)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.713% (35478/40448)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.709% (35589/40576)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.706% (35700/40704)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.703% (35811/40832)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.710% (35926/40960)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.724% (36044/41088)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.711% (36151/41216)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.708% (36262/41344)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.712% (36376/41472)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.709% (36487/41600)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.730% (36608/41728)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.722% (36717/41856)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.733% (36834/41984)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.721% (36941/42112)\n",
      "Train Epoch: 25 | Loss: 0.359 | Acc: 87.708% (37048/42240)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.691% (37153/42368)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.676% (37259/42496)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.681% (37373/42624)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.659% (37476/42752)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.680% (37597/42880)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.646% (37695/43008)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.651% (37809/43136)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.655% (37923/43264)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.657% (38036/43392)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.654% (38147/43520)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.649% (38257/43648)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.648% (38369/43776)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.653% (38483/43904)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.668% (38602/44032)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.670% (38715/44160)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.674% (38829/44288)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.678% (38943/44416)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.673% (39053/44544)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.672% (39165/44672)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.676% (39279/44800)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.685% (39395/44928)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.671% (39501/45056)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.670% (39613/45184)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.657% (39719/45312)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.652% (39829/45440)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.638% (39935/45568)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.642% (40049/45696)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.659% (40169/45824)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.661% (40282/45952)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.656% (40392/46080)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.654% (40503/46208)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.634% (40606/46336)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.631% (40717/46464)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.633% (40830/46592)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.635% (40943/46720)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.645% (41060/46848)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.640% (41170/46976)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.642% (41283/47104)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.648% (41398/47232)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.646% (41509/47360)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.641% (41619/47488)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.643% (41732/47616)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.642% (41844/47744)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.644% (41957/47872)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.640% (42067/48000)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.641% (42180/48128)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.635% (42289/48256)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.643% (42405/48384)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.646% (42519/48512)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.638% (42627/48640)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.631% (42736/48768)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.633% (42849/48896)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.631% (42960/49024)\n",
      "Train Epoch: 25 | Loss: 0.360 | Acc: 87.640% (43077/49152)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.632% (43185/49280)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.617% (43290/49408)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.613% (43400/49536)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.611% (43511/49664)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.623% (43629/49792)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.630% (43745/49920)\n",
      "Train Epoch: 25 | Loss: 0.361 | Acc: 87.630% (43815/50000)\n",
      "Test Epoch: 25 | Loss: 0.364 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 25 | Loss: 0.360 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 25 | Loss: 0.370 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 25 | Loss: 0.353 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 25 | Loss: 0.344 | Acc: 87.200% (436/500)\n",
      "Test Epoch: 25 | Loss: 0.324 | Acc: 88.167% (529/600)\n",
      "Test Epoch: 25 | Loss: 0.332 | Acc: 87.857% (615/700)\n",
      "Test Epoch: 25 | Loss: 0.357 | Acc: 86.750% (694/800)\n",
      "Test Epoch: 25 | Loss: 0.370 | Acc: 86.889% (782/900)\n",
      "Test Epoch: 25 | Loss: 0.362 | Acc: 87.200% (872/1000)\n",
      "Test Epoch: 25 | Loss: 0.364 | Acc: 86.818% (955/1100)\n",
      "Test Epoch: 25 | Loss: 0.380 | Acc: 86.583% (1039/1200)\n",
      "Test Epoch: 25 | Loss: 0.374 | Acc: 86.692% (1127/1300)\n",
      "Test Epoch: 25 | Loss: 0.369 | Acc: 86.929% (1217/1400)\n",
      "Test Epoch: 25 | Loss: 0.367 | Acc: 86.800% (1302/1500)\n",
      "Test Epoch: 25 | Loss: 0.370 | Acc: 86.875% (1390/1600)\n",
      "Test Epoch: 25 | Loss: 0.370 | Acc: 86.941% (1478/1700)\n",
      "Test Epoch: 25 | Loss: 0.375 | Acc: 86.833% (1563/1800)\n",
      "Test Epoch: 25 | Loss: 0.378 | Acc: 86.684% (1647/1900)\n",
      "Test Epoch: 25 | Loss: 0.381 | Acc: 86.500% (1730/2000)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.429% (1815/2100)\n",
      "Test Epoch: 25 | Loss: 0.378 | Acc: 86.591% (1905/2200)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.522% (1990/2300)\n",
      "Test Epoch: 25 | Loss: 0.378 | Acc: 86.667% (2080/2400)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.720% (2168/2500)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.615% (2252/2600)\n",
      "Test Epoch: 25 | Loss: 0.387 | Acc: 86.815% (2344/2700)\n",
      "Test Epoch: 25 | Loss: 0.392 | Acc: 86.679% (2427/2800)\n",
      "Test Epoch: 25 | Loss: 0.390 | Acc: 86.828% (2518/2900)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.800% (2604/3000)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 86.548% (2683/3100)\n",
      "Test Epoch: 25 | Loss: 0.399 | Acc: 86.531% (2769/3200)\n",
      "Test Epoch: 25 | Loss: 0.397 | Acc: 86.576% (2857/3300)\n",
      "Test Epoch: 25 | Loss: 0.396 | Acc: 86.529% (2942/3400)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 86.514% (3028/3500)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 86.556% (3116/3600)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 86.514% (3201/3700)\n",
      "Test Epoch: 25 | Loss: 0.400 | Acc: 86.500% (3287/3800)\n",
      "Test Epoch: 25 | Loss: 0.398 | Acc: 86.564% (3376/3900)\n",
      "Test Epoch: 25 | Loss: 0.394 | Acc: 86.675% (3467/4000)\n",
      "Test Epoch: 25 | Loss: 0.395 | Acc: 86.659% (3553/4100)\n",
      "Test Epoch: 25 | Loss: 0.396 | Acc: 86.548% (3635/4200)\n",
      "Test Epoch: 25 | Loss: 0.393 | Acc: 86.651% (3726/4300)\n",
      "Test Epoch: 25 | Loss: 0.392 | Acc: 86.727% (3816/4400)\n",
      "Test Epoch: 25 | Loss: 0.392 | Acc: 86.800% (3906/4500)\n",
      "Test Epoch: 25 | Loss: 0.394 | Acc: 86.674% (3987/4600)\n",
      "Test Epoch: 25 | Loss: 0.394 | Acc: 86.660% (4073/4700)\n",
      "Test Epoch: 25 | Loss: 0.397 | Acc: 86.562% (4155/4800)\n",
      "Test Epoch: 25 | Loss: 0.393 | Acc: 86.653% (4246/4900)\n",
      "Test Epoch: 25 | Loss: 0.395 | Acc: 86.640% (4332/5000)\n",
      "Test Epoch: 25 | Loss: 0.393 | Acc: 86.686% (4421/5100)\n",
      "Test Epoch: 25 | Loss: 0.392 | Acc: 86.750% (4511/5200)\n",
      "Test Epoch: 25 | Loss: 0.392 | Acc: 86.736% (4597/5300)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.722% (4683/5400)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.727% (4770/5500)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.661% (4853/5600)\n",
      "Test Epoch: 25 | Loss: 0.393 | Acc: 86.614% (4937/5700)\n",
      "Test Epoch: 25 | Loss: 0.390 | Acc: 86.655% (5026/5800)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.712% (5116/5900)\n",
      "Test Epoch: 25 | Loss: 0.391 | Acc: 86.650% (5199/6000)\n",
      "Test Epoch: 25 | Loss: 0.390 | Acc: 86.689% (5288/6100)\n",
      "Test Epoch: 25 | Loss: 0.389 | Acc: 86.710% (5376/6200)\n",
      "Test Epoch: 25 | Loss: 0.387 | Acc: 86.730% (5464/6300)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.797% (5555/6400)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.785% (5641/6500)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.818% (5730/6600)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.910% (5823/6700)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.779% (5901/6800)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.812% (5990/6900)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.743% (6072/7000)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.761% (6160/7100)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.736% (6245/7200)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.795% (6336/7300)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.797% (6423/7400)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.787% (6509/7500)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.816% (6598/7600)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.792% (6683/7700)\n",
      "Test Epoch: 25 | Loss: 0.381 | Acc: 86.846% (6774/7800)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.848% (6861/7900)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.850% (6948/8000)\n",
      "Test Epoch: 25 | Loss: 0.380 | Acc: 86.889% (7038/8100)\n",
      "Test Epoch: 25 | Loss: 0.380 | Acc: 86.866% (7123/8200)\n",
      "Test Epoch: 25 | Loss: 0.381 | Acc: 86.843% (7208/8300)\n",
      "Test Epoch: 25 | Loss: 0.379 | Acc: 86.857% (7296/8400)\n",
      "Test Epoch: 25 | Loss: 0.380 | Acc: 86.871% (7384/8500)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.791% (7464/8600)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.816% (7553/8700)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.784% (7637/8800)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.753% (7721/8900)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.722% (7805/9000)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.714% (7891/9100)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.761% (7982/9200)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.774% (8070/9300)\n",
      "Test Epoch: 25 | Loss: 0.385 | Acc: 86.766% (8156/9400)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.779% (8244/9500)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.802% (8333/9600)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.845% (8424/9700)\n",
      "Test Epoch: 25 | Loss: 0.382 | Acc: 86.878% (8514/9800)\n",
      "Test Epoch: 25 | Loss: 0.383 | Acc: 86.838% (8597/9900)\n",
      "Test Epoch: 25 | Loss: 0.384 | Acc: 86.850% (8685/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 26\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 88.281% (113/128)\n",
      "Train Epoch: 26 | Loss: 0.317 | Acc: 89.062% (228/256)\n",
      "Train Epoch: 26 | Loss: 0.320 | Acc: 88.802% (341/384)\n",
      "Train Epoch: 26 | Loss: 0.309 | Acc: 89.453% (458/512)\n",
      "Train Epoch: 26 | Loss: 0.294 | Acc: 89.375% (572/640)\n",
      "Train Epoch: 26 | Loss: 0.318 | Acc: 88.932% (683/768)\n",
      "Train Epoch: 26 | Loss: 0.299 | Acc: 89.509% (802/896)\n",
      "Train Epoch: 26 | Loss: 0.307 | Acc: 89.062% (912/1024)\n",
      "Train Epoch: 26 | Loss: 0.305 | Acc: 89.149% (1027/1152)\n",
      "Train Epoch: 26 | Loss: 0.318 | Acc: 88.828% (1137/1280)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.210% (1242/1408)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.411% (1358/1536)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.401% (1471/1664)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.672% (1589/1792)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.802% (1705/1920)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.721% (1817/2048)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.511% (1926/2176)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.498% (2039/2304)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.487% (2152/2432)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.516% (2266/2560)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.393% (2376/2688)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.246% (2485/2816)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.111% (2594/2944)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.281% (2712/3072)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.250% (2824/3200)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.341% (2940/3328)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.252% (3050/3456)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.253% (3163/3584)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.308% (3278/3712)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.359% (3393/3840)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.332% (3505/3968)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.281% (3616/4096)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.352% (3732/4224)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.465% (3850/4352)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.527% (3966/4480)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.563% (4081/4608)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.640% (4198/4736)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.590% (4309/4864)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.542% (4420/4992)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.516% (4532/5120)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.510% (4645/5248)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.579% (4762/5376)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.517% (4872/5504)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.494% (4984/5632)\n",
      "Train Epoch: 26 | Loss: 0.325 | Acc: 88.524% (5099/5760)\n",
      "Train Epoch: 26 | Loss: 0.321 | Acc: 88.672% (5221/5888)\n",
      "Train Epoch: 26 | Loss: 0.321 | Acc: 88.664% (5334/6016)\n",
      "Train Epoch: 26 | Loss: 0.321 | Acc: 88.672% (5448/6144)\n",
      "Train Epoch: 26 | Loss: 0.322 | Acc: 88.680% (5562/6272)\n",
      "Train Epoch: 26 | Loss: 0.320 | Acc: 88.766% (5681/6400)\n",
      "Train Epoch: 26 | Loss: 0.320 | Acc: 88.756% (5794/6528)\n",
      "Train Epoch: 26 | Loss: 0.322 | Acc: 88.732% (5906/6656)\n",
      "Train Epoch: 26 | Loss: 0.323 | Acc: 88.723% (6019/6784)\n",
      "Train Epoch: 26 | Loss: 0.325 | Acc: 88.759% (6135/6912)\n",
      "Train Epoch: 26 | Loss: 0.325 | Acc: 88.736% (6247/7040)\n",
      "Train Epoch: 26 | Loss: 0.326 | Acc: 88.700% (6358/7168)\n",
      "Train Epoch: 26 | Loss: 0.324 | Acc: 88.747% (6475/7296)\n",
      "Train Epoch: 26 | Loss: 0.324 | Acc: 88.726% (6587/7424)\n",
      "Train Epoch: 26 | Loss: 0.326 | Acc: 88.639% (6694/7552)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.555% (6801/7680)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.537% (6913/7808)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.483% (7022/7936)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.542% (7140/8064)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.513% (7251/8192)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.582% (7370/8320)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.554% (7481/8448)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.538% (7593/8576)\n",
      "Train Epoch: 26 | Loss: 0.326 | Acc: 88.557% (7708/8704)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.519% (7818/8832)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.482% (7928/8960)\n",
      "Train Epoch: 26 | Loss: 0.327 | Acc: 88.490% (8042/9088)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.466% (8153/9216)\n",
      "Train Epoch: 26 | Loss: 0.328 | Acc: 88.452% (8265/9344)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.408% (8374/9472)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.375% (8484/9600)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.435% (8603/9728)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.413% (8714/9856)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.442% (8830/9984)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.469% (8946/10112)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.467% (9059/10240)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.436% (9169/10368)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.491% (9288/10496)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.498% (9402/10624)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.486% (9514/10752)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.520% (9631/10880)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.572% (9750/11008)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.551% (9861/11136)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.583% (9978/11264)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.527% (10085/11392)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.498% (10195/11520)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.479% (10306/11648)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.477% (10419/11776)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.491% (10534/11904)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.514% (10650/12032)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.446% (10755/12160)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.420% (10865/12288)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.378% (10973/12416)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.393% (11088/12544)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.408% (11203/12672)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.438% (11320/12800)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.436% (11433/12928)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.457% (11549/13056)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.433% (11659/13184)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.401% (11768/13312)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.415% (11883/13440)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.421% (11997/13568)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.456% (12115/13696)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.433% (12225/13824)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.460% (12342/13952)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.501% (12461/14080)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.478% (12571/14208)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.491% (12686/14336)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.516% (12803/14464)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.528% (12918/14592)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.526% (13031/14720)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.517% (13143/14848)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.548% (13261/14976)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.526% (13371/15104)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.564% (13490/15232)\n",
      "Train Epoch: 26 | Loss: 0.329 | Acc: 88.561% (13603/15360)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.565% (13717/15488)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.525% (13824/15616)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.523% (13937/15744)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.533% (14052/15872)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.575% (14172/16000)\n",
      "Train Epoch: 26 | Loss: 0.330 | Acc: 88.585% (14287/16128)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.540% (14393/16256)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.525% (14504/16384)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.560% (14623/16512)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.546% (14734/16640)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.579% (14853/16768)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.577% (14966/16896)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.604% (15084/17024)\n",
      "Train Epoch: 26 | Loss: 0.331 | Acc: 88.579% (15193/17152)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.571% (15305/17280)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.586% (15421/17408)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.555% (15529/17536)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.525% (15637/17664)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.512% (15748/17792)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.499% (15859/17920)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.508% (15974/18048)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.507% (16087/18176)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.516% (16202/18304)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.515% (16315/18432)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.524% (16430/18560)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.527% (16544/18688)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.510% (16654/18816)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.498% (16765/18944)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.501% (16879/19072)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.531% (16998/19200)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.524% (17110/19328)\n",
      "Train Epoch: 26 | Loss: 0.332 | Acc: 88.543% (17227/19456)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.516% (17335/19584)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.484% (17442/19712)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.483% (17555/19840)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.472% (17666/19968)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.465% (17778/20096)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.454% (17889/20224)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.473% (18006/20352)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.452% (18115/20480)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.456% (18229/20608)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.450% (18341/20736)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.473% (18459/20864)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.496% (18577/20992)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.513% (18694/21120)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.521% (18809/21248)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.529% (18924/21376)\n",
      "Train Epoch: 26 | Loss: 0.333 | Acc: 88.532% (19038/21504)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.499% (19144/21632)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.470% (19251/21760)\n",
      "Train Epoch: 26 | Loss: 0.334 | Acc: 88.446% (19359/21888)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.449% (19473/22016)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.448% (19586/22144)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.465% (19703/22272)\n",
      "Train Epoch: 26 | Loss: 0.335 | Acc: 88.469% (19817/22400)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.472% (19931/22528)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.453% (20040/22656)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.461% (20155/22784)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.451% (20266/22912)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.455% (20380/23040)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.463% (20495/23168)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.483% (20613/23296)\n",
      "Train Epoch: 26 | Loss: 0.337 | Acc: 88.473% (20724/23424)\n",
      "Train Epoch: 26 | Loss: 0.337 | Acc: 88.472% (20837/23552)\n",
      "Train Epoch: 26 | Loss: 0.337 | Acc: 88.480% (20952/23680)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.474% (21064/23808)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.465% (21175/23936)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.464% (21288/24064)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.455% (21399/24192)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.438% (21508/24320)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.461% (21627/24448)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.468% (21742/24576)\n",
      "Train Epoch: 26 | Loss: 0.336 | Acc: 88.455% (21852/24704)\n",
      "Train Epoch: 26 | Loss: 0.337 | Acc: 88.442% (21962/24832)\n",
      "Train Epoch: 26 | Loss: 0.337 | Acc: 88.429% (22072/24960)\n",
      "Train Epoch: 26 | Loss: 0.338 | Acc: 88.413% (22181/25088)\n",
      "Train Epoch: 26 | Loss: 0.338 | Acc: 88.400% (22291/25216)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.384% (22400/25344)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.368% (22509/25472)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.355% (22619/25600)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.355% (22732/25728)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.362% (22847/25856)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.343% (22955/25984)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.346% (23069/26112)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.342% (23181/26240)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.361% (23299/26368)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.342% (23407/26496)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.341% (23520/26624)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.360% (23638/26752)\n",
      "Train Epoch: 26 | Loss: 0.339 | Acc: 88.363% (23752/26880)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.333% (23857/27008)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.318% (23966/27136)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.314% (24078/27264)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.332% (24196/27392)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.314% (24304/27520)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.321% (24419/27648)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.303% (24527/27776)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.303% (24640/27904)\n",
      "Train Epoch: 26 | Loss: 0.341 | Acc: 88.288% (24749/28032)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.306% (24867/28160)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.313% (24982/28288)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.306% (25093/28416)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.309% (25207/28544)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.302% (25318/28672)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.302% (25431/28800)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.292% (25541/28928)\n",
      "Train Epoch: 26 | Loss: 0.340 | Acc: 88.285% (25652/29056)\n",
      "Train Epoch: 26 | Loss: 0.341 | Acc: 88.247% (25754/29184)\n",
      "Train Epoch: 26 | Loss: 0.341 | Acc: 88.237% (25864/29312)\n",
      "Train Epoch: 26 | Loss: 0.342 | Acc: 88.237% (25977/29440)\n",
      "Train Epoch: 26 | Loss: 0.342 | Acc: 88.241% (26091/29568)\n",
      "Train Epoch: 26 | Loss: 0.342 | Acc: 88.241% (26204/29696)\n",
      "Train Epoch: 26 | Loss: 0.342 | Acc: 88.241% (26317/29824)\n",
      "Train Epoch: 26 | Loss: 0.342 | Acc: 88.231% (26427/29952)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.201% (26531/30080)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.198% (26643/30208)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.209% (26759/30336)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.199% (26869/30464)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.173% (26974/30592)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.167% (27085/30720)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.174% (27200/30848)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.181% (27315/30976)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.175% (27426/31104)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.176% (27539/31232)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.179% (27653/31360)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.186% (27768/31488)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.186% (27881/31616)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.199% (27998/31744)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.197% (28110/31872)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.209% (28227/32000)\n",
      "Train Epoch: 26 | Loss: 0.343 | Acc: 88.203% (28338/32128)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.185% (28445/32256)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.189% (28559/32384)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.198% (28675/32512)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.199% (28788/32640)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.193% (28899/32768)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.199% (29014/32896)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.206% (29129/33024)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.197% (29239/33152)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.182% (29347/33280)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.194% (29464/33408)\n",
      "Train Epoch: 26 | Loss: 0.344 | Acc: 88.180% (29572/33536)\n",
      "Train Epoch: 26 | Loss: 0.345 | Acc: 88.168% (29681/33664)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.139% (29784/33792)\n",
      "Train Epoch: 26 | Loss: 0.345 | Acc: 88.143% (29898/33920)\n",
      "Train Epoch: 26 | Loss: 0.345 | Acc: 88.137% (30009/34048)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.126% (30118/34176)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.130% (30232/34304)\n",
      "Train Epoch: 26 | Loss: 0.345 | Acc: 88.142% (30349/34432)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.131% (30458/34560)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.140% (30574/34688)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.149% (30690/34816)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.135% (30798/34944)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.150% (30916/35072)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.136% (31024/35200)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.145% (31140/35328)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.149% (31254/35456)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.141% (31364/35584)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.124% (31471/35712)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.128% (31585/35840)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.134% (31700/35968)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.104% (31802/36096)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.107% (31916/36224)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.100% (32026/36352)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.087% (32134/36480)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.095% (32250/36608)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.088% (32360/36736)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.083% (32471/36864)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.097% (32589/36992)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.112% (32707/37120)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.123% (32824/37248)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.121% (32936/37376)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.121% (33049/37504)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.122% (33162/37632)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.109% (33270/37760)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.110% (33383/37888)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.129% (33503/38016)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.113% (33610/38144)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.083% (33711/38272)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.091% (33827/38400)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.087% (33938/38528)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.090% (34052/38656)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.088% (34164/38784)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.078% (34273/38912)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.074% (34384/39040)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.077% (34498/39168)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.075% (34610/39296)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.081% (34725/39424)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.084% (34839/39552)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.082% (34951/39680)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.088% (35066/39808)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.091% (35180/39936)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.092% (35293/40064)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.085% (35403/40192)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.090% (35518/40320)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.086% (35629/40448)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.099% (35747/40576)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.114% (35866/40704)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.110% (35977/40832)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.108% (36089/40960)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.121% (36207/41088)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.121% (36320/41216)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.122% (36433/41344)\n",
      "Train Epoch: 26 | Loss: 0.346 | Acc: 88.110% (36541/41472)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.108% (36653/41600)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.094% (36760/41728)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.088% (36870/41856)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.088% (36983/41984)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.094% (37098/42112)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.085% (37207/42240)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.071% (37314/42368)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.079% (37430/42496)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.087% (37546/42624)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.092% (37661/42752)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.097% (37776/42880)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.084% (37883/43008)\n",
      "Train Epoch: 26 | Loss: 0.347 | Acc: 88.082% (37995/43136)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.071% (38103/43264)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.065% (38213/43392)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.042% (38316/43520)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.034% (38425/43648)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.028% (38535/43776)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.028% (38648/43904)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 88.018% (38756/44032)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 87.998% (38860/44160)\n",
      "Train Epoch: 26 | Loss: 0.348 | Acc: 87.999% (38973/44288)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.982% (39078/44416)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.976% (39188/44544)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.966% (39296/44672)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.960% (39406/44800)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.961% (39519/44928)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.948% (39626/45056)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.954% (39741/45184)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.959% (39856/45312)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.971% (39974/45440)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.981% (40091/45568)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.981% (40204/45696)\n",
      "Train Epoch: 26 | Loss: 0.349 | Acc: 87.974% (40313/45824)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.964% (40421/45952)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.954% (40529/46080)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.946% (40638/46208)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.947% (40751/46336)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.952% (40866/46464)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.940% (40973/46592)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.939% (41085/46720)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.929% (41193/46848)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.936% (41309/46976)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.927% (41417/47104)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.926% (41529/47232)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.927% (41642/47360)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.921% (41752/47488)\n",
      "Train Epoch: 26 | Loss: 0.350 | Acc: 87.926% (41867/47616)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.921% (41977/47744)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.912% (42085/47872)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.902% (42193/48000)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.903% (42306/48128)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.890% (42412/48256)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.891% (42525/48384)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.883% (42634/48512)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.897% (42753/48640)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.898% (42866/48768)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.897% (42978/48896)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.900% (43092/49024)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.899% (43204/49152)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.900% (43317/49280)\n",
      "Train Epoch: 26 | Loss: 0.352 | Acc: 87.901% (43430/49408)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.910% (43547/49536)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.919% (43664/49664)\n",
      "Train Epoch: 26 | Loss: 0.352 | Acc: 87.910% (43772/49792)\n",
      "Train Epoch: 26 | Loss: 0.351 | Acc: 87.917% (43888/49920)\n",
      "Train Epoch: 26 | Loss: 0.352 | Acc: 87.914% (43957/50000)\n",
      "Test Epoch: 26 | Loss: 0.390 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 26 | Loss: 0.400 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 26 | Loss: 0.326 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 26 | Loss: 0.322 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 26 | Loss: 0.298 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 26 | Loss: 0.303 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 26 | Loss: 0.321 | Acc: 89.143% (624/700)\n",
      "Test Epoch: 26 | Loss: 0.350 | Acc: 87.750% (702/800)\n",
      "Test Epoch: 26 | Loss: 0.355 | Acc: 87.889% (791/900)\n",
      "Test Epoch: 26 | Loss: 0.352 | Acc: 87.800% (878/1000)\n",
      "Test Epoch: 26 | Loss: 0.353 | Acc: 87.636% (964/1100)\n",
      "Test Epoch: 26 | Loss: 0.361 | Acc: 87.500% (1050/1200)\n",
      "Test Epoch: 26 | Loss: 0.351 | Acc: 87.769% (1141/1300)\n",
      "Test Epoch: 26 | Loss: 0.354 | Acc: 87.500% (1225/1400)\n",
      "Test Epoch: 26 | Loss: 0.349 | Acc: 87.733% (1316/1500)\n",
      "Test Epoch: 26 | Loss: 0.351 | Acc: 87.500% (1400/1600)\n",
      "Test Epoch: 26 | Loss: 0.349 | Acc: 87.765% (1492/1700)\n",
      "Test Epoch: 26 | Loss: 0.355 | Acc: 87.722% (1579/1800)\n",
      "Test Epoch: 26 | Loss: 0.353 | Acc: 87.684% (1666/1900)\n",
      "Test Epoch: 26 | Loss: 0.358 | Acc: 87.550% (1751/2000)\n",
      "Test Epoch: 26 | Loss: 0.359 | Acc: 87.619% (1840/2100)\n",
      "Test Epoch: 26 | Loss: 0.356 | Acc: 87.500% (1925/2200)\n",
      "Test Epoch: 26 | Loss: 0.360 | Acc: 87.478% (2012/2300)\n",
      "Test Epoch: 26 | Loss: 0.357 | Acc: 87.583% (2102/2400)\n",
      "Test Epoch: 26 | Loss: 0.365 | Acc: 87.400% (2185/2500)\n",
      "Test Epoch: 26 | Loss: 0.370 | Acc: 87.269% (2269/2600)\n",
      "Test Epoch: 26 | Loss: 0.367 | Acc: 87.370% (2359/2700)\n",
      "Test Epoch: 26 | Loss: 0.370 | Acc: 87.321% (2445/2800)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.310% (2532/2900)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.200% (2616/3000)\n",
      "Test Epoch: 26 | Loss: 0.379 | Acc: 87.129% (2701/3100)\n",
      "Test Epoch: 26 | Loss: 0.381 | Acc: 87.062% (2786/3200)\n",
      "Test Epoch: 26 | Loss: 0.379 | Acc: 87.121% (2875/3300)\n",
      "Test Epoch: 26 | Loss: 0.380 | Acc: 87.059% (2960/3400)\n",
      "Test Epoch: 26 | Loss: 0.382 | Acc: 86.943% (3043/3500)\n",
      "Test Epoch: 26 | Loss: 0.382 | Acc: 86.972% (3131/3600)\n",
      "Test Epoch: 26 | Loss: 0.383 | Acc: 86.865% (3214/3700)\n",
      "Test Epoch: 26 | Loss: 0.383 | Acc: 86.842% (3300/3800)\n",
      "Test Epoch: 26 | Loss: 0.380 | Acc: 86.949% (3391/3900)\n",
      "Test Epoch: 26 | Loss: 0.379 | Acc: 87.000% (3480/4000)\n",
      "Test Epoch: 26 | Loss: 0.379 | Acc: 86.976% (3566/4100)\n",
      "Test Epoch: 26 | Loss: 0.379 | Acc: 87.000% (3654/4200)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.140% (3747/4300)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.205% (3837/4400)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.244% (3926/4500)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.130% (4008/4600)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.106% (4094/4700)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.042% (4178/4800)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.143% (4270/4900)\n",
      "Test Epoch: 26 | Loss: 0.376 | Acc: 87.100% (4355/5000)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.216% (4448/5100)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.212% (4535/5200)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.264% (4625/5300)\n",
      "Test Epoch: 26 | Loss: 0.370 | Acc: 87.296% (4714/5400)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.273% (4800/5500)\n",
      "Test Epoch: 26 | Loss: 0.377 | Acc: 87.143% (4880/5600)\n",
      "Test Epoch: 26 | Loss: 0.377 | Acc: 87.175% (4969/5700)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.293% (5063/5800)\n",
      "Test Epoch: 26 | Loss: 0.377 | Acc: 87.220% (5146/5900)\n",
      "Test Epoch: 26 | Loss: 0.378 | Acc: 87.150% (5229/6000)\n",
      "Test Epoch: 26 | Loss: 0.376 | Acc: 87.213% (5320/6100)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.258% (5410/6200)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.302% (5500/6300)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.375% (5592/6400)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.354% (5678/6500)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.379% (5767/6600)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.403% (5856/6700)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.353% (5940/6800)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.362% (6028/6900)\n",
      "Test Epoch: 26 | Loss: 0.376 | Acc: 87.300% (6111/7000)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.310% (6199/7100)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.319% (6287/7200)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.411% (6381/7300)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.405% (6468/7400)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.373% (6553/7500)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.408% (6643/7600)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.351% (6726/7700)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.397% (6817/7800)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.342% (6900/7900)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.300% (6984/8000)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.346% (7075/8100)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.329% (7161/8200)\n",
      "Test Epoch: 26 | Loss: 0.371 | Acc: 87.337% (7249/8300)\n",
      "Test Epoch: 26 | Loss: 0.371 | Acc: 87.357% (7338/8400)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.329% (7423/8500)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.291% (7507/8600)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.230% (7589/8700)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.239% (7677/8800)\n",
      "Test Epoch: 26 | Loss: 0.374 | Acc: 87.236% (7764/8900)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.222% (7850/9000)\n",
      "Test Epoch: 26 | Loss: 0.375 | Acc: 87.220% (7937/9100)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.272% (8029/9200)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.312% (8120/9300)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.309% (8207/9400)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.347% (8298/9500)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.375% (8388/9600)\n",
      "Test Epoch: 26 | Loss: 0.371 | Acc: 87.433% (8481/9700)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.408% (8566/9800)\n",
      "Test Epoch: 26 | Loss: 0.373 | Acc: 87.404% (8653/9900)\n",
      "Test Epoch: 26 | Loss: 0.372 | Acc: 87.420% (8742/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 27\n",
      "Train Epoch: 27 | Loss: 0.261 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 27 | Loss: 0.292 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 89.583% (344/384)\n",
      "Train Epoch: 27 | Loss: 0.320 | Acc: 90.039% (461/512)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.906% (569/640)\n",
      "Train Epoch: 27 | Loss: 0.345 | Acc: 88.802% (682/768)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.393% (792/896)\n",
      "Train Epoch: 27 | Loss: 0.347 | Acc: 87.988% (901/1024)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.455% (1019/1152)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 88.672% (1135/1280)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.636% (1248/1408)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.997% (1367/1536)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 89.123% (1483/1664)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.230% (1599/1792)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.375% (1716/1920)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.355% (1830/2048)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.154% (1940/2176)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 89.062% (2052/2304)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 89.227% (2170/2432)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.531% (2292/2560)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 89.435% (2404/2688)\n",
      "Train Epoch: 27 | Loss: 0.319 | Acc: 89.702% (2526/2816)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.538% (2636/2944)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.648% (2754/3072)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.625% (2868/3200)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.513% (2979/3328)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 89.525% (3094/3456)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 89.453% (3206/3584)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 89.170% (3310/3712)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 89.115% (3422/3840)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 89.239% (3541/3968)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.185% (3653/4096)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 89.205% (3768/4224)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.200% (3882/4352)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.196% (3996/4480)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 89.301% (4115/4608)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 89.274% (4228/4736)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 89.309% (4344/4864)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 89.343% (4460/4992)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 89.336% (4574/5120)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 89.329% (4688/5248)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.397% (4806/5376)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.390% (4920/5504)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.240% (5026/5632)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.201% (5138/5760)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 89.181% (5251/5888)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 89.162% (5364/6016)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 89.225% (5482/6144)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.254% (5598/6272)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.250% (5712/6400)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.231% (5825/6528)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.228% (5939/6656)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.180% (6050/6784)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 89.149% (6162/6912)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.205% (6280/7040)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.258% (6398/7168)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.227% (6510/7296)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.184% (6621/7424)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.195% (6736/7552)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.115% (6844/7680)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.088% (6956/7808)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.025% (7065/7936)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.087% (7184/8064)\n",
      "Train Epoch: 27 | Loss: 0.320 | Acc: 89.099% (7299/8192)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.087% (7412/8320)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.086% (7526/8448)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.062% (7638/8576)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.108% (7756/8704)\n",
      "Train Epoch: 27 | Loss: 0.322 | Acc: 89.074% (7867/8832)\n",
      "Train Epoch: 27 | Loss: 0.321 | Acc: 89.085% (7982/8960)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.018% (8090/9088)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.019% (8204/9216)\n",
      "Train Epoch: 27 | Loss: 0.323 | Acc: 89.009% (8317/9344)\n",
      "Train Epoch: 27 | Loss: 0.324 | Acc: 88.957% (8426/9472)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 88.938% (8538/9600)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.877% (8646/9728)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.819% (8754/9856)\n",
      "Train Epoch: 27 | Loss: 0.325 | Acc: 88.832% (8869/9984)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.805% (8980/10112)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.770% (9090/10240)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.764% (9203/10368)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.748% (9315/10496)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.742% (9428/10624)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.709% (9538/10752)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.732% (9654/10880)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.726% (9767/11008)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.748% (9883/11136)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.707% (9992/11264)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.703% (10105/11392)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.663% (10214/11520)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 88.659% (10327/11648)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 88.689% (10444/11776)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 88.701% (10559/11904)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.722% (10675/12032)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.734% (10790/12160)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.770% (10908/12288)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.700% (11013/12416)\n",
      "Train Epoch: 27 | Loss: 0.328 | Acc: 88.664% (11122/12544)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.660% (11235/12672)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.680% (11351/12800)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.683% (11465/12928)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.703% (11581/13056)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.698% (11694/13184)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.679% (11805/13312)\n",
      "Train Epoch: 27 | Loss: 0.326 | Acc: 88.646% (11914/13440)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.620% (12024/13568)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.654% (12142/13696)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.672% (12258/13824)\n",
      "Train Epoch: 27 | Loss: 0.327 | Acc: 88.640% (12367/13952)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 88.558% (12469/14080)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.535% (12579/14208)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.518% (12690/14336)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.509% (12802/14464)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.555% (12922/14592)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 88.567% (13037/14720)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 88.557% (13149/14848)\n",
      "Train Epoch: 27 | Loss: 0.329 | Acc: 88.575% (13265/14976)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.559% (13376/15104)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.564% (13490/15232)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.568% (13604/15360)\n",
      "Train Epoch: 27 | Loss: 0.330 | Acc: 88.565% (13717/15488)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.486% (13818/15616)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.478% (13930/15744)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.495% (14046/15872)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.494% (14159/16000)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.523% (14277/16128)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.509% (14388/16256)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.483% (14497/16384)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.499% (14613/16512)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.468% (14721/16640)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.442% (14830/16768)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.447% (14944/16896)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.452% (15058/17024)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.427% (15167/17152)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.426% (15280/17280)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.436% (15395/17408)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.452% (15511/17536)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.417% (15618/17664)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.439% (15735/17792)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.393% (15840/17920)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.420% (15958/18048)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.452% (16077/18176)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.456% (16191/18304)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.439% (16301/18432)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.470% (16420/18560)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.506% (16540/18688)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.542% (16660/18816)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.545% (16774/18944)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.538% (16886/19072)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.521% (16996/19200)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.530% (17111/19328)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.513% (17221/19456)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.491% (17330/19584)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.484% (17442/19712)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.488% (17556/19840)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.512% (17674/19968)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.520% (17789/20096)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.494% (17897/20224)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.512% (18014/20352)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.540% (18133/20480)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.524% (18243/20608)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.508% (18353/20736)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.487% (18462/20864)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.481% (18574/20992)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.471% (18685/21120)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.488% (18802/21248)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.487% (18915/21376)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.491% (19029/21504)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.499% (19144/21632)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.493% (19256/21760)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.487% (19368/21888)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.504% (19485/22016)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.521% (19602/22144)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.519% (19715/22272)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.527% (19830/22400)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.525% (19943/22528)\n",
      "Train Epoch: 27 | Loss: 0.331 | Acc: 88.524% (20056/22656)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.505% (20165/22784)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.486% (20274/22912)\n",
      "Train Epoch: 27 | Loss: 0.332 | Acc: 88.472% (20384/23040)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.445% (20491/23168)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.431% (20601/23296)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.409% (20709/23424)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.404% (20821/23552)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.391% (20931/23680)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.395% (21045/23808)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.402% (21160/23936)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.418% (21277/24064)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.430% (21393/24192)\n",
      "Train Epoch: 27 | Loss: 0.333 | Acc: 88.438% (21508/24320)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.375% (21606/24448)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.359% (21715/24576)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.354% (21827/24704)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.350% (21939/24832)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.345% (22051/24960)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.329% (22160/25088)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.321% (22271/25216)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.336% (22388/25344)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.336% (22501/25472)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.355% (22619/25600)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.359% (22733/25728)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.362% (22847/25856)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.377% (22964/25984)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.346% (23069/26112)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.373% (23189/26240)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.376% (23303/26368)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.394% (23421/26496)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.401% (23536/26624)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.408% (23651/26752)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.393% (23760/26880)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.389% (23872/27008)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.370% (23980/27136)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.373% (24094/27264)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.383% (24210/27392)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.390% (24325/27520)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.393% (24439/27648)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.382% (24549/27776)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.382% (24662/27904)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.385% (24776/28032)\n",
      "Train Epoch: 27 | Loss: 0.334 | Acc: 88.391% (24891/28160)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.373% (24999/28288)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.380% (25114/28416)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.369% (25224/28544)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.354% (25333/28672)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.382% (25454/28800)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.395% (25571/28928)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.371% (25677/29056)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.353% (25785/29184)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.370% (25903/29312)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.349% (26010/29440)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.362% (26127/29568)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.362% (26240/29696)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.365% (26354/29824)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.378% (26471/29952)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.404% (26592/30080)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.397% (26703/30208)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.390% (26814/30336)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.386% (26926/30464)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.405% (27045/30592)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.408% (27159/30720)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.417% (27275/30848)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.401% (27383/30976)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.384% (27491/31104)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.397% (27608/31232)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.383% (27717/31360)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.380% (27829/31488)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.382% (27943/31616)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.373% (28053/31744)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.375% (28167/31872)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.362% (28276/32000)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.359% (28388/32128)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.371% (28505/32256)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.386% (28623/32384)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.380% (28734/32512)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.376% (28846/32640)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.394% (28965/32768)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.397% (29079/32896)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.402% (29194/33024)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.387% (29302/33152)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.395% (29418/33280)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.383% (29527/33408)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.383% (29640/33536)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.397% (29758/33664)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.403% (29873/33792)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.408% (29988/33920)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.384% (30093/34048)\n",
      "Train Epoch: 27 | Loss: 0.335 | Acc: 88.392% (30209/34176)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.392% (30322/34304)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.383% (30432/34432)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.371% (30541/34560)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.362% (30651/34688)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.370% (30767/34816)\n",
      "Train Epoch: 27 | Loss: 0.336 | Acc: 88.359% (30876/34944)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.344% (30984/35072)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.344% (31097/35200)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.332% (31206/35328)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.332% (31319/35456)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.323% (31429/35584)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.329% (31544/35712)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.329% (31657/35840)\n",
      "Train Epoch: 27 | Loss: 0.337 | Acc: 88.315% (31765/35968)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.303% (31874/36096)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.287% (31981/36224)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.298% (32098/36352)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.317% (32218/36480)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.319% (32332/36608)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.311% (32442/36736)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.311% (32555/36864)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.314% (32669/36992)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.303% (32778/37120)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.292% (32887/37248)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.292% (33000/37376)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.289% (33112/37504)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.295% (33227/37632)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.297% (33341/37760)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.300% (33455/37888)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.297% (33567/38016)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.300% (33681/38144)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.310% (33798/38272)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.323% (33916/38400)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.323% (34029/38528)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.310% (34137/38656)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.317% (34253/38784)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.320% (34367/38912)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.302% (34473/39040)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.294% (34583/39168)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.302% (34699/39296)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.294% (34809/39424)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.301% (34925/39552)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.299% (35037/39680)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.306% (35153/39808)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.306% (35266/39936)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.294% (35374/40064)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.289% (35485/40192)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.291% (35599/40320)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.296% (35714/40448)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.296% (35827/40576)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.301% (35942/40704)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.293% (36052/40832)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.303% (36169/40960)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.293% (36278/41088)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.298% (36393/41216)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.305% (36509/41344)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.303% (36621/41472)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.298% (36732/41600)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.296% (36844/41728)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.293% (36956/41856)\n",
      "Train Epoch: 27 | Loss: 0.338 | Acc: 88.291% (37068/41984)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.279% (37176/42112)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.279% (37289/42240)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.269% (37398/42368)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.269% (37511/42496)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.270% (37624/42624)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.267% (37736/42752)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.270% (37850/42880)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.265% (37961/43008)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.274% (38078/43136)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.265% (38187/43264)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.270% (38302/43392)\n",
      "Train Epoch: 27 | Loss: 0.339 | Acc: 88.265% (38413/43520)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.245% (38517/43648)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.236% (38626/43776)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.252% (38746/43904)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.247% (38857/44032)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.247% (38970/44160)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.229% (39075/44288)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.234% (39190/44416)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.221% (39297/44544)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.221% (39410/44672)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.217% (39521/44800)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.217% (39634/44928)\n",
      "Train Epoch: 27 | Loss: 0.340 | Acc: 88.219% (39748/45056)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.219% (39861/45184)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.213% (39971/45312)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.215% (40085/45440)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.213% (40197/45568)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.198% (40303/45696)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.194% (40414/45824)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.199% (40529/45952)\n",
      "Train Epoch: 27 | Loss: 0.341 | Acc: 88.197% (40641/46080)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.186% (40749/46208)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.184% (40861/46336)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.184% (40974/46464)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.189% (41089/46592)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.183% (41199/46720)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.162% (41302/46848)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.177% (41422/46976)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.164% (41529/47104)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.161% (41640/47232)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.171% (41758/47360)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.159% (41865/47488)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.147% (41972/47616)\n",
      "Train Epoch: 27 | Loss: 0.342 | Acc: 88.153% (42088/47744)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.133% (42191/47872)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.129% (42302/48000)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.123% (42412/48128)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.115% (42521/48256)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.116% (42634/48384)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.112% (42745/48512)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.106% (42855/48640)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.107% (42968/48768)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.105% (43080/48896)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.112% (43196/49024)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.116% (43311/49152)\n",
      "Train Epoch: 27 | Loss: 0.343 | Acc: 88.115% (43423/49280)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.101% (43529/49408)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.102% (43642/49536)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.106% (43757/49664)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.090% (43862/49792)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.079% (43969/49920)\n",
      "Train Epoch: 27 | Loss: 0.344 | Acc: 88.090% (44045/50000)\n",
      "Test Epoch: 27 | Loss: 0.302 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 27 | Loss: 0.386 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 27 | Loss: 0.378 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 27 | Loss: 0.372 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 27 | Loss: 0.359 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 27 | Loss: 0.330 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 27 | Loss: 0.331 | Acc: 88.571% (620/700)\n",
      "Test Epoch: 27 | Loss: 0.356 | Acc: 87.625% (701/800)\n",
      "Test Epoch: 27 | Loss: 0.368 | Acc: 87.444% (787/900)\n",
      "Test Epoch: 27 | Loss: 0.361 | Acc: 87.400% (874/1000)\n",
      "Test Epoch: 27 | Loss: 0.370 | Acc: 87.273% (960/1100)\n",
      "Test Epoch: 27 | Loss: 0.381 | Acc: 86.917% (1043/1200)\n",
      "Test Epoch: 27 | Loss: 0.378 | Acc: 87.000% (1131/1300)\n",
      "Test Epoch: 27 | Loss: 0.379 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 27 | Loss: 0.377 | Acc: 87.333% (1310/1500)\n",
      "Test Epoch: 27 | Loss: 0.381 | Acc: 87.062% (1393/1600)\n",
      "Test Epoch: 27 | Loss: 0.377 | Acc: 87.353% (1485/1700)\n",
      "Test Epoch: 27 | Loss: 0.383 | Acc: 87.111% (1568/1800)\n",
      "Test Epoch: 27 | Loss: 0.384 | Acc: 87.211% (1657/1900)\n",
      "Test Epoch: 27 | Loss: 0.387 | Acc: 87.050% (1741/2000)\n",
      "Test Epoch: 27 | Loss: 0.388 | Acc: 87.000% (1827/2100)\n",
      "Test Epoch: 27 | Loss: 0.388 | Acc: 87.000% (1914/2200)\n",
      "Test Epoch: 27 | Loss: 0.397 | Acc: 86.739% (1995/2300)\n",
      "Test Epoch: 27 | Loss: 0.394 | Acc: 86.875% (2085/2400)\n",
      "Test Epoch: 27 | Loss: 0.405 | Acc: 86.680% (2167/2500)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.538% (2250/2600)\n",
      "Test Epoch: 27 | Loss: 0.411 | Acc: 86.556% (2337/2700)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.607% (2425/2800)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.586% (2511/2900)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.567% (2597/3000)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.516% (2682/3100)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.438% (2766/3200)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.485% (2854/3300)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.441% (2939/3400)\n",
      "Test Epoch: 27 | Loss: 0.419 | Acc: 86.371% (3023/3500)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.500% (3114/3600)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.432% (3198/3700)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.500% (3287/3800)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.513% (3374/3900)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.425% (3457/4000)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.439% (3544/4100)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.452% (3631/4200)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.465% (3718/4300)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.500% (3806/4400)\n",
      "Test Epoch: 27 | Loss: 0.411 | Acc: 86.667% (3900/4500)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.587% (3983/4600)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.468% (4064/4700)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.417% (4148/4800)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.490% (4238/4900)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.280% (4314/5000)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.373% (4405/5100)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.269% (4486/5200)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.302% (4574/5300)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.315% (4661/5400)\n",
      "Test Epoch: 27 | Loss: 0.420 | Acc: 86.200% (4741/5500)\n",
      "Test Epoch: 27 | Loss: 0.422 | Acc: 86.179% (4826/5600)\n",
      "Test Epoch: 27 | Loss: 0.422 | Acc: 86.193% (4913/5700)\n",
      "Test Epoch: 27 | Loss: 0.420 | Acc: 86.276% (5004/5800)\n",
      "Test Epoch: 27 | Loss: 0.421 | Acc: 86.169% (5084/5900)\n",
      "Test Epoch: 27 | Loss: 0.422 | Acc: 86.200% (5172/6000)\n",
      "Test Epoch: 27 | Loss: 0.419 | Acc: 86.328% (5266/6100)\n",
      "Test Epoch: 27 | Loss: 0.419 | Acc: 86.323% (5352/6200)\n",
      "Test Epoch: 27 | Loss: 0.418 | Acc: 86.333% (5439/6300)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.406% (5530/6400)\n",
      "Test Epoch: 27 | Loss: 0.418 | Acc: 86.323% (5611/6500)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.379% (5701/6600)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.493% (5795/6700)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.426% (5877/6800)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.493% (5968/6900)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.443% (6051/7000)\n",
      "Test Epoch: 27 | Loss: 0.418 | Acc: 86.437% (6137/7100)\n",
      "Test Epoch: 27 | Loss: 0.419 | Acc: 86.403% (6221/7200)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.479% (6313/7300)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.554% (6405/7400)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.533% (6490/7500)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.553% (6578/7600)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.506% (6661/7700)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.564% (6752/7800)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.570% (6839/7900)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.562% (6925/8000)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.580% (7013/8100)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.610% (7102/8200)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.614% (7189/8300)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.643% (7278/8400)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.624% (7363/8500)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.570% (7445/8600)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.609% (7535/8700)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.625% (7623/8800)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.640% (7711/8900)\n",
      "Test Epoch: 27 | Loss: 0.417 | Acc: 86.556% (7790/9000)\n",
      "Test Epoch: 27 | Loss: 0.416 | Acc: 86.604% (7881/9100)\n",
      "Test Epoch: 27 | Loss: 0.414 | Acc: 86.641% (7971/9200)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.613% (8055/9300)\n",
      "Test Epoch: 27 | Loss: 0.415 | Acc: 86.649% (8145/9400)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.716% (8238/9500)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.729% (8326/9600)\n",
      "Test Epoch: 27 | Loss: 0.411 | Acc: 86.773% (8417/9700)\n",
      "Test Epoch: 27 | Loss: 0.411 | Acc: 86.776% (8504/9800)\n",
      "Test Epoch: 27 | Loss: 0.413 | Acc: 86.687% (8582/9900)\n",
      "Test Epoch: 27 | Loss: 0.412 | Acc: 86.680% (8668/10000)\n",
      "\n",
      "Epoch: 28\n",
      "Train Epoch: 28 | Loss: 0.284 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 28 | Loss: 0.276 | Acc: 91.406% (234/256)\n",
      "Train Epoch: 28 | Loss: 0.301 | Acc: 90.365% (347/384)\n",
      "Train Epoch: 28 | Loss: 0.286 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 28 | Loss: 0.295 | Acc: 90.625% (580/640)\n",
      "Train Epoch: 28 | Loss: 0.293 | Acc: 90.495% (695/768)\n",
      "Train Epoch: 28 | Loss: 0.295 | Acc: 90.402% (810/896)\n",
      "Train Epoch: 28 | Loss: 0.301 | Acc: 90.234% (924/1024)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.844% (1035/1152)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.922% (1151/1280)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.702% (1263/1408)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.323% (1372/1536)\n",
      "Train Epoch: 28 | Loss: 0.310 | Acc: 89.784% (1494/1664)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.565% (1605/1792)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.271% (1714/1920)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.209% (1827/2048)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.108% (1939/2176)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.323% (2058/2304)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.391% (2174/2432)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.297% (2286/2560)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.286% (2400/2688)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.418% (2518/2816)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.640% (2639/2944)\n",
      "Train Epoch: 28 | Loss: 0.311 | Acc: 89.648% (2754/3072)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.656% (2869/3200)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.513% (2979/3328)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.410% (3090/3456)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.453% (3206/3584)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.547% (3324/3712)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.479% (3436/3840)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.415% (3548/3968)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.404% (3662/4096)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.418% (3777/4224)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.246% (3884/4352)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.219% (3997/4480)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.258% (4113/4608)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.358% (4232/4736)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.391% (4348/4864)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.283% (4457/4992)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.414% (4578/5120)\n",
      "Train Epoch: 28 | Loss: 0.311 | Acc: 89.482% (4696/5248)\n",
      "Train Epoch: 28 | Loss: 0.310 | Acc: 89.490% (4811/5376)\n",
      "Train Epoch: 28 | Loss: 0.309 | Acc: 89.499% (4926/5504)\n",
      "Train Epoch: 28 | Loss: 0.310 | Acc: 89.471% (5039/5632)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.392% (5149/5760)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.402% (5264/5888)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.345% (5375/6016)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.323% (5488/6144)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.349% (5604/6272)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.406% (5722/6400)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.354% (5833/6528)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.333% (5946/6656)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.269% (6056/6784)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.308% (6173/6912)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.347% (6290/7040)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.397% (6408/7168)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.378% (6521/7296)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.413% (6638/7424)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.420% (6753/7552)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.401% (6866/7680)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.357% (6977/7808)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.327% (7089/7936)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.348% (7205/8064)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.368% (7321/8192)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.339% (7433/8320)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.370% (7550/8448)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.284% (7657/8576)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.350% (7777/8704)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.368% (7893/8832)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.353% (8006/8960)\n",
      "Train Epoch: 28 | Loss: 0.311 | Acc: 89.459% (8130/9088)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.377% (8237/9216)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.341% (8348/9344)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.326% (8461/9472)\n",
      "Train Epoch: 28 | Loss: 0.312 | Acc: 89.375% (8580/9600)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.330% (8690/9728)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.326% (8804/9856)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.283% (8914/9984)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.280% (9028/10112)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.287% (9143/10240)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.265% (9255/10368)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.282% (9371/10496)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.279% (9485/10624)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.267% (9598/10752)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.338% (9720/10880)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.317% (9832/11008)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.278% (9942/11136)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.293% (10058/11264)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.273% (10170/11392)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.288% (10286/11520)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.337% (10406/11648)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.334% (10520/11776)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.390% (10641/11904)\n",
      "Train Epoch: 28 | Loss: 0.313 | Acc: 89.387% (10755/12032)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.367% (10867/12160)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.364% (10981/12288)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.344% (11093/12416)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.326% (11205/12544)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.283% (11314/12672)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.281% (11428/12800)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.310% (11546/12928)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.292% (11658/13056)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.237% (11765/13184)\n",
      "Train Epoch: 28 | Loss: 0.314 | Acc: 89.258% (11882/13312)\n",
      "Train Epoch: 28 | Loss: 0.315 | Acc: 89.249% (11995/13440)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.217% (12105/13568)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.194% (12216/13696)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.200% (12331/13824)\n",
      "Train Epoch: 28 | Loss: 0.317 | Acc: 89.192% (12444/13952)\n",
      "Train Epoch: 28 | Loss: 0.316 | Acc: 89.197% (12559/14080)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.133% (12664/14208)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.104% (12774/14336)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.104% (12888/14464)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.110% (13003/14592)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.130% (13120/14720)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.143% (13236/14848)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.156% (13352/14976)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.162% (13467/15104)\n",
      "Train Epoch: 28 | Loss: 0.318 | Acc: 89.181% (13584/15232)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.134% (13691/15360)\n",
      "Train Epoch: 28 | Loss: 0.320 | Acc: 89.127% (13804/15488)\n",
      "Train Epoch: 28 | Loss: 0.320 | Acc: 89.133% (13919/15616)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.164% (14038/15744)\n",
      "Train Epoch: 28 | Loss: 0.319 | Acc: 89.182% (14155/15872)\n",
      "Train Epoch: 28 | Loss: 0.320 | Acc: 89.181% (14269/16000)\n",
      "Train Epoch: 28 | Loss: 0.320 | Acc: 89.180% (14383/16128)\n",
      "Train Epoch: 28 | Loss: 0.320 | Acc: 89.161% (14494/16256)\n",
      "Train Epoch: 28 | Loss: 0.321 | Acc: 89.142% (14605/16384)\n",
      "Train Epoch: 28 | Loss: 0.321 | Acc: 89.147% (14720/16512)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.123% (14830/16640)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.098% (14940/16768)\n",
      "Train Epoch: 28 | Loss: 0.321 | Acc: 89.104% (15055/16896)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.080% (15165/17024)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.068% (15277/17152)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.062% (15390/17280)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.068% (15505/17408)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.062% (15618/17536)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.046% (15729/17664)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.079% (15849/17792)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.074% (15962/17920)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.101% (16081/18048)\n",
      "Train Epoch: 28 | Loss: 0.322 | Acc: 89.101% (16195/18176)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.095% (16308/18304)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.073% (16418/18432)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.041% (16526/18560)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.030% (16638/18688)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.025% (16751/18816)\n",
      "Train Epoch: 28 | Loss: 0.325 | Acc: 88.994% (16859/18944)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.010% (16976/19072)\n",
      "Train Epoch: 28 | Loss: 0.325 | Acc: 88.990% (17086/19200)\n",
      "Train Epoch: 28 | Loss: 0.325 | Acc: 89.000% (17202/19328)\n",
      "Train Epoch: 28 | Loss: 0.325 | Acc: 88.996% (17315/19456)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.022% (17434/19584)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.022% (17548/19712)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.037% (17665/19840)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.052% (17782/19968)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.033% (17892/20096)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.023% (18004/20224)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.013% (18116/20352)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.019% (18231/20480)\n",
      "Train Epoch: 28 | Loss: 0.323 | Acc: 89.038% (18349/20608)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 88.995% (18454/20736)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.005% (18570/20864)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.005% (18684/20992)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 88.987% (18794/21120)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 88.992% (18909/21248)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.011% (19027/21376)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 89.021% (19143/21504)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 88.998% (19252/21632)\n",
      "Train Epoch: 28 | Loss: 0.324 | Acc: 88.971% (19360/21760)\n",
      "Train Epoch: 28 | Loss: 0.325 | Acc: 88.935% (19466/21888)\n",
      "Train Epoch: 28 | Loss: 0.327 | Acc: 88.899% (19572/22016)\n",
      "Train Epoch: 28 | Loss: 0.327 | Acc: 88.895% (19685/22144)\n",
      "Train Epoch: 28 | Loss: 0.327 | Acc: 88.878% (19795/22272)\n",
      "Train Epoch: 28 | Loss: 0.327 | Acc: 88.875% (19908/22400)\n",
      "Train Epoch: 28 | Loss: 0.327 | Acc: 88.867% (20020/22528)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.855% (20131/22656)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.839% (20241/22784)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.840% (20355/22912)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.828% (20466/23040)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.825% (20579/23168)\n",
      "Train Epoch: 28 | Loss: 0.328 | Acc: 88.835% (20695/23296)\n",
      "Train Epoch: 28 | Loss: 0.329 | Acc: 88.845% (20811/23424)\n",
      "Train Epoch: 28 | Loss: 0.329 | Acc: 88.850% (20926/23552)\n",
      "Train Epoch: 28 | Loss: 0.329 | Acc: 88.839% (21037/23680)\n",
      "Train Epoch: 28 | Loss: 0.331 | Acc: 88.785% (21138/23808)\n",
      "Train Epoch: 28 | Loss: 0.330 | Acc: 88.799% (21255/23936)\n",
      "Train Epoch: 28 | Loss: 0.330 | Acc: 88.817% (21373/24064)\n",
      "Train Epoch: 28 | Loss: 0.330 | Acc: 88.835% (21491/24192)\n",
      "Train Epoch: 28 | Loss: 0.330 | Acc: 88.832% (21604/24320)\n",
      "Train Epoch: 28 | Loss: 0.331 | Acc: 88.813% (21713/24448)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.786% (21820/24576)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.763% (21928/24704)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.777% (22045/24832)\n",
      "Train Epoch: 28 | Loss: 0.331 | Acc: 88.786% (22161/24960)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.748% (22265/25088)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.749% (22379/25216)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.767% (22497/25344)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.741% (22604/25472)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.734% (22716/25600)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.744% (22832/25728)\n",
      "Train Epoch: 28 | Loss: 0.332 | Acc: 88.745% (22946/25856)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.751% (23061/25984)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.748% (23174/26112)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.750% (23288/26240)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.748% (23401/26368)\n",
      "Train Epoch: 28 | Loss: 0.333 | Acc: 88.734% (23511/26496)\n",
      "Train Epoch: 28 | Loss: 0.334 | Acc: 88.702% (23616/26624)\n",
      "Train Epoch: 28 | Loss: 0.334 | Acc: 88.689% (23726/26752)\n",
      "Train Epoch: 28 | Loss: 0.334 | Acc: 88.661% (23832/26880)\n",
      "Train Epoch: 28 | Loss: 0.334 | Acc: 88.681% (23951/27008)\n",
      "Train Epoch: 28 | Loss: 0.335 | Acc: 88.642% (24054/27136)\n",
      "Train Epoch: 28 | Loss: 0.335 | Acc: 88.626% (24163/27264)\n",
      "Train Epoch: 28 | Loss: 0.335 | Acc: 88.646% (24282/27392)\n",
      "Train Epoch: 28 | Loss: 0.335 | Acc: 88.648% (24396/27520)\n",
      "Train Epoch: 28 | Loss: 0.336 | Acc: 88.636% (24506/27648)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.620% (24615/27776)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.607% (24725/27904)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.613% (24840/28032)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.612% (24953/28160)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.596% (25062/28288)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.601% (25177/28416)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.590% (25287/28544)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.592% (25401/28672)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.604% (25518/28800)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.617% (25635/28928)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.608% (25746/29056)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.603% (25858/29184)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.612% (25974/29312)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.611% (26087/29440)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.606% (26199/29568)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.608% (26313/29696)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.617% (26429/29824)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.575% (26530/29952)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.564% (26640/30080)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.549% (26749/30208)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.542% (26860/30336)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.531% (26970/30464)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.536% (27085/30592)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.548% (27202/30720)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.567% (27321/30848)\n",
      "Train Epoch: 28 | Loss: 0.337 | Acc: 88.559% (27432/30976)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.548% (27542/31104)\n",
      "Train Epoch: 28 | Loss: 0.338 | Acc: 88.528% (27649/31232)\n",
      "Train Epoch: 28 | Loss: 0.339 | Acc: 88.514% (27758/31360)\n",
      "Train Epoch: 28 | Loss: 0.339 | Acc: 88.504% (27868/31488)\n",
      "Train Epoch: 28 | Loss: 0.339 | Acc: 88.496% (27979/31616)\n",
      "Train Epoch: 28 | Loss: 0.339 | Acc: 88.480% (28087/31744)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.451% (28191/31872)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.453% (28305/32000)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.440% (28414/32128)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.415% (28519/32256)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.414% (28632/32384)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.404% (28742/32512)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.419% (28860/32640)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.431% (28977/32768)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.424% (29088/32896)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.414% (29198/33024)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.417% (29312/33152)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.398% (29419/33280)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.404% (29534/33408)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.404% (29647/33536)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.391% (29756/33664)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.385% (29867/33792)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.381% (29979/33920)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.405% (30100/34048)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.401% (30212/34176)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.395% (30323/34304)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.409% (30441/34432)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.420% (30558/34560)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.411% (30668/34688)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.399% (30777/34816)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.379% (30883/34944)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.384% (30998/35072)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.401% (31117/35200)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.411% (31234/35328)\n",
      "Train Epoch: 28 | Loss: 0.340 | Acc: 88.419% (31350/35456)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.377% (31448/35584)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.379% (31562/35712)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.373% (31673/35840)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.370% (31785/35968)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.362% (31895/36096)\n",
      "Train Epoch: 28 | Loss: 0.341 | Acc: 88.370% (32011/36224)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.353% (32118/36352)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.358% (32233/36480)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.339% (32339/36608)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.338% (32452/36736)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.333% (32563/36864)\n",
      "Train Epoch: 28 | Loss: 0.342 | Acc: 88.319% (32671/36992)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.305% (32779/37120)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.303% (32891/37248)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.297% (33002/37376)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.295% (33114/37504)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.292% (33226/37632)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.302% (33343/37760)\n",
      "Train Epoch: 28 | Loss: 0.343 | Acc: 88.284% (33449/37888)\n",
      "Train Epoch: 28 | Loss: 0.344 | Acc: 88.265% (33555/38016)\n",
      "Train Epoch: 28 | Loss: 0.344 | Acc: 88.260% (33666/38144)\n",
      "Train Epoch: 28 | Loss: 0.344 | Acc: 88.255% (33777/38272)\n",
      "Train Epoch: 28 | Loss: 0.344 | Acc: 88.247% (33887/38400)\n",
      "Train Epoch: 28 | Loss: 0.344 | Acc: 88.237% (33996/38528)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.237% (34109/38656)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.235% (34221/38784)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.238% (34335/38912)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.230% (34445/39040)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.223% (34555/39168)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.220% (34667/39296)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.223% (34781/39424)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.228% (34896/39552)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.226% (35008/39680)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.228% (35122/39808)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.216% (35230/39936)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.216% (35343/40064)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.217% (35456/40192)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.194% (35560/40320)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.190% (35671/40448)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.195% (35786/40576)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.210% (35905/40704)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.208% (36017/40832)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.198% (36126/40960)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.199% (36239/41088)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.187% (36347/41216)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.194% (36463/41344)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.192% (36575/41472)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.183% (36684/41600)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.197% (36803/41728)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.193% (36914/41856)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.203% (37031/41984)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.212% (37148/42112)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.215% (37262/42240)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.208% (37372/42368)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.220% (37490/42496)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.218% (37602/42624)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.216% (37714/42752)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.211% (37825/42880)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.218% (37941/43008)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.226% (38057/43136)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.230% (38172/43264)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.231% (38285/43392)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.224% (38395/43520)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.208% (38501/43648)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.208% (38614/43776)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.211% (38728/43904)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.209% (38840/44032)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.202% (38950/44160)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.207% (39065/44288)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.220% (39184/44416)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.234% (39303/44544)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.234% (39416/44672)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.237% (39530/44800)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.239% (39644/44928)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.241% (39758/45056)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.237% (39869/45184)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.239% (39983/45312)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.231% (40092/45440)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.233% (40206/45568)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.231% (40318/45696)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.229% (40430/45824)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.236% (40546/45952)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.229% (40656/46080)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.238% (40773/46208)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.234% (40884/46336)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.215% (40988/46464)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.210% (41099/46592)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.206% (41210/46720)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.209% (41324/46848)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.205% (41435/46976)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.207% (41549/47104)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.209% (41663/47232)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.220% (41781/47360)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.218% (41893/47488)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.225% (42009/47616)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.218% (42119/47744)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.210% (42228/47872)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.198% (42335/48000)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.194% (42446/48128)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.203% (42563/48256)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.203% (42676/48384)\n",
      "Train Epoch: 28 | Loss: 0.345 | Acc: 88.195% (42785/48512)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.185% (42893/48640)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.179% (43003/48768)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.185% (43119/48896)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.183% (43231/49024)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.182% (43343/49152)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.176% (43453/49280)\n",
      "Train Epoch: 28 | Loss: 0.346 | Acc: 88.174% (43565/49408)\n",
      "Train Epoch: 28 | Loss: 0.347 | Acc: 88.160% (43671/49536)\n",
      "Train Epoch: 28 | Loss: 0.347 | Acc: 88.156% (43782/49664)\n",
      "Train Epoch: 28 | Loss: 0.347 | Acc: 88.159% (43896/49792)\n",
      "Train Epoch: 28 | Loss: 0.347 | Acc: 88.163% (44011/49920)\n",
      "Train Epoch: 28 | Loss: 0.347 | Acc: 88.154% (44077/50000)\n",
      "Test Epoch: 28 | Loss: 0.549 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 28 | Loss: 0.474 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 28 | Loss: 0.446 | Acc: 85.333% (256/300)\n",
      "Test Epoch: 28 | Loss: 0.433 | Acc: 86.000% (344/400)\n",
      "Test Epoch: 28 | Loss: 0.447 | Acc: 84.800% (424/500)\n",
      "Test Epoch: 28 | Loss: 0.421 | Acc: 85.667% (514/600)\n",
      "Test Epoch: 28 | Loss: 0.431 | Acc: 85.857% (601/700)\n",
      "Test Epoch: 28 | Loss: 0.444 | Acc: 85.500% (684/800)\n",
      "Test Epoch: 28 | Loss: 0.469 | Acc: 85.222% (767/900)\n",
      "Test Epoch: 28 | Loss: 0.466 | Acc: 85.400% (854/1000)\n",
      "Test Epoch: 28 | Loss: 0.473 | Acc: 85.273% (938/1100)\n",
      "Test Epoch: 28 | Loss: 0.480 | Acc: 85.083% (1021/1200)\n",
      "Test Epoch: 28 | Loss: 0.468 | Acc: 85.154% (1107/1300)\n",
      "Test Epoch: 28 | Loss: 0.473 | Acc: 85.071% (1191/1400)\n",
      "Test Epoch: 28 | Loss: 0.469 | Acc: 85.000% (1275/1500)\n",
      "Test Epoch: 28 | Loss: 0.471 | Acc: 84.688% (1355/1600)\n",
      "Test Epoch: 28 | Loss: 0.469 | Acc: 84.647% (1439/1700)\n",
      "Test Epoch: 28 | Loss: 0.471 | Acc: 84.556% (1522/1800)\n",
      "Test Epoch: 28 | Loss: 0.473 | Acc: 84.632% (1608/1900)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 84.550% (1691/2000)\n",
      "Test Epoch: 28 | Loss: 0.477 | Acc: 84.714% (1779/2100)\n",
      "Test Epoch: 28 | Loss: 0.472 | Acc: 85.000% (1870/2200)\n",
      "Test Epoch: 28 | Loss: 0.476 | Acc: 84.870% (1952/2300)\n",
      "Test Epoch: 28 | Loss: 0.474 | Acc: 84.625% (2031/2400)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 84.480% (2112/2500)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.500% (2197/2600)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.667% (2286/2700)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 84.643% (2370/2800)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.759% (2458/2900)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.700% (2541/3000)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.613% (2623/3100)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.625% (2708/3200)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.697% (2795/3300)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.676% (2879/3400)\n",
      "Test Epoch: 28 | Loss: 0.492 | Acc: 84.657% (2963/3500)\n",
      "Test Epoch: 28 | Loss: 0.496 | Acc: 84.583% (3045/3600)\n",
      "Test Epoch: 28 | Loss: 0.497 | Acc: 84.595% (3130/3700)\n",
      "Test Epoch: 28 | Loss: 0.499 | Acc: 84.526% (3212/3800)\n",
      "Test Epoch: 28 | Loss: 0.493 | Acc: 84.718% (3304/3900)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.775% (3391/4000)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.854% (3479/4100)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.905% (3566/4200)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 85.023% (3656/4300)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 85.091% (3744/4400)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 85.089% (3829/4500)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 85.000% (3910/4600)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 84.979% (3994/4700)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.833% (4072/4800)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.898% (4160/4900)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.880% (4244/5000)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.922% (4331/5100)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.865% (4413/5200)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.774% (4493/5300)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.815% (4580/5400)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 84.873% (4668/5500)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.750% (4746/5600)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.702% (4828/5700)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.759% (4916/5800)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.729% (4999/5900)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.767% (5086/6000)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.754% (5170/6100)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.726% (5253/6200)\n",
      "Test Epoch: 28 | Loss: 0.489 | Acc: 84.778% (5341/6300)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.875% (5432/6400)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.769% (5510/6500)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 84.788% (5596/6600)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 84.851% (5685/6700)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.794% (5766/6800)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.768% (5849/6900)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.771% (5934/7000)\n",
      "Test Epoch: 28 | Loss: 0.490 | Acc: 84.732% (6016/7100)\n",
      "Test Epoch: 28 | Loss: 0.491 | Acc: 84.694% (6098/7200)\n",
      "Test Epoch: 28 | Loss: 0.488 | Acc: 84.781% (6189/7300)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.743% (6271/7400)\n",
      "Test Epoch: 28 | Loss: 0.487 | Acc: 84.720% (6354/7500)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.763% (6442/7600)\n",
      "Test Epoch: 28 | Loss: 0.486 | Acc: 84.740% (6525/7700)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.782% (6613/7800)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 84.810% (6700/7900)\n",
      "Test Epoch: 28 | Loss: 0.484 | Acc: 84.787% (6783/8000)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 84.802% (6869/8100)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 84.805% (6954/8200)\n",
      "Test Epoch: 28 | Loss: 0.479 | Acc: 84.819% (7040/8300)\n",
      "Test Epoch: 28 | Loss: 0.477 | Acc: 84.905% (7132/8400)\n",
      "Test Epoch: 28 | Loss: 0.478 | Acc: 84.847% (7212/8500)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 84.802% (7293/8600)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.805% (7378/8700)\n",
      "Test Epoch: 28 | Loss: 0.482 | Acc: 84.795% (7462/8800)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.809% (7548/8900)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.744% (7627/9000)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.769% (7714/9100)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.826% (7804/9200)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.796% (7886/9300)\n",
      "Test Epoch: 28 | Loss: 0.485 | Acc: 84.766% (7968/9400)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.800% (8056/9500)\n",
      "Test Epoch: 28 | Loss: 0.483 | Acc: 84.771% (8138/9600)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 84.825% (8228/9700)\n",
      "Test Epoch: 28 | Loss: 0.479 | Acc: 84.847% (8315/9800)\n",
      "Test Epoch: 28 | Loss: 0.481 | Acc: 84.798% (8395/9900)\n",
      "Test Epoch: 28 | Loss: 0.479 | Acc: 84.790% (8479/10000)\n",
      "\n",
      "Epoch: 29\n",
      "Train Epoch: 29 | Loss: 0.239 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 29 | Loss: 0.343 | Acc: 88.281% (226/256)\n",
      "Train Epoch: 29 | Loss: 0.319 | Acc: 88.802% (341/384)\n",
      "Train Epoch: 29 | Loss: 0.349 | Acc: 88.281% (452/512)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 89.062% (570/640)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.672% (681/768)\n",
      "Train Epoch: 29 | Loss: 0.343 | Acc: 88.281% (791/896)\n",
      "Train Epoch: 29 | Loss: 0.350 | Acc: 88.281% (904/1024)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.628% (1021/1152)\n",
      "Train Epoch: 29 | Loss: 0.332 | Acc: 88.594% (1134/1280)\n",
      "Train Epoch: 29 | Loss: 0.325 | Acc: 88.920% (1252/1408)\n",
      "Train Epoch: 29 | Loss: 0.325 | Acc: 88.867% (1365/1536)\n",
      "Train Epoch: 29 | Loss: 0.319 | Acc: 89.062% (1482/1664)\n",
      "Train Epoch: 29 | Loss: 0.325 | Acc: 88.951% (1594/1792)\n",
      "Train Epoch: 29 | Loss: 0.316 | Acc: 89.219% (1713/1920)\n",
      "Train Epoch: 29 | Loss: 0.315 | Acc: 89.209% (1827/2048)\n",
      "Train Epoch: 29 | Loss: 0.319 | Acc: 89.154% (1940/2176)\n",
      "Train Epoch: 29 | Loss: 0.318 | Acc: 89.236% (2056/2304)\n",
      "Train Epoch: 29 | Loss: 0.323 | Acc: 89.104% (2167/2432)\n",
      "Train Epoch: 29 | Loss: 0.324 | Acc: 89.023% (2279/2560)\n",
      "Train Epoch: 29 | Loss: 0.324 | Acc: 89.025% (2393/2688)\n",
      "Train Epoch: 29 | Loss: 0.324 | Acc: 89.098% (2509/2816)\n",
      "Train Epoch: 29 | Loss: 0.322 | Acc: 89.062% (2622/2944)\n",
      "Train Epoch: 29 | Loss: 0.323 | Acc: 88.932% (2732/3072)\n",
      "Train Epoch: 29 | Loss: 0.321 | Acc: 89.031% (2849/3200)\n",
      "Train Epoch: 29 | Loss: 0.322 | Acc: 89.032% (2963/3328)\n",
      "Train Epoch: 29 | Loss: 0.324 | Acc: 89.034% (3077/3456)\n",
      "Train Epoch: 29 | Loss: 0.326 | Acc: 88.951% (3188/3584)\n",
      "Train Epoch: 29 | Loss: 0.330 | Acc: 88.820% (3297/3712)\n",
      "Train Epoch: 29 | Loss: 0.330 | Acc: 88.802% (3410/3840)\n",
      "Train Epoch: 29 | Loss: 0.331 | Acc: 88.684% (3519/3968)\n",
      "Train Epoch: 29 | Loss: 0.330 | Acc: 88.721% (3634/4096)\n",
      "Train Epoch: 29 | Loss: 0.331 | Acc: 88.707% (3747/4224)\n",
      "Train Epoch: 29 | Loss: 0.332 | Acc: 88.718% (3861/4352)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.571% (3968/4480)\n",
      "Train Epoch: 29 | Loss: 0.340 | Acc: 88.542% (4080/4608)\n",
      "Train Epoch: 29 | Loss: 0.344 | Acc: 88.366% (4185/4736)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.405% (4300/4864)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.421% (4414/4992)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.340% (4523/5120)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.357% (4637/5248)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.318% (4748/5376)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.372% (4864/5504)\n",
      "Train Epoch: 29 | Loss: 0.340 | Acc: 88.459% (4982/5632)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.438% (5094/5760)\n",
      "Train Epoch: 29 | Loss: 0.344 | Acc: 88.349% (5202/5888)\n",
      "Train Epoch: 29 | Loss: 0.345 | Acc: 88.265% (5310/6016)\n",
      "Train Epoch: 29 | Loss: 0.344 | Acc: 88.281% (5424/6144)\n",
      "Train Epoch: 29 | Loss: 0.347 | Acc: 88.217% (5533/6272)\n",
      "Train Epoch: 29 | Loss: 0.345 | Acc: 88.297% (5651/6400)\n",
      "Train Epoch: 29 | Loss: 0.346 | Acc: 88.235% (5760/6528)\n",
      "Train Epoch: 29 | Loss: 0.345 | Acc: 88.266% (5875/6656)\n",
      "Train Epoch: 29 | Loss: 0.346 | Acc: 88.237% (5986/6784)\n",
      "Train Epoch: 29 | Loss: 0.347 | Acc: 88.194% (6096/6912)\n",
      "Train Epoch: 29 | Loss: 0.347 | Acc: 88.210% (6210/7040)\n",
      "Train Epoch: 29 | Loss: 0.345 | Acc: 88.253% (6326/7168)\n",
      "Train Epoch: 29 | Loss: 0.344 | Acc: 88.281% (6441/7296)\n",
      "Train Epoch: 29 | Loss: 0.343 | Acc: 88.295% (6555/7424)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.374% (6674/7552)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.346% (6785/7680)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.358% (6899/7808)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.357% (7012/7936)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.393% (7128/8064)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.416% (7243/8192)\n",
      "Train Epoch: 29 | Loss: 0.342 | Acc: 88.377% (7353/8320)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.388% (7467/8448)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.386% (7580/8576)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.339% (7689/8704)\n",
      "Train Epoch: 29 | Loss: 0.340 | Acc: 88.349% (7803/8832)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.315% (7913/8960)\n",
      "Train Epoch: 29 | Loss: 0.341 | Acc: 88.336% (8028/9088)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.433% (8150/9216)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.485% (8268/9344)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.503% (8383/9472)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.500% (8496/9600)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.497% (8609/9728)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.494% (8722/9856)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.522% (8838/9984)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.568% (8956/10112)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.555% (9068/10240)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.600% (9186/10368)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.605% (9300/10496)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.601% (9413/10624)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.607% (9527/10752)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.612% (9641/10880)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.617% (9755/11008)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.622% (9869/11136)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.601% (9980/11264)\n",
      "Train Epoch: 29 | Loss: 0.331 | Acc: 88.711% (10106/11392)\n",
      "Train Epoch: 29 | Loss: 0.330 | Acc: 88.759% (10225/11520)\n",
      "Train Epoch: 29 | Loss: 0.330 | Acc: 88.779% (10341/11648)\n",
      "Train Epoch: 29 | Loss: 0.331 | Acc: 88.714% (10447/11776)\n",
      "Train Epoch: 29 | Loss: 0.332 | Acc: 88.718% (10561/11904)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.688% (10671/12032)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.684% (10784/12160)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.672% (10896/12288)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.668% (11009/12416)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.680% (11124/12544)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.676% (11237/12672)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.641% (11346/12800)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.668% (11463/12928)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.695% (11580/13056)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.645% (11687/13184)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.657% (11802/13312)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.661% (11916/13440)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.687% (12033/13568)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.697% (12148/13696)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.686% (12260/13824)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.632% (12366/13952)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.594% (12474/14080)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.584% (12586/14208)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.567% (12697/14336)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.523% (12804/14464)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.549% (12921/14592)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.492% (13026/14720)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.477% (13137/14848)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.468% (13249/14976)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.493% (13366/15104)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.459% (13474/15232)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.438% (13584/15360)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.462% (13701/15488)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.467% (13815/15616)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.472% (13929/15744)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.477% (14043/15872)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.475% (14156/16000)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.467% (14268/16128)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.435% (14376/16256)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.470% (14495/16384)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.475% (14609/16512)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.510% (14728/16640)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.520% (14843/16768)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.530% (14958/16896)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.563% (15077/17024)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.596% (15196/17152)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.617% (15313/17280)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.551% (15415/17408)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.526% (15524/17536)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.542% (15640/17664)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.512% (15748/17792)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.532% (15865/17920)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.536% (15979/18048)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.545% (16094/18176)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.538% (16206/18304)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.542% (16320/18432)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.561% (16437/18560)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.533% (16545/18688)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.520% (16656/18816)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.545% (16774/18944)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.554% (16889/19072)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.542% (17000/19200)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.545% (17114/19328)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.554% (17229/19456)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.542% (17340/19584)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.550% (17455/19712)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.569% (17572/19840)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.602% (17692/19968)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.580% (17801/20096)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.578% (17914/20224)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.591% (18030/20352)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.579% (18141/20480)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.568% (18252/20608)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.575% (18367/20736)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.593% (18484/20864)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.605% (18600/20992)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.617% (18716/21120)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.615% (18829/21248)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.623% (18944/21376)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.649% (19063/21504)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.651% (19177/21632)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.631% (19286/21760)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.615% (19396/21888)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.608% (19508/22016)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.620% (19624/22144)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.622% (19738/22272)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.616% (19850/22400)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.623% (19965/22528)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.612% (20076/22656)\n",
      "Train Epoch: 29 | Loss: 0.333 | Acc: 88.632% (20194/22784)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.600% (20300/22912)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.594% (20412/23040)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.583% (20523/23168)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.577% (20635/23296)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.567% (20746/23424)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.578% (20862/23552)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.573% (20974/23680)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.596% (21093/23808)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.599% (21207/23936)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.576% (21315/24064)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.571% (21427/24192)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.590% (21545/24320)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.572% (21654/24448)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.586% (21771/24576)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.557% (21877/24704)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.575% (21995/24832)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.566% (22106/24960)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.568% (22220/25088)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.567% (22333/25216)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.577% (22449/25344)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.572% (22561/25472)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.562% (22672/25600)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.549% (22782/25728)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.537% (22892/25856)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.531% (23004/25984)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.530% (23117/26112)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.563% (23239/26240)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.554% (23350/26368)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.576% (23469/26496)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.574% (23582/26624)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.580% (23697/26752)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.586% (23812/26880)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.574% (23922/27008)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.594% (24041/27136)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.589% (24153/27264)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.581% (24264/27392)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.594% (24381/27520)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.592% (24494/27648)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.591% (24607/27776)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.586% (24719/27904)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.595% (24835/28032)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.597% (24949/28160)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.596% (25062/28288)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.601% (25177/28416)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.600% (25290/28544)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.606% (25405/28672)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.622% (25523/28800)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.637% (25641/28928)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.632% (25753/29056)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.620% (25863/29184)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.646% (25984/29312)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.658% (26101/29440)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.653% (26213/29568)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.645% (26324/29696)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.637% (26435/29824)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.638% (26549/29952)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.630% (26660/30080)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.616% (26769/30208)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.594% (26876/30336)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.600% (26991/30464)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.618% (27110/30592)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.626% (27226/30720)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.631% (27341/30848)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.633% (27455/30976)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.609% (27561/31104)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.605% (27673/31232)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.626% (27793/31360)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.631% (27908/31488)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.623% (28019/31616)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.606% (28127/31744)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.589% (28235/31872)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.594% (28350/32000)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.583% (28460/32128)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.591% (28576/32256)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.599% (28692/32384)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.601% (28806/32512)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.572% (28910/32640)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.571% (29023/32768)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.573% (29137/32896)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.566% (29248/33024)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.565% (29361/33152)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.567% (29475/33280)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.554% (29584/33408)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.553% (29697/33536)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.555% (29811/33664)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.556% (29925/33792)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.541% (30033/33920)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.522% (30140/34048)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.533% (30257/34176)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.535% (30371/34304)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.537% (30485/34432)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.530% (30596/34560)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.521% (30706/34688)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.537% (30825/34816)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.527% (30935/34944)\n",
      "Train Epoch: 29 | Loss: 0.334 | Acc: 88.532% (31050/35072)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.528% (31162/35200)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.533% (31277/35328)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.524% (31387/35456)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.512% (31496/35584)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.505% (31607/35712)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.499% (31718/35840)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.495% (31830/35968)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.500% (31945/36096)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.505% (32060/36224)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.507% (32174/36352)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.495% (32283/36480)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.489% (32394/36608)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.488% (32507/36736)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.479% (32617/36864)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.465% (32725/36992)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.470% (32840/37120)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.483% (32958/37248)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.493% (33075/37376)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.476% (33182/37504)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.489% (33300/37632)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.483% (33411/37760)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.474% (33521/37888)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.471% (33633/38016)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.462% (33743/38144)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.472% (33860/38272)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.471% (33973/38400)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.468% (34085/38528)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.457% (34194/38656)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.464% (34310/38784)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.474% (34427/38912)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.471% (34539/39040)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.480% (34656/39168)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.480% (34769/39296)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.487% (34885/39424)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.478% (34995/39552)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.473% (35106/39680)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.465% (35216/39808)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.467% (35330/39936)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.478% (35448/40064)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.490% (35566/40192)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.495% (35681/40320)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.482% (35789/40448)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.473% (35899/40576)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.466% (36009/40704)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.472% (36125/40832)\n",
      "Train Epoch: 29 | Loss: 0.335 | Acc: 88.472% (36238/40960)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.469% (36350/41088)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.461% (36460/41216)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.446% (36567/41344)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.445% (36680/41472)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.454% (36797/41600)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.439% (36904/41728)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.437% (37016/41856)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.434% (37128/41984)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.433% (37241/42112)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.440% (37357/42240)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.437% (37469/42368)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.448% (37587/42496)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.453% (37702/42624)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.452% (37815/42752)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.454% (37929/42880)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.444% (38038/43008)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.432% (38146/43136)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.427% (38257/43264)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.426% (38370/43392)\n",
      "Train Epoch: 29 | Loss: 0.336 | Acc: 88.431% (38485/43520)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.430% (38598/43648)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.402% (38699/43776)\n",
      "Train Epoch: 29 | Loss: 0.337 | Acc: 88.395% (38809/43904)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.381% (38916/44032)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.363% (39021/44160)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.354% (39130/44288)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.360% (39246/44416)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.358% (39358/44544)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.364% (39474/44672)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.375% (39592/44800)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.366% (39701/44928)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.372% (39817/45056)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.368% (39928/45184)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.376% (40045/45312)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.371% (40156/45440)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.373% (40270/45568)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.373% (40383/45696)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.375% (40497/45824)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.366% (40606/45952)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.359% (40716/46080)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.342% (40821/46208)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.342% (40934/46336)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.344% (41048/46464)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.348% (41163/46592)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.343% (41274/46720)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.330% (41381/46848)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.320% (41489/46976)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.311% (41598/47104)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.309% (41710/47232)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.307% (41822/47360)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.311% (41937/47488)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.317% (42053/47616)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.321% (42168/47744)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.321% (42281/47872)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.312% (42390/48000)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.308% (42501/48128)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.312% (42616/48256)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.318% (42732/48384)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.318% (42845/48512)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.335% (42966/48640)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.343% (43083/48768)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.351% (43200/48896)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.351% (43313/49024)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.346% (43424/49152)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.344% (43536/49280)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.348% (43651/49408)\n",
      "Train Epoch: 29 | Loss: 0.338 | Acc: 88.352% (43766/49536)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.348% (43877/49664)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.344% (43988/49792)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.331% (44095/49920)\n",
      "Train Epoch: 29 | Loss: 0.339 | Acc: 88.336% (44168/50000)\n",
      "Test Epoch: 29 | Loss: 0.360 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 29 | Loss: 0.421 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 29 | Loss: 0.457 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 29 | Loss: 0.436 | Acc: 85.250% (341/400)\n",
      "Test Epoch: 29 | Loss: 0.443 | Acc: 84.600% (423/500)\n",
      "Test Epoch: 29 | Loss: 0.425 | Acc: 85.333% (512/600)\n",
      "Test Epoch: 29 | Loss: 0.434 | Acc: 85.286% (597/700)\n",
      "Test Epoch: 29 | Loss: 0.440 | Acc: 85.125% (681/800)\n",
      "Test Epoch: 29 | Loss: 0.464 | Acc: 84.889% (764/900)\n",
      "Test Epoch: 29 | Loss: 0.460 | Acc: 85.100% (851/1000)\n",
      "Test Epoch: 29 | Loss: 0.473 | Acc: 84.818% (933/1100)\n",
      "Test Epoch: 29 | Loss: 0.475 | Acc: 84.917% (1019/1200)\n",
      "Test Epoch: 29 | Loss: 0.470 | Acc: 84.846% (1103/1300)\n",
      "Test Epoch: 29 | Loss: 0.466 | Acc: 84.786% (1187/1400)\n",
      "Test Epoch: 29 | Loss: 0.474 | Acc: 84.800% (1272/1500)\n",
      "Test Epoch: 29 | Loss: 0.474 | Acc: 84.875% (1358/1600)\n",
      "Test Epoch: 29 | Loss: 0.475 | Acc: 85.118% (1447/1700)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.889% (1528/1800)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 85.053% (1616/1900)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 85.100% (1702/2000)\n",
      "Test Epoch: 29 | Loss: 0.488 | Acc: 84.762% (1780/2100)\n",
      "Test Epoch: 29 | Loss: 0.487 | Acc: 84.773% (1865/2200)\n",
      "Test Epoch: 29 | Loss: 0.489 | Acc: 84.609% (1946/2300)\n",
      "Test Epoch: 29 | Loss: 0.491 | Acc: 84.500% (2028/2400)\n",
      "Test Epoch: 29 | Loss: 0.504 | Acc: 84.320% (2108/2500)\n",
      "Test Epoch: 29 | Loss: 0.505 | Acc: 84.231% (2190/2600)\n",
      "Test Epoch: 29 | Loss: 0.500 | Acc: 84.296% (2276/2700)\n",
      "Test Epoch: 29 | Loss: 0.500 | Acc: 84.179% (2357/2800)\n",
      "Test Epoch: 29 | Loss: 0.498 | Acc: 84.241% (2443/2900)\n",
      "Test Epoch: 29 | Loss: 0.497 | Acc: 84.267% (2528/3000)\n",
      "Test Epoch: 29 | Loss: 0.495 | Acc: 84.290% (2613/3100)\n",
      "Test Epoch: 29 | Loss: 0.492 | Acc: 84.312% (2698/3200)\n",
      "Test Epoch: 29 | Loss: 0.490 | Acc: 84.424% (2786/3300)\n",
      "Test Epoch: 29 | Loss: 0.493 | Acc: 84.324% (2867/3400)\n",
      "Test Epoch: 29 | Loss: 0.497 | Acc: 84.314% (2951/3500)\n",
      "Test Epoch: 29 | Loss: 0.495 | Acc: 84.500% (3042/3600)\n",
      "Test Epoch: 29 | Loss: 0.496 | Acc: 84.568% (3129/3700)\n",
      "Test Epoch: 29 | Loss: 0.497 | Acc: 84.500% (3211/3800)\n",
      "Test Epoch: 29 | Loss: 0.493 | Acc: 84.590% (3299/3900)\n",
      "Test Epoch: 29 | Loss: 0.493 | Acc: 84.600% (3384/4000)\n",
      "Test Epoch: 29 | Loss: 0.491 | Acc: 84.537% (3466/4100)\n",
      "Test Epoch: 29 | Loss: 0.493 | Acc: 84.524% (3550/4200)\n",
      "Test Epoch: 29 | Loss: 0.487 | Acc: 84.698% (3642/4300)\n",
      "Test Epoch: 29 | Loss: 0.486 | Acc: 84.705% (3727/4400)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.778% (3815/4500)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.761% (3899/4600)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.766% (3984/4700)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.771% (4069/4800)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.857% (4158/4900)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.820% (4241/5000)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.882% (4329/5100)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.769% (4408/5200)\n",
      "Test Epoch: 29 | Loss: 0.479 | Acc: 84.811% (4495/5300)\n",
      "Test Epoch: 29 | Loss: 0.479 | Acc: 84.759% (4577/5400)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.636% (4655/5500)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.554% (4735/5600)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.474% (4815/5700)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.552% (4904/5800)\n",
      "Test Epoch: 29 | Loss: 0.485 | Acc: 84.576% (4990/5900)\n",
      "Test Epoch: 29 | Loss: 0.486 | Acc: 84.600% (5076/6000)\n",
      "Test Epoch: 29 | Loss: 0.486 | Acc: 84.607% (5161/6100)\n",
      "Test Epoch: 29 | Loss: 0.485 | Acc: 84.597% (5245/6200)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.635% (5332/6300)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.672% (5419/6400)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.600% (5499/6500)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.515% (5578/6600)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.582% (5667/6700)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.515% (5747/6800)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.551% (5834/6900)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.471% (5913/7000)\n",
      "Test Epoch: 29 | Loss: 0.485 | Acc: 84.437% (5995/7100)\n",
      "Test Epoch: 29 | Loss: 0.487 | Acc: 84.319% (6071/7200)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.356% (6158/7300)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.446% (6249/7400)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.387% (6329/7500)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.434% (6417/7600)\n",
      "Test Epoch: 29 | Loss: 0.485 | Acc: 84.364% (6496/7700)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.359% (6580/7800)\n",
      "Test Epoch: 29 | Loss: 0.484 | Acc: 84.367% (6665/7900)\n",
      "Test Epoch: 29 | Loss: 0.485 | Acc: 84.362% (6749/8000)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.395% (6836/8100)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.378% (6919/8200)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.337% (7000/8300)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.405% (7090/8400)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.341% (7169/8500)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.349% (7254/8600)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.356% (7339/8700)\n",
      "Test Epoch: 29 | Loss: 0.479 | Acc: 84.398% (7427/8800)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.404% (7512/8900)\n",
      "Test Epoch: 29 | Loss: 0.482 | Acc: 84.422% (7598/9000)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.385% (7679/9100)\n",
      "Test Epoch: 29 | Loss: 0.480 | Acc: 84.435% (7768/9200)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.419% (7851/9300)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.426% (7936/9400)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.442% (8022/9500)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.448% (8107/9600)\n",
      "Test Epoch: 29 | Loss: 0.479 | Acc: 84.505% (8197/9700)\n",
      "Test Epoch: 29 | Loss: 0.479 | Acc: 84.469% (8278/9800)\n",
      "Test Epoch: 29 | Loss: 0.481 | Acc: 84.434% (8359/9900)\n",
      "Test Epoch: 29 | Loss: 0.483 | Acc: 84.400% (8440/10000)\n",
      "\n",
      "Epoch: 30\n",
      "Train Epoch: 30 | Loss: 0.262 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 30 | Loss: 0.357 | Acc: 87.891% (225/256)\n",
      "Train Epoch: 30 | Loss: 0.349 | Acc: 87.240% (335/384)\n",
      "Train Epoch: 30 | Loss: 0.359 | Acc: 87.305% (447/512)\n",
      "Train Epoch: 30 | Loss: 0.361 | Acc: 87.656% (561/640)\n",
      "Train Epoch: 30 | Loss: 0.372 | Acc: 87.240% (670/768)\n",
      "Train Epoch: 30 | Loss: 0.362 | Acc: 87.612% (785/896)\n",
      "Train Epoch: 30 | Loss: 0.350 | Acc: 87.695% (898/1024)\n",
      "Train Epoch: 30 | Loss: 0.341 | Acc: 88.108% (1015/1152)\n",
      "Train Epoch: 30 | Loss: 0.343 | Acc: 87.969% (1126/1280)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.068% (1240/1408)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.346% (1357/1536)\n",
      "Train Epoch: 30 | Loss: 0.339 | Acc: 88.341% (1470/1664)\n",
      "Train Epoch: 30 | Loss: 0.359 | Acc: 87.667% (1571/1792)\n",
      "Train Epoch: 30 | Loss: 0.352 | Acc: 87.969% (1689/1920)\n",
      "Train Epoch: 30 | Loss: 0.352 | Acc: 88.037% (1803/2048)\n",
      "Train Epoch: 30 | Loss: 0.350 | Acc: 88.143% (1918/2176)\n",
      "Train Epoch: 30 | Loss: 0.346 | Acc: 88.281% (2034/2304)\n",
      "Train Epoch: 30 | Loss: 0.348 | Acc: 88.240% (2146/2432)\n",
      "Train Epoch: 30 | Loss: 0.347 | Acc: 88.398% (2263/2560)\n",
      "Train Epoch: 30 | Loss: 0.344 | Acc: 88.430% (2377/2688)\n",
      "Train Epoch: 30 | Loss: 0.340 | Acc: 88.601% (2495/2816)\n",
      "Train Epoch: 30 | Loss: 0.341 | Acc: 88.587% (2608/2944)\n",
      "Train Epoch: 30 | Loss: 0.340 | Acc: 88.574% (2721/3072)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.781% (2841/3200)\n",
      "Train Epoch: 30 | Loss: 0.338 | Acc: 88.672% (2951/3328)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.918% (3073/3456)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.811% (3183/3584)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.820% (3297/3712)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.906% (3414/3840)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.911% (3528/3968)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.867% (3640/4096)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.944% (3757/4224)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.994% (3873/4352)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.839% (3980/4480)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.889% (4096/4608)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.830% (4207/4736)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.816% (4320/4864)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.862% (4436/4992)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.809% (4547/5120)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.910% (4666/5248)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.007% (4785/5376)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.026% (4900/5504)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.027% (5014/5632)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.097% (5132/5760)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.079% (5245/5888)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.112% (5361/6016)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.111% (5475/6144)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.174% (5593/6272)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.219% (5710/6400)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.246% (5826/6528)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.333% (5946/6656)\n",
      "Train Epoch: 30 | Loss: 0.317 | Acc: 89.402% (6065/6784)\n",
      "Train Epoch: 30 | Loss: 0.317 | Acc: 89.410% (6180/6912)\n",
      "Train Epoch: 30 | Loss: 0.317 | Acc: 89.460% (6298/7040)\n",
      "Train Epoch: 30 | Loss: 0.317 | Acc: 89.467% (6413/7168)\n",
      "Train Epoch: 30 | Loss: 0.315 | Acc: 89.501% (6530/7296)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.305% (6630/7424)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.301% (6744/7552)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.258% (6855/7680)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.267% (6970/7808)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.239% (7082/7936)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.273% (7199/8064)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.209% (7308/8192)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.219% (7423/8320)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.240% (7539/8448)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.249% (7654/8576)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.177% (7762/8704)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.187% (7877/8832)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.185% (7991/8960)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.228% (8109/9088)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.301% (8230/9216)\n",
      "Train Epoch: 30 | Loss: 0.318 | Acc: 89.244% (8339/9344)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.189% (8448/9472)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.198% (8563/9600)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.196% (8677/9728)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.235% (8795/9856)\n",
      "Train Epoch: 30 | Loss: 0.319 | Acc: 89.273% (8913/9984)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.221% (9022/10112)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.199% (9134/10240)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.188% (9247/10368)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.215% (9364/10496)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.175% (9474/10624)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.146% (9585/10752)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.127% (9697/10880)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.144% (9813/11008)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.170% (9930/11136)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.125% (10039/11264)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.115% (10152/11392)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.149% (10270/11520)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.148% (10384/11648)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.139% (10497/11776)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.113% (10608/11904)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.137% (10725/12032)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.128% (10838/12160)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.128% (10952/12288)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.143% (11068/12416)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.158% (11184/12544)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.189% (11302/12672)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.188% (11416/12800)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.240% (11537/12928)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.239% (11651/13056)\n",
      "Train Epoch: 30 | Loss: 0.320 | Acc: 89.229% (11764/13184)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.205% (11875/13312)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.167% (11984/13440)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.173% (12099/13568)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.172% (12213/13696)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.113% (12319/13824)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.113% (12433/13952)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.112% (12547/14080)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.105% (12660/14208)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.097% (12773/14336)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.118% (12890/14464)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.104% (13002/14592)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.069% (13111/14720)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.056% (13223/14848)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.056% (13337/14976)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.016% (13445/15104)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.030% (13561/15232)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.017% (13673/15360)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.011% (13786/15488)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.037% (13904/15616)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.056% (14021/15744)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.050% (14134/15872)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.044% (14247/16000)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.069% (14365/16128)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.007% (14469/16256)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.014% (14584/16384)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.990% (14694/16512)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.984% (14807/16640)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.985% (14921/16768)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.991% (15036/16896)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.969% (15146/17024)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.963% (15259/17152)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.981% (15376/17280)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.959% (15486/17408)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.948% (15598/17536)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.961% (15714/17664)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.984% (15832/17792)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.023% (15953/17920)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.013% (16065/18048)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.991% (16175/18176)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.030% (16296/18304)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.008% (16406/18432)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.987% (16516/18560)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.977% (16628/18688)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.962% (16739/18816)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.931% (16847/18944)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.931% (16961/19072)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.911% (17071/19200)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.938% (17190/19328)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.919% (17300/19456)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.930% (17416/19584)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.936% (17531/19712)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.957% (17649/19840)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.962% (17764/19968)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.963% (17878/20096)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.969% (17993/20224)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.959% (18105/20352)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.945% (18216/20480)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.970% (18335/20608)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.976% (18450/20736)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 88.995% (18568/20864)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.020% (18687/20992)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.034% (18804/21120)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.030% (18917/21248)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.030% (19031/21376)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.044% (19148/21504)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.067% (19267/21632)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.067% (19381/21760)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.072% (19496/21888)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.067% (19609/22016)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.058% (19721/22144)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.067% (19837/22272)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.085% (19955/22400)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.089% (20070/22528)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.080% (20182/22656)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.102% (20301/22784)\n",
      "Train Epoch: 30 | Loss: 0.321 | Acc: 89.115% (20418/22912)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.089% (20526/23040)\n",
      "Train Epoch: 30 | Loss: 0.322 | Acc: 89.084% (20639/23168)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.080% (20752/23296)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.071% (20864/23424)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.054% (20974/23552)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.046% (21086/23680)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.058% (21203/23808)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.033% (21311/23936)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.042% (21427/24064)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.025% (21537/24192)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.038% (21654/24320)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.042% (21769/24448)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.042% (21883/24576)\n",
      "Train Epoch: 30 | Loss: 0.323 | Acc: 89.050% (21999/24704)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.002% (22101/24832)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.030% (22222/24960)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.015% (22332/25088)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.031% (22450/25216)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.023% (22562/25344)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.015% (22674/25472)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.008% (22786/25600)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.028% (22905/25728)\n",
      "Train Epoch: 30 | Loss: 0.324 | Acc: 89.008% (23014/25856)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.989% (23123/25984)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 88.986% (23236/26112)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.967% (23345/26240)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.979% (23462/26368)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.976% (23575/26496)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.984% (23691/26624)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.010% (23812/26752)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.025% (23930/26880)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.014% (24041/27008)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.985% (24147/27136)\n",
      "Train Epoch: 30 | Loss: 0.325 | Acc: 89.007% (24267/27264)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.000% (24379/27392)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.979% (24487/27520)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.983% (24602/27648)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.976% (24714/27776)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.976% (24828/27904)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.980% (24943/28032)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 88.988% (25059/28160)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.002% (25177/28288)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.010% (25293/28416)\n",
      "Train Epoch: 30 | Loss: 0.326 | Acc: 89.006% (25406/28544)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.989% (25515/28672)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.990% (25629/28800)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.969% (25737/28928)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.970% (25851/29056)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.973% (25966/29184)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.957% (26075/29312)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.937% (26183/29440)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.931% (26295/29568)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.904% (26401/29696)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.918% (26519/29824)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.919% (26633/29952)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.913% (26745/30080)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.904% (26856/30208)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.921% (26975/30336)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.912% (27086/30464)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.925% (27204/30592)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.910% (27313/30720)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.900% (27424/30848)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.901% (27538/30976)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.911% (27655/31104)\n",
      "Train Epoch: 30 | Loss: 0.327 | Acc: 88.915% (27770/31232)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.884% (27874/31360)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.888% (27989/31488)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.895% (28105/31616)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.892% (28218/31744)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.893% (28332/31872)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.897% (28447/32000)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.910% (28565/32128)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.895% (28674/32256)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.890% (28786/32384)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.890% (28900/32512)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.897% (29016/32640)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.907% (29133/32768)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.898% (29244/32896)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.899% (29358/33024)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.906% (29474/33152)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.906% (29588/33280)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.925% (29708/33408)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.931% (29824/33536)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.932% (29938/33664)\n",
      "Train Epoch: 30 | Loss: 0.328 | Acc: 88.926% (30050/33792)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.921% (30162/33920)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.919% (30275/34048)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.910% (30386/34176)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.893% (30494/34304)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.894% (30608/34432)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.895% (30722/34560)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.904% (30839/34688)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.899% (30951/34816)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.914% (31070/34944)\n",
      "Train Epoch: 30 | Loss: 0.329 | Acc: 88.909% (31182/35072)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.889% (31289/35200)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.881% (31400/35328)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.879% (31513/35456)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.891% (31631/35584)\n",
      "Train Epoch: 30 | Loss: 0.330 | Acc: 88.880% (31741/35712)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.870% (31851/35840)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.871% (31965/35968)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.871% (32079/36096)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.858% (32188/36224)\n",
      "Train Epoch: 30 | Loss: 0.331 | Acc: 88.851% (32299/36352)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.838% (32408/36480)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.849% (32526/36608)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.845% (32638/36736)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.821% (32743/36864)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.819% (32856/36992)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.809% (32966/37120)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.807% (33079/37248)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.808% (33193/37376)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.812% (33308/37504)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.818% (33424/37632)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.790% (33527/37760)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.796% (33643/37888)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.794% (33756/38016)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.782% (33865/38144)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.786% (33980/38272)\n",
      "Train Epoch: 30 | Loss: 0.332 | Acc: 88.779% (34091/38400)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.756% (34196/38528)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.752% (34308/38656)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.745% (34419/38784)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.749% (34534/38912)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.740% (34644/39040)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.723% (34751/39168)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.732% (34868/39296)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.728% (34980/39424)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.719% (35090/39552)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.727% (35207/39680)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.736% (35324/39808)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.732% (35436/39936)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.728% (35548/40064)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.729% (35662/40192)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.728% (35775/40320)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.739% (35893/40448)\n",
      "Train Epoch: 30 | Loss: 0.333 | Acc: 88.740% (36007/40576)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.726% (36115/40704)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.720% (36226/40832)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.716% (36338/40960)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.727% (36456/41088)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.716% (36565/41216)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.717% (36679/41344)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.720% (36794/41472)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.704% (36901/41600)\n",
      "Train Epoch: 30 | Loss: 0.334 | Acc: 88.705% (37015/41728)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.702% (37127/41856)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.705% (37242/41984)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.706% (37356/42112)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.707% (37470/42240)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.692% (37577/42368)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.688% (37689/42496)\n",
      "Train Epoch: 30 | Loss: 0.335 | Acc: 88.682% (37800/42624)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.674% (37910/42752)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.682% (38027/42880)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.670% (38135/43008)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.668% (38248/43136)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.663% (38359/43264)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.659% (38471/43392)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.644% (38578/43520)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.641% (38690/43648)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.628% (38798/43776)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.634% (38914/43904)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.640% (39030/44032)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.625% (39137/44160)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.629% (39252/44288)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.632% (39367/44416)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.636% (39482/44544)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.639% (39597/44672)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.634% (39708/44800)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.622% (39816/44928)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.627% (39932/45056)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.627% (40045/45184)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.619% (40155/45312)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.622% (40270/45440)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.635% (40389/45568)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.627% (40499/45696)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.622% (40610/45824)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.632% (40728/45952)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.624% (40838/46080)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.606% (40943/46208)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.609% (41058/46336)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.611% (41172/46464)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.607% (41284/46592)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.609% (41398/46720)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.614% (41514/46848)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.601% (41621/46976)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.591% (41730/47104)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.595% (41845/47232)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.590% (41956/47360)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.591% (42070/47488)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.586% (42181/47616)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.583% (42293/47744)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.572% (42401/47872)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.577% (42517/48000)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.580% (42632/48128)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.594% (42752/48256)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.597% (42867/48384)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.595% (42979/48512)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.596% (43093/48640)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.583% (43200/48768)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.586% (43315/48896)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.591% (43431/49024)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.595% (43546/49152)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.594% (43659/49280)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.601% (43776/49408)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.596% (43887/49536)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.593% (43999/49664)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.601% (44116/49792)\n",
      "Train Epoch: 30 | Loss: 0.336 | Acc: 88.604% (44231/49920)\n",
      "Train Epoch: 30 | Loss: 0.337 | Acc: 88.596% (44298/50000)\n",
      "Test Epoch: 30 | Loss: 0.406 | Acc: 85.000% (85/100)\n",
      "Test Epoch: 30 | Loss: 0.446 | Acc: 85.500% (171/200)\n",
      "Test Epoch: 30 | Loss: 0.451 | Acc: 85.000% (255/300)\n",
      "Test Epoch: 30 | Loss: 0.419 | Acc: 86.000% (344/400)\n",
      "Test Epoch: 30 | Loss: 0.417 | Acc: 85.000% (425/500)\n",
      "Test Epoch: 30 | Loss: 0.393 | Acc: 86.167% (517/600)\n",
      "Test Epoch: 30 | Loss: 0.400 | Acc: 84.857% (594/700)\n",
      "Test Epoch: 30 | Loss: 0.416 | Acc: 85.000% (680/800)\n",
      "Test Epoch: 30 | Loss: 0.451 | Acc: 84.111% (757/900)\n",
      "Test Epoch: 30 | Loss: 0.441 | Acc: 84.700% (847/1000)\n",
      "Test Epoch: 30 | Loss: 0.438 | Acc: 85.000% (935/1100)\n",
      "Test Epoch: 30 | Loss: 0.446 | Acc: 85.000% (1020/1200)\n",
      "Test Epoch: 30 | Loss: 0.435 | Acc: 85.308% (1109/1300)\n",
      "Test Epoch: 30 | Loss: 0.431 | Acc: 85.286% (1194/1400)\n",
      "Test Epoch: 30 | Loss: 0.421 | Acc: 85.467% (1282/1500)\n",
      "Test Epoch: 30 | Loss: 0.425 | Acc: 85.125% (1362/1600)\n",
      "Test Epoch: 30 | Loss: 0.424 | Acc: 85.412% (1452/1700)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 85.444% (1538/1800)\n",
      "Test Epoch: 30 | Loss: 0.423 | Acc: 85.579% (1626/1900)\n",
      "Test Epoch: 30 | Loss: 0.427 | Acc: 85.750% (1715/2000)\n",
      "Test Epoch: 30 | Loss: 0.434 | Acc: 85.286% (1791/2100)\n",
      "Test Epoch: 30 | Loss: 0.429 | Acc: 85.409% (1879/2200)\n",
      "Test Epoch: 30 | Loss: 0.440 | Acc: 85.174% (1959/2300)\n",
      "Test Epoch: 30 | Loss: 0.441 | Acc: 85.167% (2044/2400)\n",
      "Test Epoch: 30 | Loss: 0.450 | Acc: 85.000% (2125/2500)\n",
      "Test Epoch: 30 | Loss: 0.450 | Acc: 85.154% (2214/2600)\n",
      "Test Epoch: 30 | Loss: 0.448 | Acc: 85.333% (2304/2700)\n",
      "Test Epoch: 30 | Loss: 0.448 | Acc: 85.250% (2387/2800)\n",
      "Test Epoch: 30 | Loss: 0.450 | Acc: 85.207% (2471/2900)\n",
      "Test Epoch: 30 | Loss: 0.455 | Acc: 85.100% (2553/3000)\n",
      "Test Epoch: 30 | Loss: 0.460 | Acc: 85.000% (2635/3100)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.938% (2718/3200)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.879% (2801/3300)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.735% (2881/3400)\n",
      "Test Epoch: 30 | Loss: 0.468 | Acc: 84.714% (2965/3500)\n",
      "Test Epoch: 30 | Loss: 0.469 | Acc: 84.833% (3054/3600)\n",
      "Test Epoch: 30 | Loss: 0.474 | Acc: 84.838% (3139/3700)\n",
      "Test Epoch: 30 | Loss: 0.475 | Acc: 84.763% (3221/3800)\n",
      "Test Epoch: 30 | Loss: 0.474 | Acc: 84.795% (3307/3900)\n",
      "Test Epoch: 30 | Loss: 0.472 | Acc: 84.725% (3389/4000)\n",
      "Test Epoch: 30 | Loss: 0.472 | Acc: 84.780% (3476/4100)\n",
      "Test Epoch: 30 | Loss: 0.472 | Acc: 84.738% (3559/4200)\n",
      "Test Epoch: 30 | Loss: 0.467 | Acc: 84.860% (3649/4300)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.977% (3739/4400)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 85.044% (3827/4500)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 85.065% (3913/4600)\n",
      "Test Epoch: 30 | Loss: 0.460 | Acc: 85.085% (3999/4700)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 85.083% (4084/4800)\n",
      "Test Epoch: 30 | Loss: 0.459 | Acc: 85.102% (4170/4900)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.980% (4249/5000)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.980% (4334/5100)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.865% (4413/5200)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.792% (4494/5300)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.815% (4580/5400)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.764% (4662/5500)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.786% (4748/5600)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.789% (4833/5700)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.845% (4921/5800)\n",
      "Test Epoch: 30 | Loss: 0.467 | Acc: 84.780% (5002/5900)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.833% (5090/6000)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.770% (5171/6100)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.742% (5254/6200)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.794% (5342/6300)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.859% (5431/6400)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.815% (5513/6500)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.803% (5597/6600)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 84.836% (5684/6700)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.779% (5765/6800)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.710% (5845/6900)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.657% (5926/7000)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.676% (6012/7100)\n",
      "Test Epoch: 30 | Loss: 0.468 | Acc: 84.625% (6093/7200)\n",
      "Test Epoch: 30 | Loss: 0.466 | Acc: 84.685% (6182/7300)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.730% (6270/7400)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.733% (6355/7500)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.697% (6437/7600)\n",
      "Test Epoch: 30 | Loss: 0.467 | Acc: 84.675% (6520/7700)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.769% (6612/7800)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.797% (6699/7900)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.850% (6788/8000)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.840% (6872/8100)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.866% (6959/8200)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.843% (7042/8300)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 84.881% (7130/8400)\n",
      "Test Epoch: 30 | Loss: 0.462 | Acc: 84.859% (7213/8500)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.814% (7294/8600)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.839% (7381/8700)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.864% (7468/8800)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.865% (7553/8900)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.844% (7636/9000)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.846% (7721/9100)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.891% (7810/9200)\n",
      "Test Epoch: 30 | Loss: 0.465 | Acc: 84.892% (7895/9300)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.883% (7979/9400)\n",
      "Test Epoch: 30 | Loss: 0.464 | Acc: 84.863% (8062/9500)\n",
      "Test Epoch: 30 | Loss: 0.463 | Acc: 84.854% (8146/9600)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 84.918% (8237/9700)\n",
      "Test Epoch: 30 | Loss: 0.459 | Acc: 84.939% (8324/9800)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 84.889% (8404/9900)\n",
      "Test Epoch: 30 | Loss: 0.461 | Acc: 84.880% (8488/10000)\n",
      "\n",
      "Epoch: 31\n",
      "Train Epoch: 31 | Loss: 0.258 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 31 | Loss: 0.246 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 31 | Loss: 0.271 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 31 | Loss: 0.274 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 31 | Loss: 0.271 | Acc: 91.250% (584/640)\n",
      "Train Epoch: 31 | Loss: 0.288 | Acc: 90.365% (694/768)\n",
      "Train Epoch: 31 | Loss: 0.289 | Acc: 90.737% (813/896)\n",
      "Train Epoch: 31 | Loss: 0.288 | Acc: 90.430% (926/1024)\n",
      "Train Epoch: 31 | Loss: 0.289 | Acc: 90.191% (1039/1152)\n",
      "Train Epoch: 31 | Loss: 0.292 | Acc: 89.922% (1151/1280)\n",
      "Train Epoch: 31 | Loss: 0.290 | Acc: 89.915% (1266/1408)\n",
      "Train Epoch: 31 | Loss: 0.286 | Acc: 89.974% (1382/1536)\n",
      "Train Epoch: 31 | Loss: 0.289 | Acc: 90.084% (1499/1664)\n",
      "Train Epoch: 31 | Loss: 0.298 | Acc: 89.676% (1607/1792)\n",
      "Train Epoch: 31 | Loss: 0.300 | Acc: 89.531% (1719/1920)\n",
      "Train Epoch: 31 | Loss: 0.304 | Acc: 89.551% (1834/2048)\n",
      "Train Epoch: 31 | Loss: 0.304 | Acc: 89.476% (1947/2176)\n",
      "Train Epoch: 31 | Loss: 0.304 | Acc: 89.540% (2063/2304)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.391% (2174/2432)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.414% (2289/2560)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.397% (2403/2688)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.382% (2517/2816)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.232% (2627/2944)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.355% (2745/3072)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.375% (2860/3200)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.333% (2973/3328)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.323% (3087/3456)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.342% (3202/3584)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.467% (3321/3712)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.245% (3427/3840)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.189% (3539/3968)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.258% (3656/4096)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.205% (3768/4224)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.131% (3879/4352)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.241% (3998/4480)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.323% (4116/4608)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.253% (4227/4736)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.309% (4344/4864)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.203% (4453/4992)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.102% (4562/5120)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.024% (4672/5248)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.062% (4788/5376)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.044% (4901/5504)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.045% (5015/5632)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.115% (5133/5760)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.113% (5247/5888)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.129% (5362/6016)\n",
      "Train Epoch: 31 | Loss: 0.311 | Acc: 89.176% (5479/6144)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.302% (5601/6272)\n",
      "Train Epoch: 31 | Loss: 0.307 | Acc: 89.359% (5719/6400)\n",
      "Train Epoch: 31 | Loss: 0.310 | Acc: 89.246% (5826/6528)\n",
      "Train Epoch: 31 | Loss: 0.308 | Acc: 89.273% (5942/6656)\n",
      "Train Epoch: 31 | Loss: 0.307 | Acc: 89.328% (6060/6784)\n",
      "Train Epoch: 31 | Loss: 0.307 | Acc: 89.265% (6170/6912)\n",
      "Train Epoch: 31 | Loss: 0.308 | Acc: 89.247% (6283/7040)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.244% (6397/7168)\n",
      "Train Epoch: 31 | Loss: 0.310 | Acc: 89.227% (6510/7296)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.265% (6627/7424)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.208% (6737/7552)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.167% (6848/7680)\n",
      "Train Epoch: 31 | Loss: 0.310 | Acc: 89.139% (6960/7808)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.151% (7075/7936)\n",
      "Train Epoch: 31 | Loss: 0.310 | Acc: 89.125% (7187/8064)\n",
      "Train Epoch: 31 | Loss: 0.309 | Acc: 89.185% (7306/8192)\n",
      "Train Epoch: 31 | Loss: 0.310 | Acc: 89.159% (7418/8320)\n",
      "Train Epoch: 31 | Loss: 0.311 | Acc: 89.122% (7529/8448)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.051% (7637/8576)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.074% (7753/8704)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.051% (7865/8832)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 88.996% (7974/8960)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 88.974% (8086/9088)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.019% (8204/9216)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 88.998% (8316/9344)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.073% (8437/9472)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.062% (8550/9600)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.083% (8666/9728)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.052% (8777/9856)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.052% (8891/9984)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.112% (9011/10112)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.092% (9123/10240)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.062% (9234/10368)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.053% (9347/10496)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.044% (9460/10624)\n",
      "Train Epoch: 31 | Loss: 0.311 | Acc: 89.062% (9576/10752)\n",
      "Train Epoch: 31 | Loss: 0.312 | Acc: 89.072% (9691/10880)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.053% (9803/11008)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.071% (9919/11136)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.036% (10029/11264)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.045% (10144/11392)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.062% (10260/11520)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.062% (10374/11648)\n",
      "Train Epoch: 31 | Loss: 0.314 | Acc: 89.122% (10495/11776)\n",
      "Train Epoch: 31 | Loss: 0.313 | Acc: 89.155% (10613/11904)\n",
      "Train Epoch: 31 | Loss: 0.315 | Acc: 89.087% (10719/12032)\n",
      "Train Epoch: 31 | Loss: 0.316 | Acc: 89.071% (10831/12160)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.014% (10938/12288)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.030% (11054/12416)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.031% (11168/12544)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.047% (11284/12672)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.078% (11402/12800)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.055% (11513/12928)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.024% (11623/13056)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.055% (11741/13184)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.055% (11855/13312)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.077% (11972/13440)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.085% (12087/13568)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.099% (12203/13696)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.099% (12317/13824)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.106% (12432/13952)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.105% (12546/14080)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.084% (12657/14208)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.097% (12773/14336)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.104% (12888/14464)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.104% (13002/14592)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.110% (13117/14720)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.150% (13237/14848)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.136% (13349/14976)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.129% (13462/15104)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.135% (13577/15232)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.167% (13696/15360)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.140% (13806/15488)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.152% (13922/15616)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.164% (14038/15744)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.170% (14153/15872)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.175% (14268/16000)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.162% (14380/16128)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.149% (14492/16256)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.154% (14607/16384)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.135% (14718/16512)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.165% (14837/16640)\n",
      "Train Epoch: 31 | Loss: 0.317 | Acc: 89.188% (14955/16768)\n",
      "Train Epoch: 31 | Loss: 0.318 | Acc: 89.193% (15070/16896)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.174% (15181/17024)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.173% (15295/17152)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.149% (15405/17280)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.160% (15521/17408)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.159% (15635/17536)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.176% (15752/17664)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.152% (15862/17792)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.174% (15980/17920)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.168% (16093/18048)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.173% (16208/18176)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.177% (16323/18304)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.160% (16434/18432)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.165% (16549/18560)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.196% (16669/18688)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.195% (16783/18816)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.179% (16894/18944)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.199% (17012/19072)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.156% (17118/19200)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.156% (17232/19328)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.140% (17343/19456)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.144% (17458/19584)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.149% (17573/19712)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.143% (17686/19840)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.148% (17801/19968)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.172% (17920/20096)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.142% (18028/20224)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.136% (18141/20352)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.141% (18256/20480)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.140% (18370/20608)\n",
      "Train Epoch: 31 | Loss: 0.321 | Acc: 89.135% (18483/20736)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.134% (18597/20864)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.153% (18715/20992)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.181% (18835/21120)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.175% (18948/21248)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.156% (19058/21376)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.160% (19173/21504)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.173% (19290/21632)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.187% (19407/21760)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.200% (19524/21888)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.199% (19638/22016)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.216% (19756/22144)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.193% (19865/22272)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.192% (19979/22400)\n",
      "Train Epoch: 31 | Loss: 0.319 | Acc: 89.209% (20097/22528)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.182% (20205/22656)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.168% (20316/22784)\n",
      "Train Epoch: 31 | Loss: 0.320 | Acc: 89.176% (20432/22912)\n",
      "Train Epoch: 31 | Loss: 0.321 | Acc: 89.175% (20546/23040)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.170% (20659/23168)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.161% (20771/23296)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.156% (20884/23424)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.181% (21004/23552)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.151% (21111/23680)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.142% (21223/23808)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.146% (21338/23936)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.133% (21449/24064)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.129% (21562/24192)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.137% (21678/24320)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.132% (21791/24448)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.136% (21906/24576)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.127% (22018/24704)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.119% (22130/24832)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.139% (22249/24960)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.126% (22360/25088)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.130% (22475/25216)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.130% (22589/25344)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.129% (22703/25472)\n",
      "Train Epoch: 31 | Loss: 0.322 | Acc: 89.137% (22819/25600)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.144% (22935/25728)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.124% (23044/25856)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.120% (23157/25984)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.139% (23276/26112)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.165% (23397/26240)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.161% (23510/26368)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.161% (23624/26496)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.179% (23743/26624)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.182% (23858/26752)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.182% (23972/26880)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.174% (24084/27008)\n",
      "Train Epoch: 31 | Loss: 0.323 | Acc: 89.162% (24195/27136)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.132% (24301/27264)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.125% (24413/27392)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.117% (24525/27520)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.138% (24645/27648)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.153% (24763/27776)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.131% (24871/27904)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.145% (24989/28032)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.123% (25097/28160)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.126% (25212/28288)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.119% (25324/28416)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.122% (25439/28544)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.122% (25553/28672)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.125% (25668/28800)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.107% (25777/28928)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.128% (25897/29056)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.114% (26007/29184)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.100% (26117/29312)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.093% (26229/29440)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.100% (26345/29568)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.100% (26459/29696)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.106% (26575/29824)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.103% (26688/29952)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.082% (26796/30080)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.099% (26915/30208)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.072% (27021/30336)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.066% (27133/30464)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.046% (27241/30592)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.040% (27353/30720)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.024% (27462/30848)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.053% (27585/30976)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.056% (27700/31104)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.059% (27815/31232)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.059% (27929/31360)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.043% (28038/31488)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.056% (28156/31616)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.056% (28270/31744)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.053% (28383/31872)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.062% (28500/32000)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.059% (28613/32128)\n",
      "Train Epoch: 31 | Loss: 0.324 | Acc: 89.066% (28729/32256)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.059% (28841/32384)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.041% (28949/32512)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.053% (29067/32640)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.050% (29180/32768)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.050% (29294/32896)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.041% (29405/33024)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.035% (29517/33152)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 89.026% (29628/33280)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 89.018% (29739/33408)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 89.009% (29850/33536)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 89.012% (29965/33664)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.021% (30082/33792)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.036% (30201/33920)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.027% (30312/34048)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.030% (30427/34176)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.013% (30535/34304)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.022% (30652/34432)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.025% (30767/34560)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.019% (30879/34688)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.028% (30996/34816)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.028% (31110/34944)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.025% (31223/35072)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.034% (31340/35200)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.020% (31449/35328)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.020% (31563/35456)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.026% (31679/35584)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.026% (31793/35712)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.018% (31904/35840)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.015% (32017/35968)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.026% (32135/36096)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.016% (32245/36224)\n",
      "Train Epoch: 31 | Loss: 0.325 | Acc: 89.005% (32355/36352)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 88.988% (32463/36480)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 88.970% (32570/36608)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 88.967% (32683/36736)\n",
      "Train Epoch: 31 | Loss: 0.326 | Acc: 88.965% (32796/36864)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.965% (32910/36992)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.955% (33020/37120)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.958% (33135/37248)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.966% (33252/37376)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.959% (33363/37504)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.967% (33480/37632)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.943% (33585/37760)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.941% (33698/37888)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.941% (33812/38016)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.939% (33925/38144)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.942% (34040/38272)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.948% (34156/38400)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.941% (34267/38528)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.946% (34383/38656)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.944% (34496/38784)\n",
      "Train Epoch: 31 | Loss: 0.327 | Acc: 88.944% (34610/38912)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.932% (34719/39040)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.945% (34838/39168)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.928% (34945/39296)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.920% (35056/39424)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.916% (35168/39552)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.916% (35282/39680)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.889% (35385/39808)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.885% (35497/39936)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.895% (35615/40064)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.896% (35729/40192)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.911% (35849/40320)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.917% (35965/40448)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.915% (36078/40576)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.918% (36193/40704)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.923% (36309/40832)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.904% (36415/40960)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.902% (36528/41088)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.895% (36639/41216)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.891% (36751/41344)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.879% (36860/41472)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.877% (36973/41600)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.883% (37089/41728)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.879% (37201/41856)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.872% (37312/41984)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.882% (37430/42112)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.868% (37538/42240)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.869% (37652/42368)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.877% (37769/42496)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.880% (37884/42624)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.887% (38001/42752)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.871% (38108/42880)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.874% (38223/43008)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.877% (38338/43136)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.859% (38444/43264)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.853% (38555/43392)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.865% (38674/43520)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.863% (38787/43648)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.859% (38899/43776)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.853% (39010/43904)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.863% (39128/44032)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.870% (39245/44160)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.877% (39362/44288)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.885% (39479/44416)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.881% (39591/44544)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.886% (39707/44672)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.882% (39819/44800)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.884% (39934/44928)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.889% (40050/45056)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.897% (40167/45184)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.890% (40278/45312)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.889% (40391/45440)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.876% (40499/45568)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.872% (40611/45696)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.877% (40727/45824)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.880% (40842/45952)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.893% (40962/46080)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.894% (41076/46208)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.890% (41188/46336)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.897% (41305/46464)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.902% (41421/46592)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.893% (41531/46720)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.896% (41646/46848)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.903% (41763/46976)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.903% (41877/47104)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.899% (41989/47232)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.894% (42100/47360)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.886% (42210/47488)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.880% (42321/47616)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.880% (42435/47744)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.881% (42549/47872)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.871% (42658/48000)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.861% (42767/48128)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.880% (42890/48256)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.874% (43001/48384)\n",
      "Train Epoch: 31 | Loss: 0.328 | Acc: 88.885% (43120/48512)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.880% (43231/48640)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.876% (43343/48768)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.872% (43455/48896)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.875% (43570/49024)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.859% (43676/49152)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.853% (43787/49280)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.860% (43904/49408)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.861% (44018/49536)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.859% (44131/49664)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.850% (44240/49792)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.852% (44355/49920)\n",
      "Train Epoch: 31 | Loss: 0.329 | Acc: 88.860% (44430/50000)\n",
      "Test Epoch: 31 | Loss: 0.299 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 31 | Loss: 0.389 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 31 | Loss: 0.380 | Acc: 86.667% (260/300)\n",
      "Test Epoch: 31 | Loss: 0.383 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 31 | Loss: 0.383 | Acc: 86.800% (434/500)\n",
      "Test Epoch: 31 | Loss: 0.367 | Acc: 87.333% (524/600)\n",
      "Test Epoch: 31 | Loss: 0.382 | Acc: 86.857% (608/700)\n",
      "Test Epoch: 31 | Loss: 0.405 | Acc: 86.500% (692/800)\n",
      "Test Epoch: 31 | Loss: 0.436 | Acc: 86.333% (777/900)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.300% (863/1000)\n",
      "Test Epoch: 31 | Loss: 0.414 | Acc: 86.818% (955/1100)\n",
      "Test Epoch: 31 | Loss: 0.412 | Acc: 86.750% (1041/1200)\n",
      "Test Epoch: 31 | Loss: 0.404 | Acc: 86.923% (1130/1300)\n",
      "Test Epoch: 31 | Loss: 0.405 | Acc: 86.929% (1217/1400)\n",
      "Test Epoch: 31 | Loss: 0.407 | Acc: 86.867% (1303/1500)\n",
      "Test Epoch: 31 | Loss: 0.404 | Acc: 87.062% (1393/1600)\n",
      "Test Epoch: 31 | Loss: 0.405 | Acc: 86.941% (1478/1700)\n",
      "Test Epoch: 31 | Loss: 0.414 | Acc: 86.833% (1563/1800)\n",
      "Test Epoch: 31 | Loss: 0.417 | Acc: 86.684% (1647/1900)\n",
      "Test Epoch: 31 | Loss: 0.417 | Acc: 86.750% (1735/2000)\n",
      "Test Epoch: 31 | Loss: 0.421 | Acc: 86.381% (1814/2100)\n",
      "Test Epoch: 31 | Loss: 0.416 | Acc: 86.455% (1902/2200)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.043% (1979/2300)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 86.292% (2071/2400)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.240% (2156/2500)\n",
      "Test Epoch: 31 | Loss: 0.432 | Acc: 86.154% (2240/2600)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 86.148% (2326/2700)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 86.000% (2408/2800)\n",
      "Test Epoch: 31 | Loss: 0.432 | Acc: 86.034% (2495/2900)\n",
      "Test Epoch: 31 | Loss: 0.431 | Acc: 86.033% (2581/3000)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 86.000% (2666/3100)\n",
      "Test Epoch: 31 | Loss: 0.436 | Acc: 86.000% (2752/3200)\n",
      "Test Epoch: 31 | Loss: 0.435 | Acc: 86.030% (2839/3300)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 85.853% (2919/3400)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 85.829% (3004/3500)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 85.806% (3089/3600)\n",
      "Test Epoch: 31 | Loss: 0.438 | Acc: 85.784% (3174/3700)\n",
      "Test Epoch: 31 | Loss: 0.437 | Acc: 85.737% (3258/3800)\n",
      "Test Epoch: 31 | Loss: 0.433 | Acc: 85.846% (3348/3900)\n",
      "Test Epoch: 31 | Loss: 0.433 | Acc: 85.875% (3435/4000)\n",
      "Test Epoch: 31 | Loss: 0.432 | Acc: 85.854% (3520/4100)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 85.881% (3607/4200)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 85.953% (3696/4300)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.000% (3784/4400)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.089% (3874/4500)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.087% (3960/4600)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.085% (4046/4700)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 85.958% (4126/4800)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 86.082% (4218/4900)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 86.040% (4302/5000)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.137% (4393/5100)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.115% (4478/5200)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.038% (4560/5300)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.056% (4647/5400)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 85.964% (4728/5500)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 85.911% (4811/5600)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 85.895% (4896/5700)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 85.966% (4986/5800)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 85.847% (5065/5900)\n",
      "Test Epoch: 31 | Loss: 0.429 | Acc: 85.783% (5147/6000)\n",
      "Test Epoch: 31 | Loss: 0.429 | Acc: 85.787% (5233/6100)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 85.823% (5321/6200)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 85.905% (5412/6300)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 85.938% (5500/6400)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 85.923% (5585/6500)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 85.939% (5672/6600)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 85.955% (5759/6700)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 85.809% (5835/6800)\n",
      "Test Epoch: 31 | Loss: 0.429 | Acc: 85.841% (5923/6900)\n",
      "Test Epoch: 31 | Loss: 0.431 | Acc: 85.786% (6005/7000)\n",
      "Test Epoch: 31 | Loss: 0.430 | Acc: 85.817% (6093/7100)\n",
      "Test Epoch: 31 | Loss: 0.429 | Acc: 85.861% (6182/7200)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 85.932% (6273/7300)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.014% (6365/7400)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 86.000% (6450/7500)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.039% (6539/7600)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 86.039% (6625/7700)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.077% (6714/7800)\n",
      "Test Epoch: 31 | Loss: 0.428 | Acc: 86.051% (6798/7900)\n",
      "Test Epoch: 31 | Loss: 0.427 | Acc: 86.125% (6890/8000)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.160% (6979/8100)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.171% (7066/8200)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.133% (7149/8300)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 86.179% (7239/8400)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.176% (7325/8500)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.128% (7407/8600)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.138% (7494/8700)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.148% (7581/8800)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.124% (7665/8900)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.111% (7750/9000)\n",
      "Test Epoch: 31 | Loss: 0.426 | Acc: 86.066% (7832/9100)\n",
      "Test Epoch: 31 | Loss: 0.425 | Acc: 86.120% (7923/9200)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.161% (8013/9300)\n",
      "Test Epoch: 31 | Loss: 0.424 | Acc: 86.160% (8099/9400)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 86.168% (8186/9500)\n",
      "Test Epoch: 31 | Loss: 0.423 | Acc: 86.167% (8272/9600)\n",
      "Test Epoch: 31 | Loss: 0.420 | Acc: 86.247% (8366/9700)\n",
      "Test Epoch: 31 | Loss: 0.420 | Acc: 86.286% (8456/9800)\n",
      "Test Epoch: 31 | Loss: 0.421 | Acc: 86.242% (8538/9900)\n",
      "Test Epoch: 31 | Loss: 0.421 | Acc: 86.240% (8624/10000)\n",
      "\n",
      "Epoch: 32\n",
      "Train Epoch: 32 | Loss: 0.246 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 32 | Loss: 0.259 | Acc: 90.234% (231/256)\n",
      "Train Epoch: 32 | Loss: 0.290 | Acc: 89.583% (344/384)\n",
      "Train Epoch: 32 | Loss: 0.271 | Acc: 90.430% (463/512)\n",
      "Train Epoch: 32 | Loss: 0.293 | Acc: 89.844% (575/640)\n",
      "Train Epoch: 32 | Loss: 0.278 | Acc: 90.755% (697/768)\n",
      "Train Epoch: 32 | Loss: 0.274 | Acc: 90.513% (811/896)\n",
      "Train Epoch: 32 | Loss: 0.269 | Acc: 90.625% (928/1024)\n",
      "Train Epoch: 32 | Loss: 0.270 | Acc: 90.972% (1048/1152)\n",
      "Train Epoch: 32 | Loss: 0.273 | Acc: 90.938% (1164/1280)\n",
      "Train Epoch: 32 | Loss: 0.279 | Acc: 90.909% (1280/1408)\n",
      "Train Epoch: 32 | Loss: 0.290 | Acc: 90.690% (1393/1536)\n",
      "Train Epoch: 32 | Loss: 0.298 | Acc: 90.264% (1502/1664)\n",
      "Train Epoch: 32 | Loss: 0.304 | Acc: 89.955% (1612/1792)\n",
      "Train Epoch: 32 | Loss: 0.312 | Acc: 89.896% (1726/1920)\n",
      "Train Epoch: 32 | Loss: 0.311 | Acc: 89.990% (1843/2048)\n",
      "Train Epoch: 32 | Loss: 0.314 | Acc: 89.936% (1957/2176)\n",
      "Train Epoch: 32 | Loss: 0.314 | Acc: 89.931% (2072/2304)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.638% (2180/2432)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.570% (2293/2560)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.695% (2411/2688)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.524% (2521/2816)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.368% (2631/2944)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.388% (2746/3072)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.469% (2863/3200)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.453% (2977/3328)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.468% (3092/3456)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.509% (3208/3584)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.197% (3311/3712)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 89.245% (3427/3840)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.315% (3544/3968)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 89.233% (3655/4096)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 89.181% (3767/4224)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 89.200% (3882/4352)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.353% (4003/4480)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.453% (4122/4608)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.506% (4239/4736)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.433% (4350/4864)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.363% (4461/4992)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.277% (4571/5120)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.386% (4691/5248)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.397% (4806/5376)\n",
      "Train Epoch: 32 | Loss: 0.315 | Acc: 89.462% (4924/5504)\n",
      "Train Epoch: 32 | Loss: 0.315 | Acc: 89.471% (5039/5632)\n",
      "Train Epoch: 32 | Loss: 0.312 | Acc: 89.601% (5161/5760)\n",
      "Train Epoch: 32 | Loss: 0.312 | Acc: 89.606% (5276/5888)\n",
      "Train Epoch: 32 | Loss: 0.311 | Acc: 89.678% (5395/6016)\n",
      "Train Epoch: 32 | Loss: 0.313 | Acc: 89.583% (5504/6144)\n",
      "Train Epoch: 32 | Loss: 0.313 | Acc: 89.589% (5619/6272)\n",
      "Train Epoch: 32 | Loss: 0.315 | Acc: 89.516% (5729/6400)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.476% (5841/6528)\n",
      "Train Epoch: 32 | Loss: 0.315 | Acc: 89.543% (5960/6656)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.490% (6071/6784)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.468% (6184/6912)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.389% (6293/7040)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.397% (6408/7168)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.364% (6520/7296)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.278% (6628/7424)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.261% (6741/7552)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.258% (6855/7680)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.203% (6965/7808)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.151% (7075/7936)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.137% (7188/8064)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.136% (7302/8192)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 89.099% (7413/8320)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 89.062% (7524/8448)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.981% (7631/8576)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.994% (7746/8704)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.995% (7860/8832)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 89.007% (7975/8960)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.974% (8086/9088)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.987% (8201/9216)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.988% (8315/9344)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.010% (8431/9472)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.958% (8540/9600)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.991% (8657/9728)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.971% (8769/9856)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.952% (8881/9984)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.914% (8991/10112)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.936% (9107/10240)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.899% (9217/10368)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.815% (9322/10496)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.780% (9432/10624)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.737% (9541/10752)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.805% (9662/10880)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.808% (9776/11008)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.856% (9895/11136)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.903% (10014/11264)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.940% (10132/11392)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.950% (10247/11520)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.925% (10358/11648)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.927% (10472/11776)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.936% (10587/11904)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 89.004% (10709/12032)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.021% (10825/12160)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.022% (10939/12288)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.030% (11054/12416)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.055% (11171/12544)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 89.015% (11280/12672)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.047% (11398/12800)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.055% (11513/12928)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.124% (11636/13056)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.123% (11750/13184)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.123% (11864/13312)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.115% (11977/13440)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.099% (12089/13568)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.106% (12204/13696)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.128% (12321/13824)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.098% (12431/13952)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.062% (12540/14080)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.062% (12654/14208)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.069% (12769/14336)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.090% (12886/14464)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.124% (13005/14592)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.110% (13117/14720)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.096% (13229/14848)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.103% (13344/14976)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.142% (13464/15104)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.187% (13585/15232)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.206% (13702/15360)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.185% (13813/15488)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.184% (13927/15616)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.151% (14036/15744)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.138% (14148/15872)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.175% (14268/16000)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.156% (14379/16128)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.179% (14497/16256)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.172% (14610/16384)\n",
      "Train Epoch: 32 | Loss: 0.316 | Acc: 89.172% (14724/16512)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.159% (14836/16640)\n",
      "Train Epoch: 32 | Loss: 0.317 | Acc: 89.146% (14948/16768)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.116% (15057/16896)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.104% (15169/17024)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.121% (15286/17152)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.126% (15401/17280)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.114% (15513/17408)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.137% (15631/17536)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.119% (15742/17664)\n",
      "Train Epoch: 32 | Loss: 0.318 | Acc: 89.102% (15853/17792)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.062% (15960/17920)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.079% (16077/18048)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.068% (16189/18176)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.068% (16303/18304)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.046% (16413/18432)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.019% (16522/18560)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.993% (16631/18688)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.031% (16752/18816)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.031% (16866/18944)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.052% (16984/19072)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.042% (17096/19200)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.026% (17207/19328)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.985% (17313/19456)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 88.991% (17428/19584)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.981% (17540/19712)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.936% (17645/19840)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.947% (17761/19968)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.918% (17869/20096)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.909% (17981/20224)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.905% (18094/20352)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.906% (18208/20480)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.922% (18325/20608)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.923% (18439/20736)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.938% (18556/20864)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.967% (18676/20992)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.001% (18797/21120)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.987% (18908/21248)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.988% (19022/21376)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.997% (19138/21504)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.993% (19251/21632)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.017% (19370/21760)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.008% (19482/21888)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.013% (19597/22016)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.040% (19717/22144)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.054% (19834/22272)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.022% (19941/22400)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.036% (20058/22528)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.027% (20170/22656)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.023% (20283/22784)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.014% (20395/22912)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.019% (20510/23040)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.002% (20620/23168)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.032% (20741/23296)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.024% (20853/23424)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.041% (20971/23552)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.020% (21080/23680)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.020% (21194/23808)\n",
      "Train Epoch: 32 | Loss: 0.319 | Acc: 89.042% (21313/23936)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.004% (21418/24064)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.000% (21531/24192)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 88.997% (21644/24320)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.005% (21760/24448)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.026% (21879/24576)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.042% (21997/24704)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.062% (22116/24832)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.054% (22228/24960)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.055% (22342/25088)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.055% (22456/25216)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.051% (22569/25344)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.059% (22685/25472)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.062% (22800/25600)\n",
      "Train Epoch: 32 | Loss: 0.320 | Acc: 89.070% (22916/25728)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.070% (23030/25856)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.055% (23140/25984)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.040% (23250/26112)\n",
      "Train Epoch: 32 | Loss: 0.321 | Acc: 89.040% (23364/26240)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.006% (23469/26368)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.006% (23583/26496)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.014% (23699/26624)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.010% (23812/26752)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 89.010% (23926/26880)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.988% (24034/27008)\n",
      "Train Epoch: 32 | Loss: 0.322 | Acc: 88.989% (24148/27136)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.971% (24257/27264)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.975% (24372/27392)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.946% (24478/27520)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.936% (24589/27648)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.944% (24705/27776)\n",
      "Train Epoch: 32 | Loss: 0.323 | Acc: 88.923% (24813/27904)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.909% (24923/28032)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.892% (25032/28160)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.886% (25144/28288)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.869% (25253/28416)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.866% (25366/28544)\n",
      "Train Epoch: 32 | Loss: 0.324 | Acc: 88.867% (25480/28672)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.854% (25590/28800)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.855% (25704/28928)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.846% (25815/29056)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.840% (25927/29184)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.837% (26040/29312)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.832% (26152/29440)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.836% (26267/29568)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.834% (26380/29696)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.831% (26493/29824)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.849% (26612/29952)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.856% (26728/30080)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.851% (26840/30208)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.828% (26947/30336)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.813% (27056/30464)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.791% (27163/30592)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.796% (27278/30720)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.800% (27393/30848)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.801% (27507/30976)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.799% (27620/31104)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.778% (27727/31232)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.779% (27841/31360)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.777% (27954/31488)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.784% (28070/31616)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.798% (28188/31744)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.802% (28303/31872)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.791% (28413/32000)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.792% (28527/32128)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.811% (28647/32256)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.815% (28762/32384)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.826% (28879/32512)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (28989/32640)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.812% (29102/32768)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.819% (29218/32896)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.826% (29334/33024)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.830% (29449/33152)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.846% (29568/33280)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.841% (29680/33408)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.854% (29798/33536)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.866% (29916/33664)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.864% (30029/33792)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.874% (30146/33920)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.860% (30255/34048)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.864% (30370/34176)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.873% (30487/34304)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.848% (30592/34432)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.863% (30711/34560)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.866% (30826/34688)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.873% (30942/34816)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.862% (31052/34944)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.846% (31160/35072)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.852% (31276/35200)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.862% (31393/35328)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.876% (31512/35456)\n",
      "Train Epoch: 32 | Loss: 0.325 | Acc: 88.871% (31624/35584)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.852% (31731/35712)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.850% (31844/35840)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.843% (31955/35968)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.841% (32068/36096)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.844% (32183/36224)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.829% (32291/36352)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.819% (32401/36480)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.836% (32521/36608)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.839% (32636/36736)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.845% (32752/36864)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.846% (32866/36992)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.855% (32983/37120)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.869% (33102/37248)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.859% (33212/37376)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.868% (33329/37504)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.858% (33439/37632)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.869% (33557/37760)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.867% (33670/37888)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.860% (33781/38016)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.861% (33895/38144)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.861% (34009/38272)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.854% (34120/38400)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.852% (34233/38528)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.843% (34343/38656)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.841% (34456/38784)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.829% (34565/38912)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (34673/39040)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.810% (34785/39168)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.811% (34899/39296)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (35014/39424)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.822% (35131/39552)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.831% (35248/39680)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.839% (35365/39808)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.830% (35475/39936)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.825% (35587/40064)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.821% (35699/40192)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.839% (35820/40320)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.845% (35936/40448)\n",
      "Train Epoch: 32 | Loss: 0.326 | Acc: 88.843% (36049/40576)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.834% (36159/40704)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.822% (36268/40832)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.835% (36387/40960)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.831% (36499/41088)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.839% (36616/41216)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.838% (36729/41344)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.833% (36841/41472)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.832% (36954/41600)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.825% (37065/41728)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.812% (37173/41856)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.812% (37287/41984)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.823% (37405/42112)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (37515/42240)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.819% (37631/42368)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.820% (37745/42496)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.828% (37862/42624)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.826% (37975/42752)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.808% (38081/42880)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (38197/43008)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.812% (38310/43136)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.811% (38423/43264)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.816% (38539/43392)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (38652/43520)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.820% (38768/43648)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.814% (38879/43776)\n",
      "Train Epoch: 32 | Loss: 0.327 | Acc: 88.812% (38992/43904)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.799% (39100/44032)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.798% (39213/44160)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.798% (39327/44288)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.797% (39440/44416)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.798% (39554/44544)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.805% (39671/44672)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.808% (39786/44800)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.795% (39894/44928)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.803% (40011/45056)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.806% (40126/45184)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.813% (40243/45312)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.805% (40353/45440)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.797% (40463/45568)\n",
      "Train Epoch: 32 | Loss: 0.328 | Acc: 88.780% (40569/45696)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.774% (40680/45824)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.773% (40793/45952)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.783% (40911/46080)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.777% (41022/46208)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.782% (41138/46336)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.793% (41257/46464)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.792% (41370/46592)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.799% (41487/46720)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.787% (41595/46848)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.784% (41707/46976)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.770% (41814/47104)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.768% (41927/47232)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.767% (42040/47360)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.763% (42152/47488)\n",
      "Train Epoch: 32 | Loss: 0.329 | Acc: 88.764% (42266/47616)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.734% (42365/47744)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.718% (42471/47872)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.723% (42587/48000)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.732% (42705/48128)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.731% (42818/48256)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.728% (42930/48384)\n",
      "Train Epoch: 32 | Loss: 0.330 | Acc: 88.735% (43047/48512)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.709% (43148/48640)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.700% (43257/48768)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.698% (43370/48896)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.695% (43482/49024)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.696% (43596/49152)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.681% (43702/49280)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.686% (43818/49408)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.685% (43931/49536)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.682% (44043/49664)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.685% (44158/49792)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.688% (44273/49920)\n",
      "Train Epoch: 32 | Loss: 0.331 | Acc: 88.684% (44342/50000)\n",
      "Test Epoch: 32 | Loss: 0.315 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 32 | Loss: 0.340 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 32 | Loss: 0.332 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 32 | Loss: 0.336 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 32 | Loss: 0.323 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 32 | Loss: 0.305 | Acc: 88.833% (533/600)\n",
      "Test Epoch: 32 | Loss: 0.309 | Acc: 89.000% (623/700)\n",
      "Test Epoch: 32 | Loss: 0.344 | Acc: 87.875% (703/800)\n",
      "Test Epoch: 32 | Loss: 0.368 | Acc: 87.333% (786/900)\n",
      "Test Epoch: 32 | Loss: 0.367 | Acc: 87.400% (874/1000)\n",
      "Test Epoch: 32 | Loss: 0.371 | Acc: 87.273% (960/1100)\n",
      "Test Epoch: 32 | Loss: 0.382 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.231% (1134/1300)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.333% (1310/1500)\n",
      "Test Epoch: 32 | Loss: 0.378 | Acc: 87.375% (1398/1600)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.588% (1489/1700)\n",
      "Test Epoch: 32 | Loss: 0.379 | Acc: 87.556% (1576/1800)\n",
      "Test Epoch: 32 | Loss: 0.374 | Acc: 87.737% (1667/1900)\n",
      "Test Epoch: 32 | Loss: 0.374 | Acc: 87.800% (1756/2000)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.524% (1838/2100)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.545% (1926/2200)\n",
      "Test Epoch: 32 | Loss: 0.380 | Acc: 87.435% (2011/2300)\n",
      "Test Epoch: 32 | Loss: 0.382 | Acc: 87.458% (2099/2400)\n",
      "Test Epoch: 32 | Loss: 0.388 | Acc: 87.480% (2187/2500)\n",
      "Test Epoch: 32 | Loss: 0.394 | Acc: 87.423% (2273/2600)\n",
      "Test Epoch: 32 | Loss: 0.388 | Acc: 87.593% (2365/2700)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.429% (2448/2800)\n",
      "Test Epoch: 32 | Loss: 0.393 | Acc: 87.448% (2536/2900)\n",
      "Test Epoch: 32 | Loss: 0.394 | Acc: 87.300% (2619/3000)\n",
      "Test Epoch: 32 | Loss: 0.400 | Acc: 87.129% (2701/3100)\n",
      "Test Epoch: 32 | Loss: 0.395 | Acc: 87.250% (2792/3200)\n",
      "Test Epoch: 32 | Loss: 0.393 | Acc: 87.303% (2881/3300)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.353% (2970/3400)\n",
      "Test Epoch: 32 | Loss: 0.391 | Acc: 87.457% (3061/3500)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.417% (3147/3600)\n",
      "Test Epoch: 32 | Loss: 0.395 | Acc: 87.405% (3234/3700)\n",
      "Test Epoch: 32 | Loss: 0.396 | Acc: 87.368% (3320/3800)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.436% (3410/3900)\n",
      "Test Epoch: 32 | Loss: 0.393 | Acc: 87.450% (3498/4000)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.390% (3583/4100)\n",
      "Test Epoch: 32 | Loss: 0.392 | Acc: 87.357% (3669/4200)\n",
      "Test Epoch: 32 | Loss: 0.389 | Acc: 87.488% (3762/4300)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.591% (3854/4400)\n",
      "Test Epoch: 32 | Loss: 0.384 | Acc: 87.689% (3946/4500)\n",
      "Test Epoch: 32 | Loss: 0.384 | Acc: 87.630% (4031/4600)\n",
      "Test Epoch: 32 | Loss: 0.383 | Acc: 87.681% (4121/4700)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.479% (4199/4800)\n",
      "Test Epoch: 32 | Loss: 0.383 | Acc: 87.612% (4293/4900)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.540% (4377/5000)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.569% (4466/5100)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.558% (4553/5200)\n",
      "Test Epoch: 32 | Loss: 0.385 | Acc: 87.547% (4640/5300)\n",
      "Test Epoch: 32 | Loss: 0.383 | Acc: 87.574% (4729/5400)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.509% (4813/5500)\n",
      "Test Epoch: 32 | Loss: 0.387 | Acc: 87.554% (4903/5600)\n",
      "Test Epoch: 32 | Loss: 0.386 | Acc: 87.596% (4993/5700)\n",
      "Test Epoch: 32 | Loss: 0.384 | Acc: 87.655% (5084/5800)\n",
      "Test Epoch: 32 | Loss: 0.383 | Acc: 87.627% (5170/5900)\n",
      "Test Epoch: 32 | Loss: 0.383 | Acc: 87.633% (5258/6000)\n",
      "Test Epoch: 32 | Loss: 0.382 | Acc: 87.607% (5344/6100)\n",
      "Test Epoch: 32 | Loss: 0.381 | Acc: 87.597% (5431/6200)\n",
      "Test Epoch: 32 | Loss: 0.382 | Acc: 87.619% (5520/6300)\n",
      "Test Epoch: 32 | Loss: 0.380 | Acc: 87.672% (5611/6400)\n",
      "Test Epoch: 32 | Loss: 0.380 | Acc: 87.600% (5694/6500)\n",
      "Test Epoch: 32 | Loss: 0.379 | Acc: 87.606% (5782/6600)\n",
      "Test Epoch: 32 | Loss: 0.378 | Acc: 87.687% (5875/6700)\n",
      "Test Epoch: 32 | Loss: 0.381 | Acc: 87.632% (5959/6800)\n",
      "Test Epoch: 32 | Loss: 0.379 | Acc: 87.739% (6054/6900)\n",
      "Test Epoch: 32 | Loss: 0.378 | Acc: 87.714% (6140/7000)\n",
      "Test Epoch: 32 | Loss: 0.380 | Acc: 87.718% (6228/7100)\n",
      "Test Epoch: 32 | Loss: 0.381 | Acc: 87.708% (6315/7200)\n",
      "Test Epoch: 32 | Loss: 0.379 | Acc: 87.753% (6406/7300)\n",
      "Test Epoch: 32 | Loss: 0.378 | Acc: 87.784% (6496/7400)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.813% (6586/7500)\n",
      "Test Epoch: 32 | Loss: 0.376 | Acc: 87.868% (6678/7600)\n",
      "Test Epoch: 32 | Loss: 0.377 | Acc: 87.831% (6763/7700)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.897% (6856/7800)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.911% (6945/7900)\n",
      "Test Epoch: 32 | Loss: 0.376 | Acc: 87.875% (7030/8000)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.926% (7122/8100)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.939% (7211/8200)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.952% (7300/8300)\n",
      "Test Epoch: 32 | Loss: 0.372 | Acc: 88.012% (7393/8400)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.965% (7477/8500)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.930% (7562/8600)\n",
      "Test Epoch: 32 | Loss: 0.374 | Acc: 87.977% (7654/8700)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.955% (7740/8800)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.910% (7824/8900)\n",
      "Test Epoch: 32 | Loss: 0.375 | Acc: 87.911% (7912/9000)\n",
      "Test Epoch: 32 | Loss: 0.374 | Acc: 87.956% (8004/9100)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.989% (8095/9200)\n",
      "Test Epoch: 32 | Loss: 0.373 | Acc: 87.989% (8183/9300)\n",
      "Test Epoch: 32 | Loss: 0.372 | Acc: 88.000% (8272/9400)\n",
      "Test Epoch: 32 | Loss: 0.371 | Acc: 88.021% (8362/9500)\n",
      "Test Epoch: 32 | Loss: 0.371 | Acc: 88.000% (8448/9600)\n",
      "Test Epoch: 32 | Loss: 0.368 | Acc: 88.072% (8543/9700)\n",
      "Test Epoch: 32 | Loss: 0.369 | Acc: 88.071% (8631/9800)\n",
      "Test Epoch: 32 | Loss: 0.370 | Acc: 88.051% (8717/9900)\n",
      "Test Epoch: 32 | Loss: 0.370 | Acc: 88.020% (8802/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 33\n",
      "Train Epoch: 33 | Loss: 0.221 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 33 | Loss: 0.251 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 33 | Loss: 0.278 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 33 | Loss: 0.294 | Acc: 90.625% (464/512)\n",
      "Train Epoch: 33 | Loss: 0.286 | Acc: 90.781% (581/640)\n",
      "Train Epoch: 33 | Loss: 0.280 | Acc: 91.146% (700/768)\n",
      "Train Epoch: 33 | Loss: 0.308 | Acc: 89.621% (803/896)\n",
      "Train Epoch: 33 | Loss: 0.303 | Acc: 89.648% (918/1024)\n",
      "Train Epoch: 33 | Loss: 0.308 | Acc: 89.149% (1027/1152)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.062% (1140/1280)\n",
      "Train Epoch: 33 | Loss: 0.309 | Acc: 89.560% (1261/1408)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.583% (1376/1536)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.423% (1488/1664)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.286% (1600/1792)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 89.115% (1711/1920)\n",
      "Train Epoch: 33 | Loss: 0.321 | Acc: 89.111% (1825/2048)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.108% (1939/2176)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 88.932% (2049/2304)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.268% (2171/2432)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.375% (2288/2560)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.323% (2401/2688)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.382% (2517/2816)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.368% (2631/2944)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.290% (2743/3072)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.438% (2862/3200)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.483% (2978/3328)\n",
      "Train Epoch: 33 | Loss: 0.310 | Acc: 89.641% (3098/3456)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.537% (3209/3584)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.574% (3325/3712)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.531% (3438/3840)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.365% (3546/3968)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.453% (3664/4096)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.512% (3781/4224)\n",
      "Train Epoch: 33 | Loss: 0.310 | Acc: 89.545% (3897/4352)\n",
      "Train Epoch: 33 | Loss: 0.307 | Acc: 89.688% (4018/4480)\n",
      "Train Epoch: 33 | Loss: 0.307 | Acc: 89.648% (4131/4608)\n",
      "Train Epoch: 33 | Loss: 0.308 | Acc: 89.590% (4243/4736)\n",
      "Train Epoch: 33 | Loss: 0.309 | Acc: 89.556% (4356/4864)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.423% (4464/4992)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.473% (4581/5120)\n",
      "Train Epoch: 33 | Loss: 0.311 | Acc: 89.558% (4700/5248)\n",
      "Train Epoch: 33 | Loss: 0.310 | Acc: 89.621% (4818/5376)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.553% (4929/5504)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.577% (5045/5632)\n",
      "Train Epoch: 33 | Loss: 0.311 | Acc: 89.601% (5161/5760)\n",
      "Train Epoch: 33 | Loss: 0.311 | Acc: 89.589% (5275/5888)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.644% (5393/6016)\n",
      "Train Epoch: 33 | Loss: 0.311 | Acc: 89.648% (5508/6144)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.525% (5615/6272)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.547% (5731/6400)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.537% (5845/6528)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.453% (5954/6656)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.505% (6072/6784)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.540% (6189/6912)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.489% (6300/7040)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.453% (6412/7168)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.433% (6525/7296)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.440% (6640/7424)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.486% (6758/7552)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.414% (6867/7680)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.357% (6977/7808)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.327% (7089/7936)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.323% (7203/8064)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.294% (7315/8192)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.291% (7429/8320)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.287% (7543/8448)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.249% (7654/8576)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.235% (7767/8704)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.232% (7881/8832)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.241% (7996/8960)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.283% (8114/9088)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.160% (8217/9216)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.191% (8334/9344)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.200% (8449/9472)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.208% (8564/9600)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.176% (8675/9728)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.225% (8794/9856)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.243% (8910/9984)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.231% (9023/10112)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.248% (9139/10240)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.265% (9255/10368)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.301% (9373/10496)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.307% (9488/10624)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.360% (9608/10752)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.366% (9723/10880)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.317% (9832/11008)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.341% (9949/11136)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.347% (10064/11264)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.361% (10180/11392)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.314% (10289/11520)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.260% (10397/11648)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.232% (10508/11776)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.239% (10623/11904)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.229% (10736/12032)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.243% (10852/12160)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.209% (10962/12288)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.216% (11077/12416)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.246% (11195/12544)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.244% (11309/12672)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.242% (11423/12800)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.271% (11541/12928)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.269% (11655/13056)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.282% (11771/13184)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.273% (11884/13312)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.241% (11994/13440)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.269% (12112/13568)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.282% (12228/13696)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.308% (12346/13824)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.321% (12462/13952)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.354% (12581/14080)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.323% (12691/14208)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.279% (12799/14336)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.242% (12908/14464)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.261% (13025/14592)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.253% (13138/14720)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.244% (13251/14848)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.189% (13357/14976)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.155% (13466/15104)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.168% (13582/15232)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.167% (13696/15360)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.192% (13814/15488)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.171% (13925/15616)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.139% (14034/15744)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.119% (14145/15872)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.162% (14266/16000)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.199% (14386/16128)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.229% (14505/16256)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.227% (14619/16384)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.238% (14735/16512)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.261% (14853/16640)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.259% (14967/16768)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.281% (15085/16896)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.292% (15201/17024)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.307% (15318/17152)\n",
      "Train Epoch: 33 | Loss: 0.312 | Acc: 89.294% (15430/17280)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.281% (15542/17408)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.291% (15658/17536)\n",
      "Train Epoch: 33 | Loss: 0.313 | Acc: 89.306% (15775/17664)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.254% (15880/17792)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.275% (15998/17920)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.284% (16114/18048)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.288% (16229/18176)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.248% (16336/18304)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.290% (16458/18432)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.300% (16574/18560)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.293% (16687/18688)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.275% (16798/18816)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.279% (16913/18944)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.251% (17022/19072)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.266% (17139/19200)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.259% (17252/19328)\n",
      "Train Epoch: 33 | Loss: 0.314 | Acc: 89.268% (17368/19456)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.231% (17475/19584)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.179% (17579/19712)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.189% (17695/19840)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.193% (17810/19968)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.212% (17928/20096)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.201% (18040/20224)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.205% (18155/20352)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.248% (18278/20480)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.252% (18393/20608)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.260% (18509/20736)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.269% (18625/20864)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.244% (18734/20992)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.266% (18853/21120)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.227% (18959/21248)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.250% (19078/21376)\n",
      "Train Epoch: 33 | Loss: 0.315 | Acc: 89.244% (19191/21504)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.224% (19301/21632)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.210% (19412/21760)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.200% (19524/21888)\n",
      "Train Epoch: 33 | Loss: 0.316 | Acc: 89.181% (19634/22016)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.184% (19749/22144)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.166% (19859/22272)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.134% (19966/22400)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.178% (20090/22528)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.168% (20202/22656)\n",
      "Train Epoch: 33 | Loss: 0.317 | Acc: 89.194% (20322/22784)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.159% (20428/22912)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.136% (20537/23040)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.127% (20649/23168)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.135% (20765/23296)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.131% (20878/23424)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.130% (20992/23552)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.105% (21100/23680)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.084% (21209/23808)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.092% (21325/23936)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.096% (21440/24064)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.108% (21557/24192)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.100% (21669/24320)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.103% (21784/24448)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.115% (21901/24576)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.139% (22021/24704)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.159% (22140/24832)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.155% (22253/24960)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.158% (22368/25088)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.166% (22484/25216)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.173% (22600/25344)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.172% (22714/25472)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.180% (22830/25600)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.183% (22945/25728)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.163% (23054/25856)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.163% (23168/25984)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.174% (23285/26112)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.173% (23399/26240)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.180% (23515/26368)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.172% (23627/26496)\n",
      "Train Epoch: 33 | Loss: 0.318 | Acc: 89.175% (23742/26624)\n",
      "Train Epoch: 33 | Loss: 0.319 | Acc: 89.156% (23851/26752)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.141% (23961/26880)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.114% (24068/27008)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.118% (24183/27136)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.114% (24296/27264)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.114% (24410/27392)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.128% (24528/27520)\n",
      "Train Epoch: 33 | Loss: 0.320 | Acc: 89.124% (24641/27648)\n",
      "Train Epoch: 33 | Loss: 0.321 | Acc: 89.095% (24747/27776)\n",
      "Train Epoch: 33 | Loss: 0.321 | Acc: 89.080% (24857/27904)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.066% (24967/28032)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.066% (25081/28160)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.059% (25193/28288)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.055% (25306/28416)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.059% (25421/28544)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.066% (25537/28672)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.076% (25654/28800)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.066% (25765/28928)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.049% (25874/29056)\n",
      "Train Epoch: 33 | Loss: 0.322 | Acc: 89.049% (25988/29184)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.028% (26096/29312)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.018% (26207/29440)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.015% (26320/29568)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.012% (26433/29696)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.016% (26548/29824)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.019% (26663/29952)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.006% (26773/30080)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.996% (26884/30208)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.983% (26994/30336)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.967% (27103/30464)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.974% (27219/30592)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.949% (27325/30720)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.952% (27440/30848)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.966% (27558/30976)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.979% (27676/31104)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.966% (27786/31232)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.967% (27900/31360)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.970% (28015/31488)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.974% (28130/31616)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.977% (28245/31744)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.965% (28355/31872)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.975% (28472/32000)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.966% (28583/32128)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.966% (28697/32256)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.970% (28812/32384)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.973% (28927/32512)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.983% (29044/32640)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.962% (29151/32768)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.947% (29260/32896)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.957% (29377/33024)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.954% (29490/33152)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.966% (29608/33280)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.973% (29724/33408)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.985% (29842/33536)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.000% (29961/33664)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.994% (30073/33792)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.986% (30184/33920)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.986% (30298/34048)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.989% (30413/34176)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.984% (30525/34304)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.978% (30637/34432)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.984% (30753/34560)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.973% (30863/34688)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.979% (30979/34816)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.980% (31093/34944)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.954% (31198/35072)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.955% (31312/35200)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.963% (31429/35328)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.969% (31545/35456)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.950% (31652/35584)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.936% (31761/35712)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.945% (31878/35840)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.960% (31997/35968)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.979% (32118/36096)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.963% (32226/36224)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.963% (32340/36352)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.972% (32457/36480)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.986% (32576/36608)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.981% (32688/36736)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.965% (32796/36864)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.973% (32913/36992)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.982% (33030/37120)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.985% (33145/37248)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.993% (33262/37376)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.988% (33374/37504)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.977% (33484/37632)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.988% (33602/37760)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.999% (33720/37888)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.007% (33837/38016)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.013% (33953/38144)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.023% (34071/38272)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.026% (34186/38400)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.037% (34304/38528)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.029% (34415/38656)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.026% (34528/38784)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.034% (34645/38912)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.042% (34762/39040)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.037% (34874/39168)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.035% (34987/39296)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.014% (35093/39424)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.027% (35212/39552)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.015% (35321/39680)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.002% (35430/39808)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.992% (35540/39936)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.980% (35649/40064)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.990% (35767/40192)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.003% (35886/40320)\n",
      "Train Epoch: 33 | Loss: 0.323 | Acc: 89.020% (36007/40448)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 89.011% (36117/40576)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.999% (36226/40704)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.989% (36336/40832)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.987% (36449/40960)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.992% (36565/41088)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.995% (36680/41216)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.990% (36792/41344)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.993% (36907/41472)\n",
      "Train Epoch: 33 | Loss: 0.324 | Acc: 88.976% (37014/41600)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.971% (37126/41728)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.969% (37239/41856)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.972% (37354/41984)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.975% (37469/42112)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.973% (37582/42240)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.966% (37693/42368)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.952% (37801/42496)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.938% (37909/42624)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.927% (38018/42752)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.934% (38135/42880)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.942% (38252/43008)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.940% (38365/43136)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.938% (38478/43264)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.943% (38594/43392)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.948% (38710/43520)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.948% (38824/43648)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.932% (38931/43776)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.933% (39045/43904)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.938% (39161/44032)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.936% (39274/44160)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.929% (39385/44288)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.925% (39497/44416)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.928% (39612/44544)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.908% (39717/44672)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.908% (39831/44800)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.913% (39947/44928)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.909% (40059/45056)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.910% (40173/45184)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.910% (40287/45312)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.935% (40412/45440)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.931% (40524/45568)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.936% (40640/45696)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.934% (40753/45824)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.943% (40871/45952)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.939% (40983/46080)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.939% (41097/46208)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.937% (41210/46336)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.936% (41323/46464)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.936% (41437/46592)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.940% (41553/46720)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.943% (41668/46848)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.937% (41779/46976)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.933% (41891/47104)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.931% (42004/47232)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.929% (42117/47360)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.928% (42230/47488)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.918% (42339/47616)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.912% (42450/47744)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.906% (42561/47872)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.912% (42678/48000)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.917% (42794/48128)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.907% (42903/48256)\n",
      "Train Epoch: 33 | Loss: 0.325 | Acc: 88.899% (43013/48384)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.893% (43124/48512)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.886% (43234/48640)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.878% (43344/48768)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.880% (43459/48896)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.875% (43570/49024)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.879% (43686/49152)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.880% (43800/49280)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.870% (43909/49408)\n",
      "Train Epoch: 33 | Loss: 0.327 | Acc: 88.873% (44024/49536)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.885% (44144/49664)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.882% (44256/49792)\n",
      "Train Epoch: 33 | Loss: 0.326 | Acc: 88.882% (44370/49920)\n",
      "Train Epoch: 33 | Loss: 0.327 | Acc: 88.878% (44439/50000)\n",
      "Test Epoch: 33 | Loss: 0.282 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 33 | Loss: 0.360 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 33 | Loss: 0.338 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 33 | Loss: 0.331 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 33 | Loss: 0.340 | Acc: 87.800% (439/500)\n",
      "Test Epoch: 33 | Loss: 0.338 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 33 | Loss: 0.338 | Acc: 88.571% (620/700)\n",
      "Test Epoch: 33 | Loss: 0.378 | Acc: 87.625% (701/800)\n",
      "Test Epoch: 33 | Loss: 0.401 | Acc: 87.000% (783/900)\n",
      "Test Epoch: 33 | Loss: 0.392 | Acc: 87.200% (872/1000)\n",
      "Test Epoch: 33 | Loss: 0.395 | Acc: 87.273% (960/1100)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 87.083% (1045/1200)\n",
      "Test Epoch: 33 | Loss: 0.389 | Acc: 87.231% (1134/1300)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 87.286% (1222/1400)\n",
      "Test Epoch: 33 | Loss: 0.398 | Acc: 87.067% (1306/1500)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 87.000% (1392/1600)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 87.176% (1482/1700)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 87.111% (1568/1800)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 87.000% (1653/1900)\n",
      "Test Epoch: 33 | Loss: 0.393 | Acc: 87.050% (1741/2000)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 86.952% (1826/2100)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 86.955% (1913/2200)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 86.913% (1999/2300)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 86.875% (2085/2400)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 86.600% (2165/2500)\n",
      "Test Epoch: 33 | Loss: 0.404 | Acc: 86.538% (2250/2600)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 86.741% (2342/2700)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 86.786% (2430/2800)\n",
      "Test Epoch: 33 | Loss: 0.400 | Acc: 86.759% (2516/2900)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 86.800% (2604/3000)\n",
      "Test Epoch: 33 | Loss: 0.400 | Acc: 86.742% (2689/3100)\n",
      "Test Epoch: 33 | Loss: 0.395 | Acc: 86.844% (2779/3200)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 86.788% (2864/3300)\n",
      "Test Epoch: 33 | Loss: 0.395 | Acc: 86.794% (2951/3400)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 86.800% (3038/3500)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 86.889% (3128/3600)\n",
      "Test Epoch: 33 | Loss: 0.393 | Acc: 86.865% (3214/3700)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 86.921% (3303/3800)\n",
      "Test Epoch: 33 | Loss: 0.389 | Acc: 87.128% (3398/3900)\n",
      "Test Epoch: 33 | Loss: 0.388 | Acc: 87.200% (3488/4000)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 87.146% (3573/4100)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.167% (3661/4200)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.279% (3753/4300)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.386% (3845/4400)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.378% (3932/4500)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.348% (4018/4600)\n",
      "Test Epoch: 33 | Loss: 0.384 | Acc: 87.404% (4108/4700)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.250% (4188/4800)\n",
      "Test Epoch: 33 | Loss: 0.389 | Acc: 87.265% (4276/4900)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.180% (4359/5000)\n",
      "Test Epoch: 33 | Loss: 0.389 | Acc: 87.216% (4448/5100)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 87.212% (4535/5200)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 87.132% (4618/5300)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.148% (4706/5400)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 87.055% (4788/5500)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 87.036% (4874/5600)\n",
      "Test Epoch: 33 | Loss: 0.398 | Acc: 87.000% (4959/5700)\n",
      "Test Epoch: 33 | Loss: 0.395 | Acc: 87.034% (5048/5800)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 86.983% (5132/5900)\n",
      "Test Epoch: 33 | Loss: 0.397 | Acc: 86.967% (5218/6000)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 86.967% (5305/6100)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 86.984% (5393/6200)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 87.032% (5483/6300)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 87.016% (5569/6400)\n",
      "Test Epoch: 33 | Loss: 0.396 | Acc: 86.954% (5652/6500)\n",
      "Test Epoch: 33 | Loss: 0.394 | Acc: 87.015% (5743/6600)\n",
      "Test Epoch: 33 | Loss: 0.392 | Acc: 87.090% (5835/6700)\n",
      "Test Epoch: 33 | Loss: 0.393 | Acc: 87.103% (5923/6800)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.159% (6014/6900)\n",
      "Test Epoch: 33 | Loss: 0.391 | Acc: 87.071% (6095/7000)\n",
      "Test Epoch: 33 | Loss: 0.393 | Acc: 87.099% (6184/7100)\n",
      "Test Epoch: 33 | Loss: 0.393 | Acc: 87.097% (6271/7200)\n",
      "Test Epoch: 33 | Loss: 0.390 | Acc: 87.192% (6365/7300)\n",
      "Test Epoch: 33 | Loss: 0.388 | Acc: 87.257% (6457/7400)\n",
      "Test Epoch: 33 | Loss: 0.388 | Acc: 87.240% (6543/7500)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.316% (6636/7600)\n",
      "Test Epoch: 33 | Loss: 0.388 | Acc: 87.286% (6721/7700)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.295% (6809/7800)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.342% (6900/7900)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.287% (6983/8000)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.333% (7074/8100)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.293% (7158/8200)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.289% (7245/8300)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.286% (7332/8400)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.294% (7420/8500)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.256% (7504/8600)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.345% (7599/8700)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.307% (7683/8800)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.337% (7773/8900)\n",
      "Test Epoch: 33 | Loss: 0.387 | Acc: 87.356% (7862/9000)\n",
      "Test Epoch: 33 | Loss: 0.386 | Acc: 87.341% (7948/9100)\n",
      "Test Epoch: 33 | Loss: 0.384 | Acc: 87.402% (8041/9200)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.376% (8126/9300)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.404% (8216/9400)\n",
      "Test Epoch: 33 | Loss: 0.384 | Acc: 87.421% (8305/9500)\n",
      "Test Epoch: 33 | Loss: 0.385 | Acc: 87.417% (8392/9600)\n",
      "Test Epoch: 33 | Loss: 0.383 | Acc: 87.443% (8482/9700)\n",
      "Test Epoch: 33 | Loss: 0.384 | Acc: 87.449% (8570/9800)\n",
      "Test Epoch: 33 | Loss: 0.383 | Acc: 87.465% (8659/9900)\n",
      "Test Epoch: 33 | Loss: 0.384 | Acc: 87.450% (8745/10000)\n",
      "\n",
      "Epoch: 34\n",
      "Train Epoch: 34 | Loss: 0.284 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 34 | Loss: 0.294 | Acc: 90.625% (232/256)\n",
      "Train Epoch: 34 | Loss: 0.333 | Acc: 88.542% (340/384)\n",
      "Train Epoch: 34 | Loss: 0.328 | Acc: 88.672% (454/512)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.062% (570/640)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 88.932% (683/768)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 88.839% (796/896)\n",
      "Train Epoch: 34 | Loss: 0.306 | Acc: 89.355% (915/1024)\n",
      "Train Epoch: 34 | Loss: 0.305 | Acc: 89.236% (1028/1152)\n",
      "Train Epoch: 34 | Loss: 0.299 | Acc: 89.375% (1144/1280)\n",
      "Train Epoch: 34 | Loss: 0.297 | Acc: 89.702% (1263/1408)\n",
      "Train Epoch: 34 | Loss: 0.298 | Acc: 89.714% (1378/1536)\n",
      "Train Epoch: 34 | Loss: 0.296 | Acc: 89.603% (1491/1664)\n",
      "Train Epoch: 34 | Loss: 0.297 | Acc: 89.565% (1605/1792)\n",
      "Train Epoch: 34 | Loss: 0.291 | Acc: 90.000% (1728/1920)\n",
      "Train Epoch: 34 | Loss: 0.295 | Acc: 89.844% (1840/2048)\n",
      "Train Epoch: 34 | Loss: 0.291 | Acc: 89.982% (1958/2176)\n",
      "Train Epoch: 34 | Loss: 0.288 | Acc: 90.148% (2077/2304)\n",
      "Train Epoch: 34 | Loss: 0.291 | Acc: 90.008% (2189/2432)\n",
      "Train Epoch: 34 | Loss: 0.293 | Acc: 89.922% (2302/2560)\n",
      "Train Epoch: 34 | Loss: 0.289 | Acc: 90.141% (2423/2688)\n",
      "Train Epoch: 34 | Loss: 0.285 | Acc: 90.270% (2542/2816)\n",
      "Train Epoch: 34 | Loss: 0.289 | Acc: 90.048% (2651/2944)\n",
      "Train Epoch: 34 | Loss: 0.294 | Acc: 89.909% (2762/3072)\n",
      "Train Epoch: 34 | Loss: 0.296 | Acc: 89.688% (2870/3200)\n",
      "Train Epoch: 34 | Loss: 0.301 | Acc: 89.483% (2978/3328)\n",
      "Train Epoch: 34 | Loss: 0.302 | Acc: 89.439% (3091/3456)\n",
      "Train Epoch: 34 | Loss: 0.302 | Acc: 89.453% (3206/3584)\n",
      "Train Epoch: 34 | Loss: 0.301 | Acc: 89.467% (3321/3712)\n",
      "Train Epoch: 34 | Loss: 0.301 | Acc: 89.453% (3435/3840)\n",
      "Train Epoch: 34 | Loss: 0.300 | Acc: 89.567% (3554/3968)\n",
      "Train Epoch: 34 | Loss: 0.302 | Acc: 89.478% (3665/4096)\n",
      "Train Epoch: 34 | Loss: 0.303 | Acc: 89.489% (3780/4224)\n",
      "Train Epoch: 34 | Loss: 0.304 | Acc: 89.430% (3892/4352)\n",
      "Train Epoch: 34 | Loss: 0.303 | Acc: 89.442% (4007/4480)\n",
      "Train Epoch: 34 | Loss: 0.301 | Acc: 89.518% (4125/4608)\n",
      "Train Epoch: 34 | Loss: 0.302 | Acc: 89.464% (4237/4736)\n",
      "Train Epoch: 34 | Loss: 0.301 | Acc: 89.494% (4353/4864)\n",
      "Train Epoch: 34 | Loss: 0.302 | Acc: 89.503% (4468/4992)\n",
      "Train Epoch: 34 | Loss: 0.300 | Acc: 89.551% (4585/5120)\n",
      "Train Epoch: 34 | Loss: 0.299 | Acc: 89.596% (4702/5248)\n",
      "Train Epoch: 34 | Loss: 0.303 | Acc: 89.565% (4815/5376)\n",
      "Train Epoch: 34 | Loss: 0.304 | Acc: 89.499% (4926/5504)\n",
      "Train Epoch: 34 | Loss: 0.305 | Acc: 89.453% (5038/5632)\n",
      "Train Epoch: 34 | Loss: 0.305 | Acc: 89.479% (5154/5760)\n",
      "Train Epoch: 34 | Loss: 0.307 | Acc: 89.368% (5262/5888)\n",
      "Train Epoch: 34 | Loss: 0.308 | Acc: 89.362% (5376/6016)\n",
      "Train Epoch: 34 | Loss: 0.311 | Acc: 89.258% (5484/6144)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.238% (5597/6272)\n",
      "Train Epoch: 34 | Loss: 0.311 | Acc: 89.328% (5717/6400)\n",
      "Train Epoch: 34 | Loss: 0.311 | Acc: 89.338% (5832/6528)\n",
      "Train Epoch: 34 | Loss: 0.311 | Acc: 89.288% (5943/6656)\n",
      "Train Epoch: 34 | Loss: 0.310 | Acc: 89.298% (6058/6784)\n",
      "Train Epoch: 34 | Loss: 0.310 | Acc: 89.323% (6174/6912)\n",
      "Train Epoch: 34 | Loss: 0.308 | Acc: 89.432% (6296/7040)\n",
      "Train Epoch: 34 | Loss: 0.309 | Acc: 89.425% (6410/7168)\n",
      "Train Epoch: 34 | Loss: 0.311 | Acc: 89.391% (6522/7296)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.372% (6635/7424)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.288% (6743/7552)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.323% (6860/7680)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.331% (6975/7808)\n",
      "Train Epoch: 34 | Loss: 0.312 | Acc: 89.352% (7091/7936)\n",
      "Train Epoch: 34 | Loss: 0.313 | Acc: 89.323% (7203/8064)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.331% (7318/8192)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.327% (7432/8320)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.299% (7544/8448)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.296% (7658/8576)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.292% (7772/8704)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.278% (7885/8832)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.319% (8003/8960)\n",
      "Train Epoch: 34 | Loss: 0.314 | Acc: 89.261% (8112/9088)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.236% (8224/9216)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.180% (8333/9344)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.168% (8446/9472)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.219% (8565/9600)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.186% (8676/9728)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.154% (8787/9856)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.173% (8903/9984)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.142% (9014/10112)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.150% (9129/10240)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.178% (9246/10368)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.215% (9364/10496)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.241% (9481/10624)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.258% (9597/10752)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.228% (9708/10880)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.235% (9823/11008)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.233% (9937/11136)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.249% (10053/11264)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.256% (10168/11392)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.271% (10284/11520)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.303% (10402/11648)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.241% (10509/11776)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.247% (10624/11904)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.237% (10737/12032)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.202% (10847/12160)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.160% (10956/12288)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.159% (11070/12416)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.182% (11187/12544)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.197% (11303/12672)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.203% (11418/12800)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.233% (11536/12928)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.216% (11648/13056)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.214% (11762/13184)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.220% (11877/13312)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.234% (11993/13440)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.203% (12103/13568)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.230% (12221/13696)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.229% (12335/13824)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.249% (12452/13952)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.169% (12555/14080)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.161% (12668/14208)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.188% (12786/14336)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.145% (12894/14464)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.158% (13010/14592)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.137% (13121/14720)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.184% (13242/14848)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.196% (13358/14976)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.182% (13470/15104)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.200% (13587/15232)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.199% (13701/15360)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.243% (13822/15488)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.242% (13936/15616)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.240% (14050/15744)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.270% (14169/15872)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.263% (14282/16000)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.286% (14400/16128)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.309% (14518/16256)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.313% (14633/16384)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.299% (14745/16512)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.279% (14856/16640)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.259% (14967/16768)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.264% (15082/16896)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.286% (15200/17024)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.319% (15320/17152)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.334% (15437/17280)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.355% (15555/17408)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.365% (15671/17536)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.391% (15790/17664)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.372% (15901/17792)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.381% (16017/17920)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.362% (16128/18048)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.338% (16238/18176)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.314% (16348/18304)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.290% (16458/18432)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.289% (16572/18560)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.298% (16688/18688)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.323% (16807/18816)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.305% (16918/18944)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.298% (17031/19072)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.297% (17145/19200)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.321% (17264/19328)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.294% (17373/19456)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.292% (17487/19584)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.306% (17604/19712)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.299% (17717/19840)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.273% (17826/19968)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.311% (17948/20096)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.295% (18059/20224)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.298% (18174/20352)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.312% (18291/20480)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.334% (18410/20608)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.323% (18522/20736)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.312% (18634/20864)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.329% (18752/20992)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.328% (18866/21120)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.350% (18985/21248)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.348% (19099/21376)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.337% (19211/21504)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.340% (19326/21632)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.311% (19434/21760)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.291% (19544/21888)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.267% (19653/22016)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.275% (19769/22144)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.269% (19882/22272)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.250% (19992/22400)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.262% (20109/22528)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.261% (20223/22656)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.278% (20341/22784)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.303% (20461/22912)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.288% (20572/23040)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.291% (20687/23168)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.269% (20796/23296)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.259% (20908/23424)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.254% (21021/23552)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.265% (21138/23680)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.256% (21250/23808)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.242% (21361/23936)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.241% (21475/24064)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.261% (21594/24192)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.268% (21710/24320)\n",
      "Train Epoch: 34 | Loss: 0.315 | Acc: 89.283% (21828/24448)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.262% (21937/24576)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.253% (22049/24704)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.256% (22164/24832)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.251% (22277/24960)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.254% (22392/25088)\n",
      "Train Epoch: 34 | Loss: 0.316 | Acc: 89.265% (22509/25216)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.264% (22623/25344)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.231% (22729/25472)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.219% (22840/25600)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.214% (22953/25728)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.225% (23070/25856)\n",
      "Train Epoch: 34 | Loss: 0.317 | Acc: 89.224% (23184/25984)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.208% (23294/26112)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.188% (23403/26240)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.191% (23518/26368)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.191% (23632/26496)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.171% (23741/26624)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.167% (23854/26752)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.144% (23962/26880)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.159% (24080/27008)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.147% (24191/27136)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.158% (24308/27264)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.161% (24423/27392)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.157% (24536/27520)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.146% (24647/27648)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.153% (24763/27776)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.152% (24877/27904)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.145% (24989/28032)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.151% (25105/28160)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.151% (25219/28288)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.147% (25332/28416)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.136% (25443/28544)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.122% (25553/28672)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.122% (25667/28800)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.128% (25783/28928)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.128% (25897/29056)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.117% (26008/29184)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.124% (26124/29312)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.144% (26244/29440)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.147% (26359/29568)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.153% (26475/29696)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.153% (26589/29824)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.159% (26705/29952)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.146% (26815/30080)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.142% (26928/30208)\n",
      "Train Epoch: 34 | Loss: 0.318 | Acc: 89.138% (27041/30336)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.135% (27154/30464)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.121% (27264/30592)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.128% (27380/30720)\n",
      "Train Epoch: 34 | Loss: 0.319 | Acc: 89.114% (27490/30848)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.114% (27604/30976)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.111% (27717/31104)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.120% (27834/31232)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.133% (27952/31360)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.136% (28067/31488)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.138% (28182/31616)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.135% (28295/31744)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.132% (28408/31872)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.119% (28518/32000)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.119% (28632/32128)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.140% (28753/32256)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.109% (28857/32384)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.090% (28965/32512)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.081% (29076/32640)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.075% (29188/32768)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.081% (29304/32896)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.081% (29418/33024)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.072% (29529/33152)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.069% (29642/33280)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.060% (29753/33408)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.068% (29870/33536)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.086% (29990/33664)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.071% (30099/33792)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.045% (30204/33920)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.060% (30323/34048)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.071% (30441/34176)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.065% (30553/34304)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.062% (30666/34432)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.074% (30784/34560)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.080% (30900/34688)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.100% (31021/34816)\n",
      "Train Epoch: 34 | Loss: 0.320 | Acc: 89.105% (31137/34944)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.102% (31250/35072)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.102% (31364/35200)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.074% (31468/35328)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.074% (31582/35456)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.079% (31698/35584)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.074% (31810/35712)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.062% (31920/35840)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.040% (32026/35968)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.057% (32146/36096)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.060% (32261/36224)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.065% (32377/36352)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.043% (32483/36480)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.035% (32594/36608)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.027% (32705/36736)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.019% (32816/36864)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.027% (32933/36992)\n",
      "Train Epoch: 34 | Loss: 0.321 | Acc: 89.025% (33046/37120)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.017% (33157/37248)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.014% (33270/37376)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.004% (33380/37504)\n",
      "Train Epoch: 34 | Loss: 0.322 | Acc: 89.009% (33496/37632)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 89.002% (33607/37760)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.991% (33717/37888)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.986% (33829/38016)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.989% (33944/38144)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.984% (34056/38272)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.982% (34169/38400)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.977% (34281/38528)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.982% (34397/38656)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.988% (34513/38784)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.983% (34625/38912)\n",
      "Train Epoch: 34 | Loss: 0.323 | Acc: 88.986% (34740/39040)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.973% (34849/39168)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.971% (34962/39296)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.976% (35078/39424)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.974% (35191/39552)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.979% (35307/39680)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.975% (35419/39808)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.965% (35529/39936)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.963% (35642/40064)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.970% (35759/40192)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.956% (35867/40320)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.954% (35980/40448)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.957% (36095/40576)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.964% (36212/40704)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.974% (36330/40832)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.984% (36448/40960)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.968% (36555/41088)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.970% (36670/41216)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.956% (36778/41344)\n",
      "Train Epoch: 34 | Loss: 0.324 | Acc: 88.964% (36895/41472)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.952% (37004/41600)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.952% (37118/41728)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.948% (37230/41856)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.939% (37340/41984)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.930% (37450/42112)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.916% (37558/42240)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.907% (37668/42368)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.907% (37782/42496)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.915% (37899/42624)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.910% (38011/42752)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.916% (38127/42880)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.918% (38242/43008)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.900% (38348/43136)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.889% (38457/43264)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.880% (38567/43392)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.883% (38682/43520)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.870% (38790/43648)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.877% (38907/43776)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.871% (39018/43904)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.856% (39125/44032)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.863% (39242/44160)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.868% (39358/44288)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.842% (39460/44416)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.840% (39573/44544)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.845% (39689/44672)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.844% (39802/44800)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.838% (39913/44928)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.843% (40029/45056)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.854% (40148/45184)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.862% (40265/45312)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.858% (40377/45440)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.861% (40492/45568)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.852% (40602/45696)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.855% (40717/45824)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.854% (40830/45952)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.856% (40945/46080)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.874% (41067/46208)\n",
      "Train Epoch: 34 | Loss: 0.325 | Acc: 88.873% (41180/46336)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.864% (41290/46464)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.863% (41403/46592)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.866% (41518/46720)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.853% (41626/46848)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.850% (41738/46976)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.859% (41856/47104)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.859% (41970/47232)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.860% (42084/47360)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.854% (42195/47488)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.852% (42308/47616)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.847% (42419/47744)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.847% (42533/47872)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.846% (42646/48000)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.857% (42765/48128)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.855% (42878/48256)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.850% (42989/48384)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.848% (43102/48512)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.838% (43211/48640)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.839% (43325/48768)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.838% (43438/48896)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.846% (43556/49024)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.857% (43675/49152)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.853% (43787/49280)\n",
      "Train Epoch: 34 | Loss: 0.327 | Acc: 88.854% (43901/49408)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.865% (44020/49536)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.855% (44129/49664)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.866% (44248/49792)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.874% (44366/49920)\n",
      "Train Epoch: 34 | Loss: 0.326 | Acc: 88.882% (44441/50000)\n",
      "Test Epoch: 34 | Loss: 0.268 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 34 | Loss: 0.317 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 34 | Loss: 0.332 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 34 | Loss: 0.319 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 34 | Loss: 0.328 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 34 | Loss: 0.317 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 34 | Loss: 0.326 | Acc: 88.000% (616/700)\n",
      "Test Epoch: 34 | Loss: 0.344 | Acc: 87.500% (700/800)\n",
      "Test Epoch: 34 | Loss: 0.371 | Acc: 86.667% (780/900)\n",
      "Test Epoch: 34 | Loss: 0.376 | Acc: 86.500% (865/1000)\n",
      "Test Epoch: 34 | Loss: 0.372 | Acc: 86.455% (951/1100)\n",
      "Test Epoch: 34 | Loss: 0.383 | Acc: 86.167% (1034/1200)\n",
      "Test Epoch: 34 | Loss: 0.377 | Acc: 86.000% (1118/1300)\n",
      "Test Epoch: 34 | Loss: 0.375 | Acc: 86.000% (1204/1400)\n",
      "Test Epoch: 34 | Loss: 0.379 | Acc: 86.133% (1292/1500)\n",
      "Test Epoch: 34 | Loss: 0.385 | Acc: 86.188% (1379/1600)\n",
      "Test Epoch: 34 | Loss: 0.390 | Acc: 86.176% (1465/1700)\n",
      "Test Epoch: 34 | Loss: 0.397 | Acc: 86.167% (1551/1800)\n",
      "Test Epoch: 34 | Loss: 0.398 | Acc: 86.211% (1638/1900)\n",
      "Test Epoch: 34 | Loss: 0.397 | Acc: 86.300% (1726/2000)\n",
      "Test Epoch: 34 | Loss: 0.402 | Acc: 86.143% (1809/2100)\n",
      "Test Epoch: 34 | Loss: 0.406 | Acc: 85.955% (1891/2200)\n",
      "Test Epoch: 34 | Loss: 0.412 | Acc: 85.913% (1976/2300)\n",
      "Test Epoch: 34 | Loss: 0.409 | Acc: 86.000% (2064/2400)\n",
      "Test Epoch: 34 | Loss: 0.418 | Acc: 85.680% (2142/2500)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.423% (2221/2600)\n",
      "Test Epoch: 34 | Loss: 0.424 | Acc: 85.556% (2310/2700)\n",
      "Test Epoch: 34 | Loss: 0.421 | Acc: 85.679% (2399/2800)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.483% (2479/2900)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.600% (2568/3000)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.516% (2651/3100)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.562% (2738/3200)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.424% (2819/3300)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.353% (2902/3400)\n",
      "Test Epoch: 34 | Loss: 0.440 | Acc: 85.314% (2986/3500)\n",
      "Test Epoch: 34 | Loss: 0.438 | Acc: 85.417% (3075/3600)\n",
      "Test Epoch: 34 | Loss: 0.438 | Acc: 85.432% (3161/3700)\n",
      "Test Epoch: 34 | Loss: 0.440 | Acc: 85.342% (3243/3800)\n",
      "Test Epoch: 34 | Loss: 0.437 | Acc: 85.462% (3333/3900)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.525% (3421/4000)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.585% (3509/4100)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.548% (3593/4200)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.628% (3682/4300)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.727% (3772/4400)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.756% (3859/4500)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.761% (3945/4600)\n",
      "Test Epoch: 34 | Loss: 0.425 | Acc: 85.745% (4030/4700)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.521% (4105/4800)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.633% (4196/4900)\n",
      "Test Epoch: 34 | Loss: 0.435 | Acc: 85.480% (4274/5000)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.510% (4361/5100)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.481% (4445/5200)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.509% (4532/5300)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.537% (4619/5400)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.473% (4701/5500)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.518% (4789/5600)\n",
      "Test Epoch: 34 | Loss: 0.435 | Acc: 85.491% (4873/5700)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.603% (4965/5800)\n",
      "Test Epoch: 34 | Loss: 0.435 | Acc: 85.508% (5045/5900)\n",
      "Test Epoch: 34 | Loss: 0.434 | Acc: 85.517% (5131/6000)\n",
      "Test Epoch: 34 | Loss: 0.435 | Acc: 85.475% (5214/6100)\n",
      "Test Epoch: 34 | Loss: 0.437 | Acc: 85.419% (5296/6200)\n",
      "Test Epoch: 34 | Loss: 0.436 | Acc: 85.444% (5383/6300)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.516% (5473/6400)\n",
      "Test Epoch: 34 | Loss: 0.433 | Acc: 85.446% (5554/6500)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.515% (5644/6600)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.612% (5736/6700)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.574% (5819/6800)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.609% (5907/6900)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.643% (5995/7000)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.676% (6083/7100)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.667% (6168/7200)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.699% (6256/7300)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.730% (6344/7400)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.707% (6428/7500)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.750% (6517/7600)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.675% (6597/7700)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.679% (6683/7800)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.671% (6768/7900)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.700% (6856/8000)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.753% (6946/8100)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.744% (7031/8200)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.759% (7118/8300)\n",
      "Test Epoch: 34 | Loss: 0.427 | Acc: 85.762% (7204/8400)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.694% (7284/8500)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.674% (7368/8600)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.701% (7456/8700)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.682% (7540/8800)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.618% (7620/8900)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.633% (7707/9000)\n",
      "Test Epoch: 34 | Loss: 0.432 | Acc: 85.615% (7791/9100)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.663% (7881/9200)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.667% (7967/9300)\n",
      "Test Epoch: 34 | Loss: 0.431 | Acc: 85.691% (8055/9400)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.758% (8147/9500)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.781% (8235/9600)\n",
      "Test Epoch: 34 | Loss: 0.428 | Acc: 85.804% (8323/9700)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.816% (8410/9800)\n",
      "Test Epoch: 34 | Loss: 0.430 | Acc: 85.818% (8496/9900)\n",
      "Test Epoch: 34 | Loss: 0.429 | Acc: 85.800% (8580/10000)\n",
      "\n",
      "Epoch: 35\n",
      "Train Epoch: 35 | Loss: 0.254 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 35 | Loss: 0.271 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 90.104% (346/384)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.648% (459/512)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.844% (575/640)\n",
      "Train Epoch: 35 | Loss: 0.305 | Acc: 90.234% (693/768)\n",
      "Train Epoch: 35 | Loss: 0.305 | Acc: 90.179% (808/896)\n",
      "Train Epoch: 35 | Loss: 0.302 | Acc: 90.234% (924/1024)\n",
      "Train Epoch: 35 | Loss: 0.299 | Acc: 90.104% (1038/1152)\n",
      "Train Epoch: 35 | Loss: 0.303 | Acc: 90.000% (1152/1280)\n",
      "Train Epoch: 35 | Loss: 0.299 | Acc: 90.128% (1269/1408)\n",
      "Train Epoch: 35 | Loss: 0.303 | Acc: 89.909% (1381/1536)\n",
      "Train Epoch: 35 | Loss: 0.307 | Acc: 89.663% (1492/1664)\n",
      "Train Epoch: 35 | Loss: 0.303 | Acc: 89.676% (1607/1792)\n",
      "Train Epoch: 35 | Loss: 0.298 | Acc: 89.896% (1726/1920)\n",
      "Train Epoch: 35 | Loss: 0.296 | Acc: 89.990% (1843/2048)\n",
      "Train Epoch: 35 | Loss: 0.293 | Acc: 90.074% (1960/2176)\n",
      "Train Epoch: 35 | Loss: 0.302 | Acc: 89.844% (2070/2304)\n",
      "Train Epoch: 35 | Loss: 0.300 | Acc: 89.967% (2188/2432)\n",
      "Train Epoch: 35 | Loss: 0.300 | Acc: 90.000% (2304/2560)\n",
      "Train Epoch: 35 | Loss: 0.302 | Acc: 89.918% (2417/2688)\n",
      "Train Epoch: 35 | Loss: 0.306 | Acc: 89.808% (2529/2816)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.674% (2640/2944)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.714% (2756/3072)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.656% (2869/3200)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.663% (2984/3328)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.699% (3100/3456)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.788% (3218/3584)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.601% (3326/3712)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.531% (3438/3840)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.415% (3548/3968)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.453% (3664/4096)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.654% (3787/4224)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.637% (3901/4352)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.598% (4014/4480)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.648% (4131/4608)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.696% (4248/4736)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.720% (4364/4864)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.643% (4475/4992)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.688% (4592/5120)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.825% (4714/5248)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.825% (4829/5376)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.844% (4945/5504)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.862% (5061/5632)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.948% (5181/5760)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.946% (5296/5888)\n",
      "Train Epoch: 35 | Loss: 0.307 | Acc: 89.943% (5411/6016)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.909% (5524/6144)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.860% (5636/6272)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.781% (5746/6400)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.798% (5862/6528)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.769% (5975/6656)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.829% (6094/6784)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.786% (6206/6912)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.886% (6328/7040)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.914% (6445/7168)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.940% (6562/7296)\n",
      "Train Epoch: 35 | Loss: 0.308 | Acc: 89.911% (6675/7424)\n",
      "Train Epoch: 35 | Loss: 0.309 | Acc: 89.870% (6787/7552)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.805% (6897/7680)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.805% (7012/7808)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.806% (7127/7936)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.782% (7240/8064)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.734% (7351/8192)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.736% (7466/8320)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.666% (7575/8448)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.669% (7690/8576)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.625% (7801/8704)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.651% (7918/8832)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.609% (8029/8960)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.668% (8149/9088)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.681% (8265/9216)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.683% (8380/9344)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.707% (8497/9472)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.802% (8621/9600)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.844% (8740/9728)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.834% (8854/9856)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.844% (8970/9984)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.834% (9084/10112)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.834% (9199/10240)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.863% (9317/10368)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.806% (9426/10496)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.825% (9543/10624)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.797% (9655/10752)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.807% (9771/10880)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.807% (9886/11008)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.799% (10000/11136)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.737% (10108/11264)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.677% (10216/11392)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.601% (10322/11520)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.621% (10439/11648)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.547% (10545/11776)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.575% (10663/11904)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.545% (10774/12032)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.539% (10888/12160)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.559% (11005/12288)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.594% (11124/12416)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.605% (11240/12544)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.599% (11354/12672)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.617% (11471/12800)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.604% (11584/12928)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.591% (11697/13056)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.548% (11806/13184)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.573% (11924/13312)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.568% (12038/13440)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.564% (12152/13568)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.559% (12266/13696)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.569% (12382/13824)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.579% (12498/13952)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.560% (12610/14080)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.555% (12724/14208)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.579% (12842/14336)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.602% (12960/14464)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.590% (13073/14592)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.579% (13186/14720)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.561% (13298/14848)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.550% (13411/14976)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.552% (13526/15104)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.535% (13638/15232)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.557% (13756/15360)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.566% (13872/15488)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.588% (13990/15616)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.602% (14107/15744)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.548% (14213/15872)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.537% (14326/16000)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.534% (14440/16128)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.542% (14556/16256)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.539% (14670/16384)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.523% (14782/16512)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.525% (14897/16640)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.510% (15009/16768)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.542% (15129/16896)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.550% (15245/17024)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.529% (15356/17152)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.537% (15472/17280)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.545% (15588/17408)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.564% (15706/17536)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.566% (15821/17664)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.551% (15933/17792)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.548% (16047/17920)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.545% (16161/18048)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.541% (16275/18176)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.549% (16391/18304)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.540% (16504/18432)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.558% (16622/18560)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.544% (16734/18688)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.541% (16848/18816)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.543% (16963/18944)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.529% (17075/19072)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.495% (17183/19200)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.487% (17296/19328)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.499% (17413/19456)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.502% (17528/19584)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.534% (17649/19712)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.546% (17766/19840)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.553% (17882/19968)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.545% (17995/20096)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.532% (18107/20224)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.529% (18221/20352)\n",
      "Train Epoch: 35 | Loss: 0.310 | Acc: 89.546% (18339/20480)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.504% (18445/20608)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.511% (18561/20736)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.513% (18676/20864)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.525% (18793/20992)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.531% (18909/21120)\n",
      "Train Epoch: 35 | Loss: 0.311 | Acc: 89.510% (19019/21248)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.479% (19127/21376)\n",
      "Train Epoch: 35 | Loss: 0.312 | Acc: 89.476% (19241/21504)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.446% (19349/21632)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.435% (19461/21760)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.423% (19573/21888)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.408% (19684/22016)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.419% (19801/22144)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.431% (19918/22272)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.460% (20039/22400)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.449% (20151/22528)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.455% (20267/22656)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.449% (20380/22784)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.429% (20490/22912)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.423% (20603/23040)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.421% (20717/23168)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.436% (20835/23296)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.417% (20945/23424)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.428% (21062/23552)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.417% (21174/23680)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.420% (21289/23808)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.401% (21399/23936)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.395% (21512/24064)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.381% (21623/24192)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.363% (21733/24320)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.357% (21846/24448)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.368% (21963/24576)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.394% (22084/24704)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.401% (22200/24832)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.423% (22320/24960)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.429% (22436/25088)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.415% (22547/25216)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.422% (22663/25344)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.412% (22775/25472)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.414% (22890/25600)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.432% (23009/25728)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.403% (23116/25856)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.397% (23229/25984)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.400% (23344/26112)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.394% (23457/26240)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.377% (23567/26368)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.364% (23678/26496)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.363% (23792/26624)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.350% (23903/26752)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.345% (24016/26880)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.355% (24133/27008)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.350% (24246/27136)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.371% (24366/27264)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.366% (24479/27392)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.368% (24594/27520)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.355% (24705/27648)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.376% (24825/27776)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.385% (24942/27904)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.369% (25052/28032)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.371% (25167/28160)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.352% (25276/28288)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.383% (25399/28416)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.367% (25509/28544)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.366% (25623/28672)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.392% (25745/28800)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.377% (25855/28928)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.372% (25968/29056)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.385% (26086/29184)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.390% (26202/29312)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.375% (26312/29440)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.377% (26427/29568)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.379% (26542/29696)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.378% (26656/29824)\n",
      "Train Epoch: 35 | Loss: 0.313 | Acc: 89.363% (26766/29952)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.348% (26876/30080)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.347% (26990/30208)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.336% (27101/30336)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.332% (27214/30464)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.324% (27326/30592)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.307% (27435/30720)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.293% (27545/30848)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.292% (27659/30976)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.294% (27774/31104)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.296% (27889/31232)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.286% (28000/31360)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.285% (28114/31488)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.268% (28223/31616)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.274% (28339/31744)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.270% (28452/31872)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.259% (28563/32000)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.246% (28673/32128)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.239% (28785/32256)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.235% (28898/32384)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.216% (29006/32512)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.237% (29127/32640)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.212% (29233/32768)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.211% (29347/32896)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.211% (29461/33024)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.207% (29574/33152)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.216% (29691/33280)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.224% (29808/33408)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.232% (29925/33536)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.235% (30040/33664)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.231% (30153/33792)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.251% (30274/33920)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.245% (30386/34048)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.250% (30502/34176)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.249% (30616/34304)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.243% (30728/34432)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.245% (30843/34560)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.238% (30955/34688)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.232% (31067/34816)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.228% (31180/34944)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.225% (31293/35072)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.222% (31406/35200)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.221% (31520/35328)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.226% (31636/35456)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.217% (31747/35584)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.231% (31866/35712)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.235% (31982/35840)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.249% (32101/35968)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.256% (32218/36096)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.250% (32330/36224)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.236% (32439/36352)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.238% (32554/36480)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.240% (32669/36608)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.248% (32786/36736)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.244% (32899/36864)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.246% (33014/36992)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.265% (33135/37120)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.250% (33244/37248)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.242% (33355/37376)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.252% (33473/37504)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.267% (33593/37632)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.280% (33712/37760)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.284% (33828/37888)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.281% (33941/38016)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.285% (34057/38144)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.279% (34169/38272)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.258% (34275/38400)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.249% (34386/38528)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.251% (34501/38656)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.246% (34613/38784)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.245% (34727/38912)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.247% (34842/39040)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.246% (34956/39168)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.248% (35071/39296)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.250% (35186/39424)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.255% (35302/39552)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.246% (35413/39680)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.236% (35523/39808)\n",
      "Train Epoch: 35 | Loss: 0.314 | Acc: 89.235% (35637/39936)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.230% (35749/40064)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.232% (35864/40192)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.224% (35975/40320)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.221% (36088/40448)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.220% (36202/40576)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.215% (36314/40704)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.224% (36432/40832)\n",
      "Train Epoch: 35 | Loss: 0.315 | Acc: 89.226% (36547/40960)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.228% (36662/41088)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.220% (36773/41216)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.198% (36878/41344)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.193% (36990/41472)\n",
      "Train Epoch: 35 | Loss: 0.316 | Acc: 89.204% (37109/41600)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.199% (37221/41728)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.184% (37329/41856)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.194% (37447/41984)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.172% (37552/42112)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.167% (37664/42240)\n",
      "Train Epoch: 35 | Loss: 0.317 | Acc: 89.171% (37780/42368)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.164% (37891/42496)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.159% (38003/42624)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.147% (38112/42752)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.146% (38226/42880)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.144% (38339/43008)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.155% (38458/43136)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.155% (38572/43264)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.157% (38687/43392)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.150% (38798/43520)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.154% (38914/43648)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.145% (39024/43776)\n",
      "Train Epoch: 35 | Loss: 0.318 | Acc: 89.142% (39137/43904)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.140% (39250/44032)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.137% (39363/44160)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.123% (39471/44288)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.117% (39582/44416)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.121% (39698/44544)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.107% (39806/44672)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.112% (39922/44800)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.096% (40029/44928)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.094% (40142/45056)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.091% (40255/45184)\n",
      "Train Epoch: 35 | Loss: 0.319 | Acc: 89.098% (40372/45312)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.089% (40482/45440)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.084% (40594/45568)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.080% (40706/45696)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.080% (40820/45824)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.067% (40928/45952)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.078% (41047/46080)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.086% (41165/46208)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.084% (41278/46336)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.082% (41391/46464)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.071% (41500/46592)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.075% (41616/46720)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.071% (41728/46848)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.069% (41841/46976)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.062% (41952/47104)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.062% (42066/47232)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.058% (42178/47360)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.065% (42295/47488)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.060% (42407/47616)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.065% (42523/47744)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.067% (42638/47872)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.067% (42752/48000)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.067% (42866/48128)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.069% (42981/48256)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.062% (43092/48384)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.044% (43197/48512)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.054% (43316/48640)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.058% (43432/48768)\n",
      "Train Epoch: 35 | Loss: 0.320 | Acc: 89.054% (43544/48896)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.052% (43657/49024)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.052% (43771/49152)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.050% (43884/49280)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.046% (43996/49408)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.048% (44111/49536)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.054% (44228/49664)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.054% (44342/49792)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.044% (44451/49920)\n",
      "Train Epoch: 35 | Loss: 0.321 | Acc: 89.042% (44521/50000)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 85.000% (170/200)\n",
      "Test Epoch: 35 | Loss: 0.420 | Acc: 85.333% (256/300)\n",
      "Test Epoch: 35 | Loss: 0.405 | Acc: 86.250% (345/400)\n",
      "Test Epoch: 35 | Loss: 0.405 | Acc: 86.400% (432/500)\n",
      "Test Epoch: 35 | Loss: 0.381 | Acc: 87.167% (523/600)\n",
      "Test Epoch: 35 | Loss: 0.378 | Acc: 87.286% (611/700)\n",
      "Test Epoch: 35 | Loss: 0.409 | Acc: 86.750% (694/800)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 86.556% (779/900)\n",
      "Test Epoch: 35 | Loss: 0.441 | Acc: 86.400% (864/1000)\n",
      "Test Epoch: 35 | Loss: 0.446 | Acc: 86.182% (948/1100)\n",
      "Test Epoch: 35 | Loss: 0.443 | Acc: 86.333% (1036/1200)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.462% (1124/1300)\n",
      "Test Epoch: 35 | Loss: 0.428 | Acc: 86.214% (1207/1400)\n",
      "Test Epoch: 35 | Loss: 0.417 | Acc: 86.333% (1295/1500)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 86.188% (1379/1600)\n",
      "Test Epoch: 35 | Loss: 0.424 | Acc: 86.118% (1464/1700)\n",
      "Test Epoch: 35 | Loss: 0.431 | Acc: 85.833% (1545/1800)\n",
      "Test Epoch: 35 | Loss: 0.425 | Acc: 86.000% (1634/1900)\n",
      "Test Epoch: 35 | Loss: 0.422 | Acc: 86.100% (1722/2000)\n",
      "Test Epoch: 35 | Loss: 0.429 | Acc: 85.905% (1804/2100)\n",
      "Test Epoch: 35 | Loss: 0.428 | Acc: 85.955% (1891/2200)\n",
      "Test Epoch: 35 | Loss: 0.433 | Acc: 85.696% (1971/2300)\n",
      "Test Epoch: 35 | Loss: 0.429 | Acc: 85.667% (2056/2400)\n",
      "Test Epoch: 35 | Loss: 0.435 | Acc: 85.520% (2138/2500)\n",
      "Test Epoch: 35 | Loss: 0.446 | Acc: 85.308% (2218/2600)\n",
      "Test Epoch: 35 | Loss: 0.441 | Acc: 85.481% (2308/2700)\n",
      "Test Epoch: 35 | Loss: 0.445 | Acc: 85.429% (2392/2800)\n",
      "Test Epoch: 35 | Loss: 0.443 | Acc: 85.586% (2482/2900)\n",
      "Test Epoch: 35 | Loss: 0.447 | Acc: 85.533% (2566/3000)\n",
      "Test Epoch: 35 | Loss: 0.450 | Acc: 85.419% (2648/3100)\n",
      "Test Epoch: 35 | Loss: 0.446 | Acc: 85.500% (2736/3200)\n",
      "Test Epoch: 35 | Loss: 0.449 | Acc: 85.424% (2819/3300)\n",
      "Test Epoch: 35 | Loss: 0.449 | Acc: 85.412% (2904/3400)\n",
      "Test Epoch: 35 | Loss: 0.450 | Acc: 85.486% (2992/3500)\n",
      "Test Epoch: 35 | Loss: 0.449 | Acc: 85.611% (3082/3600)\n",
      "Test Epoch: 35 | Loss: 0.449 | Acc: 85.568% (3166/3700)\n",
      "Test Epoch: 35 | Loss: 0.451 | Acc: 85.447% (3247/3800)\n",
      "Test Epoch: 35 | Loss: 0.449 | Acc: 85.513% (3335/3900)\n",
      "Test Epoch: 35 | Loss: 0.446 | Acc: 85.600% (3424/4000)\n",
      "Test Epoch: 35 | Loss: 0.447 | Acc: 85.659% (3512/4100)\n",
      "Test Epoch: 35 | Loss: 0.447 | Acc: 85.714% (3600/4200)\n",
      "Test Epoch: 35 | Loss: 0.444 | Acc: 85.837% (3691/4300)\n",
      "Test Epoch: 35 | Loss: 0.442 | Acc: 85.909% (3780/4400)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.978% (3869/4500)\n",
      "Test Epoch: 35 | Loss: 0.440 | Acc: 85.913% (3952/4600)\n",
      "Test Epoch: 35 | Loss: 0.439 | Acc: 85.979% (4041/4700)\n",
      "Test Epoch: 35 | Loss: 0.444 | Acc: 85.896% (4123/4800)\n",
      "Test Epoch: 35 | Loss: 0.439 | Acc: 86.000% (4214/4900)\n",
      "Test Epoch: 35 | Loss: 0.441 | Acc: 85.920% (4296/5000)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.980% (4385/5100)\n",
      "Test Epoch: 35 | Loss: 0.439 | Acc: 85.885% (4466/5200)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.849% (4550/5300)\n",
      "Test Epoch: 35 | Loss: 0.437 | Acc: 85.926% (4640/5400)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.836% (4721/5500)\n",
      "Test Epoch: 35 | Loss: 0.440 | Acc: 85.714% (4800/5600)\n",
      "Test Epoch: 35 | Loss: 0.441 | Acc: 85.684% (4884/5700)\n",
      "Test Epoch: 35 | Loss: 0.439 | Acc: 85.759% (4974/5800)\n",
      "Test Epoch: 35 | Loss: 0.440 | Acc: 85.729% (5058/5900)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.783% (5147/6000)\n",
      "Test Epoch: 35 | Loss: 0.438 | Acc: 85.770% (5232/6100)\n",
      "Test Epoch: 35 | Loss: 0.439 | Acc: 85.758% (5317/6200)\n",
      "Test Epoch: 35 | Loss: 0.437 | Acc: 85.825% (5407/6300)\n",
      "Test Epoch: 35 | Loss: 0.435 | Acc: 85.922% (5499/6400)\n",
      "Test Epoch: 35 | Loss: 0.436 | Acc: 85.862% (5581/6500)\n",
      "Test Epoch: 35 | Loss: 0.435 | Acc: 85.924% (5671/6600)\n",
      "Test Epoch: 35 | Loss: 0.433 | Acc: 85.970% (5760/6700)\n",
      "Test Epoch: 35 | Loss: 0.434 | Acc: 85.971% (5846/6800)\n",
      "Test Epoch: 35 | Loss: 0.434 | Acc: 86.014% (5935/6900)\n",
      "Test Epoch: 35 | Loss: 0.433 | Acc: 86.000% (6020/7000)\n",
      "Test Epoch: 35 | Loss: 0.434 | Acc: 86.000% (6106/7100)\n",
      "Test Epoch: 35 | Loss: 0.435 | Acc: 85.972% (6190/7200)\n",
      "Test Epoch: 35 | Loss: 0.432 | Acc: 86.055% (6282/7300)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.135% (6374/7400)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.107% (6458/7500)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.105% (6544/7600)\n",
      "Test Epoch: 35 | Loss: 0.432 | Acc: 86.091% (6629/7700)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.154% (6720/7800)\n",
      "Test Epoch: 35 | Loss: 0.431 | Acc: 86.152% (6806/7900)\n",
      "Test Epoch: 35 | Loss: 0.431 | Acc: 86.150% (6892/8000)\n",
      "Test Epoch: 35 | Loss: 0.430 | Acc: 86.198% (6982/8100)\n",
      "Test Epoch: 35 | Loss: 0.429 | Acc: 86.183% (7067/8200)\n",
      "Test Epoch: 35 | Loss: 0.428 | Acc: 86.157% (7151/8300)\n",
      "Test Epoch: 35 | Loss: 0.426 | Acc: 86.214% (7242/8400)\n",
      "Test Epoch: 35 | Loss: 0.427 | Acc: 86.212% (7328/8500)\n",
      "Test Epoch: 35 | Loss: 0.426 | Acc: 86.198% (7413/8600)\n",
      "Test Epoch: 35 | Loss: 0.425 | Acc: 86.207% (7500/8700)\n",
      "Test Epoch: 35 | Loss: 0.427 | Acc: 86.170% (7583/8800)\n",
      "Test Epoch: 35 | Loss: 0.426 | Acc: 86.180% (7670/8900)\n",
      "Test Epoch: 35 | Loss: 0.427 | Acc: 86.189% (7757/9000)\n",
      "Test Epoch: 35 | Loss: 0.426 | Acc: 86.198% (7844/9100)\n",
      "Test Epoch: 35 | Loss: 0.424 | Acc: 86.250% (7935/9200)\n",
      "Test Epoch: 35 | Loss: 0.423 | Acc: 86.290% (8025/9300)\n",
      "Test Epoch: 35 | Loss: 0.423 | Acc: 86.277% (8110/9400)\n",
      "Test Epoch: 35 | Loss: 0.422 | Acc: 86.284% (8197/9500)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 86.312% (8286/9600)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 86.320% (8373/9700)\n",
      "Test Epoch: 35 | Loss: 0.421 | Acc: 86.327% (8460/9800)\n",
      "Test Epoch: 35 | Loss: 0.423 | Acc: 86.283% (8542/9900)\n",
      "Test Epoch: 35 | Loss: 0.423 | Acc: 86.270% (8627/10000)\n",
      "\n",
      "Epoch: 36\n",
      "Train Epoch: 36 | Loss: 0.368 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 36 | Loss: 0.326 | Acc: 90.234% (231/256)\n",
      "Train Epoch: 36 | Loss: 0.327 | Acc: 89.844% (345/384)\n",
      "Train Epoch: 36 | Loss: 0.325 | Acc: 89.062% (456/512)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.062% (570/640)\n",
      "Train Epoch: 36 | Loss: 0.306 | Acc: 89.323% (686/768)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.732% (804/896)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.746% (919/1024)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.497% (1031/1152)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.688% (1148/1280)\n",
      "Train Epoch: 36 | Loss: 0.292 | Acc: 90.057% (1268/1408)\n",
      "Train Epoch: 36 | Loss: 0.287 | Acc: 90.299% (1387/1536)\n",
      "Train Epoch: 36 | Loss: 0.291 | Acc: 90.204% (1501/1664)\n",
      "Train Epoch: 36 | Loss: 0.292 | Acc: 90.402% (1620/1792)\n",
      "Train Epoch: 36 | Loss: 0.291 | Acc: 90.365% (1735/1920)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 90.186% (1847/2048)\n",
      "Train Epoch: 36 | Loss: 0.291 | Acc: 90.119% (1961/2176)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.931% (2072/2304)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 90.090% (2191/2432)\n",
      "Train Epoch: 36 | Loss: 0.292 | Acc: 90.078% (2306/2560)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 90.067% (2421/2688)\n",
      "Train Epoch: 36 | Loss: 0.292 | Acc: 90.163% (2539/2816)\n",
      "Train Epoch: 36 | Loss: 0.291 | Acc: 90.115% (2653/2944)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.941% (2763/3072)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.938% (2878/3200)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.784% (2988/3328)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.815% (3104/3456)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.955% (3224/3584)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.978% (3340/3712)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.896% (3452/3840)\n",
      "Train Epoch: 36 | Loss: 0.292 | Acc: 89.970% (3570/3968)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.941% (3684/4096)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.891% (3797/4224)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.867% (3911/4352)\n",
      "Train Epoch: 36 | Loss: 0.291 | Acc: 89.911% (4028/4480)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.887% (4142/4608)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.907% (4258/4736)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.864% (4371/4864)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.844% (4485/4992)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.863% (4601/5120)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.825% (4714/5248)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.862% (4831/5376)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.880% (4947/5504)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.879% (5062/5632)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.826% (5174/5760)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.776% (5286/5888)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.860% (5406/6016)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.779% (5516/6144)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.668% (5624/6272)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.688% (5740/6400)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.660% (5853/6528)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.678% (5969/6656)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.711% (6086/6784)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.800% (6207/6912)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.815% (6323/7040)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.746% (6433/7168)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.707% (6545/7296)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.696% (6659/7424)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.778% (6780/7552)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.779% (6895/7680)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.844% (7015/7808)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.781% (7125/7936)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.831% (7244/8064)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.795% (7356/8192)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.856% (7476/8320)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.808% (7587/8448)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.832% (7704/8576)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.832% (7819/8704)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.866% (7937/8832)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.821% (8048/8960)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.855% (8166/9088)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.768% (8273/9216)\n",
      "Train Epoch: 36 | Loss: 0.293 | Acc: 89.876% (8398/9344)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.812% (8507/9472)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.781% (8619/9600)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.792% (8735/9728)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.783% (8849/9856)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.784% (8964/9984)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.834% (9084/10112)\n",
      "Train Epoch: 36 | Loss: 0.294 | Acc: 89.883% (9204/10240)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.824% (9313/10368)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.768% (9422/10496)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.750% (9535/10624)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.760% (9651/10752)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.743% (9764/10880)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.762% (9881/11008)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.763% (9996/11136)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.773% (10112/11264)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.782% (10228/11392)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.766% (10341/11520)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.766% (10456/11648)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.784% (10573/11776)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.802% (10690/11904)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.769% (10801/12032)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.745% (10913/12160)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.730% (11026/12288)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.739% (11142/12416)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.708% (11253/12544)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.717% (11369/12672)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.703% (11482/12800)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.697% (11596/12928)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.729% (11715/13056)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.768% (11835/13184)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.806% (11955/13312)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.814% (12071/13440)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.822% (12187/13568)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.836% (12304/13696)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.865% (12423/13824)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.858% (12537/13952)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.865% (12653/14080)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.872% (12769/14208)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.893% (12887/14336)\n",
      "Train Epoch: 36 | Loss: 0.295 | Acc: 89.941% (13009/14464)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.871% (13114/14592)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.878% (13230/14720)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.871% (13344/14848)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.897% (13463/14976)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.890% (13577/15104)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.909% (13695/15232)\n",
      "Train Epoch: 36 | Loss: 0.296 | Acc: 89.915% (13811/15360)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.870% (13919/15488)\n",
      "Train Epoch: 36 | Loss: 0.297 | Acc: 89.850% (14031/15616)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.812% (14140/15744)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.787% (14251/15872)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.763% (14362/16000)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.695% (14466/16128)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.684% (14579/16256)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.667% (14691/16384)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.686% (14809/16512)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.675% (14922/16640)\n",
      "Train Epoch: 36 | Loss: 0.300 | Acc: 89.701% (15041/16768)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.737% (15162/16896)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.744% (15278/17024)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.721% (15389/17152)\n",
      "Train Epoch: 36 | Loss: 0.299 | Acc: 89.722% (15504/17280)\n",
      "Train Epoch: 36 | Loss: 0.298 | Acc: 89.735% (15621/17408)\n",
      "Train Epoch: 36 | Loss: 0.300 | Acc: 89.638% (15719/17536)\n",
      "Train Epoch: 36 | Loss: 0.300 | Acc: 89.668% (15839/17664)\n",
      "Train Epoch: 36 | Loss: 0.300 | Acc: 89.653% (15951/17792)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.643% (16064/17920)\n",
      "Train Epoch: 36 | Loss: 0.301 | Acc: 89.639% (16178/18048)\n",
      "Train Epoch: 36 | Loss: 0.302 | Acc: 89.585% (16283/18176)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.587% (16398/18304)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.572% (16510/18432)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.553% (16621/18560)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.587% (16742/18688)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.578% (16855/18816)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.564% (16967/18944)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.550% (17079/19072)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.536% (17191/19200)\n",
      "Train Epoch: 36 | Loss: 0.304 | Acc: 89.544% (17307/19328)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.556% (17424/19456)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.553% (17538/19584)\n",
      "Train Epoch: 36 | Loss: 0.304 | Acc: 89.524% (17647/19712)\n",
      "Train Epoch: 36 | Loss: 0.304 | Acc: 89.521% (17761/19840)\n",
      "Train Epoch: 36 | Loss: 0.304 | Acc: 89.493% (17870/19968)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.505% (17987/20096)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.508% (18102/20224)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.515% (18218/20352)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.521% (18334/20480)\n",
      "Train Epoch: 36 | Loss: 0.303 | Acc: 89.523% (18449/20608)\n",
      "Train Epoch: 36 | Loss: 0.304 | Acc: 89.501% (18559/20736)\n",
      "Train Epoch: 36 | Loss: 0.305 | Acc: 89.446% (18662/20864)\n",
      "Train Epoch: 36 | Loss: 0.305 | Acc: 89.439% (18775/20992)\n",
      "Train Epoch: 36 | Loss: 0.305 | Acc: 89.441% (18890/21120)\n",
      "Train Epoch: 36 | Loss: 0.306 | Acc: 89.401% (18996/21248)\n",
      "Train Epoch: 36 | Loss: 0.306 | Acc: 89.385% (19107/21376)\n",
      "Train Epoch: 36 | Loss: 0.306 | Acc: 89.379% (19220/21504)\n",
      "Train Epoch: 36 | Loss: 0.307 | Acc: 89.377% (19334/21632)\n",
      "Train Epoch: 36 | Loss: 0.307 | Acc: 89.366% (19446/21760)\n",
      "Train Epoch: 36 | Loss: 0.306 | Acc: 89.378% (19563/21888)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.340% (19669/22016)\n",
      "Train Epoch: 36 | Loss: 0.307 | Acc: 89.347% (19785/22144)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.336% (19897/22272)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.330% (20010/22400)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.324% (20123/22528)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.332% (20239/22656)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.326% (20352/22784)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.316% (20464/22912)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.336% (20583/23040)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.296% (20688/23168)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.264% (20795/23296)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.280% (20913/23424)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.275% (21026/23552)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.269% (21139/23680)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.268% (21253/23808)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.255% (21364/23936)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.258% (21479/24064)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.265% (21595/24192)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.256% (21707/24320)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.255% (21821/24448)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.262% (21937/24576)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.269% (22053/24704)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.280% (22170/24832)\n",
      "Train Epoch: 36 | Loss: 0.308 | Acc: 89.283% (22285/24960)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.270% (22396/25088)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.257% (22507/25216)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.280% (22627/25344)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.267% (22738/25472)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.273% (22854/25600)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.237% (22959/25728)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.240% (23074/25856)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.228% (23185/25984)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.231% (23300/26112)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.257% (23421/26240)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.267% (23538/26368)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.255% (23649/26496)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.235% (23758/26624)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.249% (23876/26752)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.249% (23990/26880)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.244% (24103/27008)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.261% (24222/27136)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.242% (24331/27264)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.227% (24441/27392)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.237% (24558/27520)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.225% (24669/27648)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.217% (24781/27776)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.238% (24901/27904)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.234% (25014/28032)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.219% (25124/28160)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.225% (25240/28288)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.228% (25355/28416)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.224% (25468/28544)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.226% (25583/28672)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.208% (25692/28800)\n",
      "Train Epoch: 36 | Loss: 0.309 | Acc: 89.228% (25812/28928)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.221% (25924/29056)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.227% (26040/29184)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.233% (26156/29312)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.226% (26268/29440)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.221% (26381/29568)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.207% (26491/29696)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.203% (26604/29824)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.196% (26716/29952)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.186% (26827/30080)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.188% (26942/30208)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.194% (27058/30336)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.204% (27175/30464)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.197% (27287/30592)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.196% (27401/30720)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.195% (27515/30848)\n",
      "Train Epoch: 36 | Loss: 0.310 | Acc: 89.201% (27631/30976)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.188% (27741/31104)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.200% (27859/31232)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.190% (27970/31360)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.196% (28086/31488)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.192% (28199/31616)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.185% (28311/31744)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.204% (28431/31872)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.203% (28545/32000)\n",
      "Train Epoch: 36 | Loss: 0.311 | Acc: 89.190% (28655/32128)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.168% (28762/32256)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.167% (28876/32384)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.170% (28991/32512)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.179% (29108/32640)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.188% (29225/32768)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.196% (29342/32896)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.184% (29452/33024)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.183% (29566/33152)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.177% (29678/33280)\n",
      "Train Epoch: 36 | Loss: 0.312 | Acc: 89.185% (29795/33408)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.164% (29902/33536)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.137% (30007/33664)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.131% (30119/33792)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.130% (30233/33920)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.136% (30349/34048)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.144% (30466/34176)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.150% (30582/34304)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.147% (30695/34432)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.164% (30815/34560)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.158% (30927/34688)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.140% (31035/34816)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.140% (31149/34944)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.148% (31266/35072)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.136% (31376/35200)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.136% (31490/35328)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.133% (31603/35456)\n",
      "Train Epoch: 36 | Loss: 0.313 | Acc: 89.138% (31719/35584)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.138% (31833/35712)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.129% (31944/35840)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.132% (32059/35968)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.121% (32169/36096)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.120% (32283/36224)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.096% (32388/36352)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.084% (32498/36480)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.079% (32610/36608)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.084% (32726/36736)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.087% (32841/36864)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.087% (32955/36992)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.089% (33070/37120)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.089% (33184/37248)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.103% (33303/37376)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.102% (33417/37504)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.108% (33533/37632)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.105% (33646/37760)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.118% (33765/37888)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.105% (33874/38016)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.104% (33988/38144)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.102% (34101/38272)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.086% (34209/38400)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.096% (34327/38528)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.114% (34448/38656)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.132% (34569/38784)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.119% (34678/38912)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.114% (34790/39040)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.137% (34913/39168)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.146% (35031/39296)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.141% (35143/39424)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.151% (35261/39552)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.151% (35375/39680)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.115% (35475/39808)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.115% (35589/39936)\n",
      "Train Epoch: 36 | Loss: 0.314 | Acc: 89.120% (35705/40064)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.110% (35815/40192)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.100% (35925/40320)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.100% (36039/40448)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.099% (36153/40576)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.102% (36268/40704)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.102% (36382/40832)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.097% (36494/40960)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.097% (36608/41088)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.087% (36718/41216)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.077% (36828/41344)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.082% (36944/41472)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.072% (37054/41600)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.074% (37169/41728)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.074% (37283/41856)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.072% (37396/41984)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.074% (37511/42112)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.077% (37626/42240)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.091% (37746/42368)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.084% (37857/42496)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.077% (37968/42624)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.079% (38083/42752)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.081% (38198/42880)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.090% (38316/43008)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.095% (38432/43136)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.095% (38546/43264)\n",
      "Train Epoch: 36 | Loss: 0.315 | Acc: 89.092% (38659/43392)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.076% (38766/43520)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.053% (38870/43648)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.056% (38985/43776)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.040% (39092/43904)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.051% (39211/44032)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.040% (39320/44160)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.026% (39428/44288)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.035% (39546/44416)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.038% (39661/44544)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.036% (39774/44672)\n",
      "Train Epoch: 36 | Loss: 0.316 | Acc: 89.036% (39888/44800)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.022% (39996/44928)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.009% (40104/45056)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.007% (40217/45184)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.010% (40332/45312)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.012% (40447/45440)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 89.008% (40559/45568)\n",
      "Train Epoch: 36 | Loss: 0.317 | Acc: 88.982% (40661/45696)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.964% (40767/45824)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.971% (40884/45952)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.961% (40993/46080)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.946% (41100/46208)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.939% (41211/46336)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.933% (41322/46464)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.923% (41431/46592)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.923% (41545/46720)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.924% (41659/46848)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.931% (41776/46976)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.931% (41890/47104)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.931% (42004/47232)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.934% (42119/47360)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.934% (42233/47488)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.936% (42348/47616)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.928% (42458/47744)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.937% (42576/47872)\n",
      "Train Epoch: 36 | Loss: 0.319 | Acc: 88.929% (42686/48000)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.934% (42802/48128)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.940% (42919/48256)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.941% (43033/48384)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.949% (43151/48512)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.960% (43270/48640)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.972% (43390/48768)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.970% (43503/48896)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.973% (43618/49024)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.969% (43730/49152)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.963% (43841/49280)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.969% (43958/49408)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.968% (44071/49536)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.966% (44184/49664)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.974% (44302/49792)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.968% (44413/49920)\n",
      "Train Epoch: 36 | Loss: 0.318 | Acc: 88.980% (44490/50000)\n",
      "Test Epoch: 36 | Loss: 0.273 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 36 | Loss: 0.359 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 36 | Loss: 0.325 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 36 | Loss: 0.344 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 36 | Loss: 0.348 | Acc: 88.400% (442/500)\n",
      "Test Epoch: 36 | Loss: 0.336 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 36 | Loss: 0.334 | Acc: 88.714% (621/700)\n",
      "Test Epoch: 36 | Loss: 0.366 | Acc: 87.750% (702/800)\n",
      "Test Epoch: 36 | Loss: 0.370 | Acc: 87.222% (785/900)\n",
      "Test Epoch: 36 | Loss: 0.376 | Acc: 87.100% (871/1000)\n",
      "Test Epoch: 36 | Loss: 0.376 | Acc: 87.455% (962/1100)\n",
      "Test Epoch: 36 | Loss: 0.384 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.077% (1132/1300)\n",
      "Test Epoch: 36 | Loss: 0.378 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.000% (1305/1500)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.000% (1392/1600)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.235% (1483/1700)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.222% (1570/1800)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.316% (1659/1900)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.550% (1751/2000)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.524% (1838/2100)\n",
      "Test Epoch: 36 | Loss: 0.376 | Acc: 87.500% (1925/2200)\n",
      "Test Epoch: 36 | Loss: 0.376 | Acc: 87.478% (2012/2300)\n",
      "Test Epoch: 36 | Loss: 0.375 | Acc: 87.333% (2096/2400)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 87.160% (2179/2500)\n",
      "Test Epoch: 36 | Loss: 0.391 | Acc: 87.077% (2264/2600)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.259% (2356/2700)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.179% (2441/2800)\n",
      "Test Epoch: 36 | Loss: 0.388 | Acc: 87.069% (2525/2900)\n",
      "Test Epoch: 36 | Loss: 0.392 | Acc: 87.033% (2611/3000)\n",
      "Test Epoch: 36 | Loss: 0.396 | Acc: 86.935% (2695/3100)\n",
      "Test Epoch: 36 | Loss: 0.394 | Acc: 86.812% (2778/3200)\n",
      "Test Epoch: 36 | Loss: 0.393 | Acc: 86.788% (2864/3300)\n",
      "Test Epoch: 36 | Loss: 0.391 | Acc: 86.882% (2954/3400)\n",
      "Test Epoch: 36 | Loss: 0.392 | Acc: 86.914% (3042/3500)\n",
      "Test Epoch: 36 | Loss: 0.392 | Acc: 86.972% (3131/3600)\n",
      "Test Epoch: 36 | Loss: 0.393 | Acc: 86.919% (3216/3700)\n",
      "Test Epoch: 36 | Loss: 0.392 | Acc: 86.842% (3300/3800)\n",
      "Test Epoch: 36 | Loss: 0.389 | Acc: 86.974% (3392/3900)\n",
      "Test Epoch: 36 | Loss: 0.388 | Acc: 86.975% (3479/4000)\n",
      "Test Epoch: 36 | Loss: 0.390 | Acc: 86.878% (3562/4100)\n",
      "Test Epoch: 36 | Loss: 0.388 | Acc: 86.976% (3653/4200)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.070% (3744/4300)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.159% (3835/4400)\n",
      "Test Epoch: 36 | Loss: 0.378 | Acc: 87.289% (3928/4500)\n",
      "Test Epoch: 36 | Loss: 0.377 | Acc: 87.304% (4016/4600)\n",
      "Test Epoch: 36 | Loss: 0.378 | Acc: 87.255% (4101/4700)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.229% (4187/4800)\n",
      "Test Epoch: 36 | Loss: 0.378 | Acc: 87.265% (4276/4900)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.180% (4359/5000)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.157% (4445/5100)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.096% (4529/5200)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.038% (4613/5300)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.056% (4701/5400)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 86.945% (4782/5500)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 86.964% (4870/5600)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 86.930% (4955/5700)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.034% (5048/5800)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.051% (5136/5900)\n",
      "Test Epoch: 36 | Loss: 0.384 | Acc: 87.000% (5220/6000)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.016% (5308/6100)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.016% (5395/6200)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.032% (5483/6300)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.047% (5571/6400)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.015% (5656/6500)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.045% (5745/6600)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.134% (5838/6700)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.176% (5928/6800)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.174% (6015/6900)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.114% (6098/7000)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.127% (6186/7100)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.069% (6269/7200)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.164% (6363/7300)\n",
      "Test Epoch: 36 | Loss: 0.378 | Acc: 87.257% (6457/7400)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.227% (6542/7500)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.289% (6634/7600)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.273% (6720/7700)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.321% (6811/7800)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.329% (6899/7900)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.338% (6987/8000)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.358% (7076/8100)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.317% (7160/8200)\n",
      "Test Epoch: 36 | Loss: 0.379 | Acc: 87.337% (7249/8300)\n",
      "Test Epoch: 36 | Loss: 0.380 | Acc: 87.310% (7334/8400)\n",
      "Test Epoch: 36 | Loss: 0.381 | Acc: 87.271% (7418/8500)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.244% (7503/8600)\n",
      "Test Epoch: 36 | Loss: 0.382 | Acc: 87.253% (7591/8700)\n",
      "Test Epoch: 36 | Loss: 0.383 | Acc: 87.227% (7676/8800)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 87.191% (7760/8900)\n",
      "Test Epoch: 36 | Loss: 0.388 | Acc: 87.167% (7845/9000)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.198% (7935/9100)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.207% (8023/9200)\n",
      "Test Epoch: 36 | Loss: 0.388 | Acc: 87.172% (8107/9300)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.191% (8196/9400)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 87.211% (8285/9500)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 87.167% (8368/9600)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 87.196% (8458/9700)\n",
      "Test Epoch: 36 | Loss: 0.385 | Acc: 87.204% (8546/9800)\n",
      "Test Epoch: 36 | Loss: 0.386 | Acc: 87.141% (8627/9900)\n",
      "Test Epoch: 36 | Loss: 0.387 | Acc: 87.160% (8716/10000)\n",
      "\n",
      "Epoch: 37\n",
      "Train Epoch: 37 | Loss: 0.264 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 37 | Loss: 0.279 | Acc: 91.406% (234/256)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 90.104% (346/384)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 90.039% (461/512)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.469% (579/640)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.583% (688/768)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 90.067% (807/896)\n",
      "Train Epoch: 37 | Loss: 0.300 | Acc: 90.039% (922/1024)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 89.931% (1036/1152)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.234% (1155/1280)\n",
      "Train Epoch: 37 | Loss: 0.300 | Acc: 90.270% (1271/1408)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 90.234% (1386/1536)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 90.084% (1499/1664)\n",
      "Train Epoch: 37 | Loss: 0.306 | Acc: 90.123% (1615/1792)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 90.000% (1728/1920)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.893% (1841/2048)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 90.074% (1960/2176)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.278% (2080/2304)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 90.173% (2193/2432)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 90.156% (2308/2560)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.179% (2424/2688)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.128% (2538/2816)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.285% (2658/2944)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.299% (2774/3072)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.094% (2883/3200)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.144% (3000/3328)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.249% (3119/3456)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.374% (3239/3584)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.248% (3350/3712)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.286% (3467/3840)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.247% (3581/3968)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.186% (3694/4096)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.294% (3814/4224)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.234% (3927/4352)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.223% (4042/4480)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.104% (4152/4608)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.203% (4272/4736)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.275% (4391/4864)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.244% (4505/4992)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.215% (4619/5120)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.149% (4731/5248)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.216% (4850/5376)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.153% (4962/5504)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.128% (5076/5632)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.087% (5189/5760)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.183% (5310/5888)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.126% (5422/6016)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.072% (5534/6144)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.083% (5650/6272)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.078% (5765/6400)\n",
      "Train Epoch: 37 | Loss: 0.291 | Acc: 90.089% (5881/6528)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.114% (5998/6656)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.153% (6116/6784)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.220% (6236/6912)\n",
      "Train Epoch: 37 | Loss: 0.288 | Acc: 90.227% (6352/7040)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.206% (6466/7168)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.269% (6586/7296)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.302% (6704/7424)\n",
      "Train Epoch: 37 | Loss: 0.289 | Acc: 90.254% (6816/7552)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.247% (6931/7680)\n",
      "Train Epoch: 37 | Loss: 0.290 | Acc: 90.241% (7046/7808)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.209% (7159/7936)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.191% (7273/8064)\n",
      "Train Epoch: 37 | Loss: 0.292 | Acc: 90.198% (7389/8192)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.132% (7499/8320)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.104% (7612/8448)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.147% (7731/8576)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.142% (7846/8704)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.149% (7962/8832)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.167% (8079/8960)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.196% (8197/9088)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.202% (8313/9216)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.165% (8425/9344)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.182% (8542/9472)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.135% (8653/9600)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.080% (8763/9728)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.057% (8876/9856)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.074% (8993/9984)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.051% (9106/10112)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.059% (9222/10240)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.037% (9335/10368)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 90.044% (9451/10496)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.088% (9571/10624)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.141% (9692/10752)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.138% (9807/10880)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.107% (9919/11008)\n",
      "Train Epoch: 37 | Loss: 0.295 | Acc: 90.122% (10036/11136)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.163% (10156/11264)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.133% (10268/11392)\n",
      "Train Epoch: 37 | Loss: 0.293 | Acc: 90.156% (10386/11520)\n",
      "Train Epoch: 37 | Loss: 0.294 | Acc: 90.153% (10501/11648)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 90.031% (10602/11776)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 89.978% (10711/11904)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 89.977% (10826/12032)\n",
      "Train Epoch: 37 | Loss: 0.296 | Acc: 89.992% (10943/12160)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.958% (11054/12288)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.957% (11169/12416)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.908% (11278/12544)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.923% (11395/12672)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.953% (11514/12800)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.906% (11623/12928)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.882% (11735/13056)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.889% (11851/13184)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.919% (11970/13312)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.911% (12084/13440)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.917% (12200/13568)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 89.931% (12317/13696)\n",
      "Train Epoch: 37 | Loss: 0.297 | Acc: 89.952% (12435/13824)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.915% (12545/13952)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.908% (12659/14080)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.893% (12772/14208)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.900% (12888/14336)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.892% (13002/14464)\n",
      "Train Epoch: 37 | Loss: 0.298 | Acc: 89.864% (13113/14592)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.857% (13227/14720)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.830% (13338/14848)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.837% (13454/14976)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.824% (13567/15104)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.837% (13684/15232)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.837% (13799/15360)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.824% (13912/15488)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.837% (14029/15616)\n",
      "Train Epoch: 37 | Loss: 0.299 | Acc: 89.837% (14144/15744)\n",
      "Train Epoch: 37 | Loss: 0.301 | Acc: 89.730% (14242/15872)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.725% (14356/16000)\n",
      "Train Epoch: 37 | Loss: 0.301 | Acc: 89.732% (14472/16128)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.702% (14582/16256)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.691% (14695/16384)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.692% (14810/16512)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.724% (14930/16640)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.719% (15044/16768)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.749% (15164/16896)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.715% (15273/17024)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.750% (15394/17152)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.751% (15509/17280)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.717% (15618/17408)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.724% (15734/17536)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.719% (15848/17664)\n",
      "Train Epoch: 37 | Loss: 0.302 | Acc: 89.714% (15962/17792)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.693% (16073/17920)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.650% (16180/18048)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.629% (16291/18176)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.625% (16405/18304)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.643% (16523/18432)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.639% (16637/18560)\n",
      "Train Epoch: 37 | Loss: 0.303 | Acc: 89.614% (16747/18688)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.610% (16861/18816)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.617% (16977/18944)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.634% (17095/19072)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.635% (17210/19200)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.632% (17324/19328)\n",
      "Train Epoch: 37 | Loss: 0.304 | Acc: 89.633% (17439/19456)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.619% (17551/19584)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.605% (17663/19712)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.597% (17776/19840)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.598% (17891/19968)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.605% (18007/20096)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.597% (18120/20224)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.593% (18234/20352)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.604% (18351/20480)\n",
      "Train Epoch: 37 | Loss: 0.305 | Acc: 89.596% (18464/20608)\n",
      "Train Epoch: 37 | Loss: 0.306 | Acc: 89.593% (18578/20736)\n",
      "Train Epoch: 37 | Loss: 0.306 | Acc: 89.580% (18690/20864)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.525% (18793/20992)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.527% (18908/21120)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.510% (19019/21248)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.512% (19134/21376)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.500% (19246/21504)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.497% (19360/21632)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.481% (19471/21760)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.483% (19586/21888)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.471% (19698/22016)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.469% (19812/22144)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.489% (19931/22272)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.504% (20049/22400)\n",
      "Train Epoch: 37 | Loss: 0.307 | Acc: 89.515% (20166/22528)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.473% (20271/22656)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.471% (20385/22784)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.473% (20500/22912)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.479% (20616/23040)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.481% (20731/23168)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.462% (20841/23296)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.485% (20961/23424)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.487% (21076/23552)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.485% (21190/23680)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.491% (21306/23808)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.447% (21410/23936)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.445% (21524/24064)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.455% (21641/24192)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.457% (21756/24320)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.463% (21872/24448)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.445% (21982/24576)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.467% (22102/24704)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.453% (22213/24832)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.435% (22323/24960)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.425% (22435/25088)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.415% (22547/25216)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.410% (22660/25344)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.424% (22778/25472)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.418% (22891/25600)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.420% (23006/25728)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.438% (23125/25856)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.440% (23240/25984)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.449% (23357/26112)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.451% (23472/26240)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.449% (23586/26368)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.436% (23697/26496)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.427% (23809/26624)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.429% (23924/26752)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.435% (24040/26880)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.444% (24157/27008)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.449% (24273/27136)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.440% (24385/27264)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.446% (24501/27392)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.469% (24622/27520)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.468% (24736/27648)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.459% (24848/27776)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.428% (24954/27904)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.434% (25070/28032)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.442% (25187/28160)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.451% (25304/28288)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.418% (25409/28416)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.416% (25523/28544)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.411% (25636/28672)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.413% (25751/28800)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.394% (25860/28928)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.407% (25978/29056)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.412% (26094/29184)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.390% (26202/29312)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.409% (26322/29440)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.407% (26436/29568)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.416% (26553/29696)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.411% (26666/29824)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.406% (26779/29952)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.402% (26892/30080)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.403% (27007/30208)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.395% (27119/30336)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.401% (27235/30464)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.380% (27343/30592)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.382% (27458/30720)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.387% (27574/30848)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.385% (27688/30976)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.365% (27796/31104)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.370% (27912/31232)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.378% (28029/31360)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.383% (28145/31488)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.388% (28261/31616)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.406% (28381/31744)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.411% (28497/31872)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.422% (28615/32000)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.430% (28732/32128)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.428% (28846/32256)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.411% (28955/32384)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.419% (29072/32512)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.412% (29184/32640)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.404% (29296/32768)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.406% (29411/32896)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.420% (29530/33024)\n",
      "Train Epoch: 37 | Loss: 0.308 | Acc: 89.424% (29646/33152)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.408% (29755/33280)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.413% (29871/33408)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.408% (29984/33536)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.413% (30100/33664)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.421% (30217/33792)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.402% (30325/33920)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.391% (30436/34048)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.390% (30550/34176)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.395% (30666/34304)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.402% (30783/34432)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.387% (30892/34560)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.385% (31006/34688)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.378% (31118/34816)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.380% (31233/34944)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.382% (31348/35072)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.375% (31460/35200)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.368% (31572/35328)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.376% (31689/35456)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.360% (31798/35584)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.368% (31915/35712)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.378% (32033/35840)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.382% (32149/35968)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.395% (32268/36096)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.372% (32374/36224)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.382% (32492/36352)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.372% (32603/36480)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.385% (32722/36608)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.359% (32827/36736)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.353% (32939/36864)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.360% (33056/36992)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.362% (33171/37120)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.339% (33277/37248)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.346% (33394/37376)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.356% (33512/37504)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.349% (33624/37632)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.362% (33743/37760)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.350% (33853/37888)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.354% (33969/38016)\n",
      "Train Epoch: 37 | Loss: 0.309 | Acc: 89.351% (34082/38144)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.345% (34194/38272)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.333% (34304/38400)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.327% (34416/38528)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.337% (34534/38656)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.310% (34638/38784)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.309% (34752/38912)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.311% (34867/39040)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.310% (34981/39168)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.314% (35097/39296)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.306% (35208/39424)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.290% (35316/39552)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.297% (35433/39680)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.294% (35546/39808)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.298% (35662/39936)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.297% (35776/40064)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.299% (35891/40192)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.298% (36005/40320)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.285% (36114/40448)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.289% (36230/40576)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.293% (36346/40704)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.298% (36462/40832)\n",
      "Train Epoch: 37 | Loss: 0.310 | Acc: 89.294% (36575/40960)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.279% (36683/41088)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.281% (36798/41216)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.287% (36915/41344)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.289% (37030/41472)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.281% (37141/41600)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.273% (37252/41728)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.258% (37360/41856)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.260% (37475/41984)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.264% (37591/42112)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.264% (37705/42240)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.254% (37815/42368)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.246% (37926/42496)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.241% (38038/42624)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.252% (38157/42752)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.261% (38275/42880)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.255% (38387/43008)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.255% (38501/43136)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.266% (38620/43264)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.261% (38732/43392)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.256% (38844/43520)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.253% (38957/43648)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.264% (39076/43776)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.261% (39189/43904)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.258% (39302/44032)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.269% (39421/44160)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.263% (39533/44288)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.256% (39644/44416)\n",
      "Train Epoch: 37 | Loss: 0.311 | Acc: 89.274% (39766/44544)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.257% (39873/44672)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.254% (39986/44800)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.254% (40100/44928)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.242% (40209/45056)\n",
      "Train Epoch: 37 | Loss: 0.312 | Acc: 89.246% (40325/45184)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.243% (40438/45312)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.236% (40549/45440)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.229% (40660/45568)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.213% (40767/45696)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.211% (40880/45824)\n",
      "Train Epoch: 37 | Loss: 0.313 | Acc: 89.208% (40993/45952)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.199% (41103/46080)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.199% (41217/46208)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.209% (41336/46336)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.200% (41446/46464)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.189% (41555/46592)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.189% (41669/46720)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.182% (41780/46848)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.160% (41884/46976)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.169% (42002/47104)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.177% (42120/47232)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.179% (42235/47360)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.183% (42351/47488)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.170% (42459/47616)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.169% (42573/47744)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.169% (42687/47872)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.158% (42796/48000)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.166% (42914/48128)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.170% (43030/48256)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.172% (43145/48384)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.159% (43253/48512)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.155% (43365/48640)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.145% (43474/48768)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.140% (43586/48896)\n",
      "Train Epoch: 37 | Loss: 0.316 | Acc: 89.134% (43697/49024)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.140% (43814/49152)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.138% (43927/49280)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.139% (44042/49408)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.145% (44159/49536)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.161% (44281/49664)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.165% (44397/49792)\n",
      "Train Epoch: 37 | Loss: 0.315 | Acc: 89.151% (44504/49920)\n",
      "Train Epoch: 37 | Loss: 0.314 | Acc: 89.152% (44576/50000)\n",
      "Test Epoch: 37 | Loss: 0.323 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 37 | Loss: 0.352 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 37 | Loss: 0.311 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 37 | Loss: 0.330 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 37 | Loss: 0.336 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 37 | Loss: 0.306 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 37 | Loss: 0.313 | Acc: 89.143% (624/700)\n",
      "Test Epoch: 37 | Loss: 0.335 | Acc: 88.250% (706/800)\n",
      "Test Epoch: 37 | Loss: 0.353 | Acc: 88.000% (792/900)\n",
      "Test Epoch: 37 | Loss: 0.344 | Acc: 88.100% (881/1000)\n",
      "Test Epoch: 37 | Loss: 0.353 | Acc: 88.000% (968/1100)\n",
      "Test Epoch: 37 | Loss: 0.363 | Acc: 87.583% (1051/1200)\n",
      "Test Epoch: 37 | Loss: 0.361 | Acc: 87.462% (1137/1300)\n",
      "Test Epoch: 37 | Loss: 0.368 | Acc: 87.286% (1222/1400)\n",
      "Test Epoch: 37 | Loss: 0.370 | Acc: 87.333% (1310/1500)\n",
      "Test Epoch: 37 | Loss: 0.373 | Acc: 87.375% (1398/1600)\n",
      "Test Epoch: 37 | Loss: 0.376 | Acc: 87.176% (1482/1700)\n",
      "Test Epoch: 37 | Loss: 0.388 | Acc: 86.889% (1564/1800)\n",
      "Test Epoch: 37 | Loss: 0.383 | Acc: 87.000% (1653/1900)\n",
      "Test Epoch: 37 | Loss: 0.390 | Acc: 86.900% (1738/2000)\n",
      "Test Epoch: 37 | Loss: 0.391 | Acc: 86.905% (1825/2100)\n",
      "Test Epoch: 37 | Loss: 0.388 | Acc: 87.000% (1914/2200)\n",
      "Test Epoch: 37 | Loss: 0.386 | Acc: 87.043% (2002/2300)\n",
      "Test Epoch: 37 | Loss: 0.383 | Acc: 87.125% (2091/2400)\n",
      "Test Epoch: 37 | Loss: 0.386 | Acc: 87.080% (2177/2500)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 87.000% (2262/2600)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 87.074% (2351/2700)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.250% (2443/2800)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 87.276% (2531/2900)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 87.300% (2619/3000)\n",
      "Test Epoch: 37 | Loss: 0.402 | Acc: 87.097% (2700/3100)\n",
      "Test Epoch: 37 | Loss: 0.401 | Acc: 87.094% (2787/3200)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 87.030% (2872/3300)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.059% (2960/3400)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 87.000% (3045/3500)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 87.056% (3134/3600)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 87.054% (3221/3700)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 87.026% (3307/3800)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.077% (3396/3900)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 87.125% (3485/4000)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 87.073% (3570/4100)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 87.119% (3659/4200)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.233% (3751/4300)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.318% (3842/4400)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.422% (3934/4500)\n",
      "Test Epoch: 37 | Loss: 0.393 | Acc: 87.370% (4019/4600)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.277% (4102/4700)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.167% (4184/4800)\n",
      "Test Epoch: 37 | Loss: 0.390 | Acc: 87.265% (4276/4900)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.140% (4357/5000)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.196% (4447/5100)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.154% (4532/5200)\n",
      "Test Epoch: 37 | Loss: 0.393 | Acc: 87.113% (4617/5300)\n",
      "Test Epoch: 37 | Loss: 0.391 | Acc: 87.204% (4709/5400)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.145% (4793/5500)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.018% (4873/5600)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.035% (4961/5700)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.052% (5049/5800)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 86.949% (5130/5900)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 86.950% (5217/6000)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.000% (5307/6100)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.000% (5394/6200)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.968% (5479/6300)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 86.953% (5565/6400)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.908% (5649/6500)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 86.894% (5735/6600)\n",
      "Test Epoch: 37 | Loss: 0.393 | Acc: 86.955% (5826/6700)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.897% (5909/6800)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.899% (5996/6900)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 86.857% (6080/7000)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 86.845% (6166/7100)\n",
      "Test Epoch: 37 | Loss: 0.400 | Acc: 86.861% (6254/7200)\n",
      "Test Epoch: 37 | Loss: 0.399 | Acc: 86.904% (6344/7300)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 86.878% (6429/7400)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.907% (6518/7500)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.934% (6607/7600)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.922% (6693/7700)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 86.987% (6785/7800)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.063% (6878/7900)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.075% (6966/8000)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.123% (7057/8100)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.134% (7145/8200)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.048% (7225/8300)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.048% (7312/8400)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.047% (7399/8500)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.047% (7486/8600)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.092% (7577/8700)\n",
      "Test Epoch: 37 | Loss: 0.396 | Acc: 87.080% (7663/8800)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 87.011% (7744/8900)\n",
      "Test Epoch: 37 | Loss: 0.398 | Acc: 86.989% (7829/9000)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.000% (7917/9100)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.043% (8008/9200)\n",
      "Test Epoch: 37 | Loss: 0.397 | Acc: 87.032% (8094/9300)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.064% (8184/9400)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.116% (8276/9500)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.125% (8364/9600)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.196% (8458/9700)\n",
      "Test Epoch: 37 | Loss: 0.392 | Acc: 87.224% (8548/9800)\n",
      "Test Epoch: 37 | Loss: 0.394 | Acc: 87.192% (8632/9900)\n",
      "Test Epoch: 37 | Loss: 0.395 | Acc: 87.150% (8715/10000)\n",
      "\n",
      "Epoch: 38\n",
      "Train Epoch: 38 | Loss: 0.261 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.625% (232/256)\n",
      "Train Epoch: 38 | Loss: 0.256 | Acc: 92.188% (354/384)\n",
      "Train Epoch: 38 | Loss: 0.245 | Acc: 92.383% (473/512)\n",
      "Train Epoch: 38 | Loss: 0.276 | Acc: 90.625% (580/640)\n",
      "Train Epoch: 38 | Loss: 0.266 | Acc: 90.495% (695/768)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.290% (809/896)\n",
      "Train Epoch: 38 | Loss: 0.273 | Acc: 90.527% (927/1024)\n",
      "Train Epoch: 38 | Loss: 0.275 | Acc: 90.365% (1041/1152)\n",
      "Train Epoch: 38 | Loss: 0.274 | Acc: 90.234% (1155/1280)\n",
      "Train Epoch: 38 | Loss: 0.267 | Acc: 90.554% (1275/1408)\n",
      "Train Epoch: 38 | Loss: 0.263 | Acc: 90.690% (1393/1536)\n",
      "Train Epoch: 38 | Loss: 0.268 | Acc: 90.505% (1506/1664)\n",
      "Train Epoch: 38 | Loss: 0.272 | Acc: 90.458% (1621/1792)\n",
      "Train Epoch: 38 | Loss: 0.274 | Acc: 90.417% (1736/1920)\n",
      "Train Epoch: 38 | Loss: 0.275 | Acc: 90.479% (1853/2048)\n",
      "Train Epoch: 38 | Loss: 0.276 | Acc: 90.533% (1970/2176)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.234% (2079/2304)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.378% (2198/2432)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.469% (2316/2560)\n",
      "Train Epoch: 38 | Loss: 0.278 | Acc: 90.476% (2432/2688)\n",
      "Train Epoch: 38 | Loss: 0.278 | Acc: 90.554% (2550/2816)\n",
      "Train Epoch: 38 | Loss: 0.277 | Acc: 90.625% (2668/2944)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.592% (2783/3072)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.500% (2896/3200)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.595% (3015/3328)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.596% (3131/3456)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.709% (3251/3584)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.679% (3366/3712)\n",
      "Train Epoch: 38 | Loss: 0.277 | Acc: 90.755% (3485/3840)\n",
      "Train Epoch: 38 | Loss: 0.276 | Acc: 90.751% (3601/3968)\n",
      "Train Epoch: 38 | Loss: 0.275 | Acc: 90.796% (3719/4096)\n",
      "Train Epoch: 38 | Loss: 0.278 | Acc: 90.625% (3828/4224)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.625% (3944/4352)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.670% (4062/4480)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.603% (4175/4608)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.583% (4290/4736)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.646% (4409/4864)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.665% (4526/4992)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.645% (4641/5120)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.663% (4758/5248)\n",
      "Train Epoch: 38 | Loss: 0.282 | Acc: 90.588% (4870/5376)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.498% (4981/5504)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.501% (5097/5632)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.417% (5208/5760)\n",
      "Train Epoch: 38 | Loss: 0.283 | Acc: 90.506% (5329/5888)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.608% (5451/6016)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.609% (5567/6144)\n",
      "Train Epoch: 38 | Loss: 0.277 | Acc: 90.721% (5690/6272)\n",
      "Train Epoch: 38 | Loss: 0.277 | Acc: 90.719% (5806/6400)\n",
      "Train Epoch: 38 | Loss: 0.278 | Acc: 90.671% (5919/6528)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.640% (6033/6656)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.581% (6145/6784)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.553% (6259/6912)\n",
      "Train Epoch: 38 | Loss: 0.279 | Acc: 90.554% (6375/7040)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.485% (6486/7168)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.461% (6600/7296)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.450% (6715/7424)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.506% (6835/7552)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.482% (6949/7680)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.459% (7063/7808)\n",
      "Train Epoch: 38 | Loss: 0.282 | Acc: 90.461% (7179/7936)\n",
      "Train Epoch: 38 | Loss: 0.282 | Acc: 90.414% (7291/8064)\n",
      "Train Epoch: 38 | Loss: 0.283 | Acc: 90.381% (7404/8192)\n",
      "Train Epoch: 38 | Loss: 0.282 | Acc: 90.409% (7522/8320)\n",
      "Train Epoch: 38 | Loss: 0.283 | Acc: 90.376% (7635/8448)\n",
      "Train Epoch: 38 | Loss: 0.282 | Acc: 90.473% (7759/8576)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.510% (7878/8704)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.523% (7995/8832)\n",
      "Train Epoch: 38 | Loss: 0.280 | Acc: 90.547% (8113/8960)\n",
      "Train Epoch: 38 | Loss: 0.281 | Acc: 90.482% (8223/9088)\n",
      "Train Epoch: 38 | Loss: 0.283 | Acc: 90.441% (8335/9216)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.390% (8446/9344)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.372% (8560/9472)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.333% (8672/9600)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.317% (8786/9728)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.300% (8900/9856)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.274% (9013/9984)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.269% (9128/10112)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.254% (9242/10240)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.297% (9362/10368)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.282% (9476/10496)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.286% (9592/10624)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.309% (9710/10752)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.322% (9827/10880)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.334% (9944/11008)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.275% (10053/11136)\n",
      "Train Epoch: 38 | Loss: 0.288 | Acc: 90.225% (10163/11264)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.256% (10282/11392)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.252% (10397/11520)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.264% (10514/11648)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.285% (10632/11776)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.297% (10749/11904)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.342% (10870/12032)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.296% (10980/12160)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.299% (11096/12288)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.287% (11210/12416)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.282% (11325/12544)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.270% (11439/12672)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.242% (11551/12800)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.207% (11662/12928)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.219% (11779/13056)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.185% (11890/13184)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.204% (12008/13312)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.216% (12125/13440)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.242% (12244/13568)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.216% (12356/13696)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.249% (12476/13824)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.202% (12585/13952)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.256% (12708/14080)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.287% (12828/14208)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.297% (12945/14336)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.314% (13063/14464)\n",
      "Train Epoch: 38 | Loss: 0.283 | Acc: 90.317% (13179/14592)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.312% (13294/14720)\n",
      "Train Epoch: 38 | Loss: 0.284 | Acc: 90.302% (13408/14848)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.251% (13516/14976)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.267% (13634/15104)\n",
      "Train Epoch: 38 | Loss: 0.285 | Acc: 90.244% (13746/15232)\n",
      "Train Epoch: 38 | Loss: 0.286 | Acc: 90.208% (13856/15360)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.173% (13966/15488)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.151% (14078/15616)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.142% (14192/15744)\n",
      "Train Epoch: 38 | Loss: 0.288 | Acc: 90.146% (14308/15872)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.162% (14426/16000)\n",
      "Train Epoch: 38 | Loss: 0.287 | Acc: 90.148% (14539/16128)\n",
      "Train Epoch: 38 | Loss: 0.288 | Acc: 90.114% (14649/16256)\n",
      "Train Epoch: 38 | Loss: 0.289 | Acc: 90.106% (14763/16384)\n",
      "Train Epoch: 38 | Loss: 0.289 | Acc: 90.086% (14875/16512)\n",
      "Train Epoch: 38 | Loss: 0.289 | Acc: 90.066% (14987/16640)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.058% (15101/16768)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.051% (15215/16896)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.055% (15331/17024)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.059% (15447/17152)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.069% (15564/17280)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.085% (15682/17408)\n",
      "Train Epoch: 38 | Loss: 0.291 | Acc: 90.066% (15794/17536)\n",
      "Train Epoch: 38 | Loss: 0.290 | Acc: 90.076% (15911/17664)\n",
      "Train Epoch: 38 | Loss: 0.291 | Acc: 90.080% (16027/17792)\n",
      "Train Epoch: 38 | Loss: 0.291 | Acc: 90.073% (16141/17920)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.004% (16244/18048)\n",
      "Train Epoch: 38 | Loss: 0.293 | Acc: 89.987% (16356/18176)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.002% (16474/18304)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.007% (16590/18432)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.000% (16704/18560)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 89.994% (16818/18688)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.003% (16935/18816)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.013% (17052/18944)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.006% (17166/19072)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.016% (17283/19200)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 89.999% (17395/19328)\n",
      "Train Epoch: 38 | Loss: 0.292 | Acc: 90.003% (17511/19456)\n",
      "Train Epoch: 38 | Loss: 0.293 | Acc: 89.987% (17623/19584)\n",
      "Train Epoch: 38 | Loss: 0.293 | Acc: 90.006% (17742/19712)\n",
      "Train Epoch: 38 | Loss: 0.294 | Acc: 89.980% (17852/19840)\n",
      "Train Epoch: 38 | Loss: 0.294 | Acc: 89.969% (17965/19968)\n",
      "Train Epoch: 38 | Loss: 0.294 | Acc: 89.973% (18081/20096)\n",
      "Train Epoch: 38 | Loss: 0.294 | Acc: 89.962% (18194/20224)\n",
      "Train Epoch: 38 | Loss: 0.294 | Acc: 89.957% (18308/20352)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.922% (18416/20480)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.883% (18523/20608)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.878% (18637/20736)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.873% (18751/20864)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.853% (18862/20992)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.867% (18980/21120)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.844% (19090/21248)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.853% (19207/21376)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.876% (19327/21504)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.853% (19437/21632)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.848% (19551/21760)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.844% (19665/21888)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.848% (19781/22016)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.848% (19896/22144)\n",
      "Train Epoch: 38 | Loss: 0.295 | Acc: 89.848% (20011/22272)\n",
      "Train Epoch: 38 | Loss: 0.296 | Acc: 89.830% (20122/22400)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.813% (20233/22528)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.791% (20343/22656)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.774% (20454/22784)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.756% (20565/22912)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.731% (20674/23040)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.749% (20793/23168)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.745% (20907/23296)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.724% (21017/23424)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.721% (21131/23552)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.721% (21246/23680)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.735% (21364/23808)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.739% (21480/23936)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.727% (21592/24064)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.707% (21702/24192)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.720% (21820/24320)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.705% (21931/24448)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.742% (22055/24576)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.730% (22167/24704)\n",
      "Train Epoch: 38 | Loss: 0.297 | Acc: 89.731% (22282/24832)\n",
      "Train Epoch: 38 | Loss: 0.298 | Acc: 89.712% (22392/24960)\n",
      "Train Epoch: 38 | Loss: 0.299 | Acc: 89.696% (22503/25088)\n",
      "Train Epoch: 38 | Loss: 0.299 | Acc: 89.689% (22616/25216)\n",
      "Train Epoch: 38 | Loss: 0.299 | Acc: 89.686% (22730/25344)\n",
      "Train Epoch: 38 | Loss: 0.299 | Acc: 89.691% (22846/25472)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.676% (22957/25600)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.677% (23072/25728)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.658% (23182/25856)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.655% (23296/25984)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.656% (23411/26112)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.649% (23524/26240)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.654% (23640/26368)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.647% (23753/26496)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.641% (23866/26624)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.649% (23983/26752)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.647% (24097/26880)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.662% (24216/27008)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.659% (24330/27136)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.646% (24441/27264)\n",
      "Train Epoch: 38 | Loss: 0.300 | Acc: 89.621% (24549/27392)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.604% (24659/27520)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.580% (24767/27648)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.606% (24889/27776)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.579% (24996/27904)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.590% (25114/28032)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.585% (25227/28160)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.582% (25341/28288)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.573% (25453/28416)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.585% (25571/28544)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.586% (25686/28672)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.604% (25806/28800)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.591% (25917/28928)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.586% (26030/29056)\n",
      "Train Epoch: 38 | Loss: 0.301 | Acc: 89.587% (26145/29184)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.574% (26256/29312)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.579% (26372/29440)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.553% (26479/29568)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.537% (26589/29696)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.545% (26706/29824)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.520% (26813/29952)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.525% (26929/30080)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.536% (27047/30208)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.547% (27165/30336)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.535% (27276/30464)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.533% (27390/30592)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.535% (27505/30720)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.533% (27619/30848)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.534% (27734/30976)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.542% (27851/31104)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.549% (27968/31232)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.550% (28083/31360)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.526% (28190/31488)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.521% (28303/31616)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.504% (28412/31744)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.502% (28526/31872)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.513% (28644/32000)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.504% (28756/32128)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.503% (28870/32256)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.489% (28980/32384)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.469% (29088/32512)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.476% (29205/32640)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.481% (29321/32768)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.479% (29435/32896)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.492% (29554/33024)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.494% (29669/33152)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.489% (29782/33280)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.485% (29895/33408)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.486% (30010/33536)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.493% (30127/33664)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.498% (30243/33792)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.475% (30350/33920)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.471% (30463/34048)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.469% (30577/34176)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.476% (30694/34304)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.487% (30812/34432)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.494% (30929/34560)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.489% (31042/34688)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.476% (31152/34816)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.469% (31264/34944)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.459% (31375/35072)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.457% (31489/35200)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.459% (31604/35328)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.457% (31718/35456)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.439% (31826/35584)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.449% (31944/35712)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.448% (32058/35840)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.455% (32175/35968)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.461% (32292/36096)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.482% (32414/36224)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.478% (32527/36352)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.487% (32645/36480)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.483% (32758/36608)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.490% (32875/36736)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.488% (32989/36864)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.484% (33102/36992)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.488% (33218/37120)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.487% (33332/37248)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.488% (33447/37376)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.473% (33556/37504)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.482% (33674/37632)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.473% (33785/37760)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.487% (33905/37888)\n",
      "Train Epoch: 38 | Loss: 0.302 | Acc: 89.478% (34016/38016)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.458% (34123/38144)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.457% (34237/38272)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.464% (34354/38400)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.462% (34468/38528)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.469% (34585/38656)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.465% (34698/38784)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.461% (34811/38912)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.465% (34927/39040)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.463% (35041/39168)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.452% (35151/39296)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.456% (35267/39424)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.454% (35381/39552)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.453% (35495/39680)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.449% (35608/39808)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.438% (35718/39936)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.434% (35831/40064)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.433% (35945/40192)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.439% (36062/40320)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.433% (36174/40448)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.444% (36293/40576)\n",
      "Train Epoch: 38 | Loss: 0.303 | Acc: 89.453% (36411/40704)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.445% (36522/40832)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.438% (36634/40960)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.442% (36750/41088)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.431% (36860/41216)\n",
      "Train Epoch: 38 | Loss: 0.304 | Acc: 89.425% (36972/41344)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.415% (37082/41472)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.401% (37191/41600)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.379% (37296/41728)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.385% (37413/41856)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.386% (37528/41984)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.388% (37643/42112)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.377% (37753/42240)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.383% (37870/42368)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.392% (37988/42496)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.393% (38103/42624)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.402% (38221/42752)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.396% (38333/42880)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.390% (38445/43008)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.389% (38559/43136)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.400% (38678/43264)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.392% (38789/43392)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.382% (38899/43520)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.381% (39013/43648)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.387% (39130/43776)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.372% (39238/43904)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.380% (39356/44032)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.393% (39476/44160)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.399% (39593/44288)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.405% (39710/44416)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.404% (39824/44544)\n",
      "Train Epoch: 38 | Loss: 0.305 | Acc: 89.407% (39940/44672)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.404% (40053/44800)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.392% (40162/44928)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.378% (40270/45056)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.386% (40388/45184)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.396% (40507/45312)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.397% (40622/45440)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.400% (40738/45568)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.400% (40852/45696)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.407% (40970/45824)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.398% (41080/45952)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.403% (41197/46080)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.398% (41309/46208)\n",
      "Train Epoch: 38 | Loss: 0.306 | Acc: 89.391% (41420/46336)\n",
      "Train Epoch: 38 | Loss: 0.307 | Acc: 89.385% (41532/46464)\n",
      "Train Epoch: 38 | Loss: 0.307 | Acc: 89.372% (41640/46592)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.351% (41745/46720)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.351% (41859/46848)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.358% (41977/46976)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.362% (42093/47104)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.361% (42207/47232)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.371% (42326/47360)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.376% (42443/47488)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.369% (42554/47616)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.368% (42668/47744)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.372% (42784/47872)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.367% (42896/48000)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.355% (43005/48128)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.351% (43117/48256)\n",
      "Train Epoch: 38 | Loss: 0.309 | Acc: 89.352% (43232/48384)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.361% (43351/48512)\n",
      "Train Epoch: 38 | Loss: 0.309 | Acc: 89.344% (43457/48640)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.360% (43579/48768)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.363% (43695/48896)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.366% (43811/49024)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.368% (43926/49152)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.379% (44046/49280)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.388% (44165/49408)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.371% (44271/49536)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.365% (44382/49664)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.368% (44498/49792)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.363% (44610/49920)\n",
      "Train Epoch: 38 | Loss: 0.308 | Acc: 89.362% (44681/50000)\n",
      "Test Epoch: 38 | Loss: 0.248 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 38 | Loss: 0.350 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 38 | Loss: 0.352 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 38 | Loss: 0.341 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 38 | Loss: 0.354 | Acc: 86.800% (434/500)\n",
      "Test Epoch: 38 | Loss: 0.320 | Acc: 88.333% (530/600)\n",
      "Test Epoch: 38 | Loss: 0.316 | Acc: 88.571% (620/700)\n",
      "Test Epoch: 38 | Loss: 0.353 | Acc: 87.875% (703/800)\n",
      "Test Epoch: 38 | Loss: 0.374 | Acc: 87.111% (784/900)\n",
      "Test Epoch: 38 | Loss: 0.371 | Acc: 87.600% (876/1000)\n",
      "Test Epoch: 38 | Loss: 0.363 | Acc: 87.909% (967/1100)\n",
      "Test Epoch: 38 | Loss: 0.366 | Acc: 87.917% (1055/1200)\n",
      "Test Epoch: 38 | Loss: 0.364 | Acc: 87.615% (1139/1300)\n",
      "Test Epoch: 38 | Loss: 0.364 | Acc: 87.571% (1226/1400)\n",
      "Test Epoch: 38 | Loss: 0.367 | Acc: 87.533% (1313/1500)\n",
      "Test Epoch: 38 | Loss: 0.367 | Acc: 87.438% (1399/1600)\n",
      "Test Epoch: 38 | Loss: 0.368 | Acc: 87.471% (1487/1700)\n",
      "Test Epoch: 38 | Loss: 0.383 | Acc: 87.000% (1566/1800)\n",
      "Test Epoch: 38 | Loss: 0.388 | Acc: 86.895% (1651/1900)\n",
      "Test Epoch: 38 | Loss: 0.388 | Acc: 86.750% (1735/2000)\n",
      "Test Epoch: 38 | Loss: 0.387 | Acc: 86.905% (1825/2100)\n",
      "Test Epoch: 38 | Loss: 0.383 | Acc: 87.000% (1914/2200)\n",
      "Test Epoch: 38 | Loss: 0.388 | Acc: 86.913% (1999/2300)\n",
      "Test Epoch: 38 | Loss: 0.387 | Acc: 86.833% (2084/2400)\n",
      "Test Epoch: 38 | Loss: 0.391 | Acc: 86.840% (2171/2500)\n",
      "Test Epoch: 38 | Loss: 0.399 | Acc: 86.731% (2255/2600)\n",
      "Test Epoch: 38 | Loss: 0.395 | Acc: 86.963% (2348/2700)\n",
      "Test Epoch: 38 | Loss: 0.397 | Acc: 86.929% (2434/2800)\n",
      "Test Epoch: 38 | Loss: 0.397 | Acc: 86.966% (2522/2900)\n",
      "Test Epoch: 38 | Loss: 0.399 | Acc: 86.867% (2606/3000)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.710% (2688/3100)\n",
      "Test Epoch: 38 | Loss: 0.403 | Acc: 86.844% (2779/3200)\n",
      "Test Epoch: 38 | Loss: 0.401 | Acc: 86.939% (2869/3300)\n",
      "Test Epoch: 38 | Loss: 0.402 | Acc: 86.882% (2954/3400)\n",
      "Test Epoch: 38 | Loss: 0.403 | Acc: 86.857% (3040/3500)\n",
      "Test Epoch: 38 | Loss: 0.402 | Acc: 86.861% (3127/3600)\n",
      "Test Epoch: 38 | Loss: 0.402 | Acc: 86.865% (3214/3700)\n",
      "Test Epoch: 38 | Loss: 0.403 | Acc: 86.816% (3299/3800)\n",
      "Test Epoch: 38 | Loss: 0.403 | Acc: 86.846% (3387/3900)\n",
      "Test Epoch: 38 | Loss: 0.401 | Acc: 86.925% (3477/4000)\n",
      "Test Epoch: 38 | Loss: 0.401 | Acc: 86.854% (3561/4100)\n",
      "Test Epoch: 38 | Loss: 0.401 | Acc: 86.833% (3647/4200)\n",
      "Test Epoch: 38 | Loss: 0.399 | Acc: 86.884% (3736/4300)\n",
      "Test Epoch: 38 | Loss: 0.398 | Acc: 86.977% (3827/4400)\n",
      "Test Epoch: 38 | Loss: 0.398 | Acc: 87.089% (3919/4500)\n",
      "Test Epoch: 38 | Loss: 0.398 | Acc: 87.130% (4008/4600)\n",
      "Test Epoch: 38 | Loss: 0.400 | Acc: 87.021% (4090/4700)\n",
      "Test Epoch: 38 | Loss: 0.401 | Acc: 86.958% (4174/4800)\n",
      "Test Epoch: 38 | Loss: 0.400 | Acc: 86.980% (4262/4900)\n",
      "Test Epoch: 38 | Loss: 0.405 | Acc: 86.840% (4342/5000)\n",
      "Test Epoch: 38 | Loss: 0.403 | Acc: 86.863% (4430/5100)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.769% (4512/5200)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.755% (4598/5300)\n",
      "Test Epoch: 38 | Loss: 0.407 | Acc: 86.852% (4690/5400)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.709% (4769/5500)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.732% (4857/5600)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.754% (4945/5700)\n",
      "Test Epoch: 38 | Loss: 0.409 | Acc: 86.793% (5034/5800)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.661% (5113/5900)\n",
      "Test Epoch: 38 | Loss: 0.413 | Acc: 86.550% (5193/6000)\n",
      "Test Epoch: 38 | Loss: 0.412 | Acc: 86.574% (5281/6100)\n",
      "Test Epoch: 38 | Loss: 0.413 | Acc: 86.516% (5364/6200)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.603% (5456/6300)\n",
      "Test Epoch: 38 | Loss: 0.409 | Acc: 86.625% (5544/6400)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.692% (5635/6500)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.773% (5727/6600)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.806% (5816/6700)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.809% (5903/6800)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.855% (5993/6900)\n",
      "Test Epoch: 38 | Loss: 0.409 | Acc: 86.757% (6073/7000)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.761% (6160/7100)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.722% (6244/7200)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.726% (6331/7300)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.770% (6421/7400)\n",
      "Test Epoch: 38 | Loss: 0.407 | Acc: 86.733% (6505/7500)\n",
      "Test Epoch: 38 | Loss: 0.407 | Acc: 86.750% (6593/7600)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.675% (6674/7700)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.705% (6763/7800)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.658% (6846/7900)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.650% (6932/8000)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.753% (7027/8100)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.756% (7114/8200)\n",
      "Test Epoch: 38 | Loss: 0.406 | Acc: 86.747% (7200/8300)\n",
      "Test Epoch: 38 | Loss: 0.407 | Acc: 86.762% (7288/8400)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.694% (7369/8500)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.698% (7456/8600)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.736% (7546/8700)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.750% (7634/8800)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.708% (7717/8900)\n",
      "Test Epoch: 38 | Loss: 0.412 | Acc: 86.711% (7804/9000)\n",
      "Test Epoch: 38 | Loss: 0.411 | Acc: 86.692% (7889/9100)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.728% (7979/9200)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.720% (8065/9300)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.734% (8153/9400)\n",
      "Test Epoch: 38 | Loss: 0.409 | Acc: 86.758% (8242/9500)\n",
      "Test Epoch: 38 | Loss: 0.409 | Acc: 86.771% (8330/9600)\n",
      "Test Epoch: 38 | Loss: 0.407 | Acc: 86.845% (8424/9700)\n",
      "Test Epoch: 38 | Loss: 0.408 | Acc: 86.827% (8509/9800)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.788% (8592/9900)\n",
      "Test Epoch: 38 | Loss: 0.410 | Acc: 86.760% (8676/10000)\n",
      "\n",
      "Epoch: 39\n",
      "Train Epoch: 39 | Loss: 0.487 | Acc: 82.031% (105/128)\n",
      "Train Epoch: 39 | Loss: 0.374 | Acc: 86.719% (222/256)\n",
      "Train Epoch: 39 | Loss: 0.362 | Acc: 87.240% (335/384)\n",
      "Train Epoch: 39 | Loss: 0.329 | Acc: 88.477% (453/512)\n",
      "Train Epoch: 39 | Loss: 0.336 | Acc: 88.281% (565/640)\n",
      "Train Epoch: 39 | Loss: 0.344 | Acc: 88.021% (676/768)\n",
      "Train Epoch: 39 | Loss: 0.325 | Acc: 88.504% (793/896)\n",
      "Train Epoch: 39 | Loss: 0.310 | Acc: 89.160% (913/1024)\n",
      "Train Epoch: 39 | Loss: 0.312 | Acc: 88.976% (1025/1152)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.297% (1143/1280)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.489% (1260/1408)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.583% (1376/1536)\n",
      "Train Epoch: 39 | Loss: 0.289 | Acc: 89.724% (1493/1664)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.565% (1605/1792)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 89.688% (1722/1920)\n",
      "Train Epoch: 39 | Loss: 0.289 | Acc: 89.844% (1840/2048)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 90.028% (1959/2176)\n",
      "Train Epoch: 39 | Loss: 0.281 | Acc: 90.061% (2075/2304)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.008% (2189/2432)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 90.078% (2306/2560)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 89.807% (2414/2688)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 89.950% (2533/2816)\n",
      "Train Epoch: 39 | Loss: 0.280 | Acc: 90.048% (2651/2944)\n",
      "Train Epoch: 39 | Loss: 0.281 | Acc: 90.072% (2767/3072)\n",
      "Train Epoch: 39 | Loss: 0.281 | Acc: 90.062% (2882/3200)\n",
      "Train Epoch: 39 | Loss: 0.280 | Acc: 90.114% (2999/3328)\n",
      "Train Epoch: 39 | Loss: 0.279 | Acc: 90.133% (3115/3456)\n",
      "Train Epoch: 39 | Loss: 0.282 | Acc: 90.011% (3226/3584)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 89.925% (3338/3712)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 89.870% (3451/3840)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 89.844% (3565/3968)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 89.966% (3685/4096)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 89.938% (3799/4224)\n",
      "Train Epoch: 39 | Loss: 0.282 | Acc: 90.051% (3919/4352)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.045% (4034/4480)\n",
      "Train Epoch: 39 | Loss: 0.288 | Acc: 89.909% (4143/4608)\n",
      "Train Epoch: 39 | Loss: 0.289 | Acc: 89.907% (4258/4736)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 90.070% (4381/4864)\n",
      "Train Epoch: 39 | Loss: 0.288 | Acc: 90.044% (4495/4992)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 90.098% (4613/5120)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 90.130% (4730/5248)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 90.160% (4847/5376)\n",
      "Train Epoch: 39 | Loss: 0.285 | Acc: 90.189% (4964/5504)\n",
      "Train Epoch: 39 | Loss: 0.285 | Acc: 90.199% (5080/5632)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.243% (5198/5760)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.183% (5310/5888)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.193% (5426/6016)\n",
      "Train Epoch: 39 | Loss: 0.283 | Acc: 90.202% (5542/6144)\n",
      "Train Epoch: 39 | Loss: 0.280 | Acc: 90.322% (5665/6272)\n",
      "Train Epoch: 39 | Loss: 0.282 | Acc: 90.203% (5773/6400)\n",
      "Train Epoch: 39 | Loss: 0.287 | Acc: 90.058% (5879/6528)\n",
      "Train Epoch: 39 | Loss: 0.286 | Acc: 90.099% (5997/6656)\n",
      "Train Epoch: 39 | Loss: 0.284 | Acc: 90.183% (6118/6784)\n",
      "Train Epoch: 39 | Loss: 0.285 | Acc: 90.090% (6227/6912)\n",
      "Train Epoch: 39 | Loss: 0.287 | Acc: 90.043% (6339/7040)\n",
      "Train Epoch: 39 | Loss: 0.288 | Acc: 90.039% (6454/7168)\n",
      "Train Epoch: 39 | Loss: 0.288 | Acc: 89.995% (6566/7296)\n",
      "Train Epoch: 39 | Loss: 0.289 | Acc: 89.992% (6681/7424)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 89.910% (6790/7552)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.883% (6903/7680)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.882% (7018/7808)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.856% (7131/7936)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.745% (7237/8064)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.758% (7353/8192)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.688% (7462/8320)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.654% (7574/8448)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.681% (7691/8576)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.648% (7803/8704)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.651% (7918/8832)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.598% (8028/8960)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.635% (8146/9088)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.659% (8263/9216)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.726% (8384/9344)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.749% (8501/9472)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.729% (8614/9600)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.731% (8729/9728)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.763% (8847/9856)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 89.804% (8966/9984)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 89.834% (9084/10112)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.814% (9197/10240)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.796% (9310/10368)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.796% (9425/10496)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.806% (9541/10624)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.825% (9658/10752)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.825% (9773/10880)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.835% (9889/11008)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.727% (9992/11136)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.693% (10103/11264)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.695% (10218/11392)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.696% (10333/11520)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.655% (10443/11648)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.614% (10553/11776)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.625% (10669/11904)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.603% (10781/12032)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.605% (10896/12160)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.665% (11018/12288)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.675% (11134/12416)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.644% (11245/12544)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.662% (11362/12672)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.664% (11477/12800)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.728% (11600/12928)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.729% (11715/13056)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.745% (11832/13184)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.739% (11946/13312)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.784% (12067/13440)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.785% (12182/13568)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.749% (12292/13696)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.800% (12414/13824)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.794% (12528/13952)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.801% (12644/14080)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.787% (12757/14208)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.795% (12873/14336)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.788% (12987/14464)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.775% (13100/14592)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.762% (13213/14720)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.763% (13328/14848)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.744% (13440/14976)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.751% (13556/15104)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.732% (13668/15232)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.746% (13785/15360)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.766% (13903/15488)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.780% (14020/15616)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.793% (14137/15744)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.831% (14258/15872)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.862% (14378/16000)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.862% (14493/16128)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.875% (14610/16256)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.886% (14727/16384)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.880% (14841/16512)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.904% (14960/16640)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.915% (15077/16768)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.915% (15192/16896)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.932% (15310/17024)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.949% (15428/17152)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.977% (15548/17280)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 89.993% (15666/17408)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.015% (15785/17536)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.002% (15898/17664)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.990% (16011/17792)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.006% (16129/17920)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.021% (16247/18048)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.014% (16361/18176)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.046% (16482/18304)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.072% (16602/18432)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.027% (16709/18560)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.026% (16824/18688)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.024% (16939/18816)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.044% (17058/18944)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.059% (17176/19072)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.068% (17293/19200)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.061% (17407/19328)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.034% (17517/19456)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.028% (17631/19584)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.047% (17750/19712)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.040% (17864/19840)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.049% (17981/19968)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.048% (18096/20096)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.046% (18211/20224)\n",
      "Train Epoch: 39 | Loss: 0.291 | Acc: 90.040% (18325/20352)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.034% (18439/20480)\n",
      "Train Epoch: 39 | Loss: 0.292 | Acc: 90.023% (18552/20608)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.998% (18662/20736)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.002% (18778/20864)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.015% (18896/20992)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.986% (19005/21120)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.999% (19123/21248)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.007% (19240/21376)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.007% (19355/21504)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.978% (19464/21632)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.968% (19577/21760)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.963% (19691/21888)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.953% (19804/22016)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.952% (19919/22144)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 89.974% (20039/22272)\n",
      "Train Epoch: 39 | Loss: 0.293 | Acc: 90.000% (20160/22400)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.986% (20272/22528)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.954% (20380/22656)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.918% (20487/22784)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.905% (20599/22912)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.926% (20719/23040)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.934% (20836/23168)\n",
      "Train Epoch: 39 | Loss: 0.294 | Acc: 89.934% (20951/23296)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.904% (21059/23424)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.916% (21177/23552)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.920% (21293/23680)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.898% (21403/23808)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.886% (21515/23936)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.898% (21633/24064)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.877% (21743/24192)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.881% (21859/24320)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.913% (21982/24448)\n",
      "Train Epoch: 39 | Loss: 0.295 | Acc: 89.901% (22094/24576)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.872% (22202/24704)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.888% (22321/24832)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.892% (22437/24960)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.868% (22546/25088)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.840% (22654/25216)\n",
      "Train Epoch: 39 | Loss: 0.296 | Acc: 89.860% (22774/25344)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.816% (22878/25472)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.812% (22992/25600)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.824% (23110/25728)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.824% (23225/25856)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.840% (23344/25984)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.813% (23452/26112)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.794% (23562/26240)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.791% (23676/26368)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.791% (23791/26496)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.799% (23908/26624)\n",
      "Train Epoch: 39 | Loss: 0.297 | Acc: 89.806% (24025/26752)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.792% (24136/26880)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.777% (24247/27008)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.788% (24365/27136)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.811% (24486/27264)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.818% (24603/27392)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.818% (24718/27520)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.808% (24830/27648)\n",
      "Train Epoch: 39 | Loss: 0.298 | Acc: 89.833% (24952/27776)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.815% (25062/27904)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.815% (25177/28032)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.826% (25295/28160)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.812% (25406/28288)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.812% (25521/28416)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.816% (25637/28544)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.809% (25750/28672)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.806% (25864/28800)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.813% (25981/28928)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.789% (26089/29056)\n",
      "Train Epoch: 39 | Loss: 0.299 | Acc: 89.785% (26203/29184)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.769% (26313/29312)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.762% (26426/29440)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.776% (26545/29568)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.763% (26656/29696)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.743% (26765/29824)\n",
      "Train Epoch: 39 | Loss: 0.300 | Acc: 89.747% (26881/29952)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.727% (26990/30080)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.708% (27099/30208)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.722% (27218/30336)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.745% (27340/30464)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.749% (27456/30592)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.730% (27565/30720)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.743% (27684/30848)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.750% (27801/30976)\n",
      "Train Epoch: 39 | Loss: 0.301 | Acc: 89.734% (27911/31104)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.719% (28021/31232)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.732% (28140/31360)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.748% (28260/31488)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.739% (28372/31616)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.718% (28480/31744)\n",
      "Train Epoch: 39 | Loss: 0.302 | Acc: 89.721% (28596/31872)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.703% (28705/32000)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.704% (28820/32128)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.710% (28937/32256)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.711% (29052/32384)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.708% (29166/32512)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.688% (29274/32640)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.694% (29391/32768)\n",
      "Train Epoch: 39 | Loss: 0.303 | Acc: 89.701% (29508/32896)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.689% (29619/33024)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.675% (29729/33152)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.660% (29839/33280)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.646% (29949/33408)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.647% (30064/33536)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.648% (30179/33664)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.663% (30299/33792)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.655% (30411/33920)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.656% (30526/34048)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.668% (30645/34176)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.663% (30758/34304)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.652% (30869/34432)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.638% (30979/34560)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.639% (31094/34688)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.637% (31208/34816)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.632% (31321/34944)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.636% (31437/35072)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.636% (31552/35200)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.612% (31658/35328)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.601% (31769/35456)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.613% (31888/35584)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.614% (32003/35712)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.618% (32119/35840)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.616% (32233/35968)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.611% (32346/36096)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.623% (32465/36224)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.635% (32584/36352)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.649% (32704/36480)\n",
      "Train Epoch: 39 | Loss: 0.304 | Acc: 89.650% (32819/36608)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.626% (32925/36736)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.632% (33042/36864)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.633% (33157/36992)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.623% (33268/37120)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.616% (33380/37248)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.603% (33490/37376)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.609% (33607/37504)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.605% (33720/37632)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.605% (33835/37760)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.611% (33952/37888)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.615% (34068/38016)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.597% (34176/38144)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.601% (34292/38272)\n",
      "Train Epoch: 39 | Loss: 0.305 | Acc: 89.602% (34407/38400)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.582% (34514/38528)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.588% (34631/38656)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.578% (34742/38784)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.571% (34854/38912)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.572% (34969/39040)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.578% (35086/39168)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.577% (35200/39296)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.580% (35316/39424)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.576% (35429/39552)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.579% (35545/39680)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.567% (35655/39808)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.553% (35764/39936)\n",
      "Train Epoch: 39 | Loss: 0.306 | Acc: 89.569% (35885/40064)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.563% (35997/40192)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.549% (36106/40320)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.550% (36221/40448)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.536% (36330/40576)\n",
      "Train Epoch: 39 | Loss: 0.307 | Acc: 89.534% (36444/40704)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.523% (36554/40832)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.536% (36674/40960)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.535% (36788/41088)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.523% (36898/41216)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.527% (37014/41344)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.530% (37130/41472)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.534% (37246/41600)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.532% (37360/41728)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.536% (37476/41856)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.525% (37586/41984)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.516% (37697/42112)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.519% (37813/42240)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.525% (37930/42368)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.517% (38041/42496)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.534% (38163/42624)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.533% (38277/42752)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.527% (38389/42880)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.532% (38506/43008)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.531% (38620/43136)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.534% (38736/43264)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.544% (38855/43392)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.543% (38969/43520)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.541% (39083/43648)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.538% (39196/43776)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.532% (39308/43904)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.539% (39426/44032)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.536% (39539/44160)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.530% (39651/44288)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.526% (39764/44416)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.520% (39876/44544)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.521% (39991/44672)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.529% (40109/44800)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.510% (40215/44928)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.517% (40333/45056)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.523% (40450/45184)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.517% (40562/45312)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.518% (40677/45440)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.519% (40792/45568)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.531% (40912/45696)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.525% (41024/45824)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.519% (41136/45952)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.518% (41250/46080)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.521% (41366/46208)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.524% (41482/46336)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.523% (41596/46464)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.509% (41704/46592)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.499% (41814/46720)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.504% (41931/46848)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.501% (42044/46976)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.513% (42164/47104)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.507% (42276/47232)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.491% (42383/47360)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.486% (42495/47488)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.483% (42608/47616)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.490% (42726/47744)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.507% (42849/47872)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.521% (42970/48000)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.518% (43083/48128)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.506% (43192/48256)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.507% (43307/48384)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.508% (43422/48512)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.531% (43548/48640)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.528% (43661/48768)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.527% (43775/48896)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.536% (43894/49024)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.528% (44005/49152)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.539% (44125/49280)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.534% (44237/49408)\n",
      "Train Epoch: 39 | Loss: 0.308 | Acc: 89.535% (44352/49536)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.526% (44462/49664)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.514% (44571/49792)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.521% (44689/49920)\n",
      "Train Epoch: 39 | Loss: 0.309 | Acc: 89.522% (44761/50000)\n",
      "Test Epoch: 39 | Loss: 0.303 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 39 | Loss: 0.346 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 39 | Loss: 0.333 | Acc: 87.800% (439/500)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 39 | Loss: 0.308 | Acc: 88.714% (621/700)\n",
      "Test Epoch: 39 | Loss: 0.340 | Acc: 87.750% (702/800)\n",
      "Test Epoch: 39 | Loss: 0.360 | Acc: 87.667% (789/900)\n",
      "Test Epoch: 39 | Loss: 0.349 | Acc: 87.900% (879/1000)\n",
      "Test Epoch: 39 | Loss: 0.357 | Acc: 87.818% (966/1100)\n",
      "Test Epoch: 39 | Loss: 0.347 | Acc: 88.167% (1058/1200)\n",
      "Test Epoch: 39 | Loss: 0.341 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 39 | Loss: 0.339 | Acc: 88.071% (1233/1400)\n",
      "Test Epoch: 39 | Loss: 0.334 | Acc: 88.200% (1323/1500)\n",
      "Test Epoch: 39 | Loss: 0.334 | Acc: 88.312% (1413/1600)\n",
      "Test Epoch: 39 | Loss: 0.333 | Acc: 88.529% (1505/1700)\n",
      "Test Epoch: 39 | Loss: 0.341 | Acc: 88.278% (1589/1800)\n",
      "Test Epoch: 39 | Loss: 0.338 | Acc: 88.263% (1677/1900)\n",
      "Test Epoch: 39 | Loss: 0.344 | Acc: 88.050% (1761/2000)\n",
      "Test Epoch: 39 | Loss: 0.344 | Acc: 88.048% (1849/2100)\n",
      "Test Epoch: 39 | Loss: 0.342 | Acc: 88.227% (1941/2200)\n",
      "Test Epoch: 39 | Loss: 0.347 | Acc: 88.174% (2028/2300)\n",
      "Test Epoch: 39 | Loss: 0.345 | Acc: 88.208% (2117/2400)\n",
      "Test Epoch: 39 | Loss: 0.350 | Acc: 88.040% (2201/2500)\n",
      "Test Epoch: 39 | Loss: 0.362 | Acc: 87.846% (2284/2600)\n",
      "Test Epoch: 39 | Loss: 0.359 | Acc: 87.963% (2375/2700)\n",
      "Test Epoch: 39 | Loss: 0.359 | Acc: 88.036% (2465/2800)\n",
      "Test Epoch: 39 | Loss: 0.358 | Acc: 88.000% (2552/2900)\n",
      "Test Epoch: 39 | Loss: 0.358 | Acc: 88.033% (2641/3000)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.935% (2726/3100)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.906% (2813/3200)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.970% (2903/3300)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.882% (2988/3400)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.829% (3074/3500)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.917% (3165/3600)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.865% (3251/3700)\n",
      "Test Epoch: 39 | Loss: 0.371 | Acc: 87.763% (3335/3800)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.846% (3426/3900)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.775% (3511/4000)\n",
      "Test Epoch: 39 | Loss: 0.371 | Acc: 87.756% (3598/4100)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.786% (3687/4200)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.884% (3779/4300)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.955% (3870/4400)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 88.022% (3961/4500)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.957% (4046/4600)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.979% (4135/4700)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.917% (4220/4800)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.939% (4309/4900)\n",
      "Test Epoch: 39 | Loss: 0.370 | Acc: 87.780% (4389/5000)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.843% (4480/5100)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.865% (4569/5200)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.830% (4655/5300)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.870% (4745/5400)\n",
      "Test Epoch: 39 | Loss: 0.371 | Acc: 87.764% (4827/5500)\n",
      "Test Epoch: 39 | Loss: 0.371 | Acc: 87.768% (4915/5600)\n",
      "Test Epoch: 39 | Loss: 0.370 | Acc: 87.737% (5001/5700)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.776% (5091/5800)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.746% (5177/5900)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.700% (5262/6000)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.705% (5350/6100)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.677% (5436/6200)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.698% (5525/6300)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.750% (5616/6400)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.738% (5703/6500)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.833% (5797/6600)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.925% (5891/6700)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.838% (5973/6800)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.913% (6066/6900)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.914% (6154/7000)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.930% (6243/7100)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.847% (6325/7200)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.904% (6417/7300)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.946% (6508/7400)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.933% (6595/7500)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.961% (6685/7600)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.909% (6769/7700)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.936% (6859/7800)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.911% (6945/7900)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.875% (7030/8000)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.926% (7122/8100)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.902% (7208/8200)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 87.928% (7298/8300)\n",
      "Test Epoch: 39 | Loss: 0.364 | Acc: 87.881% (7382/8400)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.859% (7468/8500)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.791% (7550/8600)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.770% (7636/8700)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.761% (7723/8800)\n",
      "Test Epoch: 39 | Loss: 0.370 | Acc: 87.719% (7807/8900)\n",
      "Test Epoch: 39 | Loss: 0.370 | Acc: 87.711% (7894/9000)\n",
      "Test Epoch: 39 | Loss: 0.371 | Acc: 87.725% (7983/9100)\n",
      "Test Epoch: 39 | Loss: 0.369 | Acc: 87.783% (8076/9200)\n",
      "Test Epoch: 39 | Loss: 0.368 | Acc: 87.839% (8169/9300)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.872% (8260/9400)\n",
      "Test Epoch: 39 | Loss: 0.366 | Acc: 87.895% (8350/9500)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.938% (8442/9600)\n",
      "Test Epoch: 39 | Loss: 0.363 | Acc: 88.010% (8537/9700)\n",
      "Test Epoch: 39 | Loss: 0.365 | Acc: 87.980% (8622/9800)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.980% (8710/9900)\n",
      "Test Epoch: 39 | Loss: 0.367 | Acc: 87.970% (8797/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Train Epoch: 40 | Loss: 0.346 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 40 | Loss: 0.316 | Acc: 89.062% (228/256)\n",
      "Train Epoch: 40 | Loss: 0.287 | Acc: 90.104% (346/384)\n",
      "Train Epoch: 40 | Loss: 0.259 | Acc: 91.406% (468/512)\n",
      "Train Epoch: 40 | Loss: 0.271 | Acc: 91.094% (583/640)\n",
      "Train Epoch: 40 | Loss: 0.267 | Acc: 91.406% (702/768)\n",
      "Train Epoch: 40 | Loss: 0.279 | Acc: 91.295% (818/896)\n",
      "Train Epoch: 40 | Loss: 0.276 | Acc: 91.406% (936/1024)\n",
      "Train Epoch: 40 | Loss: 0.274 | Acc: 91.406% (1053/1152)\n",
      "Train Epoch: 40 | Loss: 0.280 | Acc: 91.094% (1166/1280)\n",
      "Train Epoch: 40 | Loss: 0.279 | Acc: 91.051% (1282/1408)\n",
      "Train Epoch: 40 | Loss: 0.283 | Acc: 91.016% (1398/1536)\n",
      "Train Epoch: 40 | Loss: 0.284 | Acc: 91.046% (1515/1664)\n",
      "Train Epoch: 40 | Loss: 0.289 | Acc: 90.792% (1627/1792)\n",
      "Train Epoch: 40 | Loss: 0.289 | Acc: 90.677% (1741/1920)\n",
      "Train Epoch: 40 | Loss: 0.288 | Acc: 90.820% (1860/2048)\n",
      "Train Epoch: 40 | Loss: 0.286 | Acc: 90.855% (1977/2176)\n",
      "Train Epoch: 40 | Loss: 0.286 | Acc: 90.885% (2094/2304)\n",
      "Train Epoch: 40 | Loss: 0.291 | Acc: 90.625% (2204/2432)\n",
      "Train Epoch: 40 | Loss: 0.290 | Acc: 90.625% (2320/2560)\n",
      "Train Epoch: 40 | Loss: 0.292 | Acc: 90.625% (2436/2688)\n",
      "Train Epoch: 40 | Loss: 0.292 | Acc: 90.554% (2550/2816)\n",
      "Train Epoch: 40 | Loss: 0.293 | Acc: 90.421% (2662/2944)\n",
      "Train Epoch: 40 | Loss: 0.295 | Acc: 90.267% (2773/3072)\n",
      "Train Epoch: 40 | Loss: 0.294 | Acc: 90.219% (2887/3200)\n",
      "Train Epoch: 40 | Loss: 0.295 | Acc: 90.084% (2998/3328)\n",
      "Train Epoch: 40 | Loss: 0.294 | Acc: 90.046% (3112/3456)\n",
      "Train Epoch: 40 | Loss: 0.292 | Acc: 90.123% (3230/3584)\n",
      "Train Epoch: 40 | Loss: 0.293 | Acc: 90.113% (3345/3712)\n",
      "Train Epoch: 40 | Loss: 0.297 | Acc: 89.922% (3453/3840)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.819% (3564/3968)\n",
      "Train Epoch: 40 | Loss: 0.305 | Acc: 89.624% (3671/4096)\n",
      "Train Epoch: 40 | Loss: 0.303 | Acc: 89.725% (3790/4224)\n",
      "Train Epoch: 40 | Loss: 0.302 | Acc: 89.798% (3908/4352)\n",
      "Train Epoch: 40 | Loss: 0.303 | Acc: 89.777% (4022/4480)\n",
      "Train Epoch: 40 | Loss: 0.302 | Acc: 89.757% (4136/4608)\n",
      "Train Epoch: 40 | Loss: 0.299 | Acc: 89.823% (4254/4736)\n",
      "Train Epoch: 40 | Loss: 0.300 | Acc: 89.700% (4363/4864)\n",
      "Train Epoch: 40 | Loss: 0.299 | Acc: 89.724% (4479/4992)\n",
      "Train Epoch: 40 | Loss: 0.300 | Acc: 89.648% (4590/5120)\n",
      "Train Epoch: 40 | Loss: 0.300 | Acc: 89.653% (4705/5248)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.602% (4817/5376)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.680% (4936/5504)\n",
      "Train Epoch: 40 | Loss: 0.299 | Acc: 89.808% (5058/5632)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.740% (5169/5760)\n",
      "Train Epoch: 40 | Loss: 0.299 | Acc: 89.810% (5288/5888)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.678% (5395/6016)\n",
      "Train Epoch: 40 | Loss: 0.301 | Acc: 89.730% (5513/6144)\n",
      "Train Epoch: 40 | Loss: 0.302 | Acc: 89.700% (5626/6272)\n",
      "Train Epoch: 40 | Loss: 0.303 | Acc: 89.641% (5737/6400)\n",
      "Train Epoch: 40 | Loss: 0.304 | Acc: 89.599% (5849/6528)\n",
      "Train Epoch: 40 | Loss: 0.304 | Acc: 89.588% (5963/6656)\n",
      "Train Epoch: 40 | Loss: 0.306 | Acc: 89.505% (6072/6784)\n",
      "Train Epoch: 40 | Loss: 0.307 | Acc: 89.468% (6184/6912)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.474% (6299/7040)\n",
      "Train Epoch: 40 | Loss: 0.305 | Acc: 89.551% (6419/7168)\n",
      "Train Epoch: 40 | Loss: 0.307 | Acc: 89.501% (6530/7296)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.520% (6646/7424)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.552% (6763/7552)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.466% (6871/7680)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.485% (6987/7808)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.491% (7102/7936)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.472% (7215/8064)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.429% (7326/8192)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.423% (7440/8320)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.406% (7553/8448)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.436% (7670/8576)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.453% (7786/8704)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.425% (7898/8832)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.364% (8007/8960)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.349% (8120/9088)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.334% (8233/9216)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.351% (8349/9344)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.411% (8469/9472)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.438% (8586/9600)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.484% (8705/9728)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.438% (8815/9856)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.403% (8926/9984)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.438% (9044/10112)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.424% (9157/10240)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.468% (9276/10368)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.472% (9391/10496)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.458% (9504/10624)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.472% (9620/10752)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.513% (9739/10880)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.499% (9852/11008)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.538% (9971/11136)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.542% (10086/11264)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.545% (10201/11392)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.531% (10314/11520)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.518% (10427/11648)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.504% (10540/11776)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.483% (10652/11904)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.528% (10772/12032)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.515% (10885/12160)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.502% (10998/12288)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.449% (11106/12416)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.485% (11225/12544)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.504% (11342/12672)\n",
      "Train Epoch: 40 | Loss: 0.309 | Acc: 89.484% (11454/12800)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.527% (11574/12928)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.530% (11689/13056)\n",
      "Train Epoch: 40 | Loss: 0.307 | Acc: 89.571% (11809/13184)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.528% (11918/13312)\n",
      "Train Epoch: 40 | Loss: 0.308 | Acc: 89.539% (12034/13440)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.475% (12140/13568)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.457% (12252/13696)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.482% (12370/13824)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.493% (12486/13952)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.517% (12604/14080)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.464% (12711/14208)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.425% (12820/14336)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.477% (12942/14464)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.481% (13057/14592)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.477% (13171/14720)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.487% (13287/14848)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.503% (13404/14976)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.499% (13518/15104)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.463% (13627/15232)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.460% (13741/15360)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.450% (13854/15488)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.453% (13969/15616)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.431% (14080/15744)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.428% (14194/15872)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.438% (14310/16000)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.435% (14424/16128)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.438% (14539/16256)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.453% (14656/16384)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.480% (14775/16512)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.471% (14888/16640)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.486% (15005/16768)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.495% (15121/16896)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.485% (15234/17024)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.494% (15350/17152)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.508% (15467/17280)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.499% (15580/17408)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.496% (15694/17536)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.493% (15808/17664)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.478% (15920/17792)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.498% (16038/17920)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.500% (16153/18048)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.514% (16270/18176)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.472% (16377/18304)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.469% (16491/18432)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.472% (16606/18560)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.469% (16720/18688)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.450% (16831/18816)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.448% (16945/18944)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.477% (17065/19072)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.469% (17178/19200)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.461% (17291/19328)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.474% (17408/19456)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.445% (17517/19584)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.428% (17628/19712)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.430% (17743/19840)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.418% (17855/19968)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.421% (17970/20096)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.419% (18084/20224)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.426% (18200/20352)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.404% (18310/20480)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.373% (18418/20608)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.361% (18530/20736)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.388% (18650/20864)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.391% (18765/20992)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.394% (18880/21120)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.406% (18997/21248)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.409% (19112/21376)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.411% (19227/21504)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.386% (19336/21632)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.389% (19451/21760)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.387% (19565/21888)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.394% (19681/22016)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.410% (19799/22144)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.381% (19907/22272)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.393% (20024/22400)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.369% (20133/22528)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.336% (20240/22656)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.339% (20355/22784)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.342% (20470/22912)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.336% (20583/23040)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.347% (20700/23168)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.324% (20809/23296)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.344% (20928/23424)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.330% (21039/23552)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.307% (21148/23680)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.319% (21265/23808)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.317% (21379/23936)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.304% (21490/24064)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.298% (21603/24192)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.309% (21720/24320)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.312% (21835/24448)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.299% (21946/24576)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.301% (22061/24704)\n",
      "Train Epoch: 40 | Loss: 0.314 | Acc: 89.304% (22176/24832)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.323% (22295/24960)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.326% (22410/25088)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.328% (22525/25216)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (22643/25344)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.341% (22757/25472)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.355% (22875/25600)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.350% (22988/25728)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.329% (23097/25856)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.336% (23213/25984)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.334% (23327/26112)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.341% (23443/26240)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.324% (23553/26368)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.342% (23672/26496)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.340% (23786/26624)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.320% (23895/26752)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.345% (24016/26880)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.340% (24129/27008)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.339% (24243/27136)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.327% (24354/27264)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.303% (24462/27392)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.317% (24580/27520)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.345% (24702/27648)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.347% (24817/27776)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.353% (24933/27904)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.355% (25048/28032)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.347% (25160/28160)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.359% (25278/28288)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.362% (25393/28416)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.360% (25507/28544)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.348% (25618/28672)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.368% (25738/28800)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.374% (25854/28928)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.376% (25969/29056)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.378% (26084/29184)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.376% (26198/29312)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.378% (26313/29440)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.370% (26425/29568)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.362% (26537/29696)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.348% (26647/29824)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.336% (26758/29952)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.335% (26872/30080)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.331% (26985/30208)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.333% (27100/30336)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.338% (27216/30464)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.340% (27331/30592)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.339% (27445/30720)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.341% (27560/30848)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.369% (27683/30976)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.368% (27797/31104)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.354% (27907/31232)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.369% (28026/31360)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.348% (28134/31488)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.341% (28246/31616)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (28361/31744)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.332% (28472/31872)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.319% (28582/32000)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.321% (28697/32128)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.323% (28812/32256)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.331% (28929/32384)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.333% (29044/32512)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.341% (29161/32640)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.337% (29274/32768)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.339% (29389/32896)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.320% (29497/33024)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.322% (29612/33152)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.315% (29724/33280)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.323% (29841/33408)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.331% (29958/33536)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.324% (30070/33664)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.320% (30183/33792)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.325% (30299/33920)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.339% (30418/34048)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.317% (30525/34176)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.319% (30640/34304)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.321% (30755/34432)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.329% (30872/34560)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.319% (30983/34688)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.332% (31102/34816)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.334% (31217/34944)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.348% (31336/35072)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.366% (31457/35200)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.360% (31569/35328)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.361% (31684/35456)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.360% (31798/35584)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.371% (31916/35712)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.361% (32027/35840)\n",
      "Train Epoch: 40 | Loss: 0.310 | Acc: 89.349% (32137/35968)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.345% (32250/36096)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.330% (32359/36224)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.329% (32473/36352)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.326% (32586/36480)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.322% (32699/36608)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.337% (32819/36736)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.334% (32932/36864)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.338% (33048/36992)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.348% (33166/37120)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.358% (33284/37248)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.349% (33395/37376)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.350% (33510/37504)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.328% (33616/37632)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.322% (33728/37760)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.316% (33840/37888)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.302% (33949/38016)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.306% (34065/38144)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.305% (34179/38272)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.305% (34293/38400)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.306% (34408/38528)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.316% (34526/38656)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.325% (34644/38784)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.330% (34760/38912)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.321% (34871/39040)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.333% (34990/39168)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.345% (35109/39296)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.347% (35224/39424)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.343% (35337/39552)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.332% (35447/39680)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.324% (35558/39808)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.323% (35672/39936)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.330% (35789/40064)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.319% (35899/40192)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.318% (36013/40320)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.317% (36127/40448)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.306% (36237/40576)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.306% (36351/40704)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.312% (36468/40832)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.307% (36580/40960)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.306% (36694/41088)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.303% (36807/41216)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.307% (36923/41344)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.292% (37031/41472)\n",
      "Train Epoch: 40 | Loss: 0.313 | Acc: 89.291% (37145/41600)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.307% (37266/41728)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.321% (37386/41856)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.327% (37503/41984)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.333% (37620/42112)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.330% (37733/42240)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.327% (37846/42368)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.333% (37963/42496)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.337% (38079/42624)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.339% (38194/42752)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.347% (38312/42880)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.346% (38426/43008)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.345% (38540/43136)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.351% (38657/43264)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.341% (38767/43392)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.350% (38885/43520)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.349% (38999/43648)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.350% (39114/43776)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.352% (39229/43904)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.355% (39345/44032)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.359% (39461/44160)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.356% (39574/44288)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.355% (39688/44416)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.352% (39801/44544)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.358% (39918/44672)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.337% (40023/44800)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (40140/44928)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.342% (40254/45056)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.335% (40365/45184)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.336% (40480/45312)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.333% (40593/45440)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.328% (40705/45568)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.334% (40822/45696)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.342% (40940/45824)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.354% (41060/45952)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.349% (41172/46080)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.361% (41292/46208)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.358% (41405/46336)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.342% (41512/46464)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.346% (41628/46592)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.351% (41745/46720)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.338% (41853/46848)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.341% (41969/46976)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.353% (42089/47104)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.355% (42204/47232)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.339% (42311/47360)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.334% (42423/47488)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.336% (42538/47616)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.326% (42648/47744)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.326% (42762/47872)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.327% (42877/48000)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.335% (42995/48128)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.334% (43109/48256)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.337% (43225/48384)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (43342/48512)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.348% (43459/48640)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.345% (43572/48768)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (43685/48896)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.352% (43804/49024)\n",
      "Train Epoch: 40 | Loss: 0.312 | Acc: 89.343% (43914/49152)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.343% (44028/49280)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.350% (44146/49408)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.349% (44260/49536)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.354% (44377/49664)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.360% (44494/49792)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.351% (44604/49920)\n",
      "Train Epoch: 40 | Loss: 0.311 | Acc: 89.354% (44677/50000)\n",
      "Test Epoch: 40 | Loss: 0.386 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 40 | Loss: 0.410 | Acc: 84.500% (169/200)\n",
      "Test Epoch: 40 | Loss: 0.370 | Acc: 86.000% (258/300)\n",
      "Test Epoch: 40 | Loss: 0.336 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 40 | Loss: 0.309 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 40 | Loss: 0.288 | Acc: 89.667% (538/600)\n",
      "Test Epoch: 40 | Loss: 0.289 | Acc: 89.571% (627/700)\n",
      "Test Epoch: 40 | Loss: 0.319 | Acc: 88.500% (708/800)\n",
      "Test Epoch: 40 | Loss: 0.334 | Acc: 88.444% (796/900)\n",
      "Test Epoch: 40 | Loss: 0.339 | Acc: 88.400% (884/1000)\n",
      "Test Epoch: 40 | Loss: 0.345 | Acc: 88.364% (972/1100)\n",
      "Test Epoch: 40 | Loss: 0.342 | Acc: 88.500% (1062/1200)\n",
      "Test Epoch: 40 | Loss: 0.333 | Acc: 88.538% (1151/1300)\n",
      "Test Epoch: 40 | Loss: 0.332 | Acc: 88.429% (1238/1400)\n",
      "Test Epoch: 40 | Loss: 0.330 | Acc: 88.533% (1328/1500)\n",
      "Test Epoch: 40 | Loss: 0.330 | Acc: 88.625% (1418/1600)\n",
      "Test Epoch: 40 | Loss: 0.329 | Acc: 88.588% (1506/1700)\n",
      "Test Epoch: 40 | Loss: 0.335 | Acc: 88.389% (1591/1800)\n",
      "Test Epoch: 40 | Loss: 0.332 | Acc: 88.421% (1680/1900)\n",
      "Test Epoch: 40 | Loss: 0.335 | Acc: 88.300% (1766/2000)\n",
      "Test Epoch: 40 | Loss: 0.344 | Acc: 87.952% (1847/2100)\n",
      "Test Epoch: 40 | Loss: 0.344 | Acc: 87.864% (1933/2200)\n",
      "Test Epoch: 40 | Loss: 0.347 | Acc: 87.826% (2020/2300)\n",
      "Test Epoch: 40 | Loss: 0.349 | Acc: 87.750% (2106/2400)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 87.640% (2191/2500)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 87.500% (2275/2600)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.704% (2368/2700)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 87.714% (2456/2800)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 87.655% (2542/2900)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 87.533% (2626/3000)\n",
      "Test Epoch: 40 | Loss: 0.368 | Acc: 87.548% (2714/3100)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 87.656% (2805/3200)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.515% (2888/3300)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 87.382% (2971/3400)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.486% (3062/3500)\n",
      "Test Epoch: 40 | Loss: 0.363 | Acc: 87.556% (3152/3600)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.595% (3241/3700)\n",
      "Test Epoch: 40 | Loss: 0.365 | Acc: 87.526% (3326/3800)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.538% (3414/3900)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 87.525% (3501/4000)\n",
      "Test Epoch: 40 | Loss: 0.367 | Acc: 87.512% (3588/4100)\n",
      "Test Epoch: 40 | Loss: 0.366 | Acc: 87.595% (3679/4200)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.674% (3770/4300)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 87.750% (3861/4400)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 87.822% (3952/4500)\n",
      "Test Epoch: 40 | Loss: 0.358 | Acc: 87.891% (4043/4600)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 87.830% (4128/4700)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 87.771% (4213/4800)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.837% (4304/4900)\n",
      "Test Epoch: 40 | Loss: 0.364 | Acc: 87.720% (4386/5000)\n",
      "Test Epoch: 40 | Loss: 0.362 | Acc: 87.824% (4479/5100)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 87.846% (4568/5200)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.792% (4653/5300)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 87.870% (4745/5400)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 87.836% (4831/5500)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 87.839% (4919/5600)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.860% (5008/5700)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 87.879% (5097/5800)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.780% (5179/5900)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.800% (5268/6000)\n",
      "Test Epoch: 40 | Loss: 0.361 | Acc: 87.787% (5355/6100)\n",
      "Test Epoch: 40 | Loss: 0.360 | Acc: 87.839% (5446/6200)\n",
      "Test Epoch: 40 | Loss: 0.359 | Acc: 87.873% (5536/6300)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 87.969% (5630/6400)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.031% (5722/6500)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.091% (5814/6600)\n",
      "Test Epoch: 40 | Loss: 0.352 | Acc: 88.194% (5909/6700)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.118% (5992/6800)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.101% (6079/6900)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.086% (6166/7000)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.099% (6255/7100)\n",
      "Test Epoch: 40 | Loss: 0.356 | Acc: 88.139% (6346/7200)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.205% (6439/7300)\n",
      "Test Epoch: 40 | Loss: 0.352 | Acc: 88.243% (6530/7400)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.240% (6618/7500)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.237% (6706/7600)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.208% (6792/7700)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.192% (6879/7800)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.228% (6970/7900)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.250% (7060/8000)\n",
      "Test Epoch: 40 | Loss: 0.351 | Acc: 88.309% (7153/8100)\n",
      "Test Epoch: 40 | Loss: 0.351 | Acc: 88.329% (7243/8200)\n",
      "Test Epoch: 40 | Loss: 0.351 | Acc: 88.289% (7328/8300)\n",
      "Test Epoch: 40 | Loss: 0.351 | Acc: 88.298% (7417/8400)\n",
      "Test Epoch: 40 | Loss: 0.352 | Acc: 88.271% (7503/8500)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.233% (7588/8600)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.264% (7679/8700)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.205% (7762/8800)\n",
      "Test Epoch: 40 | Loss: 0.354 | Acc: 88.213% (7851/8900)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.222% (7940/9000)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.187% (8025/9100)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.250% (8119/9200)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.258% (8208/9300)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.223% (8293/9400)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.242% (8383/9500)\n",
      "Test Epoch: 40 | Loss: 0.353 | Acc: 88.219% (8469/9600)\n",
      "Test Epoch: 40 | Loss: 0.351 | Acc: 88.289% (8564/9700)\n",
      "Test Epoch: 40 | Loss: 0.352 | Acc: 88.265% (8650/9800)\n",
      "Test Epoch: 40 | Loss: 0.355 | Acc: 88.172% (8729/9900)\n",
      "Test Epoch: 40 | Loss: 0.356 | Acc: 88.130% (8813/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 41\n",
      "Train Epoch: 41 | Loss: 0.287 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 41 | Loss: 0.267 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 41 | Loss: 0.252 | Acc: 91.667% (352/384)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 88.867% (455/512)\n",
      "Train Epoch: 41 | Loss: 0.295 | Acc: 89.688% (574/640)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.365% (694/768)\n",
      "Train Epoch: 41 | Loss: 0.274 | Acc: 90.737% (813/896)\n",
      "Train Epoch: 41 | Loss: 0.269 | Acc: 90.918% (931/1024)\n",
      "Train Epoch: 41 | Loss: 0.270 | Acc: 90.799% (1046/1152)\n",
      "Train Epoch: 41 | Loss: 0.270 | Acc: 90.703% (1161/1280)\n",
      "Train Epoch: 41 | Loss: 0.273 | Acc: 90.554% (1275/1408)\n",
      "Train Epoch: 41 | Loss: 0.265 | Acc: 90.885% (1396/1536)\n",
      "Train Epoch: 41 | Loss: 0.265 | Acc: 90.925% (1513/1664)\n",
      "Train Epoch: 41 | Loss: 0.265 | Acc: 91.183% (1634/1792)\n",
      "Train Epoch: 41 | Loss: 0.259 | Acc: 91.510% (1757/1920)\n",
      "Train Epoch: 41 | Loss: 0.260 | Acc: 91.553% (1875/2048)\n",
      "Train Epoch: 41 | Loss: 0.263 | Acc: 91.406% (1989/2176)\n",
      "Train Epoch: 41 | Loss: 0.262 | Acc: 91.493% (2108/2304)\n",
      "Train Epoch: 41 | Loss: 0.266 | Acc: 91.406% (2223/2432)\n",
      "Train Epoch: 41 | Loss: 0.261 | Acc: 91.484% (2342/2560)\n",
      "Train Epoch: 41 | Loss: 0.263 | Acc: 91.443% (2458/2688)\n",
      "Train Epoch: 41 | Loss: 0.268 | Acc: 91.335% (2572/2816)\n",
      "Train Epoch: 41 | Loss: 0.268 | Acc: 91.101% (2682/2944)\n",
      "Train Epoch: 41 | Loss: 0.274 | Acc: 90.885% (2792/3072)\n",
      "Train Epoch: 41 | Loss: 0.276 | Acc: 90.812% (2906/3200)\n",
      "Train Epoch: 41 | Loss: 0.277 | Acc: 90.805% (3022/3328)\n",
      "Train Epoch: 41 | Loss: 0.276 | Acc: 90.828% (3139/3456)\n",
      "Train Epoch: 41 | Loss: 0.278 | Acc: 90.737% (3252/3584)\n",
      "Train Epoch: 41 | Loss: 0.274 | Acc: 90.867% (3373/3712)\n",
      "Train Epoch: 41 | Loss: 0.273 | Acc: 90.938% (3492/3840)\n",
      "Train Epoch: 41 | Loss: 0.276 | Acc: 90.776% (3602/3968)\n",
      "Train Epoch: 41 | Loss: 0.277 | Acc: 90.674% (3714/4096)\n",
      "Train Epoch: 41 | Loss: 0.279 | Acc: 90.696% (3831/4224)\n",
      "Train Epoch: 41 | Loss: 0.279 | Acc: 90.740% (3949/4352)\n",
      "Train Epoch: 41 | Loss: 0.279 | Acc: 90.692% (4063/4480)\n",
      "Train Epoch: 41 | Loss: 0.283 | Acc: 90.603% (4175/4608)\n",
      "Train Epoch: 41 | Loss: 0.284 | Acc: 90.519% (4287/4736)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.440% (4399/4864)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.425% (4514/4992)\n",
      "Train Epoch: 41 | Loss: 0.285 | Acc: 90.430% (4630/5120)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.396% (4744/5248)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.402% (4860/5376)\n",
      "Train Epoch: 41 | Loss: 0.288 | Acc: 90.298% (4970/5504)\n",
      "Train Epoch: 41 | Loss: 0.288 | Acc: 90.288% (5085/5632)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.365% (5205/5760)\n",
      "Train Epoch: 41 | Loss: 0.285 | Acc: 90.421% (5324/5888)\n",
      "Train Epoch: 41 | Loss: 0.285 | Acc: 90.442% (5441/6016)\n",
      "Train Epoch: 41 | Loss: 0.286 | Acc: 90.381% (5553/6144)\n",
      "Train Epoch: 41 | Loss: 0.288 | Acc: 90.322% (5665/6272)\n",
      "Train Epoch: 41 | Loss: 0.290 | Acc: 90.266% (5777/6400)\n",
      "Train Epoch: 41 | Loss: 0.291 | Acc: 90.242% (5891/6528)\n",
      "Train Epoch: 41 | Loss: 0.291 | Acc: 90.159% (6001/6656)\n",
      "Train Epoch: 41 | Loss: 0.292 | Acc: 90.139% (6115/6784)\n",
      "Train Epoch: 41 | Loss: 0.294 | Acc: 90.046% (6224/6912)\n",
      "Train Epoch: 41 | Loss: 0.295 | Acc: 90.000% (6336/7040)\n",
      "Train Epoch: 41 | Loss: 0.295 | Acc: 89.983% (6450/7168)\n",
      "Train Epoch: 41 | Loss: 0.296 | Acc: 89.953% (6563/7296)\n",
      "Train Epoch: 41 | Loss: 0.297 | Acc: 89.938% (6677/7424)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.831% (6784/7552)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.740% (6892/7680)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.703% (7004/7808)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.655% (7115/7936)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.645% (7229/8064)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.612% (7341/8192)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.579% (7453/8320)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.607% (7570/8448)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.599% (7684/8576)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.557% (7795/8704)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.583% (7912/8832)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.576% (8026/8960)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.525% (8136/9088)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.464% (8245/9216)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.491% (8362/9344)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.495% (8477/9472)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.531% (8595/9600)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.546% (8711/9728)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.580% (8829/9856)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.583% (8944/9984)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.606% (9061/10112)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.619% (9177/10240)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.622% (9292/10368)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.615% (9406/10496)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.637% (9523/10624)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.686% (9643/10752)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.688% (9758/10880)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.726% (9877/11008)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.718% (9991/11136)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.684% (10102/11264)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.695% (10218/11392)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.705% (10334/11520)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.646% (10442/11648)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.614% (10553/11776)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.583% (10664/11904)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.594% (10780/12032)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.630% (10899/12160)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.648% (11016/12288)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.626% (11128/12416)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.565% (11235/12544)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.575% (11351/12672)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.586% (11467/12800)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.581% (11581/12928)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.583% (11696/13056)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.616% (11815/13184)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.581% (11925/13312)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.576% (12039/13440)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.630% (12161/13568)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.647% (12278/13696)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.670% (12396/13824)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.650% (12508/13952)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.659% (12624/14080)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.654% (12738/14208)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.662% (12854/14336)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.657% (12968/14464)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.638% (13080/14592)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.654% (13197/14720)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.662% (13313/14848)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.710% (13435/14976)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.758% (13557/15104)\n",
      "Train Epoch: 41 | Loss: 0.297 | Acc: 89.798% (13678/15232)\n",
      "Train Epoch: 41 | Loss: 0.297 | Acc: 89.824% (13797/15360)\n",
      "Train Epoch: 41 | Loss: 0.297 | Acc: 89.805% (13909/15488)\n",
      "Train Epoch: 41 | Loss: 0.297 | Acc: 89.805% (14024/15616)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.768% (14133/15744)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.749% (14245/15872)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.756% (14361/16000)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.776% (14479/16128)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.770% (14593/16256)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.740% (14703/16384)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.729% (14816/16512)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.730% (14931/16640)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.748% (15049/16768)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.749% (15164/16896)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.738% (15277/17024)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.768% (15397/17152)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.740% (15507/17280)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.729% (15620/17408)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.753% (15739/17536)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.759% (15855/17664)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.754% (15969/17792)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.760% (16085/17920)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.750% (16198/18048)\n",
      "Train Epoch: 41 | Loss: 0.298 | Acc: 89.739% (16311/18176)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.718% (16422/18304)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.719% (16537/18432)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.704% (16649/18560)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.694% (16762/18688)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.722% (16882/18816)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.712% (16995/18944)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.723% (17112/19072)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.745% (17231/19200)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.740% (17345/19328)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.762% (17464/19456)\n",
      "Train Epoch: 41 | Loss: 0.299 | Acc: 89.752% (17577/19584)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.732% (17688/19712)\n",
      "Train Epoch: 41 | Loss: 0.300 | Acc: 89.708% (17798/19840)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.699% (17911/19968)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.699% (18026/20096)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.651% (18131/20224)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.588% (18233/20352)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.595% (18349/20480)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.591% (18463/20608)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.607% (18581/20736)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.614% (18697/20864)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.625% (18814/20992)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.640% (18932/21120)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.637% (19046/21248)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.624% (19158/21376)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.644% (19277/21504)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.631% (19389/21632)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.646% (19507/21760)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.643% (19621/21888)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.644% (19736/22016)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.659% (19854/22144)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.669% (19971/22272)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.679% (20088/22400)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.648% (20196/22528)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.627% (20306/22656)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.594% (20413/22784)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.599% (20529/22912)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.592% (20642/23040)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.580% (20754/23168)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.573% (20867/23296)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.571% (20981/23424)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.572% (21096/23552)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.565% (21209/23680)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.567% (21324/23808)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.560% (21437/23936)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.574% (21555/24064)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.559% (21666/24192)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.585% (21787/24320)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.607% (21907/24448)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.591% (22018/24576)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.593% (22133/24704)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.562% (22240/24832)\n",
      "Train Epoch: 41 | Loss: 0.301 | Acc: 89.559% (22354/24960)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.561% (22469/25088)\n",
      "Train Epoch: 41 | Loss: 0.302 | Acc: 89.538% (22578/25216)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.520% (22688/25344)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.522% (22803/25472)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.520% (22917/25600)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.509% (23029/25728)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.500% (23141/25856)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.520% (23261/25984)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.511% (23373/26112)\n",
      "Train Epoch: 41 | Loss: 0.303 | Acc: 89.516% (23489/26240)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.506% (23601/26368)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.493% (23712/26496)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.491% (23826/26624)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.485% (23939/26752)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.479% (24052/26880)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.499% (24172/27008)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.501% (24287/27136)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.514% (24405/27264)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.522% (24522/27392)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.539% (24641/27520)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.529% (24753/27648)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.516% (24864/27776)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.510% (24977/27904)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.516% (25093/28032)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (25206/28160)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.526% (25325/28288)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.545% (25445/28416)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.539% (25558/28544)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.554% (25677/28672)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.552% (25791/28800)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.557% (25907/28928)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.548% (26019/29056)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.542% (26132/29184)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.530% (26243/29312)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.541% (26361/29440)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.543% (26476/29568)\n",
      "Train Epoch: 41 | Loss: 0.304 | Acc: 89.554% (26594/29696)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.555% (26709/29824)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.550% (26822/29952)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.555% (26938/30080)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.533% (27046/30208)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.540% (27163/30336)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.538% (27277/30464)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.540% (27392/30592)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.531% (27504/30720)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.539% (27621/30848)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.518% (27729/30976)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (27840/31104)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.520% (27959/31232)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.534% (28078/31360)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.529% (28191/31488)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.524% (28304/31616)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.532% (28421/31744)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.533% (28536/31872)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.525% (28648/32000)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.520% (28761/32128)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.493% (28867/32256)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.504% (28985/32384)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.508% (29101/32512)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (29216/32640)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.514% (29332/32768)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.512% (29446/32896)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.511% (29560/33024)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.491% (29668/33152)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.504% (29787/33280)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.500% (29900/33408)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.495% (30013/33536)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.508% (30132/33664)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.512% (30248/33792)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.514% (30363/33920)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (30475/34048)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.493% (30585/34176)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.503% (30703/34304)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.498% (30816/34432)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.494% (30929/34560)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.492% (31043/34688)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.490% (31157/34816)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.492% (31272/34944)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.496% (31388/35072)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.503% (31505/35200)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.496% (31617/35328)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.494% (31731/35456)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.507% (31850/35584)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.519% (31969/35712)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.512% (32081/35840)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (32195/35968)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (32308/36096)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.515% (32426/36224)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.503% (32536/36352)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.512% (32654/36480)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.508% (32767/36608)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.503% (32880/36736)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.497% (32992/36864)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.503% (33109/36992)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.502% (33223/37120)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.503% (33338/37248)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.499% (33451/37376)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.494% (33564/37504)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (33683/37632)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (33799/37760)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.514% (33915/37888)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (34028/38016)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.492% (34136/38144)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.507% (34256/38272)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.513% (34373/38400)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.519% (34490/38528)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.526% (34607/38656)\n",
      "Train Epoch: 41 | Loss: 0.305 | Acc: 89.540% (34727/38784)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.520% (34834/38912)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (34943/39040)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.509% (35059/39168)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.521% (35178/39296)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.506% (35287/39424)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.518% (35406/39552)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.521% (35522/39680)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.522% (35637/39808)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.518% (35750/39936)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.522% (35866/40064)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.498% (35971/40192)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.487% (36081/40320)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (36205/40448)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.514% (36321/40576)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.524% (36440/40704)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.533% (36558/40832)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.519% (36667/40960)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.510% (36778/41088)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.511% (36893/41216)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.508% (37006/41344)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.513% (37123/41472)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.505% (37234/41600)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.491% (37343/41728)\n",
      "Train Epoch: 41 | Loss: 0.306 | Acc: 89.493% (37458/41856)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.475% (37565/41984)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.473% (37679/42112)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.465% (37790/42240)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.466% (37905/42368)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.453% (38014/42496)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.445% (38125/42624)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.439% (38237/42752)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.440% (38352/42880)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.437% (38465/43008)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.424% (38574/43136)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.421% (38687/43264)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.427% (38804/43392)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.428% (38919/43520)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.434% (39036/43648)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.428% (39148/43776)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.436% (39266/43904)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.437% (39381/44032)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.438% (39496/44160)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.446% (39614/44288)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.457% (39733/44416)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.471% (39854/44544)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.474% (39970/44672)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.473% (40084/44800)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.468% (40196/44928)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.462% (40308/45056)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.476% (40429/45184)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.480% (40545/45312)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.472% (40656/45440)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.475% (40772/45568)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.478% (40888/45696)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.464% (40996/45824)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.465% (41111/45952)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.460% (41223/46080)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.465% (41340/46208)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.457% (41451/46336)\n",
      "Train Epoch: 41 | Loss: 0.307 | Acc: 89.452% (41563/46464)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.423% (41664/46592)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.426% (41780/46720)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.430% (41896/46848)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.414% (42003/46976)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.411% (42116/47104)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.401% (42226/47232)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.398% (42339/47360)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.410% (42459/47488)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.417% (42577/47616)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.429% (42697/47744)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.422% (42808/47872)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.438% (42930/48000)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.439% (43045/48128)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.444% (43162/48256)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.439% (43274/48384)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.436% (43387/48512)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.447% (43507/48640)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.438% (43617/48768)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.435% (43730/48896)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.432% (43843/49024)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.435% (43959/49152)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.424% (44068/49280)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.423% (44182/49408)\n",
      "Train Epoch: 41 | Loss: 0.309 | Acc: 89.412% (44291/49536)\n",
      "Train Epoch: 41 | Loss: 0.309 | Acc: 89.407% (44403/49664)\n",
      "Train Epoch: 41 | Loss: 0.309 | Acc: 89.402% (44515/49792)\n",
      "Train Epoch: 41 | Loss: 0.309 | Acc: 89.415% (44636/49920)\n",
      "Train Epoch: 41 | Loss: 0.308 | Acc: 89.418% (44709/50000)\n",
      "Test Epoch: 41 | Loss: 0.323 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 41 | Loss: 0.385 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 41 | Loss: 0.354 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 41 | Loss: 0.355 | Acc: 88.250% (353/400)\n",
      "Test Epoch: 41 | Loss: 0.356 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 41 | Loss: 0.343 | Acc: 88.333% (530/600)\n",
      "Test Epoch: 41 | Loss: 0.350 | Acc: 88.286% (618/700)\n",
      "Test Epoch: 41 | Loss: 0.376 | Acc: 87.125% (697/800)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 86.889% (782/900)\n",
      "Test Epoch: 41 | Loss: 0.392 | Acc: 86.800% (868/1000)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 86.818% (955/1100)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 86.583% (1039/1200)\n",
      "Test Epoch: 41 | Loss: 0.384 | Acc: 86.692% (1127/1300)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 86.357% (1209/1400)\n",
      "Test Epoch: 41 | Loss: 0.386 | Acc: 86.533% (1298/1500)\n",
      "Test Epoch: 41 | Loss: 0.386 | Acc: 86.750% (1388/1600)\n",
      "Test Epoch: 41 | Loss: 0.385 | Acc: 87.000% (1479/1700)\n",
      "Test Epoch: 41 | Loss: 0.385 | Acc: 86.944% (1565/1800)\n",
      "Test Epoch: 41 | Loss: 0.379 | Acc: 87.105% (1655/1900)\n",
      "Test Epoch: 41 | Loss: 0.380 | Acc: 87.250% (1745/2000)\n",
      "Test Epoch: 41 | Loss: 0.389 | Acc: 86.952% (1826/2100)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 86.864% (1911/2200)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 86.826% (1997/2300)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 86.833% (2084/2400)\n",
      "Test Epoch: 41 | Loss: 0.402 | Acc: 86.440% (2161/2500)\n",
      "Test Epoch: 41 | Loss: 0.411 | Acc: 86.346% (2245/2600)\n",
      "Test Epoch: 41 | Loss: 0.406 | Acc: 86.519% (2336/2700)\n",
      "Test Epoch: 41 | Loss: 0.407 | Acc: 86.536% (2423/2800)\n",
      "Test Epoch: 41 | Loss: 0.407 | Acc: 86.483% (2508/2900)\n",
      "Test Epoch: 41 | Loss: 0.408 | Acc: 86.400% (2592/3000)\n",
      "Test Epoch: 41 | Loss: 0.409 | Acc: 86.258% (2674/3100)\n",
      "Test Epoch: 41 | Loss: 0.405 | Acc: 86.375% (2764/3200)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 86.455% (2853/3300)\n",
      "Test Epoch: 41 | Loss: 0.405 | Acc: 86.412% (2938/3400)\n",
      "Test Epoch: 41 | Loss: 0.403 | Acc: 86.400% (3024/3500)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 86.444% (3112/3600)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 86.459% (3199/3700)\n",
      "Test Epoch: 41 | Loss: 0.409 | Acc: 86.368% (3282/3800)\n",
      "Test Epoch: 41 | Loss: 0.406 | Acc: 86.487% (3373/3900)\n",
      "Test Epoch: 41 | Loss: 0.406 | Acc: 86.500% (3460/4000)\n",
      "Test Epoch: 41 | Loss: 0.404 | Acc: 86.512% (3547/4100)\n",
      "Test Epoch: 41 | Loss: 0.402 | Acc: 86.595% (3637/4200)\n",
      "Test Epoch: 41 | Loss: 0.399 | Acc: 86.674% (3727/4300)\n",
      "Test Epoch: 41 | Loss: 0.398 | Acc: 86.773% (3818/4400)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 86.889% (3910/4500)\n",
      "Test Epoch: 41 | Loss: 0.395 | Acc: 86.935% (3999/4600)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 86.936% (4086/4700)\n",
      "Test Epoch: 41 | Loss: 0.399 | Acc: 86.812% (4167/4800)\n",
      "Test Epoch: 41 | Loss: 0.396 | Acc: 86.918% (4259/4900)\n",
      "Test Epoch: 41 | Loss: 0.399 | Acc: 86.840% (4342/5000)\n",
      "Test Epoch: 41 | Loss: 0.397 | Acc: 86.922% (4433/5100)\n",
      "Test Epoch: 41 | Loss: 0.397 | Acc: 86.923% (4520/5200)\n",
      "Test Epoch: 41 | Loss: 0.399 | Acc: 86.830% (4602/5300)\n",
      "Test Epoch: 41 | Loss: 0.397 | Acc: 86.926% (4694/5400)\n",
      "Test Epoch: 41 | Loss: 0.398 | Acc: 86.909% (4780/5500)\n",
      "Test Epoch: 41 | Loss: 0.400 | Acc: 86.946% (4869/5600)\n",
      "Test Epoch: 41 | Loss: 0.399 | Acc: 86.912% (4954/5700)\n",
      "Test Epoch: 41 | Loss: 0.400 | Acc: 86.914% (5041/5800)\n",
      "Test Epoch: 41 | Loss: 0.402 | Acc: 86.898% (5127/5900)\n",
      "Test Epoch: 41 | Loss: 0.400 | Acc: 86.917% (5215/6000)\n",
      "Test Epoch: 41 | Loss: 0.398 | Acc: 86.984% (5306/6100)\n",
      "Test Epoch: 41 | Loss: 0.398 | Acc: 86.968% (5392/6200)\n",
      "Test Epoch: 41 | Loss: 0.396 | Acc: 87.016% (5482/6300)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 87.078% (5573/6400)\n",
      "Test Epoch: 41 | Loss: 0.396 | Acc: 86.954% (5652/6500)\n",
      "Test Epoch: 41 | Loss: 0.394 | Acc: 87.030% (5744/6600)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.134% (5838/6700)\n",
      "Test Epoch: 41 | Loss: 0.392 | Acc: 87.103% (5923/6800)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.145% (6013/6900)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.157% (6101/7000)\n",
      "Test Epoch: 41 | Loss: 0.393 | Acc: 87.127% (6186/7100)\n",
      "Test Epoch: 41 | Loss: 0.393 | Acc: 87.125% (6273/7200)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.192% (6365/7300)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.270% (6458/7400)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.307% (6548/7500)\n",
      "Test Epoch: 41 | Loss: 0.387 | Acc: 87.329% (6637/7600)\n",
      "Test Epoch: 41 | Loss: 0.387 | Acc: 87.286% (6721/7700)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.321% (6811/7800)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.354% (6901/7900)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.375% (6990/8000)\n",
      "Test Epoch: 41 | Loss: 0.387 | Acc: 87.420% (7081/8100)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.366% (7164/8200)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.361% (7251/8300)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.381% (7340/8400)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.329% (7423/8500)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.279% (7506/8600)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.299% (7595/8700)\n",
      "Test Epoch: 41 | Loss: 0.392 | Acc: 87.239% (7677/8800)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.281% (7768/8900)\n",
      "Test Epoch: 41 | Loss: 0.392 | Acc: 87.289% (7856/9000)\n",
      "Test Epoch: 41 | Loss: 0.392 | Acc: 87.242% (7939/9100)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.293% (8031/9200)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.301% (8119/9300)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.309% (8207/9400)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.274% (8291/9500)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.240% (8375/9600)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.309% (8469/9700)\n",
      "Test Epoch: 41 | Loss: 0.388 | Acc: 87.296% (8555/9800)\n",
      "Test Epoch: 41 | Loss: 0.391 | Acc: 87.212% (8634/9900)\n",
      "Test Epoch: 41 | Loss: 0.390 | Acc: 87.230% (8723/10000)\n",
      "\n",
      "Epoch: 42\n",
      "Train Epoch: 42 | Loss: 0.215 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 42 | Loss: 0.232 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 42 | Loss: 0.237 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 42 | Loss: 0.257 | Acc: 90.625% (464/512)\n",
      "Train Epoch: 42 | Loss: 0.252 | Acc: 90.781% (581/640)\n",
      "Train Epoch: 42 | Loss: 0.255 | Acc: 90.495% (695/768)\n",
      "Train Epoch: 42 | Loss: 0.256 | Acc: 90.290% (809/896)\n",
      "Train Epoch: 42 | Loss: 0.257 | Acc: 90.723% (929/1024)\n",
      "Train Epoch: 42 | Loss: 0.260 | Acc: 90.799% (1046/1152)\n",
      "Train Epoch: 42 | Loss: 0.252 | Acc: 91.250% (1168/1280)\n",
      "Train Epoch: 42 | Loss: 0.252 | Acc: 91.264% (1285/1408)\n",
      "Train Epoch: 42 | Loss: 0.258 | Acc: 91.081% (1399/1536)\n",
      "Train Epoch: 42 | Loss: 0.256 | Acc: 91.286% (1519/1664)\n",
      "Train Epoch: 42 | Loss: 0.261 | Acc: 91.127% (1633/1792)\n",
      "Train Epoch: 42 | Loss: 0.259 | Acc: 90.990% (1747/1920)\n",
      "Train Epoch: 42 | Loss: 0.262 | Acc: 90.918% (1862/2048)\n",
      "Train Epoch: 42 | Loss: 0.259 | Acc: 91.085% (1982/2176)\n",
      "Train Epoch: 42 | Loss: 0.259 | Acc: 90.929% (2095/2304)\n",
      "Train Epoch: 42 | Loss: 0.260 | Acc: 90.748% (2207/2432)\n",
      "Train Epoch: 42 | Loss: 0.264 | Acc: 90.586% (2319/2560)\n",
      "Train Epoch: 42 | Loss: 0.261 | Acc: 90.662% (2437/2688)\n",
      "Train Epoch: 42 | Loss: 0.265 | Acc: 90.376% (2545/2816)\n",
      "Train Epoch: 42 | Loss: 0.266 | Acc: 90.285% (2658/2944)\n",
      "Train Epoch: 42 | Loss: 0.270 | Acc: 90.234% (2772/3072)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.156% (2885/3200)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.054% (2997/3328)\n",
      "Train Epoch: 42 | Loss: 0.277 | Acc: 90.046% (3112/3456)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.123% (3230/3584)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.059% (3343/3712)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.156% (3462/3840)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.171% (3578/3968)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.234% (3696/4096)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.080% (3805/4224)\n",
      "Train Epoch: 42 | Loss: 0.273 | Acc: 90.188% (3925/4352)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.134% (4038/4480)\n",
      "Train Epoch: 42 | Loss: 0.278 | Acc: 90.082% (4151/4608)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.097% (4267/4736)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.090% (4382/4864)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.084% (4497/4992)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.215% (4619/5120)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.225% (4735/5248)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.179% (4848/5376)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.134% (4961/5504)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.092% (5074/5632)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.087% (5189/5760)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.099% (5305/5888)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.126% (5422/6016)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.186% (5541/6144)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.242% (5660/6272)\n",
      "Train Epoch: 42 | Loss: 0.273 | Acc: 90.312% (5780/6400)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.273% (5893/6528)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.340% (6013/6656)\n",
      "Train Epoch: 42 | Loss: 0.273 | Acc: 90.360% (6130/6784)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.422% (6250/6912)\n",
      "Train Epoch: 42 | Loss: 0.273 | Acc: 90.412% (6365/7040)\n",
      "Train Epoch: 42 | Loss: 0.274 | Acc: 90.360% (6477/7168)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.392% (6595/7296)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.396% (6711/7424)\n",
      "Train Epoch: 42 | Loss: 0.271 | Acc: 90.413% (6828/7552)\n",
      "Train Epoch: 42 | Loss: 0.270 | Acc: 90.417% (6944/7680)\n",
      "Train Epoch: 42 | Loss: 0.270 | Acc: 90.420% (7060/7808)\n",
      "Train Epoch: 42 | Loss: 0.271 | Acc: 90.398% (7174/7936)\n",
      "Train Epoch: 42 | Loss: 0.272 | Acc: 90.377% (7288/8064)\n",
      "Train Epoch: 42 | Loss: 0.273 | Acc: 90.369% (7403/8192)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.288% (7512/8320)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.270% (7626/8448)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.240% (7739/8576)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.269% (7857/8704)\n",
      "Train Epoch: 42 | Loss: 0.275 | Acc: 90.297% (7975/8832)\n",
      "Train Epoch: 42 | Loss: 0.276 | Acc: 90.279% (8089/8960)\n",
      "Train Epoch: 42 | Loss: 0.279 | Acc: 90.152% (8193/9088)\n",
      "Train Epoch: 42 | Loss: 0.277 | Acc: 90.213% (8314/9216)\n",
      "Train Epoch: 42 | Loss: 0.277 | Acc: 90.218% (8430/9344)\n",
      "Train Epoch: 42 | Loss: 0.278 | Acc: 90.150% (8539/9472)\n",
      "Train Epoch: 42 | Loss: 0.278 | Acc: 90.198% (8659/9600)\n",
      "Train Epoch: 42 | Loss: 0.278 | Acc: 90.173% (8772/9728)\n",
      "Train Epoch: 42 | Loss: 0.280 | Acc: 90.158% (8886/9856)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.114% (8997/9984)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.101% (9111/10112)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.146% (9231/10240)\n",
      "Train Epoch: 42 | Loss: 0.280 | Acc: 90.181% (9350/10368)\n",
      "Train Epoch: 42 | Loss: 0.280 | Acc: 90.158% (9463/10496)\n",
      "Train Epoch: 42 | Loss: 0.282 | Acc: 90.126% (9575/10624)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.151% (9693/10752)\n",
      "Train Epoch: 42 | Loss: 0.282 | Acc: 90.165% (9810/10880)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.198% (9929/11008)\n",
      "Train Epoch: 42 | Loss: 0.281 | Acc: 90.203% (10045/11136)\n",
      "Train Epoch: 42 | Loss: 0.282 | Acc: 90.190% (10159/11264)\n",
      "Train Epoch: 42 | Loss: 0.282 | Acc: 90.177% (10273/11392)\n",
      "Train Epoch: 42 | Loss: 0.283 | Acc: 90.165% (10387/11520)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.118% (10497/11648)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.073% (10607/11776)\n",
      "Train Epoch: 42 | Loss: 0.284 | Acc: 90.087% (10724/11904)\n",
      "Train Epoch: 42 | Loss: 0.284 | Acc: 90.085% (10839/12032)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.058% (10951/12160)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 90.023% (11062/12288)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.045% (11180/12416)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.035% (11294/12544)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.065% (11413/12672)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.062% (11528/12800)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.084% (11646/12928)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.097% (11763/13056)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.064% (11874/13184)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.069% (11990/13312)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.045% (12102/13440)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.035% (12216/13568)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.019% (12329/13696)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 90.003% (12442/13824)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.001% (12557/13952)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.028% (12676/14080)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.034% (12792/14208)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 90.018% (12905/14336)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.051% (13025/14464)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.036% (13138/14592)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.034% (13253/14720)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.059% (13372/14848)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.077% (13490/14976)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.062% (13603/15104)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.067% (13719/15232)\n",
      "Train Epoch: 42 | Loss: 0.284 | Acc: 90.085% (13837/15360)\n",
      "Train Epoch: 42 | Loss: 0.285 | Acc: 90.037% (13945/15488)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 90.023% (14058/15616)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 89.996% (14169/15744)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 89.970% (14280/15872)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 89.963% (14394/16000)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 89.943% (14506/16128)\n",
      "Train Epoch: 42 | Loss: 0.286 | Acc: 89.942% (14621/16256)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 89.935% (14735/16384)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 89.947% (14852/16512)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 89.946% (14967/16640)\n",
      "Train Epoch: 42 | Loss: 0.287 | Acc: 89.951% (15083/16768)\n",
      "Train Epoch: 42 | Loss: 0.288 | Acc: 89.921% (15193/16896)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.897% (15304/17024)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.885% (15417/17152)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.850% (15526/17280)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.867% (15644/17408)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.832% (15753/17536)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.832% (15868/17664)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.844% (15985/17792)\n",
      "Train Epoch: 42 | Loss: 0.289 | Acc: 89.844% (16100/17920)\n",
      "Train Epoch: 42 | Loss: 0.290 | Acc: 89.855% (16217/18048)\n",
      "Train Epoch: 42 | Loss: 0.290 | Acc: 89.844% (16330/18176)\n",
      "Train Epoch: 42 | Loss: 0.290 | Acc: 89.860% (16448/18304)\n",
      "Train Epoch: 42 | Loss: 0.291 | Acc: 89.827% (16557/18432)\n",
      "Train Epoch: 42 | Loss: 0.291 | Acc: 89.806% (16668/18560)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.790% (16780/18688)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.785% (16894/18816)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.791% (17010/18944)\n",
      "Train Epoch: 42 | Loss: 0.291 | Acc: 89.823% (17131/19072)\n",
      "Train Epoch: 42 | Loss: 0.291 | Acc: 89.812% (17244/19200)\n",
      "Train Epoch: 42 | Loss: 0.291 | Acc: 89.818% (17360/19328)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.813% (17474/19456)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.808% (17588/19584)\n",
      "Train Epoch: 42 | Loss: 0.292 | Acc: 89.788% (17699/19712)\n",
      "Train Epoch: 42 | Loss: 0.293 | Acc: 89.763% (17809/19840)\n",
      "Train Epoch: 42 | Loss: 0.293 | Acc: 89.759% (17923/19968)\n",
      "Train Epoch: 42 | Loss: 0.293 | Acc: 89.744% (18035/20096)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.730% (18147/20224)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.745% (18265/20352)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.751% (18381/20480)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.742% (18494/20608)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.752% (18611/20736)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.762% (18728/20864)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.734% (18837/20992)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.721% (18949/21120)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.721% (19064/21248)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.727% (19180/21376)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.709% (19291/21504)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.728% (19410/21632)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.733% (19526/21760)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.725% (19639/21888)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.717% (19752/22016)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.699% (19863/22144)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.709% (19980/22272)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.714% (20096/22400)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.742% (20217/22528)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.738% (20331/22656)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.774% (20454/22784)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.778% (20570/22912)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.766% (20682/23040)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.775% (20799/23168)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.779% (20915/23296)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.758% (21025/23424)\n",
      "Train Epoch: 42 | Loss: 0.294 | Acc: 89.721% (21131/23552)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.696% (21240/23680)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.714% (21359/23808)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.714% (21474/23936)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.707% (21587/24064)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.707% (21702/24192)\n",
      "Train Epoch: 42 | Loss: 0.295 | Acc: 89.708% (21817/24320)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.696% (21929/24448)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.709% (22047/24576)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.714% (22163/24704)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.735% (22283/24832)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.700% (22389/24960)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.692% (22502/25088)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.681% (22614/25216)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.694% (22732/25344)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.698% (22848/25472)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.699% (22963/25600)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.696% (23077/25728)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.705% (23194/25856)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.709% (23310/25984)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.710% (23425/26112)\n",
      "Train Epoch: 42 | Loss: 0.296 | Acc: 89.703% (23538/26240)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.684% (23648/26368)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.663% (23757/26496)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.675% (23875/26624)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.668% (23988/26752)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.665% (24102/26880)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.670% (24218/27008)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.678% (24335/27136)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.679% (24450/27264)\n",
      "Train Epoch: 42 | Loss: 0.297 | Acc: 89.679% (24565/27392)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.684% (24681/27520)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.670% (24792/27648)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.678% (24909/27776)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.661% (25019/27904)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.676% (25138/28032)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.677% (25253/28160)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.692% (25372/28288)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.699% (25489/28416)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.686% (25600/28544)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.694% (25717/28672)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.705% (25835/28800)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.712% (25952/28928)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.696% (26062/29056)\n",
      "Train Epoch: 42 | Loss: 0.298 | Acc: 89.679% (26172/29184)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.639% (26275/29312)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.647% (26392/29440)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.648% (26507/29568)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.652% (26623/29696)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.653% (26738/29824)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.667% (26857/29952)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.651% (26967/30080)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.639% (27078/30208)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.653% (27197/30336)\n",
      "Train Epoch: 42 | Loss: 0.299 | Acc: 89.660% (27314/30464)\n",
      "Train Epoch: 42 | Loss: 0.300 | Acc: 89.644% (27424/30592)\n",
      "Train Epoch: 42 | Loss: 0.300 | Acc: 89.635% (27536/30720)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.623% (27647/30848)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.605% (27756/30976)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.619% (27875/31104)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.616% (27989/31232)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.621% (28105/31360)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.625% (28221/31488)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.622% (28335/31616)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.614% (28447/31744)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.583% (28552/31872)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.594% (28670/32000)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.595% (28785/32128)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.596% (28900/32256)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.594% (29014/32384)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.576% (29123/32512)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.580% (29239/32640)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.590% (29357/32768)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.607% (29477/32896)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.623% (29597/33024)\n",
      "Train Epoch: 42 | Loss: 0.301 | Acc: 89.615% (29709/33152)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.615% (29824/33280)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.607% (29936/33408)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.596% (30047/33536)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.579% (30156/33664)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.586% (30273/33792)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.584% (30387/33920)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.579% (30500/34048)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.575% (30613/34176)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.578% (30729/34304)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.556% (30836/34432)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.540% (30945/34560)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.518% (31052/34688)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.511% (31164/34816)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.506% (31277/34944)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.524% (31398/35072)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.531% (31515/35200)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.524% (31627/35328)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.536% (31746/35456)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.529% (31858/35584)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.516% (31968/35712)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.531% (32088/35840)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.527% (32201/35968)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.517% (32312/36096)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.529% (32431/36224)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.541% (32550/36352)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (32668/36480)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.560% (32786/36608)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.563% (32902/36736)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.559% (33015/36864)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.557% (33129/36992)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.564% (33246/37120)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.567% (33362/37248)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.565% (33476/37376)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.574% (33594/37504)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.570% (33707/37632)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.566% (33820/37760)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.561% (33933/37888)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.544% (34041/38016)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.563% (34163/38144)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.569% (34280/38272)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.565% (34393/38400)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (34502/38528)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.570% (34624/38656)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.563% (34736/38784)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.564% (34851/38912)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.544% (34958/39040)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.537% (35070/39168)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.528% (35181/39296)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.527% (35295/39424)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.523% (35408/39552)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.534% (35527/39680)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.527% (35639/39808)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.531% (35755/39936)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.519% (35865/40064)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.523% (35981/40192)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.519% (36094/40320)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.515% (36207/40448)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.518% (36323/40576)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.522% (36439/40704)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.525% (36555/40832)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.529% (36671/40960)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.508% (36777/41088)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.514% (36894/41216)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.515% (37009/41344)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.506% (37120/41472)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.517% (37239/41600)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.520% (37355/41728)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.528% (37473/41856)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.529% (37588/41984)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.537% (37706/42112)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.541% (37822/42240)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.542% (37937/42368)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.540% (38051/42496)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.536% (38164/42624)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.535% (38278/42752)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.545% (38397/42880)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.532% (38506/43008)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.540% (38624/43136)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.527% (38733/43264)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.540% (38853/43392)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (38972/43520)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (39087/43648)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.547% (39200/43776)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (39316/43904)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.553% (39432/44032)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.570% (39554/44160)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.573% (39670/44288)\n",
      "Train Epoch: 42 | Loss: 0.302 | Acc: 89.578% (39787/44416)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.556% (39892/44544)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.555% (40006/44672)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.549% (40118/44800)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.543% (40230/44928)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.553% (40349/45056)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.558% (40466/45184)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.572% (40587/45312)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.555% (40694/45440)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.552% (40807/45568)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.548% (40920/45696)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.547% (41034/45824)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.539% (41145/45952)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.542% (41261/46080)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.534% (41372/46208)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.539% (41489/46336)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.540% (41604/46464)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.541% (41719/46592)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.536% (41831/46720)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.543% (41949/46848)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.535% (42060/46976)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.534% (42174/47104)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.530% (42287/47232)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.519% (42396/47360)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.528% (42515/47488)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.520% (42626/47616)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.527% (42744/47744)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.537% (42863/47872)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.535% (42977/48000)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.547% (43097/48128)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.560% (43218/48256)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.554% (43330/48384)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.557% (43446/48512)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.550% (43557/48640)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.540% (43667/48768)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.535% (43779/48896)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.530% (43891/49024)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.528% (44005/49152)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.539% (44125/49280)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.542% (44241/49408)\n",
      "Train Epoch: 42 | Loss: 0.303 | Acc: 89.541% (44355/49536)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.532% (44465/49664)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.512% (44570/49792)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.513% (44685/49920)\n",
      "Train Epoch: 42 | Loss: 0.304 | Acc: 89.520% (44760/50000)\n",
      "Test Epoch: 42 | Loss: 0.350 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 42 | Loss: 0.364 | Acc: 86.667% (260/300)\n",
      "Test Epoch: 42 | Loss: 0.339 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 42 | Loss: 0.318 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 42 | Loss: 0.313 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 42 | Loss: 0.318 | Acc: 89.143% (624/700)\n",
      "Test Epoch: 42 | Loss: 0.347 | Acc: 88.375% (707/800)\n",
      "Test Epoch: 42 | Loss: 0.364 | Acc: 87.667% (789/900)\n",
      "Test Epoch: 42 | Loss: 0.367 | Acc: 87.700% (877/1000)\n",
      "Test Epoch: 42 | Loss: 0.363 | Acc: 87.818% (966/1100)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 87.500% (1050/1200)\n",
      "Test Epoch: 42 | Loss: 0.361 | Acc: 87.769% (1141/1300)\n",
      "Test Epoch: 42 | Loss: 0.358 | Acc: 87.929% (1231/1400)\n",
      "Test Epoch: 42 | Loss: 0.353 | Acc: 88.133% (1322/1500)\n",
      "Test Epoch: 42 | Loss: 0.359 | Acc: 87.688% (1403/1600)\n",
      "Test Epoch: 42 | Loss: 0.354 | Acc: 87.941% (1495/1700)\n",
      "Test Epoch: 42 | Loss: 0.360 | Acc: 87.667% (1578/1800)\n",
      "Test Epoch: 42 | Loss: 0.356 | Acc: 87.737% (1667/1900)\n",
      "Test Epoch: 42 | Loss: 0.359 | Acc: 87.750% (1755/2000)\n",
      "Test Epoch: 42 | Loss: 0.359 | Acc: 87.952% (1847/2100)\n",
      "Test Epoch: 42 | Loss: 0.355 | Acc: 88.000% (1936/2200)\n",
      "Test Epoch: 42 | Loss: 0.359 | Acc: 88.043% (2025/2300)\n",
      "Test Epoch: 42 | Loss: 0.357 | Acc: 88.167% (2116/2400)\n",
      "Test Epoch: 42 | Loss: 0.364 | Acc: 88.040% (2201/2500)\n",
      "Test Epoch: 42 | Loss: 0.376 | Acc: 87.692% (2280/2600)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.741% (2369/2700)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.714% (2456/2800)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.724% (2544/2900)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 87.833% (2635/3000)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.581% (2715/3100)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.625% (2804/3200)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.667% (2893/3300)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.588% (2978/3400)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.629% (3067/3500)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.694% (3157/3600)\n",
      "Test Epoch: 42 | Loss: 0.377 | Acc: 87.568% (3240/3700)\n",
      "Test Epoch: 42 | Loss: 0.378 | Acc: 87.500% (3325/3800)\n",
      "Test Epoch: 42 | Loss: 0.375 | Acc: 87.513% (3413/3900)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.550% (3502/4000)\n",
      "Test Epoch: 42 | Loss: 0.375 | Acc: 87.537% (3589/4100)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.595% (3679/4200)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.674% (3770/4300)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.682% (3858/4400)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 87.778% (3950/4500)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.739% (4036/4600)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.745% (4124/4700)\n",
      "Test Epoch: 42 | Loss: 0.376 | Acc: 87.667% (4208/4800)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.776% (4301/4900)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.780% (4389/5000)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.863% (4481/5100)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.865% (4569/5200)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.830% (4655/5300)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.944% (4749/5400)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.945% (4837/5500)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.964% (4926/5600)\n",
      "Test Epoch: 42 | Loss: 0.375 | Acc: 87.895% (5010/5700)\n",
      "Test Epoch: 42 | Loss: 0.374 | Acc: 87.897% (5098/5800)\n",
      "Test Epoch: 42 | Loss: 0.377 | Acc: 87.780% (5179/5900)\n",
      "Test Epoch: 42 | Loss: 0.376 | Acc: 87.783% (5267/6000)\n",
      "Test Epoch: 42 | Loss: 0.376 | Acc: 87.705% (5350/6100)\n",
      "Test Epoch: 42 | Loss: 0.376 | Acc: 87.710% (5438/6200)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.810% (5532/6300)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.859% (5623/6400)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.831% (5709/6500)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.879% (5800/6600)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.985% (5895/6700)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 87.941% (5980/6800)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.971% (6070/6900)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 87.900% (6153/7000)\n",
      "Test Epoch: 42 | Loss: 0.372 | Acc: 87.873% (6239/7100)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.889% (6328/7200)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 87.973% (6422/7300)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.946% (6508/7400)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.947% (6596/7500)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.961% (6685/7600)\n",
      "Test Epoch: 42 | Loss: 0.369 | Acc: 87.987% (6775/7700)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 87.987% (6863/7800)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 88.013% (6953/7900)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 88.000% (7040/8000)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.074% (7134/8100)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.024% (7218/8200)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.000% (7304/8300)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 87.988% (7391/8400)\n",
      "Test Epoch: 42 | Loss: 0.367 | Acc: 87.988% (7479/8500)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.965% (7565/8600)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 88.023% (7658/8700)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 88.000% (7744/8800)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 88.022% (7834/8900)\n",
      "Test Epoch: 42 | Loss: 0.373 | Acc: 87.967% (7917/9000)\n",
      "Test Epoch: 42 | Loss: 0.371 | Acc: 87.956% (8004/9100)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 88.000% (8096/9200)\n",
      "Test Epoch: 42 | Loss: 0.370 | Acc: 88.011% (8185/9300)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.053% (8277/9400)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.053% (8365/9500)\n",
      "Test Epoch: 42 | Loss: 0.368 | Acc: 88.021% (8450/9600)\n",
      "Test Epoch: 42 | Loss: 0.366 | Acc: 88.103% (8546/9700)\n",
      "Test Epoch: 42 | Loss: 0.366 | Acc: 88.092% (8633/9800)\n",
      "Test Epoch: 42 | Loss: 0.367 | Acc: 88.071% (8719/9900)\n",
      "Test Epoch: 42 | Loss: 0.367 | Acc: 88.090% (8809/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Train Epoch: 43 | Loss: 0.428 | Acc: 84.375% (108/128)\n",
      "Train Epoch: 43 | Loss: 0.442 | Acc: 85.547% (219/256)\n",
      "Train Epoch: 43 | Loss: 0.355 | Acc: 88.542% (340/384)\n",
      "Train Epoch: 43 | Loss: 0.356 | Acc: 88.281% (452/512)\n",
      "Train Epoch: 43 | Loss: 0.341 | Acc: 88.594% (567/640)\n",
      "Train Epoch: 43 | Loss: 0.328 | Acc: 88.932% (683/768)\n",
      "Train Epoch: 43 | Loss: 0.336 | Acc: 88.616% (794/896)\n",
      "Train Epoch: 43 | Loss: 0.322 | Acc: 89.258% (914/1024)\n",
      "Train Epoch: 43 | Loss: 0.321 | Acc: 89.323% (1029/1152)\n",
      "Train Epoch: 43 | Loss: 0.317 | Acc: 89.531% (1146/1280)\n",
      "Train Epoch: 43 | Loss: 0.322 | Acc: 89.418% (1259/1408)\n",
      "Train Epoch: 43 | Loss: 0.316 | Acc: 89.518% (1375/1536)\n",
      "Train Epoch: 43 | Loss: 0.310 | Acc: 89.964% (1497/1664)\n",
      "Train Epoch: 43 | Loss: 0.307 | Acc: 90.123% (1615/1792)\n",
      "Train Epoch: 43 | Loss: 0.310 | Acc: 90.000% (1728/1920)\n",
      "Train Epoch: 43 | Loss: 0.306 | Acc: 90.088% (1845/2048)\n",
      "Train Epoch: 43 | Loss: 0.303 | Acc: 90.119% (1961/2176)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 90.191% (2078/2304)\n",
      "Train Epoch: 43 | Loss: 0.304 | Acc: 90.132% (2192/2432)\n",
      "Train Epoch: 43 | Loss: 0.305 | Acc: 90.117% (2307/2560)\n",
      "Train Epoch: 43 | Loss: 0.309 | Acc: 90.067% (2421/2688)\n",
      "Train Epoch: 43 | Loss: 0.308 | Acc: 90.057% (2536/2816)\n",
      "Train Epoch: 43 | Loss: 0.309 | Acc: 90.014% (2650/2944)\n",
      "Train Epoch: 43 | Loss: 0.307 | Acc: 90.072% (2767/3072)\n",
      "Train Epoch: 43 | Loss: 0.307 | Acc: 89.969% (2879/3200)\n",
      "Train Epoch: 43 | Loss: 0.304 | Acc: 90.114% (2999/3328)\n",
      "Train Epoch: 43 | Loss: 0.305 | Acc: 90.017% (3111/3456)\n",
      "Train Epoch: 43 | Loss: 0.303 | Acc: 90.095% (3229/3584)\n",
      "Train Epoch: 43 | Loss: 0.303 | Acc: 90.086% (3344/3712)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 90.104% (3460/3840)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 90.071% (3574/3968)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.990% (3686/4096)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.962% (3800/4224)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.936% (3914/4352)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 90.089% (4036/4480)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.169% (4155/4608)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 90.224% (4273/4736)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 90.173% (4386/4864)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.204% (4503/4992)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.273% (4622/5120)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.149% (4731/5248)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 90.030% (4840/5376)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 90.062% (4957/5504)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 90.075% (5073/5632)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.087% (5189/5760)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.031% (5301/5888)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 90.043% (5417/6016)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 90.039% (5532/6144)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.067% (5649/6272)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 90.047% (5763/6400)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.104% (5882/6528)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 90.129% (5999/6656)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 90.153% (6116/6784)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.119% (6229/6912)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 90.128% (6345/7040)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.067% (6456/7168)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 90.104% (6574/7296)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.965% (6679/7424)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.976% (6795/7552)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.987% (6911/7680)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.972% (7025/7808)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.020% (7144/7936)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 90.005% (7258/8064)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.929% (7367/8192)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.904% (7480/8320)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.856% (7591/8448)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.844% (7705/8576)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.809% (7817/8704)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.832% (7934/8832)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.799% (8046/8960)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.767% (8158/9088)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.757% (8272/9216)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.737% (8385/9344)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.728% (8499/9472)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.760% (8617/9600)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.782% (8734/9728)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.783% (8849/9856)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.744% (8960/9984)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.755% (9076/10112)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.805% (9196/10240)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.805% (9311/10368)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.787% (9424/10496)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.750% (9535/10624)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.714% (9646/10752)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.706% (9760/10880)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.744% (9879/11008)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.772% (9997/11136)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.764% (10111/11264)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.747% (10224/11392)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.688% (10332/11520)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.689% (10447/11648)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.623% (10554/11776)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.642% (10671/11904)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.702% (10793/12032)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.720% (10910/12160)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.738% (11027/12288)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.747% (11143/12416)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.756% (11259/12544)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.789% (11378/12672)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.789% (11493/12800)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.790% (11608/12928)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.805% (11725/13056)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.813% (11841/13184)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.844% (11960/13312)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.829% (12073/13440)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.844% (12190/13568)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.851% (12306/13696)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.894% (12427/13824)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.894% (12542/13952)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.929% (12662/14080)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.872% (12769/14208)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.886% (12886/14336)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.892% (13002/14464)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.899% (13118/14592)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.925% (13237/14720)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.931% (13353/14848)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.904% (13464/14976)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.903% (13579/15104)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.923% (13697/15232)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.909% (13810/15360)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.947% (13931/15488)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.908% (14040/15616)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.926% (14158/15744)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.919% (14272/15872)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.906% (14385/16000)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.931% (14504/16128)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.954% (14623/16256)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.966% (14740/16384)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.983% (14858/16512)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.952% (14968/16640)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.963% (15085/16768)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.980% (15203/16896)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 90.002% (15322/17024)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.972% (15432/17152)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.948% (15543/17280)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.976% (15663/17408)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.998% (15782/17536)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.997% (15897/17664)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.967% (16007/17792)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.927% (16115/17920)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.943% (16233/18048)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.948% (16349/18176)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.953% (16465/18304)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.979% (16585/18432)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.973% (16699/18560)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 89.988% (16817/18688)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 90.003% (16935/18816)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 89.981% (17046/18944)\n",
      "Train Epoch: 43 | Loss: 0.291 | Acc: 89.996% (17164/19072)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 89.969% (17274/19200)\n",
      "Train Epoch: 43 | Loss: 0.292 | Acc: 89.983% (17392/19328)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.957% (17502/19456)\n",
      "Train Epoch: 43 | Loss: 0.293 | Acc: 89.946% (17615/19584)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.920% (17725/19712)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.934% (17843/19840)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.924% (17956/19968)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.894% (18065/20096)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.898% (18181/20224)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.883% (18293/20352)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.883% (18408/20480)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.887% (18524/20608)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.892% (18640/20736)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.882% (18753/20864)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.882% (18868/20992)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.886% (18984/21120)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.896% (19101/21248)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.905% (19218/21376)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.900% (19332/21504)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.881% (19443/21632)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.853% (19552/21760)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.844% (19665/21888)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.857% (19783/22016)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.857% (19898/22144)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.857% (20013/22272)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.853% (20127/22400)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.853% (20242/22528)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.861% (20359/22656)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.848% (20471/22784)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.861% (20589/22912)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.835% (20698/23040)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.818% (20809/23168)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.818% (20924/23296)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.831% (21042/23424)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.840% (21159/23552)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.852% (21277/23680)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.831% (21387/23808)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.835% (21503/23936)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.844% (21620/24064)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.864% (21740/24192)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.873% (21857/24320)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.864% (21970/24448)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.860% (22084/24576)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.848% (22196/24704)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.848% (22311/24832)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.876% (22433/24960)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.876% (22548/25088)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.891% (22667/25216)\n",
      "Train Epoch: 43 | Loss: 0.294 | Acc: 89.891% (22782/25344)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.836% (22883/25472)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.855% (23003/25600)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.836% (23113/25728)\n",
      "Train Epoch: 43 | Loss: 0.295 | Acc: 89.821% (23224/25856)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.801% (23334/25984)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.779% (23443/26112)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.775% (23557/26240)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.757% (23667/26368)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.742% (23778/26496)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.746% (23894/26624)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.750% (24010/26752)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.743% (24123/26880)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.762% (24243/27008)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.781% (24363/27136)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.792% (24481/27264)\n",
      "Train Epoch: 43 | Loss: 0.296 | Acc: 89.785% (24594/27392)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.767% (24704/27520)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.753% (24815/27648)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.765% (24933/27776)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.768% (25049/27904)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.762% (25162/28032)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.748% (25273/28160)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.748% (25388/28288)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.756% (25505/28416)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.728% (25612/28544)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.743% (25731/28672)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.747% (25847/28800)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.723% (25955/28928)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.727% (26071/29056)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.738% (26189/29184)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.741% (26305/29312)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.735% (26418/29440)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.739% (26534/29568)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.746% (26651/29696)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.757% (26769/29824)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.774% (26889/29952)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.791% (27009/30080)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.801% (27127/30208)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.814% (27246/30336)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.824% (27364/30464)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.808% (27474/30592)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.814% (27591/30720)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.818% (27707/30848)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.808% (27819/30976)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.815% (27936/31104)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.793% (28044/31232)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.809% (28164/31360)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.796% (28275/31488)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.790% (28388/31616)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.806% (28508/31744)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.800% (28621/31872)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.794% (28734/32000)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.760% (28838/32128)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.766% (28955/32256)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.760% (29068/32384)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.758% (29182/32512)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.758% (29297/32640)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.758% (29412/32768)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.774% (29532/32896)\n",
      "Train Epoch: 43 | Loss: 0.297 | Acc: 89.786% (29651/33024)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.768% (29760/33152)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.763% (29873/33280)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.760% (29987/33408)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.751% (30099/33536)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.755% (30215/33664)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.749% (30328/33792)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.752% (30444/33920)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.753% (30559/34048)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.738% (30669/34176)\n",
      "Train Epoch: 43 | Loss: 0.298 | Acc: 89.748% (30787/34304)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.739% (30899/34432)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.722% (31008/34560)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.720% (31122/34688)\n",
      "Train Epoch: 43 | Loss: 0.299 | Acc: 89.709% (31233/34816)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.706% (31347/34944)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.690% (31456/35072)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.690% (31571/35200)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.699% (31689/35328)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.686% (31799/35456)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.695% (31917/35584)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.701% (32034/35712)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.688% (32144/35840)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.677% (32255/35968)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.680% (32371/36096)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.673% (32483/36224)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.679% (32600/36352)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.671% (32712/36480)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.674% (32828/36608)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.675% (32943/36736)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.667% (33055/36864)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.663% (33168/36992)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.658% (33281/37120)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.661% (33397/37248)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.664% (33513/37376)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.668% (33629/37504)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.666% (33743/37632)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.669% (33859/37760)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.670% (33974/37888)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.657% (34084/38016)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.642% (34193/38144)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.637% (34306/38272)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.622% (34415/38400)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.618% (34528/38528)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.606% (34638/38656)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.617% (34757/38784)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (34869/38912)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.608% (34983/39040)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.609% (35098/39168)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (35213/39296)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.626% (35334/39424)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.619% (35446/39552)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.612% (35558/39680)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (35672/39808)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.613% (35788/39936)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.607% (35900/40064)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.605% (36014/40192)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.601% (36127/40320)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.606% (36244/40448)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.612% (36361/40576)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (36475/40704)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.601% (36586/40832)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.614% (36706/40960)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.600% (36815/41088)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.604% (36931/41216)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.609% (37048/41344)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.598% (37158/41472)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.606% (37276/41600)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.585% (37382/41728)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.598% (37502/41856)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.591% (37614/41984)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.599% (37732/42112)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.612% (37852/42240)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.596% (37960/42368)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.594% (38074/42496)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.607% (38194/42624)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (38310/42752)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.606% (38423/42880)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.614% (38541/43008)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.626% (38661/43136)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.631% (38778/43264)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.639% (38896/43392)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.651% (39016/43520)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.654% (39132/43648)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.652% (39246/43776)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.652% (39361/43904)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.644% (39472/44032)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.660% (39594/44160)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.661% (39709/44288)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.659% (39823/44416)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.648% (39933/44544)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.645% (40046/44672)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.658% (40167/44800)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.655% (40280/44928)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.651% (40393/45056)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.658% (40511/45184)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.663% (40628/45312)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.661% (40742/45440)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.657% (40855/45568)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.658% (40970/45696)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.660% (41086/45824)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.648% (41195/45952)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.646% (41309/46080)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.649% (41425/46208)\n",
      "Train Epoch: 43 | Loss: 0.300 | Acc: 89.641% (41536/46336)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.635% (41648/46464)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.627% (41759/46592)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.619% (41870/46720)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.622% (41986/46848)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.605% (42093/46976)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.593% (42202/47104)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.596% (42318/47232)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.595% (42432/47360)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.599% (42549/47488)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.596% (42662/47616)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.601% (42779/47744)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.585% (42886/47872)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.598% (43007/48000)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.594% (43120/48128)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.605% (43240/48256)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.616% (43360/48384)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.603% (43468/48512)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.595% (43579/48640)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.598% (43695/48768)\n",
      "Train Epoch: 43 | Loss: 0.302 | Acc: 89.596% (43809/48896)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.599% (43925/49024)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.602% (44041/49152)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.614% (44162/49280)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.611% (44275/49408)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.608% (44388/49536)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.614% (44506/49664)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.613% (44620/49792)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.621% (44739/49920)\n",
      "Train Epoch: 43 | Loss: 0.301 | Acc: 89.610% (44805/50000)\n",
      "Test Epoch: 43 | Loss: 0.267 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 43 | Loss: 0.320 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 43 | Loss: 0.323 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 43 | Loss: 0.326 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 43 | Loss: 0.325 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 88.833% (533/600)\n",
      "Test Epoch: 43 | Loss: 0.302 | Acc: 89.143% (624/700)\n",
      "Test Epoch: 43 | Loss: 0.322 | Acc: 88.125% (705/800)\n",
      "Test Epoch: 43 | Loss: 0.352 | Acc: 87.556% (788/900)\n",
      "Test Epoch: 43 | Loss: 0.351 | Acc: 87.700% (877/1000)\n",
      "Test Epoch: 43 | Loss: 0.349 | Acc: 87.727% (965/1100)\n",
      "Test Epoch: 43 | Loss: 0.350 | Acc: 88.000% (1056/1200)\n",
      "Test Epoch: 43 | Loss: 0.348 | Acc: 87.923% (1143/1300)\n",
      "Test Epoch: 43 | Loss: 0.349 | Acc: 88.000% (1232/1400)\n",
      "Test Epoch: 43 | Loss: 0.346 | Acc: 88.067% (1321/1500)\n",
      "Test Epoch: 43 | Loss: 0.349 | Acc: 87.875% (1406/1600)\n",
      "Test Epoch: 43 | Loss: 0.346 | Acc: 87.941% (1495/1700)\n",
      "Test Epoch: 43 | Loss: 0.358 | Acc: 87.722% (1579/1800)\n",
      "Test Epoch: 43 | Loss: 0.352 | Acc: 87.684% (1666/1900)\n",
      "Test Epoch: 43 | Loss: 0.354 | Acc: 87.900% (1758/2000)\n",
      "Test Epoch: 43 | Loss: 0.359 | Acc: 87.810% (1844/2100)\n",
      "Test Epoch: 43 | Loss: 0.357 | Acc: 87.909% (1934/2200)\n",
      "Test Epoch: 43 | Loss: 0.359 | Acc: 87.696% (2017/2300)\n",
      "Test Epoch: 43 | Loss: 0.355 | Acc: 87.875% (2109/2400)\n",
      "Test Epoch: 43 | Loss: 0.365 | Acc: 87.800% (2195/2500)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.615% (2278/2600)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.667% (2367/2700)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.750% (2457/2800)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.690% (2543/2900)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.600% (2628/3000)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.548% (2714/3100)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.719% (2807/3200)\n",
      "Test Epoch: 43 | Loss: 0.369 | Acc: 87.788% (2897/3300)\n",
      "Test Epoch: 43 | Loss: 0.370 | Acc: 87.676% (2981/3400)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.686% (3069/3500)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 87.722% (3158/3600)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 87.730% (3246/3700)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 87.684% (3332/3800)\n",
      "Test Epoch: 43 | Loss: 0.370 | Acc: 87.821% (3425/3900)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.850% (3514/4000)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.780% (3599/4100)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.857% (3690/4200)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.907% (3780/4300)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 88.000% (3872/4400)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 88.022% (3961/4500)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.913% (4044/4600)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 87.872% (4130/4700)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.750% (4212/4800)\n",
      "Test Epoch: 43 | Loss: 0.371 | Acc: 87.878% (4306/4900)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.760% (4388/5000)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.765% (4476/5100)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.731% (4562/5200)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.679% (4647/5300)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.704% (4736/5400)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.673% (4822/5500)\n",
      "Test Epoch: 43 | Loss: 0.379 | Acc: 87.696% (4911/5600)\n",
      "Test Epoch: 43 | Loss: 0.379 | Acc: 87.719% (5000/5700)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.776% (5091/5800)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.695% (5174/5900)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.717% (5263/6000)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.656% (5347/6100)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.694% (5437/6200)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.778% (5530/6300)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.922% (5627/6400)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.862% (5711/6500)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.818% (5796/6600)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.881% (5888/6700)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.824% (5972/6800)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.899% (6065/6900)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.800% (6146/7000)\n",
      "Test Epoch: 43 | Loss: 0.378 | Acc: 87.803% (6234/7100)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.806% (6322/7200)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.849% (6413/7300)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.892% (6504/7400)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.867% (6590/7500)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.868% (6678/7600)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.857% (6765/7700)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.846% (6852/7800)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.835% (6939/7900)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.850% (7028/8000)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.901% (7120/8100)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.890% (7207/8200)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.819% (7289/8300)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.798% (7375/8400)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.776% (7461/8500)\n",
      "Test Epoch: 43 | Loss: 0.377 | Acc: 87.733% (7545/8600)\n",
      "Test Epoch: 43 | Loss: 0.378 | Acc: 87.736% (7633/8700)\n",
      "Test Epoch: 43 | Loss: 0.378 | Acc: 87.727% (7720/8800)\n",
      "Test Epoch: 43 | Loss: 0.379 | Acc: 87.730% (7808/8900)\n",
      "Test Epoch: 43 | Loss: 0.379 | Acc: 87.711% (7894/9000)\n",
      "Test Epoch: 43 | Loss: 0.378 | Acc: 87.725% (7983/9100)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.804% (8078/9200)\n",
      "Test Epoch: 43 | Loss: 0.376 | Acc: 87.806% (8166/9300)\n",
      "Test Epoch: 43 | Loss: 0.375 | Acc: 87.819% (8255/9400)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.863% (8347/9500)\n",
      "Test Epoch: 43 | Loss: 0.374 | Acc: 87.844% (8433/9600)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.918% (8528/9700)\n",
      "Test Epoch: 43 | Loss: 0.372 | Acc: 87.918% (8616/9800)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.889% (8701/9900)\n",
      "Test Epoch: 43 | Loss: 0.373 | Acc: 87.860% (8786/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Train Epoch: 44 | Loss: 0.257 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 44 | Loss: 0.305 | Acc: 90.234% (231/256)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.104% (346/384)\n",
      "Train Epoch: 44 | Loss: 0.270 | Acc: 90.039% (461/512)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 89.688% (574/640)\n",
      "Train Epoch: 44 | Loss: 0.282 | Acc: 89.844% (690/768)\n",
      "Train Epoch: 44 | Loss: 0.274 | Acc: 90.179% (808/896)\n",
      "Train Epoch: 44 | Loss: 0.271 | Acc: 90.332% (925/1024)\n",
      "Train Epoch: 44 | Loss: 0.273 | Acc: 90.191% (1039/1152)\n",
      "Train Epoch: 44 | Loss: 0.270 | Acc: 90.156% (1154/1280)\n",
      "Train Epoch: 44 | Loss: 0.274 | Acc: 90.057% (1268/1408)\n",
      "Train Epoch: 44 | Loss: 0.280 | Acc: 89.909% (1381/1536)\n",
      "Train Epoch: 44 | Loss: 0.277 | Acc: 89.964% (1497/1664)\n",
      "Train Epoch: 44 | Loss: 0.273 | Acc: 90.179% (1616/1792)\n",
      "Train Epoch: 44 | Loss: 0.276 | Acc: 90.156% (1731/1920)\n",
      "Train Epoch: 44 | Loss: 0.277 | Acc: 90.381% (1851/2048)\n",
      "Train Epoch: 44 | Loss: 0.276 | Acc: 90.395% (1967/2176)\n",
      "Train Epoch: 44 | Loss: 0.275 | Acc: 90.538% (2086/2304)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.173% (2193/2432)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.039% (2305/2560)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 89.844% (2415/2688)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 89.879% (2531/2816)\n",
      "Train Epoch: 44 | Loss: 0.281 | Acc: 89.946% (2648/2944)\n",
      "Train Epoch: 44 | Loss: 0.279 | Acc: 90.104% (2768/3072)\n",
      "Train Epoch: 44 | Loss: 0.286 | Acc: 89.812% (2874/3200)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 89.904% (2992/3328)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 89.902% (3107/3456)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 89.927% (3223/3584)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 89.925% (3338/3712)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 89.870% (3451/3840)\n",
      "Train Epoch: 44 | Loss: 0.285 | Acc: 89.995% (3571/3968)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.088% (3690/4096)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.152% (3808/4224)\n",
      "Train Epoch: 44 | Loss: 0.281 | Acc: 90.188% (3925/4352)\n",
      "Train Epoch: 44 | Loss: 0.280 | Acc: 90.246% (4043/4480)\n",
      "Train Epoch: 44 | Loss: 0.280 | Acc: 90.299% (4161/4608)\n",
      "Train Epoch: 44 | Loss: 0.279 | Acc: 90.329% (4278/4736)\n",
      "Train Epoch: 44 | Loss: 0.279 | Acc: 90.358% (4395/4864)\n",
      "Train Epoch: 44 | Loss: 0.279 | Acc: 90.345% (4510/4992)\n",
      "Train Epoch: 44 | Loss: 0.281 | Acc: 90.273% (4622/5120)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.206% (4734/5248)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.272% (4853/5376)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.243% (4967/5504)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.270% (5084/5632)\n",
      "Train Epoch: 44 | Loss: 0.282 | Acc: 90.312% (5202/5760)\n",
      "Train Epoch: 44 | Loss: 0.283 | Acc: 90.268% (5315/5888)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.226% (5428/6016)\n",
      "Train Epoch: 44 | Loss: 0.285 | Acc: 90.202% (5542/6144)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.226% (5659/6272)\n",
      "Train Epoch: 44 | Loss: 0.285 | Acc: 90.250% (5776/6400)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.273% (5893/6528)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.340% (6013/6656)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.330% (6128/6784)\n",
      "Train Epoch: 44 | Loss: 0.284 | Acc: 90.307% (6242/6912)\n",
      "Train Epoch: 44 | Loss: 0.285 | Acc: 90.298% (6357/7040)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.276% (6471/7168)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.241% (6584/7296)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.288% (6703/7424)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.347% (6823/7552)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.299% (6935/7680)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.305% (7051/7808)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.234% (7161/7936)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.216% (7275/8064)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.137% (7384/8192)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.168% (7502/8320)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.199% (7620/8448)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.182% (7734/8576)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.154% (7847/8704)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.229% (7969/8832)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.156% (8078/8960)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.119% (8190/9088)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.126% (8306/9216)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.090% (8418/9344)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.065% (8531/9472)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.094% (8649/9600)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.090% (8764/9728)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.118% (8882/9856)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.124% (8998/9984)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.150% (9116/10112)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.146% (9231/10240)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.152% (9347/10368)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.130% (9460/10496)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.126% (9575/10624)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.067% (9684/10752)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.018% (9794/10880)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.016% (9909/11008)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.041% (10027/11136)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.039% (10142/11264)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.019% (10255/11392)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.052% (10374/11520)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.110% (10496/11648)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.141% (10615/11776)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.163% (10733/11904)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.151% (10847/12032)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.189% (10967/12160)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.226% (11087/12288)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.238% (11204/12416)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.171% (11311/12544)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.167% (11426/12672)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.180% (11543/12800)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.130% (11652/12928)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.104% (11764/13056)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.124% (11882/13184)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.152% (12001/13312)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.186% (12121/13440)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.220% (12241/13568)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.260% (12362/13696)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.256% (12477/13824)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.252% (12592/13952)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.263% (12709/14080)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.280% (12827/14208)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.290% (12944/14336)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.307% (13062/14464)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.303% (13177/14592)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.299% (13292/14720)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.275% (13404/14848)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.284% (13521/14976)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.274% (13635/15104)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.270% (13750/15232)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.260% (13864/15360)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.270% (13981/15488)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.241% (14092/15616)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.257% (14210/15744)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.234% (14322/15872)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.275% (14444/16000)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.259% (14557/16128)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.274% (14675/16256)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.247% (14786/16384)\n",
      "Train Epoch: 44 | Loss: 0.287 | Acc: 90.250% (14902/16512)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.204% (15010/16640)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.225% (15129/16768)\n",
      "Train Epoch: 44 | Loss: 0.288 | Acc: 90.211% (15242/16896)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.173% (15351/17024)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.176% (15467/17152)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.168% (15581/17280)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.160% (15695/17408)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.157% (15810/17536)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.161% (15926/17664)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.187% (16046/17792)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.179% (16160/17920)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.160% (16272/18048)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.168% (16389/18176)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.172% (16505/18304)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.186% (16623/18432)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.178% (16737/18560)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.202% (16857/18688)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.179% (16968/18816)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.208% (17089/18944)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.195% (17202/19072)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.182% (17315/19200)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.211% (17436/19328)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.204% (17550/19456)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.217% (17668/19584)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.184% (17777/19712)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.181% (17892/19840)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.154% (18002/19968)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.147% (18116/20096)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.145% (18231/20224)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.134% (18344/20352)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.103% (18453/20480)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.101% (18568/20608)\n",
      "Train Epoch: 44 | Loss: 0.289 | Acc: 90.123% (18688/20736)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.098% (18798/20864)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.077% (18909/20992)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.057% (19020/21120)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.051% (19134/21248)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.031% (19245/21376)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.034% (19361/21504)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.043% (19478/21632)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.037% (19592/21760)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.013% (19702/21888)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.016% (19818/22016)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.011% (19932/22144)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.005% (20046/22272)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.013% (20163/22400)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.030% (20282/22528)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.011% (20393/22656)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.024% (20511/22784)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.027% (20627/22912)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.030% (20743/23040)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.008% (20853/23168)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.011% (20969/23296)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.036% (21090/23424)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.048% (21208/23552)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.063% (21327/23680)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.071% (21444/23808)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.057% (21556/23936)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.039% (21667/24064)\n",
      "Train Epoch: 44 | Loss: 0.290 | Acc: 90.055% (21786/24192)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.037% (21897/24320)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.036% (22012/24448)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.043% (22129/24576)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.050% (22246/24704)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.045% (22360/24832)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.060% (22479/24960)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.067% (22596/25088)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.050% (22707/25216)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.057% (22824/25344)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.060% (22940/25472)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.055% (23054/25600)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.050% (23168/25728)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.045% (23282/25856)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.055% (23400/25984)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.051% (23514/26112)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.046% (23628/26240)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.056% (23746/26368)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.074% (23866/26496)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.054% (23976/26624)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.023% (24083/26752)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.030% (24200/26880)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.040% (24318/27008)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.028% (24430/27136)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.023% (24544/27264)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.026% (24660/27392)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.025% (24775/27520)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.035% (24893/27648)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.045% (25011/27776)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.048% (25127/27904)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.047% (25242/28032)\n",
      "Train Epoch: 44 | Loss: 0.291 | Acc: 90.032% (25353/28160)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.021% (25465/28288)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.020% (25580/28416)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.022% (25696/28544)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 90.011% (25808/28672)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 90.017% (25925/28800)\n",
      "Train Epoch: 44 | Loss: 0.292 | Acc: 90.024% (26042/28928)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 90.009% (26153/29056)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 89.998% (26265/29184)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 89.990% (26378/29312)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 89.993% (26494/29440)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 89.999% (26611/29568)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.982% (26721/29696)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.985% (26837/29824)\n",
      "Train Epoch: 44 | Loss: 0.293 | Acc: 89.987% (26953/29952)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.983% (27067/30080)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.970% (27178/30208)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.962% (27291/30336)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.942% (27400/30464)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.952% (27518/30592)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.941% (27630/30720)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.935% (27743/30848)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.928% (27856/30976)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.921% (27969/31104)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.927% (28086/31232)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.923% (28200/31360)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.923% (28315/31488)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.923% (28430/31616)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.945% (28552/31744)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.941% (28666/31872)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.947% (28783/32000)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.934% (28894/32128)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.927% (29007/32256)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.927% (29122/32384)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.933% (29239/32512)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.939% (29356/32640)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.954% (29476/32768)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.953% (29591/32896)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.953% (29706/33024)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.958% (29823/33152)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.961% (29939/33280)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.969% (30057/33408)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.972% (30173/33536)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.966% (30286/33664)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.947% (30395/33792)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.953% (30512/33920)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.952% (30627/34048)\n",
      "Train Epoch: 44 | Loss: 0.294 | Acc: 89.961% (30745/34176)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.946% (30855/34304)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.948% (30971/34432)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.957% (31089/34560)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.950% (31202/34688)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.936% (31312/34816)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.927% (31424/34944)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.918% (31536/35072)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.915% (31650/35200)\n",
      "Train Epoch: 44 | Loss: 0.295 | Acc: 89.909% (31763/35328)\n",
      "Train Epoch: 44 | Loss: 0.296 | Acc: 89.889% (31871/35456)\n",
      "Train Epoch: 44 | Loss: 0.296 | Acc: 89.889% (31986/35584)\n",
      "Train Epoch: 44 | Loss: 0.296 | Acc: 89.877% (32097/35712)\n",
      "Train Epoch: 44 | Loss: 0.296 | Acc: 89.869% (32209/35840)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.869% (32324/35968)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.860% (32436/36096)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.855% (32549/36224)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.858% (32665/36352)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.855% (32779/36480)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.871% (32900/36608)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.857% (33010/36736)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.852% (33123/36864)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.841% (33234/36992)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.817% (33340/37120)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.809% (33452/37248)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.801% (33564/37376)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.798% (33678/37504)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.796% (33792/37632)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.788% (33904/37760)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.804% (34025/37888)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.804% (34140/38016)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.820% (34261/38144)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.815% (34374/38272)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.823% (34492/38400)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.820% (34606/38528)\n",
      "Train Epoch: 44 | Loss: 0.297 | Acc: 89.810% (34717/38656)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.800% (34828/38784)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.782% (34936/38912)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.759% (35042/39040)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.770% (35161/39168)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.775% (35278/39296)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.775% (35393/39424)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.768% (35505/39552)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.781% (35625/39680)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.783% (35741/39808)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.771% (35851/39936)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.751% (35958/40064)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.752% (36073/40192)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.762% (36192/40320)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.762% (36307/40448)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.767% (36424/40576)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.765% (36538/40704)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.763% (36652/40832)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.771% (36770/40960)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.783% (36890/41088)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.766% (36998/41216)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.778% (37118/41344)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.779% (37233/41472)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.786% (37351/41600)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.801% (37472/41728)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.803% (37588/41856)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.808% (37705/41984)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.806% (37819/42112)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.792% (37928/42240)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.792% (38043/42368)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.808% (38165/42496)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.802% (38277/42624)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.799% (38391/42752)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.785% (38500/42880)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.800% (38621/43008)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.790% (38732/43136)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.788% (38846/43264)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.784% (38959/43392)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.798% (39080/43520)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.800% (39196/43648)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.803% (39312/43776)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.800% (39426/43904)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.807% (39544/44032)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.803% (39657/44160)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.781% (39762/44288)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.785% (39879/44416)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.779% (39991/44544)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.768% (40101/44672)\n",
      "Train Epoch: 44 | Loss: 0.298 | Acc: 89.770% (40217/44800)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.757% (40326/44928)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.757% (40441/45056)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.760% (40557/45184)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.758% (40671/45312)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.740% (40778/45440)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.738% (40892/45568)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.730% (41003/45696)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.732% (41119/45824)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.731% (41233/45952)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.724% (41345/46080)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.729% (41462/46208)\n",
      "Train Epoch: 44 | Loss: 0.299 | Acc: 89.723% (41574/46336)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.719% (41687/46464)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.700% (41793/46592)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.698% (41907/46720)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.688% (42017/46848)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.684% (42130/46976)\n",
      "Train Epoch: 44 | Loss: 0.300 | Acc: 89.680% (42243/47104)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.674% (42355/47232)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.662% (42464/47360)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.654% (42575/47488)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.640% (42683/47616)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.632% (42794/47744)\n",
      "Train Epoch: 44 | Loss: 0.301 | Acc: 89.643% (42914/47872)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.635% (43025/48000)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.632% (43138/48128)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.641% (43257/48256)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.635% (43369/48384)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.615% (43474/48512)\n",
      "Train Epoch: 44 | Loss: 0.302 | Acc: 89.605% (43584/48640)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.598% (43695/48768)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.598% (43810/48896)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.601% (43926/49024)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.596% (44038/49152)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.594% (44152/49280)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.597% (44268/49408)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.604% (44386/49536)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.610% (44504/49664)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.599% (44613/49792)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.599% (44728/49920)\n",
      "Train Epoch: 44 | Loss: 0.303 | Acc: 89.590% (44795/50000)\n",
      "Test Epoch: 44 | Loss: 0.398 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 44 | Loss: 0.439 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 44 | Loss: 0.387 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 44 | Loss: 0.362 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 44 | Loss: 0.333 | Acc: 90.000% (540/600)\n",
      "Test Epoch: 44 | Loss: 0.336 | Acc: 89.429% (626/700)\n",
      "Test Epoch: 44 | Loss: 0.364 | Acc: 88.625% (709/800)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 88.667% (798/900)\n",
      "Test Epoch: 44 | Loss: 0.368 | Acc: 88.600% (886/1000)\n",
      "Test Epoch: 44 | Loss: 0.380 | Acc: 88.182% (970/1100)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.750% (1053/1200)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.538% (1138/1300)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.500% (1225/1400)\n",
      "Test Epoch: 44 | Loss: 0.370 | Acc: 87.467% (1312/1500)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.312% (1397/1600)\n",
      "Test Epoch: 44 | Loss: 0.368 | Acc: 87.412% (1486/1700)\n",
      "Test Epoch: 44 | Loss: 0.371 | Acc: 87.278% (1571/1800)\n",
      "Test Epoch: 44 | Loss: 0.369 | Acc: 87.105% (1655/1900)\n",
      "Test Epoch: 44 | Loss: 0.370 | Acc: 87.050% (1741/2000)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.048% (1828/2100)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.000% (1914/2200)\n",
      "Test Epoch: 44 | Loss: 0.376 | Acc: 86.957% (2000/2300)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 87.083% (2090/2400)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.040% (2176/2500)\n",
      "Test Epoch: 44 | Loss: 0.386 | Acc: 87.038% (2263/2600)\n",
      "Test Epoch: 44 | Loss: 0.382 | Acc: 87.111% (2352/2700)\n",
      "Test Epoch: 44 | Loss: 0.381 | Acc: 87.179% (2441/2800)\n",
      "Test Epoch: 44 | Loss: 0.381 | Acc: 87.241% (2530/2900)\n",
      "Test Epoch: 44 | Loss: 0.382 | Acc: 87.233% (2617/3000)\n",
      "Test Epoch: 44 | Loss: 0.384 | Acc: 87.226% (2704/3100)\n",
      "Test Epoch: 44 | Loss: 0.381 | Acc: 87.188% (2790/3200)\n",
      "Test Epoch: 44 | Loss: 0.383 | Acc: 87.121% (2875/3300)\n",
      "Test Epoch: 44 | Loss: 0.386 | Acc: 86.882% (2954/3400)\n",
      "Test Epoch: 44 | Loss: 0.388 | Acc: 86.800% (3038/3500)\n",
      "Test Epoch: 44 | Loss: 0.386 | Acc: 86.861% (3127/3600)\n",
      "Test Epoch: 44 | Loss: 0.385 | Acc: 86.919% (3216/3700)\n",
      "Test Epoch: 44 | Loss: 0.385 | Acc: 86.947% (3304/3800)\n",
      "Test Epoch: 44 | Loss: 0.382 | Acc: 87.026% (3394/3900)\n",
      "Test Epoch: 44 | Loss: 0.380 | Acc: 87.075% (3483/4000)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.146% (3573/4100)\n",
      "Test Epoch: 44 | Loss: 0.380 | Acc: 87.167% (3661/4200)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.349% (3756/4300)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.432% (3847/4400)\n",
      "Test Epoch: 44 | Loss: 0.374 | Acc: 87.489% (3937/4500)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.435% (4022/4600)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.426% (4109/4700)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.396% (4195/4800)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.469% (4286/4900)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.360% (4368/5000)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.412% (4458/5100)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.423% (4546/5200)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.434% (4634/5300)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.463% (4723/5400)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.473% (4811/5500)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.500% (4900/5600)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.544% (4990/5700)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.483% (5074/5800)\n",
      "Test Epoch: 44 | Loss: 0.383 | Acc: 87.322% (5152/5900)\n",
      "Test Epoch: 44 | Loss: 0.383 | Acc: 87.317% (5239/6000)\n",
      "Test Epoch: 44 | Loss: 0.385 | Acc: 87.295% (5325/6100)\n",
      "Test Epoch: 44 | Loss: 0.385 | Acc: 87.323% (5414/6200)\n",
      "Test Epoch: 44 | Loss: 0.383 | Acc: 87.381% (5505/6300)\n",
      "Test Epoch: 44 | Loss: 0.380 | Acc: 87.516% (5601/6400)\n",
      "Test Epoch: 44 | Loss: 0.380 | Acc: 87.554% (5691/6500)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.591% (5781/6600)\n",
      "Test Epoch: 44 | Loss: 0.376 | Acc: 87.672% (5874/6700)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.662% (5961/6800)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.696% (6051/6900)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.614% (6133/7000)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.577% (6218/7100)\n",
      "Test Epoch: 44 | Loss: 0.379 | Acc: 87.542% (6303/7200)\n",
      "Test Epoch: 44 | Loss: 0.378 | Acc: 87.575% (6393/7300)\n",
      "Test Epoch: 44 | Loss: 0.376 | Acc: 87.581% (6481/7400)\n",
      "Test Epoch: 44 | Loss: 0.376 | Acc: 87.573% (6568/7500)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.553% (6654/7600)\n",
      "Test Epoch: 44 | Loss: 0.377 | Acc: 87.506% (6738/7700)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.538% (6828/7800)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.570% (6918/7900)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.575% (7006/8000)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.630% (7098/8100)\n",
      "Test Epoch: 44 | Loss: 0.374 | Acc: 87.573% (7181/8200)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.590% (7270/8300)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 87.631% (7361/8400)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.541% (7441/8500)\n",
      "Test Epoch: 44 | Loss: 0.374 | Acc: 87.523% (7527/8600)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.575% (7619/8700)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.511% (7701/8800)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.573% (7794/8900)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.522% (7877/9000)\n",
      "Test Epoch: 44 | Loss: 0.375 | Acc: 87.516% (7964/9100)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.565% (8056/9200)\n",
      "Test Epoch: 44 | Loss: 0.374 | Acc: 87.570% (8144/9300)\n",
      "Test Epoch: 44 | Loss: 0.373 | Acc: 87.596% (8234/9400)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 87.600% (8322/9500)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 87.573% (8407/9600)\n",
      "Test Epoch: 44 | Loss: 0.370 | Acc: 87.608% (8498/9700)\n",
      "Test Epoch: 44 | Loss: 0.371 | Acc: 87.582% (8583/9800)\n",
      "Test Epoch: 44 | Loss: 0.372 | Acc: 87.566% (8669/9900)\n",
      "Test Epoch: 44 | Loss: 0.371 | Acc: 87.560% (8756/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Epoch: 45 | Loss: 0.222 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 45 | Loss: 0.221 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 45 | Loss: 0.262 | Acc: 89.323% (343/384)\n",
      "Train Epoch: 45 | Loss: 0.283 | Acc: 89.453% (458/512)\n",
      "Train Epoch: 45 | Loss: 0.276 | Acc: 90.000% (576/640)\n",
      "Train Epoch: 45 | Loss: 0.278 | Acc: 90.104% (692/768)\n",
      "Train Epoch: 45 | Loss: 0.286 | Acc: 89.844% (805/896)\n",
      "Train Epoch: 45 | Loss: 0.303 | Acc: 89.453% (916/1024)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.757% (1034/1152)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.766% (1149/1280)\n",
      "Train Epoch: 45 | Loss: 0.285 | Acc: 89.986% (1267/1408)\n",
      "Train Epoch: 45 | Loss: 0.284 | Acc: 90.039% (1383/1536)\n",
      "Train Epoch: 45 | Loss: 0.284 | Acc: 89.964% (1497/1664)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.290% (1618/1792)\n",
      "Train Epoch: 45 | Loss: 0.282 | Acc: 90.156% (1731/1920)\n",
      "Train Epoch: 45 | Loss: 0.283 | Acc: 90.186% (1847/2048)\n",
      "Train Epoch: 45 | Loss: 0.283 | Acc: 90.303% (1965/2176)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.278% (2080/2304)\n",
      "Train Epoch: 45 | Loss: 0.279 | Acc: 90.337% (2197/2432)\n",
      "Train Epoch: 45 | Loss: 0.279 | Acc: 90.312% (2312/2560)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.253% (2426/2688)\n",
      "Train Epoch: 45 | Loss: 0.275 | Acc: 90.412% (2546/2816)\n",
      "Train Epoch: 45 | Loss: 0.273 | Acc: 90.523% (2665/2944)\n",
      "Train Epoch: 45 | Loss: 0.276 | Acc: 90.495% (2780/3072)\n",
      "Train Epoch: 45 | Loss: 0.273 | Acc: 90.688% (2902/3200)\n",
      "Train Epoch: 45 | Loss: 0.275 | Acc: 90.715% (3019/3328)\n",
      "Train Epoch: 45 | Loss: 0.279 | Acc: 90.538% (3129/3456)\n",
      "Train Epoch: 45 | Loss: 0.278 | Acc: 90.597% (3247/3584)\n",
      "Train Epoch: 45 | Loss: 0.281 | Acc: 90.409% (3356/3712)\n",
      "Train Epoch: 45 | Loss: 0.281 | Acc: 90.365% (3470/3840)\n",
      "Train Epoch: 45 | Loss: 0.284 | Acc: 90.323% (3584/3968)\n",
      "Train Epoch: 45 | Loss: 0.283 | Acc: 90.332% (3700/4096)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.388% (3818/4224)\n",
      "Train Epoch: 45 | Loss: 0.281 | Acc: 90.372% (3933/4352)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.446% (4052/4480)\n",
      "Train Epoch: 45 | Loss: 0.279 | Acc: 90.495% (4170/4608)\n",
      "Train Epoch: 45 | Loss: 0.280 | Acc: 90.456% (4284/4736)\n",
      "Train Epoch: 45 | Loss: 0.281 | Acc: 90.399% (4397/4864)\n",
      "Train Epoch: 45 | Loss: 0.282 | Acc: 90.425% (4514/4992)\n",
      "Train Epoch: 45 | Loss: 0.284 | Acc: 90.410% (4629/5120)\n",
      "Train Epoch: 45 | Loss: 0.282 | Acc: 90.454% (4747/5248)\n",
      "Train Epoch: 45 | Loss: 0.284 | Acc: 90.420% (4861/5376)\n",
      "Train Epoch: 45 | Loss: 0.282 | Acc: 90.443% (4978/5504)\n",
      "Train Epoch: 45 | Loss: 0.285 | Acc: 90.323% (5087/5632)\n",
      "Train Epoch: 45 | Loss: 0.287 | Acc: 90.278% (5200/5760)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.268% (5315/5888)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.143% (5423/6016)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.169% (5540/6144)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.083% (5650/6272)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.109% (5767/6400)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.165% (5886/6528)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.189% (6003/6656)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.198% (6119/6784)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.205% (6235/6912)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.142% (6346/7040)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.151% (6462/7168)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.118% (6575/7296)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.140% (6692/7424)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.201% (6812/7552)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.130% (6922/7680)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.113% (7036/7808)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.108% (7151/7936)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.141% (7269/8064)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.112% (7382/8192)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.120% (7498/8320)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.080% (7610/8448)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.077% (7725/8576)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.085% (7841/8704)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.093% (7957/8832)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.078% (8071/8960)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.097% (8188/9088)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.072% (8301/9216)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.983% (8408/9344)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.875% (8513/9472)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.885% (8629/9600)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.916% (8747/9728)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.905% (8861/9856)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.964% (8982/9984)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.923% (9093/10112)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.902% (9206/10240)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.959% (9327/10368)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.949% (9441/10496)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.919% (9553/10624)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.937% (9670/10752)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.972% (9789/10880)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.044% (9912/11008)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.041% (10027/11136)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.066% (10145/11264)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.125% (10267/11392)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.087% (10378/11520)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.033% (10487/11648)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.048% (10604/11776)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.020% (10716/11904)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.993% (10828/12032)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.984% (10942/12160)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.015% (11061/12288)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.013% (11176/12416)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.011% (11291/12544)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.049% (11411/12672)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.031% (11524/12800)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.014% (11637/12928)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.936% (11742/13056)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.950% (11859/13184)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.964% (11976/13312)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.993% (12095/13440)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.962% (12206/13568)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.997% (12326/13696)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 90.003% (12442/13824)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 90.001% (12557/13952)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.028% (12676/14080)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.055% (12795/14208)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.039% (12908/14336)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.037% (13023/14464)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.049% (13140/14592)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.095% (13262/14720)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.066% (13373/14848)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.064% (13488/14976)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.016% (13596/15104)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.041% (13715/15232)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.046% (13831/15360)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.018% (13942/15488)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.042% (14061/15616)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.022% (14173/15744)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.976% (14281/15872)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.981% (14397/16000)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.980% (14512/16128)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.979% (14627/16256)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 90.015% (14748/16384)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.056% (14870/16512)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.060% (14986/16640)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.035% (15097/16768)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.033% (15212/16896)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.043% (15329/17024)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.042% (15444/17152)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.058% (15562/17280)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.033% (15673/17408)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.009% (15784/17536)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.997% (15897/17664)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.007% (16014/17792)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.972% (16123/17920)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.966% (16237/18048)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.981% (16355/18176)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.002% (16474/18304)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.969% (16583/18432)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.968% (16698/18560)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.961% (16812/18688)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.955% (16926/18816)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.960% (17042/18944)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.964% (17158/19072)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.948% (17270/19200)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.968% (17389/19328)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.983% (17507/19456)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.956% (17617/19584)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.960% (17733/19712)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.934% (17843/19840)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.909% (17953/19968)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.908% (18068/20096)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.938% (18189/20224)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.937% (18304/20352)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.946% (18421/20480)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.965% (18540/20608)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.974% (18657/20736)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.992% (18776/20864)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.006% (18894/20992)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.009% (19010/21120)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.018% (19127/21248)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.017% (19242/21376)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.025% (19359/21504)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.024% (19474/21632)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.995% (19583/21760)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.013% (19702/21888)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.989% (19812/22016)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.975% (19924/22144)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.952% (20034/22272)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.969% (20153/22400)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.990% (20273/22528)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.025% (20396/22656)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.032% (20513/22784)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 90.014% (20624/22912)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.022% (20741/23040)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.016% (20855/23168)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 90.011% (20969/23296)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.997% (21081/23424)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.967% (21189/23552)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.962% (21303/23680)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.970% (21420/23808)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.961% (21533/23936)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.977% (21652/24064)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.988% (21770/24192)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.967% (21880/24320)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.946% (21990/24448)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.933% (22102/24576)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.937% (22218/24704)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.961% (22339/24832)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.968% (22456/24960)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.963% (22570/25088)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.955% (22683/25216)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.946% (22796/25344)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.942% (22910/25472)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.949% (23027/25600)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.956% (23144/25728)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.956% (23259/25856)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.944% (23371/25984)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.939% (23485/26112)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.939% (23600/26240)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.927% (23712/26368)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.912% (23823/26496)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.915% (23939/26624)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.911% (24053/26752)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.914% (24169/26880)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.922% (24286/27008)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.910% (24398/27136)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.913% (24514/27264)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.928% (24633/27392)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.913% (24744/27520)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.923% (24862/27648)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.930% (24979/27776)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.930% (25094/27904)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.926% (25208/28032)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.929% (25324/28160)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.950% (25445/28288)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.960% (25563/28416)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.987% (25686/28544)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.973% (25797/28672)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.972% (25912/28800)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.972% (26027/28928)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.957% (26138/29056)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.953% (26252/29184)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.984% (26376/29312)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.980% (26490/29440)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.976% (26604/29568)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.972% (26718/29696)\n",
      "Train Epoch: 45 | Loss: 0.288 | Acc: 89.975% (26834/29824)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.971% (26948/29952)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.967% (27062/30080)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.970% (27178/30208)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.953% (27288/30336)\n",
      "Train Epoch: 45 | Loss: 0.289 | Acc: 89.965% (27407/30464)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.955% (27519/30592)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.961% (27636/30720)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.967% (27753/30848)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.957% (27865/30976)\n",
      "Train Epoch: 45 | Loss: 0.290 | Acc: 89.956% (27980/31104)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.937% (28089/31232)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.933% (28203/31360)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.929% (28317/31488)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.929% (28432/31616)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.945% (28552/31744)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.935% (28664/31872)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.938% (28780/32000)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.915% (28888/32128)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.915% (29003/32256)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.909% (29116/32384)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.908% (29231/32512)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.917% (29349/32640)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.914% (29463/32768)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.914% (29578/32896)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.913% (29693/33024)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.922% (29811/33152)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.922% (29926/33280)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.913% (30038/33408)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.909% (30152/33536)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.909% (30267/33664)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.909% (30382/33792)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.912% (30498/33920)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.902% (30610/34048)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.908% (30727/34176)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.931% (30850/34304)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.913% (30959/34432)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.910% (31073/34560)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.910% (31188/34688)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.918% (31306/34816)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.935% (31427/34944)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.932% (31541/35072)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.918% (31651/35200)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.920% (31767/35328)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.923% (31883/35456)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.922% (31998/35584)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.942% (32120/35712)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.927% (32230/35840)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.913% (32340/35968)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.919% (32457/36096)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.913% (32570/36224)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.913% (32685/36352)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.918% (32802/36480)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.915% (32916/36608)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.917% (33032/36736)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.922% (33149/36864)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.917% (33262/36992)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.914% (33376/37120)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.922% (33494/37248)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.932% (33613/37376)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.921% (33724/37504)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.915% (33837/37632)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.915% (33952/37760)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.915% (34067/37888)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.896% (34175/38016)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.894% (34289/38144)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.872% (34396/38272)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.872% (34511/38400)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.875% (34627/38528)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.883% (34745/38656)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.885% (34861/38784)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.872% (34971/38912)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.877% (35088/39040)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.869% (35200/39168)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.882% (35320/39296)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.887% (35437/39424)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.892% (35554/39552)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.894% (35670/39680)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.881% (35780/39808)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.886% (35897/39936)\n",
      "Train Epoch: 45 | Loss: 0.294 | Acc: 89.889% (36013/40064)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.894% (36130/40192)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.896% (36246/40320)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.888% (36358/40448)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.896% (36476/40576)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.890% (36589/40704)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.883% (36701/40832)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.890% (36819/40960)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.902% (36939/41088)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.914% (37059/41216)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.928% (37180/41344)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.923% (37293/41472)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.909% (37402/41600)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.906% (37516/41728)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.918% (37636/41856)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.910% (37748/41984)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.910% (37863/42112)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.903% (37975/42240)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.900% (38089/42368)\n",
      "Train Epoch: 45 | Loss: 0.293 | Acc: 89.914% (38210/42496)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.916% (38326/42624)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.919% (38442/42752)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.925% (38560/42880)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.932% (38678/43008)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.946% (38799/43136)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.945% (38914/43264)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.959% (39035/43392)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.956% (39149/43520)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.961% (39266/43648)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.974% (39387/43776)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.976% (39503/43904)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.966% (39614/44032)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.971% (39731/44160)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.970% (39846/44288)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.983% (39967/44416)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.974% (40078/44544)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.965% (40189/44672)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.958% (40301/44800)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.944% (40410/44928)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.944% (40525/45056)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.930% (40634/45184)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.932% (40750/45312)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.947% (40872/45440)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.949% (40988/45568)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.936% (41097/45696)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.935% (41212/45824)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.933% (41326/45952)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.939% (41444/46080)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.948% (41563/46208)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.954% (41681/46336)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.949% (41794/46464)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.947% (41908/46592)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.953% (42026/46720)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.953% (42141/46848)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.950% (42255/46976)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.946% (42368/47104)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.947% (42484/47232)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.954% (42602/47360)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.966% (42723/47488)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.970% (42840/47616)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.955% (42948/47744)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.952% (43062/47872)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.958% (43180/48000)\n",
      "Train Epoch: 45 | Loss: 0.292 | Acc: 89.964% (43298/48128)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.968% (43415/48256)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.976% (43534/48384)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.980% (43651/48512)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.994% (43773/48640)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.998% (43890/48768)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.993% (44003/48896)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.989% (44116/49024)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.984% (44229/49152)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.982% (44343/49280)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.991% (44463/49408)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.993% (44579/49536)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.991% (44693/49664)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.994% (44810/49792)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.996% (44926/49920)\n",
      "Train Epoch: 45 | Loss: 0.291 | Acc: 89.990% (44995/50000)\n",
      "Test Epoch: 45 | Loss: 0.283 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 45 | Loss: 0.338 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 45 | Loss: 0.325 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 45 | Loss: 0.307 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 45 | Loss: 0.303 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 45 | Loss: 0.289 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 45 | Loss: 0.302 | Acc: 90.000% (630/700)\n",
      "Test Epoch: 45 | Loss: 0.328 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 45 | Loss: 0.348 | Acc: 88.667% (798/900)\n",
      "Test Epoch: 45 | Loss: 0.352 | Acc: 88.400% (884/1000)\n",
      "Test Epoch: 45 | Loss: 0.356 | Acc: 88.091% (969/1100)\n",
      "Test Epoch: 45 | Loss: 0.369 | Acc: 87.833% (1054/1200)\n",
      "Test Epoch: 45 | Loss: 0.353 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 45 | Loss: 0.354 | Acc: 88.143% (1234/1400)\n",
      "Test Epoch: 45 | Loss: 0.350 | Acc: 88.400% (1326/1500)\n",
      "Test Epoch: 45 | Loss: 0.355 | Acc: 88.312% (1413/1600)\n",
      "Test Epoch: 45 | Loss: 0.359 | Acc: 88.412% (1503/1700)\n",
      "Test Epoch: 45 | Loss: 0.371 | Acc: 88.000% (1584/1800)\n",
      "Test Epoch: 45 | Loss: 0.364 | Acc: 88.211% (1676/1900)\n",
      "Test Epoch: 45 | Loss: 0.365 | Acc: 88.050% (1761/2000)\n",
      "Test Epoch: 45 | Loss: 0.372 | Acc: 87.952% (1847/2100)\n",
      "Test Epoch: 45 | Loss: 0.369 | Acc: 87.818% (1932/2200)\n",
      "Test Epoch: 45 | Loss: 0.376 | Acc: 87.696% (2017/2300)\n",
      "Test Epoch: 45 | Loss: 0.376 | Acc: 87.667% (2104/2400)\n",
      "Test Epoch: 45 | Loss: 0.385 | Acc: 87.480% (2187/2500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.231% (2268/2600)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 87.370% (2359/2700)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.286% (2444/2800)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.138% (2527/2900)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 87.200% (2616/3000)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.097% (2700/3100)\n",
      "Test Epoch: 45 | Loss: 0.399 | Acc: 87.156% (2789/3200)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.121% (2875/3300)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.147% (2963/3400)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 87.143% (3050/3500)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.222% (3140/3600)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 87.162% (3225/3700)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 87.053% (3308/3800)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 87.103% (3397/3900)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 87.125% (3485/4000)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.049% (3569/4100)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.190% (3662/4200)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.256% (3752/4300)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 87.364% (3844/4400)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 87.422% (3934/4500)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.304% (4016/4600)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.234% (4100/4700)\n",
      "Test Epoch: 45 | Loss: 0.397 | Acc: 87.146% (4183/4800)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 87.163% (4271/4900)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.000% (4350/5000)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.059% (4440/5100)\n",
      "Test Epoch: 45 | Loss: 0.402 | Acc: 87.058% (4527/5200)\n",
      "Test Epoch: 45 | Loss: 0.403 | Acc: 87.000% (4611/5300)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 87.093% (4703/5400)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.000% (4785/5500)\n",
      "Test Epoch: 45 | Loss: 0.399 | Acc: 87.125% (4879/5600)\n",
      "Test Epoch: 45 | Loss: 0.399 | Acc: 87.158% (4968/5700)\n",
      "Test Epoch: 45 | Loss: 0.396 | Acc: 87.259% (5061/5800)\n",
      "Test Epoch: 45 | Loss: 0.398 | Acc: 87.153% (5142/5900)\n",
      "Test Epoch: 45 | Loss: 0.398 | Acc: 87.183% (5231/6000)\n",
      "Test Epoch: 45 | Loss: 0.400 | Acc: 87.148% (5316/6100)\n",
      "Test Epoch: 45 | Loss: 0.401 | Acc: 87.113% (5401/6200)\n",
      "Test Epoch: 45 | Loss: 0.399 | Acc: 87.143% (5490/6300)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 87.281% (5586/6400)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.262% (5672/6500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.273% (5760/6600)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 87.313% (5850/6700)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.265% (5934/6800)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 87.304% (6024/6900)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.257% (6108/7000)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 87.324% (6200/7100)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.250% (6282/7200)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.288% (6372/7300)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 87.311% (6461/7400)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.307% (6548/7500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.276% (6633/7600)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.195% (6714/7700)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.192% (6801/7800)\n",
      "Test Epoch: 45 | Loss: 0.394 | Acc: 87.165% (6886/7900)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.213% (6977/8000)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 87.309% (7072/8100)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 87.280% (7157/8200)\n",
      "Test Epoch: 45 | Loss: 0.388 | Acc: 87.301% (7246/8300)\n",
      "Test Epoch: 45 | Loss: 0.388 | Acc: 87.298% (7333/8400)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 87.247% (7416/8500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.209% (7500/8600)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.218% (7588/8700)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 87.193% (7673/8800)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 87.169% (7758/8900)\n",
      "Test Epoch: 45 | Loss: 0.395 | Acc: 87.167% (7845/9000)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 87.154% (7931/9100)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 87.217% (8024/9200)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 87.226% (8112/9300)\n",
      "Test Epoch: 45 | Loss: 0.393 | Acc: 87.245% (8201/9400)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.284% (8292/9500)\n",
      "Test Epoch: 45 | Loss: 0.392 | Acc: 87.260% (8377/9600)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 87.309% (8469/9700)\n",
      "Test Epoch: 45 | Loss: 0.389 | Acc: 87.316% (8557/9800)\n",
      "Test Epoch: 45 | Loss: 0.391 | Acc: 87.273% (8640/9900)\n",
      "Test Epoch: 45 | Loss: 0.390 | Acc: 87.290% (8729/10000)\n",
      "\n",
      "Epoch: 46\n",
      "Train Epoch: 46 | Loss: 0.363 | Acc: 87.500% (112/128)\n",
      "Train Epoch: 46 | Loss: 0.318 | Acc: 89.453% (229/256)\n",
      "Train Epoch: 46 | Loss: 0.306 | Acc: 89.583% (344/384)\n",
      "Train Epoch: 46 | Loss: 0.285 | Acc: 89.844% (460/512)\n",
      "Train Epoch: 46 | Loss: 0.272 | Acc: 90.625% (580/640)\n",
      "Train Epoch: 46 | Loss: 0.256 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 46 | Loss: 0.253 | Acc: 91.295% (818/896)\n",
      "Train Epoch: 46 | Loss: 0.263 | Acc: 91.309% (935/1024)\n",
      "Train Epoch: 46 | Loss: 0.258 | Acc: 91.319% (1052/1152)\n",
      "Train Epoch: 46 | Loss: 0.267 | Acc: 91.016% (1165/1280)\n",
      "Train Epoch: 46 | Loss: 0.273 | Acc: 90.767% (1278/1408)\n",
      "Train Epoch: 46 | Loss: 0.263 | Acc: 91.276% (1402/1536)\n",
      "Train Epoch: 46 | Loss: 0.266 | Acc: 91.046% (1515/1664)\n",
      "Train Epoch: 46 | Loss: 0.271 | Acc: 90.848% (1628/1792)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.625% (1740/1920)\n",
      "Train Epoch: 46 | Loss: 0.277 | Acc: 90.674% (1857/2048)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.717% (1974/2176)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.755% (2091/2304)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.789% (2208/2432)\n",
      "Train Epoch: 46 | Loss: 0.280 | Acc: 90.781% (2324/2560)\n",
      "Train Epoch: 46 | Loss: 0.278 | Acc: 90.848% (2442/2688)\n",
      "Train Epoch: 46 | Loss: 0.282 | Acc: 90.696% (2554/2816)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.727% (2671/2944)\n",
      "Train Epoch: 46 | Loss: 0.277 | Acc: 90.918% (2793/3072)\n",
      "Train Epoch: 46 | Loss: 0.275 | Acc: 90.969% (2911/3200)\n",
      "Train Epoch: 46 | Loss: 0.272 | Acc: 91.106% (3032/3328)\n",
      "Train Epoch: 46 | Loss: 0.275 | Acc: 91.059% (3147/3456)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 90.960% (3260/3584)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 90.948% (3376/3712)\n",
      "Train Epoch: 46 | Loss: 0.278 | Acc: 90.911% (3491/3840)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.776% (3602/3968)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 90.869% (3722/4096)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 90.909% (3840/4224)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.855% (3954/4352)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 90.960% (4075/4480)\n",
      "Train Epoch: 46 | Loss: 0.280 | Acc: 90.951% (4191/4608)\n",
      "Train Epoch: 46 | Loss: 0.278 | Acc: 91.026% (4311/4736)\n",
      "Train Epoch: 46 | Loss: 0.279 | Acc: 91.016% (4427/4864)\n",
      "Train Epoch: 46 | Loss: 0.280 | Acc: 90.966% (4541/4992)\n",
      "Train Epoch: 46 | Loss: 0.280 | Acc: 90.938% (4656/5120)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.835% (4767/5248)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.737% (4878/5376)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.643% (4989/5504)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.625% (5104/5632)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.625% (5220/5760)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.557% (5332/5888)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.525% (5446/6016)\n",
      "Train Epoch: 46 | Loss: 0.282 | Acc: 90.609% (5567/6144)\n",
      "Train Epoch: 46 | Loss: 0.282 | Acc: 90.593% (5682/6272)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.562% (5796/6400)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.564% (5912/6528)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.580% (6029/6656)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.507% (6140/6784)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.466% (6253/6912)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.426% (6366/7040)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.374% (6478/7168)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.392% (6595/7296)\n",
      "Train Epoch: 46 | Loss: 0.282 | Acc: 90.423% (6713/7424)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.493% (6834/7552)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.456% (6947/7680)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.523% (7068/7808)\n",
      "Train Epoch: 46 | Loss: 0.281 | Acc: 90.512% (7183/7936)\n",
      "Train Epoch: 46 | Loss: 0.282 | Acc: 90.476% (7296/8064)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.393% (7405/8192)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.385% (7520/8320)\n",
      "Train Epoch: 46 | Loss: 0.283 | Acc: 90.412% (7638/8448)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.357% (7749/8576)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.361% (7865/8704)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.353% (7980/8832)\n",
      "Train Epoch: 46 | Loss: 0.285 | Acc: 90.346% (8095/8960)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.328% (8209/9088)\n",
      "Train Epoch: 46 | Loss: 0.285 | Acc: 90.365% (8328/9216)\n",
      "Train Epoch: 46 | Loss: 0.285 | Acc: 90.315% (8439/9344)\n",
      "Train Epoch: 46 | Loss: 0.285 | Acc: 90.319% (8555/9472)\n",
      "Train Epoch: 46 | Loss: 0.284 | Acc: 90.323% (8671/9600)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.234% (8778/9728)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.199% (8890/9856)\n",
      "Train Epoch: 46 | Loss: 0.286 | Acc: 90.214% (9007/9984)\n",
      "Train Epoch: 46 | Loss: 0.287 | Acc: 90.150% (9116/10112)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.146% (9231/10240)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.104% (9342/10368)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.091% (9456/10496)\n",
      "Train Epoch: 46 | Loss: 0.287 | Acc: 90.107% (9573/10624)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.067% (9684/10752)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.037% (9796/10880)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.071% (9915/11008)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.059% (10029/11136)\n",
      "Train Epoch: 46 | Loss: 0.288 | Acc: 90.066% (10145/11264)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.054% (10259/11392)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.061% (10375/11520)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.076% (10492/11648)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.005% (10599/11776)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.029% (10717/11904)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.060% (10836/12032)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.033% (10948/12160)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.055% (11066/12288)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.061% (11182/12416)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.083% (11300/12544)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.096% (11417/12672)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.094% (11532/12800)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.091% (11647/12928)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.051% (11757/13056)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.995% (11865/13184)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.964% (11976/13312)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.940% (12088/13440)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.954% (12205/13568)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.946% (12319/13696)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.959% (12436/13824)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.987% (12555/13952)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.036% (12677/14080)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.020% (12790/14208)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.032% (12907/14336)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.982% (13015/14464)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 90.001% (13133/14592)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.020% (13251/14720)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.026% (13367/14848)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.044% (13485/14976)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.996% (13593/15104)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.955% (13702/15232)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.961% (13818/15360)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.979% (13936/15488)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.004% (14055/15616)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.022% (14173/15744)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.058% (14294/15872)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.075% (14412/16000)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.048% (14523/16128)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.059% (14640/16256)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.076% (14758/16384)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.122% (14881/16512)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.096% (14992/16640)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.106% (15109/16768)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.122% (15227/16896)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.126% (15343/17024)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.100% (15454/17152)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.145% (15577/17280)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.154% (15694/17408)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.129% (15805/17536)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.121% (15919/17664)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.108% (16032/17792)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.089% (16144/17920)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.088% (16259/18048)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.102% (16377/18176)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.090% (16490/18304)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.110% (16609/18432)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.108% (16724/18560)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.085% (16835/18688)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.088% (16951/18816)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.081% (17065/18944)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.059% (17176/19072)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.062% (17292/19200)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.102% (17415/19328)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.101% (17530/19456)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.104% (17646/19584)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.118% (17764/19712)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.076% (17871/19840)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.079% (17987/19968)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.083% (18103/20096)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.086% (18219/20224)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.094% (18336/20352)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.122% (18457/20480)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.111% (18570/20608)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.114% (18686/20736)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.146% (18808/20864)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.144% (18923/20992)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.142% (19038/21120)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.150% (19155/21248)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.171% (19275/21376)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.160% (19388/21504)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.186% (19509/21632)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.170% (19621/21760)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.173% (19737/21888)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.171% (19852/22016)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.169% (19967/22144)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.149% (20078/22272)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.174% (20199/22400)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.194% (20319/22528)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.162% (20427/22656)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.151% (20540/22784)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.162% (20658/22912)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.135% (20767/23040)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.133% (20882/23168)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.131% (20997/23296)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.138% (21114/23424)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.141% (21230/23552)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.156% (21349/23680)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.159% (21465/23808)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.157% (21580/23936)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.176% (21700/24064)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.166% (21813/24192)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.173% (21930/24320)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.151% (22040/24448)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.149% (22155/24576)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.155% (22272/24704)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.150% (22386/24832)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.140% (22499/24960)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.163% (22620/25088)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.173% (22738/25216)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.183% (22856/25344)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.158% (22965/25472)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.172% (23084/25600)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.166% (23198/25728)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.165% (23313/25856)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.167% (23429/25984)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.192% (23551/26112)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.198% (23668/26240)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.200% (23784/26368)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.199% (23899/26496)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.219% (24020/26624)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.191% (24128/26752)\n",
      "Train Epoch: 46 | Loss: 0.289 | Acc: 90.190% (24243/26880)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.173% (24354/27008)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.161% (24466/27136)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.159% (24581/27264)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.150% (24694/27392)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.167% (24814/27520)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.162% (24928/27648)\n",
      "Train Epoch: 46 | Loss: 0.290 | Acc: 90.161% (25043/27776)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.152% (25156/27904)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.151% (25271/28032)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.146% (25385/28160)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.148% (25501/28288)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.143% (25615/28416)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.124% (25725/28544)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.109% (25836/28672)\n",
      "Train Epoch: 46 | Loss: 0.291 | Acc: 90.094% (25947/28800)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.075% (26057/28928)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.043% (26163/29056)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.015% (26270/29184)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.004% (26382/29312)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.993% (26494/29440)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 90.003% (26612/29568)\n",
      "Train Epoch: 46 | Loss: 0.292 | Acc: 90.005% (26728/29696)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.985% (26837/29824)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.961% (26945/29952)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.973% (27064/30080)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.970% (27178/30208)\n",
      "Train Epoch: 46 | Loss: 0.293 | Acc: 89.979% (27296/30336)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.965% (27407/30464)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.958% (27520/30592)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.932% (27627/30720)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.928% (27741/30848)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.899% (27847/30976)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.905% (27964/31104)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.895% (28076/31232)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.901% (28193/31360)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.904% (28309/31488)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.901% (28423/31616)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.891% (28535/31744)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.881% (28647/31872)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.878% (28761/32000)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.887% (28879/32128)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.893% (28996/32256)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.890% (29110/32384)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.890% (29225/32512)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.899% (29343/32640)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.914% (29463/32768)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.908% (29576/32896)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.907% (29691/33024)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.898% (29803/33152)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.901% (29919/33280)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.892% (30031/33408)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.894% (30147/33536)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.891% (30261/33664)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.897% (30378/33792)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.906% (30496/33920)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.914% (30614/34048)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.929% (30734/34176)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.937% (30852/34304)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.940% (30968/34432)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.945% (31085/34560)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.924% (31193/34688)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.913% (31304/34816)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.918% (31421/34944)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.926% (31539/35072)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.926% (31654/35200)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.929% (31770/35328)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.934% (31887/35456)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.945% (32006/35584)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.939% (32119/35712)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.939% (32234/35840)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.944% (32351/35968)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.941% (32465/36096)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.929% (32576/36224)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.935% (32693/36352)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.921% (32803/36480)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.920% (32918/36608)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.906% (33028/36736)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.903% (33142/36864)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.901% (33256/36992)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.887% (33366/37120)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.884% (33480/37248)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.887% (33596/37376)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.897% (33715/37504)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.892% (33828/37632)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.902% (33947/37760)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.897% (34060/37888)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.904% (34178/38016)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.901% (34292/38144)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.904% (34408/38272)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.904% (34523/38400)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.903% (34638/38528)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.895% (34750/38656)\n",
      "Train Epoch: 46 | Loss: 0.294 | Acc: 89.898% (34866/38784)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.890% (34978/38912)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.880% (35089/39040)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.882% (35205/39168)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.887% (35322/39296)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.869% (35430/39424)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.856% (35540/39552)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.854% (35654/39680)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.856% (35770/39808)\n",
      "Train Epoch: 46 | Loss: 0.295 | Acc: 89.854% (35884/39936)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.846% (35996/40064)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.839% (36108/40192)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.834% (36221/40320)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.839% (36338/40448)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.836% (36452/40576)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.817% (36559/40704)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.797% (36666/40832)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.810% (36786/40960)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.802% (36898/41088)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.795% (37010/41216)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.791% (37123/41344)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.783% (37235/41472)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.781% (37349/41600)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.777% (37462/41728)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.791% (37583/41856)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.791% (37698/41984)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.794% (37814/42112)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.811% (37936/42240)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.801% (38047/42368)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.811% (38166/42496)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.809% (38280/42624)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.799% (38391/42752)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.802% (38507/42880)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.800% (38621/43008)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.797% (38735/43136)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.788% (38846/43264)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.795% (38964/43392)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.795% (39079/43520)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.798% (39195/43648)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.798% (39310/43776)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.796% (39424/43904)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.792% (39537/44032)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.787% (39650/44160)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.785% (39764/44288)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.767% (39871/44416)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.776% (39990/44544)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.770% (40102/44672)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.781% (40222/44800)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.768% (40331/44928)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.775% (40449/45056)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.777% (40565/45184)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.786% (40684/45312)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.791% (40801/45440)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.795% (40918/45568)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.800% (41035/45696)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.791% (41146/45824)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.798% (41264/45952)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.803% (41381/46080)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.796% (41493/46208)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.809% (41614/46336)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.811% (41730/46464)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.809% (41844/46592)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.818% (41963/46720)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.822% (42080/46848)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.825% (42196/46976)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.823% (42310/47104)\n",
      "Train Epoch: 46 | Loss: 0.296 | Acc: 89.823% (42425/47232)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.812% (42535/47360)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.808% (42648/47488)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.798% (42758/47616)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.808% (42878/47744)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.808% (42993/47872)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.804% (43106/48000)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.804% (43221/48128)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.809% (43338/48256)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.807% (43452/48384)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.800% (43564/48512)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.803% (43680/48640)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.799% (43793/48768)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.784% (43901/48896)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.774% (44011/49024)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.768% (44123/49152)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.771% (44239/49280)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.765% (44351/49408)\n",
      "Train Epoch: 46 | Loss: 0.297 | Acc: 89.769% (44468/49536)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.769% (44583/49664)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.765% (44696/49792)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.776% (44816/49920)\n",
      "Train Epoch: 46 | Loss: 0.298 | Acc: 89.772% (44886/50000)\n",
      "Test Epoch: 46 | Loss: 0.352 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 46 | Loss: 0.411 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 46 | Loss: 0.393 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 46 | Loss: 0.362 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 46 | Loss: 0.347 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 89.429% (626/700)\n",
      "Test Epoch: 46 | Loss: 0.349 | Acc: 88.375% (707/800)\n",
      "Test Epoch: 46 | Loss: 0.356 | Acc: 88.111% (793/900)\n",
      "Test Epoch: 46 | Loss: 0.353 | Acc: 88.000% (880/1000)\n",
      "Test Epoch: 46 | Loss: 0.359 | Acc: 88.000% (968/1100)\n",
      "Test Epoch: 46 | Loss: 0.364 | Acc: 87.917% (1055/1200)\n",
      "Test Epoch: 46 | Loss: 0.360 | Acc: 87.923% (1143/1300)\n",
      "Test Epoch: 46 | Loss: 0.359 | Acc: 88.000% (1232/1400)\n",
      "Test Epoch: 46 | Loss: 0.355 | Acc: 88.067% (1321/1500)\n",
      "Test Epoch: 46 | Loss: 0.357 | Acc: 87.875% (1406/1600)\n",
      "Test Epoch: 46 | Loss: 0.361 | Acc: 87.824% (1493/1700)\n",
      "Test Epoch: 46 | Loss: 0.368 | Acc: 87.611% (1577/1800)\n",
      "Test Epoch: 46 | Loss: 0.369 | Acc: 87.684% (1666/1900)\n",
      "Test Epoch: 46 | Loss: 0.375 | Acc: 87.550% (1751/2000)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.619% (1840/2100)\n",
      "Test Epoch: 46 | Loss: 0.369 | Acc: 87.727% (1930/2200)\n",
      "Test Epoch: 46 | Loss: 0.367 | Acc: 87.783% (2019/2300)\n",
      "Test Epoch: 46 | Loss: 0.368 | Acc: 87.792% (2107/2400)\n",
      "Test Epoch: 46 | Loss: 0.375 | Acc: 87.680% (2192/2500)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.538% (2276/2600)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.741% (2369/2700)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.750% (2457/2800)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.690% (2543/2900)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.667% (2630/3000)\n",
      "Test Epoch: 46 | Loss: 0.386 | Acc: 87.548% (2714/3100)\n",
      "Test Epoch: 46 | Loss: 0.383 | Acc: 87.469% (2799/3200)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.485% (2887/3300)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.618% (2979/3400)\n",
      "Test Epoch: 46 | Loss: 0.383 | Acc: 87.429% (3060/3500)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.444% (3148/3600)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.378% (3233/3700)\n",
      "Test Epoch: 46 | Loss: 0.383 | Acc: 87.342% (3319/3800)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.410% (3409/3900)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.450% (3498/4000)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.415% (3584/4100)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.429% (3672/4200)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.465% (3761/4300)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.568% (3853/4400)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.578% (3941/4500)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.457% (4023/4600)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.426% (4109/4700)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.271% (4189/4800)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.306% (4278/4900)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.220% (4361/5000)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.294% (4452/5100)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.231% (4536/5200)\n",
      "Test Epoch: 46 | Loss: 0.384 | Acc: 87.283% (4626/5300)\n",
      "Test Epoch: 46 | Loss: 0.382 | Acc: 87.352% (4717/5400)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.382% (4806/5500)\n",
      "Test Epoch: 46 | Loss: 0.383 | Acc: 87.375% (4893/5600)\n",
      "Test Epoch: 46 | Loss: 0.381 | Acc: 87.421% (4983/5700)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.534% (5077/5800)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.508% (5163/5900)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.550% (5253/6000)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.557% (5341/6100)\n",
      "Test Epoch: 46 | Loss: 0.379 | Acc: 87.565% (5429/6200)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.651% (5522/6300)\n",
      "Test Epoch: 46 | Loss: 0.375 | Acc: 87.672% (5611/6400)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.692% (5700/6500)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.697% (5788/6600)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 87.776% (5881/6700)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.735% (5966/6800)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 87.797% (6058/6900)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.757% (6143/7000)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 87.775% (6232/7100)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.708% (6315/7200)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.781% (6408/7300)\n",
      "Test Epoch: 46 | Loss: 0.372 | Acc: 87.824% (6499/7400)\n",
      "Test Epoch: 46 | Loss: 0.372 | Acc: 87.813% (6586/7500)\n",
      "Test Epoch: 46 | Loss: 0.371 | Acc: 87.842% (6676/7600)\n",
      "Test Epoch: 46 | Loss: 0.372 | Acc: 87.792% (6760/7700)\n",
      "Test Epoch: 46 | Loss: 0.371 | Acc: 87.833% (6851/7800)\n",
      "Test Epoch: 46 | Loss: 0.371 | Acc: 87.835% (6939/7900)\n",
      "Test Epoch: 46 | Loss: 0.371 | Acc: 87.838% (7027/8000)\n",
      "Test Epoch: 46 | Loss: 0.369 | Acc: 87.901% (7120/8100)\n",
      "Test Epoch: 46 | Loss: 0.370 | Acc: 87.878% (7206/8200)\n",
      "Test Epoch: 46 | Loss: 0.370 | Acc: 87.867% (7293/8300)\n",
      "Test Epoch: 46 | Loss: 0.370 | Acc: 87.905% (7384/8400)\n",
      "Test Epoch: 46 | Loss: 0.372 | Acc: 87.847% (7467/8500)\n",
      "Test Epoch: 46 | Loss: 0.373 | Acc: 87.802% (7551/8600)\n",
      "Test Epoch: 46 | Loss: 0.374 | Acc: 87.828% (7641/8700)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.807% (7727/8800)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.831% (7817/8900)\n",
      "Test Epoch: 46 | Loss: 0.377 | Acc: 87.833% (7905/9000)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.813% (7991/9100)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.804% (8078/9200)\n",
      "Test Epoch: 46 | Loss: 0.377 | Acc: 87.796% (8165/9300)\n",
      "Test Epoch: 46 | Loss: 0.377 | Acc: 87.777% (8251/9400)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.747% (8336/9500)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.729% (8422/9600)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.784% (8515/9700)\n",
      "Test Epoch: 46 | Loss: 0.376 | Acc: 87.786% (8603/9800)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.737% (8686/9900)\n",
      "Test Epoch: 46 | Loss: 0.378 | Acc: 87.710% (8771/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Epoch: 47 | Loss: 0.214 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 47 | Loss: 0.234 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 47 | Loss: 0.234 | Acc: 92.188% (354/384)\n",
      "Train Epoch: 47 | Loss: 0.257 | Acc: 91.797% (470/512)\n",
      "Train Epoch: 47 | Loss: 0.253 | Acc: 91.719% (587/640)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.016% (699/768)\n",
      "Train Epoch: 47 | Loss: 0.254 | Acc: 91.518% (820/896)\n",
      "Train Epoch: 47 | Loss: 0.252 | Acc: 91.699% (939/1024)\n",
      "Train Epoch: 47 | Loss: 0.254 | Acc: 91.753% (1057/1152)\n",
      "Train Epoch: 47 | Loss: 0.259 | Acc: 91.562% (1172/1280)\n",
      "Train Epoch: 47 | Loss: 0.258 | Acc: 91.477% (1288/1408)\n",
      "Train Epoch: 47 | Loss: 0.258 | Acc: 91.276% (1402/1536)\n",
      "Train Epoch: 47 | Loss: 0.264 | Acc: 91.226% (1518/1664)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.183% (1634/1792)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 91.094% (1749/1920)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 91.016% (1864/2048)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.993% (1980/2176)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 91.146% (2100/2304)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 91.242% (2219/2432)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 91.250% (2336/2560)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 91.146% (2450/2688)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.335% (2572/2816)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.406% (2691/2944)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 91.243% (2803/3072)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 91.062% (2914/3200)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.895% (3025/3328)\n",
      "Train Epoch: 47 | Loss: 0.282 | Acc: 90.856% (3140/3456)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.876% (3257/3584)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.921% (3375/3712)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.990% (3494/3840)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 91.028% (3612/3968)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 91.113% (3732/4096)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 91.146% (3850/4224)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 91.199% (3969/4352)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 91.183% (4085/4480)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 91.016% (4194/4608)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 91.047% (4312/4736)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 91.016% (4427/4864)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 91.046% (4545/4992)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 91.035% (4661/5120)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 91.044% (4778/5248)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 91.071% (4896/5376)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 91.079% (5013/5504)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 91.104% (5131/5632)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 91.163% (5251/5760)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 91.033% (5360/5888)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 91.024% (5476/6016)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.967% (5589/6144)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.992% (5707/6272)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.984% (5823/6400)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.977% (5939/6528)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.910% (6051/6656)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.905% (6167/6784)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.929% (6285/6912)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.852% (6396/7040)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.806% (6509/7168)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.817% (6626/7296)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.773% (6739/7424)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.797% (6857/7552)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.820% (6975/7680)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.804% (7090/7808)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.852% (7210/7936)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.898% (7330/8064)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.967% (7452/8192)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.950% (7567/8320)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.945% (7683/8448)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.882% (7794/8576)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.924% (7914/8704)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 90.965% (8034/8832)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.971% (8151/8960)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 91.021% (8272/9088)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 91.059% (8392/9216)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 91.085% (8511/9344)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.111% (8630/9472)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.115% (8747/9600)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.129% (8865/9728)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.102% (8979/9856)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.126% (9098/9984)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.100% (9212/10112)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.133% (9332/10240)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.127% (9448/10368)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.111% (9563/10496)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.114% (9680/10624)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.109% (9796/10752)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.075% (9909/10880)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.097% (10028/11008)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.110% (10146/11136)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.122% (10264/11264)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.169% (10386/11392)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.155% (10501/11520)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.217% (10625/11648)\n",
      "Train Epoch: 47 | Loss: 0.267 | Acc: 91.219% (10742/11776)\n",
      "Train Epoch: 47 | Loss: 0.267 | Acc: 91.213% (10858/11904)\n",
      "Train Epoch: 47 | Loss: 0.266 | Acc: 91.273% (10982/12032)\n",
      "Train Epoch: 47 | Loss: 0.266 | Acc: 91.275% (11099/12160)\n",
      "Train Epoch: 47 | Loss: 0.266 | Acc: 91.260% (11214/12288)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.245% (11329/12416)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.239% (11445/12544)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.256% (11564/12672)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.289% (11685/12800)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.298% (11803/12928)\n",
      "Train Epoch: 47 | Loss: 0.267 | Acc: 91.299% (11920/13056)\n",
      "Train Epoch: 47 | Loss: 0.268 | Acc: 91.270% (12033/13184)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.203% (12141/13312)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.190% (12256/13440)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.193% (12373/13568)\n",
      "Train Epoch: 47 | Loss: 0.269 | Acc: 91.173% (12487/13696)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.117% (12596/13824)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.134% (12715/13952)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.122% (12830/14080)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.132% (12948/14208)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.113% (13062/14336)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.116% (13179/14464)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.091% (13292/14592)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.067% (13405/14720)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.103% (13527/14848)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.092% (13642/14976)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.115% (13762/15104)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.111% (13878/15232)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.120% (13996/15360)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.077% (14106/15488)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.092% (14225/15616)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.063% (14337/15744)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.035% (14449/15872)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.037% (14566/16000)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 91.047% (14684/16128)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.019% (14796/16256)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 91.016% (14912/16384)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.982% (15023/16512)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.998% (15142/16640)\n",
      "Train Epoch: 47 | Loss: 0.270 | Acc: 90.995% (15258/16768)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.974% (15371/16896)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.966% (15486/17024)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.963% (15602/17152)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.972% (15720/17280)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.958% (15834/17408)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.933% (15946/17536)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.914% (16059/17664)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.923% (16177/17792)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.954% (16299/17920)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.980% (16420/18048)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.977% (16536/18176)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.953% (16648/18304)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.951% (16764/18432)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.948% (16880/18560)\n",
      "Train Epoch: 47 | Loss: 0.271 | Acc: 90.962% (16999/18688)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.933% (17110/18816)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.936% (17227/18944)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.950% (17346/19072)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.948% (17462/19200)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.941% (17577/19328)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.933% (17692/19456)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.926% (17807/19584)\n",
      "Train Epoch: 47 | Loss: 0.272 | Acc: 90.919% (17922/19712)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 90.897% (18034/19840)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 90.875% (18146/19968)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.854% (18258/20096)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.852% (18374/20224)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.841% (18488/20352)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.830% (18602/20480)\n",
      "Train Epoch: 47 | Loss: 0.273 | Acc: 90.834% (18719/20608)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.803% (18829/20736)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.798% (18944/20864)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.782% (19057/20992)\n",
      "Train Epoch: 47 | Loss: 0.274 | Acc: 90.786% (19174/21120)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 90.761% (19285/21248)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 90.756% (19400/21376)\n",
      "Train Epoch: 47 | Loss: 0.275 | Acc: 90.769% (19519/21504)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.745% (19630/21632)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.726% (19742/21760)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.744% (19862/21888)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.757% (19981/22016)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.760% (20098/22144)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.760% (20214/22272)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.772% (20333/22400)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.771% (20449/22528)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.753% (20561/22656)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.744% (20675/22784)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.717% (20785/22912)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.725% (20903/23040)\n",
      "Train Epoch: 47 | Loss: 0.276 | Acc: 90.742% (21023/23168)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.719% (21134/23296)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.710% (21248/23424)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.693% (21360/23552)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.680% (21473/23680)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.705% (21595/23808)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.671% (21703/23936)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.675% (21820/24064)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.679% (21937/24192)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.678% (22053/24320)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.662% (22165/24448)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.670% (22283/24576)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.665% (22398/24704)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.653% (22511/24832)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.625% (22620/24960)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.609% (22732/25088)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.625% (22852/25216)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.621% (22967/25344)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.621% (23083/25472)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.613% (23197/25600)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.606% (23311/25728)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.571% (23418/25856)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.579% (23536/25984)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.571% (23650/26112)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.583% (23769/26240)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.583% (23885/26368)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.591% (24003/26496)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.599% (24121/26624)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.603% (24238/26752)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.621% (24359/26880)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.618% (24474/27008)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.629% (24593/27136)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.614% (24705/27264)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.625% (24824/27392)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.647% (24946/27520)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.639% (25060/27648)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.636% (25175/27776)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.639% (25292/27904)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.629% (25405/28032)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.639% (25524/28160)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.643% (25641/28288)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.625% (25752/28416)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.636% (25871/28544)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.642% (25989/28672)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.635% (26103/28800)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.622% (26215/28928)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.632% (26334/29056)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.635% (26451/29184)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.642% (26569/29312)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.635% (26683/29440)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.652% (26804/29568)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.649% (26919/29696)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.655% (27037/29824)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.675% (27159/29952)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.675% (27275/30080)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.671% (27390/30208)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.674% (27507/30336)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.664% (27620/30464)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.651% (27732/30592)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.658% (27850/30720)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.651% (27964/30848)\n",
      "Train Epoch: 47 | Loss: 0.277 | Acc: 90.661% (28083/30976)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.667% (28201/31104)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.644% (28310/31232)\n",
      "Train Epoch: 47 | Loss: 0.278 | Acc: 90.654% (28429/31360)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.638% (28540/31488)\n",
      "Train Epoch: 47 | Loss: 0.279 | Acc: 90.622% (28651/31616)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.606% (28762/31744)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.606% (28878/31872)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.622% (28999/32000)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.609% (29111/32128)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.582% (29218/32256)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.585% (29335/32384)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.588% (29452/32512)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.585% (29567/32640)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.567% (29677/32768)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.564% (29792/32896)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.570% (29910/33024)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.580% (30029/33152)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.571% (30142/33280)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.568% (30257/33408)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.562% (30371/33536)\n",
      "Train Epoch: 47 | Loss: 0.280 | Acc: 90.572% (30490/33664)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.575% (30607/33792)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.548% (30714/33920)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.555% (30832/34048)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.543% (30944/34176)\n",
      "Train Epoch: 47 | Loss: 0.281 | Acc: 90.535% (31057/34304)\n",
      "Train Epoch: 47 | Loss: 0.282 | Acc: 90.523% (31169/34432)\n",
      "Train Epoch: 47 | Loss: 0.282 | Acc: 90.524% (31285/34560)\n",
      "Train Epoch: 47 | Loss: 0.282 | Acc: 90.513% (31397/34688)\n",
      "Train Epoch: 47 | Loss: 0.282 | Acc: 90.516% (31514/34816)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.505% (31626/34944)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.468% (31729/35072)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.472% (31846/35200)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.481% (31965/35328)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.487% (32083/35456)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.476% (32195/35584)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.477% (32311/35712)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.480% (32428/35840)\n",
      "Train Epoch: 47 | Loss: 0.283 | Acc: 90.475% (32542/35968)\n",
      "Train Epoch: 47 | Loss: 0.284 | Acc: 90.431% (32642/36096)\n",
      "Train Epoch: 47 | Loss: 0.284 | Acc: 90.440% (32761/36224)\n",
      "Train Epoch: 47 | Loss: 0.284 | Acc: 90.430% (32873/36352)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.422% (32986/36480)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.417% (33100/36608)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.407% (33212/36736)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.381% (33318/36864)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.374% (33431/36992)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.383% (33550/37120)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.394% (33670/37248)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.400% (33788/37376)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.404% (33905/37504)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.402% (34020/37632)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.392% (34132/37760)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.411% (34255/37888)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.409% (34370/38016)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.397% (34481/38144)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.379% (34590/38272)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.362% (34699/38400)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.360% (34814/38528)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.369% (34933/38656)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.380% (35053/38784)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.363% (35162/38912)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.371% (35281/39040)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.367% (35395/39168)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.353% (35505/39296)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.349% (35619/39424)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.332% (35728/39552)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.328% (35842/39680)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.324% (35956/39808)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.312% (36067/39936)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.315% (36184/40064)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.329% (36305/40192)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.332% (36422/40320)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.331% (36537/40448)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.329% (36652/40576)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.335% (36770/40704)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.336% (36886/40832)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.330% (36999/40960)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.335% (37117/41088)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.334% (37232/41216)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.327% (37345/41344)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.314% (37455/41472)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.308% (37568/41600)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.313% (37686/41728)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.314% (37802/41856)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.320% (37920/41984)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.312% (38032/42112)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.298% (38142/42240)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.287% (38253/42368)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.284% (38367/42496)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.287% (38484/42624)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.283% (38598/42752)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.285% (38714/42880)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.283% (38829/43008)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.282% (38944/43136)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.285% (39061/43264)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.300% (39183/43392)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.308% (39302/43520)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.318% (39422/43648)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.310% (39534/43776)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.311% (39650/43904)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.316% (39768/44032)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.319% (39885/44160)\n",
      "Train Epoch: 47 | Loss: 0.285 | Acc: 90.322% (40002/44288)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.305% (40110/44416)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.311% (40228/44544)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.300% (40339/44672)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.297% (40453/44800)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.302% (40571/44928)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.303% (40687/45056)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.282% (40793/45184)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.261% (40899/45312)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.264% (41016/45440)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.269% (41134/45568)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.284% (41256/45696)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.276% (41368/45824)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.275% (41483/45952)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.271% (41597/46080)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.270% (41712/46208)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.275% (41830/46336)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.283% (41949/46464)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.286% (42066/46592)\n",
      "Train Epoch: 47 | Loss: 0.286 | Acc: 90.295% (42186/46720)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.288% (42298/46848)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.289% (42414/46976)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.283% (42527/47104)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.295% (42648/47232)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.285% (42759/47360)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.280% (42872/47488)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.274% (42985/47616)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.273% (43100/47744)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.270% (43214/47872)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.277% (43333/48000)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.282% (43451/48128)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.281% (43566/48256)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.284% (43683/48384)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.277% (43795/48512)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.273% (43909/48640)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.270% (44023/48768)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.277% (44142/48896)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.290% (44264/49024)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.285% (44377/49152)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.286% (44493/49280)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.291% (44611/49408)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.284% (44723/49536)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.277% (44835/49664)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.278% (44951/49792)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.270% (45063/49920)\n",
      "Train Epoch: 47 | Loss: 0.287 | Acc: 90.276% (45138/50000)\n",
      "Test Epoch: 47 | Loss: 0.296 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 47 | Loss: 0.361 | Acc: 85.500% (171/200)\n",
      "Test Epoch: 47 | Loss: 0.352 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 47 | Loss: 0.344 | Acc: 87.750% (351/400)\n",
      "Test Epoch: 47 | Loss: 0.334 | Acc: 88.400% (442/500)\n",
      "Test Epoch: 47 | Loss: 0.335 | Acc: 88.667% (532/600)\n",
      "Test Epoch: 47 | Loss: 0.349 | Acc: 88.571% (620/700)\n",
      "Test Epoch: 47 | Loss: 0.386 | Acc: 87.250% (698/800)\n",
      "Test Epoch: 47 | Loss: 0.397 | Acc: 87.111% (784/900)\n",
      "Test Epoch: 47 | Loss: 0.398 | Acc: 87.000% (870/1000)\n",
      "Test Epoch: 47 | Loss: 0.404 | Acc: 87.000% (957/1100)\n",
      "Test Epoch: 47 | Loss: 0.401 | Acc: 87.000% (1044/1200)\n",
      "Test Epoch: 47 | Loss: 0.395 | Acc: 87.077% (1132/1300)\n",
      "Test Epoch: 47 | Loss: 0.396 | Acc: 87.000% (1218/1400)\n",
      "Test Epoch: 47 | Loss: 0.396 | Acc: 86.867% (1303/1500)\n",
      "Test Epoch: 47 | Loss: 0.403 | Acc: 86.812% (1389/1600)\n",
      "Test Epoch: 47 | Loss: 0.398 | Acc: 86.941% (1478/1700)\n",
      "Test Epoch: 47 | Loss: 0.409 | Acc: 86.722% (1561/1800)\n",
      "Test Epoch: 47 | Loss: 0.407 | Acc: 86.947% (1652/1900)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 87.050% (1741/2000)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 86.952% (1826/2100)\n",
      "Test Epoch: 47 | Loss: 0.405 | Acc: 86.955% (1913/2200)\n",
      "Test Epoch: 47 | Loss: 0.403 | Acc: 87.087% (2003/2300)\n",
      "Test Epoch: 47 | Loss: 0.399 | Acc: 87.125% (2091/2400)\n",
      "Test Epoch: 47 | Loss: 0.405 | Acc: 86.840% (2171/2500)\n",
      "Test Epoch: 47 | Loss: 0.415 | Acc: 86.500% (2249/2600)\n",
      "Test Epoch: 47 | Loss: 0.412 | Acc: 86.667% (2340/2700)\n",
      "Test Epoch: 47 | Loss: 0.414 | Acc: 86.607% (2425/2800)\n",
      "Test Epoch: 47 | Loss: 0.415 | Acc: 86.621% (2512/2900)\n",
      "Test Epoch: 47 | Loss: 0.416 | Acc: 86.600% (2598/3000)\n",
      "Test Epoch: 47 | Loss: 0.418 | Acc: 86.581% (2684/3100)\n",
      "Test Epoch: 47 | Loss: 0.417 | Acc: 86.625% (2772/3200)\n",
      "Test Epoch: 47 | Loss: 0.416 | Acc: 86.667% (2860/3300)\n",
      "Test Epoch: 47 | Loss: 0.416 | Acc: 86.647% (2946/3400)\n",
      "Test Epoch: 47 | Loss: 0.417 | Acc: 86.686% (3034/3500)\n",
      "Test Epoch: 47 | Loss: 0.414 | Acc: 86.806% (3125/3600)\n",
      "Test Epoch: 47 | Loss: 0.415 | Acc: 86.784% (3211/3700)\n",
      "Test Epoch: 47 | Loss: 0.414 | Acc: 86.711% (3295/3800)\n",
      "Test Epoch: 47 | Loss: 0.410 | Acc: 86.795% (3385/3900)\n",
      "Test Epoch: 47 | Loss: 0.412 | Acc: 86.850% (3474/4000)\n",
      "Test Epoch: 47 | Loss: 0.413 | Acc: 86.854% (3561/4100)\n",
      "Test Epoch: 47 | Loss: 0.414 | Acc: 86.881% (3649/4200)\n",
      "Test Epoch: 47 | Loss: 0.410 | Acc: 87.000% (3741/4300)\n",
      "Test Epoch: 47 | Loss: 0.409 | Acc: 87.091% (3832/4400)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 87.200% (3924/4500)\n",
      "Test Epoch: 47 | Loss: 0.404 | Acc: 87.217% (4012/4600)\n",
      "Test Epoch: 47 | Loss: 0.403 | Acc: 87.234% (4100/4700)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 87.083% (4180/4800)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 87.163% (4271/4900)\n",
      "Test Epoch: 47 | Loss: 0.410 | Acc: 87.040% (4352/5000)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 87.137% (4444/5100)\n",
      "Test Epoch: 47 | Loss: 0.410 | Acc: 87.058% (4527/5200)\n",
      "Test Epoch: 47 | Loss: 0.409 | Acc: 87.019% (4612/5300)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 87.019% (4699/5400)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 87.018% (4786/5500)\n",
      "Test Epoch: 47 | Loss: 0.407 | Acc: 87.071% (4876/5600)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 87.018% (4960/5700)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 87.034% (5048/5800)\n",
      "Test Epoch: 47 | Loss: 0.408 | Acc: 86.915% (5128/5900)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 86.967% (5218/6000)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 86.934% (5303/6100)\n",
      "Test Epoch: 47 | Loss: 0.406 | Acc: 86.952% (5391/6200)\n",
      "Test Epoch: 47 | Loss: 0.404 | Acc: 87.032% (5483/6300)\n",
      "Test Epoch: 47 | Loss: 0.401 | Acc: 87.109% (5575/6400)\n",
      "Test Epoch: 47 | Loss: 0.401 | Acc: 87.108% (5662/6500)\n",
      "Test Epoch: 47 | Loss: 0.401 | Acc: 87.152% (5752/6600)\n",
      "Test Epoch: 47 | Loss: 0.398 | Acc: 87.209% (5843/6700)\n",
      "Test Epoch: 47 | Loss: 0.399 | Acc: 87.118% (5924/6800)\n",
      "Test Epoch: 47 | Loss: 0.396 | Acc: 87.174% (6015/6900)\n",
      "Test Epoch: 47 | Loss: 0.397 | Acc: 87.143% (6100/7000)\n",
      "Test Epoch: 47 | Loss: 0.397 | Acc: 87.169% (6189/7100)\n",
      "Test Epoch: 47 | Loss: 0.397 | Acc: 87.194% (6278/7200)\n",
      "Test Epoch: 47 | Loss: 0.394 | Acc: 87.247% (6369/7300)\n",
      "Test Epoch: 47 | Loss: 0.393 | Acc: 87.284% (6459/7400)\n",
      "Test Epoch: 47 | Loss: 0.393 | Acc: 87.213% (6541/7500)\n",
      "Test Epoch: 47 | Loss: 0.392 | Acc: 87.237% (6630/7600)\n",
      "Test Epoch: 47 | Loss: 0.394 | Acc: 87.260% (6719/7700)\n",
      "Test Epoch: 47 | Loss: 0.393 | Acc: 87.256% (6806/7800)\n",
      "Test Epoch: 47 | Loss: 0.393 | Acc: 87.278% (6895/7900)\n",
      "Test Epoch: 47 | Loss: 0.392 | Acc: 87.312% (6985/8000)\n",
      "Test Epoch: 47 | Loss: 0.391 | Acc: 87.333% (7074/8100)\n",
      "Test Epoch: 47 | Loss: 0.391 | Acc: 87.305% (7159/8200)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.325% (7248/8300)\n",
      "Test Epoch: 47 | Loss: 0.388 | Acc: 87.357% (7338/8400)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.329% (7423/8500)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.314% (7509/8600)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.356% (7600/8700)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.318% (7684/8800)\n",
      "Test Epoch: 47 | Loss: 0.388 | Acc: 87.382% (7777/8900)\n",
      "Test Epoch: 47 | Loss: 0.388 | Acc: 87.389% (7865/9000)\n",
      "Test Epoch: 47 | Loss: 0.390 | Acc: 87.330% (7947/9100)\n",
      "Test Epoch: 47 | Loss: 0.389 | Acc: 87.359% (8037/9200)\n",
      "Test Epoch: 47 | Loss: 0.389 | Acc: 87.344% (8123/9300)\n",
      "Test Epoch: 47 | Loss: 0.388 | Acc: 87.351% (8211/9400)\n",
      "Test Epoch: 47 | Loss: 0.387 | Acc: 87.347% (8298/9500)\n",
      "Test Epoch: 47 | Loss: 0.387 | Acc: 87.333% (8384/9600)\n",
      "Test Epoch: 47 | Loss: 0.387 | Acc: 87.289% (8467/9700)\n",
      "Test Epoch: 47 | Loss: 0.389 | Acc: 87.245% (8550/9800)\n",
      "Test Epoch: 47 | Loss: 0.391 | Acc: 87.202% (8633/9900)\n",
      "Test Epoch: 47 | Loss: 0.391 | Acc: 87.200% (8720/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Train Epoch: 48 | Loss: 0.368 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 48 | Loss: 0.295 | Acc: 90.234% (231/256)\n",
      "Train Epoch: 48 | Loss: 0.307 | Acc: 90.625% (348/384)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 91.602% (469/512)\n",
      "Train Epoch: 48 | Loss: 0.266 | Acc: 91.562% (586/640)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.797% (705/768)\n",
      "Train Epoch: 48 | Loss: 0.255 | Acc: 92.076% (825/896)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 92.090% (943/1024)\n",
      "Train Epoch: 48 | Loss: 0.252 | Acc: 92.535% (1066/1152)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 48 | Loss: 0.253 | Acc: 92.330% (1300/1408)\n",
      "Train Epoch: 48 | Loss: 0.254 | Acc: 92.383% (1419/1536)\n",
      "Train Epoch: 48 | Loss: 0.256 | Acc: 92.248% (1535/1664)\n",
      "Train Epoch: 48 | Loss: 0.252 | Acc: 92.243% (1653/1792)\n",
      "Train Epoch: 48 | Loss: 0.253 | Acc: 92.031% (1767/1920)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.748% (1879/2048)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.682% (1995/2176)\n",
      "Train Epoch: 48 | Loss: 0.261 | Acc: 91.580% (2110/2304)\n",
      "Train Epoch: 48 | Loss: 0.262 | Acc: 91.571% (2227/2432)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.758% (2349/2560)\n",
      "Train Epoch: 48 | Loss: 0.260 | Acc: 91.667% (2464/2688)\n",
      "Train Epoch: 48 | Loss: 0.257 | Acc: 91.726% (2583/2816)\n",
      "Train Epoch: 48 | Loss: 0.256 | Acc: 91.814% (2703/2944)\n",
      "Train Epoch: 48 | Loss: 0.254 | Acc: 91.862% (2822/3072)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.781% (2937/3200)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.827% (3056/3328)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.725% (3170/3456)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.685% (3286/3584)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.595% (3400/3712)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.536% (3515/3840)\n",
      "Train Epoch: 48 | Loss: 0.257 | Acc: 91.633% (3636/3968)\n",
      "Train Epoch: 48 | Loss: 0.257 | Acc: 91.479% (3747/4096)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.430% (3862/4224)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.429% (3979/4352)\n",
      "Train Epoch: 48 | Loss: 0.259 | Acc: 91.362% (4093/4480)\n",
      "Train Epoch: 48 | Loss: 0.261 | Acc: 91.254% (4205/4608)\n",
      "Train Epoch: 48 | Loss: 0.258 | Acc: 91.364% (4327/4736)\n",
      "Train Epoch: 48 | Loss: 0.260 | Acc: 91.345% (4443/4864)\n",
      "Train Epoch: 48 | Loss: 0.261 | Acc: 91.326% (4559/4992)\n",
      "Train Epoch: 48 | Loss: 0.263 | Acc: 91.270% (4673/5120)\n",
      "Train Epoch: 48 | Loss: 0.263 | Acc: 91.235% (4788/5248)\n",
      "Train Epoch: 48 | Loss: 0.262 | Acc: 91.257% (4906/5376)\n",
      "Train Epoch: 48 | Loss: 0.262 | Acc: 91.261% (5023/5504)\n",
      "Train Epoch: 48 | Loss: 0.265 | Acc: 91.140% (5133/5632)\n",
      "Train Epoch: 48 | Loss: 0.266 | Acc: 91.128% (5249/5760)\n",
      "Train Epoch: 48 | Loss: 0.264 | Acc: 91.168% (5368/5888)\n",
      "Train Epoch: 48 | Loss: 0.264 | Acc: 91.140% (5483/6016)\n",
      "Train Epoch: 48 | Loss: 0.262 | Acc: 91.162% (5601/6144)\n",
      "Train Epoch: 48 | Loss: 0.263 | Acc: 91.167% (5718/6272)\n",
      "Train Epoch: 48 | Loss: 0.262 | Acc: 91.188% (5836/6400)\n",
      "Train Epoch: 48 | Loss: 0.264 | Acc: 91.146% (5950/6528)\n",
      "Train Epoch: 48 | Loss: 0.264 | Acc: 91.091% (6063/6656)\n",
      "Train Epoch: 48 | Loss: 0.264 | Acc: 91.052% (6177/6784)\n",
      "Train Epoch: 48 | Loss: 0.265 | Acc: 91.016% (6291/6912)\n",
      "Train Epoch: 48 | Loss: 0.265 | Acc: 91.037% (6409/7040)\n",
      "Train Epoch: 48 | Loss: 0.267 | Acc: 90.988% (6522/7168)\n",
      "Train Epoch: 48 | Loss: 0.267 | Acc: 91.050% (6643/7296)\n",
      "Train Epoch: 48 | Loss: 0.268 | Acc: 91.002% (6756/7424)\n",
      "Train Epoch: 48 | Loss: 0.268 | Acc: 91.009% (6873/7552)\n",
      "Train Epoch: 48 | Loss: 0.271 | Acc: 90.951% (6985/7680)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.920% (7099/7808)\n",
      "Train Epoch: 48 | Loss: 0.271 | Acc: 90.915% (7215/7936)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.836% (7325/8064)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.845% (7442/8192)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.853% (7559/8320)\n",
      "Train Epoch: 48 | Loss: 0.273 | Acc: 90.874% (7677/8448)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.893% (7795/8576)\n",
      "Train Epoch: 48 | Loss: 0.272 | Acc: 90.912% (7913/8704)\n",
      "Train Epoch: 48 | Loss: 0.273 | Acc: 90.851% (8024/8832)\n",
      "Train Epoch: 48 | Loss: 0.273 | Acc: 90.826% (8138/8960)\n",
      "Train Epoch: 48 | Loss: 0.273 | Acc: 90.790% (8251/9088)\n",
      "Train Epoch: 48 | Loss: 0.275 | Acc: 90.679% (8357/9216)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.604% (8466/9344)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.614% (8583/9472)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.583% (8696/9600)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.584% (8812/9728)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.534% (8923/9856)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.555% (9041/9984)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.576% (9159/10112)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.586% (9276/10240)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.557% (9389/10368)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.558% (9505/10496)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.587% (9624/10624)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.606% (9742/10752)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.570% (9854/10880)\n",
      "Train Epoch: 48 | Loss: 0.276 | Acc: 90.580% (9971/11008)\n",
      "Train Epoch: 48 | Loss: 0.275 | Acc: 90.589% (10088/11136)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.527% (10197/11264)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.537% (10314/11392)\n",
      "Train Epoch: 48 | Loss: 0.277 | Acc: 90.530% (10429/11520)\n",
      "Train Epoch: 48 | Loss: 0.279 | Acc: 90.470% (10538/11648)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.506% (10658/11776)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.516% (10775/11904)\n",
      "Train Epoch: 48 | Loss: 0.278 | Acc: 90.500% (10889/12032)\n",
      "Train Epoch: 48 | Loss: 0.279 | Acc: 90.493% (11004/12160)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.470% (11117/12288)\n",
      "Train Epoch: 48 | Loss: 0.279 | Acc: 90.464% (11232/12416)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.434% (11344/12544)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.412% (11457/12672)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.414% (11573/12800)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.416% (11689/12928)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.411% (11804/13056)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.405% (11919/13184)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.392% (12033/13312)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.365% (12145/13440)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.382% (12263/13568)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.369% (12377/13696)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.386% (12495/13824)\n",
      "Train Epoch: 48 | Loss: 0.281 | Acc: 90.360% (12607/13952)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.362% (12723/14080)\n",
      "Train Epoch: 48 | Loss: 0.280 | Acc: 90.358% (12838/14208)\n",
      "Train Epoch: 48 | Loss: 0.281 | Acc: 90.360% (12954/14336)\n",
      "Train Epoch: 48 | Loss: 0.281 | Acc: 90.342% (13067/14464)\n",
      "Train Epoch: 48 | Loss: 0.281 | Acc: 90.330% (13181/14592)\n",
      "Train Epoch: 48 | Loss: 0.281 | Acc: 90.312% (13294/14720)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.295% (13407/14848)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.291% (13522/14976)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.281% (13636/15104)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.297% (13754/15232)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.267% (13865/15360)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.289% (13984/15488)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.273% (14097/15616)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.263% (14211/15744)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.266% (14327/15872)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.231% (14437/16000)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.234% (14553/16128)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.237% (14669/16256)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.271% (14790/16384)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.280% (14907/16512)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.312% (15028/16640)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.321% (15145/16768)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.288% (15255/16896)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.308% (15374/17024)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.316% (15491/17152)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.312% (15606/17280)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.315% (15722/17408)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.323% (15839/17536)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.336% (15957/17664)\n",
      "Train Epoch: 48 | Loss: 0.282 | Acc: 90.350% (16075/17792)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.340% (16189/17920)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.348% (16306/18048)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.289% (16411/18176)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.281% (16525/18304)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.278% (16640/18432)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.253% (16751/18560)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.256% (16867/18688)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.248% (16981/18816)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.287% (17104/18944)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.295% (17221/19072)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.297% (17337/19200)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.289% (17451/19328)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.291% (17567/19456)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.308% (17686/19584)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.316% (17803/19712)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.297% (17915/19840)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.304% (18032/19968)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.292% (18145/20096)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.304% (18263/20224)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.306% (18379/20352)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.312% (18496/20480)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.295% (18608/20608)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.312% (18727/20736)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.294% (18839/20864)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.301% (18956/20992)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.312% (19074/21120)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.305% (19188/21248)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.293% (19301/21376)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.253% (19408/21504)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.241% (19521/21632)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.248% (19638/21760)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.255% (19755/21888)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.280% (19876/22016)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.277% (19991/22144)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.288% (20109/22272)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.281% (20223/22400)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.310% (20345/22528)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.320% (20463/22656)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.305% (20575/22784)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.306% (20691/22912)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.308% (20807/23040)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.310% (20923/23168)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.303% (21037/23296)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.296% (21151/23424)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.294% (21266/23552)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.304% (21384/23680)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.289% (21496/23808)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.274% (21608/23936)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.284% (21726/24064)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.290% (21843/24192)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.296% (21960/24320)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.302% (22077/24448)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.299% (22192/24576)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.285% (22304/24704)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.287% (22420/24832)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.260% (22529/24960)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.270% (22647/25088)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.268% (22762/25216)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.278% (22880/25344)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.280% (22996/25472)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.285% (23113/25600)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.279% (23227/25728)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.277% (23342/25856)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.271% (23456/25984)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.257% (23568/26112)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.274% (23688/26240)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.291% (23808/26368)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.293% (23924/26496)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.294% (24040/26624)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.292% (24155/26752)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.298% (24272/26880)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.310% (24391/27008)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.304% (24505/27136)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.321% (24625/27264)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.300% (24735/27392)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.305% (24852/27520)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.314% (24970/27648)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.294% (25080/27776)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.306% (25199/27904)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.311% (25316/28032)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.316% (25433/28160)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.314% (25548/28288)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.333% (25669/28416)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.345% (25788/28544)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.342% (25903/28672)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.354% (26022/28800)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.342% (26134/28928)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.350% (26252/29056)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.351% (26368/29184)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.325% (26476/29312)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.319% (26590/29440)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.321% (26706/29568)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.329% (26824/29696)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.313% (26935/29824)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.311% (27050/29952)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.329% (27171/30080)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.337% (27289/30208)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.325% (27401/30336)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.323% (27516/30464)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.314% (27629/30592)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.326% (27748/30720)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.330% (27865/30848)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.328% (27980/30976)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.336% (28098/31104)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.340% (28215/31232)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.341% (28331/31360)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.323% (28441/31488)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.328% (28558/31616)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.345% (28679/31744)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.346% (28795/31872)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.359% (28915/32000)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.351% (29028/32128)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.343% (29141/32256)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.363% (29263/32384)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.367% (29380/32512)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.371% (29497/32640)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.375% (29614/32768)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.376% (29730/32896)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.352% (29838/33024)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.351% (29953/33152)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.361% (30072/33280)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.365% (30189/33408)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.372% (30307/33536)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.375% (30424/33664)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.376% (30540/33792)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.386% (30659/33920)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.393% (30777/34048)\n",
      "Train Epoch: 48 | Loss: 0.283 | Acc: 90.376% (30887/34176)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.354% (30995/34304)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.364% (31114/34432)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.353% (31226/34560)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.340% (31337/34688)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.335% (31451/34816)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.347% (31571/34944)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.351% (31688/35072)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.341% (31800/35200)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.331% (31912/35328)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.334% (32029/35456)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.321% (32140/35584)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.328% (32258/35712)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.324% (32372/35840)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.314% (32484/35968)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.287% (32590/36096)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.288% (32706/36224)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.295% (32824/36352)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.288% (32937/36480)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.275% (33048/36608)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.268% (33161/36736)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.270% (33277/36864)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.274% (33394/36992)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.286% (33514/37120)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.284% (33629/37248)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.280% (33743/37376)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.300% (33866/37504)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.290% (33978/37632)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.297% (34096/37760)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.290% (34209/37888)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.291% (34325/38016)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.289% (34440/38144)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.275% (34550/38272)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.268% (34663/38400)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.264% (34777/38528)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.255% (34889/38656)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.267% (35009/38784)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.265% (35124/38912)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.287% (35248/39040)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.288% (35364/39168)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.292% (35481/39296)\n",
      "Train Epoch: 48 | Loss: 0.284 | Acc: 90.290% (35596/39424)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.286% (35710/39552)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.280% (35823/39680)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.283% (35940/39808)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.274% (36052/39936)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.263% (36163/40064)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.259% (36277/40192)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.258% (36392/40320)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.254% (36506/40448)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.255% (36622/40576)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.244% (36733/40704)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.238% (36846/40832)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.244% (36964/40960)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.240% (37078/41088)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.247% (37196/41216)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.238% (37308/41344)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.244% (37426/41472)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.231% (37536/41600)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.234% (37653/41728)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.236% (37769/41856)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.230% (37882/41984)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.224% (37995/42112)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.227% (38112/42240)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.219% (38224/42368)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.234% (38346/42496)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.226% (38458/42624)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.227% (38574/42752)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.222% (38687/42880)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.223% (38803/43008)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.217% (38916/43136)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.218% (39032/43264)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.208% (39143/43392)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.211% (39260/43520)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.194% (39368/43648)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.198% (39485/43776)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.210% (39606/43904)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.216% (39724/44032)\n",
      "Train Epoch: 48 | Loss: 0.285 | Acc: 90.215% (39839/44160)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.203% (39949/44288)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.208% (40067/44416)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.214% (40185/44544)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.213% (40300/44672)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.203% (40411/44800)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.198% (40524/44928)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.206% (40643/45056)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.202% (40757/45184)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.197% (40870/45312)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.198% (40986/45440)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.195% (41100/45568)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.209% (41222/45696)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.221% (41343/45824)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.214% (41455/45952)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.219% (41573/46080)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.212% (41685/46208)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.228% (41808/46336)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.225% (41922/46464)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.221% (42036/46592)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.220% (42151/46720)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.224% (42268/46848)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.227% (42385/46976)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.226% (42500/47104)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.231% (42618/47232)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.236% (42736/47360)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.235% (42851/47488)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.245% (42971/47616)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.246% (43087/47744)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.249% (43204/47872)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.246% (43318/48000)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.239% (43430/48128)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.217% (43535/48256)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.212% (43648/48384)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.202% (43759/48512)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.197% (43872/48640)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.192% (43985/48768)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.185% (44097/48896)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.188% (44214/49024)\n",
      "Train Epoch: 48 | Loss: 0.286 | Acc: 90.188% (44329/49152)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.179% (44440/49280)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.178% (44555/49408)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.167% (44665/49536)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.168% (44781/49664)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.165% (44895/49792)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.166% (45011/49920)\n",
      "Train Epoch: 48 | Loss: 0.287 | Acc: 90.168% (45084/50000)\n",
      "Test Epoch: 48 | Loss: 0.462 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 48 | Loss: 0.461 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 48 | Loss: 0.419 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 48 | Loss: 0.401 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 48 | Loss: 0.373 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 48 | Loss: 0.336 | Acc: 89.833% (539/600)\n",
      "Test Epoch: 48 | Loss: 0.330 | Acc: 89.714% (628/700)\n",
      "Test Epoch: 48 | Loss: 0.364 | Acc: 88.875% (711/800)\n",
      "Test Epoch: 48 | Loss: 0.370 | Acc: 88.333% (795/900)\n",
      "Test Epoch: 48 | Loss: 0.367 | Acc: 88.300% (883/1000)\n",
      "Test Epoch: 48 | Loss: 0.366 | Acc: 88.545% (974/1100)\n",
      "Test Epoch: 48 | Loss: 0.373 | Acc: 88.000% (1056/1200)\n",
      "Test Epoch: 48 | Loss: 0.364 | Acc: 88.077% (1145/1300)\n",
      "Test Epoch: 48 | Loss: 0.364 | Acc: 88.286% (1236/1400)\n",
      "Test Epoch: 48 | Loss: 0.362 | Acc: 88.067% (1321/1500)\n",
      "Test Epoch: 48 | Loss: 0.363 | Acc: 88.125% (1410/1600)\n",
      "Test Epoch: 48 | Loss: 0.364 | Acc: 88.294% (1501/1700)\n",
      "Test Epoch: 48 | Loss: 0.363 | Acc: 88.333% (1590/1800)\n",
      "Test Epoch: 48 | Loss: 0.366 | Acc: 88.263% (1677/1900)\n",
      "Test Epoch: 48 | Loss: 0.377 | Acc: 88.000% (1760/2000)\n",
      "Test Epoch: 48 | Loss: 0.373 | Acc: 88.143% (1851/2100)\n",
      "Test Epoch: 48 | Loss: 0.365 | Acc: 88.318% (1943/2200)\n",
      "Test Epoch: 48 | Loss: 0.368 | Acc: 88.174% (2028/2300)\n",
      "Test Epoch: 48 | Loss: 0.369 | Acc: 88.250% (2118/2400)\n",
      "Test Epoch: 48 | Loss: 0.375 | Acc: 88.120% (2203/2500)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.846% (2284/2600)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.926% (2374/2700)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.857% (2460/2800)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.931% (2550/2900)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 88.000% (2640/3000)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.839% (2723/3100)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.969% (2815/3200)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.939% (2902/3300)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.912% (2989/3400)\n",
      "Test Epoch: 48 | Loss: 0.391 | Acc: 87.743% (3071/3500)\n",
      "Test Epoch: 48 | Loss: 0.389 | Acc: 87.778% (3160/3600)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.865% (3251/3700)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.737% (3334/3800)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.795% (3424/3900)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.900% (3516/4000)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.854% (3602/4100)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.786% (3687/4200)\n",
      "Test Epoch: 48 | Loss: 0.383 | Acc: 87.953% (3782/4300)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.955% (3870/4400)\n",
      "Test Epoch: 48 | Loss: 0.383 | Acc: 88.000% (3960/4500)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.978% (4047/4600)\n",
      "Test Epoch: 48 | Loss: 0.383 | Acc: 88.064% (4139/4700)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.958% (4222/4800)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 88.000% (4312/4900)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.860% (4393/5000)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.882% (4482/5100)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.808% (4566/5200)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.774% (4652/5300)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.833% (4743/5400)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.873% (4833/5500)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.839% (4919/5600)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.719% (5000/5700)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.724% (5088/5800)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.712% (5175/5900)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.650% (5259/6000)\n",
      "Test Epoch: 48 | Loss: 0.388 | Acc: 87.623% (5345/6100)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.661% (5435/6200)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.730% (5527/6300)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.703% (5613/6400)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.708% (5701/6500)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.697% (5788/6600)\n",
      "Test Epoch: 48 | Loss: 0.382 | Acc: 87.731% (5878/6700)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.691% (5963/6800)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.841% (6061/6900)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.814% (6147/7000)\n",
      "Test Epoch: 48 | Loss: 0.383 | Acc: 87.817% (6235/7100)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.792% (6321/7200)\n",
      "Test Epoch: 48 | Loss: 0.382 | Acc: 87.836% (6412/7300)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.824% (6499/7400)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.800% (6585/7500)\n",
      "Test Epoch: 48 | Loss: 0.380 | Acc: 87.842% (6676/7600)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.805% (6761/7700)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.808% (6849/7800)\n",
      "Test Epoch: 48 | Loss: 0.382 | Acc: 87.810% (6937/7900)\n",
      "Test Epoch: 48 | Loss: 0.381 | Acc: 87.812% (7025/8000)\n",
      "Test Epoch: 48 | Loss: 0.380 | Acc: 87.827% (7114/8100)\n",
      "Test Epoch: 48 | Loss: 0.380 | Acc: 87.817% (7201/8200)\n",
      "Test Epoch: 48 | Loss: 0.380 | Acc: 87.807% (7288/8300)\n",
      "Test Epoch: 48 | Loss: 0.380 | Acc: 87.821% (7377/8400)\n",
      "Test Epoch: 48 | Loss: 0.382 | Acc: 87.741% (7458/8500)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.686% (7541/8600)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.690% (7629/8700)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.693% (7717/8800)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.697% (7805/8900)\n",
      "Test Epoch: 48 | Loss: 0.387 | Acc: 87.622% (7886/9000)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.648% (7976/9100)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.707% (8069/9200)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.720% (8158/9300)\n",
      "Test Epoch: 48 | Loss: 0.384 | Acc: 87.734% (8247/9400)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.695% (8331/9500)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.635% (8413/9600)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.711% (8508/9700)\n",
      "Test Epoch: 48 | Loss: 0.385 | Acc: 87.694% (8594/9800)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.667% (8679/9900)\n",
      "Test Epoch: 48 | Loss: 0.386 | Acc: 87.640% (8764/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Epoch: 49 | Loss: 0.254 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 49 | Loss: 0.257 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 49 | Loss: 0.254 | Acc: 91.875% (588/640)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 91.016% (699/768)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.848% (814/896)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.723% (929/1024)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 91.059% (1049/1152)\n",
      "Train Epoch: 49 | Loss: 0.280 | Acc: 90.781% (1162/1280)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.625% (1276/1408)\n",
      "Train Epoch: 49 | Loss: 0.275 | Acc: 90.755% (1394/1536)\n",
      "Train Epoch: 49 | Loss: 0.275 | Acc: 90.805% (1511/1664)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.960% (1630/1792)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 91.042% (1748/1920)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 91.016% (1864/2048)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.947% (1979/2176)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 91.102% (2099/2304)\n",
      "Train Epoch: 49 | Loss: 0.267 | Acc: 91.118% (2216/2432)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.977% (2329/2560)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.960% (2445/2688)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.838% (2558/2816)\n",
      "Train Epoch: 49 | Loss: 0.275 | Acc: 90.659% (2669/2944)\n",
      "Train Epoch: 49 | Loss: 0.276 | Acc: 90.495% (2780/3072)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.312% (2890/3200)\n",
      "Train Epoch: 49 | Loss: 0.277 | Acc: 90.385% (3008/3328)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.509% (3128/3456)\n",
      "Train Epoch: 49 | Loss: 0.275 | Acc: 90.569% (3246/3584)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.409% (3356/3712)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.599% (3479/3840)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.701% (3599/3968)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.820% (3720/4096)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.885% (3839/4224)\n",
      "Train Epoch: 49 | Loss: 0.268 | Acc: 90.901% (3956/4352)\n",
      "Train Epoch: 49 | Loss: 0.267 | Acc: 90.938% (4074/4480)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 90.907% (4189/4608)\n",
      "Train Epoch: 49 | Loss: 0.263 | Acc: 91.047% (4312/4736)\n",
      "Train Epoch: 49 | Loss: 0.262 | Acc: 91.118% (4432/4864)\n",
      "Train Epoch: 49 | Loss: 0.264 | Acc: 91.046% (4545/4992)\n",
      "Train Epoch: 49 | Loss: 0.261 | Acc: 91.172% (4668/5120)\n",
      "Train Epoch: 49 | Loss: 0.261 | Acc: 91.216% (4787/5248)\n",
      "Train Epoch: 49 | Loss: 0.260 | Acc: 91.164% (4901/5376)\n",
      "Train Epoch: 49 | Loss: 0.261 | Acc: 91.188% (5019/5504)\n",
      "Train Epoch: 49 | Loss: 0.259 | Acc: 91.229% (5138/5632)\n",
      "Train Epoch: 49 | Loss: 0.260 | Acc: 91.198% (5253/5760)\n",
      "Train Epoch: 49 | Loss: 0.264 | Acc: 91.101% (5364/5888)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 91.057% (5478/6016)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 91.048% (5594/6144)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 90.992% (5707/6272)\n",
      "Train Epoch: 49 | Loss: 0.268 | Acc: 90.906% (5818/6400)\n",
      "Train Epoch: 49 | Loss: 0.267 | Acc: 90.931% (5936/6528)\n",
      "Train Epoch: 49 | Loss: 0.266 | Acc: 90.956% (6054/6656)\n",
      "Train Epoch: 49 | Loss: 0.268 | Acc: 90.935% (6169/6784)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 90.885% (6282/6912)\n",
      "Train Epoch: 49 | Loss: 0.269 | Acc: 90.881% (6398/7040)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.890% (6515/7168)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.776% (6623/7296)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.719% (6735/7424)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.718% (6851/7552)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.781% (6972/7680)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.804% (7090/7808)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.764% (7203/7936)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.786% (7321/8064)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.820% (7440/8192)\n",
      "Train Epoch: 49 | Loss: 0.270 | Acc: 90.781% (7553/8320)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.767% (7668/8448)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.730% (7781/8576)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.717% (7896/8704)\n",
      "Train Epoch: 49 | Loss: 0.271 | Acc: 90.784% (8018/8832)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.703% (8127/8960)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.713% (8244/9088)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.668% (8356/9216)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.700% (8475/9344)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.667% (8588/9472)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.698% (8707/9600)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.687% (8822/9728)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.676% (8937/9856)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.685% (9054/9984)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.704% (9172/10112)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.674% (9285/10240)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.654% (9399/10368)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.625% (9512/10496)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.653% (9631/10624)\n",
      "Train Epoch: 49 | Loss: 0.272 | Acc: 90.606% (9742/10752)\n",
      "Train Epoch: 49 | Loss: 0.273 | Acc: 90.579% (9855/10880)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.561% (9969/11008)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.553% (10084/11136)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.563% (10201/11264)\n",
      "Train Epoch: 49 | Loss: 0.274 | Acc: 90.537% (10314/11392)\n",
      "Train Epoch: 49 | Loss: 0.276 | Acc: 90.451% (10420/11520)\n",
      "Train Epoch: 49 | Loss: 0.276 | Acc: 90.479% (10539/11648)\n",
      "Train Epoch: 49 | Loss: 0.277 | Acc: 90.430% (10649/11776)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.407% (10762/11904)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.401% (10877/12032)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.428% (10996/12160)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.422% (11111/12288)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.464% (11232/12416)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.466% (11348/12544)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.475% (11465/12672)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.461% (11579/12800)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.455% (11694/12928)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.456% (11810/13056)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.481% (11929/13184)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.437% (12039/13312)\n",
      "Train Epoch: 49 | Loss: 0.278 | Acc: 90.476% (12160/13440)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.426% (12269/13568)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.421% (12384/13696)\n",
      "Train Epoch: 49 | Loss: 0.279 | Acc: 90.422% (12500/13824)\n",
      "Train Epoch: 49 | Loss: 0.280 | Acc: 90.396% (12612/13952)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.384% (12726/14080)\n",
      "Train Epoch: 49 | Loss: 0.280 | Acc: 90.407% (12845/14208)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.395% (12959/14336)\n",
      "Train Epoch: 49 | Loss: 0.280 | Acc: 90.411% (13077/14464)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.392% (13190/14592)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.374% (13303/14720)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.335% (13413/14848)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.351% (13531/14976)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.354% (13647/15104)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.369% (13765/15232)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.391% (13884/15360)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.393% (14000/15488)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.362% (14111/15616)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.358% (14226/15744)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.304% (14333/15872)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.319% (14451/16000)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.303% (14564/16128)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.336% (14685/16256)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.356% (14804/16384)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.352% (14919/16512)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.385% (15040/16640)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.345% (15149/16768)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.329% (15262/16896)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.331% (15378/17024)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.328% (15493/17152)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.266% (15598/17280)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.263% (15713/17408)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.254% (15827/17536)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.246% (15941/17664)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.220% (16052/17792)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.229% (16169/17920)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.204% (16280/18048)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.196% (16394/18176)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.199% (16510/18304)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.196% (16625/18432)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.221% (16745/18560)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.213% (16859/18688)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.179% (16968/18816)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.171% (17082/18944)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.169% (17197/19072)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.167% (17312/19200)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.185% (17431/19328)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.193% (17548/19456)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.181% (17661/19584)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.179% (17776/19712)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.192% (17894/19840)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.189% (18009/19968)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.197% (18126/20096)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.190% (18240/20224)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.183% (18354/20352)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.220% (18477/20480)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.222% (18593/20608)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.239% (18712/20736)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.242% (18828/20864)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.234% (18942/20992)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.227% (19056/21120)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.197% (19165/21248)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.218% (19285/21376)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.211% (19399/21504)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.218% (19516/21632)\n",
      "Train Epoch: 49 | Loss: 0.288 | Acc: 90.216% (19631/21760)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.214% (19746/21888)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.234% (19866/22016)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.246% (19984/22144)\n",
      "Train Epoch: 49 | Loss: 0.287 | Acc: 90.243% (20099/22272)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.259% (20218/22400)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.270% (20336/22528)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.285% (20455/22656)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.305% (20575/22784)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.302% (20690/22912)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.312% (20808/23040)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.314% (20924/23168)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.307% (21038/23296)\n",
      "Train Epoch: 49 | Loss: 0.286 | Acc: 90.296% (21151/23424)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.332% (21275/23552)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.329% (21390/23680)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.327% (21505/23808)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.328% (21621/23936)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.338% (21739/24064)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.332% (21853/24192)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.341% (21971/24320)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.339% (22086/24448)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.356% (22206/24576)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.374% (22326/24704)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.359% (22438/24832)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.337% (22548/24960)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.322% (22660/25088)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.304% (22771/25216)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.317% (22890/25344)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.327% (23008/25472)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.348% (23129/25600)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.368% (23250/25728)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.370% (23366/25856)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.371% (23482/25984)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.384% (23601/26112)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.362% (23711/26240)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.367% (23828/26368)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.372% (23945/26496)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.377% (24062/26624)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.378% (24178/26752)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.379% (24294/26880)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.395% (24414/27008)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.408% (24533/27136)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.390% (24644/27264)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.384% (24758/27392)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.392% (24876/27520)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.390% (24991/27648)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.384% (25105/27776)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.356% (25213/27904)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.354% (25328/28032)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.359% (25445/28160)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.363% (25562/28288)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.361% (25677/28416)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.369% (25795/28544)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.374% (25912/28672)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.378% (26029/28800)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.390% (26148/28928)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.394% (26265/29056)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.392% (26380/29184)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.396% (26497/29312)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.404% (26615/29440)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.422% (26736/29568)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.433% (26855/29696)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.431% (26970/29824)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.438% (27088/29952)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.422% (27199/30080)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.426% (27316/30208)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.421% (27430/30336)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.435% (27550/30464)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.426% (27663/30592)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.426% (27779/30720)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.443% (27900/30848)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.422% (28009/30976)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.426% (28126/31104)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.436% (28245/31232)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.424% (28357/31360)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.425% (28473/31488)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.435% (28592/31616)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.433% (28707/31744)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.430% (28822/31872)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.444% (28942/32000)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.429% (29053/32128)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.433% (29170/32256)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.443% (29289/32384)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.440% (29404/32512)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.444% (29521/32640)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.460% (29642/32768)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.461% (29758/32896)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.461% (29874/33024)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.459% (29989/33152)\n",
      "Train Epoch: 49 | Loss: 0.281 | Acc: 90.445% (30100/33280)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.442% (30215/33408)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.440% (30330/33536)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.444% (30447/33664)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.453% (30566/33792)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.442% (30678/33920)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.440% (30793/34048)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.423% (30903/34176)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.438% (31024/34304)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.433% (31138/34432)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.451% (31260/34560)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.443% (31373/34688)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.453% (31492/34816)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.453% (31608/34944)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.437% (31718/35072)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.418% (31827/35200)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.421% (31944/35328)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.428% (32062/35456)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.434% (32180/35584)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.418% (32290/35712)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.410% (32403/35840)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.405% (32517/35968)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.395% (32629/36096)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.399% (32746/36224)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.391% (32859/36352)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.400% (32978/36480)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.387% (33089/36608)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.380% (33202/36736)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.375% (33316/36864)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.368% (33429/36992)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.372% (33546/37120)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.362% (33658/37248)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.371% (33777/37376)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.377% (33895/37504)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.378% (34011/37632)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.373% (34125/37760)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.369% (34239/37888)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.375% (34357/38016)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.384% (34476/38144)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.392% (34595/38272)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.411% (34718/38400)\n",
      "Train Epoch: 49 | Loss: 0.282 | Acc: 90.399% (34829/38528)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.390% (34941/38656)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.383% (35054/38784)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.378% (35168/38912)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.369% (35280/39040)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.370% (35396/39168)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.373% (35513/39296)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.376% (35630/39424)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.377% (35746/39552)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.383% (35864/39680)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.386% (35981/39808)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.377% (36093/39936)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.378% (36209/40064)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.391% (36330/40192)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.394% (36447/40320)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.390% (36561/40448)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.376% (36671/40576)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.365% (36782/40704)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.368% (36899/40832)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.381% (37020/40960)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.386% (37138/41088)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.385% (37253/41216)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.371% (37363/41344)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.377% (37481/41472)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.387% (37601/41600)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.388% (37717/41728)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.386% (37832/41856)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.387% (37948/41984)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.371% (38057/42112)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.374% (38174/42240)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.372% (38289/42368)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.385% (38410/42496)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.390% (38528/42624)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.389% (38643/42752)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.387% (38758/42880)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.379% (38870/43008)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.391% (38991/43136)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.387% (39105/43264)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.374% (39215/43392)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.375% (39331/43520)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.364% (39442/43648)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.365% (39558/43776)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.368% (39675/43904)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.359% (39787/44032)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.362% (39904/44160)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.379% (40027/44288)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.373% (40140/44416)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.362% (40251/44544)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.374% (40372/44672)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.373% (40487/44800)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.376% (40604/44928)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.379% (40721/45056)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.375% (40835/45184)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.380% (40953/45312)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.383% (41070/45440)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.384% (41186/45568)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.376% (41298/45696)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.365% (41409/45824)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.370% (41527/45952)\n",
      "Train Epoch: 49 | Loss: 0.283 | Acc: 90.373% (41644/46080)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.376% (41761/46208)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.366% (41872/46336)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.360% (41985/46464)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.365% (42103/46592)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.355% (42214/46720)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.365% (42334/46848)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.357% (42446/46976)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.358% (42562/47104)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.356% (42677/47232)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.361% (42795/47360)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.358% (42909/47488)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.360% (43026/47616)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.353% (43138/47744)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.360% (43257/47872)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.354% (43370/48000)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.355% (43486/48128)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.360% (43604/48256)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.360% (43720/48384)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.359% (43835/48512)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.362% (43952/48640)\n",
      "Train Epoch: 49 | Loss: 0.284 | Acc: 90.356% (44065/48768)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.351% (44178/48896)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.346% (44291/49024)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.334% (44401/49152)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.341% (44520/49280)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.340% (44635/49408)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.336% (44749/49536)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.339% (44866/49664)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.348% (44986/49792)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.341% (45098/49920)\n",
      "Train Epoch: 49 | Loss: 0.285 | Acc: 90.348% (45174/50000)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 49 | Loss: 0.349 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 49 | Loss: 0.366 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 49 | Loss: 0.374 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 49 | Loss: 0.356 | Acc: 87.400% (437/500)\n",
      "Test Epoch: 49 | Loss: 0.325 | Acc: 88.333% (530/600)\n",
      "Test Epoch: 49 | Loss: 0.324 | Acc: 88.143% (617/700)\n",
      "Test Epoch: 49 | Loss: 0.346 | Acc: 87.250% (698/800)\n",
      "Test Epoch: 49 | Loss: 0.363 | Acc: 87.222% (785/900)\n",
      "Test Epoch: 49 | Loss: 0.364 | Acc: 87.600% (876/1000)\n",
      "Test Epoch: 49 | Loss: 0.371 | Acc: 87.091% (958/1100)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 86.750% (1041/1200)\n",
      "Test Epoch: 49 | Loss: 0.364 | Acc: 87.000% (1131/1300)\n",
      "Test Epoch: 49 | Loss: 0.366 | Acc: 86.857% (1216/1400)\n",
      "Test Epoch: 49 | Loss: 0.361 | Acc: 86.733% (1301/1500)\n",
      "Test Epoch: 49 | Loss: 0.357 | Acc: 87.062% (1393/1600)\n",
      "Test Epoch: 49 | Loss: 0.355 | Acc: 87.294% (1484/1700)\n",
      "Test Epoch: 49 | Loss: 0.360 | Acc: 87.222% (1570/1800)\n",
      "Test Epoch: 49 | Loss: 0.356 | Acc: 87.368% (1660/1900)\n",
      "Test Epoch: 49 | Loss: 0.362 | Acc: 87.300% (1746/2000)\n",
      "Test Epoch: 49 | Loss: 0.364 | Acc: 87.095% (1829/2100)\n",
      "Test Epoch: 49 | Loss: 0.362 | Acc: 87.182% (1918/2200)\n",
      "Test Epoch: 49 | Loss: 0.375 | Acc: 87.130% (2004/2300)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 87.167% (2092/2400)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 87.240% (2181/2500)\n",
      "Test Epoch: 49 | Loss: 0.395 | Acc: 87.038% (2263/2600)\n",
      "Test Epoch: 49 | Loss: 0.393 | Acc: 87.148% (2353/2700)\n",
      "Test Epoch: 49 | Loss: 0.394 | Acc: 87.036% (2437/2800)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 87.069% (2525/2900)\n",
      "Test Epoch: 49 | Loss: 0.397 | Acc: 87.000% (2610/3000)\n",
      "Test Epoch: 49 | Loss: 0.400 | Acc: 86.968% (2696/3100)\n",
      "Test Epoch: 49 | Loss: 0.396 | Acc: 87.156% (2789/3200)\n",
      "Test Epoch: 49 | Loss: 0.397 | Acc: 87.182% (2877/3300)\n",
      "Test Epoch: 49 | Loss: 0.395 | Acc: 87.324% (2969/3400)\n",
      "Test Epoch: 49 | Loss: 0.397 | Acc: 87.257% (3054/3500)\n",
      "Test Epoch: 49 | Loss: 0.396 | Acc: 87.306% (3143/3600)\n",
      "Test Epoch: 49 | Loss: 0.397 | Acc: 87.189% (3226/3700)\n",
      "Test Epoch: 49 | Loss: 0.399 | Acc: 87.079% (3309/3800)\n",
      "Test Epoch: 49 | Loss: 0.393 | Acc: 87.231% (3402/3900)\n",
      "Test Epoch: 49 | Loss: 0.395 | Acc: 87.225% (3489/4000)\n",
      "Test Epoch: 49 | Loss: 0.396 | Acc: 87.146% (3573/4100)\n",
      "Test Epoch: 49 | Loss: 0.395 | Acc: 87.119% (3659/4200)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 87.256% (3752/4300)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 87.341% (3843/4400)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 87.422% (3934/4500)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 87.326% (4017/4600)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 87.383% (4107/4700)\n",
      "Test Epoch: 49 | Loss: 0.392 | Acc: 87.354% (4193/4800)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 87.429% (4284/4900)\n",
      "Test Epoch: 49 | Loss: 0.391 | Acc: 87.340% (4367/5000)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 87.373% (4456/5100)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 87.365% (4543/5200)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 87.340% (4629/5300)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 87.426% (4721/5400)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 87.364% (4805/5500)\n",
      "Test Epoch: 49 | Loss: 0.390 | Acc: 87.286% (4888/5600)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 87.351% (4979/5700)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 87.397% (5069/5800)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 87.339% (5153/5900)\n",
      "Test Epoch: 49 | Loss: 0.389 | Acc: 87.317% (5239/6000)\n",
      "Test Epoch: 49 | Loss: 0.388 | Acc: 87.344% (5328/6100)\n",
      "Test Epoch: 49 | Loss: 0.387 | Acc: 87.355% (5416/6200)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 87.444% (5509/6300)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.469% (5598/6400)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.477% (5686/6500)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 87.485% (5774/6600)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 87.537% (5865/6700)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.485% (5949/6800)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.522% (6039/6900)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 87.571% (6130/7000)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 87.507% (6213/7100)\n",
      "Test Epoch: 49 | Loss: 0.387 | Acc: 87.472% (6298/7200)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 87.534% (6390/7300)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 87.541% (6478/7400)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.533% (6565/7500)\n",
      "Test Epoch: 49 | Loss: 0.384 | Acc: 87.539% (6653/7600)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 87.519% (6739/7700)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 87.538% (6828/7800)\n",
      "Test Epoch: 49 | Loss: 0.386 | Acc: 87.544% (6916/7900)\n",
      "Test Epoch: 49 | Loss: 0.385 | Acc: 87.537% (7003/8000)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 87.593% (7095/8100)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 87.634% (7186/8200)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 87.639% (7274/8300)\n",
      "Test Epoch: 49 | Loss: 0.379 | Acc: 87.679% (7365/8400)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 87.671% (7452/8500)\n",
      "Test Epoch: 49 | Loss: 0.383 | Acc: 87.616% (7535/8600)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 87.632% (7624/8700)\n",
      "Test Epoch: 49 | Loss: 0.382 | Acc: 87.648% (7713/8800)\n",
      "Test Epoch: 49 | Loss: 0.381 | Acc: 87.697% (7805/8900)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 87.689% (7892/9000)\n",
      "Test Epoch: 49 | Loss: 0.380 | Acc: 87.703% (7981/9100)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 87.772% (8075/9200)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 87.785% (8164/9300)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 87.830% (8256/9400)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 87.832% (8344/9500)\n",
      "Test Epoch: 49 | Loss: 0.376 | Acc: 87.844% (8433/9600)\n",
      "Test Epoch: 49 | Loss: 0.376 | Acc: 87.866% (8523/9700)\n",
      "Test Epoch: 49 | Loss: 0.376 | Acc: 87.857% (8610/9800)\n",
      "Test Epoch: 49 | Loss: 0.377 | Acc: 87.848% (8697/9900)\n",
      "Test Epoch: 49 | Loss: 0.378 | Acc: 87.830% (8783/10000)\n",
      "\n",
      "Epoch: 50\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 88.672% (227/256)\n",
      "Train Epoch: 50 | Loss: 0.287 | Acc: 89.323% (343/384)\n",
      "Train Epoch: 50 | Loss: 0.281 | Acc: 89.258% (457/512)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 90.000% (576/640)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 89.974% (691/768)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.402% (810/896)\n",
      "Train Epoch: 50 | Loss: 0.248 | Acc: 90.918% (931/1024)\n",
      "Train Epoch: 50 | Loss: 0.243 | Acc: 91.146% (1050/1152)\n",
      "Train Epoch: 50 | Loss: 0.241 | Acc: 91.172% (1167/1280)\n",
      "Train Epoch: 50 | Loss: 0.247 | Acc: 90.980% (1281/1408)\n",
      "Train Epoch: 50 | Loss: 0.250 | Acc: 91.081% (1399/1536)\n",
      "Train Epoch: 50 | Loss: 0.252 | Acc: 91.106% (1516/1664)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.071% (1632/1792)\n",
      "Train Epoch: 50 | Loss: 0.254 | Acc: 90.990% (1747/1920)\n",
      "Train Epoch: 50 | Loss: 0.257 | Acc: 90.820% (1860/2048)\n",
      "Train Epoch: 50 | Loss: 0.254 | Acc: 90.993% (1980/2176)\n",
      "Train Epoch: 50 | Loss: 0.255 | Acc: 90.885% (2094/2304)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 90.995% (2213/2432)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.016% (2330/2560)\n",
      "Train Epoch: 50 | Loss: 0.251 | Acc: 91.183% (2451/2688)\n",
      "Train Epoch: 50 | Loss: 0.248 | Acc: 91.300% (2571/2816)\n",
      "Train Epoch: 50 | Loss: 0.249 | Acc: 91.202% (2685/2944)\n",
      "Train Epoch: 50 | Loss: 0.250 | Acc: 91.178% (2801/3072)\n",
      "Train Epoch: 50 | Loss: 0.252 | Acc: 91.094% (2915/3200)\n",
      "Train Epoch: 50 | Loss: 0.252 | Acc: 91.106% (3032/3328)\n",
      "Train Epoch: 50 | Loss: 0.251 | Acc: 91.175% (3151/3456)\n",
      "Train Epoch: 50 | Loss: 0.254 | Acc: 91.099% (3265/3584)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.110% (3382/3712)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.146% (3500/3840)\n",
      "Train Epoch: 50 | Loss: 0.251 | Acc: 91.230% (3620/3968)\n",
      "Train Epoch: 50 | Loss: 0.252 | Acc: 91.235% (3737/4096)\n",
      "Train Epoch: 50 | Loss: 0.256 | Acc: 91.075% (3847/4224)\n",
      "Train Epoch: 50 | Loss: 0.255 | Acc: 91.131% (3966/4352)\n",
      "Train Epoch: 50 | Loss: 0.255 | Acc: 91.049% (4079/4480)\n",
      "Train Epoch: 50 | Loss: 0.254 | Acc: 91.168% (4201/4608)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.174% (4318/4736)\n",
      "Train Epoch: 50 | Loss: 0.254 | Acc: 91.139% (4433/4864)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.146% (4550/4992)\n",
      "Train Epoch: 50 | Loss: 0.252 | Acc: 91.133% (4666/5120)\n",
      "Train Epoch: 50 | Loss: 0.253 | Acc: 91.082% (4780/5248)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.923% (4888/5376)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.916% (5004/5504)\n",
      "Train Epoch: 50 | Loss: 0.258 | Acc: 90.962% (5123/5632)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.955% (5239/5760)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.914% (5353/5888)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.908% (5469/6016)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.902% (5585/6144)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.912% (5702/6272)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.891% (5817/6400)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.916% (5935/6528)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.880% (6049/6656)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.890% (6166/6784)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.914% (6284/6912)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.852% (6396/7040)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.862% (6513/7168)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.803% (6625/7296)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.787% (6740/7424)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.837% (6860/7552)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.846% (6977/7680)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.907% (7098/7808)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.890% (7213/7936)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.910% (7331/8064)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.930% (7449/8192)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.974% (7569/8320)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.980% (7686/8448)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.940% (7799/8576)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.889% (7911/8704)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.897% (8028/8832)\n",
      "Train Epoch: 50 | Loss: 0.259 | Acc: 90.904% (8145/8960)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.889% (8260/9088)\n",
      "Train Epoch: 50 | Loss: 0.260 | Acc: 90.885% (8376/9216)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.871% (8491/9344)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.857% (8606/9472)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.844% (8721/9600)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.831% (8836/9728)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.848% (8954/9856)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.865% (9072/9984)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.833% (9185/10112)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.879% (9306/10240)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.914% (9426/10368)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.930% (9544/10496)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.907% (9658/10624)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.932% (9777/10752)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 90.928% (9893/10880)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 90.979% (10015/11008)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 90.993% (10133/11136)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 91.042% (10255/11264)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 91.038% (10371/11392)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 91.050% (10489/11520)\n",
      "Train Epoch: 50 | Loss: 0.261 | Acc: 91.037% (10604/11648)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.033% (10720/11776)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 91.020% (10835/11904)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 91.041% (10954/12032)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.077% (11075/12160)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.081% (11192/12288)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 91.100% (11311/12416)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.111% (11429/12544)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.138% (11549/12672)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.117% (11663/12800)\n",
      "Train Epoch: 50 | Loss: 0.262 | Acc: 91.128% (11781/12928)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 91.092% (11893/13056)\n",
      "Train Epoch: 50 | Loss: 0.263 | Acc: 91.073% (12007/13184)\n",
      "Train Epoch: 50 | Loss: 0.265 | Acc: 90.993% (12113/13312)\n",
      "Train Epoch: 50 | Loss: 0.265 | Acc: 91.019% (12233/13440)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 90.994% (12346/13568)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 91.041% (12469/13696)\n",
      "Train Epoch: 50 | Loss: 0.265 | Acc: 91.059% (12588/13824)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 91.019% (12699/13952)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 90.994% (12812/14080)\n",
      "Train Epoch: 50 | Loss: 0.266 | Acc: 90.991% (12928/14208)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.939% (13037/14336)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.867% (13143/14464)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.879% (13261/14592)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.904% (13381/14720)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.888% (13495/14848)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.885% (13611/14976)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.877% (13726/15104)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.888% (13844/15232)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.885% (13960/15360)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.916% (14081/15488)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.900% (14195/15616)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.898% (14311/15744)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.902% (14428/15872)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.888% (14542/16000)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.885% (14658/16128)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.890% (14775/16256)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.875% (14889/16384)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.891% (15008/16512)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.901% (15126/16640)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.875% (15238/16768)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.874% (15354/16896)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.878% (15471/17024)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.870% (15586/17152)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.856% (15700/17280)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.838% (15813/17408)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.836% (15929/17536)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.817% (16042/17664)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.822% (16159/17792)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.854% (16281/17920)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.863% (16399/18048)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.851% (16513/18176)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.822% (16624/18304)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.842% (16744/18432)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.841% (16860/18560)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.839% (16976/18688)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.848% (17094/18816)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.868% (17214/18944)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.892% (17335/19072)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.891% (17451/19200)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.832% (17556/19328)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.841% (17674/19456)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.860% (17794/19584)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.823% (17903/19712)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.817% (18018/19840)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.825% (18136/19968)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.809% (18249/20096)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.798% (18363/20224)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.802% (18480/20352)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.776% (18591/20480)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.785% (18709/20608)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.784% (18825/20736)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.788% (18942/20864)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.806% (19062/20992)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.791% (19175/21120)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.818% (19297/21248)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.831% (19416/21376)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.858% (19538/21504)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.842% (19651/21632)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.836% (19766/21760)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.844% (19884/21888)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.834% (19998/22016)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.824% (20112/22144)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.818% (20227/22272)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.821% (20344/22400)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.829% (20462/22528)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.828% (20578/22656)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.849% (20699/22784)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.839% (20813/22912)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.816% (20924/23040)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.806% (21038/23168)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.771% (21146/23296)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.783% (21265/23424)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.782% (21381/23552)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.764% (21493/23680)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.776% (21612/23808)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.784% (21730/23936)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.770% (21843/24064)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.794% (21965/24192)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.810% (22085/24320)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.825% (22205/24448)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.828% (22322/24576)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.831% (22439/24704)\n",
      "Train Epoch: 50 | Loss: 0.267 | Acc: 90.842% (22558/24832)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.825% (22670/24960)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.812% (22783/25088)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.807% (22898/25216)\n",
      "Train Epoch: 50 | Loss: 0.268 | Acc: 90.814% (23016/25344)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.798% (23128/25472)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.773% (23238/25600)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.780% (23356/25728)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.760% (23467/25856)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.756% (23582/25984)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.748% (23696/26112)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.747% (23812/26240)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.750% (23929/26368)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.750% (24045/26496)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.726% (24155/26624)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.711% (24267/26752)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.707% (24382/26880)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.706% (24498/27008)\n",
      "Train Epoch: 50 | Loss: 0.269 | Acc: 90.717% (24617/27136)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.706% (24730/27264)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.705% (24846/27392)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.701% (24961/27520)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.690% (25074/27648)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.683% (25188/27776)\n",
      "Train Epoch: 50 | Loss: 0.270 | Acc: 90.664% (25299/27904)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.657% (25413/28032)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.650% (25527/28160)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.636% (25639/28288)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.639% (25756/28416)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.629% (25869/28544)\n",
      "Train Epoch: 50 | Loss: 0.271 | Acc: 90.632% (25986/28672)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.628% (26101/28800)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.632% (26218/28928)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.615% (26329/29056)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.594% (26439/29184)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.591% (26554/29312)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.591% (26670/29440)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.598% (26788/29568)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.612% (26908/29696)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.612% (27024/29824)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.612% (27140/29952)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.598% (27252/30080)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.602% (27369/30208)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.599% (27484/30336)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.592% (27598/30464)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.592% (27714/30592)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.599% (27832/30720)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.599% (27948/30848)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.606% (28066/30976)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.631% (28190/31104)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.635% (28307/31232)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.628% (28421/31360)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.635% (28539/31488)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.641% (28657/31616)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.622% (28767/31744)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.631% (28886/31872)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.647% (29007/32000)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.641% (29121/32128)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.625% (29232/32256)\n",
      "Train Epoch: 50 | Loss: 0.272 | Acc: 90.634% (29351/32384)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.628% (29465/32512)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.628% (29581/32640)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.613% (29692/32768)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.613% (29808/32896)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.610% (29923/33024)\n",
      "Train Epoch: 50 | Loss: 0.273 | Acc: 90.595% (30034/33152)\n",
      "Train Epoch: 50 | Loss: 0.274 | Acc: 90.595% (30150/33280)\n",
      "Train Epoch: 50 | Loss: 0.274 | Acc: 90.595% (30266/33408)\n",
      "Train Epoch: 50 | Loss: 0.274 | Acc: 90.589% (30380/33536)\n",
      "Train Epoch: 50 | Loss: 0.274 | Acc: 90.595% (30498/33664)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.589% (30612/33792)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.572% (30722/33920)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.563% (30835/34048)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.558% (30949/34176)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.546% (31061/34304)\n",
      "Train Epoch: 50 | Loss: 0.275 | Acc: 90.547% (31177/34432)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.527% (31286/34560)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.521% (31400/34688)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.522% (31516/34816)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.511% (31628/34944)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.508% (31743/35072)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.523% (31864/35200)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.534% (31984/35328)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.521% (32095/35456)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.529% (32214/35584)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.533% (32331/35712)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.516% (32441/35840)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.517% (32557/35968)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.514% (32672/36096)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.506% (32785/36224)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.523% (32907/36352)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.532% (33026/36480)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.527% (33140/36608)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.530% (33257/36736)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.527% (33372/36864)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.509% (33481/36992)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.504% (33595/37120)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.502% (33710/37248)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.494% (33823/37376)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.489% (33937/37504)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.492% (34054/37632)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.479% (34165/37760)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.472% (34278/37888)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.470% (34393/38016)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.478% (34512/38144)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.479% (34628/38272)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.477% (34743/38400)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.472% (34857/38528)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.467% (34971/38656)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.460% (35084/38784)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.466% (35202/38912)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.474% (35321/39040)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.485% (35441/39168)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.480% (35555/39296)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.483% (35672/39424)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.486% (35789/39552)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.484% (35904/39680)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.482% (36019/39808)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.465% (36128/39936)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.470% (36246/40064)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.463% (36359/40192)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.441% (36466/40320)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.440% (36581/40448)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.450% (36701/40576)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.453% (36818/40704)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.454% (36934/40832)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.454% (37050/40960)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.445% (37162/41088)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.455% (37282/41216)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.463% (37401/41344)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.454% (37513/41472)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.442% (37624/41600)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.431% (37735/41728)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.443% (37856/41856)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.444% (37972/41984)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.445% (38088/42112)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.455% (38208/42240)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.446% (38320/42368)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.434% (38431/42496)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.437% (38548/42624)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.436% (38663/42752)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.438% (38780/42880)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.437% (38895/43008)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.435% (39010/43136)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.435% (39126/43264)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.443% (39245/43392)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.441% (39360/43520)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.433% (39472/43648)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.429% (39586/43776)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.431% (39703/43904)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.430% (39818/44032)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.423% (39931/44160)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.433% (40051/44288)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.443% (40171/44416)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.434% (40283/44544)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.441% (40402/44672)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.431% (40513/44800)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.431% (40629/44928)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.434% (40746/45056)\n",
      "Train Epoch: 50 | Loss: 0.276 | Acc: 90.426% (40858/45184)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.424% (40973/45312)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.412% (41083/45440)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.412% (41199/45568)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.411% (41314/45696)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.409% (41429/45824)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.403% (41542/45952)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.417% (41664/46080)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.432% (41787/46208)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.442% (41907/46336)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.438% (42021/46464)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.434% (42135/46592)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.426% (42247/46720)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.426% (42363/46848)\n",
      "Train Epoch: 50 | Loss: 0.277 | Acc: 90.421% (42476/46976)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.406% (42585/47104)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.403% (42699/47232)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.397% (42812/47360)\n",
      "Train Epoch: 50 | Loss: 0.278 | Acc: 90.398% (42928/47488)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.390% (43040/47616)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.386% (43154/47744)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.381% (43267/47872)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.383% (43384/48000)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.380% (43498/48128)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.385% (43616/48256)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.381% (43730/48384)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.388% (43849/48512)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.370% (43956/48640)\n",
      "Train Epoch: 50 | Loss: 0.279 | Acc: 90.363% (44068/48768)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.347% (44176/48896)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.339% (44288/49024)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.324% (44396/49152)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.317% (44508/49280)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.327% (44629/49408)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.326% (44744/49536)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.325% (44859/49664)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.328% (44976/49792)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.331% (45093/49920)\n",
      "Train Epoch: 50 | Loss: 0.280 | Acc: 90.332% (45166/50000)\n",
      "Test Epoch: 50 | Loss: 0.342 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 50 | Loss: 0.380 | Acc: 86.000% (172/200)\n",
      "Test Epoch: 50 | Loss: 0.342 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 50 | Loss: 0.327 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 50 | Loss: 0.313 | Acc: 88.000% (440/500)\n",
      "Test Epoch: 50 | Loss: 0.311 | Acc: 88.000% (528/600)\n",
      "Test Epoch: 50 | Loss: 0.314 | Acc: 88.143% (617/700)\n",
      "Test Epoch: 50 | Loss: 0.335 | Acc: 87.875% (703/800)\n",
      "Test Epoch: 50 | Loss: 0.338 | Acc: 87.889% (791/900)\n",
      "Test Epoch: 50 | Loss: 0.348 | Acc: 87.800% (878/1000)\n",
      "Test Epoch: 50 | Loss: 0.347 | Acc: 87.909% (967/1100)\n",
      "Test Epoch: 50 | Loss: 0.347 | Acc: 88.250% (1059/1200)\n",
      "Test Epoch: 50 | Loss: 0.340 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 50 | Loss: 0.340 | Acc: 88.286% (1236/1400)\n",
      "Test Epoch: 50 | Loss: 0.337 | Acc: 88.600% (1329/1500)\n",
      "Test Epoch: 50 | Loss: 0.337 | Acc: 88.500% (1416/1600)\n",
      "Test Epoch: 50 | Loss: 0.340 | Acc: 88.412% (1503/1700)\n",
      "Test Epoch: 50 | Loss: 0.350 | Acc: 88.000% (1584/1800)\n",
      "Test Epoch: 50 | Loss: 0.344 | Acc: 88.211% (1676/1900)\n",
      "Test Epoch: 50 | Loss: 0.349 | Acc: 88.250% (1765/2000)\n",
      "Test Epoch: 50 | Loss: 0.352 | Acc: 88.048% (1849/2100)\n",
      "Test Epoch: 50 | Loss: 0.348 | Acc: 88.136% (1939/2200)\n",
      "Test Epoch: 50 | Loss: 0.352 | Acc: 88.000% (2024/2300)\n",
      "Test Epoch: 50 | Loss: 0.351 | Acc: 88.083% (2114/2400)\n",
      "Test Epoch: 50 | Loss: 0.360 | Acc: 87.840% (2196/2500)\n",
      "Test Epoch: 50 | Loss: 0.369 | Acc: 87.769% (2282/2600)\n",
      "Test Epoch: 50 | Loss: 0.371 | Acc: 87.704% (2368/2700)\n",
      "Test Epoch: 50 | Loss: 0.373 | Acc: 87.750% (2457/2800)\n",
      "Test Epoch: 50 | Loss: 0.379 | Acc: 87.724% (2544/2900)\n",
      "Test Epoch: 50 | Loss: 0.386 | Acc: 87.500% (2625/3000)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.387% (2709/3100)\n",
      "Test Epoch: 50 | Loss: 0.385 | Acc: 87.562% (2802/3200)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.545% (2889/3300)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.500% (2975/3400)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.457% (3061/3500)\n",
      "Test Epoch: 50 | Loss: 0.383 | Acc: 87.639% (3155/3600)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 87.541% (3239/3700)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 87.395% (3321/3800)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.564% (3415/3900)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.650% (3506/4000)\n",
      "Test Epoch: 50 | Loss: 0.386 | Acc: 87.610% (3592/4100)\n",
      "Test Epoch: 50 | Loss: 0.388 | Acc: 87.524% (3676/4200)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 87.558% (3765/4300)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.659% (3857/4400)\n",
      "Test Epoch: 50 | Loss: 0.383 | Acc: 87.711% (3947/4500)\n",
      "Test Epoch: 50 | Loss: 0.383 | Acc: 87.674% (4033/4600)\n",
      "Test Epoch: 50 | Loss: 0.381 | Acc: 87.681% (4121/4700)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.562% (4203/4800)\n",
      "Test Epoch: 50 | Loss: 0.384 | Acc: 87.592% (4292/4900)\n",
      "Test Epoch: 50 | Loss: 0.388 | Acc: 87.420% (4371/5000)\n",
      "Test Epoch: 50 | Loss: 0.387 | Acc: 87.490% (4462/5100)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.462% (4548/5200)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 87.396% (4632/5300)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.500% (4725/5400)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.455% (4810/5500)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.393% (4894/5600)\n",
      "Test Epoch: 50 | Loss: 0.396 | Acc: 87.421% (4983/5700)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.483% (5074/5800)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.458% (5160/5900)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.450% (5247/6000)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.393% (5331/6100)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.403% (5419/6200)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.460% (5510/6300)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 87.531% (5602/6400)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.523% (5689/6500)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.485% (5774/6600)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.493% (5862/6700)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.397% (5943/6800)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.391% (6030/6900)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.300% (6111/7000)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.296% (6198/7100)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.264% (6283/7200)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.315% (6374/7300)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 87.338% (6463/7400)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 87.387% (6554/7500)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.408% (6643/7600)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.364% (6727/7700)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.397% (6817/7800)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.405% (6905/7900)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.425% (6994/8000)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.481% (7086/8100)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.427% (7169/8200)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.386% (7253/8300)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.405% (7342/8400)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.341% (7424/8500)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.302% (7508/8600)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.322% (7597/8700)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.341% (7686/8800)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.281% (7768/8900)\n",
      "Test Epoch: 50 | Loss: 0.395 | Acc: 87.278% (7855/9000)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.319% (7946/9100)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.402% (8041/9200)\n",
      "Test Epoch: 50 | Loss: 0.394 | Acc: 87.419% (8130/9300)\n",
      "Test Epoch: 50 | Loss: 0.393 | Acc: 87.404% (8216/9400)\n",
      "Test Epoch: 50 | Loss: 0.392 | Acc: 87.421% (8305/9500)\n",
      "Test Epoch: 50 | Loss: 0.391 | Acc: 87.438% (8394/9600)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.474% (8485/9700)\n",
      "Test Epoch: 50 | Loss: 0.389 | Acc: 87.520% (8577/9800)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.515% (8664/9900)\n",
      "Test Epoch: 50 | Loss: 0.390 | Acc: 87.510% (8751/10000)\n",
      "\n",
      "Epoch: 51\n",
      "Train Epoch: 51 | Loss: 0.407 | Acc: 87.500% (112/128)\n",
      "Train Epoch: 51 | Loss: 0.291 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 51 | Loss: 0.263 | Acc: 91.927% (353/384)\n",
      "Train Epoch: 51 | Loss: 0.249 | Acc: 91.797% (470/512)\n",
      "Train Epoch: 51 | Loss: 0.270 | Acc: 90.312% (578/640)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.625% (696/768)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 89.955% (806/896)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.039% (922/1024)\n",
      "Train Epoch: 51 | Loss: 0.263 | Acc: 90.625% (1044/1152)\n",
      "Train Epoch: 51 | Loss: 0.262 | Acc: 90.781% (1162/1280)\n",
      "Train Epoch: 51 | Loss: 0.267 | Acc: 90.625% (1276/1408)\n",
      "Train Epoch: 51 | Loss: 0.263 | Acc: 90.690% (1393/1536)\n",
      "Train Epoch: 51 | Loss: 0.269 | Acc: 90.505% (1506/1664)\n",
      "Train Epoch: 51 | Loss: 0.270 | Acc: 90.458% (1621/1792)\n",
      "Train Epoch: 51 | Loss: 0.265 | Acc: 90.729% (1742/1920)\n",
      "Train Epoch: 51 | Loss: 0.266 | Acc: 90.674% (1857/2048)\n",
      "Train Epoch: 51 | Loss: 0.270 | Acc: 90.487% (1969/2176)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.365% (2082/2304)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.214% (2194/2432)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.352% (2313/2560)\n",
      "Train Epoch: 51 | Loss: 0.273 | Acc: 90.402% (2430/2688)\n",
      "Train Epoch: 51 | Loss: 0.271 | Acc: 90.483% (2548/2816)\n",
      "Train Epoch: 51 | Loss: 0.273 | Acc: 90.557% (2666/2944)\n",
      "Train Epoch: 51 | Loss: 0.273 | Acc: 90.592% (2783/3072)\n",
      "Train Epoch: 51 | Loss: 0.273 | Acc: 90.531% (2897/3200)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.415% (3009/3328)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.307% (3121/3456)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.151% (3231/3584)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.059% (3343/3712)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 89.974% (3455/3840)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.020% (3572/3968)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.088% (3690/4096)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.057% (3804/4224)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.211% (3926/4352)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.290% (4045/4480)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.343% (4163/4608)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.351% (4279/4736)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.214% (4388/4864)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.124% (4499/4992)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.234% (4620/5120)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.320% (4740/5248)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.197% (4849/5376)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.243% (4967/5504)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.234% (5082/5632)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.243% (5198/5760)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.200% (5311/5888)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.110% (5421/6016)\n",
      "Train Epoch: 51 | Loss: 0.287 | Acc: 90.039% (5532/6144)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.163% (5655/6272)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.094% (5766/6400)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.074% (5880/6528)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.159% (6001/6656)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.183% (6118/6784)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.148% (6231/6912)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.142% (6346/7040)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.137% (6461/7168)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.186% (6580/7296)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.127% (6691/7424)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.109% (6805/7552)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.169% (6925/7680)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.177% (7041/7808)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.146% (7154/7936)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.216% (7275/8064)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.247% (7393/8192)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.240% (7508/8320)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.234% (7623/8448)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.194% (7735/8576)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.142% (7846/8704)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.172% (7964/8832)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.190% (8081/8960)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.218% (8199/9088)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.245% (8317/9216)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.229% (8431/9344)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.224% (8546/9472)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.229% (8662/9600)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.132% (8768/9728)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.128% (8883/9856)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.094% (8995/9984)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.081% (9109/10112)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.049% (9221/10240)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.056% (9337/10368)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.101% (9457/10496)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.126% (9575/10624)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.141% (9692/10752)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.165% (9810/10880)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.207% (9930/11008)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.221% (10047/11136)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.279% (10169/11264)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.230% (10279/11392)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.174% (10388/11520)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.187% (10505/11648)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.217% (10624/11776)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.180% (10735/11904)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.168% (10849/12032)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.173% (10965/12160)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.234% (11088/12288)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.230% (11203/12416)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.258% (11322/12544)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.278% (11440/12672)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.281% (11556/12800)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.246% (11667/12928)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.273% (11786/13056)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.276% (11902/13184)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.294% (12020/13312)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.290% (12135/13440)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.279% (12249/13568)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.253% (12361/13696)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.307% (12484/13824)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.295% (12598/13952)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.270% (12710/14080)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.245% (12822/14208)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.269% (12941/14336)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.272% (13057/14464)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.282% (13174/14592)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.279% (13289/14720)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.228% (13397/14848)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.218% (13511/14976)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.221% (13627/15104)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.225% (13743/15232)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.247% (13862/15360)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.283% (13983/15488)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.286% (14099/15616)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.333% (14222/15744)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.379% (14345/15872)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.381% (14461/16000)\n",
      "Train Epoch: 51 | Loss: 0.273 | Acc: 90.402% (14580/16128)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.373% (14691/16256)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.369% (14806/16384)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.377% (14923/16512)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.379% (15039/16640)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.386% (15156/16768)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.406% (15275/16896)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.414% (15392/17024)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.380% (15502/17152)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.347% (15612/17280)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.355% (15729/17408)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.380% (15849/17536)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.359% (15961/17664)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.344% (16074/17792)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.352% (16191/17920)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.376% (16311/18048)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.399% (16431/18176)\n",
      "Train Epoch: 51 | Loss: 0.274 | Acc: 90.385% (16544/18304)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.359% (16655/18432)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.350% (16769/18560)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.331% (16881/18688)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.322% (16995/18816)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.335% (17113/18944)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.352% (17232/19072)\n",
      "Train Epoch: 51 | Loss: 0.275 | Acc: 90.349% (17347/19200)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.320% (17457/19328)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.311% (17571/19456)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.308% (17686/19584)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.310% (17802/19712)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.312% (17918/19840)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.289% (18029/19968)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.282% (18143/20096)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.269% (18256/20224)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.266% (18371/20352)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.264% (18486/20480)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.251% (18599/20608)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.239% (18712/20736)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.246% (18829/20864)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.239% (18943/20992)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.246% (19060/21120)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.253% (19177/21248)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.255% (19293/21376)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.234% (19404/21504)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.251% (19523/21632)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.239% (19636/21760)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.255% (19755/21888)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.271% (19874/22016)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.268% (19989/22144)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.261% (20103/22272)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.268% (20220/22400)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.257% (20333/22528)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.254% (20448/22656)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.265% (20566/22784)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.267% (20682/22912)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.260% (20796/23040)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.258% (20911/23168)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.269% (21029/23296)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.296% (21151/23424)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.273% (21261/23552)\n",
      "Train Epoch: 51 | Loss: 0.276 | Acc: 90.279% (21378/23680)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.251% (21487/23808)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.224% (21596/23936)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.214% (21709/24064)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.241% (21831/24192)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.259% (21951/24320)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.257% (22066/24448)\n",
      "Train Epoch: 51 | Loss: 0.277 | Acc: 90.255% (22181/24576)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.249% (22295/24704)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.238% (22408/24832)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.240% (22524/24960)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.202% (22630/25088)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.217% (22749/25216)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.250% (22873/25344)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.240% (22986/25472)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.246% (23103/25600)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.260% (23222/25728)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.254% (23336/25856)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.256% (23452/25984)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.250% (23566/26112)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.259% (23684/26240)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.231% (23792/26368)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.232% (23908/26496)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.234% (24024/26624)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.247% (24143/26752)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.260% (24262/26880)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.251% (24375/27008)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.249% (24490/27136)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.222% (24598/27264)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.216% (24712/27392)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.236% (24833/27520)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.245% (24951/27648)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.243% (25066/27776)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.242% (25181/27904)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.254% (25300/28032)\n",
      "Train Epoch: 51 | Loss: 0.278 | Acc: 90.259% (25417/28160)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.247% (25529/28288)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.241% (25643/28416)\n",
      "Train Epoch: 51 | Loss: 0.279 | Acc: 90.240% (25758/28544)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.234% (25872/28672)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.222% (25984/28800)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.231% (26102/28928)\n",
      "Train Epoch: 51 | Loss: 0.280 | Acc: 90.226% (26216/29056)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.207% (26326/29184)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.212% (26443/29312)\n",
      "Train Epoch: 51 | Loss: 0.281 | Acc: 90.211% (26558/29440)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.182% (26665/29568)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.180% (26780/29696)\n",
      "Train Epoch: 51 | Loss: 0.282 | Acc: 90.182% (26896/29824)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.174% (27009/29952)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.150% (27117/30080)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.138% (27229/30208)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.150% (27348/30336)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.126% (27456/30464)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.128% (27572/30592)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.143% (27692/30720)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.148% (27809/30848)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.154% (27926/30976)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.152% (28041/31104)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.158% (28158/31232)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.163% (28275/31360)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.158% (28389/31488)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.144% (28500/31616)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.156% (28619/31744)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.158% (28735/31872)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.153% (28849/32000)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.149% (28963/32128)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.135% (29074/32256)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.143% (29192/32384)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.154% (29311/32512)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.172% (29432/32640)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.179% (29550/32768)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.172% (29663/32896)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.183% (29782/33024)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.173% (29894/33152)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.159% (30005/33280)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.149% (30117/33408)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.154% (30234/33536)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.156% (30350/33664)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.154% (30465/33792)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.136% (30574/33920)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.140% (30691/34048)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.148% (30809/34176)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.150% (30925/34304)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.155% (31042/34432)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.133% (31150/34560)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.121% (31261/34688)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.119% (31376/34816)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.141% (31499/34944)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.143% (31615/35072)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.151% (31733/35200)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.166% (31854/35328)\n",
      "Train Epoch: 51 | Loss: 0.285 | Acc: 90.168% (31970/35456)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.175% (32088/35584)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.185% (32207/35712)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.187% (32323/35840)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.208% (32446/35968)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.190% (32555/36096)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.205% (32676/36224)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.212% (32794/36352)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.219% (32912/36480)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.207% (33023/36608)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.209% (33139/36736)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.199% (33251/36864)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.203% (33368/36992)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.189% (33478/37120)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.206% (33600/37248)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.208% (33716/37376)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (33826/37504)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.202% (33945/37632)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (34061/37760)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.200% (34175/37888)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.201% (34291/38016)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.198% (34405/38144)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.191% (34518/38272)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.195% (34635/38400)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.184% (34746/38528)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.190% (34864/38656)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.200% (34983/38784)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.198% (35098/38912)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.207% (35217/39040)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (35331/39168)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.210% (35449/39296)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.209% (35564/39424)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.203% (35677/39552)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (35793/39680)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.211% (35911/39808)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.212% (36027/39936)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (36135/40064)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.190% (36249/40192)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.198% (36368/40320)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.197% (36483/40448)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.196% (36598/40576)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.198% (36714/40704)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.194% (36828/40832)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.195% (36944/40960)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.194% (37059/41088)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (37174/41216)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (37294/41344)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.205% (37410/41472)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.202% (37524/41600)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.206% (37641/41728)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.200% (37754/41856)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.201% (37870/41984)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.214% (37991/42112)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.196% (38099/42240)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.195% (38214/42368)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.201% (38332/42496)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.196% (38445/42624)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.183% (38555/42752)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.196% (38676/42880)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.199% (38793/43008)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.205% (38911/43136)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (39021/43264)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.189% (39135/43392)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.188% (39250/43520)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.192% (39367/43648)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.198% (39485/43776)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (39603/43904)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.205% (39719/44032)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.204% (39834/44160)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.201% (39948/44288)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (40060/44416)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.196% (40177/44544)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.193% (40291/44672)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.190% (40405/44800)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.180% (40516/44928)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.181% (40632/45056)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.187% (40750/45184)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.184% (40864/45312)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.191% (40983/45440)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.197% (41101/45568)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.187% (41212/45696)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.184% (41326/45824)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.179% (41439/45952)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.180% (41555/46080)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.173% (41667/46208)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.172% (41782/46336)\n",
      "Train Epoch: 51 | Loss: 0.283 | Acc: 90.171% (41897/46464)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.161% (42008/46592)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.178% (42131/46720)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.177% (42246/46848)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.180% (42363/46976)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.177% (42477/47104)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.180% (42594/47232)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.177% (42708/47360)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.183% (42826/47488)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.186% (42943/47616)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.191% (43061/47744)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.203% (43182/47872)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.194% (43293/48000)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.195% (43409/48128)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.202% (43528/48256)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.205% (43645/48384)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.204% (43760/48512)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.199% (43873/48640)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.194% (43986/48768)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.200% (44104/48896)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.197% (44218/49024)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.210% (44340/49152)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.217% (44459/49280)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.220% (44576/49408)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.225% (44694/49536)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.228% (44811/49664)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.233% (44929/49792)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.234% (45045/49920)\n",
      "Train Epoch: 51 | Loss: 0.284 | Acc: 90.234% (45117/50000)\n",
      "Test Epoch: 51 | Loss: 0.252 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 51 | Loss: 0.389 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 51 | Loss: 0.370 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 51 | Loss: 0.341 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 51 | Loss: 0.345 | Acc: 87.600% (438/500)\n",
      "Test Epoch: 51 | Loss: 0.330 | Acc: 87.833% (527/600)\n",
      "Test Epoch: 51 | Loss: 0.331 | Acc: 87.857% (615/700)\n",
      "Test Epoch: 51 | Loss: 0.369 | Acc: 86.500% (692/800)\n",
      "Test Epoch: 51 | Loss: 0.366 | Acc: 86.889% (782/900)\n",
      "Test Epoch: 51 | Loss: 0.361 | Acc: 87.100% (871/1000)\n",
      "Test Epoch: 51 | Loss: 0.364 | Acc: 87.000% (957/1100)\n",
      "Test Epoch: 51 | Loss: 0.368 | Acc: 86.917% (1043/1200)\n",
      "Test Epoch: 51 | Loss: 0.365 | Acc: 87.000% (1131/1300)\n",
      "Test Epoch: 51 | Loss: 0.356 | Acc: 87.214% (1221/1400)\n",
      "Test Epoch: 51 | Loss: 0.348 | Acc: 87.600% (1314/1500)\n",
      "Test Epoch: 51 | Loss: 0.345 | Acc: 87.875% (1406/1600)\n",
      "Test Epoch: 51 | Loss: 0.350 | Acc: 87.882% (1494/1700)\n",
      "Test Epoch: 51 | Loss: 0.356 | Acc: 87.778% (1580/1800)\n",
      "Test Epoch: 51 | Loss: 0.354 | Acc: 88.053% (1673/1900)\n",
      "Test Epoch: 51 | Loss: 0.359 | Acc: 88.000% (1760/2000)\n",
      "Test Epoch: 51 | Loss: 0.358 | Acc: 87.857% (1845/2100)\n",
      "Test Epoch: 51 | Loss: 0.354 | Acc: 87.955% (1935/2200)\n",
      "Test Epoch: 51 | Loss: 0.362 | Acc: 87.783% (2019/2300)\n",
      "Test Epoch: 51 | Loss: 0.363 | Acc: 87.667% (2104/2400)\n",
      "Test Epoch: 51 | Loss: 0.372 | Acc: 87.600% (2190/2500)\n",
      "Test Epoch: 51 | Loss: 0.377 | Acc: 87.538% (2276/2600)\n",
      "Test Epoch: 51 | Loss: 0.372 | Acc: 87.667% (2367/2700)\n",
      "Test Epoch: 51 | Loss: 0.375 | Acc: 87.643% (2454/2800)\n",
      "Test Epoch: 51 | Loss: 0.377 | Acc: 87.621% (2541/2900)\n",
      "Test Epoch: 51 | Loss: 0.377 | Acc: 87.533% (2626/3000)\n",
      "Test Epoch: 51 | Loss: 0.382 | Acc: 87.387% (2709/3100)\n",
      "Test Epoch: 51 | Loss: 0.382 | Acc: 87.500% (2800/3200)\n",
      "Test Epoch: 51 | Loss: 0.381 | Acc: 87.576% (2890/3300)\n",
      "Test Epoch: 51 | Loss: 0.379 | Acc: 87.618% (2979/3400)\n",
      "Test Epoch: 51 | Loss: 0.383 | Acc: 87.571% (3065/3500)\n",
      "Test Epoch: 51 | Loss: 0.383 | Acc: 87.611% (3154/3600)\n",
      "Test Epoch: 51 | Loss: 0.388 | Acc: 87.324% (3231/3700)\n",
      "Test Epoch: 51 | Loss: 0.394 | Acc: 87.079% (3309/3800)\n",
      "Test Epoch: 51 | Loss: 0.391 | Acc: 87.231% (3402/3900)\n",
      "Test Epoch: 51 | Loss: 0.396 | Acc: 87.175% (3487/4000)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.049% (3569/4100)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.095% (3658/4200)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.186% (3749/4300)\n",
      "Test Epoch: 51 | Loss: 0.396 | Acc: 87.250% (3839/4400)\n",
      "Test Epoch: 51 | Loss: 0.394 | Acc: 87.311% (3929/4500)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.196% (4011/4600)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.213% (4099/4700)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.208% (4186/4800)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.286% (4277/4900)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.300% (4365/5000)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.353% (4455/5100)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.269% (4538/5200)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.226% (4623/5300)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.296% (4714/5400)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.182% (4795/5500)\n",
      "Test Epoch: 51 | Loss: 0.406 | Acc: 87.161% (4881/5600)\n",
      "Test Epoch: 51 | Loss: 0.405 | Acc: 87.123% (4966/5700)\n",
      "Test Epoch: 51 | Loss: 0.403 | Acc: 87.190% (5057/5800)\n",
      "Test Epoch: 51 | Loss: 0.406 | Acc: 87.102% (5139/5900)\n",
      "Test Epoch: 51 | Loss: 0.406 | Acc: 87.083% (5225/6000)\n",
      "Test Epoch: 51 | Loss: 0.406 | Acc: 87.098% (5313/6100)\n",
      "Test Epoch: 51 | Loss: 0.405 | Acc: 87.145% (5403/6200)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.238% (5496/6300)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.312% (5588/6400)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.323% (5676/6500)\n",
      "Test Epoch: 51 | Loss: 0.397 | Acc: 87.379% (5767/6600)\n",
      "Test Epoch: 51 | Loss: 0.395 | Acc: 87.478% (5861/6700)\n",
      "Test Epoch: 51 | Loss: 0.397 | Acc: 87.441% (5946/6800)\n",
      "Test Epoch: 51 | Loss: 0.396 | Acc: 87.507% (6038/6900)\n",
      "Test Epoch: 51 | Loss: 0.395 | Acc: 87.471% (6123/7000)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.408% (6206/7100)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.389% (6292/7200)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.384% (6379/7300)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.392% (6467/7400)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.427% (6557/7500)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.434% (6645/7600)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.429% (6732/7700)\n",
      "Test Epoch: 51 | Loss: 0.399 | Acc: 87.410% (6818/7800)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.405% (6905/7900)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.400% (6992/8000)\n",
      "Test Epoch: 51 | Loss: 0.397 | Acc: 87.432% (7082/8100)\n",
      "Test Epoch: 51 | Loss: 0.397 | Acc: 87.366% (7164/8200)\n",
      "Test Epoch: 51 | Loss: 0.396 | Acc: 87.325% (7248/8300)\n",
      "Test Epoch: 51 | Loss: 0.395 | Acc: 87.345% (7337/8400)\n",
      "Test Epoch: 51 | Loss: 0.396 | Acc: 87.282% (7419/8500)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.198% (7499/8600)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.184% (7585/8700)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.148% (7669/8800)\n",
      "Test Epoch: 51 | Loss: 0.403 | Acc: 87.090% (7751/8900)\n",
      "Test Epoch: 51 | Loss: 0.403 | Acc: 87.044% (7834/9000)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.033% (7920/9100)\n",
      "Test Epoch: 51 | Loss: 0.401 | Acc: 87.076% (8011/9200)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.086% (8099/9300)\n",
      "Test Epoch: 51 | Loss: 0.402 | Acc: 87.064% (8184/9400)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.105% (8275/9500)\n",
      "Test Epoch: 51 | Loss: 0.400 | Acc: 87.094% (8361/9600)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.165% (8455/9700)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.153% (8541/9800)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.172% (8630/9900)\n",
      "Test Epoch: 51 | Loss: 0.398 | Acc: 87.160% (8716/10000)\n",
      "\n",
      "Epoch: 52\n",
      "Train Epoch: 52 | Loss: 0.258 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 52 | Loss: 0.228 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 52 | Loss: 0.230 | Acc: 91.927% (353/384)\n",
      "Train Epoch: 52 | Loss: 0.252 | Acc: 91.797% (470/512)\n",
      "Train Epoch: 52 | Loss: 0.262 | Acc: 91.250% (584/640)\n",
      "Train Epoch: 52 | Loss: 0.249 | Acc: 91.667% (704/768)\n",
      "Train Epoch: 52 | Loss: 0.241 | Acc: 91.964% (824/896)\n",
      "Train Epoch: 52 | Loss: 0.249 | Acc: 91.504% (937/1024)\n",
      "Train Epoch: 52 | Loss: 0.252 | Acc: 91.580% (1055/1152)\n",
      "Train Epoch: 52 | Loss: 0.252 | Acc: 91.797% (1175/1280)\n",
      "Train Epoch: 52 | Loss: 0.256 | Acc: 91.548% (1289/1408)\n",
      "Train Epoch: 52 | Loss: 0.259 | Acc: 91.276% (1402/1536)\n",
      "Train Epoch: 52 | Loss: 0.255 | Acc: 91.647% (1525/1664)\n",
      "Train Epoch: 52 | Loss: 0.256 | Acc: 91.518% (1640/1792)\n",
      "Train Epoch: 52 | Loss: 0.253 | Acc: 91.615% (1759/1920)\n",
      "Train Epoch: 52 | Loss: 0.253 | Acc: 91.602% (1876/2048)\n",
      "Train Epoch: 52 | Loss: 0.257 | Acc: 91.360% (1988/2176)\n",
      "Train Epoch: 52 | Loss: 0.258 | Acc: 91.406% (2106/2304)\n",
      "Train Epoch: 52 | Loss: 0.264 | Acc: 91.242% (2219/2432)\n",
      "Train Epoch: 52 | Loss: 0.262 | Acc: 91.406% (2340/2560)\n",
      "Train Epoch: 52 | Loss: 0.261 | Acc: 91.369% (2456/2688)\n",
      "Train Epoch: 52 | Loss: 0.261 | Acc: 91.442% (2575/2816)\n",
      "Train Epoch: 52 | Loss: 0.259 | Acc: 91.542% (2695/2944)\n",
      "Train Epoch: 52 | Loss: 0.258 | Acc: 91.602% (2814/3072)\n",
      "Train Epoch: 52 | Loss: 0.263 | Acc: 91.375% (2924/3200)\n",
      "Train Epoch: 52 | Loss: 0.265 | Acc: 91.286% (3038/3328)\n",
      "Train Epoch: 52 | Loss: 0.265 | Acc: 91.319% (3156/3456)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.267% (3271/3584)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.272% (3388/3712)\n",
      "Train Epoch: 52 | Loss: 0.265 | Acc: 91.328% (3507/3840)\n",
      "Train Epoch: 52 | Loss: 0.263 | Acc: 91.482% (3630/3968)\n",
      "Train Epoch: 52 | Loss: 0.263 | Acc: 91.528% (3749/4096)\n",
      "Train Epoch: 52 | Loss: 0.265 | Acc: 91.454% (3863/4224)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.429% (3979/4352)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.317% (4091/4480)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 91.254% (4205/4608)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 91.195% (4319/4736)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 91.201% (4436/4864)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.226% (4554/4992)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.211% (4670/5120)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.235% (4788/5248)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 91.202% (4903/5376)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 91.225% (5021/5504)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.246% (5139/5632)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.267% (5257/5760)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.287% (5375/5888)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.257% (5490/6016)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.146% (5600/6144)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.183% (5719/6272)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.219% (5838/6400)\n",
      "Train Epoch: 52 | Loss: 0.266 | Acc: 91.222% (5955/6528)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.166% (6068/6656)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 91.052% (6177/6784)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.102% (6297/6912)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 91.122% (6415/7040)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 91.071% (6528/7168)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 91.009% (6640/7296)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.935% (6751/7424)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.956% (6869/7552)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.990% (6988/7680)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.996% (7105/7808)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.965% (7219/7936)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.960% (7335/8064)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.869% (7444/8192)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.829% (7557/8320)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.909% (7680/8448)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.928% (7798/8576)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.843% (7907/8704)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.863% (8025/8832)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.882% (8143/8960)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.922% (8263/9088)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.875% (8375/9216)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.871% (8491/9344)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.836% (8604/9472)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.865% (8723/9600)\n",
      "Train Epoch: 52 | Loss: 0.266 | Acc: 90.913% (8844/9728)\n",
      "Train Epoch: 52 | Loss: 0.266 | Acc: 90.909% (8960/9856)\n",
      "Train Epoch: 52 | Loss: 0.266 | Acc: 90.885% (9074/9984)\n",
      "Train Epoch: 52 | Loss: 0.266 | Acc: 90.833% (9185/10112)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.830% (9301/10240)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.789% (9413/10368)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.777% (9528/10496)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.700% (9636/10624)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.718% (9754/10752)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.735% (9872/10880)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.743% (9989/11008)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.706% (10101/11136)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.723% (10219/11264)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.713% (10334/11392)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.686% (10447/11520)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.728% (10568/11648)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.761% (10688/11776)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.785% (10807/11904)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.750% (10919/12032)\n",
      "Train Epoch: 52 | Loss: 0.268 | Acc: 90.773% (11038/12160)\n",
      "Train Epoch: 52 | Loss: 0.267 | Acc: 90.788% (11156/12288)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.770% (11270/12416)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.729% (11381/12544)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.743% (11499/12672)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.711% (11611/12800)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.702% (11726/12928)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.671% (11838/13056)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.678% (11955/13184)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.693% (12073/13312)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.670% (12186/13440)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.677% (12303/13568)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.640% (12414/13696)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.654% (12532/13824)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.632% (12645/13952)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.661% (12765/14080)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.674% (12883/14208)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.646% (12995/14336)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.632% (13109/14464)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.639% (13226/14592)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.659% (13345/14720)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.652% (13460/14848)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.652% (13576/14976)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.645% (13691/15104)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.651% (13808/15232)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.664% (13926/15360)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.683% (14045/15488)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.695% (14163/15616)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.695% (14279/15744)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.707% (14397/15872)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.688% (14510/16000)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.712% (14630/16128)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.748% (14752/16256)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.729% (14865/16384)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.758% (14986/16512)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.745% (15100/16640)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.756% (15218/16768)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.732% (15330/16896)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.731% (15446/17024)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.712% (15559/17152)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.723% (15677/17280)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.728% (15794/17408)\n",
      "Train Epoch: 52 | Loss: 0.269 | Acc: 90.745% (15913/17536)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.733% (16027/17664)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.749% (16146/17792)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.737% (16260/17920)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.741% (16377/18048)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.730% (16491/18176)\n",
      "Train Epoch: 52 | Loss: 0.270 | Acc: 90.729% (16607/18304)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.701% (16718/18432)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.700% (16834/18560)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.695% (16949/18688)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.705% (17067/18816)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.694% (17181/18944)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.698% (17298/19072)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.708% (17416/19200)\n",
      "Train Epoch: 52 | Loss: 0.271 | Acc: 90.708% (17532/19328)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.702% (17647/19456)\n",
      "Train Epoch: 52 | Loss: 0.272 | Acc: 90.702% (17763/19584)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.671% (17873/19712)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.650% (17985/19840)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.655% (18102/19968)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.650% (18217/20096)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.605% (18324/20224)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.596% (18438/20352)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.610% (18557/20480)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.615% (18674/20608)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.606% (18788/20736)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.591% (18901/20864)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.587% (19016/20992)\n",
      "Train Epoch: 52 | Loss: 0.273 | Acc: 90.611% (19137/21120)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.587% (19248/21248)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.555% (19357/21376)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.541% (19470/21504)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.556% (19589/21632)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.542% (19702/21760)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.538% (19817/21888)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.575% (19941/22016)\n",
      "Train Epoch: 52 | Loss: 0.274 | Acc: 90.557% (20053/22144)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.562% (20170/22272)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.531% (20279/22400)\n",
      "Train Epoch: 52 | Loss: 0.275 | Acc: 90.523% (20393/22528)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.501% (20504/22656)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.502% (20620/22784)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.490% (20733/22912)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.482% (20847/23040)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.465% (20959/23168)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.475% (21077/23296)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.476% (21193/23424)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.472% (21308/23552)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.452% (21419/23680)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.457% (21536/23808)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.458% (21652/23936)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.450% (21766/24064)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.451% (21882/24192)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.428% (21992/24320)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.408% (22103/24448)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.422% (22222/24576)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.419% (22337/24704)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.408% (22450/24832)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.397% (22563/24960)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.422% (22685/25088)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.423% (22801/25216)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.420% (22916/25344)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.417% (23031/25472)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.395% (23141/25600)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.376% (23252/25728)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.385% (23370/25856)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.398% (23489/25984)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.399% (23605/26112)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.385% (23717/26240)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.401% (23837/26368)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.395% (23951/26496)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.388% (24065/26624)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.393% (24182/26752)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.398% (24299/26880)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.395% (24414/27008)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.385% (24527/27136)\n",
      "Train Epoch: 52 | Loss: 0.276 | Acc: 90.372% (24639/27264)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.362% (24752/27392)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.352% (24865/27520)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.346% (24979/27648)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.341% (25093/27776)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.356% (25213/27904)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.347% (25326/28032)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.355% (25444/28160)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.339% (25555/28288)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.343% (25672/28416)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.345% (25788/28544)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.367% (25910/28672)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.375% (26028/28800)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.359% (26139/28928)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.367% (26257/29056)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.354% (26369/29184)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.366% (26488/29312)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.370% (26605/29440)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.381% (26724/29568)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.379% (26839/29696)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.353% (26947/29824)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.348% (27061/29952)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.352% (27178/30080)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.354% (27294/30208)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.365% (27413/30336)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.376% (27532/30464)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.380% (27649/30592)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.391% (27768/30720)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.392% (27884/30848)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.373% (27994/30976)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.381% (28112/31104)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.385% (28229/31232)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.383% (28344/31360)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.393% (28463/31488)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.369% (28571/31616)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.367% (28686/31744)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.361% (28800/31872)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.388% (28924/32000)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.395% (29042/32128)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.402% (29160/32256)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.387% (29271/32384)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.391% (29388/32512)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.395% (29505/32640)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.384% (29617/32768)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.400% (29738/32896)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.392% (29851/33024)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.399% (29969/33152)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.394% (30083/33280)\n",
      "Train Epoch: 52 | Loss: 0.277 | Acc: 90.412% (30205/33408)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.389% (30313/33536)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.393% (30430/33664)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.379% (30541/33792)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.371% (30654/33920)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.384% (30774/34048)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.365% (30883/34176)\n",
      "Train Epoch: 52 | Loss: 0.278 | Acc: 90.366% (30999/34304)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.343% (31107/34432)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.341% (31222/34560)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.328% (31333/34688)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.335% (31451/34816)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.339% (31568/34944)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.309% (31673/35072)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.321% (31793/35200)\n",
      "Train Epoch: 52 | Loss: 0.279 | Acc: 90.314% (31906/35328)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.295% (32015/35456)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.293% (32130/35584)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.281% (32241/35712)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.268% (32352/35840)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.277% (32471/35968)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.276% (32586/36096)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.285% (32705/36224)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.289% (32822/36352)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.291% (32938/36480)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.289% (33053/36608)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.290% (33169/36736)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.294% (33286/36864)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.290% (33400/36992)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.296% (33518/37120)\n",
      "Train Epoch: 52 | Loss: 0.280 | Acc: 90.289% (33631/37248)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.261% (33736/37376)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.249% (33847/37504)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.245% (33961/37632)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.249% (34078/37760)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.250% (34194/37888)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.249% (34309/38016)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.261% (34429/38144)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.262% (34545/38272)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.266% (34662/38400)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.264% (34777/38528)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.252% (34888/38656)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.251% (35003/38784)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.227% (35109/38912)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.228% (35225/39040)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.224% (35339/39168)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.223% (35454/39296)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.217% (35567/39424)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.215% (35682/39552)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.219% (35799/39680)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.216% (35913/39808)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.212% (36027/39936)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.206% (36140/40064)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.190% (36249/40192)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.193% (36366/40320)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.200% (36484/40448)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.201% (36600/40576)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.200% (36715/40704)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.206% (36833/40832)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.210% (36950/40960)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.211% (37066/41088)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.208% (37180/41216)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.214% (37298/41344)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.217% (37415/41472)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.214% (37529/41600)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.215% (37645/41728)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.219% (37762/41856)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.227% (37881/41984)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.236% (38000/42112)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.230% (38113/42240)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.231% (38229/42368)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.225% (38342/42496)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.231% (38460/42624)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.237% (38578/42752)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.245% (38697/42880)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.255% (38817/43008)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.254% (38932/43136)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.260% (39050/43264)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.254% (39163/43392)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.255% (39279/43520)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.258% (39396/43648)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.244% (39505/43776)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.231% (39615/43904)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.232% (39731/44032)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.233% (39847/44160)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.234% (39963/44288)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.226% (40075/44416)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.219% (40187/44544)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.224% (40305/44672)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.234% (40425/44800)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.233% (40540/44928)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.241% (40659/45056)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.238% (40773/45184)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.243% (40891/45312)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.253% (41011/45440)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.248% (41124/45568)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.253% (41242/45696)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.245% (41354/45824)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.242% (41468/45952)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.230% (41578/46080)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.235% (41696/46208)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.237% (41812/46336)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.238% (41928/46464)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.241% (42045/46592)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.233% (42157/46720)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.243% (42277/46848)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.244% (42393/46976)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.230% (42502/47104)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.231% (42618/47232)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.226% (42731/47360)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.223% (42845/47488)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.213% (42956/47616)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.217% (43073/47744)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.218% (43189/47872)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.229% (43310/48000)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.241% (43431/48128)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.240% (43546/48256)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.226% (43655/48384)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.231% (43773/48512)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.226% (43886/48640)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.227% (44002/48768)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.226% (44117/48896)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.225% (44232/49024)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.224% (44347/49152)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.205% (44453/49280)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.196% (44564/49408)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.199% (44681/49536)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.198% (44796/49664)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.193% (44909/49792)\n",
      "Train Epoch: 52 | Loss: 0.282 | Acc: 90.194% (45025/49920)\n",
      "Train Epoch: 52 | Loss: 0.281 | Acc: 90.202% (45101/50000)\n",
      "Test Epoch: 52 | Loss: 0.392 | Acc: 87.000% (87/100)\n",
      "Test Epoch: 52 | Loss: 0.392 | Acc: 85.500% (171/200)\n",
      "Test Epoch: 52 | Loss: 0.375 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.250% (349/400)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 85.800% (429/500)\n",
      "Test Epoch: 52 | Loss: 0.343 | Acc: 86.500% (519/600)\n",
      "Test Epoch: 52 | Loss: 0.352 | Acc: 86.857% (608/700)\n",
      "Test Epoch: 52 | Loss: 0.391 | Acc: 85.875% (687/800)\n",
      "Test Epoch: 52 | Loss: 0.391 | Acc: 86.000% (774/900)\n",
      "Test Epoch: 52 | Loss: 0.390 | Acc: 86.100% (861/1000)\n",
      "Test Epoch: 52 | Loss: 0.405 | Acc: 85.909% (945/1100)\n",
      "Test Epoch: 52 | Loss: 0.403 | Acc: 85.833% (1030/1200)\n",
      "Test Epoch: 52 | Loss: 0.391 | Acc: 85.923% (1117/1300)\n",
      "Test Epoch: 52 | Loss: 0.382 | Acc: 86.429% (1210/1400)\n",
      "Test Epoch: 52 | Loss: 0.376 | Acc: 86.467% (1297/1500)\n",
      "Test Epoch: 52 | Loss: 0.371 | Acc: 86.688% (1387/1600)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.000% (1479/1700)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 86.944% (1565/1800)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.158% (1656/1900)\n",
      "Test Epoch: 52 | Loss: 0.367 | Acc: 87.150% (1743/2000)\n",
      "Test Epoch: 52 | Loss: 0.377 | Acc: 86.952% (1826/2100)\n",
      "Test Epoch: 52 | Loss: 0.374 | Acc: 87.045% (1915/2200)\n",
      "Test Epoch: 52 | Loss: 0.378 | Acc: 86.783% (1996/2300)\n",
      "Test Epoch: 52 | Loss: 0.375 | Acc: 86.833% (2084/2400)\n",
      "Test Epoch: 52 | Loss: 0.378 | Acc: 86.680% (2167/2500)\n",
      "Test Epoch: 52 | Loss: 0.391 | Acc: 86.615% (2252/2600)\n",
      "Test Epoch: 52 | Loss: 0.384 | Acc: 86.852% (2345/2700)\n",
      "Test Epoch: 52 | Loss: 0.383 | Acc: 86.964% (2435/2800)\n",
      "Test Epoch: 52 | Loss: 0.382 | Acc: 87.069% (2525/2900)\n",
      "Test Epoch: 52 | Loss: 0.383 | Acc: 87.067% (2612/3000)\n",
      "Test Epoch: 52 | Loss: 0.382 | Acc: 87.097% (2700/3100)\n",
      "Test Epoch: 52 | Loss: 0.379 | Acc: 87.094% (2787/3200)\n",
      "Test Epoch: 52 | Loss: 0.374 | Acc: 87.273% (2880/3300)\n",
      "Test Epoch: 52 | Loss: 0.371 | Acc: 87.324% (2969/3400)\n",
      "Test Epoch: 52 | Loss: 0.376 | Acc: 87.171% (3051/3500)\n",
      "Test Epoch: 52 | Loss: 0.375 | Acc: 87.306% (3143/3600)\n",
      "Test Epoch: 52 | Loss: 0.375 | Acc: 87.405% (3234/3700)\n",
      "Test Epoch: 52 | Loss: 0.374 | Acc: 87.395% (3321/3800)\n",
      "Test Epoch: 52 | Loss: 0.370 | Acc: 87.538% (3414/3900)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.600% (3504/4000)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.634% (3593/4100)\n",
      "Test Epoch: 52 | Loss: 0.367 | Acc: 87.643% (3681/4200)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.744% (3773/4300)\n",
      "Test Epoch: 52 | Loss: 0.365 | Acc: 87.818% (3864/4400)\n",
      "Test Epoch: 52 | Loss: 0.367 | Acc: 87.778% (3950/4500)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.739% (4036/4600)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.787% (4126/4700)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.750% (4212/4800)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.796% (4302/4900)\n",
      "Test Epoch: 52 | Loss: 0.371 | Acc: 87.740% (4387/5000)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.804% (4478/5100)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.827% (4567/5200)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.774% (4652/5300)\n",
      "Test Epoch: 52 | Loss: 0.368 | Acc: 87.815% (4742/5400)\n",
      "Test Epoch: 52 | Loss: 0.370 | Acc: 87.691% (4823/5500)\n",
      "Test Epoch: 52 | Loss: 0.371 | Acc: 87.714% (4912/5600)\n",
      "Test Epoch: 52 | Loss: 0.372 | Acc: 87.737% (5001/5700)\n",
      "Test Epoch: 52 | Loss: 0.372 | Acc: 87.741% (5089/5800)\n",
      "Test Epoch: 52 | Loss: 0.375 | Acc: 87.627% (5170/5900)\n",
      "Test Epoch: 52 | Loss: 0.373 | Acc: 87.683% (5261/6000)\n",
      "Test Epoch: 52 | Loss: 0.371 | Acc: 87.705% (5350/6100)\n",
      "Test Epoch: 52 | Loss: 0.369 | Acc: 87.742% (5440/6200)\n",
      "Test Epoch: 52 | Loss: 0.367 | Acc: 87.841% (5534/6300)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.953% (5629/6400)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.969% (5718/6500)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 87.985% (5807/6600)\n",
      "Test Epoch: 52 | Loss: 0.359 | Acc: 88.030% (5898/6700)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 87.971% (5982/6800)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 88.014% (6073/6900)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 88.029% (6162/7000)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 88.028% (6250/7100)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.917% (6330/7200)\n",
      "Test Epoch: 52 | Loss: 0.360 | Acc: 87.945% (6420/7300)\n",
      "Test Epoch: 52 | Loss: 0.360 | Acc: 87.959% (6509/7400)\n",
      "Test Epoch: 52 | Loss: 0.360 | Acc: 87.907% (6593/7500)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 87.895% (6680/7600)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.857% (6765/7700)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.897% (6856/7800)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.873% (6942/7900)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 87.875% (7030/8000)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 87.914% (7121/8100)\n",
      "Test Epoch: 52 | Loss: 0.361 | Acc: 87.902% (7208/8200)\n",
      "Test Epoch: 52 | Loss: 0.360 | Acc: 87.928% (7298/8300)\n",
      "Test Epoch: 52 | Loss: 0.359 | Acc: 87.976% (7390/8400)\n",
      "Test Epoch: 52 | Loss: 0.359 | Acc: 87.918% (7473/8500)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 87.872% (7557/8600)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 87.897% (7647/8700)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.852% (7731/8800)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.843% (7818/8900)\n",
      "Test Epoch: 52 | Loss: 0.365 | Acc: 87.822% (7904/9000)\n",
      "Test Epoch: 52 | Loss: 0.365 | Acc: 87.813% (7991/9100)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.837% (8081/9200)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.839% (8169/9300)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.819% (8255/9400)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.779% (8339/9500)\n",
      "Test Epoch: 52 | Loss: 0.365 | Acc: 87.792% (8428/9600)\n",
      "Test Epoch: 52 | Loss: 0.363 | Acc: 87.856% (8522/9700)\n",
      "Test Epoch: 52 | Loss: 0.362 | Acc: 87.878% (8612/9800)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.859% (8698/9900)\n",
      "Test Epoch: 52 | Loss: 0.364 | Acc: 87.870% (8787/10000)\n",
      "\n",
      "Epoch: 53\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 53 | Loss: 0.248 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 53 | Loss: 0.254 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 53 | Loss: 0.260 | Acc: 92.383% (473/512)\n",
      "Train Epoch: 53 | Loss: 0.254 | Acc: 92.500% (592/640)\n",
      "Train Epoch: 53 | Loss: 0.248 | Acc: 92.318% (709/768)\n",
      "Train Epoch: 53 | Loss: 0.252 | Acc: 91.853% (823/896)\n",
      "Train Epoch: 53 | Loss: 0.259 | Acc: 91.699% (939/1024)\n",
      "Train Epoch: 53 | Loss: 0.258 | Acc: 91.753% (1057/1152)\n",
      "Train Epoch: 53 | Loss: 0.255 | Acc: 91.641% (1173/1280)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 91.122% (1283/1408)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 91.341% (1403/1536)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 91.226% (1518/1664)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 91.350% (1637/1792)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 91.250% (1752/1920)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 91.260% (1869/2048)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 91.176% (1984/2176)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 91.102% (2099/2304)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.913% (2211/2432)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.820% (2325/2560)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.997% (2446/2688)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 91.087% (2565/2816)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 91.101% (2682/2944)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 91.178% (2801/3072)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 91.188% (2918/3200)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 91.016% (3029/3328)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 91.001% (3145/3456)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.932% (3259/3584)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.975% (3377/3712)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.990% (3494/3840)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 91.003% (3611/3968)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 91.016% (3728/4096)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 91.122% (3849/4224)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 91.176% (3968/4352)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 91.138% (4083/4480)\n",
      "Train Epoch: 53 | Loss: 0.263 | Acc: 91.189% (4202/4608)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 91.047% (4312/4736)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.995% (4426/4864)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 91.006% (4543/4992)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 91.016% (4660/5120)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.968% (4774/5248)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.904% (4887/5376)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 90.879% (5002/5504)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.785% (5113/5632)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.851% (5233/5760)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.778% (5345/5888)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.708% (5457/6016)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.641% (5569/6144)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.609% (5683/6272)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.625% (5800/6400)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.533% (5910/6528)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.565% (6028/6656)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.551% (6143/6784)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.538% (6258/6912)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.540% (6374/7040)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.555% (6491/7168)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.556% (6607/7296)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.571% (6724/7424)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.651% (6846/7552)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.547% (6954/7680)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.535% (7069/7808)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.499% (7182/7936)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.526% (7300/8064)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.515% (7415/8192)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.481% (7528/8320)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.459% (7642/8448)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.462% (7758/8576)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.522% (7879/8704)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.489% (7992/8832)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.469% (8106/8960)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.537% (8228/9088)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.549% (8345/9216)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.625% (8468/9344)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.614% (8583/9472)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.615% (8699/9600)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.656% (8819/9728)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.625% (8932/9856)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.655% (9051/9984)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.674% (9169/10112)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.674% (9285/10240)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.586% (9392/10368)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.635% (9513/10496)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 90.681% (9634/10624)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.644% (9746/10752)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.634% (9861/10880)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.616% (9975/11008)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.607% (10090/11136)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.598% (10205/11264)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.590% (10320/11392)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.582% (10435/11520)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.616% (10555/11648)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.659% (10676/11776)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.591% (10784/11904)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.617% (10903/12032)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.650% (11023/12160)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.649% (11139/12288)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.665% (11257/12416)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.705% (11378/12544)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.712% (11495/12672)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.727% (11613/12800)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.749% (11732/12928)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.786% (11853/13056)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 90.807% (11972/13184)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.783% (12085/13312)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.781% (12201/13440)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.780% (12317/13568)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.778% (12433/13696)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.791% (12551/13824)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.811% (12670/13952)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.795% (12784/14080)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.780% (12898/14208)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.792% (13016/14336)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.791% (13132/14464)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.817% (13252/14592)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.829% (13370/14720)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 90.854% (13490/14848)\n",
      "Train Epoch: 53 | Loss: 0.264 | Acc: 90.852% (13606/14976)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.810% (13716/15104)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.809% (13832/15232)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.794% (13946/15360)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.799% (14063/15488)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.759% (14173/15616)\n",
      "Train Epoch: 53 | Loss: 0.265 | Acc: 90.777% (14292/15744)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.732% (14401/15872)\n",
      "Train Epoch: 53 | Loss: 0.266 | Acc: 90.713% (14514/16000)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.675% (14624/16128)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.668% (14739/16256)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.668% (14855/16384)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.649% (14968/16512)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.643% (15083/16640)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.661% (15202/16768)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.643% (15315/16896)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.654% (15433/17024)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.666% (15551/17152)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.648% (15664/17280)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.659% (15782/17408)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.654% (15897/17536)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.642% (16011/17664)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.681% (16134/17792)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.686% (16251/17920)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.686% (16367/18048)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.686% (16483/18176)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.691% (16600/18304)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.690% (16716/18432)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.695% (16833/18560)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.679% (16946/18688)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.699% (17066/18816)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.683% (17179/18944)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.688% (17296/19072)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.693% (17413/19200)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.697% (17530/19328)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.687% (17644/19456)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.676% (17758/19584)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.686% (17876/19712)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.665% (17988/19840)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.650% (18101/19968)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.615% (18210/20096)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.650% (18333/20224)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.650% (18449/20352)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.649% (18565/20480)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.644% (18680/20608)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.659% (18799/20736)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.678% (18919/20864)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.687% (19037/20992)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.677% (19151/21120)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.663% (19264/21248)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.672% (19382/21376)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.681% (19500/21504)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.667% (19613/21632)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.685% (19733/21760)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.684% (19849/21888)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.689% (19966/22016)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.693% (20083/22144)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.683% (20197/22272)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.692% (20315/22400)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.696% (20432/22528)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.713% (20552/22656)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.708% (20667/22784)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.695% (20780/22912)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.699% (20897/23040)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.685% (21010/23168)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.694% (21128/23296)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.702% (21246/23424)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.701% (21362/23552)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.701% (21478/23680)\n",
      "Train Epoch: 53 | Loss: 0.267 | Acc: 90.696% (21593/23808)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.667% (21702/23936)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.662% (21817/24064)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.654% (21931/24192)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.670% (22051/24320)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.666% (22166/24448)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.649% (22278/24576)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.645% (22393/24704)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.641% (22508/24832)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.637% (22623/24960)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.645% (22741/25088)\n",
      "Train Epoch: 53 | Loss: 0.268 | Acc: 90.641% (22856/25216)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.633% (22970/25344)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.617% (23082/25472)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.598% (23193/25600)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.602% (23310/25728)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.610% (23428/25856)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.602% (23542/25984)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.579% (23652/26112)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.591% (23771/26240)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.579% (23884/26368)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.583% (24001/26496)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.599% (24121/26624)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.603% (24238/26752)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.621% (24359/26880)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.640% (24480/27008)\n",
      "Train Epoch: 53 | Loss: 0.269 | Acc: 90.640% (24596/27136)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.625% (24708/27264)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.603% (24818/27392)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.614% (24937/27520)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.600% (25049/27648)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.593% (25163/27776)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.575% (25274/27904)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.593% (25395/28032)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.607% (25515/28160)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.604% (25630/28288)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.597% (25744/28416)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.600% (25861/28544)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.611% (25980/28672)\n",
      "Train Epoch: 53 | Loss: 0.270 | Acc: 90.611% (26096/28800)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.615% (26213/28928)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.601% (26325/29056)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.591% (26438/29184)\n",
      "Train Epoch: 53 | Loss: 0.271 | Acc: 90.598% (26556/29312)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.601% (26673/29440)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.601% (26789/29568)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.581% (26899/29696)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.585% (27016/29824)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.595% (27135/29952)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.582% (27247/30080)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.599% (27368/30208)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.595% (27483/30336)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.602% (27601/30464)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.576% (27709/30592)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.566% (27822/30720)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.573% (27940/30848)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.573% (28056/30976)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.583% (28175/31104)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.558% (28283/31232)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.568% (28402/31360)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.584% (28523/31488)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.584% (28639/31616)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.571% (28751/31744)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.572% (28867/31872)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.588% (28988/32000)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.575% (29100/32128)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.578% (29217/32256)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.573% (29331/32384)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.579% (29449/32512)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.576% (29564/32640)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.567% (29677/32768)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.579% (29797/32896)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.589% (29916/33024)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.577% (30028/33152)\n",
      "Train Epoch: 53 | Loss: 0.272 | Acc: 90.583% (30146/33280)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.568% (30257/33408)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.571% (30374/33536)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.557% (30485/33664)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.551% (30599/33792)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.548% (30714/33920)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.552% (30831/34048)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.549% (30946/34176)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.543% (31060/34304)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.535% (31173/34432)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.530% (31287/34560)\n",
      "Train Epoch: 53 | Loss: 0.273 | Acc: 90.524% (31401/34688)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.504% (31510/34816)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.499% (31624/34944)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.497% (31739/35072)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.500% (31856/35200)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.506% (31974/35328)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.512% (32092/35456)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.521% (32211/35584)\n",
      "Train Epoch: 53 | Loss: 0.274 | Acc: 90.516% (32325/35712)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.505% (32437/35840)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.486% (32546/35968)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.486% (32662/36096)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.481% (32776/36224)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.482% (32892/36352)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.491% (33011/36480)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.488% (33126/36608)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.492% (33243/36736)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.495% (33360/36864)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.495% (33476/36992)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.501% (33594/37120)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.493% (33707/37248)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.486% (33820/37376)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.497% (33940/37504)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.500% (34057/37632)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.498% (34172/37760)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.509% (34292/37888)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.517% (34411/38016)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.520% (34528/38144)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.505% (34638/38272)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.516% (34758/38400)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.513% (34873/38528)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.522% (34992/38656)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.527% (35110/38784)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.509% (35219/38912)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.510% (35335/39040)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.518% (35454/39168)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.498% (35562/39296)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.491% (35675/39424)\n",
      "Train Epoch: 53 | Loss: 0.275 | Acc: 90.486% (35789/39552)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.479% (35902/39680)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.479% (36018/39808)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.472% (36131/39936)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.475% (36248/40064)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.476% (36364/40192)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.474% (36479/40320)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.474% (36595/40448)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.475% (36711/40576)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.473% (36826/40704)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.471% (36941/40832)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.483% (37062/40960)\n",
      "Train Epoch: 53 | Loss: 0.276 | Acc: 90.472% (37173/41088)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.453% (37281/41216)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.465% (37402/41344)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.456% (37514/41472)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.442% (37624/41600)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.452% (37744/41728)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.458% (37862/41856)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.458% (37978/41984)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.454% (38092/42112)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.452% (38207/42240)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.448% (38321/42368)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.446% (38436/42496)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.449% (38553/42624)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.433% (38662/42752)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.429% (38776/42880)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.423% (38889/43008)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.426% (39006/43136)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.419% (39119/43264)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.415% (39233/43392)\n",
      "Train Epoch: 53 | Loss: 0.277 | Acc: 90.418% (39350/43520)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.407% (39461/43648)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.397% (39572/43776)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.397% (39688/43904)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.393% (39802/44032)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.394% (39918/44160)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.401% (40037/44288)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.402% (40153/44416)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.394% (40265/44544)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.374% (40372/44672)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.373% (40487/44800)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.373% (40603/44928)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.368% (40716/45056)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.364% (40830/45184)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.360% (40944/45312)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.350% (41055/45440)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.353% (41172/45568)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.356% (41289/45696)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.350% (41402/45824)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.357% (41521/45952)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.356% (41636/46080)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.363% (41755/46208)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.364% (41871/46336)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.375% (41992/46464)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.380% (42110/46592)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.385% (42228/46720)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.392% (42347/46848)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.395% (42464/46976)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.400% (42582/47104)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.405% (42700/47232)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.399% (42813/47360)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.404% (42931/47488)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.388% (43039/47616)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.388% (43155/47744)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.391% (43272/47872)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.381% (43383/48000)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.378% (43497/48128)\n",
      "Train Epoch: 53 | Loss: 0.279 | Acc: 90.374% (43611/48256)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.385% (43732/48384)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.398% (43854/48512)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.403% (43972/48640)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.389% (44081/48768)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.394% (44199/48896)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.390% (44313/49024)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.385% (44426/49152)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.384% (44541/49280)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.386% (44658/49408)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.391% (44776/49536)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.397% (44895/49664)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.396% (45010/49792)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.401% (45128/49920)\n",
      "Train Epoch: 53 | Loss: 0.278 | Acc: 90.396% (45198/50000)\n",
      "Test Epoch: 53 | Loss: 0.391 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 53 | Loss: 0.423 | Acc: 85.000% (170/200)\n",
      "Test Epoch: 53 | Loss: 0.390 | Acc: 85.667% (257/300)\n",
      "Test Epoch: 53 | Loss: 0.379 | Acc: 86.250% (345/400)\n",
      "Test Epoch: 53 | Loss: 0.364 | Acc: 87.000% (435/500)\n",
      "Test Epoch: 53 | Loss: 0.347 | Acc: 87.500% (525/600)\n",
      "Test Epoch: 53 | Loss: 0.355 | Acc: 87.143% (610/700)\n",
      "Test Epoch: 53 | Loss: 0.368 | Acc: 86.750% (694/800)\n",
      "Test Epoch: 53 | Loss: 0.376 | Acc: 86.333% (777/900)\n",
      "Test Epoch: 53 | Loss: 0.377 | Acc: 86.400% (864/1000)\n",
      "Test Epoch: 53 | Loss: 0.387 | Acc: 86.273% (949/1100)\n",
      "Test Epoch: 53 | Loss: 0.390 | Acc: 86.167% (1034/1200)\n",
      "Test Epoch: 53 | Loss: 0.381 | Acc: 86.462% (1124/1300)\n",
      "Test Epoch: 53 | Loss: 0.380 | Acc: 86.357% (1209/1400)\n",
      "Test Epoch: 53 | Loss: 0.377 | Acc: 86.067% (1291/1500)\n",
      "Test Epoch: 53 | Loss: 0.376 | Acc: 86.250% (1380/1600)\n",
      "Test Epoch: 53 | Loss: 0.377 | Acc: 86.294% (1467/1700)\n",
      "Test Epoch: 53 | Loss: 0.379 | Acc: 86.333% (1554/1800)\n",
      "Test Epoch: 53 | Loss: 0.385 | Acc: 86.421% (1642/1900)\n",
      "Test Epoch: 53 | Loss: 0.383 | Acc: 86.600% (1732/2000)\n",
      "Test Epoch: 53 | Loss: 0.393 | Acc: 86.333% (1813/2100)\n",
      "Test Epoch: 53 | Loss: 0.393 | Acc: 86.318% (1899/2200)\n",
      "Test Epoch: 53 | Loss: 0.397 | Acc: 86.391% (1987/2300)\n",
      "Test Epoch: 53 | Loss: 0.394 | Acc: 86.417% (2074/2400)\n",
      "Test Epoch: 53 | Loss: 0.392 | Acc: 86.440% (2161/2500)\n",
      "Test Epoch: 53 | Loss: 0.402 | Acc: 86.269% (2243/2600)\n",
      "Test Epoch: 53 | Loss: 0.403 | Acc: 86.333% (2331/2700)\n",
      "Test Epoch: 53 | Loss: 0.406 | Acc: 86.214% (2414/2800)\n",
      "Test Epoch: 53 | Loss: 0.405 | Acc: 86.276% (2502/2900)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.267% (2588/3000)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.161% (2671/3100)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.219% (2759/3200)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.182% (2844/3300)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.147% (2929/3400)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.171% (3016/3500)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.250% (3105/3600)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.162% (3188/3700)\n",
      "Test Epoch: 53 | Loss: 0.420 | Acc: 85.974% (3267/3800)\n",
      "Test Epoch: 53 | Loss: 0.417 | Acc: 86.128% (3359/3900)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.225% (3449/4000)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.220% (3535/4100)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.167% (3619/4200)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.140% (3704/4300)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.205% (3793/4400)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.244% (3881/4500)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.174% (3964/4600)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.128% (4048/4700)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.125% (4134/4800)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.265% (4227/4900)\n",
      "Test Epoch: 53 | Loss: 0.418 | Acc: 86.120% (4306/5000)\n",
      "Test Epoch: 53 | Loss: 0.417 | Acc: 86.137% (4393/5100)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.058% (4475/5200)\n",
      "Test Epoch: 53 | Loss: 0.417 | Acc: 86.019% (4559/5300)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.056% (4647/5400)\n",
      "Test Epoch: 53 | Loss: 0.420 | Acc: 85.964% (4728/5500)\n",
      "Test Epoch: 53 | Loss: 0.418 | Acc: 86.018% (4817/5600)\n",
      "Test Epoch: 53 | Loss: 0.417 | Acc: 86.035% (4904/5700)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.103% (4994/5800)\n",
      "Test Epoch: 53 | Loss: 0.416 | Acc: 86.068% (5078/5900)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.133% (5168/6000)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.082% (5251/6100)\n",
      "Test Epoch: 53 | Loss: 0.418 | Acc: 86.048% (5335/6200)\n",
      "Test Epoch: 53 | Loss: 0.417 | Acc: 86.095% (5424/6300)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.156% (5514/6400)\n",
      "Test Epoch: 53 | Loss: 0.415 | Acc: 86.154% (5600/6500)\n",
      "Test Epoch: 53 | Loss: 0.413 | Acc: 86.212% (5690/6600)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.254% (5779/6700)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.191% (5861/6800)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.188% (5947/6900)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.129% (6029/7000)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.113% (6114/7100)\n",
      "Test Epoch: 53 | Loss: 0.414 | Acc: 86.111% (6200/7200)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.151% (6289/7300)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.189% (6378/7400)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.227% (6467/7500)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.263% (6556/7600)\n",
      "Test Epoch: 53 | Loss: 0.412 | Acc: 86.221% (6639/7700)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.269% (6729/7800)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.278% (6816/7900)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.350% (6908/8000)\n",
      "Test Epoch: 53 | Loss: 0.408 | Acc: 86.395% (6998/8100)\n",
      "Test Epoch: 53 | Loss: 0.408 | Acc: 86.354% (7081/8200)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.398% (7171/8300)\n",
      "Test Epoch: 53 | Loss: 0.408 | Acc: 86.429% (7260/8400)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.376% (7342/8500)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.372% (7428/8600)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.356% (7513/8700)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.341% (7598/8800)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.315% (7682/8900)\n",
      "Test Epoch: 53 | Loss: 0.411 | Acc: 86.333% (7770/9000)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.297% (7853/9100)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.337% (7943/9200)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.301% (8026/9300)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.319% (8114/9400)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.326% (8201/9500)\n",
      "Test Epoch: 53 | Loss: 0.410 | Acc: 86.271% (8282/9600)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.330% (8374/9700)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.347% (8462/9800)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.333% (8547/9900)\n",
      "Test Epoch: 53 | Loss: 0.409 | Acc: 86.370% (8637/10000)\n",
      "\n",
      "Epoch: 54\n",
      "Train Epoch: 54 | Loss: 0.175 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 54 | Loss: 0.201 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 54 | Loss: 0.222 | Acc: 91.927% (353/384)\n",
      "Train Epoch: 54 | Loss: 0.237 | Acc: 91.797% (470/512)\n",
      "Train Epoch: 54 | Loss: 0.232 | Acc: 92.031% (589/640)\n",
      "Train Epoch: 54 | Loss: 0.236 | Acc: 91.797% (705/768)\n",
      "Train Epoch: 54 | Loss: 0.237 | Acc: 91.741% (822/896)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.504% (937/1024)\n",
      "Train Epoch: 54 | Loss: 0.228 | Acc: 91.927% (1059/1152)\n",
      "Train Epoch: 54 | Loss: 0.234 | Acc: 91.562% (1172/1280)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.122% (1283/1408)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.081% (1399/1536)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.106% (1516/1664)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.239% (1635/1792)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.198% (1751/1920)\n",
      "Train Epoch: 54 | Loss: 0.238 | Acc: 91.406% (1872/2048)\n",
      "Train Epoch: 54 | Loss: 0.238 | Acc: 91.406% (1989/2176)\n",
      "Train Epoch: 54 | Loss: 0.240 | Acc: 91.363% (2105/2304)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.365% (2222/2432)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.289% (2337/2560)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.332% (2455/2688)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.442% (2575/2816)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.270% (2687/2944)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.243% (2803/3072)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.188% (2918/3200)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.286% (3038/3328)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.435% (3160/3456)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.574% (3282/3584)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.433% (3394/3712)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.406% (3510/3840)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.482% (3630/3968)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.479% (3747/4096)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.383% (3860/4224)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.475% (3981/4352)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.518% (4100/4480)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.558% (4219/4608)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.596% (4338/4736)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.571% (4454/4864)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.627% (4574/4992)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.621% (4691/5120)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.559% (4805/5248)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.462% (4917/5376)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.479% (5035/5504)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.531% (5155/5632)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.493% (5270/5760)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.559% (5391/5888)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.506% (5505/6016)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.520% (5623/6144)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.534% (5741/6272)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.406% (5850/6400)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.360% (5964/6528)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.391% (6083/6656)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.436% (6203/6784)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.435% (6320/6912)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.406% (6435/7040)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.378% (6550/7168)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.324% (6663/7296)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.339% (6781/7424)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.353% (6899/7552)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.302% (7012/7680)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.227% (7123/7808)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.242% (7241/7936)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.245% (7358/8064)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.248% (7475/8192)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.214% (7589/8320)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.252% (7709/8448)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.196% (7821/8576)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.222% (7940/8704)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.180% (8053/8832)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.127% (8165/8960)\n",
      "Train Epoch: 54 | Loss: 0.253 | Acc: 91.076% (8277/9088)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.092% (8395/9216)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.117% (8514/9344)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.142% (8633/9472)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.146% (8750/9600)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.108% (8863/9728)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.092% (8978/9856)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.076% (9093/9984)\n",
      "Train Epoch: 54 | Loss: 0.253 | Acc: 91.050% (9207/10112)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.094% (9328/10240)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.117% (9447/10368)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.130% (9565/10496)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.162% (9685/10624)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.220% (9808/10752)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.241% (9927/10880)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.252% (10045/11008)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.281% (10165/11136)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.353% (10290/11264)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.397% (10412/11392)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.458% (10536/11520)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.484% (10656/11648)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.500% (10775/11776)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.524% (10895/11904)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.548% (11015/12032)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.571% (11135/12160)\n",
      "Train Epoch: 54 | Loss: 0.242 | Acc: 91.553% (11250/12288)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.511% (11362/12416)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.478% (11475/12544)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.477% (11592/12672)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.430% (11703/12800)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.468% (11825/12928)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.452% (11940/13056)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.444% (12056/13184)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.474% (12177/13312)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.488% (12296/13440)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.517% (12417/13568)\n",
      "Train Epoch: 54 | Loss: 0.243 | Acc: 91.523% (12535/13696)\n",
      "Train Epoch: 54 | Loss: 0.244 | Acc: 91.493% (12648/13824)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.492% (12765/13952)\n",
      "Train Epoch: 54 | Loss: 0.245 | Acc: 91.484% (12881/14080)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.441% (12992/14208)\n",
      "Train Epoch: 54 | Loss: 0.246 | Acc: 91.441% (13109/14336)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.420% (13223/14464)\n",
      "Train Epoch: 54 | Loss: 0.247 | Acc: 91.420% (13340/14592)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.379% (13451/14720)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.332% (13561/14848)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.366% (13683/14976)\n",
      "Train Epoch: 54 | Loss: 0.248 | Acc: 91.340% (13796/15104)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.327% (13911/15232)\n",
      "Train Epoch: 54 | Loss: 0.249 | Acc: 91.309% (14025/15360)\n",
      "Train Epoch: 54 | Loss: 0.250 | Acc: 91.296% (14140/15488)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.246% (14249/15616)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.209% (14360/15744)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.205% (14476/15872)\n",
      "Train Epoch: 54 | Loss: 0.251 | Acc: 91.194% (14591/16000)\n",
      "Train Epoch: 54 | Loss: 0.252 | Acc: 91.189% (14707/16128)\n",
      "Train Epoch: 54 | Loss: 0.253 | Acc: 91.172% (14821/16256)\n",
      "Train Epoch: 54 | Loss: 0.253 | Acc: 91.168% (14937/16384)\n",
      "Train Epoch: 54 | Loss: 0.254 | Acc: 91.170% (15054/16512)\n",
      "Train Epoch: 54 | Loss: 0.254 | Acc: 91.148% (15167/16640)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.126% (15280/16768)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.146% (15400/16896)\n",
      "Train Epoch: 54 | Loss: 0.254 | Acc: 91.165% (15520/17024)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.161% (15636/17152)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.134% (15748/17280)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.131% (15864/17408)\n",
      "Train Epoch: 54 | Loss: 0.254 | Acc: 91.138% (15982/17536)\n",
      "Train Epoch: 54 | Loss: 0.255 | Acc: 91.106% (16093/17664)\n",
      "Train Epoch: 54 | Loss: 0.256 | Acc: 91.086% (16206/17792)\n",
      "Train Epoch: 54 | Loss: 0.256 | Acc: 91.066% (16319/17920)\n",
      "Train Epoch: 54 | Loss: 0.256 | Acc: 91.085% (16439/18048)\n",
      "Train Epoch: 54 | Loss: 0.256 | Acc: 91.071% (16553/18176)\n",
      "Train Epoch: 54 | Loss: 0.256 | Acc: 91.111% (16677/18304)\n",
      "Train Epoch: 54 | Loss: 0.257 | Acc: 91.081% (16788/18432)\n",
      "Train Epoch: 54 | Loss: 0.258 | Acc: 91.051% (16899/18560)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.037% (17013/18688)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.029% (17128/18816)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.042% (17247/18944)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.018% (17359/19072)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.021% (17476/19200)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.023% (17593/19328)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.036% (17712/19456)\n",
      "Train Epoch: 54 | Loss: 0.259 | Acc: 91.044% (17830/19584)\n",
      "Train Epoch: 54 | Loss: 0.260 | Acc: 91.021% (17942/19712)\n",
      "Train Epoch: 54 | Loss: 0.260 | Acc: 91.013% (18057/19840)\n",
      "Train Epoch: 54 | Loss: 0.261 | Acc: 90.996% (18170/19968)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.983% (18284/20096)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.976% (18399/20224)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.959% (18512/20352)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.923% (18621/20480)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.926% (18738/20608)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.914% (18852/20736)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.922% (18970/20864)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.911% (19084/20992)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.904% (19199/21120)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.898% (19314/21248)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.873% (19425/21376)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.848% (19536/21504)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.852% (19653/21632)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.827% (19764/21760)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.817% (19878/21888)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.820% (19995/22016)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.806% (20108/22144)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.796% (20222/22272)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.777% (20334/22400)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.789% (20453/22528)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.802% (20572/22656)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.792% (20686/22784)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.795% (20803/22912)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.812% (20923/23040)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.811% (21039/23168)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.814% (21156/23296)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.804% (21270/23424)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.808% (21387/23552)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.823% (21507/23680)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.848% (21629/23808)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.846% (21745/23936)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.841% (21860/24064)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.832% (21974/24192)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.831% (22090/24320)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.801% (22199/24448)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.800% (22315/24576)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.815% (22435/24704)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.846% (22559/24832)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.833% (22672/24960)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.832% (22788/25088)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.847% (22908/25216)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.842% (23023/25344)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.849% (23141/25472)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.863% (23261/25600)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.866% (23378/25728)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.884% (23499/25856)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.879% (23614/25984)\n",
      "Train Epoch: 54 | Loss: 0.262 | Acc: 90.870% (23728/26112)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.869% (23844/26240)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.868% (23960/26368)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.859% (24074/26496)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.873% (24194/26624)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.875% (24311/26752)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.871% (24426/26880)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.869% (24542/27008)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.883% (24662/27136)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.893% (24781/27264)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.906% (24901/27392)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.916% (25020/27520)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.904% (25133/27648)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.891% (25246/27776)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.912% (25368/27904)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.900% (25481/28032)\n",
      "Train Epoch: 54 | Loss: 0.263 | Acc: 90.898% (25597/28160)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.876% (25707/28288)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.864% (25820/28416)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.825% (25925/28544)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.813% (26038/28672)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.802% (26151/28800)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.805% (26268/28928)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.814% (26387/29056)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.813% (26503/29184)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.816% (26620/29312)\n",
      "Train Epoch: 54 | Loss: 0.264 | Acc: 90.812% (26735/29440)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.814% (26852/29568)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.817% (26969/29696)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.806% (27082/29824)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.795% (27195/29952)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.795% (27311/30080)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.800% (27429/30208)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.803% (27546/30336)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.809% (27664/30464)\n",
      "Train Epoch: 54 | Loss: 0.265 | Acc: 90.798% (27777/30592)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.778% (27887/30720)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.781% (28004/30848)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.751% (28111/30976)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.754% (28228/31104)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.734% (28338/31232)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.733% (28454/31360)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.730% (28569/31488)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.729% (28685/31616)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.726% (28800/31744)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.722% (28915/31872)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.734% (29035/32000)\n",
      "Train Epoch: 54 | Loss: 0.266 | Acc: 90.731% (29150/32128)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.706% (29258/32256)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.708% (29375/32384)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.687% (29484/32512)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.683% (29599/32640)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.692% (29718/32768)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.683% (29831/32896)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.686% (29948/33024)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.682% (30063/33152)\n",
      "Train Epoch: 54 | Loss: 0.267 | Acc: 90.691% (30182/33280)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.679% (30294/33408)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.673% (30408/33536)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.673% (30524/33664)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.672% (30640/33792)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.646% (30747/33920)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.634% (30859/34048)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.625% (30972/34176)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.628% (31089/34304)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.616% (31201/34432)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.611% (31315/34560)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.625% (31436/34688)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.631% (31554/34816)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.639% (31673/34944)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.616% (31781/35072)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.619% (31898/35200)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.631% (32018/35328)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.636% (32136/35456)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.656% (32259/35584)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.650% (32373/35712)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.642% (32486/35840)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.633% (32599/35968)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.631% (32714/36096)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.633% (32831/36224)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.633% (32947/36352)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.639% (33065/36480)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.630% (33178/36608)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.628% (33293/36736)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.625% (33408/36864)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.620% (33522/36992)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.630% (33642/37120)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.625% (33756/37248)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.633% (33875/37376)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.649% (33997/37504)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.662% (34118/37632)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.665% (34235/37760)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.670% (34353/37888)\n",
      "Train Epoch: 54 | Loss: 0.268 | Acc: 90.654% (34463/38016)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.649% (34577/38144)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.643% (34691/38272)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.648% (34809/38400)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.643% (34923/38528)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.635% (35036/38656)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.638% (35153/38784)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.638% (35269/38912)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.622% (35379/39040)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.620% (35494/39168)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.610% (35606/39296)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.600% (35718/39424)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.612% (35839/39552)\n",
      "Train Epoch: 54 | Loss: 0.269 | Acc: 90.610% (35954/39680)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.607% (36069/39808)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.590% (36178/39936)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.580% (36290/40064)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.590% (36410/40192)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.585% (36524/40320)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.580% (36638/40448)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.583% (36755/40576)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.586% (36872/40704)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.588% (36989/40832)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.588% (37105/40960)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.591% (37222/41088)\n",
      "Train Epoch: 54 | Loss: 0.270 | Acc: 90.579% (37333/41216)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.577% (37448/41344)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.567% (37560/41472)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.567% (37676/41600)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.556% (37787/41728)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.551% (37901/41856)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.551% (38017/41984)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.554% (38134/42112)\n",
      "Train Epoch: 54 | Loss: 0.271 | Acc: 90.563% (38254/42240)\n",
      "Train Epoch: 54 | Loss: 0.272 | Acc: 90.545% (38362/42368)\n",
      "Train Epoch: 54 | Loss: 0.272 | Acc: 90.540% (38476/42496)\n",
      "Train Epoch: 54 | Loss: 0.272 | Acc: 90.536% (38590/42624)\n",
      "Train Epoch: 54 | Loss: 0.272 | Acc: 90.522% (38700/42752)\n",
      "Train Epoch: 54 | Loss: 0.272 | Acc: 90.520% (38815/42880)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.513% (38928/43008)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.511% (39043/43136)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.509% (39158/43264)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.501% (39270/43392)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.510% (39390/43520)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.513% (39507/43648)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.508% (39621/43776)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.511% (39738/43904)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.498% (39848/44032)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.500% (39965/44160)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.496% (40079/44288)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.499% (40196/44416)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.499% (40312/44544)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.495% (40426/44672)\n",
      "Train Epoch: 54 | Loss: 0.273 | Acc: 90.504% (40546/44800)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.494% (40657/44928)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.490% (40771/45056)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.481% (40883/45184)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.486% (41001/45312)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.467% (41108/45440)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.467% (41224/45568)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.465% (41339/45696)\n",
      "Train Epoch: 54 | Loss: 0.274 | Acc: 90.464% (41454/45824)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.460% (41568/45952)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.464% (41686/46080)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.461% (41800/46208)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.444% (41908/46336)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.453% (42028/46464)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.449% (42142/46592)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.452% (42259/46720)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.459% (42378/46848)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.448% (42489/46976)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.438% (42600/47104)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.428% (42711/47232)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.431% (42828/47360)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.435% (42946/47488)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.438% (43063/47616)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.430% (43175/47744)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.435% (43293/47872)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.435% (43409/48000)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.432% (43523/48128)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.426% (43636/48256)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.429% (43753/48384)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.425% (43867/48512)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.428% (43984/48640)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.416% (44094/48768)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.427% (44215/48896)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.427% (44331/49024)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.432% (44449/49152)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.440% (44569/49280)\n",
      "Train Epoch: 54 | Loss: 0.275 | Acc: 90.443% (44686/49408)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.433% (44797/49536)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.430% (44911/49664)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.426% (45025/49792)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.417% (45136/49920)\n",
      "Train Epoch: 54 | Loss: 0.276 | Acc: 90.416% (45208/50000)\n",
      "Test Epoch: 54 | Loss: 0.427 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 54 | Loss: 0.371 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 54 | Loss: 0.368 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 54 | Loss: 0.342 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 54 | Loss: 0.322 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 54 | Loss: 0.305 | Acc: 89.333% (536/600)\n",
      "Test Epoch: 54 | Loss: 0.283 | Acc: 90.000% (630/700)\n",
      "Test Epoch: 54 | Loss: 0.304 | Acc: 89.625% (717/800)\n",
      "Test Epoch: 54 | Loss: 0.334 | Acc: 88.556% (797/900)\n",
      "Test Epoch: 54 | Loss: 0.336 | Acc: 88.400% (884/1000)\n",
      "Test Epoch: 54 | Loss: 0.345 | Acc: 88.091% (969/1100)\n",
      "Test Epoch: 54 | Loss: 0.349 | Acc: 87.833% (1054/1200)\n",
      "Test Epoch: 54 | Loss: 0.334 | Acc: 88.231% (1147/1300)\n",
      "Test Epoch: 54 | Loss: 0.337 | Acc: 88.357% (1237/1400)\n",
      "Test Epoch: 54 | Loss: 0.331 | Acc: 88.533% (1328/1500)\n",
      "Test Epoch: 54 | Loss: 0.337 | Acc: 88.438% (1415/1600)\n",
      "Test Epoch: 54 | Loss: 0.339 | Acc: 88.294% (1501/1700)\n",
      "Test Epoch: 54 | Loss: 0.346 | Acc: 88.111% (1586/1800)\n",
      "Test Epoch: 54 | Loss: 0.345 | Acc: 88.211% (1676/1900)\n",
      "Test Epoch: 54 | Loss: 0.351 | Acc: 88.100% (1762/2000)\n",
      "Test Epoch: 54 | Loss: 0.351 | Acc: 88.238% (1853/2100)\n",
      "Test Epoch: 54 | Loss: 0.347 | Acc: 88.182% (1940/2200)\n",
      "Test Epoch: 54 | Loss: 0.351 | Acc: 88.000% (2024/2300)\n",
      "Test Epoch: 54 | Loss: 0.350 | Acc: 88.083% (2114/2400)\n",
      "Test Epoch: 54 | Loss: 0.355 | Acc: 88.080% (2202/2500)\n",
      "Test Epoch: 54 | Loss: 0.363 | Acc: 87.962% (2287/2600)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.111% (2379/2700)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 88.000% (2464/2800)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.103% (2555/2900)\n",
      "Test Epoch: 54 | Loss: 0.363 | Acc: 88.000% (2640/3000)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 87.871% (2724/3100)\n",
      "Test Epoch: 54 | Loss: 0.363 | Acc: 87.938% (2814/3200)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.091% (2907/3300)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.059% (2994/3400)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 87.971% (3079/3500)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 88.000% (3168/3600)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.973% (3255/3700)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 87.789% (3336/3800)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.872% (3427/3900)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.875% (3515/4000)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.829% (3601/4100)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 87.929% (3693/4200)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 88.023% (3785/4300)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.045% (3874/4400)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.022% (3961/4500)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.957% (4046/4600)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.000% (4136/4700)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.979% (4223/4800)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 87.980% (4311/4900)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 87.920% (4396/5000)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 87.961% (4486/5100)\n",
      "Test Epoch: 54 | Loss: 0.363 | Acc: 88.000% (4576/5200)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 88.057% (4667/5300)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 88.111% (4758/5400)\n",
      "Test Epoch: 54 | Loss: 0.363 | Acc: 88.091% (4845/5500)\n",
      "Test Epoch: 54 | Loss: 0.364 | Acc: 88.054% (4931/5600)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 88.035% (5018/5700)\n",
      "Test Epoch: 54 | Loss: 0.364 | Acc: 88.086% (5109/5800)\n",
      "Test Epoch: 54 | Loss: 0.366 | Acc: 88.068% (5196/5900)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 88.083% (5285/6000)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 88.066% (5372/6100)\n",
      "Test Epoch: 54 | Loss: 0.365 | Acc: 88.081% (5461/6200)\n",
      "Test Epoch: 54 | Loss: 0.364 | Acc: 88.111% (5551/6300)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.203% (5645/6400)\n",
      "Test Epoch: 54 | Loss: 0.364 | Acc: 88.154% (5730/6500)\n",
      "Test Epoch: 54 | Loss: 0.362 | Acc: 88.212% (5822/6600)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 88.284% (5915/6700)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.221% (5999/6800)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 88.232% (6088/6900)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 88.257% (6178/7000)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.268% (6267/7100)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.264% (6355/7200)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.370% (6451/7300)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 88.378% (6540/7400)\n",
      "Test Epoch: 54 | Loss: 0.357 | Acc: 88.387% (6629/7500)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.382% (6717/7600)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.377% (6805/7700)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.372% (6893/7800)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.354% (6980/7900)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.338% (7067/8000)\n",
      "Test Epoch: 54 | Loss: 0.357 | Acc: 88.432% (7163/8100)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 88.463% (7254/8200)\n",
      "Test Epoch: 54 | Loss: 0.355 | Acc: 88.458% (7342/8300)\n",
      "Test Epoch: 54 | Loss: 0.355 | Acc: 88.488% (7433/8400)\n",
      "Test Epoch: 54 | Loss: 0.357 | Acc: 88.435% (7517/8500)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.384% (7601/8600)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.379% (7689/8700)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.352% (7775/8800)\n",
      "Test Epoch: 54 | Loss: 0.360 | Acc: 88.337% (7862/8900)\n",
      "Test Epoch: 54 | Loss: 0.361 | Acc: 88.311% (7948/9000)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.363% (8041/9100)\n",
      "Test Epoch: 54 | Loss: 0.359 | Acc: 88.413% (8134/9200)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.409% (8222/9300)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.426% (8312/9400)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.432% (8401/9500)\n",
      "Test Epoch: 54 | Loss: 0.358 | Acc: 88.427% (8489/9600)\n",
      "Test Epoch: 54 | Loss: 0.357 | Acc: 88.474% (8582/9700)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 88.541% (8677/9800)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 88.525% (8764/9900)\n",
      "Test Epoch: 54 | Loss: 0.356 | Acc: 88.490% (8849/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 55\n",
      "Train Epoch: 55 | Loss: 0.221 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 55 | Loss: 0.279 | Acc: 89.844% (230/256)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.104% (346/384)\n",
      "Train Epoch: 55 | Loss: 0.275 | Acc: 89.648% (459/512)\n",
      "Train Epoch: 55 | Loss: 0.260 | Acc: 90.312% (578/640)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.365% (694/768)\n",
      "Train Epoch: 55 | Loss: 0.262 | Acc: 90.625% (812/896)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.820% (930/1024)\n",
      "Train Epoch: 55 | Loss: 0.278 | Acc: 90.365% (1041/1152)\n",
      "Train Epoch: 55 | Loss: 0.286 | Acc: 90.000% (1152/1280)\n",
      "Train Epoch: 55 | Loss: 0.285 | Acc: 89.915% (1266/1408)\n",
      "Train Epoch: 55 | Loss: 0.279 | Acc: 90.234% (1386/1536)\n",
      "Train Epoch: 55 | Loss: 0.282 | Acc: 90.024% (1498/1664)\n",
      "Train Epoch: 55 | Loss: 0.275 | Acc: 90.290% (1618/1792)\n",
      "Train Epoch: 55 | Loss: 0.276 | Acc: 90.208% (1732/1920)\n",
      "Train Epoch: 55 | Loss: 0.273 | Acc: 90.332% (1850/2048)\n",
      "Train Epoch: 55 | Loss: 0.280 | Acc: 90.211% (1963/2176)\n",
      "Train Epoch: 55 | Loss: 0.280 | Acc: 90.365% (2082/2304)\n",
      "Train Epoch: 55 | Loss: 0.277 | Acc: 90.378% (2198/2432)\n",
      "Train Epoch: 55 | Loss: 0.282 | Acc: 90.234% (2310/2560)\n",
      "Train Epoch: 55 | Loss: 0.282 | Acc: 90.067% (2421/2688)\n",
      "Train Epoch: 55 | Loss: 0.278 | Acc: 90.163% (2539/2816)\n",
      "Train Epoch: 55 | Loss: 0.276 | Acc: 90.353% (2660/2944)\n",
      "Train Epoch: 55 | Loss: 0.275 | Acc: 90.365% (2776/3072)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.438% (2894/3200)\n",
      "Train Epoch: 55 | Loss: 0.273 | Acc: 90.325% (3006/3328)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.307% (3121/3456)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.402% (3240/3584)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.436% (3357/3712)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.443% (3473/3840)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.348% (3585/3968)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.332% (3700/4096)\n",
      "Train Epoch: 55 | Loss: 0.274 | Acc: 90.223% (3811/4224)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.326% (3931/4352)\n",
      "Train Epoch: 55 | Loss: 0.275 | Acc: 90.134% (4038/4480)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.234% (4158/4608)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.329% (4278/4736)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.337% (4394/4864)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.345% (4510/4992)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.371% (4627/5120)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.415% (4745/5248)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.476% (4864/5376)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.443% (4978/5504)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.465% (5095/5632)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.538% (5215/5760)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.540% (5331/5888)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.608% (5451/6016)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.641% (5569/6144)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.689% (5688/6272)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.719% (5806/6400)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.686% (5920/6528)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.730% (6039/6656)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.699% (6153/6784)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.683% (6268/6912)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.682% (6384/7040)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.723% (6503/7168)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.735% (6620/7296)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.800% (6741/7424)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.824% (6859/7552)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.846% (6977/7680)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.843% (7093/7808)\n",
      "Train Epoch: 55 | Loss: 0.262 | Acc: 90.852% (7210/7936)\n",
      "Train Epoch: 55 | Loss: 0.262 | Acc: 90.848% (7326/8064)\n",
      "Train Epoch: 55 | Loss: 0.262 | Acc: 90.857% (7443/8192)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.829% (7557/8320)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.826% (7673/8448)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.718% (7780/8576)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.717% (7896/8704)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.727% (8013/8832)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.714% (8128/8960)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.779% (8250/9088)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.809% (8369/9216)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.786% (8483/9344)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.783% (8599/9472)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.781% (8715/9600)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.769% (8830/9728)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.767% (8946/9856)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.785% (9064/9984)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.763% (9178/10112)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.742% (9292/10240)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.789% (9413/10368)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.806% (9531/10496)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.766% (9643/10624)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.727% (9755/10752)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.680% (9866/10880)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.716% (9986/11008)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.751% (10106/11136)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.696% (10216/11264)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.704% (10333/11392)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.738% (10453/11520)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.737% (10569/11648)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.761% (10688/11776)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.717% (10799/11904)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.700% (10913/12032)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.650% (11023/12160)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.633% (11137/12288)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.641% (11254/12416)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.657% (11372/12544)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.664% (11489/12672)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.641% (11602/12800)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.687% (11724/12928)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.709% (11843/13056)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.633% (11949/13184)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.610% (12062/13312)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.588% (12175/13440)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.603% (12293/13568)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.625% (12412/13696)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.632% (12529/13824)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.668% (12650/13952)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.639% (12762/14080)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.646% (12879/14208)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.660% (12997/14336)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.618% (13107/14464)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.639% (13226/14592)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.666% (13346/14720)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.612% (13454/14848)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.625% (13572/14976)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.599% (13684/15104)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.586% (13798/15232)\n",
      "Train Epoch: 55 | Loss: 0.272 | Acc: 90.586% (13914/15360)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.606% (14033/15488)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.631% (14153/15616)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.625% (14268/15744)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.619% (14383/15872)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.650% (14504/16000)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.706% (14629/16128)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.656% (14737/16256)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.680% (14857/16384)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.698% (14976/16512)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.709% (15094/16640)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.708% (15210/16768)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.714% (15327/16896)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.719% (15444/17024)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.736% (15563/17152)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.718% (15676/17280)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.717% (15792/17408)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.693% (15904/17536)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.704% (16022/17664)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.715% (16140/17792)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.742% (16261/17920)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.730% (16375/18048)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.757% (16496/18176)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.762% (16613/18304)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.761% (16729/18432)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.754% (16844/18560)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.748% (16959/18688)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.774% (17080/18816)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.762% (17194/18944)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.767% (17311/19072)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.781% (17430/19200)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.785% (17547/19328)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.779% (17662/19456)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.778% (17778/19584)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.797% (17898/19712)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.811% (18017/19840)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.825% (18136/19968)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.834% (18254/20096)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.852% (18374/20224)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.846% (18489/20352)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.840% (18604/20480)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.809% (18714/20608)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.828% (18834/20736)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.826% (18950/20864)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.816% (19064/20992)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.824% (19182/21120)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.841% (19302/21248)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.854% (19421/21376)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.871% (19541/21504)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.893% (19662/21632)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.887% (19777/21760)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.881% (19892/21888)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.879% (20008/22016)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.878% (20124/22144)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.863% (20237/22272)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.848% (20350/22400)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.856% (20468/22528)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.837% (20580/22656)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.836% (20696/22784)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.808% (20806/22912)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.812% (20923/23040)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.824% (21042/23168)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.831% (21160/23296)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.843% (21279/23424)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.842% (21395/23552)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.845% (21512/23680)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.835% (21626/23808)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.867% (21750/23936)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.837% (21859/24064)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.819% (21971/24192)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.831% (22090/24320)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.817% (22203/24448)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.828% (22322/24576)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.840% (22441/24704)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.830% (22555/24832)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.837% (22673/24960)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.832% (22788/25088)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.839% (22906/25216)\n",
      "Train Epoch: 55 | Loss: 0.263 | Acc: 90.834% (23021/25344)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.802% (23129/25472)\n",
      "Train Epoch: 55 | Loss: 0.264 | Acc: 90.805% (23246/25600)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.792% (23359/25728)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.803% (23478/25856)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.802% (23594/25984)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.813% (23713/26112)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.793% (23824/26240)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.803% (23943/26368)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.802% (24059/26496)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.809% (24177/26624)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.804% (24292/26752)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.792% (24405/26880)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.803% (24524/27008)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.798% (24639/27136)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.794% (24754/27264)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.789% (24869/27392)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.774% (24981/27520)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.759% (25093/27648)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.776% (25214/27776)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.776% (25330/27904)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.789% (25450/28032)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.785% (25565/28160)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.777% (25679/28288)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.766% (25792/28416)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.748% (25903/28544)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.775% (26027/28672)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.788% (26147/28800)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.784% (26262/28928)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.794% (26381/29056)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.793% (26497/29184)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.792% (26613/29312)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.798% (26731/29440)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.797% (26847/29568)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.777% (26957/29696)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.776% (27073/29824)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.789% (27193/29952)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.791% (27310/30080)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.767% (27419/30208)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.773% (27537/30336)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.763% (27650/30464)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.769% (27768/30592)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.762% (27882/30720)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.764% (27999/30848)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.774% (28118/30976)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.754% (28228/31104)\n",
      "Train Epoch: 55 | Loss: 0.265 | Acc: 90.759% (28346/31232)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.737% (28455/31360)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.743% (28573/31488)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.733% (28686/31616)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.713% (28796/31744)\n",
      "Train Epoch: 55 | Loss: 0.266 | Acc: 90.719% (28914/31872)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.703% (29025/32000)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.703% (29141/32128)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.706% (29258/32256)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.684% (29367/32384)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.696% (29487/32512)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.695% (29603/32640)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.689% (29717/32768)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.689% (29833/32896)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.673% (29944/33024)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.676% (30061/33152)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.682% (30179/33280)\n",
      "Train Epoch: 55 | Loss: 0.267 | Acc: 90.691% (30298/33408)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.679% (30410/33536)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.670% (30523/33664)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.663% (30637/33792)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.646% (30747/33920)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.640% (30861/34048)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.654% (30982/34176)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.660% (31100/34304)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.654% (31214/34432)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.639% (31325/34560)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.639% (31441/34688)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.642% (31558/34816)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.645% (31675/34944)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (31788/35072)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (31904/35200)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.628% (32017/35328)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.631% (32134/35456)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.647% (32256/35584)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.656% (32375/35712)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.670% (32496/35840)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.681% (32616/35968)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.675% (32730/36096)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.666% (32843/36224)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.677% (32963/36352)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.672% (33077/36480)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.671% (33193/36608)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.671% (33309/36736)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.668% (33424/36864)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.666% (33539/36992)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.652% (33650/37120)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (33760/37248)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (33876/37376)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.646% (33996/37504)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.633% (34107/37632)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.638% (34225/37760)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (34340/37888)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (34452/38016)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (34568/38144)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.628% (34685/38272)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.633% (34803/38400)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (34916/38528)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (35032/38656)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.615% (35144/38784)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (35264/38912)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (35380/39040)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.622% (35495/39168)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.628% (35613/39296)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.622% (35727/39424)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.612% (35839/39552)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.612% (35955/39680)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.607% (36069/39808)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.610% (36186/39936)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.618% (36305/40064)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (36424/40192)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.630% (36542/40320)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.623% (36655/40448)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.632% (36775/40576)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (36888/40704)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (37004/40832)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (37120/40960)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.630% (37238/41088)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.627% (37353/41216)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.637% (37473/41344)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.642% (37591/41472)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.642% (37707/41600)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.635% (37820/41728)\n",
      "Train Epoch: 55 | Loss: 0.268 | Acc: 90.642% (37939/41856)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.635% (38052/41984)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.620% (38162/42112)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.618% (38277/42240)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.616% (38392/42368)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.613% (38507/42496)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.620% (38626/42624)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.618% (38741/42752)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.623% (38859/42880)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (38976/43008)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.630% (39094/43136)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.623% (39207/43264)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.620% (39322/43392)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.620% (39438/43520)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.632% (39559/43648)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.634% (39676/43776)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.630% (39790/43904)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (39904/44032)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.627% (40021/44160)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.639% (40142/44288)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.643% (40260/44416)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.627% (40369/44544)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.641% (40491/44672)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.634% (40604/44800)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.632% (40719/44928)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.625% (40832/45056)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.627% (40949/45184)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.623% (41063/45312)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.636% (41185/45440)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.632% (41299/45568)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.621% (41410/45696)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.629% (41530/45824)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.629% (41646/45952)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.621% (41758/46080)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.608% (41868/46208)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.612% (41986/46336)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.606% (42099/46464)\n",
      "Train Epoch: 55 | Loss: 0.269 | Acc: 90.610% (42217/46592)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.601% (42329/46720)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.593% (42441/46848)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.585% (42553/46976)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.574% (42664/47104)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.566% (42776/47232)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.572% (42895/47360)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.566% (43008/47488)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.562% (43122/47616)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.575% (43244/47744)\n",
      "Train Epoch: 55 | Loss: 0.270 | Acc: 90.579% (43362/47872)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.569% (43473/48000)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.573% (43591/48128)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.579% (43710/48256)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.573% (43823/48384)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.565% (43935/48512)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.565% (44051/48640)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.559% (44164/48768)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.574% (44287/48896)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.568% (44400/49024)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.564% (44514/49152)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.560% (44628/49280)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.566% (44747/49408)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.566% (44863/49536)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.569% (44980/49664)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.567% (45095/49792)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.563% (45209/49920)\n",
      "Train Epoch: 55 | Loss: 0.271 | Acc: 90.558% (45279/50000)\n",
      "Test Epoch: 55 | Loss: 0.421 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 87.000% (261/300)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 86.750% (347/400)\n",
      "Test Epoch: 55 | Loss: 0.439 | Acc: 86.800% (434/500)\n",
      "Test Epoch: 55 | Loss: 0.426 | Acc: 87.500% (525/600)\n",
      "Test Epoch: 55 | Loss: 0.434 | Acc: 87.143% (610/700)\n",
      "Test Epoch: 55 | Loss: 0.442 | Acc: 86.625% (693/800)\n",
      "Test Epoch: 55 | Loss: 0.452 | Acc: 86.444% (778/900)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 86.300% (863/1000)\n",
      "Test Epoch: 55 | Loss: 0.467 | Acc: 86.182% (948/1100)\n",
      "Test Epoch: 55 | Loss: 0.475 | Acc: 85.583% (1027/1200)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 85.538% (1112/1300)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 85.786% (1201/1400)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 85.467% (1282/1500)\n",
      "Test Epoch: 55 | Loss: 0.471 | Acc: 85.125% (1362/1600)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 85.353% (1451/1700)\n",
      "Test Epoch: 55 | Loss: 0.467 | Acc: 85.278% (1535/1800)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 85.474% (1624/1900)\n",
      "Test Epoch: 55 | Loss: 0.459 | Acc: 85.550% (1711/2000)\n",
      "Test Epoch: 55 | Loss: 0.455 | Acc: 85.571% (1797/2100)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.727% (1886/2200)\n",
      "Test Epoch: 55 | Loss: 0.450 | Acc: 85.522% (1967/2300)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.417% (2050/2400)\n",
      "Test Epoch: 55 | Loss: 0.457 | Acc: 85.080% (2127/2500)\n",
      "Test Epoch: 55 | Loss: 0.472 | Acc: 84.769% (2204/2600)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 84.667% (2286/2700)\n",
      "Test Epoch: 55 | Loss: 0.470 | Acc: 84.679% (2371/2800)\n",
      "Test Epoch: 55 | Loss: 0.472 | Acc: 84.793% (2459/2900)\n",
      "Test Epoch: 55 | Loss: 0.473 | Acc: 84.867% (2546/3000)\n",
      "Test Epoch: 55 | Loss: 0.473 | Acc: 84.710% (2626/3100)\n",
      "Test Epoch: 55 | Loss: 0.468 | Acc: 84.812% (2714/3200)\n",
      "Test Epoch: 55 | Loss: 0.470 | Acc: 84.727% (2796/3300)\n",
      "Test Epoch: 55 | Loss: 0.473 | Acc: 84.618% (2877/3400)\n",
      "Test Epoch: 55 | Loss: 0.474 | Acc: 84.571% (2960/3500)\n",
      "Test Epoch: 55 | Loss: 0.477 | Acc: 84.611% (3046/3600)\n",
      "Test Epoch: 55 | Loss: 0.477 | Acc: 84.703% (3134/3700)\n",
      "Test Epoch: 55 | Loss: 0.478 | Acc: 84.684% (3218/3800)\n",
      "Test Epoch: 55 | Loss: 0.475 | Acc: 84.795% (3307/3900)\n",
      "Test Epoch: 55 | Loss: 0.475 | Acc: 84.775% (3391/4000)\n",
      "Test Epoch: 55 | Loss: 0.476 | Acc: 84.854% (3479/4100)\n",
      "Test Epoch: 55 | Loss: 0.474 | Acc: 85.000% (3570/4200)\n",
      "Test Epoch: 55 | Loss: 0.471 | Acc: 85.163% (3662/4300)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 85.341% (3755/4400)\n",
      "Test Epoch: 55 | Loss: 0.462 | Acc: 85.467% (3846/4500)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 85.370% (3927/4600)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 85.298% (4009/4700)\n",
      "Test Epoch: 55 | Loss: 0.466 | Acc: 85.229% (4091/4800)\n",
      "Test Epoch: 55 | Loss: 0.462 | Acc: 85.327% (4181/4900)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 85.240% (4262/5000)\n",
      "Test Epoch: 55 | Loss: 0.459 | Acc: 85.333% (4352/5100)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 85.288% (4435/5200)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 85.170% (4514/5300)\n",
      "Test Epoch: 55 | Loss: 0.462 | Acc: 85.241% (4603/5400)\n",
      "Test Epoch: 55 | Loss: 0.463 | Acc: 85.236% (4688/5500)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 85.250% (4774/5600)\n",
      "Test Epoch: 55 | Loss: 0.464 | Acc: 85.246% (4859/5700)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 85.224% (4943/5800)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 85.119% (5022/5900)\n",
      "Test Epoch: 55 | Loss: 0.470 | Acc: 85.100% (5106/6000)\n",
      "Test Epoch: 55 | Loss: 0.469 | Acc: 85.066% (5189/6100)\n",
      "Test Epoch: 55 | Loss: 0.468 | Acc: 85.081% (5275/6200)\n",
      "Test Epoch: 55 | Loss: 0.465 | Acc: 85.159% (5365/6300)\n",
      "Test Epoch: 55 | Loss: 0.461 | Acc: 85.250% (5456/6400)\n",
      "Test Epoch: 55 | Loss: 0.461 | Acc: 85.215% (5539/6500)\n",
      "Test Epoch: 55 | Loss: 0.458 | Acc: 85.318% (5631/6600)\n",
      "Test Epoch: 55 | Loss: 0.454 | Acc: 85.448% (5725/6700)\n",
      "Test Epoch: 55 | Loss: 0.454 | Acc: 85.515% (5815/6800)\n",
      "Test Epoch: 55 | Loss: 0.452 | Acc: 85.580% (5905/6900)\n",
      "Test Epoch: 55 | Loss: 0.452 | Acc: 85.571% (5990/7000)\n",
      "Test Epoch: 55 | Loss: 0.450 | Acc: 85.662% (6082/7100)\n",
      "Test Epoch: 55 | Loss: 0.450 | Acc: 85.681% (6169/7200)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.753% (6260/7300)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.784% (6348/7400)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.707% (6428/7500)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 85.724% (6515/7600)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.675% (6597/7700)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.679% (6683/7800)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.696% (6770/7900)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.737% (6859/8000)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.765% (6947/8100)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.756% (7032/8200)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.747% (7117/8300)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.726% (7201/8400)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.729% (7287/8500)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 85.733% (7373/8600)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.782% (7463/8700)\n",
      "Test Epoch: 55 | Loss: 0.447 | Acc: 85.761% (7547/8800)\n",
      "Test Epoch: 55 | Loss: 0.449 | Acc: 85.742% (7631/8900)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 85.767% (7719/9000)\n",
      "Test Epoch: 55 | Loss: 0.448 | Acc: 85.780% (7806/9100)\n",
      "Test Epoch: 55 | Loss: 0.445 | Acc: 85.848% (7898/9200)\n",
      "Test Epoch: 55 | Loss: 0.446 | Acc: 85.871% (7986/9300)\n",
      "Test Epoch: 55 | Loss: 0.444 | Acc: 85.904% (8075/9400)\n",
      "Test Epoch: 55 | Loss: 0.444 | Acc: 85.884% (8159/9500)\n",
      "Test Epoch: 55 | Loss: 0.445 | Acc: 85.875% (8244/9600)\n",
      "Test Epoch: 55 | Loss: 0.443 | Acc: 85.918% (8334/9700)\n",
      "Test Epoch: 55 | Loss: 0.444 | Acc: 85.888% (8417/9800)\n",
      "Test Epoch: 55 | Loss: 0.443 | Acc: 85.899% (8504/9900)\n",
      "Test Epoch: 55 | Loss: 0.443 | Acc: 85.910% (8591/10000)\n",
      "\n",
      "Epoch: 56\n",
      "Train Epoch: 56 | Loss: 0.400 | Acc: 84.375% (108/128)\n",
      "Train Epoch: 56 | Loss: 0.352 | Acc: 86.328% (221/256)\n",
      "Train Epoch: 56 | Loss: 0.328 | Acc: 87.760% (337/384)\n",
      "Train Epoch: 56 | Loss: 0.316 | Acc: 87.891% (450/512)\n",
      "Train Epoch: 56 | Loss: 0.346 | Acc: 87.344% (559/640)\n",
      "Train Epoch: 56 | Loss: 0.340 | Acc: 87.370% (671/768)\n",
      "Train Epoch: 56 | Loss: 0.329 | Acc: 87.835% (787/896)\n",
      "Train Epoch: 56 | Loss: 0.314 | Acc: 88.574% (907/1024)\n",
      "Train Epoch: 56 | Loss: 0.298 | Acc: 89.410% (1030/1152)\n",
      "Train Epoch: 56 | Loss: 0.290 | Acc: 89.766% (1149/1280)\n",
      "Train Epoch: 56 | Loss: 0.290 | Acc: 89.702% (1263/1408)\n",
      "Train Epoch: 56 | Loss: 0.288 | Acc: 89.844% (1380/1536)\n",
      "Train Epoch: 56 | Loss: 0.283 | Acc: 89.964% (1497/1664)\n",
      "Train Epoch: 56 | Loss: 0.286 | Acc: 89.844% (1610/1792)\n",
      "Train Epoch: 56 | Loss: 0.281 | Acc: 90.052% (1729/1920)\n",
      "Train Epoch: 56 | Loss: 0.278 | Acc: 90.283% (1849/2048)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.349% (1966/2176)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.408% (2083/2304)\n",
      "Train Epoch: 56 | Loss: 0.276 | Acc: 90.419% (2199/2432)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.664% (2321/2560)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.699% (2438/2688)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.661% (2553/2816)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.591% (2667/2944)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.658% (2785/3072)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.500% (2896/3200)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.445% (3010/3328)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.509% (3128/3456)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.625% (3248/3584)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.598% (3363/3712)\n",
      "Train Epoch: 56 | Loss: 0.275 | Acc: 90.521% (3476/3840)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.650% (3597/3968)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.503% (3707/4096)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.625% (3828/4224)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.625% (3944/4352)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.647% (4061/4480)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.690% (4179/4608)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.731% (4297/4736)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.604% (4407/4864)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.565% (4521/4992)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.625% (4640/5120)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.625% (4756/5248)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.662% (4874/5376)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.680% (4991/5504)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.625% (5104/5632)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.642% (5221/5760)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.676% (5339/5888)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.708% (5457/6016)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.739% (5575/6144)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.784% (5694/6272)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.781% (5810/6400)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.839% (5930/6528)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.835% (6046/6656)\n",
      "Train Epoch: 56 | Loss: 0.263 | Acc: 90.846% (6163/6784)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.828% (6278/6912)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.781% (6391/7040)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.834% (6511/7168)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.817% (6626/7296)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.814% (6742/7424)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.784% (6856/7552)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.846% (6977/7680)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.779% (7088/7808)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.801% (7206/7936)\n",
      "Train Epoch: 56 | Loss: 0.262 | Acc: 90.898% (7330/8064)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.845% (7442/8192)\n",
      "Train Epoch: 56 | Loss: 0.262 | Acc: 90.865% (7560/8320)\n",
      "Train Epoch: 56 | Loss: 0.263 | Acc: 90.803% (7671/8448)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.812% (7788/8576)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.797% (7903/8704)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.772% (8017/8832)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.703% (8127/8960)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.713% (8244/9088)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.777% (8366/9216)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.732% (8478/9344)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.720% (8593/9472)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.719% (8709/9600)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.707% (8824/9728)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.767% (8946/9856)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.775% (9063/9984)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.754% (9177/10112)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.811% (9299/10240)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.799% (9414/10368)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.777% (9528/10496)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.757% (9642/10624)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.737% (9756/10752)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.735% (9872/10880)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.761% (9991/11008)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.760% (10107/11136)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.705% (10217/11264)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.713% (10334/11392)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.747% (10454/11520)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.780% (10574/11648)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.769% (10689/11776)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.785% (10807/11904)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.766% (10921/12032)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.814% (11043/12160)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.780% (11155/12288)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.762% (11269/12416)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.800% (11390/12544)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.822% (11509/12672)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.852% (11629/12800)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.849% (11745/12928)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.839% (11860/13056)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.815% (11973/13184)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.828% (12091/13312)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.774% (12200/13440)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.758% (12314/13568)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.771% (12432/13696)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.791% (12551/13824)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.761% (12663/13952)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.746% (12777/14080)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.716% (12889/14208)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.723% (13006/14336)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.715% (13121/14464)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.748% (13242/14592)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.747% (13358/14720)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.739% (13473/14848)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.745% (13590/14976)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.744% (13706/15104)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.769% (13826/15232)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.768% (13942/15360)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.774% (14059/15488)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.804% (14180/15616)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.796% (14295/15744)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.789% (14410/15872)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.819% (14531/16000)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.799% (14644/16128)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.816% (14763/16256)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.796% (14876/16384)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.813% (14995/16512)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.781% (15106/16640)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.738% (15215/16768)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.732% (15330/16896)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.748% (15449/17024)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.759% (15567/17152)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.752% (15682/17280)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.740% (15796/17408)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.750% (15914/17536)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.755% (16031/17664)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.766% (16149/17792)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.748% (16262/17920)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.758% (16380/18048)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.741% (16493/18176)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.767% (16614/18304)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.766% (16730/18432)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.776% (16848/18560)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.791% (16967/18688)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.774% (17080/18816)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.820% (17205/18944)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.845% (17326/19072)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.854% (17444/19200)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.837% (17557/19328)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.846% (17675/19456)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.850% (17792/19584)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.853% (17909/19712)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.862% (18027/19840)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.865% (18144/19968)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.884% (18264/20096)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.882% (18380/20224)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.856% (18491/20352)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.859% (18608/20480)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.863% (18725/20608)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.852% (18839/20736)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.826% (18950/20864)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.844% (19070/20992)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.852% (19188/21120)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.889% (19312/21248)\n",
      "Train Epoch: 56 | Loss: 0.264 | Acc: 90.887% (19428/21376)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.867% (19540/21504)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.875% (19658/21632)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.873% (19774/21760)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.881% (19892/21888)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.875% (20007/22016)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.860% (20120/22144)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.858% (20236/22272)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.866% (20354/22400)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.856% (20468/22528)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.850% (20583/22656)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.844% (20698/22784)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.852% (20816/22912)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.855% (20933/23040)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.867% (21052/23168)\n",
      "Train Epoch: 56 | Loss: 0.265 | Acc: 90.848% (21164/23296)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.834% (21277/23424)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.825% (21391/23552)\n",
      "Train Epoch: 56 | Loss: 0.266 | Acc: 90.828% (21508/23680)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.793% (21616/23808)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.800% (21734/23936)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.783% (21846/24064)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.799% (21966/24192)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.798% (22082/24320)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.805% (22200/24448)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.804% (22316/24576)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.799% (22431/24704)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.758% (22537/24832)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.753% (22652/24960)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.761% (22770/25088)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.744% (22882/25216)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.759% (23002/25344)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.743% (23114/25472)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.730% (23227/25600)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.730% (23343/25728)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.706% (23453/25856)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.706% (23569/25984)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.698% (23683/26112)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.709% (23802/26240)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.686% (23912/26368)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.678% (24026/26496)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.681% (24143/26624)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.666% (24255/26752)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.685% (24376/26880)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.666% (24487/27008)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.673% (24605/27136)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.684% (24724/27264)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.683% (24840/27392)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.669% (24952/27520)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.679% (25071/27648)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.665% (25183/27776)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.668% (25300/27904)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.664% (25415/28032)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.671% (25533/28160)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.671% (25649/28288)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.674% (25766/28416)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.685% (25885/28544)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.681% (26000/28672)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.694% (26120/28800)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.715% (26242/28928)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.732% (26363/29056)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.735% (26480/29184)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.724% (26593/29312)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.727% (26710/29440)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.737% (26829/29568)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.746% (26948/29696)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.759% (27068/29824)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.765% (27186/29952)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.771% (27304/30080)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.781% (27423/30208)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.767% (27535/30336)\n",
      "Train Epoch: 56 | Loss: 0.267 | Acc: 90.769% (27652/30464)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.759% (27765/30592)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.732% (27873/30720)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.738% (27991/30848)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.738% (28107/30976)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.744% (28225/31104)\n",
      "Train Epoch: 56 | Loss: 0.268 | Acc: 90.747% (28342/31232)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.727% (28452/31360)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.727% (28568/31488)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.726% (28684/31616)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.716% (28797/31744)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.703% (28909/31872)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.709% (29027/32000)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.703% (29141/32128)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.693% (29254/32256)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.696% (29371/32384)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.699% (29488/32512)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.705% (29606/32640)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.710% (29724/32768)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.710% (29840/32896)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.719% (29959/33024)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.725% (30077/33152)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.712% (30189/33280)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.709% (30304/33408)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.723% (30425/33536)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.732% (30544/33664)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.740% (30663/33792)\n",
      "Train Epoch: 56 | Loss: 0.269 | Acc: 90.740% (30779/33920)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.704% (30883/34048)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.701% (30998/34176)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.698% (31113/34304)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.695% (31228/34432)\n",
      "Train Epoch: 56 | Loss: 0.270 | Acc: 90.700% (31346/34560)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.686% (31457/34688)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.688% (31574/34816)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.688% (31690/34944)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.702% (31811/35072)\n",
      "Train Epoch: 56 | Loss: 0.271 | Acc: 90.699% (31926/35200)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.682% (32036/35328)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.676% (32150/35456)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.664% (32262/35584)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.653% (32374/35712)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.653% (32490/35840)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.642% (32602/35968)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.644% (32719/36096)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.644% (32835/36224)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.644% (32951/36352)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.628% (33061/36480)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.630% (33178/36608)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.628% (33293/36736)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.620% (33406/36864)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.628% (33525/36992)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.638% (33645/37120)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.649% (33765/37248)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.668% (33888/37376)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.660% (34001/37504)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.673% (34122/37632)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.678% (34240/37760)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.686% (34359/37888)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.667% (34468/38016)\n",
      "Train Epoch: 56 | Loss: 0.274 | Acc: 90.670% (34585/38144)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.680% (34705/38272)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.693% (34826/38400)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.695% (34943/38528)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.700% (35061/38656)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.702% (35178/38784)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.692% (35290/38912)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.704% (35411/39040)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.691% (35522/39168)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.699% (35641/39296)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.696% (35756/39424)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.696% (35872/39552)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.688% (35985/39680)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.693% (36103/39808)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.690% (36218/39936)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.685% (36332/40064)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.680% (36446/40192)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.675% (36560/40320)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.665% (36672/40448)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.667% (36789/40576)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.657% (36901/40704)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.664% (37020/40832)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.667% (37137/40960)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.649% (37246/41088)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.654% (37364/41216)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.656% (37481/41344)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.656% (37597/41472)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.654% (37712/41600)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.666% (37833/41728)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.678% (37954/41856)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.668% (38066/41984)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.658% (38178/42112)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.658% (38294/42240)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.658% (38410/42368)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.658% (38526/42496)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.660% (38643/42624)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.660% (38759/42752)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.669% (38879/42880)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.672% (38996/43008)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.669% (39111/43136)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.653% (39220/43264)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.653% (39336/43392)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.653% (39452/43520)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.648% (39566/43648)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.659% (39687/43776)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.657% (39802/43904)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.664% (39921/44032)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.677% (40043/44160)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.681% (40161/44288)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.670% (40272/44416)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.672% (40389/44544)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.674% (40506/44672)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.688% (40628/44800)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.685% (40743/44928)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.696% (40864/45056)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.698% (40981/45184)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.693% (41095/45312)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.678% (41204/45440)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.689% (41325/45568)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.691% (41442/45696)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.693% (41559/45824)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.699% (41678/45952)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.688% (41789/46080)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.694% (41908/46208)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.694% (42024/46336)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.700% (42143/46464)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.707% (42262/46592)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.708% (42379/46720)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.713% (42497/46848)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.708% (42611/46976)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.701% (42724/47104)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.695% (42837/47232)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.699% (42955/47360)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.705% (43074/47488)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.694% (43185/47616)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.690% (43299/47744)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.683% (43412/47872)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.679% (43526/48000)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.681% (43643/48128)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.681% (43759/48256)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.675% (43872/48384)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.687% (43994/48512)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.685% (44109/48640)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.684% (44225/48768)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.682% (44340/48896)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.690% (44460/49024)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.688% (44575/49152)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.692% (44693/49280)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.696% (44811/49408)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.710% (44934/49536)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.708% (45049/49664)\n",
      "Train Epoch: 56 | Loss: 0.272 | Acc: 90.713% (45168/49792)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.709% (45282/49920)\n",
      "Train Epoch: 56 | Loss: 0.273 | Acc: 90.710% (45355/50000)\n",
      "Test Epoch: 56 | Loss: 0.407 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 56 | Loss: 0.330 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 56 | Loss: 0.316 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 56 | Loss: 0.316 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 56 | Loss: 0.295 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 56 | Loss: 0.283 | Acc: 89.833% (539/600)\n",
      "Test Epoch: 56 | Loss: 0.284 | Acc: 89.857% (629/700)\n",
      "Test Epoch: 56 | Loss: 0.323 | Acc: 88.625% (709/800)\n",
      "Test Epoch: 56 | Loss: 0.343 | Acc: 88.111% (793/900)\n",
      "Test Epoch: 56 | Loss: 0.348 | Acc: 87.900% (879/1000)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 87.636% (964/1100)\n",
      "Test Epoch: 56 | Loss: 0.360 | Acc: 87.583% (1051/1200)\n",
      "Test Epoch: 56 | Loss: 0.347 | Acc: 88.154% (1146/1300)\n",
      "Test Epoch: 56 | Loss: 0.354 | Acc: 88.000% (1232/1400)\n",
      "Test Epoch: 56 | Loss: 0.348 | Acc: 88.200% (1323/1500)\n",
      "Test Epoch: 56 | Loss: 0.349 | Acc: 88.188% (1411/1600)\n",
      "Test Epoch: 56 | Loss: 0.353 | Acc: 88.176% (1499/1700)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 87.889% (1582/1800)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 87.842% (1669/1900)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 87.800% (1756/2000)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 87.810% (1844/2100)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 87.818% (1932/2200)\n",
      "Test Epoch: 56 | Loss: 0.364 | Acc: 87.783% (2019/2300)\n",
      "Test Epoch: 56 | Loss: 0.364 | Acc: 87.708% (2105/2400)\n",
      "Test Epoch: 56 | Loss: 0.367 | Acc: 87.720% (2193/2500)\n",
      "Test Epoch: 56 | Loss: 0.378 | Acc: 87.423% (2273/2600)\n",
      "Test Epoch: 56 | Loss: 0.375 | Acc: 87.519% (2363/2700)\n",
      "Test Epoch: 56 | Loss: 0.377 | Acc: 87.607% (2453/2800)\n",
      "Test Epoch: 56 | Loss: 0.375 | Acc: 87.793% (2546/2900)\n",
      "Test Epoch: 56 | Loss: 0.376 | Acc: 87.767% (2633/3000)\n",
      "Test Epoch: 56 | Loss: 0.375 | Acc: 87.710% (2719/3100)\n",
      "Test Epoch: 56 | Loss: 0.373 | Acc: 87.750% (2808/3200)\n",
      "Test Epoch: 56 | Loss: 0.371 | Acc: 87.879% (2900/3300)\n",
      "Test Epoch: 56 | Loss: 0.373 | Acc: 87.706% (2982/3400)\n",
      "Test Epoch: 56 | Loss: 0.373 | Acc: 87.657% (3068/3500)\n",
      "Test Epoch: 56 | Loss: 0.372 | Acc: 87.778% (3160/3600)\n",
      "Test Epoch: 56 | Loss: 0.374 | Acc: 87.730% (3246/3700)\n",
      "Test Epoch: 56 | Loss: 0.377 | Acc: 87.684% (3332/3800)\n",
      "Test Epoch: 56 | Loss: 0.375 | Acc: 87.718% (3421/3900)\n",
      "Test Epoch: 56 | Loss: 0.375 | Acc: 87.750% (3510/4000)\n",
      "Test Epoch: 56 | Loss: 0.376 | Acc: 87.683% (3595/4100)\n",
      "Test Epoch: 56 | Loss: 0.376 | Acc: 87.667% (3682/4200)\n",
      "Test Epoch: 56 | Loss: 0.372 | Acc: 87.767% (3774/4300)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 87.909% (3868/4400)\n",
      "Test Epoch: 56 | Loss: 0.367 | Acc: 88.044% (3962/4500)\n",
      "Test Epoch: 56 | Loss: 0.371 | Acc: 87.891% (4043/4600)\n",
      "Test Epoch: 56 | Loss: 0.371 | Acc: 87.936% (4133/4700)\n",
      "Test Epoch: 56 | Loss: 0.371 | Acc: 87.938% (4221/4800)\n",
      "Test Epoch: 56 | Loss: 0.369 | Acc: 88.061% (4315/4900)\n",
      "Test Epoch: 56 | Loss: 0.371 | Acc: 87.940% (4397/5000)\n",
      "Test Epoch: 56 | Loss: 0.369 | Acc: 88.059% (4491/5100)\n",
      "Test Epoch: 56 | Loss: 0.368 | Acc: 88.096% (4581/5200)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 88.057% (4667/5300)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 88.093% (4757/5400)\n",
      "Test Epoch: 56 | Loss: 0.369 | Acc: 88.091% (4845/5500)\n",
      "Test Epoch: 56 | Loss: 0.370 | Acc: 88.054% (4931/5600)\n",
      "Test Epoch: 56 | Loss: 0.368 | Acc: 88.088% (5021/5700)\n",
      "Test Epoch: 56 | Loss: 0.365 | Acc: 88.138% (5112/5800)\n",
      "Test Epoch: 56 | Loss: 0.369 | Acc: 88.051% (5195/5900)\n",
      "Test Epoch: 56 | Loss: 0.368 | Acc: 88.067% (5284/6000)\n",
      "Test Epoch: 56 | Loss: 0.367 | Acc: 88.115% (5375/6100)\n",
      "Test Epoch: 56 | Loss: 0.367 | Acc: 88.145% (5465/6200)\n",
      "Test Epoch: 56 | Loss: 0.365 | Acc: 88.254% (5560/6300)\n",
      "Test Epoch: 56 | Loss: 0.363 | Acc: 88.344% (5654/6400)\n",
      "Test Epoch: 56 | Loss: 0.362 | Acc: 88.354% (5743/6500)\n",
      "Test Epoch: 56 | Loss: 0.361 | Acc: 88.439% (5837/6600)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 88.537% (5932/6700)\n",
      "Test Epoch: 56 | Loss: 0.361 | Acc: 88.441% (6014/6800)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 88.522% (6108/6900)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 88.529% (6197/7000)\n",
      "Test Epoch: 56 | Loss: 0.362 | Acc: 88.451% (6280/7100)\n",
      "Test Epoch: 56 | Loss: 0.362 | Acc: 88.444% (6368/7200)\n",
      "Test Epoch: 56 | Loss: 0.359 | Acc: 88.521% (6462/7300)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.541% (6552/7400)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.533% (6640/7500)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.526% (6728/7600)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.468% (6812/7700)\n",
      "Test Epoch: 56 | Loss: 0.355 | Acc: 88.487% (6902/7800)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.456% (6988/7900)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.438% (7075/8000)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.469% (7166/8100)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.427% (7251/8200)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.422% (7339/8300)\n",
      "Test Epoch: 56 | Loss: 0.355 | Acc: 88.464% (7431/8400)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.459% (7519/8500)\n",
      "Test Epoch: 56 | Loss: 0.357 | Acc: 88.430% (7605/8600)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.471% (7697/8700)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 88.443% (7783/8800)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 88.438% (7871/8900)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 88.433% (7959/9000)\n",
      "Test Epoch: 56 | Loss: 0.358 | Acc: 88.440% (8048/9100)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.500% (8142/9200)\n",
      "Test Epoch: 56 | Loss: 0.356 | Acc: 88.484% (8229/9300)\n",
      "Test Epoch: 56 | Loss: 0.354 | Acc: 88.521% (8321/9400)\n",
      "Test Epoch: 56 | Loss: 0.354 | Acc: 88.537% (8411/9500)\n",
      "Test Epoch: 56 | Loss: 0.355 | Acc: 88.510% (8497/9600)\n",
      "Test Epoch: 56 | Loss: 0.353 | Acc: 88.557% (8590/9700)\n",
      "Test Epoch: 56 | Loss: 0.353 | Acc: 88.561% (8679/9800)\n",
      "Test Epoch: 56 | Loss: 0.354 | Acc: 88.505% (8762/9900)\n",
      "Test Epoch: 56 | Loss: 0.355 | Acc: 88.480% (8848/10000)\n",
      "\n",
      "Epoch: 57\n",
      "Train Epoch: 57 | Loss: 0.297 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 57 | Loss: 0.250 | Acc: 91.016% (233/256)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 90.625% (348/384)\n",
      "Train Epoch: 57 | Loss: 0.251 | Acc: 91.211% (467/512)\n",
      "Train Epoch: 57 | Loss: 0.274 | Acc: 90.312% (578/640)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.755% (697/768)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.406% (819/896)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.211% (934/1024)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.406% (1053/1152)\n",
      "Train Epoch: 57 | Loss: 0.254 | Acc: 91.406% (1170/1280)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.193% (1284/1408)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.081% (1399/1536)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.106% (1516/1664)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 91.071% (1632/1792)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 91.094% (1749/1920)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.771% (1859/2048)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.947% (1979/2176)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.016% (2097/2304)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.872% (2210/2432)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.133% (2333/2560)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.034% (2447/2688)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.945% (2561/2816)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.829% (2674/2944)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.885% (2792/3072)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.906% (2909/3200)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.895% (3025/3328)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.972% (3144/3456)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.099% (3265/3584)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.164% (3384/3712)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.146% (3500/3840)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.179% (3618/3968)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.211% (3736/4096)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.170% (3851/4224)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.199% (3969/4352)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.116% (4082/4480)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.124% (4199/4608)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.111% (4315/4736)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.180% (4435/4864)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.146% (4550/4992)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.211% (4670/5120)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.025% (4777/5248)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.109% (4898/5376)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.188% (5019/5504)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.300% (5142/5632)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.215% (5254/5760)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.219% (5371/5888)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.157% (5484/6016)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.162% (5601/6144)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.055% (5711/6272)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.062% (5828/6400)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.977% (5939/6528)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.910% (6051/6656)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.905% (6167/6784)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.885% (6282/6912)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.938% (6402/7040)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.932% (6518/7168)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.954% (6636/7296)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.016% (6757/7424)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.009% (6873/7552)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.003% (6989/7680)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.971% (7103/7808)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.953% (7218/7936)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.935% (7333/8064)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.967% (7452/8192)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.974% (7569/8320)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.968% (7685/8448)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.021% (7806/8576)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.981% (7919/8704)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.965% (8034/8832)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.949% (8149/8960)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.977% (8268/9088)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 90.972% (8384/9216)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.000% (8503/9344)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.047% (8624/9472)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.073% (8743/9600)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.098% (8862/9728)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.112% (8980/9856)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.146% (9100/9984)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.179% (9220/10112)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.172% (9336/10240)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.184% (9454/10368)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.225% (9575/10496)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.209% (9690/10624)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.211% (9807/10752)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.204% (9923/10880)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.234% (10043/11008)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.191% (10155/11136)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.175% (10270/11264)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.213% (10391/11392)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.224% (10509/11520)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.192% (10622/11648)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.219% (10742/11776)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.221% (10859/11904)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.215% (10975/12032)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.217% (11092/12160)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.243% (11212/12288)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.221% (11326/12416)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.247% (11446/12544)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.241% (11562/12672)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.250% (11680/12800)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.252% (11797/12928)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.253% (11914/13056)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.270% (12033/13184)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.241% (12146/13312)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.213% (12259/13440)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.215% (12376/13568)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.173% (12487/13696)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.168% (12603/13824)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.163% (12719/13952)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.158% (12835/14080)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.160% (12952/14208)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.162% (13069/14336)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.185% (13189/14464)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.194% (13307/14592)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.189% (13423/14720)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.204% (13542/14848)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.193% (13657/14976)\n",
      "Train Epoch: 57 | Loss: 0.254 | Acc: 91.221% (13778/15104)\n",
      "Train Epoch: 57 | Loss: 0.254 | Acc: 91.196% (13891/15232)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.172% (14004/15360)\n",
      "Train Epoch: 57 | Loss: 0.254 | Acc: 91.193% (14124/15488)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.176% (14238/15616)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.139% (14349/15744)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.116% (14462/15872)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.144% (14583/16000)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.140% (14699/16128)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.142% (14816/16256)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.138% (14932/16384)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.140% (15049/16512)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.130% (15164/16640)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.162% (15286/16768)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.181% (15406/16896)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.142% (15516/17024)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.144% (15633/17152)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.181% (15756/17280)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.182% (15873/17408)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.172% (15988/17536)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.180% (16106/17664)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.181% (16223/17792)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.189% (16341/17920)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.174% (16455/18048)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.175% (16572/18176)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.199% (16693/18304)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.211% (16812/18432)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.228% (16932/18560)\n",
      "Train Epoch: 57 | Loss: 0.255 | Acc: 91.240% (17051/18688)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.231% (17166/18816)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.248% (17286/18944)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.223% (17398/19072)\n",
      "Train Epoch: 57 | Loss: 0.256 | Acc: 91.224% (17515/19200)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.184% (17624/19328)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.185% (17741/19456)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.161% (17853/19584)\n",
      "Train Epoch: 57 | Loss: 0.257 | Acc: 91.127% (17963/19712)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.129% (18080/19840)\n",
      "Train Epoch: 57 | Loss: 0.258 | Acc: 91.091% (18189/19968)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.078% (18303/20096)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.070% (18418/20224)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.097% (18540/20352)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.123% (18662/20480)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.110% (18776/20608)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.112% (18893/20736)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.114% (19010/20864)\n",
      "Train Epoch: 57 | Loss: 0.259 | Acc: 91.116% (19127/20992)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.103% (19241/21120)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.100% (19357/21248)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.088% (19471/21376)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.099% (19590/21504)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.078% (19702/21632)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.062% (19815/21760)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.073% (19934/21888)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.066% (20049/22016)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.068% (20166/22144)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.078% (20285/22272)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.058% (20397/22400)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.096% (20522/22528)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.093% (20638/22656)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.086% (20753/22784)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.096% (20872/22912)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.094% (20988/23040)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.091% (21104/23168)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.063% (21214/23296)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.043% (21326/23424)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.028% (21439/23552)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.009% (21551/23680)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.990% (21663/23808)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.976% (21776/23936)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.978% (21893/24064)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.997% (22014/24192)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.987% (22128/24320)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.997% (22247/24448)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.995% (22363/24576)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.985% (22477/24704)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.983% (22593/24832)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.962% (22704/24960)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.976% (22824/25088)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.994% (22945/25216)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.000% (23063/25344)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.006% (23181/25472)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 90.996% (23295/25600)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.018% (23417/25728)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.027% (23536/25856)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.010% (23648/25984)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.000% (23762/26112)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.010% (23881/26240)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.016% (23999/26368)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.006% (24113/26496)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.016% (24232/26624)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.021% (24350/26752)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.031% (24469/26880)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.040% (24588/27008)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.049% (24707/27136)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.061% (24827/27264)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.067% (24945/27392)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.039% (25054/27520)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.045% (25172/27648)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.035% (25286/27776)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.044% (25405/27904)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.039% (25520/28032)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.030% (25634/28160)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.032% (25751/28288)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.037% (25869/28416)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.038% (25986/28544)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.033% (26101/28672)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.042% (26220/28800)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.029% (26333/28928)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.038% (26452/29056)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.036% (26568/29184)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.055% (26690/29312)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.053% (26806/29440)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.055% (26923/29568)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.053% (27039/29696)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.058% (27157/29824)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.066% (27276/29952)\n",
      "Train Epoch: 57 | Loss: 0.260 | Acc: 91.067% (27393/30080)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.055% (27506/30208)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.054% (27622/30336)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.045% (27736/30464)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.043% (27852/30592)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.042% (27968/30720)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.033% (28082/30848)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.041% (28201/30976)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.040% (28317/31104)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.060% (28440/31232)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.065% (28558/31360)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.057% (28672/31488)\n",
      "Train Epoch: 57 | Loss: 0.261 | Acc: 91.071% (28793/31616)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.072% (28910/31744)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.071% (29026/31872)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.053% (29137/32000)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.042% (29250/32128)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.028% (29362/32256)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.020% (29476/32384)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.034% (29597/32512)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.042% (29716/32640)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.052% (29836/32768)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.075% (29960/32896)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.079% (30078/33024)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.080% (30195/33152)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.082% (30312/33280)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.080% (30428/33408)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.078% (30544/33536)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.056% (30653/33664)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.051% (30768/33792)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.041% (30881/33920)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.045% (30999/34048)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.040% (31114/34176)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.033% (31228/34304)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 91.023% (31341/34432)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 91.007% (31452/34560)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.991% (31563/34688)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.996% (31681/34816)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.997% (31798/34944)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 91.007% (31918/35072)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.989% (32028/35200)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.999% (32148/35328)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.994% (32263/35456)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 91.002% (32382/35584)\n",
      "Train Epoch: 57 | Loss: 0.262 | Acc: 90.997% (32497/35712)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.979% (32607/35840)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.970% (32720/35968)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.969% (32836/36096)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.987% (32959/36224)\n",
      "Train Epoch: 57 | Loss: 0.263 | Acc: 90.980% (33073/36352)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.987% (33192/36480)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.997% (33312/36608)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.995% (33428/36736)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.972% (33536/36864)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.955% (33646/36992)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.959% (33764/37120)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.969% (33884/37248)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.959% (33997/37376)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.964% (34115/37504)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.949% (34226/37632)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.945% (34341/37760)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.947% (34458/37888)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.951% (34576/38016)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.950% (34692/38144)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.949% (34808/38272)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.935% (34919/38400)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.921% (35030/38528)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.925% (35148/38656)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.937% (35269/38784)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.915% (35377/38912)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.912% (35492/39040)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.914% (35609/39168)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.902% (35721/39296)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.904% (35838/39424)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.908% (35956/39552)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.895% (36067/39680)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.894% (36183/39808)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.895% (36300/39936)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.905% (36420/40064)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.901% (36535/40192)\n",
      "Train Epoch: 57 | Loss: 0.264 | Acc: 90.908% (36654/40320)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.890% (36763/40448)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.894% (36881/40576)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.900% (37000/40704)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.904% (37118/40832)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.896% (37231/40960)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.898% (37348/41088)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.894% (37463/41216)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.891% (37578/41344)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.883% (37691/41472)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.885% (37808/41600)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.877% (37921/41728)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.883% (38040/41856)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.875% (38153/41984)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.870% (38267/42112)\n",
      "Train Epoch: 57 | Loss: 0.265 | Acc: 90.862% (38380/42240)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.854% (38493/42368)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.846% (38606/42496)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.857% (38727/42624)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.852% (38841/42752)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.835% (38950/42880)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.839% (39068/43008)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.845% (39187/43136)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.831% (39297/43264)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.828% (39412/43392)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.832% (39530/43520)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.836% (39648/43648)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.821% (39758/43776)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.828% (39877/43904)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.829% (39994/44032)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.817% (40105/44160)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.830% (40227/44288)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.828% (40342/44416)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.838% (40463/44544)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.840% (40580/44672)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.846% (40699/44800)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.843% (40814/44928)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.834% (40926/45056)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.831% (41041/45184)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.828% (41156/45312)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.816% (41267/45440)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.816% (41383/45568)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.807% (41495/45696)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.804% (41610/45824)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.803% (41726/45952)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.786% (41834/46080)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.789% (41952/46208)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.800% (42073/46336)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.810% (42194/46464)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.814% (42312/46592)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.809% (42426/46720)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.815% (42545/46848)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.808% (42658/46976)\n",
      "Train Epoch: 57 | Loss: 0.266 | Acc: 90.812% (42776/47104)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.794% (42884/47232)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.788% (42997/47360)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.785% (43112/47488)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.789% (43230/47616)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.793% (43348/47744)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.786% (43461/47872)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.771% (43570/48000)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.777% (43689/48128)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.789% (43811/48256)\n",
      "Train Epoch: 57 | Loss: 0.267 | Acc: 90.792% (43929/48384)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.782% (44040/48512)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.783% (44157/48640)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.783% (44273/48768)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.766% (44381/48896)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.772% (44500/49024)\n",
      "Train Epoch: 57 | Loss: 0.268 | Acc: 90.771% (44616/49152)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.753% (44723/49280)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.744% (44835/49408)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.742% (44950/49536)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.732% (45061/49664)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.735% (45179/49792)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.731% (45293/49920)\n",
      "Train Epoch: 57 | Loss: 0.269 | Acc: 90.728% (45364/50000)\n",
      "Test Epoch: 57 | Loss: 0.182 | Acc: 94.000% (94/100)\n",
      "Test Epoch: 57 | Loss: 0.270 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 57 | Loss: 0.259 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 57 | Loss: 0.263 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 57 | Loss: 0.265 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 57 | Loss: 0.264 | Acc: 90.500% (543/600)\n",
      "Test Epoch: 57 | Loss: 0.278 | Acc: 90.714% (635/700)\n",
      "Test Epoch: 57 | Loss: 0.289 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 57 | Loss: 0.308 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 57 | Loss: 0.306 | Acc: 89.200% (892/1000)\n",
      "Test Epoch: 57 | Loss: 0.314 | Acc: 89.273% (982/1100)\n",
      "Test Epoch: 57 | Loss: 0.321 | Acc: 89.250% (1071/1200)\n",
      "Test Epoch: 57 | Loss: 0.317 | Acc: 89.154% (1159/1300)\n",
      "Test Epoch: 57 | Loss: 0.322 | Acc: 88.786% (1243/1400)\n",
      "Test Epoch: 57 | Loss: 0.318 | Acc: 89.000% (1335/1500)\n",
      "Test Epoch: 57 | Loss: 0.319 | Acc: 88.938% (1423/1600)\n",
      "Test Epoch: 57 | Loss: 0.324 | Acc: 88.824% (1510/1700)\n",
      "Test Epoch: 57 | Loss: 0.330 | Acc: 88.722% (1597/1800)\n",
      "Test Epoch: 57 | Loss: 0.330 | Acc: 88.737% (1686/1900)\n",
      "Test Epoch: 57 | Loss: 0.334 | Acc: 88.600% (1772/2000)\n",
      "Test Epoch: 57 | Loss: 0.336 | Acc: 88.524% (1859/2100)\n",
      "Test Epoch: 57 | Loss: 0.334 | Acc: 88.545% (1948/2200)\n",
      "Test Epoch: 57 | Loss: 0.337 | Acc: 88.435% (2034/2300)\n",
      "Test Epoch: 57 | Loss: 0.337 | Acc: 88.458% (2123/2400)\n",
      "Test Epoch: 57 | Loss: 0.345 | Acc: 88.240% (2206/2500)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.115% (2291/2600)\n",
      "Test Epoch: 57 | Loss: 0.354 | Acc: 88.222% (2382/2700)\n",
      "Test Epoch: 57 | Loss: 0.355 | Acc: 88.179% (2469/2800)\n",
      "Test Epoch: 57 | Loss: 0.356 | Acc: 88.069% (2554/2900)\n",
      "Test Epoch: 57 | Loss: 0.356 | Acc: 88.033% (2641/3000)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 87.903% (2725/3100)\n",
      "Test Epoch: 57 | Loss: 0.356 | Acc: 88.031% (2817/3200)\n",
      "Test Epoch: 57 | Loss: 0.358 | Acc: 88.061% (2906/3300)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.088% (2995/3400)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.086% (3083/3500)\n",
      "Test Epoch: 57 | Loss: 0.358 | Acc: 88.222% (3176/3600)\n",
      "Test Epoch: 57 | Loss: 0.358 | Acc: 88.162% (3262/3700)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.053% (3346/3800)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.077% (3435/3900)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.150% (3526/4000)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.122% (3613/4100)\n",
      "Test Epoch: 57 | Loss: 0.364 | Acc: 88.071% (3699/4200)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.209% (3793/4300)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.295% (3885/4400)\n",
      "Test Epoch: 57 | Loss: 0.355 | Acc: 88.378% (3977/4500)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.348% (4064/4600)\n",
      "Test Epoch: 57 | Loss: 0.355 | Acc: 88.340% (4152/4700)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.292% (4238/4800)\n",
      "Test Epoch: 57 | Loss: 0.355 | Acc: 88.408% (4332/4900)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.300% (4415/5000)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.333% (4505/5100)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.231% (4588/5200)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.094% (4669/5300)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.130% (4759/5400)\n",
      "Test Epoch: 57 | Loss: 0.364 | Acc: 88.018% (4841/5500)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 87.964% (4926/5600)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 88.000% (5016/5700)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 88.000% (5104/5800)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 87.898% (5186/5900)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 87.900% (5274/6000)\n",
      "Test Epoch: 57 | Loss: 0.367 | Acc: 87.902% (5362/6100)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 87.935% (5452/6200)\n",
      "Test Epoch: 57 | Loss: 0.366 | Acc: 87.968% (5542/6300)\n",
      "Test Epoch: 57 | Loss: 0.364 | Acc: 88.047% (5635/6400)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.062% (5724/6500)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.121% (5816/6600)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.179% (5908/6700)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.132% (5993/6800)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.145% (6082/6900)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.171% (6172/7000)\n",
      "Test Epoch: 57 | Loss: 0.364 | Acc: 88.113% (6256/7100)\n",
      "Test Epoch: 57 | Loss: 0.364 | Acc: 88.083% (6342/7200)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.110% (6432/7300)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.095% (6519/7400)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.080% (6606/7500)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.105% (6696/7600)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.104% (6784/7700)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.128% (6874/7800)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.127% (6962/7900)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.162% (7053/8000)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.210% (7145/8100)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.220% (7234/8200)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.157% (7317/8300)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.202% (7409/8400)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.176% (7495/8500)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.174% (7583/8600)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.207% (7674/8700)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.170% (7759/8800)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.135% (7844/8900)\n",
      "Test Epoch: 57 | Loss: 0.363 | Acc: 88.133% (7932/9000)\n",
      "Test Epoch: 57 | Loss: 0.362 | Acc: 88.187% (8025/9100)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.207% (8115/9200)\n",
      "Test Epoch: 57 | Loss: 0.361 | Acc: 88.161% (8199/9300)\n",
      "Test Epoch: 57 | Loss: 0.360 | Acc: 88.181% (8289/9400)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.211% (8380/9500)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.198% (8467/9600)\n",
      "Test Epoch: 57 | Loss: 0.358 | Acc: 88.258% (8561/9700)\n",
      "Test Epoch: 57 | Loss: 0.357 | Acc: 88.276% (8651/9800)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.242% (8736/9900)\n",
      "Test Epoch: 57 | Loss: 0.359 | Acc: 88.200% (8820/10000)\n",
      "\n",
      "Epoch: 58\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 58 | Loss: 0.198 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 58 | Loss: 0.220 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 58 | Loss: 0.228 | Acc: 91.992% (471/512)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.406% (585/640)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.536% (703/768)\n",
      "Train Epoch: 58 | Loss: 0.238 | Acc: 92.076% (825/896)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.895% (941/1024)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.493% (1054/1152)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.562% (1172/1280)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.477% (1288/1408)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.667% (1408/1536)\n",
      "Train Epoch: 58 | Loss: 0.254 | Acc: 91.526% (1523/1664)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.741% (1644/1792)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.562% (1758/1920)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.553% (1875/2048)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 91.544% (1992/2176)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.406% (2106/2304)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.283% (2220/2432)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.328% (2338/2560)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.295% (2454/2688)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.229% (2569/2816)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.338% (2689/2944)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.439% (2809/3072)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.469% (2927/3200)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.256% (3037/3328)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.233% (3153/3456)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.323% (3273/3584)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.433% (3394/3712)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.354% (3508/3840)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.331% (3624/3968)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.333% (3741/4096)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.430% (3862/4224)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.590% (3986/4352)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.652% (4106/4480)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.710% (4226/4608)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.660% (4341/4736)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.571% (4454/4864)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.587% (4572/4992)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.582% (4689/5120)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.730% (4814/5248)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.704% (4930/5376)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.606% (5042/5504)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.619% (5160/5632)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.649% (5279/5760)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.661% (5397/5888)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.672% (5515/6016)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.699% (5634/6144)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.709% (5752/6272)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.703% (5869/6400)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.713% (5987/6528)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.632% (6099/6656)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.598% (6214/6784)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.623% (6333/6912)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.577% (6447/7040)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.643% (6569/7168)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.584% (6682/7296)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.541% (6796/7424)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.539% (6913/7552)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.484% (7026/7680)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.509% (7145/7808)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.494% (7261/7936)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.505% (7379/8064)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.528% (7498/8192)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.550% (7617/8320)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.536% (7733/8448)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.569% (7853/8576)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.521% (7966/8704)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.452% (8077/8832)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.484% (8197/8960)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.494% (8315/9088)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.461% (8429/9216)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.460% (8546/9344)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.427% (8660/9472)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.490% (8783/9600)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.478% (8899/9728)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.447% (9013/9856)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.456% (9131/9984)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.475% (9250/10112)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.416% (9361/10240)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.464% (9483/10368)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.502% (9604/10496)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.538% (9725/10624)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.536% (9842/10752)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.553% (9961/10880)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.533% (10076/11008)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.568% (10197/11136)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.602% (10318/11264)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.617% (10437/11392)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.658% (10559/11520)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.664% (10677/11648)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.703% (10799/11776)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.667% (10912/11904)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.689% (11032/12032)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.661% (11146/12160)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.659% (11263/12288)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.648% (11379/12416)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.629% (11494/12544)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.596% (11607/12672)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.625% (11728/12800)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.615% (11844/12928)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.651% (11966/13056)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.626% (12080/13184)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.639% (12199/13312)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.637% (12316/13440)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.642% (12434/13568)\n",
      "Train Epoch: 58 | Loss: 0.245 | Acc: 91.640% (12551/13696)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.630% (12667/13824)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.628% (12784/13952)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.591% (12896/14080)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.582% (13012/14208)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.546% (13124/14336)\n",
      "Train Epoch: 58 | Loss: 0.246 | Acc: 91.565% (13244/14464)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.536% (13357/14592)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.529% (13473/14720)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.507% (13587/14848)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.546% (13710/14976)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.525% (13824/15104)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.524% (13941/15232)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.510% (14056/15360)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.522% (14175/15488)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.534% (14294/15616)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.508% (14407/15744)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.551% (14531/15872)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.544% (14647/16000)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.555% (14766/16128)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.548% (14882/16256)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.534% (14997/16384)\n",
      "Train Epoch: 58 | Loss: 0.247 | Acc: 91.533% (15114/16512)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.520% (15229/16640)\n",
      "Train Epoch: 58 | Loss: 0.248 | Acc: 91.508% (15344/16768)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.471% (15455/16896)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.447% (15568/17024)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.447% (15685/17152)\n",
      "Train Epoch: 58 | Loss: 0.249 | Acc: 91.447% (15802/17280)\n",
      "Train Epoch: 58 | Loss: 0.250 | Acc: 91.423% (15915/17408)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.423% (16032/17536)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.395% (16144/17664)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.384% (16259/17792)\n",
      "Train Epoch: 58 | Loss: 0.251 | Acc: 91.362% (16372/17920)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.301% (16478/18048)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.285% (16592/18176)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.292% (16710/18304)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.292% (16827/18432)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.315% (16948/18560)\n",
      "Train Epoch: 58 | Loss: 0.252 | Acc: 91.342% (17070/18688)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.316% (17182/18816)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.295% (17295/18944)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.296% (17412/19072)\n",
      "Train Epoch: 58 | Loss: 0.253 | Acc: 91.276% (17525/19200)\n",
      "Train Epoch: 58 | Loss: 0.254 | Acc: 91.277% (17642/19328)\n",
      "Train Epoch: 58 | Loss: 0.254 | Acc: 91.262% (17756/19456)\n",
      "Train Epoch: 58 | Loss: 0.254 | Acc: 91.279% (17876/19584)\n",
      "Train Epoch: 58 | Loss: 0.254 | Acc: 91.284% (17994/19712)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.235% (18101/19840)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.226% (18216/19968)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.197% (18327/20096)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.208% (18446/20224)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.224% (18566/20352)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.245% (18687/20480)\n",
      "Train Epoch: 58 | Loss: 0.255 | Acc: 91.256% (18806/20608)\n",
      "Train Epoch: 58 | Loss: 0.255 | Acc: 91.266% (18925/20736)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.277% (19044/20864)\n",
      "Train Epoch: 58 | Loss: 0.256 | Acc: 91.249% (19155/20992)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.241% (19270/21120)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.246% (19388/21248)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.224% (19500/21376)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.225% (19617/21504)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.194% (19727/21632)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.172% (19839/21760)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.192% (19960/21888)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.197% (20078/22016)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.189% (20193/22144)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.200% (20312/22272)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.205% (20430/22400)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.193% (20544/22528)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.181% (20658/22656)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.209% (20781/22784)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.201% (20896/22912)\n",
      "Train Epoch: 58 | Loss: 0.257 | Acc: 91.189% (21010/23040)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.182% (21125/23168)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.179% (21241/23296)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.159% (21353/23424)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.160% (21470/23552)\n",
      "Train Epoch: 58 | Loss: 0.258 | Acc: 91.128% (21579/23680)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.091% (21687/23808)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.110% (21808/23936)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.111% (21925/24064)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.096% (22038/24192)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.094% (22154/24320)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.091% (22270/24448)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.085% (22385/24576)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.095% (22504/24704)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.096% (22621/24832)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.086% (22735/24960)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.095% (22854/25088)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.069% (22964/25216)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.063% (23079/25344)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.073% (23198/25472)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.066% (23313/25600)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.084% (23434/25728)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.093% (23553/25856)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.095% (23670/25984)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.100% (23788/26112)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.120% (23910/26240)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.122% (24027/26368)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.116% (24142/26496)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.113% (24258/26624)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.130% (24379/26752)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.124% (24494/26880)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.117% (24609/27008)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.115% (24725/27136)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.120% (24843/27264)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.103% (24955/27392)\n",
      "Train Epoch: 58 | Loss: 0.259 | Acc: 91.112% (25074/27520)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.102% (25188/27648)\n",
      "Train Epoch: 58 | Loss: 0.260 | Acc: 91.071% (25296/27776)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.069% (25412/27904)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.074% (25530/28032)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.072% (25646/28160)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.063% (25760/28288)\n",
      "Train Epoch: 58 | Loss: 0.261 | Acc: 91.068% (25878/28416)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.049% (25989/28544)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.044% (26104/28672)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.038% (26219/28800)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.040% (26336/28928)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.035% (26451/29056)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.043% (26570/29184)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.038% (26685/29312)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.033% (26800/29440)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.031% (26916/29568)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 91.002% (27024/29696)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.997% (27139/29824)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.996% (27255/29952)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.014% (27377/30080)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.022% (27496/30208)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.037% (27617/30336)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.045% (27736/30464)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.030% (27848/30592)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.025% (27963/30720)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.014% (28076/30848)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.003% (28189/30976)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.008% (28307/31104)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.000% (28421/31232)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.008% (28540/31360)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.000% (28654/31488)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.014% (28775/31616)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.019% (28893/31744)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.027% (29012/31872)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.019% (29126/32000)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.036% (29248/32128)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.028% (29362/32256)\n",
      "Train Epoch: 58 | Loss: 0.262 | Acc: 91.030% (29479/32384)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.022% (29593/32512)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.026% (29711/32640)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.022% (29826/32768)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.014% (29940/32896)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.013% (30056/33024)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.023% (30176/33152)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.019% (30291/33280)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.023% (30409/33408)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.013% (30522/33536)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 90.996% (30633/33664)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.001% (30751/33792)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.002% (30868/33920)\n",
      "Train Epoch: 58 | Loss: 0.263 | Acc: 91.010% (30987/34048)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 91.005% (31102/34176)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 91.007% (31219/34304)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.994% (31331/34432)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.995% (31448/34560)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.991% (31563/34688)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.998% (31682/34816)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.997% (31798/34944)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.987% (31911/35072)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.983% (32026/35200)\n",
      "Train Epoch: 58 | Loss: 0.264 | Acc: 90.990% (32145/35328)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.986% (32260/35456)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.993% (32379/35584)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.978% (32490/35712)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.968% (32603/35840)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.964% (32718/35968)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.957% (32832/36096)\n",
      "Train Epoch: 58 | Loss: 0.265 | Acc: 90.967% (32952/36224)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.958% (33065/36352)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.951% (33179/36480)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.945% (33293/36608)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.938% (33407/36736)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.942% (33525/36864)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.936% (33639/36992)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.935% (33755/37120)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.942% (33874/37248)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.925% (33984/37376)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.926% (34101/37504)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.923% (34216/37632)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.916% (34330/37760)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.915% (34446/37888)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.909% (34560/38016)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.911% (34677/38144)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.918% (34796/38272)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.919% (34913/38400)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.923% (35031/38528)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.928% (35149/38656)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.937% (35269/38784)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.941% (35387/38912)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.938% (35502/39040)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.934% (35617/39168)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.930% (35732/39296)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.932% (35849/39424)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.941% (35969/39552)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.932% (36082/39680)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (36191/39808)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.918% (36309/39936)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.915% (36424/40064)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.916% (36541/40192)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.915% (36657/40320)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.909% (36771/40448)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.918% (36891/40576)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.925% (37010/40704)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.926% (37127/40832)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.930% (37245/40960)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.924% (37359/41088)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.926% (37476/41216)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.925% (37592/41344)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.924% (37708/41472)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.925% (37825/41600)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.929% (37943/41728)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.931% (38060/41856)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.927% (38175/41984)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.922% (38289/42112)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.902% (38397/42240)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.896% (38511/42368)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.877% (38619/42496)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.876% (38735/42624)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.873% (38850/42752)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.875% (38967/42880)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.871% (39082/43008)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.866% (39196/43136)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.870% (39314/43264)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.888% (39438/43392)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.894% (39557/43520)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.893% (39673/43648)\n",
      "Train Epoch: 58 | Loss: 0.268 | Acc: 90.908% (39796/43776)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.912% (39914/43904)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.911% (40030/44032)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.917% (40149/44160)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (40264/44288)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.915% (40381/44416)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.906% (40493/44544)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.912% (40612/44672)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.917% (40731/44800)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (40846/44928)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.922% (40966/45056)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.926% (41084/45184)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.936% (41205/45312)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.933% (41320/45440)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.926% (41433/45568)\n",
      "Train Epoch: 58 | Loss: 0.266 | Acc: 90.934% (41553/45696)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.924% (41665/45824)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.923% (41781/45952)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (41893/46080)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.911% (42008/46208)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.916% (42127/46336)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.907% (42239/46464)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.910% (42357/46592)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.912% (42474/46720)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.905% (42587/46848)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.908% (42705/46976)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.905% (42820/47104)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.900% (42934/47232)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.902% (43051/47360)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.892% (43163/47488)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.896% (43281/47616)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.895% (43397/47744)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.894% (43513/47872)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.890% (43627/48000)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.906% (43751/48128)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.915% (43872/48256)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (43988/48384)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.914% (44104/48512)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.917% (44222/48640)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.916% (44338/48768)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.922% (44457/48896)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.921% (44573/49024)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.926% (44692/49152)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.921% (44806/49280)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.908% (44916/49408)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.908% (45032/49536)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.907% (45148/49664)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.906% (45264/49792)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.901% (45378/49920)\n",
      "Train Epoch: 58 | Loss: 0.267 | Acc: 90.908% (45454/50000)\n",
      "Test Epoch: 58 | Loss: 0.255 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 58 | Loss: 0.294 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 58 | Loss: 0.305 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 58 | Loss: 0.304 | Acc: 90.000% (360/400)\n",
      "Test Epoch: 58 | Loss: 0.294 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 58 | Loss: 0.276 | Acc: 90.333% (542/600)\n",
      "Test Epoch: 58 | Loss: 0.268 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 58 | Loss: 0.289 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 58 | Loss: 0.318 | Acc: 89.444% (805/900)\n",
      "Test Epoch: 58 | Loss: 0.313 | Acc: 89.600% (896/1000)\n",
      "Test Epoch: 58 | Loss: 0.321 | Acc: 89.091% (980/1100)\n",
      "Test Epoch: 58 | Loss: 0.329 | Acc: 88.750% (1065/1200)\n",
      "Test Epoch: 58 | Loss: 0.325 | Acc: 88.769% (1154/1300)\n",
      "Test Epoch: 58 | Loss: 0.323 | Acc: 88.857% (1244/1400)\n",
      "Test Epoch: 58 | Loss: 0.328 | Acc: 88.667% (1330/1500)\n",
      "Test Epoch: 58 | Loss: 0.326 | Acc: 88.812% (1421/1600)\n",
      "Test Epoch: 58 | Loss: 0.325 | Acc: 88.882% (1511/1700)\n",
      "Test Epoch: 58 | Loss: 0.339 | Acc: 88.611% (1595/1800)\n",
      "Test Epoch: 58 | Loss: 0.340 | Acc: 88.579% (1683/1900)\n",
      "Test Epoch: 58 | Loss: 0.345 | Acc: 88.550% (1771/2000)\n",
      "Test Epoch: 58 | Loss: 0.351 | Acc: 88.286% (1854/2100)\n",
      "Test Epoch: 58 | Loss: 0.350 | Acc: 88.182% (1940/2200)\n",
      "Test Epoch: 58 | Loss: 0.353 | Acc: 88.087% (2026/2300)\n",
      "Test Epoch: 58 | Loss: 0.352 | Acc: 88.125% (2115/2400)\n",
      "Test Epoch: 58 | Loss: 0.356 | Acc: 88.120% (2203/2500)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 87.769% (2282/2600)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 87.889% (2373/2700)\n",
      "Test Epoch: 58 | Loss: 0.374 | Acc: 87.714% (2456/2800)\n",
      "Test Epoch: 58 | Loss: 0.375 | Acc: 87.690% (2543/2900)\n",
      "Test Epoch: 58 | Loss: 0.380 | Acc: 87.433% (2623/3000)\n",
      "Test Epoch: 58 | Loss: 0.382 | Acc: 87.387% (2709/3100)\n",
      "Test Epoch: 58 | Loss: 0.380 | Acc: 87.531% (2801/3200)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.636% (2892/3300)\n",
      "Test Epoch: 58 | Loss: 0.379 | Acc: 87.588% (2978/3400)\n",
      "Test Epoch: 58 | Loss: 0.382 | Acc: 87.543% (3064/3500)\n",
      "Test Epoch: 58 | Loss: 0.381 | Acc: 87.556% (3152/3600)\n",
      "Test Epoch: 58 | Loss: 0.383 | Acc: 87.595% (3241/3700)\n",
      "Test Epoch: 58 | Loss: 0.386 | Acc: 87.526% (3326/3800)\n",
      "Test Epoch: 58 | Loss: 0.385 | Acc: 87.564% (3415/3900)\n",
      "Test Epoch: 58 | Loss: 0.385 | Acc: 87.600% (3504/4000)\n",
      "Test Epoch: 58 | Loss: 0.385 | Acc: 87.634% (3593/4100)\n",
      "Test Epoch: 58 | Loss: 0.383 | Acc: 87.714% (3684/4200)\n",
      "Test Epoch: 58 | Loss: 0.380 | Acc: 87.767% (3774/4300)\n",
      "Test Epoch: 58 | Loss: 0.379 | Acc: 87.932% (3869/4400)\n",
      "Test Epoch: 58 | Loss: 0.377 | Acc: 88.000% (3960/4500)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.935% (4045/4600)\n",
      "Test Epoch: 58 | Loss: 0.377 | Acc: 87.894% (4131/4700)\n",
      "Test Epoch: 58 | Loss: 0.377 | Acc: 87.854% (4217/4800)\n",
      "Test Epoch: 58 | Loss: 0.375 | Acc: 87.918% (4308/4900)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.800% (4390/5000)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.824% (4479/5100)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.750% (4563/5200)\n",
      "Test Epoch: 58 | Loss: 0.379 | Acc: 87.698% (4648/5300)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.778% (4740/5400)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.745% (4826/5500)\n",
      "Test Epoch: 58 | Loss: 0.379 | Acc: 87.679% (4910/5600)\n",
      "Test Epoch: 58 | Loss: 0.379 | Acc: 87.719% (5000/5700)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.724% (5088/5800)\n",
      "Test Epoch: 58 | Loss: 0.380 | Acc: 87.644% (5171/5900)\n",
      "Test Epoch: 58 | Loss: 0.378 | Acc: 87.683% (5261/6000)\n",
      "Test Epoch: 58 | Loss: 0.375 | Acc: 87.738% (5352/6100)\n",
      "Test Epoch: 58 | Loss: 0.376 | Acc: 87.774% (5442/6200)\n",
      "Test Epoch: 58 | Loss: 0.375 | Acc: 87.810% (5532/6300)\n",
      "Test Epoch: 58 | Loss: 0.373 | Acc: 87.875% (5624/6400)\n",
      "Test Epoch: 58 | Loss: 0.376 | Acc: 87.785% (5706/6500)\n",
      "Test Epoch: 58 | Loss: 0.372 | Acc: 87.939% (5804/6600)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 88.030% (5898/6700)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 87.971% (5982/6800)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 88.014% (6073/6900)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 87.986% (6159/7000)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 87.986% (6247/7100)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 87.958% (6333/7200)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.027% (6426/7300)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.041% (6515/7400)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 87.987% (6599/7500)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 88.013% (6689/7600)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 87.948% (6772/7700)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.013% (6865/7800)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.025% (6954/7900)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.000% (7040/8000)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 87.988% (7127/8100)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 87.976% (7214/8200)\n",
      "Test Epoch: 58 | Loss: 0.366 | Acc: 87.988% (7303/8300)\n",
      "Test Epoch: 58 | Loss: 0.366 | Acc: 88.012% (7393/8400)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 87.976% (7478/8500)\n",
      "Test Epoch: 58 | Loss: 0.371 | Acc: 87.953% (7564/8600)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 87.966% (7653/8700)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 87.989% (7743/8800)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.011% (7833/8900)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.011% (7921/9000)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.022% (8010/9100)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.033% (8099/9200)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.011% (8185/9300)\n",
      "Test Epoch: 58 | Loss: 0.370 | Acc: 88.032% (8275/9400)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 88.042% (8364/9500)\n",
      "Test Epoch: 58 | Loss: 0.369 | Acc: 88.062% (8454/9600)\n",
      "Test Epoch: 58 | Loss: 0.366 | Acc: 88.165% (8552/9700)\n",
      "Test Epoch: 58 | Loss: 0.366 | Acc: 88.184% (8642/9800)\n",
      "Test Epoch: 58 | Loss: 0.368 | Acc: 88.111% (8723/9900)\n",
      "Test Epoch: 58 | Loss: 0.367 | Acc: 88.070% (8807/10000)\n",
      "\n",
      "Epoch: 59\n",
      "Train Epoch: 59 | Loss: 0.226 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 59 | Loss: 0.201 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 59 | Loss: 0.204 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.211% (467/512)\n",
      "Train Epoch: 59 | Loss: 0.242 | Acc: 91.562% (586/640)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 90.885% (698/768)\n",
      "Train Epoch: 59 | Loss: 0.275 | Acc: 90.402% (810/896)\n",
      "Train Epoch: 59 | Loss: 0.273 | Acc: 90.723% (929/1024)\n",
      "Train Epoch: 59 | Loss: 0.274 | Acc: 90.625% (1044/1152)\n",
      "Train Epoch: 59 | Loss: 0.267 | Acc: 91.016% (1165/1280)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.193% (1284/1408)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.081% (1399/1536)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 90.925% (1513/1664)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.016% (1631/1792)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.146% (1750/1920)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 90.967% (1863/2048)\n",
      "Train Epoch: 59 | Loss: 0.275 | Acc: 90.579% (1971/2176)\n",
      "Train Epoch: 59 | Loss: 0.270 | Acc: 90.755% (2091/2304)\n",
      "Train Epoch: 59 | Loss: 0.268 | Acc: 90.831% (2209/2432)\n",
      "Train Epoch: 59 | Loss: 0.268 | Acc: 90.859% (2326/2560)\n",
      "Train Epoch: 59 | Loss: 0.273 | Acc: 90.774% (2440/2688)\n",
      "Train Epoch: 59 | Loss: 0.275 | Acc: 90.696% (2554/2816)\n",
      "Train Epoch: 59 | Loss: 0.275 | Acc: 90.727% (2671/2944)\n",
      "Train Epoch: 59 | Loss: 0.275 | Acc: 90.723% (2787/3072)\n",
      "Train Epoch: 59 | Loss: 0.270 | Acc: 90.938% (2910/3200)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.166% (3034/3328)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.233% (3153/3456)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.155% (3267/3584)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.110% (3382/3712)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.120% (3499/3840)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.331% (3624/3968)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.431% (3745/4096)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.454% (3863/4224)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.429% (3979/4352)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.384% (4094/4480)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.385% (4211/4608)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.470% (4332/4736)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.571% (4454/4864)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.647% (4575/4992)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.660% (4693/5120)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.635% (4809/5248)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.611% (4925/5376)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.570% (5040/5504)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.566% (5157/5632)\n",
      "Train Epoch: 59 | Loss: 0.249 | Acc: 91.597% (5276/5760)\n",
      "Train Epoch: 59 | Loss: 0.248 | Acc: 91.644% (5396/5888)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.672% (5515/6016)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.650% (5631/6144)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.629% (5747/6272)\n",
      "Train Epoch: 59 | Loss: 0.245 | Acc: 91.672% (5867/6400)\n",
      "Train Epoch: 59 | Loss: 0.245 | Acc: 91.667% (5984/6528)\n",
      "Train Epoch: 59 | Loss: 0.246 | Acc: 91.572% (6095/6656)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.583% (6213/6784)\n",
      "Train Epoch: 59 | Loss: 0.246 | Acc: 91.609% (6332/6912)\n",
      "Train Epoch: 59 | Loss: 0.248 | Acc: 91.506% (6442/7040)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.518% (6560/7168)\n",
      "Train Epoch: 59 | Loss: 0.246 | Acc: 91.557% (6680/7296)\n",
      "Train Epoch: 59 | Loss: 0.247 | Acc: 91.581% (6799/7424)\n",
      "Train Epoch: 59 | Loss: 0.249 | Acc: 91.525% (6912/7552)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.562% (7032/7680)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.560% (7149/7808)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.557% (7266/7936)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.567% (7384/8064)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.455% (7492/8192)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.490% (7612/8320)\n",
      "Train Epoch: 59 | Loss: 0.250 | Acc: 91.536% (7733/8448)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.465% (7844/8576)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.395% (7955/8704)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.406% (8073/8832)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.395% (8189/8960)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.384% (8305/9088)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.395% (8423/9216)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.396% (8540/9344)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.385% (8656/9472)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.375% (8772/9600)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.375% (8889/9728)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.345% (9003/9856)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.396% (9125/9984)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.406% (9243/10112)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.396% (9359/10240)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.377% (9474/10368)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.349% (9588/10496)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.397% (9710/10624)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.360% (9823/10752)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.278% (9931/10880)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.288% (10049/11008)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.298% (10167/11136)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.317% (10286/11264)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.257% (10396/11392)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.267% (10514/11520)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.243% (10628/11648)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.270% (10748/11776)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.255% (10863/11904)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.240% (10978/12032)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.275% (11099/12160)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.309% (11220/12288)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.334% (11340/12416)\n",
      "Train Epoch: 59 | Loss: 0.251 | Acc: 91.335% (11457/12544)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.319% (11572/12672)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.305% (11687/12800)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.275% (11800/12928)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.261% (11915/13056)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.239% (12029/13184)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.256% (12148/13312)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.265% (12266/13440)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.266% (12383/13568)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.253% (12498/13696)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.262% (12616/13824)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.284% (12736/13952)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.293% (12854/14080)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.287% (12970/14208)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.288% (13087/14336)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.282% (13203/14464)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.283% (13320/14592)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.284% (13437/14720)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.319% (13559/14848)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.333% (13678/14976)\n",
      "Train Epoch: 59 | Loss: 0.252 | Acc: 91.353% (13798/15104)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.301% (13907/15232)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.263% (14018/15360)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.251% (14133/15488)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.246% (14249/15616)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.254% (14367/15744)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.249% (14483/15872)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.250% (14600/16000)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.245% (14716/16128)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.265% (14836/16256)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.278% (14955/16384)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.261% (15069/16512)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.262% (15186/16640)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.257% (15302/16768)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.282% (15423/16896)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.283% (15540/17024)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.266% (15654/17152)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.262% (15770/17280)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.268% (15888/17408)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.264% (16004/17536)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.287% (16125/17664)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.299% (16244/17792)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.306% (16362/17920)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.307% (16479/18048)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.302% (16595/18176)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.302% (16712/18304)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.314% (16831/18432)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.315% (16948/18560)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.305% (17063/18688)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.327% (17184/18816)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.290% (17294/18944)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.296% (17412/19072)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.302% (17530/19200)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.318% (17650/19328)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.319% (17767/19456)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.309% (17882/19584)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.310% (17999/19712)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.326% (18119/19840)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.326% (18236/19968)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.352% (18358/20096)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.352% (18475/20224)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.362% (18594/20352)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.377% (18714/20480)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.392% (18834/20608)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.387% (18950/20736)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.392% (19068/20864)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.392% (19185/20992)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.392% (19302/21120)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.373% (19415/21248)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.369% (19531/21376)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.355% (19645/21504)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.360% (19763/21632)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.360% (19880/21760)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.351% (19995/21888)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.374% (20117/22016)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.388% (20237/22144)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.375% (20351/22272)\n",
      "Train Epoch: 59 | Loss: 0.253 | Acc: 91.379% (20469/22400)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.366% (20583/22528)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.344% (20695/22656)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.336% (20810/22784)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.367% (20934/22912)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.345% (21046/23040)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.337% (21161/23168)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.342% (21279/23296)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.338% (21395/23424)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.334% (21511/23552)\n",
      "Train Epoch: 59 | Loss: 0.254 | Acc: 91.351% (21632/23680)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.347% (21748/23808)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.339% (21863/23936)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.311% (21973/24064)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.262% (22078/24192)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.266% (22196/24320)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.275% (22315/24448)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.288% (22435/24576)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.293% (22553/24704)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.302% (22672/24832)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.290% (22786/24960)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.323% (22911/25088)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.311% (23025/25216)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.315% (23143/25344)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.340% (23266/25472)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.328% (23380/25600)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.317% (23494/25728)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.298% (23606/25856)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.298% (23723/25984)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.280% (23835/26112)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.311% (23960/26240)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.319% (24079/26368)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.319% (24196/26496)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.309% (24310/26624)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.320% (24430/26752)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.328% (24549/26880)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.317% (24663/27008)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.329% (24783/27136)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.329% (24900/27264)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.322% (25015/27392)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.334% (25135/27520)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.345% (25255/27648)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.367% (25378/27776)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.352% (25491/27904)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.371% (25613/28032)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.364% (25728/28160)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.364% (25845/28288)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.364% (25962/28416)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.382% (26084/28544)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.378% (26200/28672)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.361% (26312/28800)\n",
      "Train Epoch: 59 | Loss: 0.255 | Acc: 91.361% (26429/28928)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.331% (26537/29056)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.334% (26655/29184)\n",
      "Train Epoch: 59 | Loss: 0.256 | Acc: 91.335% (26772/29312)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.325% (26886/29440)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.325% (27003/29568)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.302% (27113/29696)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.296% (27228/29824)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.296% (27345/29952)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.283% (27458/30080)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.290% (27577/30208)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.304% (27698/30336)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.298% (27813/30464)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.295% (27929/30592)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.289% (28044/30720)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.257% (28151/30848)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.245% (28264/30976)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.252% (28383/31104)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.259% (28502/31232)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.260% (28619/31360)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.257% (28735/31488)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.245% (28848/31616)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.246% (28965/31744)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.256% (29085/31872)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.259% (29203/32000)\n",
      "Train Epoch: 59 | Loss: 0.257 | Acc: 91.266% (29322/32128)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.251% (29434/32256)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.233% (29545/32384)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.216% (29656/32512)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.219% (29774/32640)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.235% (29896/32768)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.245% (30016/32896)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.237% (30130/33024)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.243% (30249/33152)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.244% (30366/33280)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.236% (30480/33408)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.239% (30598/33536)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.234% (30713/33664)\n",
      "Train Epoch: 59 | Loss: 0.258 | Acc: 91.229% (30828/33792)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.209% (30938/33920)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.215% (31057/34048)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.190% (31165/34176)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.182% (31279/34304)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.183% (31396/34432)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.181% (31512/34560)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.190% (31632/34688)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.194% (31750/34816)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.189% (31865/34944)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.198% (31985/35072)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.202% (32103/35200)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.202% (32220/35328)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.192% (32333/35456)\n",
      "Train Epoch: 59 | Loss: 0.259 | Acc: 91.207% (32455/35584)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.202% (32570/35712)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.191% (32683/35840)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.206% (32805/35968)\n",
      "Train Epoch: 59 | Loss: 0.260 | Acc: 91.187% (32915/36096)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.185% (33031/36224)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.178% (33145/36352)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.171% (33259/36480)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.166% (33374/36608)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.169% (33492/36736)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.159% (33605/36864)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.152% (33719/36992)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.145% (33833/37120)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.140% (33948/37248)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.131% (34061/37376)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.118% (34173/37504)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.119% (34290/37632)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.096% (34398/37760)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.090% (34512/37888)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.093% (34630/38016)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.107% (34752/38144)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.103% (34867/38272)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.117% (34989/38400)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.105% (35101/38528)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.109% (35219/38656)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.105% (35334/38784)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.113% (35454/38912)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.124% (35575/39040)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.110% (35686/39168)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.106% (35801/39296)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.112% (35920/39424)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.115% (36038/39552)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.111% (36153/39680)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.112% (36270/39808)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.131% (36394/39936)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.144% (36516/40064)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.155% (36637/40192)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.146% (36750/40320)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.161% (36873/40448)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.147% (36984/40576)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.141% (37098/40704)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.144% (37216/40832)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.140% (37331/40960)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.139% (37447/41088)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.135% (37562/41216)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.133% (37678/41344)\n",
      "Train Epoch: 59 | Loss: 0.261 | Acc: 91.119% (37789/41472)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.111% (37902/41600)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.104% (38016/41728)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.110% (38135/41856)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.104% (38249/41984)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.107% (38367/42112)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.101% (38481/42240)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.095% (38595/42368)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.089% (38709/42496)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.090% (38826/42624)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.079% (38938/42752)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.070% (39051/42880)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.064% (39165/43008)\n",
      "Train Epoch: 59 | Loss: 0.262 | Acc: 91.059% (39279/43136)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.041% (39388/43264)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.047% (39507/43392)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.048% (39624/43520)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.053% (39743/43648)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.059% (39862/43776)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.058% (39978/43904)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.059% (40095/44032)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.067% (40215/44160)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.047% (40323/44288)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.048% (40440/44416)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.047% (40556/44544)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.050% (40674/44672)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.060% (40795/44800)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.061% (40912/44928)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.062% (41029/45056)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.054% (41142/45184)\n",
      "Train Epoch: 59 | Loss: 0.263 | Acc: 91.049% (41256/45312)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.039% (41368/45440)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.033% (41482/45568)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.039% (41601/45696)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.037% (41717/45824)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.043% (41836/45952)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.039% (41951/46080)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.034% (42065/46208)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.035% (42182/46336)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.034% (42298/46464)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.035% (42415/46592)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.025% (42527/46720)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.026% (42644/46848)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.023% (42759/46976)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.026% (42877/47104)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.021% (42991/47232)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.026% (43110/47360)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.034% (43230/47488)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.022% (43341/47616)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.015% (43454/47744)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.022% (43574/47872)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.029% (43694/48000)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.022% (43807/48128)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.025% (43925/48256)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.024% (44041/48384)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.029% (44160/48512)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.034% (44279/48640)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.027% (44392/48768)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.032% (44511/48896)\n",
      "Train Epoch: 59 | Loss: 0.264 | Acc: 91.029% (44626/49024)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.024% (44740/49152)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.021% (44855/49280)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.018% (44970/49408)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.017% (45086/49536)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.012% (45200/49664)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.013% (45317/49792)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.010% (45432/49920)\n",
      "Train Epoch: 59 | Loss: 0.265 | Acc: 91.006% (45503/50000)\n",
      "Test Epoch: 59 | Loss: 0.326 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 59 | Loss: 0.298 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 59 | Loss: 0.289 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 59 | Loss: 0.281 | Acc: 91.500% (366/400)\n",
      "Test Epoch: 59 | Loss: 0.273 | Acc: 91.000% (455/500)\n",
      "Test Epoch: 59 | Loss: 0.275 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 59 | Loss: 0.276 | Acc: 90.429% (633/700)\n",
      "Test Epoch: 59 | Loss: 0.293 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 59 | Loss: 0.305 | Acc: 89.667% (807/900)\n",
      "Test Epoch: 59 | Loss: 0.312 | Acc: 89.700% (897/1000)\n",
      "Test Epoch: 59 | Loss: 0.324 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 59 | Loss: 0.339 | Acc: 89.167% (1070/1200)\n",
      "Test Epoch: 59 | Loss: 0.328 | Acc: 89.385% (1162/1300)\n",
      "Test Epoch: 59 | Loss: 0.330 | Acc: 89.214% (1249/1400)\n",
      "Test Epoch: 59 | Loss: 0.329 | Acc: 89.333% (1340/1500)\n",
      "Test Epoch: 59 | Loss: 0.325 | Acc: 89.375% (1430/1600)\n",
      "Test Epoch: 59 | Loss: 0.328 | Acc: 89.412% (1520/1700)\n",
      "Test Epoch: 59 | Loss: 0.332 | Acc: 89.333% (1608/1800)\n",
      "Test Epoch: 59 | Loss: 0.328 | Acc: 89.316% (1697/1900)\n",
      "Test Epoch: 59 | Loss: 0.331 | Acc: 89.350% (1787/2000)\n",
      "Test Epoch: 59 | Loss: 0.334 | Acc: 89.143% (1872/2100)\n",
      "Test Epoch: 59 | Loss: 0.331 | Acc: 89.136% (1961/2200)\n",
      "Test Epoch: 59 | Loss: 0.337 | Acc: 88.957% (2046/2300)\n",
      "Test Epoch: 59 | Loss: 0.337 | Acc: 88.708% (2129/2400)\n",
      "Test Epoch: 59 | Loss: 0.337 | Acc: 88.840% (2221/2500)\n",
      "Test Epoch: 59 | Loss: 0.345 | Acc: 88.769% (2308/2600)\n",
      "Test Epoch: 59 | Loss: 0.347 | Acc: 88.667% (2394/2700)\n",
      "Test Epoch: 59 | Loss: 0.345 | Acc: 88.679% (2483/2800)\n",
      "Test Epoch: 59 | Loss: 0.346 | Acc: 88.724% (2573/2900)\n",
      "Test Epoch: 59 | Loss: 0.349 | Acc: 88.633% (2659/3000)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.548% (2745/3100)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 88.625% (2836/3200)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 88.606% (2924/3300)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 88.618% (3013/3400)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.571% (3100/3500)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.583% (3189/3600)\n",
      "Test Epoch: 59 | Loss: 0.359 | Acc: 88.541% (3276/3700)\n",
      "Test Epoch: 59 | Loss: 0.362 | Acc: 88.447% (3361/3800)\n",
      "Test Epoch: 59 | Loss: 0.362 | Acc: 88.513% (3452/3900)\n",
      "Test Epoch: 59 | Loss: 0.362 | Acc: 88.575% (3543/4000)\n",
      "Test Epoch: 59 | Loss: 0.365 | Acc: 88.512% (3629/4100)\n",
      "Test Epoch: 59 | Loss: 0.363 | Acc: 88.500% (3717/4200)\n",
      "Test Epoch: 59 | Loss: 0.361 | Acc: 88.558% (3808/4300)\n",
      "Test Epoch: 59 | Loss: 0.360 | Acc: 88.614% (3899/4400)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.689% (3991/4500)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.652% (4078/4600)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.681% (4168/4700)\n",
      "Test Epoch: 59 | Loss: 0.361 | Acc: 88.562% (4251/4800)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.551% (4339/4900)\n",
      "Test Epoch: 59 | Loss: 0.360 | Acc: 88.400% (4420/5000)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.471% (4512/5100)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.500% (4602/5200)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.491% (4690/5300)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.500% (4779/5400)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.473% (4866/5500)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.429% (4952/5600)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.439% (5041/5700)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.483% (5132/5800)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.407% (5216/5900)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.467% (5308/6000)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.426% (5394/6100)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.403% (5481/6200)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.460% (5573/6300)\n",
      "Test Epoch: 59 | Loss: 0.352 | Acc: 88.547% (5667/6400)\n",
      "Test Epoch: 59 | Loss: 0.352 | Acc: 88.554% (5756/6500)\n",
      "Test Epoch: 59 | Loss: 0.350 | Acc: 88.621% (5849/6600)\n",
      "Test Epoch: 59 | Loss: 0.348 | Acc: 88.657% (5940/6700)\n",
      "Test Epoch: 59 | Loss: 0.352 | Acc: 88.544% (6021/6800)\n",
      "Test Epoch: 59 | Loss: 0.351 | Acc: 88.594% (6113/6900)\n",
      "Test Epoch: 59 | Loss: 0.351 | Acc: 88.600% (6202/7000)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.549% (6287/7100)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.528% (6374/7200)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.562% (6465/7300)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 88.608% (6557/7400)\n",
      "Test Epoch: 59 | Loss: 0.352 | Acc: 88.640% (6648/7500)\n",
      "Test Epoch: 59 | Loss: 0.353 | Acc: 88.671% (6739/7600)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.649% (6826/7700)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.628% (6913/7800)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.608% (7000/7900)\n",
      "Test Epoch: 59 | Loss: 0.356 | Acc: 88.575% (7086/8000)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.630% (7179/8100)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.634% (7268/8200)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.614% (7355/8300)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.583% (7441/8400)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.553% (7527/8500)\n",
      "Test Epoch: 59 | Loss: 0.360 | Acc: 88.488% (7610/8600)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.506% (7700/8700)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.545% (7792/8800)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.551% (7881/8900)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.544% (7969/9000)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.527% (8056/9100)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.543% (8146/9200)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.538% (8234/9300)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.553% (8324/9400)\n",
      "Test Epoch: 59 | Loss: 0.358 | Acc: 88.568% (8414/9500)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.542% (8500/9600)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.588% (8593/9700)\n",
      "Test Epoch: 59 | Loss: 0.355 | Acc: 88.602% (8683/9800)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.576% (8769/9900)\n",
      "Test Epoch: 59 | Loss: 0.357 | Acc: 88.550% (8855/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 60\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.927% (353/384)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.992% (471/512)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 92.057% (707/768)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.741% (822/896)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.113% (933/1024)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.059% (1049/1152)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 90.938% (1164/1280)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.264% (1285/1408)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.536% (1406/1536)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.466% (1522/1664)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.629% (1642/1792)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.719% (1761/1920)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.699% (1878/2048)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.544% (1992/2176)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.493% (2108/2304)\n",
      "Train Epoch: 60 | Loss: 0.247 | Acc: 91.488% (2225/2432)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.289% (2337/2560)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 91.183% (2451/2688)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.229% (2569/2816)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.202% (2685/2944)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 91.211% (2802/3072)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.219% (2919/3200)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.106% (3032/3328)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.175% (3151/3456)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 91.211% (3269/3584)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.137% (3383/3712)\n",
      "Train Epoch: 60 | Loss: 0.247 | Acc: 91.328% (3507/3840)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 91.280% (3622/3968)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.284% (3739/4096)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.454% (3863/4224)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.452% (3980/4352)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.518% (4100/4480)\n",
      "Train Epoch: 60 | Loss: 0.249 | Acc: 91.536% (4218/4608)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.596% (4338/4736)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.591% (4455/4864)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.687% (4577/4992)\n",
      "Train Epoch: 60 | Loss: 0.247 | Acc: 91.602% (4690/5120)\n",
      "Train Epoch: 60 | Loss: 0.247 | Acc: 91.578% (4806/5248)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.611% (4925/5376)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.733% (5049/5504)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.637% (5161/5632)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.545% (5273/5760)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.542% (5390/5888)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.589% (5510/6016)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.618% (5629/6144)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.614% (5746/6272)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.516% (5857/6400)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.513% (5974/6528)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.556% (6094/6656)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.568% (6212/6784)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.580% (6330/6912)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.534% (6444/7040)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.546% (6562/7168)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.557% (6680/7296)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.554% (6797/7424)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.618% (6919/7552)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.641% (7038/7680)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.637% (7155/7808)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.633% (7272/7936)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.617% (7388/8064)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.663% (7509/8192)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.647% (7625/8320)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.607% (7739/8448)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.604% (7856/8576)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.636% (7976/8704)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.621% (8092/8832)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.629% (8210/8960)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.670% (8331/9088)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.667% (8448/9216)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.663% (8565/9344)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.639% (8680/9472)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.688% (8802/9600)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.704% (8921/9728)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.721% (9040/9856)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.727% (9158/9984)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.752% (9278/10112)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.709% (9391/10240)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.734% (9511/10368)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.759% (9631/10496)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.773% (9750/10624)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.778% (9868/10752)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.756% (9983/10880)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.788% (10104/11008)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.801% (10223/11136)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.832% (10344/11264)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.845% (10463/11392)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.849% (10581/11520)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.861% (10700/11648)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.882% (10820/11776)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.860% (10935/11904)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.863% (11053/12032)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.859% (11170/12160)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.846% (11286/12288)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.793% (11397/12416)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.789% (11514/12544)\n",
      "Train Epoch: 60 | Loss: 0.240 | Acc: 91.785% (11631/12672)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.844% (11756/12800)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.886% (11879/12928)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.858% (11993/13056)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.854% (12110/13184)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.857% (12228/13312)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.868% (12347/13440)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.871% (12465/13568)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.852% (12580/13696)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.833% (12695/13824)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.836% (12813/13952)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.847% (12932/14080)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.857% (13051/14208)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.860% (13169/14336)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.869% (13288/14464)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.852% (13403/14592)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.848% (13520/14720)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.844% (13637/14848)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.814% (13750/14976)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.823% (13869/15104)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.833% (13988/15232)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.855% (14109/15360)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.845% (14225/15488)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.848% (14343/15616)\n",
      "Train Epoch: 60 | Loss: 0.237 | Acc: 91.857% (14462/15744)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.847% (14578/15872)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.850% (14696/16000)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.822% (14809/16128)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.825% (14927/16256)\n",
      "Train Epoch: 60 | Loss: 0.238 | Acc: 91.846% (15048/16384)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.836% (15164/16512)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.827% (15280/16640)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.782% (15390/16768)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.797% (15510/16896)\n",
      "Train Epoch: 60 | Loss: 0.239 | Acc: 91.776% (15624/17024)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.750% (15737/17152)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.742% (15853/17280)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.739% (15970/17408)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.743% (16088/17536)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.740% (16205/17664)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.727% (16320/17792)\n",
      "Train Epoch: 60 | Loss: 0.241 | Acc: 91.719% (16436/17920)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.717% (16553/18048)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.714% (16670/18176)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.712% (16787/18304)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.699% (16902/18432)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.703% (17020/18560)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.711% (17139/18688)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.704% (17255/18816)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.734% (17378/18944)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.705% (17490/19072)\n",
      "Train Epoch: 60 | Loss: 0.242 | Acc: 91.698% (17606/19200)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.696% (17723/19328)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.689% (17839/19456)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.682% (17955/19584)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.655% (18067/19712)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.658% (18185/19840)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.662% (18303/19968)\n",
      "Train Epoch: 60 | Loss: 0.243 | Acc: 91.660% (18420/20096)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.668% (18539/20224)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.667% (18656/20352)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.655% (18771/20480)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.654% (18888/20608)\n",
      "Train Epoch: 60 | Loss: 0.244 | Acc: 91.643% (19003/20736)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.627% (19117/20864)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.621% (19233/20992)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.634% (19353/21120)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.613% (19466/21248)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.598% (19580/21376)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.597% (19697/21504)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.591% (19813/21632)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.581% (19928/21760)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.584% (20046/21888)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.592% (20165/22016)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.600% (20284/22144)\n",
      "Train Epoch: 60 | Loss: 0.245 | Acc: 91.595% (20400/22272)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.580% (20514/22400)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.570% (20629/22528)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.574% (20747/22656)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.560% (20861/22784)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.576% (20982/22912)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.554% (21094/23040)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.540% (21208/23168)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.539% (21325/23296)\n",
      "Train Epoch: 60 | Loss: 0.246 | Acc: 91.534% (21441/23424)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.508% (21552/23552)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.499% (21667/23680)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.486% (21781/23808)\n",
      "Train Epoch: 60 | Loss: 0.248 | Acc: 91.481% (21897/23936)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.435% (22003/24064)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.406% (22113/24192)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.410% (22231/24320)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.386% (22342/24448)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.390% (22460/24576)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.386% (22576/24704)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.370% (22689/24832)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.382% (22809/24960)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.378% (22925/25088)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.367% (23039/25216)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.359% (23154/25344)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.336% (23265/25472)\n",
      "Train Epoch: 60 | Loss: 0.250 | Acc: 91.336% (23382/25600)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.325% (23496/25728)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.275% (23600/25856)\n",
      "Train Epoch: 60 | Loss: 0.251 | Acc: 91.272% (23716/25984)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.245% (23826/26112)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.254% (23945/26240)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.255% (24062/26368)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.255% (24179/26496)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.256% (24296/26624)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.234% (24407/26752)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.224% (24521/26880)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.225% (24638/27008)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.229% (24756/27136)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.227% (24872/27264)\n",
      "Train Epoch: 60 | Loss: 0.252 | Acc: 91.213% (24985/27392)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.203% (25099/27520)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.186% (25211/27648)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.187% (25328/27776)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.177% (25442/27904)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.174% (25558/28032)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.158% (25670/28160)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.169% (25790/28288)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.163% (25905/28416)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.154% (26019/28544)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.159% (26137/28672)\n",
      "Train Epoch: 60 | Loss: 0.253 | Acc: 91.146% (26250/28800)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.133% (26363/28928)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.121% (26476/29056)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.112% (26590/29184)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.120% (26709/29312)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.135% (26830/29440)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.129% (26945/29568)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.137% (27064/29696)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.118% (27175/29824)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.132% (27296/29952)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.107% (27405/30080)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.115% (27524/30208)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.096% (27635/30336)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.104% (27754/30464)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.099% (27869/30592)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.084% (27981/30720)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.095% (28101/30848)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.106% (28221/30976)\n",
      "Train Epoch: 60 | Loss: 0.254 | Acc: 91.117% (28341/31104)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.102% (28453/31232)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.091% (28566/31360)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.092% (28683/31488)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.096% (28801/31616)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.098% (28918/31744)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.083% (29030/31872)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.084% (29147/32000)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.073% (29260/32128)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.062% (29373/32256)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.051% (29486/32384)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.059% (29605/32512)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.054% (29720/32640)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.052% (29836/32768)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.063% (29956/32896)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.052% (30069/33024)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.053% (30186/33152)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.049% (30301/33280)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.050% (30418/33408)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.057% (30537/33536)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.056% (30653/33664)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.054% (30769/33792)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.044% (30882/33920)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.057% (31003/34048)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.052% (31118/34176)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.054% (31235/34304)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.066% (31356/34432)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.068% (31473/34560)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.078% (31593/34688)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.064% (31705/34816)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.074% (31825/34944)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.070% (31940/35072)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.074% (32058/35200)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.055% (32168/35328)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.057% (32285/35456)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.047% (32398/35584)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.056% (32518/35712)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.063% (32637/35840)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.064% (32754/35968)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.063% (32870/36096)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.069% (32989/36224)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.049% (33098/36352)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.058% (33218/36480)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.068% (33338/36608)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.071% (33456/36736)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.056% (33567/36864)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.068% (33688/36992)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.080% (33809/37120)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.084% (33927/37248)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.085% (34044/37376)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.089% (34162/37504)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.085% (34277/37632)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.094% (34397/37760)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.090% (34512/37888)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.093% (34630/38016)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.102% (34750/38144)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.106% (34868/38272)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.102% (34983/38400)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.103% (35100/38528)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.122% (35224/38656)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.117% (35339/38784)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.113% (35454/38912)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.112% (35570/39040)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.105% (35684/39168)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.096% (35797/39296)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.089% (35911/39424)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.088% (36027/39552)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.094% (36146/39680)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.097% (36264/39808)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.096% (36380/39936)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.104% (36500/40064)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.110% (36619/40192)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.089% (36727/40320)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.082% (36841/40448)\n",
      "Train Epoch: 60 | Loss: 0.255 | Acc: 91.101% (36965/40576)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.087% (37076/40704)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.088% (37193/40832)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.084% (37308/40960)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.075% (37421/41088)\n",
      "Train Epoch: 60 | Loss: 0.256 | Acc: 91.076% (37538/41216)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.065% (37650/41344)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.049% (37760/41472)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.041% (37873/41600)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.035% (37987/41728)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.036% (38104/41856)\n",
      "Train Epoch: 60 | Loss: 0.257 | Acc: 91.032% (38219/41984)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.026% (38333/42112)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.023% (38448/42240)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.029% (38567/42368)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.034% (38686/42496)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.024% (38798/42624)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.027% (38916/42752)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.021% (39030/42880)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.016% (39144/43008)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.014% (39260/43136)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.018% (39378/43264)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.012% (39492/43392)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.009% (39607/43520)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.008% (39723/43648)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.009% (39840/43776)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.014% (39959/43904)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.004% (40071/44032)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 90.999% (40185/44160)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.011% (40307/44288)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.992% (40415/44416)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.998% (40534/44544)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.003% (40653/44672)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.009% (40772/44800)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.006% (40887/44928)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.011% (41006/45056)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.012% (41123/45184)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.013% (41240/45312)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.019% (41359/45440)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.020% (41476/45568)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.028% (41596/45696)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.022% (41710/45824)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.028% (41829/45952)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.013% (41939/46080)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.015% (42056/46208)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.994% (42163/46336)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.995% (42280/46464)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.005% (42401/46592)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.004% (42517/46720)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.013% (42638/46848)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.010% (42753/46976)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.014% (42871/47104)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.021% (42991/47232)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.018% (43106/47360)\n",
      "Train Epoch: 60 | Loss: 0.258 | Acc: 91.012% (43220/47488)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.001% (43331/47616)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.002% (43448/47744)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.005% (43566/47872)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.996% (43678/48000)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.001% (43797/48128)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.996% (43911/48256)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.003% (44031/48384)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.002% (44147/48512)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.999% (44262/48640)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 90.998% (44378/48768)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.007% (44499/48896)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.004% (44614/49024)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.007% (44732/49152)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.015% (44852/49280)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.018% (44970/49408)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.009% (45082/49536)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.002% (45195/49664)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.007% (45314/49792)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.010% (45432/49920)\n",
      "Train Epoch: 60 | Loss: 0.259 | Acc: 91.006% (45503/50000)\n",
      "Test Epoch: 60 | Loss: 0.247 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 60 | Loss: 0.337 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 60 | Loss: 0.322 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 60 | Loss: 0.303 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 60 | Loss: 0.292 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 60 | Loss: 0.296 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 60 | Loss: 0.306 | Acc: 88.857% (622/700)\n",
      "Test Epoch: 60 | Loss: 0.320 | Acc: 88.875% (711/800)\n",
      "Test Epoch: 60 | Loss: 0.339 | Acc: 88.889% (800/900)\n",
      "Test Epoch: 60 | Loss: 0.347 | Acc: 88.700% (887/1000)\n",
      "Test Epoch: 60 | Loss: 0.355 | Acc: 88.545% (974/1100)\n",
      "Test Epoch: 60 | Loss: 0.361 | Acc: 88.417% (1061/1200)\n",
      "Test Epoch: 60 | Loss: 0.352 | Acc: 88.538% (1151/1300)\n",
      "Test Epoch: 60 | Loss: 0.357 | Acc: 88.286% (1236/1400)\n",
      "Test Epoch: 60 | Loss: 0.357 | Acc: 87.933% (1319/1500)\n",
      "Test Epoch: 60 | Loss: 0.358 | Acc: 87.938% (1407/1600)\n",
      "Test Epoch: 60 | Loss: 0.356 | Acc: 88.176% (1499/1700)\n",
      "Test Epoch: 60 | Loss: 0.355 | Acc: 88.056% (1585/1800)\n",
      "Test Epoch: 60 | Loss: 0.356 | Acc: 87.947% (1671/1900)\n",
      "Test Epoch: 60 | Loss: 0.356 | Acc: 88.100% (1762/2000)\n",
      "Test Epoch: 60 | Loss: 0.356 | Acc: 88.000% (1848/2100)\n",
      "Test Epoch: 60 | Loss: 0.354 | Acc: 88.136% (1939/2200)\n",
      "Test Epoch: 60 | Loss: 0.365 | Acc: 87.957% (2023/2300)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.042% (2113/2400)\n",
      "Test Epoch: 60 | Loss: 0.372 | Acc: 87.640% (2191/2500)\n",
      "Test Epoch: 60 | Loss: 0.381 | Acc: 87.423% (2273/2600)\n",
      "Test Epoch: 60 | Loss: 0.377 | Acc: 87.593% (2365/2700)\n",
      "Test Epoch: 60 | Loss: 0.378 | Acc: 87.643% (2454/2800)\n",
      "Test Epoch: 60 | Loss: 0.378 | Acc: 87.724% (2544/2900)\n",
      "Test Epoch: 60 | Loss: 0.377 | Acc: 87.700% (2631/3000)\n",
      "Test Epoch: 60 | Loss: 0.382 | Acc: 87.742% (2720/3100)\n",
      "Test Epoch: 60 | Loss: 0.378 | Acc: 87.812% (2810/3200)\n",
      "Test Epoch: 60 | Loss: 0.380 | Acc: 87.758% (2896/3300)\n",
      "Test Epoch: 60 | Loss: 0.381 | Acc: 87.824% (2986/3400)\n",
      "Test Epoch: 60 | Loss: 0.382 | Acc: 87.857% (3075/3500)\n",
      "Test Epoch: 60 | Loss: 0.378 | Acc: 88.000% (3168/3600)\n",
      "Test Epoch: 60 | Loss: 0.383 | Acc: 87.919% (3253/3700)\n",
      "Test Epoch: 60 | Loss: 0.384 | Acc: 87.947% (3342/3800)\n",
      "Test Epoch: 60 | Loss: 0.381 | Acc: 88.051% (3434/3900)\n",
      "Test Epoch: 60 | Loss: 0.381 | Acc: 88.100% (3524/4000)\n",
      "Test Epoch: 60 | Loss: 0.383 | Acc: 88.146% (3614/4100)\n",
      "Test Epoch: 60 | Loss: 0.382 | Acc: 88.119% (3701/4200)\n",
      "Test Epoch: 60 | Loss: 0.379 | Acc: 88.186% (3792/4300)\n",
      "Test Epoch: 60 | Loss: 0.378 | Acc: 88.318% (3886/4400)\n",
      "Test Epoch: 60 | Loss: 0.374 | Acc: 88.400% (3978/4500)\n",
      "Test Epoch: 60 | Loss: 0.376 | Acc: 88.304% (4062/4600)\n",
      "Test Epoch: 60 | Loss: 0.374 | Acc: 88.298% (4150/4700)\n",
      "Test Epoch: 60 | Loss: 0.377 | Acc: 88.167% (4232/4800)\n",
      "Test Epoch: 60 | Loss: 0.373 | Acc: 88.265% (4325/4900)\n",
      "Test Epoch: 60 | Loss: 0.372 | Acc: 88.240% (4412/5000)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.314% (4504/5100)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.250% (4589/5200)\n",
      "Test Epoch: 60 | Loss: 0.371 | Acc: 88.151% (4672/5300)\n",
      "Test Epoch: 60 | Loss: 0.370 | Acc: 88.167% (4761/5400)\n",
      "Test Epoch: 60 | Loss: 0.373 | Acc: 88.127% (4847/5500)\n",
      "Test Epoch: 60 | Loss: 0.373 | Acc: 88.107% (4934/5600)\n",
      "Test Epoch: 60 | Loss: 0.373 | Acc: 88.088% (5021/5700)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.138% (5112/5800)\n",
      "Test Epoch: 60 | Loss: 0.371 | Acc: 88.119% (5199/5900)\n",
      "Test Epoch: 60 | Loss: 0.373 | Acc: 88.100% (5286/6000)\n",
      "Test Epoch: 60 | Loss: 0.374 | Acc: 88.033% (5370/6100)\n",
      "Test Epoch: 60 | Loss: 0.374 | Acc: 88.000% (5456/6200)\n",
      "Test Epoch: 60 | Loss: 0.374 | Acc: 88.032% (5546/6300)\n",
      "Test Epoch: 60 | Loss: 0.372 | Acc: 88.125% (5640/6400)\n",
      "Test Epoch: 60 | Loss: 0.371 | Acc: 88.169% (5731/6500)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.167% (5819/6600)\n",
      "Test Epoch: 60 | Loss: 0.368 | Acc: 88.224% (5911/6700)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.206% (5998/6800)\n",
      "Test Epoch: 60 | Loss: 0.368 | Acc: 88.261% (6090/6900)\n",
      "Test Epoch: 60 | Loss: 0.368 | Acc: 88.229% (6176/7000)\n",
      "Test Epoch: 60 | Loss: 0.370 | Acc: 88.225% (6264/7100)\n",
      "Test Epoch: 60 | Loss: 0.369 | Acc: 88.222% (6352/7200)\n",
      "Test Epoch: 60 | Loss: 0.367 | Acc: 88.260% (6443/7300)\n",
      "Test Epoch: 60 | Loss: 0.365 | Acc: 88.338% (6537/7400)\n",
      "Test Epoch: 60 | Loss: 0.364 | Acc: 88.333% (6625/7500)\n",
      "Test Epoch: 60 | Loss: 0.364 | Acc: 88.368% (6716/7600)\n",
      "Test Epoch: 60 | Loss: 0.364 | Acc: 88.312% (6800/7700)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.308% (6888/7800)\n",
      "Test Epoch: 60 | Loss: 0.364 | Acc: 88.291% (6975/7900)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.287% (7063/8000)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.296% (7152/8100)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.232% (7235/8200)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.241% (7324/8300)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.262% (7414/8400)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.235% (7500/8500)\n",
      "Test Epoch: 60 | Loss: 0.365 | Acc: 88.198% (7585/8600)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.264% (7679/8700)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.250% (7766/8800)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.247% (7854/8900)\n",
      "Test Epoch: 60 | Loss: 0.363 | Acc: 88.244% (7942/9000)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.209% (8027/9100)\n",
      "Test Epoch: 60 | Loss: 0.361 | Acc: 88.272% (8121/9200)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.237% (8206/9300)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.223% (8293/9400)\n",
      "Test Epoch: 60 | Loss: 0.361 | Acc: 88.253% (8384/9500)\n",
      "Test Epoch: 60 | Loss: 0.362 | Acc: 88.208% (8468/9600)\n",
      "Test Epoch: 60 | Loss: 0.360 | Acc: 88.268% (8562/9700)\n",
      "Test Epoch: 60 | Loss: 0.360 | Acc: 88.224% (8646/9800)\n",
      "Test Epoch: 60 | Loss: 0.360 | Acc: 88.212% (8733/9900)\n",
      "Test Epoch: 60 | Loss: 0.359 | Acc: 88.230% (8823/10000)\n",
      "\n",
      "Epoch: 61\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 61 | Loss: 0.232 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.146% (350/384)\n",
      "Train Epoch: 61 | Loss: 0.242 | Acc: 91.602% (469/512)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.094% (583/640)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.295% (818/896)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.309% (935/1024)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.319% (1052/1152)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.484% (1171/1280)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.690% (1291/1408)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.667% (1408/1536)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.647% (1525/1664)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.574% (1641/1792)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.458% (1756/1920)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.406% (1872/2048)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.452% (1990/2176)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.667% (2112/2304)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.612% (2228/2432)\n",
      "Train Epoch: 61 | Loss: 0.259 | Acc: 91.562% (2344/2560)\n",
      "Train Epoch: 61 | Loss: 0.260 | Acc: 91.518% (2460/2688)\n",
      "Train Epoch: 61 | Loss: 0.259 | Acc: 91.513% (2577/2816)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.610% (2697/2944)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.634% (2815/3072)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.750% (2936/3200)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.647% (3050/3328)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.725% (3170/3456)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.713% (3287/3584)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.568% (3399/3712)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.562% (3516/3840)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.658% (3637/3968)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.626% (3753/4096)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.714% (3874/4224)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.705% (3991/4352)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.741% (4110/4480)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.645% (4223/4608)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.639% (4340/4736)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.674% (4459/4864)\n",
      "Train Epoch: 61 | Loss: 0.246 | Acc: 91.847% (4585/4992)\n",
      "Train Epoch: 61 | Loss: 0.245 | Acc: 91.836% (4702/5120)\n",
      "Train Epoch: 61 | Loss: 0.244 | Acc: 91.845% (4820/5248)\n",
      "Train Epoch: 61 | Loss: 0.243 | Acc: 91.890% (4940/5376)\n",
      "Train Epoch: 61 | Loss: 0.242 | Acc: 91.933% (5060/5504)\n",
      "Train Epoch: 61 | Loss: 0.244 | Acc: 91.868% (5174/5632)\n",
      "Train Epoch: 61 | Loss: 0.245 | Acc: 91.840% (5290/5760)\n",
      "Train Epoch: 61 | Loss: 0.246 | Acc: 91.763% (5403/5888)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.705% (5517/6016)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.732% (5636/6144)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.805% (5758/6272)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.781% (5874/6400)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.820% (5994/6528)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.782% (6109/6656)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.790% (6227/6784)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.811% (6346/6912)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.818% (6464/7040)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.825% (6582/7168)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.913% (6706/7296)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.905% (6823/7424)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.936% (6943/7552)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.849% (7054/7680)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.855% (7172/7808)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.885% (7292/7936)\n",
      "Train Epoch: 61 | Loss: 0.247 | Acc: 91.902% (7411/8064)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.882% (7527/8192)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.875% (7644/8320)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.868% (7761/8448)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.849% (7877/8576)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.843% (7994/8704)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.848% (8112/8832)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.853% (8230/8960)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.890% (8351/9088)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.895% (8469/9216)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.866% (8584/9344)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.892% (8704/9472)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.854% (8818/9600)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.817% (8932/9728)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.832% (9051/9856)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.757% (9161/9984)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.752% (9278/10112)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.748% (9395/10240)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.763% (9514/10368)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.721% (9627/10496)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.726% (9745/10624)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.741% (9864/10752)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.774% (9985/10880)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.770% (10102/11008)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.792% (10222/11136)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.770% (10337/11264)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.775% (10455/11392)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.745% (10569/11520)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.758% (10688/11648)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.737% (10803/11776)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.709% (10917/11904)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.714% (11035/12032)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.702% (11151/12160)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.732% (11272/12288)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.769% (11394/12416)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.733% (11507/12544)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.738% (11625/12672)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.711% (11739/12800)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.700% (11855/12928)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.713% (11974/13056)\n",
      "Train Epoch: 61 | Loss: 0.248 | Acc: 91.702% (12090/13184)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.677% (12204/13312)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.696% (12324/13440)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.627% (12432/13568)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.574% (12542/13696)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.551% (12656/13824)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.564% (12775/13952)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.534% (12888/14080)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.554% (13008/14208)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.581% (13129/14336)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.579% (13246/14464)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.564% (13361/14592)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.569% (13479/14720)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.608% (13602/14848)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.607% (13719/14976)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.578% (13832/15104)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.551% (13945/15232)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.543% (14061/15360)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.555% (14180/15488)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.534% (14294/15616)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.527% (14410/15744)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.482% (14520/15872)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.487% (14638/16000)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.437% (14747/16128)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.449% (14866/16256)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.431% (14980/16384)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.418% (15095/16512)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.388% (15207/16640)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.382% (15323/16768)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.400% (15443/16896)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.400% (15560/17024)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.412% (15679/17152)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.418% (15797/17280)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.423% (15915/17408)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.435% (16034/17536)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.440% (16152/17664)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.451% (16271/17792)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.473% (16392/17920)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.451% (16505/18048)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.478% (16627/18176)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.499% (16748/18304)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.509% (16867/18432)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.498% (16982/18560)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.497% (17099/18688)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.459% (17209/18816)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.485% (17331/18944)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.474% (17446/19072)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.484% (17565/19200)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.484% (17682/19328)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.494% (17801/19456)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.498% (17919/19584)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.523% (18041/19712)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.537% (18161/19840)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.526% (18276/19968)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.536% (18395/20096)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.515% (18508/20224)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.509% (18624/20352)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.489% (18737/20480)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.474% (18851/20608)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.469% (18967/20736)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.478% (19086/20864)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.482% (19204/20992)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.487% (19322/21120)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.491% (19440/21248)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.509% (19561/21376)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.513% (19679/21504)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.513% (19796/21632)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.517% (19914/21760)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.516% (20031/21888)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.493% (20143/22016)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.479% (20257/22144)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.492% (20377/22272)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.491% (20494/22400)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.491% (20611/22528)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.499% (20730/22656)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.503% (20848/22784)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.498% (20964/22912)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.476% (21076/23040)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.471% (21192/23168)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.471% (21309/23296)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.453% (21422/23424)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.457% (21540/23552)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.448% (21655/23680)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.448% (21772/23808)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.469% (21894/23936)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.469% (22011/24064)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.464% (22127/24192)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.460% (22243/24320)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.447% (22357/24448)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.439% (22472/24576)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.447% (22591/24704)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.455% (22710/24832)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.454% (22827/24960)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.442% (22941/25088)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.434% (23056/25216)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.438% (23174/25344)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.449% (23294/25472)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.457% (23413/25600)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.449% (23528/25728)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.437% (23642/25856)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.441% (23760/25984)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.429% (23874/26112)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.429% (23991/26240)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.440% (24111/26368)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.444% (24229/26496)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.451% (24348/26624)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.462% (24468/26752)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.451% (24582/26880)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.443% (24697/27008)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.417% (24807/27136)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.414% (24923/27264)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.432% (25045/27392)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.439% (25164/27520)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.442% (25282/27648)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.457% (25403/27776)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.439% (25515/27904)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.445% (25634/28032)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.438% (25749/28160)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.424% (25862/28288)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.434% (25982/28416)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.452% (26104/28544)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.455% (26222/28672)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.462% (26341/28800)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.468% (26460/28928)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.475% (26579/29056)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.458% (26691/29184)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.478% (26814/29312)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.474% (26930/29440)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.487% (27051/29568)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.497% (27171/29696)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.510% (27292/29824)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.493% (27404/29952)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.489% (27520/30080)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.486% (27636/30208)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.482% (27752/30336)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.485% (27870/30464)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.491% (27989/30592)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.497% (28108/30720)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.507% (28228/30848)\n",
      "Train Epoch: 61 | Loss: 0.249 | Acc: 91.519% (28349/30976)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.506% (28462/31104)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.502% (28578/31232)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.499% (28694/31360)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.505% (28813/31488)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.520% (28935/31616)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.510% (29049/31744)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.497% (29162/31872)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.503% (29281/32000)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.512% (29401/32128)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.505% (29516/32256)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.499% (29631/32384)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.502% (29749/32512)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.498% (29865/32640)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.498% (29982/32768)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.494% (30098/32896)\n",
      "Train Epoch: 61 | Loss: 0.250 | Acc: 91.491% (30214/33024)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.458% (30320/33152)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.457% (30437/33280)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.442% (30549/33408)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.439% (30665/33536)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.445% (30784/33664)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.442% (30900/33792)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.450% (31020/33920)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.433% (31131/34048)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.436% (31249/34176)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.424% (31362/34304)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.435% (31483/34432)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.432% (31599/34560)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.426% (31714/34688)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.426% (31831/34816)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.435% (31951/34944)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.438% (32069/35072)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.440% (32187/35200)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.429% (32300/35328)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.434% (32419/35456)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.432% (32535/35584)\n",
      "Train Epoch: 61 | Loss: 0.251 | Acc: 91.426% (32650/35712)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.420% (32765/35840)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.417% (32881/35968)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.409% (32995/36096)\n",
      "Train Epoch: 61 | Loss: 0.252 | Acc: 91.387% (33104/36224)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.384% (33220/36352)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.376% (33334/36480)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.376% (33451/36608)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.374% (33567/36736)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.360% (33679/36864)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.349% (33792/36992)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.339% (33905/37120)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.339% (34022/37248)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.334% (34137/37376)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.332% (34253/37504)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.327% (34368/37632)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.327% (34485/37760)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.330% (34603/37888)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.322% (34717/38016)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.328% (34836/38144)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.333% (34955/38272)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.344% (35076/38400)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.328% (35187/38528)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.329% (35304/38656)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.311% (35414/38784)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.306% (35529/38912)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.309% (35647/39040)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.309% (35764/39168)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.320% (35885/39296)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.307% (35997/39424)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.295% (36109/39552)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.293% (36225/39680)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.276% (36335/39808)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.276% (36452/39936)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.271% (36567/40064)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.279% (36687/40192)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.290% (36808/40320)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.300% (36929/40448)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.305% (37048/40576)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.318% (37170/40704)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.328% (37291/40832)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.316% (37403/40960)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.324% (37523/41088)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.314% (37636/41216)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.319% (37755/41344)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.327% (37875/41472)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.322% (37990/41600)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.327% (38109/41728)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.323% (38224/41856)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.332% (38345/41984)\n",
      "Train Epoch: 61 | Loss: 0.253 | Acc: 91.316% (38455/42112)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.316% (38572/42240)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.312% (38687/42368)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.300% (38799/42496)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.289% (38911/42624)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.285% (39026/42752)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.283% (39142/42880)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.269% (39253/43008)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.269% (39370/43136)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.268% (39486/43264)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.279% (39608/43392)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.284% (39727/43520)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.283% (39843/43648)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.285% (39961/43776)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.290% (40080/43904)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.288% (40196/44032)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.298% (40317/44160)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.296% (40433/44288)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.305% (40554/44416)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.305% (40671/44544)\n",
      "Train Epoch: 61 | Loss: 0.254 | Acc: 91.303% (40787/44672)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.299% (40902/44800)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.295% (41017/44928)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.289% (41131/45056)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.291% (41249/45184)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.287% (41364/45312)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.292% (41483/45440)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.286% (41597/45568)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.288% (41715/45696)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.286% (41831/45824)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.291% (41950/45952)\n",
      "Train Epoch: 61 | Loss: 0.255 | Acc: 91.289% (42066/46080)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.274% (42176/46208)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.259% (42286/46336)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.258% (42402/46464)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.262% (42521/46592)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.263% (42638/46720)\n",
      "Train Epoch: 61 | Loss: 0.256 | Acc: 91.263% (42755/46848)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.255% (42868/46976)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.241% (42978/47104)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.250% (43099/47232)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.252% (43217/47360)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.242% (43329/47488)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.253% (43451/47616)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.258% (43570/47744)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.256% (43686/47872)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.254% (43802/48000)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.257% (43920/48128)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.257% (44037/48256)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.255% (44153/48384)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.252% (44268/48512)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.238% (44378/48640)\n",
      "Train Epoch: 61 | Loss: 0.257 | Acc: 91.236% (44494/48768)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.228% (44607/48896)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.225% (44722/49024)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.213% (44833/49152)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.207% (44947/49280)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.214% (45067/49408)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.219% (45186/49536)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.217% (45302/49664)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.219% (45420/49792)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.222% (45538/49920)\n",
      "Train Epoch: 61 | Loss: 0.258 | Acc: 91.220% (45610/50000)\n",
      "Test Epoch: 61 | Loss: 0.359 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 61 | Loss: 0.359 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 61 | Loss: 0.388 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 61 | Loss: 0.352 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 61 | Loss: 0.332 | Acc: 89.400% (447/500)\n",
      "Test Epoch: 61 | Loss: 0.309 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 61 | Loss: 0.311 | Acc: 90.143% (631/700)\n",
      "Test Epoch: 61 | Loss: 0.344 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 61 | Loss: 0.365 | Acc: 88.556% (797/900)\n",
      "Test Epoch: 61 | Loss: 0.362 | Acc: 88.800% (888/1000)\n",
      "Test Epoch: 61 | Loss: 0.360 | Acc: 88.909% (978/1100)\n",
      "Test Epoch: 61 | Loss: 0.368 | Acc: 88.417% (1061/1200)\n",
      "Test Epoch: 61 | Loss: 0.366 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 61 | Loss: 0.364 | Acc: 88.571% (1240/1400)\n",
      "Test Epoch: 61 | Loss: 0.368 | Acc: 88.400% (1326/1500)\n",
      "Test Epoch: 61 | Loss: 0.362 | Acc: 88.375% (1414/1600)\n",
      "Test Epoch: 61 | Loss: 0.364 | Acc: 88.412% (1503/1700)\n",
      "Test Epoch: 61 | Loss: 0.377 | Acc: 88.056% (1585/1800)\n",
      "Test Epoch: 61 | Loss: 0.371 | Acc: 88.211% (1676/1900)\n",
      "Test Epoch: 61 | Loss: 0.374 | Acc: 88.350% (1767/2000)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.381% (1856/2100)\n",
      "Test Epoch: 61 | Loss: 0.371 | Acc: 88.364% (1944/2200)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.130% (2027/2300)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.208% (2117/2400)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.160% (2204/2500)\n",
      "Test Epoch: 61 | Loss: 0.388 | Acc: 87.923% (2286/2600)\n",
      "Test Epoch: 61 | Loss: 0.380 | Acc: 88.148% (2380/2700)\n",
      "Test Epoch: 61 | Loss: 0.384 | Acc: 88.071% (2466/2800)\n",
      "Test Epoch: 61 | Loss: 0.386 | Acc: 88.000% (2552/2900)\n",
      "Test Epoch: 61 | Loss: 0.383 | Acc: 88.133% (2644/3000)\n",
      "Test Epoch: 61 | Loss: 0.388 | Acc: 87.968% (2727/3100)\n",
      "Test Epoch: 61 | Loss: 0.383 | Acc: 88.156% (2821/3200)\n",
      "Test Epoch: 61 | Loss: 0.379 | Acc: 88.152% (2909/3300)\n",
      "Test Epoch: 61 | Loss: 0.377 | Acc: 88.118% (2996/3400)\n",
      "Test Epoch: 61 | Loss: 0.382 | Acc: 87.971% (3079/3500)\n",
      "Test Epoch: 61 | Loss: 0.379 | Acc: 88.056% (3170/3600)\n",
      "Test Epoch: 61 | Loss: 0.381 | Acc: 88.000% (3256/3700)\n",
      "Test Epoch: 61 | Loss: 0.378 | Acc: 88.026% (3345/3800)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.051% (3434/3900)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.125% (3525/4000)\n",
      "Test Epoch: 61 | Loss: 0.382 | Acc: 87.976% (3607/4100)\n",
      "Test Epoch: 61 | Loss: 0.378 | Acc: 88.095% (3700/4200)\n",
      "Test Epoch: 61 | Loss: 0.377 | Acc: 88.140% (3790/4300)\n",
      "Test Epoch: 61 | Loss: 0.377 | Acc: 88.182% (3880/4400)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.222% (3970/4500)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.109% (4053/4600)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.064% (4139/4700)\n",
      "Test Epoch: 61 | Loss: 0.378 | Acc: 88.000% (4224/4800)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.102% (4317/4900)\n",
      "Test Epoch: 61 | Loss: 0.380 | Acc: 88.020% (4401/5000)\n",
      "Test Epoch: 61 | Loss: 0.378 | Acc: 88.118% (4494/5100)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.096% (4581/5200)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.094% (4669/5300)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.167% (4761/5400)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.145% (4848/5500)\n",
      "Test Epoch: 61 | Loss: 0.377 | Acc: 88.143% (4936/5600)\n",
      "Test Epoch: 61 | Loss: 0.379 | Acc: 88.140% (5024/5700)\n",
      "Test Epoch: 61 | Loss: 0.378 | Acc: 88.155% (5113/5800)\n",
      "Test Epoch: 61 | Loss: 0.380 | Acc: 88.068% (5196/5900)\n",
      "Test Epoch: 61 | Loss: 0.380 | Acc: 88.067% (5284/6000)\n",
      "Test Epoch: 61 | Loss: 0.380 | Acc: 88.066% (5372/6100)\n",
      "Test Epoch: 61 | Loss: 0.381 | Acc: 88.113% (5463/6200)\n",
      "Test Epoch: 61 | Loss: 0.379 | Acc: 88.190% (5556/6300)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.281% (5650/6400)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.215% (5734/6500)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.227% (5823/6600)\n",
      "Test Epoch: 61 | Loss: 0.373 | Acc: 88.299% (5916/6700)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.235% (6000/6800)\n",
      "Test Epoch: 61 | Loss: 0.373 | Acc: 88.304% (6093/6900)\n",
      "Test Epoch: 61 | Loss: 0.374 | Acc: 88.314% (6182/7000)\n",
      "Test Epoch: 61 | Loss: 0.375 | Acc: 88.338% (6272/7100)\n",
      "Test Epoch: 61 | Loss: 0.376 | Acc: 88.333% (6360/7200)\n",
      "Test Epoch: 61 | Loss: 0.373 | Acc: 88.411% (6454/7300)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.392% (6541/7400)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.387% (6629/7500)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.408% (6719/7600)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.403% (6807/7700)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.449% (6899/7800)\n",
      "Test Epoch: 61 | Loss: 0.370 | Acc: 88.443% (6987/7900)\n",
      "Test Epoch: 61 | Loss: 0.370 | Acc: 88.450% (7076/8000)\n",
      "Test Epoch: 61 | Loss: 0.368 | Acc: 88.481% (7167/8100)\n",
      "Test Epoch: 61 | Loss: 0.369 | Acc: 88.488% (7256/8200)\n",
      "Test Epoch: 61 | Loss: 0.368 | Acc: 88.518% (7347/8300)\n",
      "Test Epoch: 61 | Loss: 0.367 | Acc: 88.536% (7437/8400)\n",
      "Test Epoch: 61 | Loss: 0.368 | Acc: 88.518% (7524/8500)\n",
      "Test Epoch: 61 | Loss: 0.370 | Acc: 88.465% (7608/8600)\n",
      "Test Epoch: 61 | Loss: 0.370 | Acc: 88.471% (7697/8700)\n",
      "Test Epoch: 61 | Loss: 0.370 | Acc: 88.489% (7787/8800)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.449% (7872/8900)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.400% (7956/9000)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.385% (8043/9100)\n",
      "Test Epoch: 61 | Loss: 0.371 | Acc: 88.424% (8135/9200)\n",
      "Test Epoch: 61 | Loss: 0.373 | Acc: 88.387% (8220/9300)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.394% (8309/9400)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.400% (8398/9500)\n",
      "Test Epoch: 61 | Loss: 0.373 | Acc: 88.396% (8486/9600)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.443% (8579/9700)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.459% (8669/9800)\n",
      "Test Epoch: 61 | Loss: 0.372 | Acc: 88.424% (8754/9900)\n",
      "Test Epoch: 61 | Loss: 0.371 | Acc: 88.440% (8844/10000)\n",
      "\n",
      "Epoch: 62\n",
      "Train Epoch: 62 | Loss: 0.283 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 62 | Loss: 0.284 | Acc: 89.062% (228/256)\n",
      "Train Epoch: 62 | Loss: 0.277 | Acc: 89.323% (343/384)\n",
      "Train Epoch: 62 | Loss: 0.266 | Acc: 90.039% (461/512)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 90.469% (579/640)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 90.625% (696/768)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.071% (816/896)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.016% (932/1024)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 90.972% (1048/1152)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 90.859% (1163/1280)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.193% (1284/1408)\n",
      "Train Epoch: 62 | Loss: 0.243 | Acc: 91.471% (1405/1536)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.346% (1520/1664)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.295% (1636/1792)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.458% (1756/1920)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.211% (1868/2048)\n",
      "Train Epoch: 62 | Loss: 0.260 | Acc: 91.131% (1983/2176)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.276% (2103/2304)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.406% (2223/2432)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.562% (2344/2560)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.629% (2463/2688)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.442% (2575/2816)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.508% (2694/2944)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.406% (2808/3072)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.250% (2920/3200)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.346% (3040/3328)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.175% (3151/3456)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.295% (3272/3584)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.352% (3391/3712)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.354% (3508/3840)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.280% (3622/3968)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.357% (3742/4096)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.264% (3855/4224)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.222% (3970/4352)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.183% (4085/4480)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.254% (4205/4608)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.068% (4313/4736)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.057% (4429/4864)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 90.925% (4539/4992)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.016% (4660/5120)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.044% (4778/5248)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.109% (4898/5376)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.134% (5016/5504)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.193% (5136/5632)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.250% (5256/5760)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.270% (5374/5888)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.273% (5491/6016)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.325% (5611/6144)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.406% (5733/6272)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.453% (5853/6400)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.391% (5966/6528)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.406% (6084/6656)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.436% (6203/6784)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.377% (6316/6912)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.406% (6435/7040)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.406% (6552/7168)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.351% (6665/7296)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.312% (6779/7424)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.327% (6897/7552)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.263% (7009/7680)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.278% (7127/7808)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.255% (7242/7936)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.332% (7365/8064)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.382% (7486/8192)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.370% (7602/8320)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.359% (7718/8448)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.348% (7834/8576)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.291% (7946/8704)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.338% (8067/8832)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.395% (8189/8960)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.384% (8305/9088)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.385% (8422/9216)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.428% (8543/9344)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.406% (8658/9472)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.427% (8777/9600)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.375% (8889/9728)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.396% (9008/9856)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.436% (9129/9984)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (9243/10112)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.445% (9364/10240)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.454% (9482/10368)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.425% (9596/10496)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.434% (9714/10624)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.481% (9836/10752)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.526% (9958/10880)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.561% (10079/11008)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.532% (10193/11136)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.548% (10312/11264)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.573% (10432/11392)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.580% (10550/11520)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.501% (10658/11648)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.508% (10776/11776)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.524% (10895/11904)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.506% (11010/12032)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.562% (11134/12160)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.536% (11248/12288)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.551% (11367/12416)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.558% (11485/12544)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.572% (11604/12672)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.570% (11721/12800)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.584% (11840/12928)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.605% (11960/13056)\n",
      "Train Epoch: 62 | Loss: 0.245 | Acc: 91.619% (12079/13184)\n",
      "Train Epoch: 62 | Loss: 0.245 | Acc: 91.632% (12198/13312)\n",
      "Train Epoch: 62 | Loss: 0.244 | Acc: 91.652% (12318/13440)\n",
      "Train Epoch: 62 | Loss: 0.245 | Acc: 91.635% (12433/13568)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.596% (12545/13696)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.616% (12665/13824)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.578% (12777/13952)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.555% (12891/14080)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.547% (13007/14208)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.560% (13126/14336)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.551% (13242/14464)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.536% (13357/14592)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.535% (13474/14720)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.561% (13595/14848)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.560% (13712/14976)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.559% (13829/15104)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.564% (13947/15232)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.510% (14056/15360)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.548% (14179/15488)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.566% (14299/15616)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.514% (14408/15744)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.513% (14525/15872)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.513% (14642/16000)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.555% (14766/16128)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.554% (14883/16256)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.553% (15000/16384)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.576% (15121/16512)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.562% (15236/16640)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.579% (15356/16768)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.566% (15471/16896)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.553% (15586/17024)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.540% (15701/17152)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.510% (15813/17280)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.504% (15929/17408)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.486% (16043/17536)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.491% (16161/17664)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.502% (16280/17792)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.501% (16397/17920)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.495% (16513/18048)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.483% (16628/18176)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.472% (16743/18304)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.450% (16856/18432)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.476% (16978/18560)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.454% (17091/18688)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.449% (17207/18816)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.454% (17325/18944)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.427% (17437/19072)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.411% (17551/19200)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.422% (17670/19328)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.411% (17785/19456)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.422% (17904/19584)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.432% (18023/19712)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.452% (18144/19840)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.451% (18261/19968)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.461% (18380/20096)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.471% (18499/20224)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.490% (18620/20352)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.470% (18733/20480)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.484% (18853/20608)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.474% (18968/20736)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.459% (19082/20864)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.440% (19195/20992)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.425% (19309/21120)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.430% (19427/21248)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.434% (19545/21376)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.434% (19662/21504)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.439% (19780/21632)\n",
      "Train Epoch: 62 | Loss: 0.246 | Acc: 91.443% (19898/21760)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (20007/21888)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.402% (20123/22016)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.397% (20239/22144)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (20358/22272)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (20475/22400)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.437% (20599/22528)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.428% (20714/22656)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.402% (20825/22784)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.393% (20940/22912)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (21060/23040)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.376% (21170/23168)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.346% (21280/23296)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.325% (21392/23424)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.360% (21517/23552)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.381% (21639/23680)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.381% (21756/23808)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.352% (21866/23936)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.352% (21983/24064)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.373% (22105/24192)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.390% (22226/24320)\n",
      "Train Epoch: 62 | Loss: 0.247 | Acc: 91.406% (22347/24448)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.398% (22462/24576)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.394% (22578/24704)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.402% (22697/24832)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.390% (22811/24960)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.386% (22927/25088)\n",
      "Train Epoch: 62 | Loss: 0.248 | Acc: 91.378% (23042/25216)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.375% (23158/25344)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.379% (23276/25472)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.371% (23391/25600)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.356% (23504/25728)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.379% (23627/25856)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.395% (23748/25984)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.391% (23864/26112)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.383% (23979/26240)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.391% (24098/26368)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.384% (24213/26496)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.391% (24332/26624)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.384% (24447/26752)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.369% (24560/26880)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.362% (24675/27008)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.358% (24791/27136)\n",
      "Train Epoch: 62 | Loss: 0.249 | Acc: 91.373% (24912/27264)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.373% (25029/27392)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.359% (25142/27520)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.345% (25255/27648)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.349% (25373/27776)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.363% (25494/27904)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.356% (25609/28032)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.360% (25727/28160)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.357% (25843/28288)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.346% (25957/28416)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.340% (26072/28544)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.350% (26192/28672)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.365% (26313/28800)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.358% (26428/28928)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.341% (26540/29056)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.334% (26655/29184)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.324% (26769/29312)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.332% (26888/29440)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.325% (27003/29568)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.342% (27125/29696)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.343% (27242/29824)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.333% (27356/29952)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.333% (27473/30080)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.330% (27589/30208)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.334% (27707/30336)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.324% (27821/30464)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.334% (27941/30592)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.335% (28058/30720)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.335% (28175/30848)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.335% (28292/30976)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.348% (28413/31104)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.339% (28527/31232)\n",
      "Train Epoch: 62 | Loss: 0.250 | Acc: 91.352% (28648/31360)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.352% (28765/31488)\n",
      "Train Epoch: 62 | Loss: 0.251 | Acc: 91.318% (28871/31616)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.315% (28987/31744)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.312% (29103/31872)\n",
      "Train Epoch: 62 | Loss: 0.252 | Acc: 91.297% (29215/32000)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.272% (29324/32128)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.285% (29445/32256)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.286% (29562/32384)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.289% (29680/32512)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.290% (29797/32640)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.287% (29913/32768)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.276% (30026/32896)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.279% (30144/33024)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.286% (30263/33152)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.280% (30378/33280)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.287% (30497/33408)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.284% (30613/33536)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.279% (30728/33664)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.273% (30843/33792)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.271% (30959/33920)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.271% (31076/34048)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.272% (31193/34176)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.284% (31314/34304)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.281% (31430/34432)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.276% (31545/34560)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.271% (31660/34688)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.268% (31776/34816)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.252% (31887/34944)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.264% (32008/35072)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.264% (32125/35200)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.256% (32239/35328)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.257% (32356/35456)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.257% (32473/35584)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.252% (32588/35712)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.242% (32701/35840)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.242% (32818/35968)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.246% (32936/36096)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.249% (33054/36224)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.241% (33168/36352)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.225% (33279/36480)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.220% (33394/36608)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.213% (33508/36736)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.216% (33626/36864)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.225% (33746/36992)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.242% (33869/37120)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.248% (33988/37248)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.235% (34100/37376)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.249% (34222/37504)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.249% (34339/37632)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.250% (34456/37760)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.253% (34574/37888)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.254% (34691/38016)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.259% (34810/38144)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.270% (34931/38272)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.273% (35049/38400)\n",
      "Train Epoch: 62 | Loss: 0.253 | Acc: 91.276% (35167/38528)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.267% (35280/38656)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.270% (35398/38784)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.267% (35514/38912)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.265% (35630/39040)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.258% (35744/39168)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.256% (35860/39296)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.252% (35975/39424)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.255% (36093/39552)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.255% (36210/39680)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.251% (36325/39808)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.261% (36446/39936)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.249% (36558/40064)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.254% (36677/40192)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.255% (36794/40320)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.248% (36908/40448)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.253% (37027/40576)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.249% (37142/40704)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.247% (37258/40832)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.252% (37377/40960)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.255% (37495/41088)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.258% (37613/41216)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.244% (37724/41344)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.240% (37839/41472)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.236% (37954/41600)\n",
      "Train Epoch: 62 | Loss: 0.254 | Acc: 91.246% (38075/41728)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.227% (38184/41856)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.204% (38291/41984)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.202% (38407/42112)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.205% (38525/42240)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.203% (38641/42368)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.206% (38759/42496)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.202% (38874/42624)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.210% (38994/42752)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.208% (39110/42880)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.209% (39227/43008)\n",
      "Train Epoch: 62 | Loss: 0.255 | Acc: 91.207% (39343/43136)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.203% (39458/43264)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.210% (39578/43392)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.202% (39691/43520)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.198% (39806/43648)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.201% (39924/43776)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.204% (40042/43904)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.195% (40155/44032)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.202% (40275/44160)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.203% (40392/44288)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.206% (40510/44416)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.209% (40628/44544)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.216% (40748/44672)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.210% (40862/44800)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.213% (40980/44928)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.222% (41101/45056)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.227% (41220/45184)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.214% (41331/45312)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.204% (41443/45440)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.185% (41551/45568)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.187% (41669/45696)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.190% (41787/45824)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.176% (41897/45952)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.185% (42018/46080)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.181% (42133/46208)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.190% (42254/46336)\n",
      "Train Epoch: 62 | Loss: 0.256 | Acc: 91.180% (42366/46464)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.177% (42481/46592)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.164% (42592/46720)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.161% (42707/46848)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.170% (42828/46976)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.166% (42943/47104)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.165% (43059/47232)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.151% (43169/47360)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.158% (43289/47488)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.165% (43409/47616)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.157% (43522/47744)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.162% (43641/47872)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.162% (43758/48000)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.161% (43874/48128)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.170% (43995/48256)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.167% (44110/48384)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.171% (44229/48512)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.176% (44348/48640)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.172% (44463/48768)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.181% (44584/48896)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.168% (44694/49024)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.162% (44808/49152)\n",
      "Train Epoch: 62 | Loss: 0.257 | Acc: 91.161% (44924/49280)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.139% (45030/49408)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.134% (45144/49536)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.132% (45260/49664)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.129% (45375/49792)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.116% (45485/49920)\n",
      "Train Epoch: 62 | Loss: 0.258 | Acc: 91.118% (45559/50000)\n",
      "Test Epoch: 62 | Loss: 0.271 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 62 | Loss: 0.336 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 62 | Loss: 0.312 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 62 | Loss: 0.282 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 62 | Loss: 0.281 | Acc: 89.800% (449/500)\n",
      "Test Epoch: 62 | Loss: 0.280 | Acc: 90.333% (542/600)\n",
      "Test Epoch: 62 | Loss: 0.294 | Acc: 89.714% (628/700)\n",
      "Test Epoch: 62 | Loss: 0.318 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 62 | Loss: 0.357 | Acc: 88.667% (798/900)\n",
      "Test Epoch: 62 | Loss: 0.344 | Acc: 88.800% (888/1000)\n",
      "Test Epoch: 62 | Loss: 0.351 | Acc: 88.818% (977/1100)\n",
      "Test Epoch: 62 | Loss: 0.357 | Acc: 88.500% (1062/1200)\n",
      "Test Epoch: 62 | Loss: 0.352 | Acc: 88.308% (1148/1300)\n",
      "Test Epoch: 62 | Loss: 0.353 | Acc: 88.286% (1236/1400)\n",
      "Test Epoch: 62 | Loss: 0.350 | Acc: 88.467% (1327/1500)\n",
      "Test Epoch: 62 | Loss: 0.345 | Acc: 88.688% (1419/1600)\n",
      "Test Epoch: 62 | Loss: 0.344 | Acc: 88.765% (1509/1700)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.556% (1594/1800)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.579% (1683/1900)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.700% (1774/2000)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.714% (1863/2100)\n",
      "Test Epoch: 62 | Loss: 0.344 | Acc: 88.636% (1950/2200)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.739% (2041/2300)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.833% (2132/2400)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.640% (2216/2500)\n",
      "Test Epoch: 62 | Loss: 0.354 | Acc: 88.462% (2300/2600)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.630% (2393/2700)\n",
      "Test Epoch: 62 | Loss: 0.350 | Acc: 88.679% (2483/2800)\n",
      "Test Epoch: 62 | Loss: 0.352 | Acc: 88.586% (2569/2900)\n",
      "Test Epoch: 62 | Loss: 0.355 | Acc: 88.333% (2650/3000)\n",
      "Test Epoch: 62 | Loss: 0.358 | Acc: 88.226% (2735/3100)\n",
      "Test Epoch: 62 | Loss: 0.353 | Acc: 88.312% (2826/3200)\n",
      "Test Epoch: 62 | Loss: 0.354 | Acc: 88.212% (2911/3300)\n",
      "Test Epoch: 62 | Loss: 0.355 | Acc: 88.088% (2995/3400)\n",
      "Test Epoch: 62 | Loss: 0.357 | Acc: 87.886% (3076/3500)\n",
      "Test Epoch: 62 | Loss: 0.356 | Acc: 87.972% (3167/3600)\n",
      "Test Epoch: 62 | Loss: 0.358 | Acc: 88.000% (3256/3700)\n",
      "Test Epoch: 62 | Loss: 0.357 | Acc: 87.947% (3342/3800)\n",
      "Test Epoch: 62 | Loss: 0.354 | Acc: 88.026% (3433/3900)\n",
      "Test Epoch: 62 | Loss: 0.352 | Acc: 88.125% (3525/4000)\n",
      "Test Epoch: 62 | Loss: 0.354 | Acc: 88.049% (3610/4100)\n",
      "Test Epoch: 62 | Loss: 0.354 | Acc: 88.024% (3697/4200)\n",
      "Test Epoch: 62 | Loss: 0.352 | Acc: 88.093% (3788/4300)\n",
      "Test Epoch: 62 | Loss: 0.351 | Acc: 88.159% (3879/4400)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.244% (3971/4500)\n",
      "Test Epoch: 62 | Loss: 0.350 | Acc: 88.174% (4056/4600)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.213% (4146/4700)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.188% (4233/4800)\n",
      "Test Epoch: 62 | Loss: 0.347 | Acc: 88.265% (4325/4900)\n",
      "Test Epoch: 62 | Loss: 0.347 | Acc: 88.280% (4414/5000)\n",
      "Test Epoch: 62 | Loss: 0.345 | Acc: 88.314% (4504/5100)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.269% (4590/5200)\n",
      "Test Epoch: 62 | Loss: 0.347 | Acc: 88.245% (4677/5300)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.296% (4768/5400)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.273% (4855/5500)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.268% (4943/5600)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.316% (5034/5700)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.414% (5128/5800)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.356% (5213/5900)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.333% (5300/6000)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.328% (5388/6100)\n",
      "Test Epoch: 62 | Loss: 0.349 | Acc: 88.339% (5477/6200)\n",
      "Test Epoch: 62 | Loss: 0.348 | Acc: 88.413% (5570/6300)\n",
      "Test Epoch: 62 | Loss: 0.346 | Acc: 88.484% (5663/6400)\n",
      "Test Epoch: 62 | Loss: 0.347 | Acc: 88.446% (5749/6500)\n",
      "Test Epoch: 62 | Loss: 0.344 | Acc: 88.500% (5841/6600)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 88.537% (5932/6700)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 88.529% (6020/6800)\n",
      "Test Epoch: 62 | Loss: 0.342 | Acc: 88.623% (6115/6900)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 88.614% (6203/7000)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 88.606% (6291/7100)\n",
      "Test Epoch: 62 | Loss: 0.343 | Acc: 88.611% (6380/7200)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.685% (6474/7300)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.730% (6566/7400)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.653% (6649/7500)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.697% (6741/7600)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.649% (6826/7700)\n",
      "Test Epoch: 62 | Loss: 0.342 | Acc: 88.628% (6913/7800)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.684% (7006/7900)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.675% (7094/8000)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.691% (7184/8100)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.720% (7275/8200)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.723% (7364/8300)\n",
      "Test Epoch: 62 | Loss: 0.338 | Acc: 88.690% (7450/8400)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.635% (7534/8500)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.581% (7618/8600)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.621% (7710/8700)\n",
      "Test Epoch: 62 | Loss: 0.342 | Acc: 88.625% (7799/8800)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.674% (7892/8900)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.700% (7983/9000)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.714% (8073/9100)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.750% (8165/9200)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.742% (8253/9300)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.691% (8337/9400)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.684% (8425/9500)\n",
      "Test Epoch: 62 | Loss: 0.341 | Acc: 88.635% (8509/9600)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.691% (8603/9700)\n",
      "Test Epoch: 62 | Loss: 0.339 | Acc: 88.694% (8692/9800)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.687% (8780/9900)\n",
      "Test Epoch: 62 | Loss: 0.340 | Acc: 88.720% (8872/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 63\n",
      "Train Epoch: 63 | Loss: 0.230 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 63 | Loss: 0.183 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 63 | Loss: 0.182 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 63 | Loss: 0.230 | Acc: 92.969% (476/512)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 63 | Loss: 0.279 | Acc: 91.797% (705/768)\n",
      "Train Epoch: 63 | Loss: 0.281 | Acc: 91.629% (821/896)\n",
      "Train Epoch: 63 | Loss: 0.267 | Acc: 91.797% (940/1024)\n",
      "Train Epoch: 63 | Loss: 0.266 | Acc: 91.667% (1056/1152)\n",
      "Train Epoch: 63 | Loss: 0.276 | Acc: 91.250% (1168/1280)\n",
      "Train Epoch: 63 | Loss: 0.280 | Acc: 91.193% (1284/1408)\n",
      "Train Epoch: 63 | Loss: 0.283 | Acc: 90.951% (1397/1536)\n",
      "Train Epoch: 63 | Loss: 0.276 | Acc: 91.286% (1519/1664)\n",
      "Train Epoch: 63 | Loss: 0.278 | Acc: 91.350% (1637/1792)\n",
      "Train Epoch: 63 | Loss: 0.277 | Acc: 91.458% (1756/1920)\n",
      "Train Epoch: 63 | Loss: 0.268 | Acc: 91.650% (1877/2048)\n",
      "Train Epoch: 63 | Loss: 0.272 | Acc: 91.498% (1991/2176)\n",
      "Train Epoch: 63 | Loss: 0.274 | Acc: 91.493% (2108/2304)\n",
      "Train Epoch: 63 | Loss: 0.270 | Acc: 91.612% (2228/2432)\n",
      "Train Epoch: 63 | Loss: 0.265 | Acc: 91.797% (2350/2560)\n",
      "Train Epoch: 63 | Loss: 0.265 | Acc: 91.667% (2464/2688)\n",
      "Train Epoch: 63 | Loss: 0.263 | Acc: 91.726% (2583/2816)\n",
      "Train Epoch: 63 | Loss: 0.262 | Acc: 91.678% (2699/2944)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.797% (2820/3072)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.750% (2936/3200)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.947% (3060/3328)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.811% (3173/3456)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.881% (3293/3584)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.783% (3407/3712)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.797% (3525/3840)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.809% (3643/3968)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.772% (3759/4096)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.643% (3871/4224)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.659% (3989/4352)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.629% (4105/4480)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.602% (4221/4608)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.639% (4340/4736)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.694% (4460/4864)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.707% (4578/4992)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.719% (4696/5120)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.673% (4811/5248)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.704% (4930/5376)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.788% (5052/5504)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.797% (5170/5632)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.771% (5286/5760)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.814% (5406/5888)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.772% (5521/6016)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.846% (5643/6144)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.805% (5758/6272)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.828% (5877/6400)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.774% (5991/6528)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.797% (6110/6656)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.760% (6225/6784)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.782% (6344/6912)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.790% (6462/7040)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.713% (6574/7168)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.735% (6693/7296)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.716% (6809/7424)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.737% (6928/7552)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.732% (7045/7680)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.714% (7161/7808)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.759% (7282/7936)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.853% (7407/8064)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.833% (7523/8192)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.851% (7642/8320)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.892% (7763/8448)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.873% (7879/8576)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.877% (7997/8704)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.927% (8119/8832)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.953% (8239/8960)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.956% (8357/9088)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.938% (8473/9216)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.866% (8584/9344)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.871% (8702/9472)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.833% (8816/9600)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.817% (8932/9728)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.792% (9047/9856)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.797% (9165/9984)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.822% (9285/10112)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.807% (9401/10240)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.802% (9518/10368)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.787% (9634/10496)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.736% (9746/10624)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.732% (9863/10752)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.746% (9982/10880)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.724% (10097/11008)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.712% (10213/11136)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.699% (10329/11264)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.713% (10448/11392)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.719% (10566/11520)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.767% (10689/11648)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.771% (10807/11776)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.784% (10926/11904)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.705% (11034/12032)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.711% (11152/12160)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.707% (11269/12288)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.696% (11385/12416)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.701% (11503/12544)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.714% (11622/12672)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.719% (11740/12800)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.747% (11861/12928)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.774% (11982/13056)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.801% (12103/13184)\n",
      "Train Epoch: 63 | Loss: 0.243 | Acc: 91.819% (12223/13312)\n",
      "Train Epoch: 63 | Loss: 0.243 | Acc: 91.793% (12337/13440)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.767% (12451/13568)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.749% (12566/13696)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.703% (12677/13824)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.671% (12790/13952)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.690% (12910/14080)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.681% (13026/14208)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.685% (13144/14336)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.710% (13265/14464)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.742% (13387/14592)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.732% (13503/14720)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.736% (13621/14848)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.707% (13734/14976)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.638% (13841/15104)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.629% (13957/15232)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.634% (14075/15360)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.632% (14192/15488)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.643% (14311/15616)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.648% (14429/15744)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.671% (14550/15872)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.681% (14669/16000)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.679% (14786/16128)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.665% (14901/16256)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.669% (15019/16384)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.673% (15137/16512)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.677% (15255/16640)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.710% (15378/16768)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.684% (15491/16896)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.659% (15604/17024)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.686% (15726/17152)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.678% (15842/17280)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.665% (15957/17408)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.669% (16075/17536)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.672% (16193/17664)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.670% (16310/17792)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.669% (16427/17920)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.667% (16544/18048)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.643% (16657/18176)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.658% (16777/18304)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.650% (16893/18432)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.649% (17010/18560)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.668% (17131/18688)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.704% (17255/18816)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.681% (17368/18944)\n",
      "Train Epoch: 63 | Loss: 0.244 | Acc: 91.674% (17484/19072)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.656% (17598/19200)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.644% (17713/19328)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.627% (17827/19456)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.626% (17944/19584)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.609% (18058/19712)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.618% (18177/19840)\n",
      "Train Epoch: 63 | Loss: 0.245 | Acc: 91.632% (18297/19968)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.605% (18409/20096)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.624% (18530/20224)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.613% (18645/20352)\n",
      "Train Epoch: 63 | Loss: 0.246 | Acc: 91.582% (18756/20480)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.552% (18867/20608)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.551% (18984/20736)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.560% (19103/20864)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.568% (19222/20992)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.553% (19336/21120)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.566% (19456/21248)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.570% (19574/21376)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.574% (19692/21504)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.563% (19807/21632)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.562% (19924/21760)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.575% (20044/21888)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.556% (20157/22016)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.542% (20271/22144)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.550% (20390/22272)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.554% (20508/22400)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.539% (20622/22528)\n",
      "Train Epoch: 63 | Loss: 0.247 | Acc: 91.547% (20741/22656)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.538% (20856/22784)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.507% (20966/22912)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.523% (21087/23040)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.518% (21203/23168)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.518% (21320/23296)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.487% (21430/23424)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.517% (21554/23552)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.482% (21663/23680)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.499% (21784/23808)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.490% (21899/23936)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.498% (22018/24064)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.505% (22137/24192)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.517% (22257/24320)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.537% (22379/24448)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.549% (22499/24576)\n",
      "Train Epoch: 63 | Loss: 0.248 | Acc: 91.520% (22609/24704)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.503% (22722/24832)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.482% (22834/24960)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.470% (22948/25088)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.486% (23069/25216)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.477% (23184/25344)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.465% (23298/25472)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.469% (23416/25600)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.468% (23533/25728)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.499% (23658/25856)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.510% (23778/25984)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.525% (23899/26112)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.528% (24017/26240)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.516% (24131/26368)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.504% (24245/26496)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.511% (24364/26624)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.481% (24473/26752)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.488% (24592/26880)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.495% (24711/27008)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.506% (24831/27136)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.502% (24947/27264)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.505% (25065/27392)\n",
      "Train Epoch: 63 | Loss: 0.249 | Acc: 91.497% (25180/27520)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.479% (25292/27648)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.485% (25411/27776)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.478% (25526/27904)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.474% (25642/28032)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.474% (25759/28160)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.484% (25879/28288)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.494% (25999/28416)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.490% (26115/28544)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.497% (26234/28672)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.503% (26353/28800)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.500% (26469/28928)\n",
      "Train Epoch: 63 | Loss: 0.250 | Acc: 91.485% (26582/29056)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.488% (26700/29184)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.481% (26815/29312)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.484% (26933/29440)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.471% (27046/29568)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.470% (27163/29696)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.467% (27279/29824)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.460% (27394/29952)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.463% (27512/30080)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.472% (27632/30208)\n",
      "Train Epoch: 63 | Loss: 0.251 | Acc: 91.462% (27746/30336)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.459% (27862/30464)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.452% (27977/30592)\n",
      "Train Epoch: 63 | Loss: 0.252 | Acc: 91.429% (28087/30720)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.409% (28198/30848)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.403% (28313/30976)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.397% (28428/31104)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.397% (28545/31232)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.381% (28657/31360)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.387% (28776/31488)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.390% (28894/31616)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.394% (29012/31744)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.394% (29129/31872)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.391% (29245/32000)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.366% (29354/32128)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.378% (29475/32256)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.363% (29587/32384)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.379% (29709/32512)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.388% (29829/32640)\n",
      "Train Epoch: 63 | Loss: 0.253 | Acc: 91.364% (29938/32768)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.342% (30048/32896)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.352% (30168/33024)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.346% (30283/33152)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.334% (30396/33280)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.328% (30511/33408)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.335% (30630/33536)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.344% (30750/33664)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.362% (30873/33792)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.353% (30987/33920)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.342% (31100/34048)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.354% (31221/34176)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.354% (31338/34304)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.319% (31443/34432)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.331% (31564/34560)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.340% (31684/34688)\n",
      "Train Epoch: 63 | Loss: 0.254 | Acc: 91.337% (31800/34816)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.318% (31910/34944)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.301% (32021/35072)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.298% (32137/35200)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.304% (32256/35328)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.305% (32373/35456)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.305% (32490/35584)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.314% (32610/35712)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.317% (32728/35840)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.331% (32850/35968)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.345% (32972/36096)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.329% (33083/36224)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.321% (33197/36352)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.319% (33313/36480)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.322% (33431/36608)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.303% (33541/36736)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.303% (33658/36864)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.295% (33772/36992)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.298% (33890/37120)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.288% (34003/37248)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.299% (34124/37376)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.300% (34241/37504)\n",
      "Train Epoch: 63 | Loss: 0.255 | Acc: 91.313% (34363/37632)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.306% (34477/37760)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.306% (34594/37888)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.306% (34711/38016)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.309% (34829/38144)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.304% (34944/38272)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.286% (35054/38400)\n",
      "Train Epoch: 63 | Loss: 0.256 | Acc: 91.284% (35170/38528)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.274% (35283/38656)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.264% (35396/38784)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.255% (35509/38912)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.263% (35629/39040)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.253% (35742/39168)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.256% (35860/39296)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.257% (35977/39424)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.265% (36097/39552)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.265% (36214/39680)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.268% (36332/39808)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.264% (36447/39936)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.251% (36559/40064)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.250% (36675/40192)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.238% (36787/40320)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.231% (36901/40448)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.236% (37020/40576)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.242% (37139/40704)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.252% (37260/40832)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.252% (37377/40960)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.246% (37491/41088)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.244% (37607/41216)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.254% (37728/41344)\n",
      "Train Epoch: 63 | Loss: 0.257 | Acc: 91.235% (37837/41472)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.221% (37948/41600)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.227% (38067/41728)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.222% (38182/41856)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.223% (38299/41984)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.226% (38417/42112)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.219% (38531/42240)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.227% (38651/42368)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.227% (38768/42496)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.233% (38887/42624)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.219% (38998/42752)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.210% (39111/42880)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.206% (39226/43008)\n",
      "Train Epoch: 63 | Loss: 0.258 | Acc: 91.212% (39345/43136)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.198% (39456/43264)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.190% (39569/43392)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.176% (39680/43520)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.159% (39789/43648)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.160% (39906/43776)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.156% (40021/43904)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.154% (40137/44032)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.144% (40249/44160)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.140% (40364/44288)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.138% (40480/44416)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.141% (40598/44544)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.140% (40714/44672)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.141% (40831/44800)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.144% (40949/44928)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.147% (41067/45056)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.145% (41183/45184)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.141% (41298/45312)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.151% (41419/45440)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.156% (41538/45568)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.148% (41651/45696)\n",
      "Train Epoch: 63 | Loss: 0.260 | Acc: 91.147% (41767/45824)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.152% (41886/45952)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.152% (42003/46080)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.157% (42122/46208)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.156% (42238/46336)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.150% (42352/46464)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.149% (42468/46592)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.156% (42588/46720)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.150% (42702/46848)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.142% (42815/46976)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.141% (42931/47104)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.133% (43044/47232)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.123% (43156/47360)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.124% (43273/47488)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.127% (43391/47616)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.126% (43507/47744)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.122% (43622/47872)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.127% (43741/48000)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.130% (43859/48128)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.141% (43981/48256)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.142% (44098/48384)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.147% (44217/48512)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.145% (44333/48640)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.142% (44448/48768)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.142% (44565/48896)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.149% (44685/49024)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.152% (44803/49152)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.149% (44918/49280)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.149% (45035/49408)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.154% (45154/49536)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.151% (45269/49664)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.145% (45383/49792)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.142% (45498/49920)\n",
      "Train Epoch: 63 | Loss: 0.259 | Acc: 91.144% (45572/50000)\n",
      "Test Epoch: 63 | Loss: 0.443 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 63 | Loss: 0.368 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 63 | Loss: 0.346 | Acc: 88.667% (266/300)\n",
      "Test Epoch: 63 | Loss: 0.329 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 63 | Loss: 0.312 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 63 | Loss: 0.284 | Acc: 90.333% (542/600)\n",
      "Test Epoch: 63 | Loss: 0.278 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 63 | Loss: 0.305 | Acc: 90.000% (720/800)\n",
      "Test Epoch: 63 | Loss: 0.315 | Acc: 89.778% (808/900)\n",
      "Test Epoch: 63 | Loss: 0.318 | Acc: 89.800% (898/1000)\n",
      "Test Epoch: 63 | Loss: 0.345 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 63 | Loss: 0.357 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 63 | Loss: 0.347 | Acc: 89.692% (1166/1300)\n",
      "Test Epoch: 63 | Loss: 0.345 | Acc: 89.500% (1253/1400)\n",
      "Test Epoch: 63 | Loss: 0.341 | Acc: 89.667% (1345/1500)\n",
      "Test Epoch: 63 | Loss: 0.341 | Acc: 89.625% (1434/1600)\n",
      "Test Epoch: 63 | Loss: 0.339 | Acc: 89.824% (1527/1700)\n",
      "Test Epoch: 63 | Loss: 0.344 | Acc: 89.722% (1615/1800)\n",
      "Test Epoch: 63 | Loss: 0.336 | Acc: 89.842% (1707/1900)\n",
      "Test Epoch: 63 | Loss: 0.342 | Acc: 89.750% (1795/2000)\n",
      "Test Epoch: 63 | Loss: 0.341 | Acc: 89.524% (1880/2100)\n",
      "Test Epoch: 63 | Loss: 0.336 | Acc: 89.591% (1971/2200)\n",
      "Test Epoch: 63 | Loss: 0.337 | Acc: 89.435% (2057/2300)\n",
      "Test Epoch: 63 | Loss: 0.335 | Acc: 89.500% (2148/2400)\n",
      "Test Epoch: 63 | Loss: 0.337 | Acc: 89.640% (2241/2500)\n",
      "Test Epoch: 63 | Loss: 0.342 | Acc: 89.500% (2327/2600)\n",
      "Test Epoch: 63 | Loss: 0.341 | Acc: 89.519% (2417/2700)\n",
      "Test Epoch: 63 | Loss: 0.345 | Acc: 89.500% (2506/2800)\n",
      "Test Epoch: 63 | Loss: 0.347 | Acc: 89.552% (2597/2900)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.500% (2685/3000)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.387% (2771/3100)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.469% (2863/3200)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.485% (2953/3300)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.382% (3039/3400)\n",
      "Test Epoch: 63 | Loss: 0.356 | Acc: 89.314% (3126/3500)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.472% (3221/3600)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.324% (3305/3700)\n",
      "Test Epoch: 63 | Loss: 0.356 | Acc: 89.316% (3394/3800)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.385% (3486/3900)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.475% (3579/4000)\n",
      "Test Epoch: 63 | Loss: 0.356 | Acc: 89.390% (3665/4100)\n",
      "Test Epoch: 63 | Loss: 0.357 | Acc: 89.310% (3751/4200)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.372% (3843/4300)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.455% (3936/4400)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.444% (4025/4500)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.326% (4109/4600)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.362% (4200/4700)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.312% (4287/4800)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.265% (4374/4900)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.160% (4458/5000)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.231% (4640/5200)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.170% (4726/5300)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.204% (4817/5400)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.164% (4904/5500)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.179% (4994/5600)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.140% (5081/5700)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.138% (5170/5800)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.068% (5255/5900)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.050% (5343/6000)\n",
      "Test Epoch: 63 | Loss: 0.355 | Acc: 89.000% (5429/6100)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.048% (5521/6200)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.127% (5615/6300)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.188% (5708/6400)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.185% (5797/6500)\n",
      "Test Epoch: 63 | Loss: 0.348 | Acc: 89.242% (5890/6600)\n",
      "Test Epoch: 63 | Loss: 0.346 | Acc: 89.313% (5984/6700)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.250% (6069/6800)\n",
      "Test Epoch: 63 | Loss: 0.348 | Acc: 89.261% (6159/6900)\n",
      "Test Epoch: 63 | Loss: 0.347 | Acc: 89.257% (6248/7000)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.225% (6335/7100)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.208% (6423/7200)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.247% (6515/7300)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.203% (6601/7400)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.200% (6690/7500)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.211% (6780/7600)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.208% (6869/7700)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.244% (6961/7800)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.291% (7054/7900)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.237% (7139/8000)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.247% (7229/8100)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.220% (7316/8200)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.253% (7408/8300)\n",
      "Test Epoch: 63 | Loss: 0.349 | Acc: 89.214% (7494/8400)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.141% (7577/8500)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.058% (7659/8600)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.069% (7749/8700)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.045% (7836/8800)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.022% (7923/8900)\n",
      "Test Epoch: 63 | Loss: 0.354 | Acc: 89.000% (8010/9000)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.022% (8101/9100)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.011% (8189/9200)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.000% (8277/9300)\n",
      "Test Epoch: 63 | Loss: 0.353 | Acc: 89.000% (8366/9400)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.021% (8457/9500)\n",
      "Test Epoch: 63 | Loss: 0.352 | Acc: 89.031% (8547/9600)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.072% (8640/9700)\n",
      "Test Epoch: 63 | Loss: 0.350 | Acc: 89.071% (8729/9800)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.030% (8814/9900)\n",
      "Test Epoch: 63 | Loss: 0.351 | Acc: 89.020% (8902/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 64\n",
      "Train Epoch: 64 | Loss: 0.212 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 64 | Loss: 0.259 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 64 | Loss: 0.255 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 64 | Loss: 0.275 | Acc: 91.602% (469/512)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 92.500% (592/640)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 92.578% (711/768)\n",
      "Train Epoch: 64 | Loss: 0.239 | Acc: 92.634% (830/896)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.992% (942/1024)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 92.274% (1063/1152)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 92.045% (1296/1408)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.927% (1412/1536)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 92.127% (1533/1664)\n",
      "Train Epoch: 64 | Loss: 0.252 | Acc: 91.908% (1647/1792)\n",
      "Train Epoch: 64 | Loss: 0.254 | Acc: 91.771% (1762/1920)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.895% (1882/2048)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.866% (1999/2176)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.840% (2116/2304)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.817% (2233/2432)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.914% (2353/2560)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.964% (2472/2688)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 92.010% (2591/2816)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.848% (2704/2944)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.732% (2818/3072)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.750% (2936/3200)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.737% (3053/3328)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.840% (3174/3456)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.908% (3294/3584)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.837% (3409/3712)\n",
      "Train Epoch: 64 | Loss: 0.239 | Acc: 91.875% (3528/3840)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.986% (3650/3968)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.943% (3766/4096)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.903% (3882/4224)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.889% (3999/4352)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.920% (4118/4480)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.970% (4238/4608)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 92.019% (4358/4736)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 92.002% (4475/4864)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 92.067% (4596/4992)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 92.031% (4712/5120)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 92.035% (4830/5248)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.946% (4943/5376)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.951% (5061/5504)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.939% (5178/5632)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.962% (5297/5760)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.899% (5411/5888)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.888% (5528/6016)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.862% (5644/6144)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.885% (5763/6272)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.844% (5878/6400)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.912% (6000/6528)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.902% (6117/6656)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.907% (6235/6784)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.927% (6354/6912)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.818% (6464/7040)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.881% (6586/7168)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.804% (6698/7296)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.851% (6819/7424)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.896% (6940/7552)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.914% (7059/7680)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.893% (7175/7808)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.973% (7299/7936)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.039% (7422/8064)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.053% (7541/8192)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.043% (7658/8320)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.034% (7775/8448)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.071% (7896/8576)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.038% (8011/8704)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.984% (8124/8832)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.987% (8242/8960)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.967% (8358/9088)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 92.003% (8479/9216)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.984% (8595/9344)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.976% (8712/9472)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.865% (8819/9600)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.817% (8932/9728)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.853% (9053/9856)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.897% (9175/9984)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.930% (9296/10112)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.904% (9411/10240)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.927% (9531/10368)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.959% (9652/10496)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.933% (9767/10624)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.899% (9881/10752)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.884% (9997/10880)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.879% (10114/11008)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.846% (10228/11136)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.850% (10346/11264)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.845% (10463/11392)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.875% (10584/11520)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.887% (10703/11648)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.924% (10825/11776)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.944% (10945/11904)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.963% (11065/12032)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.990% (11186/12160)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.984% (11303/12288)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.986% (11421/12416)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 92.012% (11542/12544)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 92.030% (11662/12672)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.023% (11779/12800)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.041% (11899/12928)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.065% (12020/13056)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 92.059% (12137/13184)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.105% (12261/13312)\n",
      "Train Epoch: 64 | Loss: 0.231 | Acc: 92.143% (12384/13440)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.173% (12506/13568)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.188% (12626/13696)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.180% (12743/13824)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.209% (12865/13952)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.209% (12983/14080)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.209% (13101/14208)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.215% (13220/14336)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.215% (13338/14464)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.215% (13456/14592)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.221% (13575/14720)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.201% (13690/14848)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.201% (13808/14976)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.188% (13924/15104)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.201% (14044/15232)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.227% (14166/15360)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.188% (14278/15488)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.194% (14397/15616)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.175% (14512/15744)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.188% (14632/15872)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.200% (14752/16000)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.219% (14873/16128)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.231% (14993/16256)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.218% (15109/16384)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.200% (15224/16512)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.212% (15344/16640)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.205% (15461/16768)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.229% (15583/16896)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.229% (15701/17024)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.234% (15820/17152)\n",
      "Train Epoch: 64 | Loss: 0.228 | Acc: 92.234% (15938/17280)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.210% (16052/17408)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.193% (16167/17536)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.176% (16282/17664)\n",
      "Train Epoch: 64 | Loss: 0.229 | Acc: 92.154% (16396/17792)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.148% (16513/17920)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.110% (16624/18048)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.132% (16746/18176)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.122% (16862/18304)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.139% (16983/18432)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.128% (17099/18560)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.145% (17220/18688)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.161% (17341/18816)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.145% (17456/18944)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.130% (17571/19072)\n",
      "Train Epoch: 64 | Loss: 0.230 | Acc: 92.109% (17685/19200)\n",
      "Train Epoch: 64 | Loss: 0.231 | Acc: 92.100% (17801/19328)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.059% (17911/19456)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.060% (18029/19584)\n",
      "Train Epoch: 64 | Loss: 0.231 | Acc: 92.051% (18145/19712)\n",
      "Train Epoch: 64 | Loss: 0.231 | Acc: 92.061% (18265/19840)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.047% (18380/19968)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.023% (18493/20096)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.000% (18606/20224)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 91.986% (18721/20352)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 91.992% (18840/20480)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.003% (18960/20608)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.024% (19082/20736)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.025% (19200/20864)\n",
      "Train Epoch: 64 | Loss: 0.231 | Acc: 92.026% (19318/20992)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.012% (19433/21120)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.023% (19553/21248)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.005% (19667/21376)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.006% (19785/21504)\n",
      "Train Epoch: 64 | Loss: 0.232 | Acc: 92.003% (19902/21632)\n",
      "Train Epoch: 64 | Loss: 0.233 | Acc: 91.972% (20013/21760)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.950% (20126/21888)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.933% (20240/22016)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.948% (20361/22144)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.954% (20480/22272)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.924% (20591/22400)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.943% (20713/22528)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.927% (20827/22656)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.924% (20944/22784)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.943% (21066/22912)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.936% (21182/23040)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.929% (21298/23168)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.943% (21419/23296)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.944% (21537/23424)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.941% (21654/23552)\n",
      "Train Epoch: 64 | Loss: 0.234 | Acc: 91.947% (21773/23680)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.952% (21892/23808)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.920% (22002/23936)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.926% (22121/24064)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.919% (22237/24192)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.941% (22360/24320)\n",
      "Train Epoch: 64 | Loss: 0.235 | Acc: 91.926% (22474/24448)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.903% (22586/24576)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.888% (22700/24704)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.889% (22818/24832)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.879% (22933/24960)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.869% (23048/25088)\n",
      "Train Epoch: 64 | Loss: 0.236 | Acc: 91.874% (23167/25216)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.864% (23282/25344)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.873% (23402/25472)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.875% (23520/25600)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.869% (23636/25728)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.847% (23748/25856)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.845% (23865/25984)\n",
      "Train Epoch: 64 | Loss: 0.237 | Acc: 91.850% (23984/26112)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.845% (24100/26240)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.827% (24213/26368)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.825% (24330/26496)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.819% (24446/26624)\n",
      "Train Epoch: 64 | Loss: 0.238 | Acc: 91.806% (24560/26752)\n",
      "Train Epoch: 64 | Loss: 0.239 | Acc: 91.778% (24670/26880)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.751% (24780/27008)\n",
      "Train Epoch: 64 | Loss: 0.239 | Acc: 91.760% (24900/27136)\n",
      "Train Epoch: 64 | Loss: 0.239 | Acc: 91.762% (25018/27264)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.749% (25132/27392)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.748% (25249/27520)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.746% (25366/27648)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.752% (25485/27776)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.747% (25601/27904)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.727% (25713/28032)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.733% (25832/28160)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.739% (25951/28288)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.751% (26072/28416)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.746% (26188/28544)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.752% (26307/28672)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.750% (26424/28800)\n",
      "Train Epoch: 64 | Loss: 0.240 | Acc: 91.735% (26537/28928)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.726% (26652/29056)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.718% (26767/29184)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.700% (26879/29312)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.695% (26995/29440)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.704% (27115/29568)\n",
      "Train Epoch: 64 | Loss: 0.241 | Acc: 91.692% (27229/29696)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.678% (27342/29824)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.660% (27454/29952)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.669% (27574/30080)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.664% (27690/30208)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.667% (27808/30336)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.646% (27919/30464)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.642% (28035/30592)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.641% (28152/30720)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.656% (28274/30848)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.661% (28393/30976)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.667% (28512/31104)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.672% (28631/31232)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.665% (28746/31360)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.676% (28867/31488)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.685% (28987/31616)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.687% (29105/31744)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.701% (29227/31872)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.691% (29341/32000)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.689% (29458/32128)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.667% (29568/32256)\n",
      "Train Epoch: 64 | Loss: 0.242 | Acc: 91.678% (29689/32384)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.671% (29804/32512)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.676% (29923/32640)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.669% (30038/32768)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.662% (30153/32896)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.655% (30268/33024)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 91.626% (30376/33152)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.632% (30495/33280)\n",
      "Train Epoch: 64 | Loss: 0.243 | Acc: 91.640% (30615/33408)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 91.636% (30731/33536)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 91.620% (30843/33664)\n",
      "Train Epoch: 64 | Loss: 0.244 | Acc: 91.619% (30960/33792)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.613% (31075/33920)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.609% (31191/34048)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.608% (31308/34176)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.616% (31428/34304)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.621% (31547/34432)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.632% (31668/34560)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.620% (31781/34688)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.622% (31899/34816)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.612% (32013/34944)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.609% (32129/35072)\n",
      "Train Epoch: 64 | Loss: 0.245 | Acc: 91.614% (32248/35200)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.596% (32359/35328)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.595% (32476/35456)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.595% (32593/35584)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.585% (32707/35712)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.579% (32822/35840)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.590% (32943/35968)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.584% (33058/36096)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.577% (33173/36224)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.566% (33286/36352)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.557% (33400/36480)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.556% (33517/36608)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.559% (33635/36736)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.550% (33749/36864)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.544% (33864/36992)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.541% (33980/37120)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.551% (34101/37248)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.543% (34215/37376)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.542% (34332/37504)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.544% (34450/37632)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.525% (34560/37760)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.541% (34683/37888)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.546% (34802/38016)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.548% (34920/38144)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.560% (35042/38272)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.568% (35162/38400)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.559% (35276/38528)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.554% (35391/38656)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.556% (35509/38784)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.560% (35628/38912)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.570% (35749/39040)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.565% (35864/39168)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.561% (35980/39296)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.561% (36097/39424)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.563% (36215/39552)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.562% (36332/39680)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.572% (36453/39808)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.574% (36571/39936)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.581% (36691/40064)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.565% (36802/40192)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.558% (36916/40320)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.564% (37036/40448)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.552% (37148/40576)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.551% (37265/40704)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.551% (37382/40832)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.550% (37499/40960)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.557% (37619/41088)\n",
      "Train Epoch: 64 | Loss: 0.246 | Acc: 91.552% (37734/41216)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.544% (37848/41344)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.532% (37960/41472)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.522% (38073/41600)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.512% (38186/41728)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.514% (38304/41856)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.504% (38417/41984)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.513% (38538/42112)\n",
      "Train Epoch: 64 | Loss: 0.247 | Acc: 91.510% (38654/42240)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.512% (38772/42368)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.496% (38882/42496)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.495% (38999/42624)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.476% (39108/42752)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.483% (39228/42880)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.476% (39342/43008)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.473% (39458/43136)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.466% (39572/43264)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.468% (39690/43392)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.461% (39804/43520)\n",
      "Train Epoch: 64 | Loss: 0.248 | Acc: 91.470% (39925/43648)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.463% (40039/43776)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.454% (40152/43904)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.447% (40266/44032)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.447% (40383/44160)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.445% (40499/44288)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.442% (40615/44416)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.442% (40732/44544)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.440% (40848/44672)\n",
      "Train Epoch: 64 | Loss: 0.249 | Acc: 91.442% (40966/44800)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.433% (41079/44928)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.428% (41194/45056)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.426% (41310/45184)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.417% (41423/45312)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.415% (41539/45440)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.413% (41655/45568)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.417% (41774/45696)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.426% (41895/45824)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.430% (42014/45952)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.419% (42126/46080)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.415% (42241/46208)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.404% (42353/46336)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.404% (42470/46464)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.398% (42584/46592)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.404% (42704/46720)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.411% (42824/46848)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.413% (42942/46976)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.398% (43052/47104)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.398% (43169/47232)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.402% (43288/47360)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.402% (43405/47488)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.398% (43520/47616)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.408% (43642/47744)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.413% (43761/47872)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.419% (43881/48000)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.427% (44002/48128)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.429% (44120/48256)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.423% (44234/48384)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.425% (44352/48512)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.423% (44468/48640)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.423% (44585/48768)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.429% (44705/48896)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.418% (44817/49024)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.418% (44934/49152)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.420% (45052/49280)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.422% (45170/49408)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.416% (45284/49536)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.420% (45403/49664)\n",
      "Train Epoch: 64 | Loss: 0.250 | Acc: 91.416% (45518/49792)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.410% (45632/49920)\n",
      "Train Epoch: 64 | Loss: 0.251 | Acc: 91.412% (45706/50000)\n",
      "Test Epoch: 64 | Loss: 0.388 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 64 | Loss: 0.439 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 64 | Loss: 0.379 | Acc: 87.333% (262/300)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 64 | Loss: 0.361 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 64 | Loss: 0.360 | Acc: 89.286% (625/700)\n",
      "Test Epoch: 64 | Loss: 0.369 | Acc: 89.000% (712/800)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.889% (800/900)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 89.000% (890/1000)\n",
      "Test Epoch: 64 | Loss: 0.399 | Acc: 88.545% (974/1100)\n",
      "Test Epoch: 64 | Loss: 0.394 | Acc: 88.167% (1058/1200)\n",
      "Test Epoch: 64 | Loss: 0.387 | Acc: 88.231% (1147/1300)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.286% (1236/1400)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.133% (1322/1500)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.188% (1411/1600)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.235% (1500/1700)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.222% (1588/1800)\n",
      "Test Epoch: 64 | Loss: 0.381 | Acc: 88.368% (1679/1900)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.350% (1767/2000)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.524% (1859/2100)\n",
      "Test Epoch: 64 | Loss: 0.373 | Acc: 88.636% (1950/2200)\n",
      "Test Epoch: 64 | Loss: 0.373 | Acc: 88.478% (2035/2300)\n",
      "Test Epoch: 64 | Loss: 0.371 | Acc: 88.500% (2124/2400)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.360% (2209/2500)\n",
      "Test Epoch: 64 | Loss: 0.395 | Acc: 88.115% (2291/2600)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.185% (2381/2700)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.214% (2470/2800)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.207% (2558/2900)\n",
      "Test Epoch: 64 | Loss: 0.394 | Acc: 88.100% (2643/3000)\n",
      "Test Epoch: 64 | Loss: 0.399 | Acc: 87.935% (2726/3100)\n",
      "Test Epoch: 64 | Loss: 0.393 | Acc: 88.094% (2819/3200)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.152% (2909/3300)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.088% (2995/3400)\n",
      "Test Epoch: 64 | Loss: 0.393 | Acc: 88.029% (3081/3500)\n",
      "Test Epoch: 64 | Loss: 0.390 | Acc: 88.111% (3172/3600)\n",
      "Test Epoch: 64 | Loss: 0.398 | Acc: 88.000% (3256/3700)\n",
      "Test Epoch: 64 | Loss: 0.399 | Acc: 88.026% (3345/3800)\n",
      "Test Epoch: 64 | Loss: 0.394 | Acc: 88.154% (3438/3900)\n",
      "Test Epoch: 64 | Loss: 0.394 | Acc: 88.175% (3527/4000)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.171% (3615/4100)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.143% (3702/4200)\n",
      "Test Epoch: 64 | Loss: 0.389 | Acc: 88.233% (3794/4300)\n",
      "Test Epoch: 64 | Loss: 0.388 | Acc: 88.318% (3886/4400)\n",
      "Test Epoch: 64 | Loss: 0.385 | Acc: 88.400% (3978/4500)\n",
      "Test Epoch: 64 | Loss: 0.386 | Acc: 88.348% (4064/4600)\n",
      "Test Epoch: 64 | Loss: 0.388 | Acc: 88.277% (4149/4700)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.083% (4228/4800)\n",
      "Test Epoch: 64 | Loss: 0.390 | Acc: 88.184% (4321/4900)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.080% (4404/5000)\n",
      "Test Epoch: 64 | Loss: 0.390 | Acc: 88.157% (4496/5100)\n",
      "Test Epoch: 64 | Loss: 0.390 | Acc: 88.154% (4584/5200)\n",
      "Test Epoch: 64 | Loss: 0.390 | Acc: 88.113% (4670/5300)\n",
      "Test Epoch: 64 | Loss: 0.388 | Acc: 88.185% (4762/5400)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.091% (4845/5500)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.071% (4932/5600)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 88.018% (5017/5700)\n",
      "Test Epoch: 64 | Loss: 0.391 | Acc: 88.017% (5105/5800)\n",
      "Test Epoch: 64 | Loss: 0.394 | Acc: 87.847% (5183/5900)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 87.850% (5271/6000)\n",
      "Test Epoch: 64 | Loss: 0.393 | Acc: 87.836% (5358/6100)\n",
      "Test Epoch: 64 | Loss: 0.392 | Acc: 87.823% (5445/6200)\n",
      "Test Epoch: 64 | Loss: 0.389 | Acc: 87.889% (5537/6300)\n",
      "Test Epoch: 64 | Loss: 0.386 | Acc: 87.906% (5626/6400)\n",
      "Test Epoch: 64 | Loss: 0.386 | Acc: 87.954% (5717/6500)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.015% (5809/6600)\n",
      "Test Epoch: 64 | Loss: 0.381 | Acc: 88.090% (5902/6700)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 87.985% (5983/6800)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.014% (6073/6900)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.000% (6160/7000)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.014% (6249/7100)\n",
      "Test Epoch: 64 | Loss: 0.383 | Acc: 88.000% (6336/7200)\n",
      "Test Epoch: 64 | Loss: 0.382 | Acc: 88.055% (6428/7300)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.081% (6518/7400)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.107% (6608/7500)\n",
      "Test Epoch: 64 | Loss: 0.379 | Acc: 88.145% (6699/7600)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.143% (6787/7700)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.179% (6878/7800)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.203% (6968/7900)\n",
      "Test Epoch: 64 | Loss: 0.377 | Acc: 88.250% (7060/8000)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.284% (7151/8100)\n",
      "Test Epoch: 64 | Loss: 0.377 | Acc: 88.293% (7240/8200)\n",
      "Test Epoch: 64 | Loss: 0.377 | Acc: 88.277% (7327/8300)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.298% (7417/8400)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.271% (7503/8500)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.198% (7585/8600)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.195% (7673/8700)\n",
      "Test Epoch: 64 | Loss: 0.379 | Acc: 88.148% (7757/8800)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.135% (7844/8900)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.122% (7931/9000)\n",
      "Test Epoch: 64 | Loss: 0.381 | Acc: 88.110% (8018/9100)\n",
      "Test Epoch: 64 | Loss: 0.379 | Acc: 88.130% (8108/9200)\n",
      "Test Epoch: 64 | Loss: 0.380 | Acc: 88.129% (8196/9300)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.191% (8290/9400)\n",
      "Test Epoch: 64 | Loss: 0.377 | Acc: 88.221% (8381/9500)\n",
      "Test Epoch: 64 | Loss: 0.378 | Acc: 88.208% (8468/9600)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.299% (8565/9700)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.306% (8654/9800)\n",
      "Test Epoch: 64 | Loss: 0.376 | Acc: 88.242% (8736/9900)\n",
      "Test Epoch: 64 | Loss: 0.375 | Acc: 88.270% (8827/10000)\n",
      "\n",
      "Epoch: 65\n",
      "Train Epoch: 65 | Loss: 0.302 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 65 | Loss: 0.234 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 65 | Loss: 0.224 | Acc: 93.359% (478/512)\n",
      "Train Epoch: 65 | Loss: 0.233 | Acc: 93.125% (596/640)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 92.708% (712/768)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.964% (824/896)\n",
      "Train Epoch: 65 | Loss: 0.268 | Acc: 91.504% (937/1024)\n",
      "Train Epoch: 65 | Loss: 0.264 | Acc: 91.667% (1056/1152)\n",
      "Train Epoch: 65 | Loss: 0.265 | Acc: 91.641% (1173/1280)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.761% (1292/1408)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.732% (1409/1536)\n",
      "Train Epoch: 65 | Loss: 0.260 | Acc: 91.647% (1525/1664)\n",
      "Train Epoch: 65 | Loss: 0.257 | Acc: 91.629% (1642/1792)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.771% (1762/1920)\n",
      "Train Epoch: 65 | Loss: 0.259 | Acc: 91.553% (1875/2048)\n",
      "Train Epoch: 65 | Loss: 0.263 | Acc: 91.360% (1988/2176)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.450% (2107/2304)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.365% (2222/2432)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.406% (2340/2560)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.481% (2459/2688)\n",
      "Train Epoch: 65 | Loss: 0.263 | Acc: 91.406% (2574/2816)\n",
      "Train Epoch: 65 | Loss: 0.264 | Acc: 91.202% (2685/2944)\n",
      "Train Epoch: 65 | Loss: 0.264 | Acc: 91.243% (2803/3072)\n",
      "Train Epoch: 65 | Loss: 0.262 | Acc: 91.219% (2919/3200)\n",
      "Train Epoch: 65 | Loss: 0.261 | Acc: 91.196% (3035/3328)\n",
      "Train Epoch: 65 | Loss: 0.256 | Acc: 91.435% (3160/3456)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.602% (3283/3584)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.649% (3402/3712)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.693% (3521/3840)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.608% (3635/3968)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.675% (3755/4096)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.714% (3874/4224)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.797% (3995/4352)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.875% (4116/4480)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 92.014% (4240/4608)\n",
      "Train Epoch: 65 | Loss: 0.239 | Acc: 91.997% (4357/4736)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.941% (4472/4864)\n",
      "Train Epoch: 65 | Loss: 0.239 | Acc: 91.987% (4592/4992)\n",
      "Train Epoch: 65 | Loss: 0.238 | Acc: 92.051% (4713/5120)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 91.997% (4828/5248)\n",
      "Train Epoch: 65 | Loss: 0.238 | Acc: 92.020% (4947/5376)\n",
      "Train Epoch: 65 | Loss: 0.238 | Acc: 92.078% (5068/5504)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 92.045% (5184/5632)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 91.962% (5297/5760)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 92.018% (5418/5888)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 92.021% (5536/6016)\n",
      "Train Epoch: 65 | Loss: 0.239 | Acc: 92.008% (5653/6144)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 92.012% (5771/6272)\n",
      "Train Epoch: 65 | Loss: 0.239 | Acc: 92.031% (5890/6400)\n",
      "Train Epoch: 65 | Loss: 0.238 | Acc: 92.050% (6009/6528)\n",
      "Train Epoch: 65 | Loss: 0.240 | Acc: 91.977% (6122/6656)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.907% (6235/6784)\n",
      "Train Epoch: 65 | Loss: 0.242 | Acc: 91.913% (6353/6912)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.875% (6468/7040)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.825% (6582/7168)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.735% (6693/7296)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.797% (6815/7424)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.883% (6939/7552)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.836% (7053/7680)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.919% (7177/7808)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.923% (7295/7936)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.853% (7407/8064)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.858% (7525/8192)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.839% (7641/8320)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.821% (7757/8448)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.838% (7876/8576)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.820% (7992/8704)\n",
      "Train Epoch: 65 | Loss: 0.242 | Acc: 91.837% (8111/8832)\n",
      "Train Epoch: 65 | Loss: 0.242 | Acc: 91.819% (8227/8960)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.846% (8347/9088)\n",
      "Train Epoch: 65 | Loss: 0.239 | Acc: 91.905% (8470/9216)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.888% (8586/9344)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.902% (8705/9472)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.927% (8825/9600)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.931% (8943/9728)\n",
      "Train Epoch: 65 | Loss: 0.241 | Acc: 91.873% (9055/9856)\n",
      "Train Epoch: 65 | Loss: 0.242 | Acc: 91.837% (9169/9984)\n",
      "Train Epoch: 65 | Loss: 0.243 | Acc: 91.831% (9286/10112)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.748% (9395/10240)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.705% (9508/10368)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.692% (9624/10496)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.717% (9744/10624)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.722% (9862/10752)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.700% (9977/10880)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.670% (10091/11008)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.649% (10206/11136)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.628% (10321/11264)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.608% (10436/11392)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.615% (10554/11520)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.638% (10674/11648)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.636% (10791/11776)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.633% (10908/11904)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.622% (11024/12032)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.620% (11141/12160)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.626% (11259/12288)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.591% (11372/12416)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.598% (11490/12544)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.580% (11605/12672)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.625% (11728/12800)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.615% (11844/12928)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.651% (11966/13056)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.641% (12082/13184)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.632% (12198/13312)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.659% (12319/13440)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.642% (12434/13568)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.676% (12556/13696)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.674% (12673/13824)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.671% (12790/13952)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.676% (12908/14080)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.688% (13027/14208)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.671% (13142/14336)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.669% (13259/14464)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.639% (13372/14592)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.637% (13489/14720)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.655% (13609/14848)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.653% (13726/14976)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.638% (13841/15104)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.616% (13955/15232)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.615% (14072/15360)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.619% (14190/15488)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.605% (14305/15616)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.597% (14421/15744)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.589% (14537/15872)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.569% (14651/16000)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.555% (14766/16128)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.535% (14880/16256)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.553% (15000/16384)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.558% (15118/16512)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.556% (15235/16640)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.555% (15352/16768)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.560% (15470/16896)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.582% (15591/17024)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.575% (15707/17152)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.574% (15824/17280)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.573% (15941/17408)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.594% (16062/17536)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.593% (16179/17664)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.530% (16285/17792)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.551% (16406/17920)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.550% (16523/18048)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.527% (16636/18176)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.516% (16751/18304)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.526% (16870/18432)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.519% (16986/18560)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.513% (17102/18688)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.555% (17227/18816)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.543% (17342/18944)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.553% (17461/19072)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.562% (17580/19200)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.572% (17699/19328)\n",
      "Train Epoch: 65 | Loss: 0.244 | Acc: 91.576% (17817/19456)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.539% (17927/19584)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.538% (18044/19712)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.542% (18162/19840)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.526% (18276/19968)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.501% (18388/20096)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.535% (18512/20224)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.554% (18633/20352)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.548% (18749/20480)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.547% (18866/20608)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.556% (18985/20736)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.545% (19100/20864)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.559% (19220/20992)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.581% (19342/21120)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.557% (19454/21248)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.556% (19571/21376)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.569% (19691/21504)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.582% (19811/21632)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.595% (19931/21760)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.562% (20041/21888)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.556% (20157/22016)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.537% (20270/22144)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.550% (20390/22272)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.536% (20504/22400)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.513% (20616/22528)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.521% (20735/22656)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.525% (20853/22784)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.498% (20964/22912)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.510% (21084/23040)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.493% (21197/23168)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.501% (21316/23296)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.483% (21429/23424)\n",
      "Train Epoch: 65 | Loss: 0.245 | Acc: 91.508% (21552/23552)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.508% (21669/23680)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.507% (21786/23808)\n",
      "Train Epoch: 65 | Loss: 0.246 | Acc: 91.494% (21900/23936)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.477% (22013/24064)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.456% (22125/24192)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.460% (22243/24320)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.447% (22357/24448)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.463% (22478/24576)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.459% (22594/24704)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.447% (22708/24832)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.458% (22828/24960)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.454% (22944/25088)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.466% (23064/25216)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.461% (23180/25344)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.465% (23298/25472)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.453% (23412/25600)\n",
      "Train Epoch: 65 | Loss: 0.247 | Acc: 91.441% (23526/25728)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.433% (23641/25856)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.437% (23759/25984)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.445% (23878/26112)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.441% (23994/26240)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.418% (24105/26368)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.440% (24228/26496)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.436% (24344/26624)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.440% (24462/26752)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.436% (24578/26880)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.436% (24695/27008)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.421% (24808/27136)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.417% (24924/27264)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.414% (25040/27392)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.417% (25158/27520)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.428% (25278/27648)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.428% (25395/27776)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.428% (25512/27904)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (25623/28032)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.417% (25743/28160)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.410% (25858/28288)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (25974/28416)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (26091/28544)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.434% (26216/28672)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.438% (26334/28800)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.424% (26447/28928)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.413% (26561/29056)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.417% (26679/29184)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.416% (26796/29312)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.420% (26914/29440)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.420% (27031/29568)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (27144/29696)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.396% (27258/29824)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.410% (27379/29952)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.410% (27496/30080)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.386% (27606/30208)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.370% (27718/30336)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.380% (27838/30464)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.390% (27958/30592)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.400% (28078/30720)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (28197/30848)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.422% (28319/30976)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.419% (28435/31104)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.419% (28552/31232)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.413% (28667/31360)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.416% (28785/31488)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.409% (28900/31616)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.413% (29018/31744)\n",
      "Train Epoch: 65 | Loss: 0.248 | Acc: 91.419% (29137/31872)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (29250/32000)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.403% (29366/32128)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.397% (29481/32256)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.366% (29588/32384)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.375% (29708/32512)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.385% (29828/32640)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.388% (29946/32768)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.400% (30067/32896)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.403% (30185/33024)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.409% (30304/33152)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.409% (30421/33280)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.412% (30539/33408)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.412% (30656/33536)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.409% (30772/33664)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.400% (30886/33792)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.406% (31005/33920)\n",
      "Train Epoch: 65 | Loss: 0.249 | Acc: 91.392% (31117/34048)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.368% (31226/34176)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.365% (31342/34304)\n",
      "Train Epoch: 65 | Loss: 0.250 | Acc: 91.351% (31454/34432)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.340% (31567/34560)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.317% (31676/34688)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.320% (31794/34816)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.323% (31912/34944)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.335% (32033/35072)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.330% (32148/35200)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.327% (32264/35328)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.322% (32379/35456)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.325% (32497/35584)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.328% (32615/35712)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.323% (32730/35840)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.320% (32846/35968)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.320% (32963/36096)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.326% (33082/36224)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.318% (33196/36352)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.324% (33315/36480)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.322% (33431/36608)\n",
      "Train Epoch: 65 | Loss: 0.251 | Acc: 91.333% (33552/36736)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.336% (33670/36864)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.322% (33782/36992)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.309% (33894/37120)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.296% (34006/37248)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.286% (34119/37376)\n",
      "Train Epoch: 65 | Loss: 0.252 | Acc: 91.292% (34238/37504)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.292% (34355/37632)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.290% (34471/37760)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.285% (34586/37888)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.288% (34704/38016)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.288% (34821/38144)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.278% (34934/38272)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.271% (35048/38400)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.276% (35167/38528)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.290% (35289/38656)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.295% (35408/38784)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.301% (35527/38912)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.294% (35641/39040)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.286% (35755/39168)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.282% (35870/39296)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.287% (35989/39424)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.272% (36100/39552)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.273% (36217/39680)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.271% (36333/39808)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.276% (36452/39936)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.266% (36565/40064)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.272% (36684/40192)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.272% (36801/40320)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.263% (36914/40448)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.246% (37024/40576)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.254% (37144/40704)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.254% (37261/40832)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.257% (37379/40960)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.263% (37498/41088)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.253% (37611/41216)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.254% (37728/41344)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.252% (37844/41472)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.260% (37964/41600)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.258% (38080/41728)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.268% (38201/41856)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.278% (38322/41984)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.276% (38438/42112)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.274% (38554/42240)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.274% (38671/42368)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.277% (38789/42496)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.275% (38905/42624)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.271% (39020/42752)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.255% (39130/42880)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.260% (39249/43008)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.260% (39366/43136)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.251% (39479/43264)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.263% (39601/43392)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.268% (39720/43520)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.283% (39843/43648)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.276% (39957/43776)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.274% (40073/43904)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.265% (40186/44032)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.266% (40303/44160)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.257% (40416/44288)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.267% (40537/44416)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.269% (40655/44544)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.267% (40771/44672)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.270% (40889/44800)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.259% (41001/44928)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.262% (41119/45056)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.260% (41235/45184)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.269% (41356/45312)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.281% (41478/45440)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.283% (41596/45568)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.282% (41712/45696)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.282% (41829/45824)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.278% (41944/45952)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.280% (42062/46080)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.289% (42183/46208)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.283% (42297/46336)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.296% (42420/46464)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.292% (42535/46592)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.286% (42649/46720)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.282% (42764/46848)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.285% (42882/46976)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.283% (42998/47104)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.292% (43119/47232)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.299% (43239/47360)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.299% (43356/47488)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.305% (43476/47616)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.310% (43595/47744)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.312% (43713/47872)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.321% (43834/48000)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.315% (43948/48128)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.317% (44066/48256)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.317% (44183/48384)\n",
      "Train Epoch: 65 | Loss: 0.255 | Acc: 91.313% (44298/48512)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.318% (44417/48640)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.324% (44537/48768)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.320% (44652/48896)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.314% (44766/49024)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.317% (44884/49152)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.321% (45003/49280)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.317% (45118/49408)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.323% (45238/49536)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.322% (45354/49664)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.332% (45476/49792)\n",
      "Train Epoch: 65 | Loss: 0.254 | Acc: 91.332% (45593/49920)\n",
      "Train Epoch: 65 | Loss: 0.253 | Acc: 91.340% (45670/50000)\n",
      "Test Epoch: 65 | Loss: 0.286 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 65 | Loss: 0.331 | Acc: 89.000% (178/200)\n",
      "Test Epoch: 65 | Loss: 0.316 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 65 | Loss: 0.329 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 65 | Loss: 0.308 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 65 | Loss: 0.280 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 65 | Loss: 0.277 | Acc: 90.429% (633/700)\n",
      "Test Epoch: 65 | Loss: 0.305 | Acc: 89.625% (717/800)\n",
      "Test Epoch: 65 | Loss: 0.332 | Acc: 88.889% (800/900)\n",
      "Test Epoch: 65 | Loss: 0.338 | Acc: 89.000% (890/1000)\n",
      "Test Epoch: 65 | Loss: 0.350 | Acc: 88.818% (977/1100)\n",
      "Test Epoch: 65 | Loss: 0.364 | Acc: 88.583% (1063/1200)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.846% (1155/1300)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.786% (1243/1400)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.667% (1330/1500)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.562% (1417/1600)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.588% (1506/1700)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.667% (1596/1800)\n",
      "Test Epoch: 65 | Loss: 0.349 | Acc: 88.789% (1687/1900)\n",
      "Test Epoch: 65 | Loss: 0.346 | Acc: 88.950% (1779/2000)\n",
      "Test Epoch: 65 | Loss: 0.348 | Acc: 88.857% (1866/2100)\n",
      "Test Epoch: 65 | Loss: 0.346 | Acc: 88.864% (1955/2200)\n",
      "Test Epoch: 65 | Loss: 0.351 | Acc: 88.783% (2042/2300)\n",
      "Test Epoch: 65 | Loss: 0.345 | Acc: 88.958% (2135/2400)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.720% (2218/2500)\n",
      "Test Epoch: 65 | Loss: 0.359 | Acc: 88.692% (2306/2600)\n",
      "Test Epoch: 65 | Loss: 0.358 | Acc: 88.667% (2394/2700)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.714% (2484/2800)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.690% (2572/2900)\n",
      "Test Epoch: 65 | Loss: 0.358 | Acc: 88.667% (2660/3000)\n",
      "Test Epoch: 65 | Loss: 0.362 | Acc: 88.516% (2744/3100)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.688% (2838/3200)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.697% (2927/3300)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.794% (3019/3400)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.743% (3106/3500)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.778% (3196/3600)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.730% (3283/3700)\n",
      "Test Epoch: 65 | Loss: 0.360 | Acc: 88.658% (3369/3800)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.744% (3461/3900)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.775% (3551/4000)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.683% (3636/4100)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.762% (3728/4200)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.837% (3820/4300)\n",
      "Test Epoch: 65 | Loss: 0.350 | Acc: 88.977% (3915/4400)\n",
      "Test Epoch: 65 | Loss: 0.346 | Acc: 89.111% (4010/4500)\n",
      "Test Epoch: 65 | Loss: 0.348 | Acc: 89.087% (4098/4600)\n",
      "Test Epoch: 65 | Loss: 0.347 | Acc: 89.064% (4186/4700)\n",
      "Test Epoch: 65 | Loss: 0.349 | Acc: 88.938% (4269/4800)\n",
      "Test Epoch: 65 | Loss: 0.348 | Acc: 89.020% (4362/4900)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.900% (4445/5000)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.902% (4534/5100)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.827% (4619/5200)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.698% (4701/5300)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.796% (4795/5400)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.727% (4880/5500)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.732% (4969/5600)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.719% (5057/5700)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.724% (5146/5800)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.712% (5234/5900)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.650% (5319/6000)\n",
      "Test Epoch: 65 | Loss: 0.358 | Acc: 88.639% (5407/6100)\n",
      "Test Epoch: 65 | Loss: 0.362 | Acc: 88.613% (5494/6200)\n",
      "Test Epoch: 65 | Loss: 0.359 | Acc: 88.698% (5588/6300)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.734% (5679/6400)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.723% (5767/6500)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.742% (5857/6600)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.851% (5953/6700)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.765% (6036/6800)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.841% (6130/6900)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.757% (6213/7000)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.775% (6303/7100)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.750% (6390/7200)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.781% (6481/7300)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.797% (6571/7400)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.773% (6658/7500)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.737% (6744/7600)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.727% (6832/7700)\n",
      "Test Epoch: 65 | Loss: 0.357 | Acc: 88.679% (6917/7800)\n",
      "Test Epoch: 65 | Loss: 0.358 | Acc: 88.671% (7005/7900)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.700% (7096/8000)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.741% (7188/8100)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.744% (7277/8200)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.747% (7366/8300)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.750% (7455/8400)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.718% (7541/8500)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.686% (7627/8600)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.724% (7719/8700)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.693% (7805/8800)\n",
      "Test Epoch: 65 | Loss: 0.356 | Acc: 88.708% (7895/8900)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.700% (7983/9000)\n",
      "Test Epoch: 65 | Loss: 0.355 | Acc: 88.703% (8072/9100)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.728% (8163/9200)\n",
      "Test Epoch: 65 | Loss: 0.354 | Acc: 88.774% (8256/9300)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.745% (8342/9400)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.789% (8435/9500)\n",
      "Test Epoch: 65 | Loss: 0.353 | Acc: 88.792% (8524/9600)\n",
      "Test Epoch: 65 | Loss: 0.351 | Acc: 88.845% (8618/9700)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.806% (8703/9800)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.798% (8791/9900)\n",
      "Test Epoch: 65 | Loss: 0.352 | Acc: 88.760% (8876/10000)\n",
      "\n",
      "Epoch: 66\n",
      "Train Epoch: 66 | Loss: 0.169 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 66 | Loss: 0.182 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 66 | Loss: 0.199 | Acc: 93.750% (360/384)\n",
      "Train Epoch: 66 | Loss: 0.219 | Acc: 93.164% (477/512)\n",
      "Train Epoch: 66 | Loss: 0.260 | Acc: 91.562% (586/640)\n",
      "Train Epoch: 66 | Loss: 0.269 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.853% (823/896)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.895% (941/1024)\n",
      "Train Epoch: 66 | Loss: 0.237 | Acc: 92.014% (1060/1152)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.797% (1175/1280)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.761% (1292/1408)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.862% (1411/1536)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.767% (1527/1664)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.574% (1641/1792)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.510% (1757/1920)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.553% (1875/2048)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.498% (1991/2176)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.450% (2107/2304)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.488% (2225/2432)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.562% (2344/2560)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.815% (2468/2688)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.797% (2585/2816)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.814% (2703/2944)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.602% (2814/3072)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.625% (2932/3200)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.647% (3050/3328)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.696% (3169/3456)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.713% (3287/3584)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.676% (3403/3712)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.693% (3521/3840)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.608% (3635/3968)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.577% (3751/4096)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.667% (3872/4224)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.682% (3990/4352)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.719% (4109/4480)\n",
      "Train Epoch: 66 | Loss: 0.239 | Acc: 91.819% (4231/4608)\n",
      "Train Epoch: 66 | Loss: 0.238 | Acc: 91.829% (4349/4736)\n",
      "Train Epoch: 66 | Loss: 0.239 | Acc: 91.756% (4463/4864)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.747% (4580/4992)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.680% (4694/5120)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.635% (4809/5248)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.667% (4928/5376)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.661% (5045/5504)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.548% (5156/5632)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.545% (5273/5760)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.542% (5390/5888)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.539% (5507/6016)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.618% (5629/6144)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.677% (5750/6272)\n",
      "Train Epoch: 66 | Loss: 0.238 | Acc: 91.734% (5871/6400)\n",
      "Train Epoch: 66 | Loss: 0.238 | Acc: 91.759% (5990/6528)\n",
      "Train Epoch: 66 | Loss: 0.239 | Acc: 91.722% (6105/6656)\n",
      "Train Epoch: 66 | Loss: 0.238 | Acc: 91.775% (6226/6784)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.725% (6340/6912)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.676% (6454/7040)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.699% (6573/7168)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.721% (6692/7296)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.662% (6805/7424)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.618% (6919/7552)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.615% (7036/7680)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.573% (7150/7808)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.608% (7270/7936)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.592% (7386/8064)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.516% (7497/8192)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.538% (7616/8320)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.596% (7738/8448)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.604% (7856/8576)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.567% (7970/8704)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.531% (8084/8832)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.540% (8202/8960)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.538% (8319/9088)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.547% (8437/9216)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.556% (8555/9344)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.533% (8670/9472)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.500% (8784/9600)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.427% (8894/9728)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.437% (9012/9856)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.456% (9131/9984)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.495% (9252/10112)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.475% (9367/10240)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.483% (9485/10368)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.425% (9596/10496)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.444% (9715/10624)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.425% (9830/10752)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.406% (9945/10880)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.397% (10061/11008)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.406% (10179/11136)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.406% (10296/11264)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.389% (10411/11392)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.415% (10531/11520)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.441% (10651/11648)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.449% (10769/11776)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.499% (10892/11904)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.464% (11005/12032)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.480% (11124/12160)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.471% (11240/12288)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.495% (11360/12416)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.510% (11479/12544)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.525% (11598/12672)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.539% (11717/12800)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.515% (11831/12928)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.536% (11951/13056)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.520% (12066/13184)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.496% (12180/13312)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.510% (12299/13440)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.480% (12412/13568)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.508% (12533/13696)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.493% (12648/13824)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.528% (12770/13952)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.513% (12885/14080)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.519% (13003/14208)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.497% (13117/14336)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.482% (13232/14464)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.454% (13345/14592)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.440% (13460/14720)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.406% (13572/14848)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.433% (13693/14976)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.433% (13810/15104)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.459% (13931/15232)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.439% (14045/15360)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.439% (14162/15488)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.445% (14280/15616)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.451% (14398/15744)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.469% (14518/15872)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.463% (14634/16000)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.499% (14757/16128)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.492% (14873/16256)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.492% (14990/16384)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.509% (15110/16512)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.514% (15228/16640)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.526% (15347/16768)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.519% (15463/16896)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.477% (15573/17024)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.500% (15694/17152)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.510% (15813/17280)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.492% (15927/17408)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.480% (16042/17536)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.480% (16159/17664)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.513% (16282/17792)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.546% (16405/17920)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.539% (16521/18048)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.538% (16638/18176)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.565% (16760/18304)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.580% (16880/18432)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.589% (16999/18560)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.599% (17118/18688)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.592% (17234/18816)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.591% (17351/18944)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.585% (17467/19072)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.594% (17586/19200)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.624% (17709/19328)\n",
      "Train Epoch: 66 | Loss: 0.240 | Acc: 91.648% (17831/19456)\n",
      "Train Epoch: 66 | Loss: 0.241 | Acc: 91.631% (17945/19584)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.599% (18056/19712)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.608% (18175/19840)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.617% (18294/19968)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.595% (18407/20096)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.604% (18526/20224)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.568% (18636/20352)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.548% (18749/20480)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.557% (18868/20608)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.546% (18983/20736)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.555% (19102/20864)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.554% (19219/20992)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.567% (19339/21120)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.585% (19460/21248)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.579% (19576/21376)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.588% (19695/21504)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.600% (19815/21632)\n",
      "Train Epoch: 66 | Loss: 0.242 | Acc: 91.590% (19930/21760)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.562% (20041/21888)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.552% (20156/22016)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.564% (20276/22144)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.568% (20394/22272)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.567% (20511/22400)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.588% (20633/22528)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.592% (20751/22656)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.591% (20868/22784)\n",
      "Train Epoch: 66 | Loss: 0.243 | Acc: 91.603% (20988/22912)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.589% (21102/23040)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.575% (21216/23168)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.574% (21333/23296)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.560% (21447/23424)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.559% (21564/23552)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.579% (21686/23680)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.591% (21806/23808)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.590% (21923/23936)\n",
      "Train Epoch: 66 | Loss: 0.244 | Acc: 91.589% (22040/24064)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.584% (22156/24192)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.591% (22275/24320)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.562% (22385/24448)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.561% (22502/24576)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.552% (22617/24704)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.559% (22736/24832)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.558% (22853/24960)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.570% (22973/25088)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.573% (23091/25216)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.564% (23206/25344)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.583% (23328/25472)\n",
      "Train Epoch: 66 | Loss: 0.245 | Acc: 91.574% (23443/25600)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.569% (23559/25728)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.557% (23673/25856)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.545% (23787/25984)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.552% (23906/26112)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.536% (24019/26240)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.547% (24139/26368)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.553% (24258/26496)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.556% (24376/26624)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.556% (24493/26752)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.551% (24609/26880)\n",
      "Train Epoch: 66 | Loss: 0.246 | Acc: 91.540% (24723/27008)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.520% (24835/27136)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.520% (24952/27264)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.527% (25071/27392)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.526% (25188/27520)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.522% (25304/27648)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.525% (25422/27776)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.517% (25537/27904)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.513% (25653/28032)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.499% (25766/28160)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.502% (25884/28288)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.498% (26000/28416)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.504% (26119/28544)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.504% (26236/28672)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.497% (26351/28800)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.482% (26464/28928)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.489% (26583/29056)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.516% (26708/29184)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.498% (26820/29312)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.478% (26931/29440)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.498% (27054/29568)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.497% (27171/29696)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.497% (27288/29824)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.500% (27406/29952)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.496% (27522/30080)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.492% (27638/30208)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.495% (27756/30336)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.488% (27871/30464)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.475% (27984/30592)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.458% (28096/30720)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.478% (28219/30848)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.481% (28337/30976)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.483% (28455/31104)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.483% (28572/31232)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.470% (28685/31360)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.476% (28804/31488)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.473% (28920/31616)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.469% (29036/31744)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.463% (29151/31872)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.453% (29265/32000)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.453% (29382/32128)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.459% (29501/32256)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.449% (29615/32384)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.462% (29736/32512)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.468% (29855/32640)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.476% (29975/32768)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.473% (30091/32896)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.464% (30205/33024)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.458% (30320/33152)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.469% (30441/33280)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.475% (30560/33408)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.469% (30675/33536)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.472% (30793/33664)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.462% (30907/33792)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.483% (31031/33920)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.471% (31144/34048)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.474% (31262/34176)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.462% (31375/34304)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.456% (31490/34432)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.450% (31605/34560)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.449% (31722/34688)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.452% (31840/34816)\n",
      "Train Epoch: 66 | Loss: 0.247 | Acc: 91.452% (31957/34944)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (32069/35072)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.443% (32188/35200)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.432% (32301/35328)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.443% (32422/35456)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.437% (32537/35584)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.443% (32656/35712)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.437% (32771/35840)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.456% (32895/35968)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.451% (33010/36096)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.456% (33129/36224)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.472% (33252/36352)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.469% (33368/36480)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.450% (33478/36608)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.442% (33592/36736)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.439% (33708/36864)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.425% (33820/36992)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.425% (33937/37120)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.428% (34055/37248)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.428% (34172/37376)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (34293/37504)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.441% (34411/37632)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.446% (34530/37760)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.451% (34649/37888)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.454% (34767/38016)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (34878/38144)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (34995/38272)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (35112/38400)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.427% (35225/38528)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.442% (35348/38656)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.453% (35469/38784)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.440% (35581/38912)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.419% (35690/39040)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.427% (35810/39168)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.437% (35931/39296)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.427% (36044/39424)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.426% (36161/39552)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.429% (36279/39680)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.436% (36399/39808)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.434% (36515/39936)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.444% (36636/40064)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.446% (36754/40192)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.446% (36871/40320)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.448% (36989/40448)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.451% (37107/40576)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.438% (37219/40704)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.453% (37342/40832)\n",
      "Train Epoch: 66 | Loss: 0.248 | Acc: 91.440% (37454/40960)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.433% (37568/41088)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.406% (37674/41216)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.401% (37789/41344)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.397% (37904/41472)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.394% (38020/41600)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.392% (38136/41728)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.390% (38252/41856)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.382% (38366/41984)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.385% (38484/42112)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.378% (38598/42240)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.376% (38714/42368)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.371% (38829/42496)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.362% (38942/42624)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.376% (39065/42752)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.376% (39182/42880)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.385% (39303/43008)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.385% (39420/43136)\n",
      "Train Epoch: 66 | Loss: 0.249 | Acc: 91.390% (39539/43264)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.381% (39652/43392)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.379% (39768/43520)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.381% (39886/43648)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.381% (40003/43776)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.365% (40113/43904)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.359% (40227/44032)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.363% (40346/44160)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.352% (40458/44288)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.341% (40570/44416)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.346% (40689/44544)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.353% (40809/44672)\n",
      "Train Epoch: 66 | Loss: 0.250 | Acc: 91.357% (40928/44800)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.348% (41041/44928)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.342% (41155/45056)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.342% (41272/45184)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.338% (41387/45312)\n",
      "Train Epoch: 66 | Loss: 0.251 | Acc: 91.342% (41506/45440)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.332% (41618/45568)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.332% (41735/45696)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.319% (41846/45824)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.308% (41958/45952)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.306% (42074/46080)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.313% (42194/46208)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.298% (42304/46336)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.284% (42414/46464)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.280% (42529/46592)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.278% (42645/46720)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.276% (42761/46848)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.283% (42881/46976)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.277% (42995/47104)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.273% (43110/47232)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.280% (43230/47360)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.280% (43347/47488)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.276% (43462/47616)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.276% (43579/47744)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.266% (43691/47872)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.265% (43807/48000)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.277% (43930/48128)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.280% (44048/48256)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.288% (44169/48384)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.293% (44288/48512)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.289% (44403/48640)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.296% (44523/48768)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.286% (44635/48896)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.298% (44758/49024)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.300% (44876/49152)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.303% (44994/49280)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.303% (45111/49408)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.305% (45229/49536)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.304% (45345/49664)\n",
      "Train Epoch: 66 | Loss: 0.253 | Acc: 91.312% (45466/49792)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.308% (45581/49920)\n",
      "Train Epoch: 66 | Loss: 0.252 | Acc: 91.314% (45657/50000)\n",
      "Test Epoch: 66 | Loss: 0.362 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 66 | Loss: 0.430 | Acc: 88.000% (176/200)\n",
      "Test Epoch: 66 | Loss: 0.387 | Acc: 88.333% (265/300)\n",
      "Test Epoch: 66 | Loss: 0.358 | Acc: 89.500% (358/400)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.600% (448/500)\n",
      "Test Epoch: 66 | Loss: 0.306 | Acc: 90.167% (541/600)\n",
      "Test Epoch: 66 | Loss: 0.292 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 66 | Loss: 0.311 | Acc: 89.750% (718/800)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.300% (893/1000)\n",
      "Test Epoch: 66 | Loss: 0.336 | Acc: 89.091% (980/1100)\n",
      "Test Epoch: 66 | Loss: 0.340 | Acc: 88.917% (1067/1200)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.308% (1161/1300)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.143% (1248/1400)\n",
      "Test Epoch: 66 | Loss: 0.318 | Acc: 89.133% (1337/1500)\n",
      "Test Epoch: 66 | Loss: 0.315 | Acc: 89.188% (1427/1600)\n",
      "Test Epoch: 66 | Loss: 0.314 | Acc: 89.235% (1517/1700)\n",
      "Test Epoch: 66 | Loss: 0.323 | Acc: 89.056% (1603/1800)\n",
      "Test Epoch: 66 | Loss: 0.317 | Acc: 89.316% (1697/1900)\n",
      "Test Epoch: 66 | Loss: 0.320 | Acc: 89.450% (1789/2000)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.286% (1875/2100)\n",
      "Test Epoch: 66 | Loss: 0.320 | Acc: 89.364% (1966/2200)\n",
      "Test Epoch: 66 | Loss: 0.322 | Acc: 89.348% (2055/2300)\n",
      "Test Epoch: 66 | Loss: 0.316 | Acc: 89.542% (2149/2400)\n",
      "Test Epoch: 66 | Loss: 0.324 | Acc: 89.400% (2235/2500)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.115% (2317/2600)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.259% (2410/2700)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.143% (2496/2800)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.069% (2583/2900)\n",
      "Test Epoch: 66 | Loss: 0.334 | Acc: 89.033% (2671/3000)\n",
      "Test Epoch: 66 | Loss: 0.336 | Acc: 88.968% (2758/3100)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.094% (2851/3200)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.121% (2941/3300)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.176% (3032/3400)\n",
      "Test Epoch: 66 | Loss: 0.336 | Acc: 89.029% (3116/3500)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.111% (3208/3600)\n",
      "Test Epoch: 66 | Loss: 0.339 | Acc: 89.027% (3294/3700)\n",
      "Test Epoch: 66 | Loss: 0.339 | Acc: 89.053% (3384/3800)\n",
      "Test Epoch: 66 | Loss: 0.336 | Acc: 89.128% (3476/3900)\n",
      "Test Epoch: 66 | Loss: 0.334 | Acc: 89.175% (3567/4000)\n",
      "Test Epoch: 66 | Loss: 0.338 | Acc: 89.122% (3654/4100)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.190% (3746/4200)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.279% (3839/4300)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.364% (3932/4400)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.333% (4020/4500)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.283% (4107/4600)\n",
      "Test Epoch: 66 | Loss: 0.331 | Acc: 89.340% (4199/4700)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.208% (4282/4800)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.265% (4374/4900)\n",
      "Test Epoch: 66 | Loss: 0.336 | Acc: 89.160% (4458/5000)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.157% (4547/5100)\n",
      "Test Epoch: 66 | Loss: 0.334 | Acc: 89.154% (4636/5200)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.113% (4723/5300)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.185% (4816/5400)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.091% (4900/5500)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.089% (4989/5600)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.088% (5078/5700)\n",
      "Test Epoch: 66 | Loss: 0.332 | Acc: 89.172% (5172/5800)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.102% (5257/5900)\n",
      "Test Epoch: 66 | Loss: 0.334 | Acc: 89.133% (5348/6000)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.115% (5436/6100)\n",
      "Test Epoch: 66 | Loss: 0.335 | Acc: 89.065% (5522/6200)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.159% (5617/6300)\n",
      "Test Epoch: 66 | Loss: 0.331 | Acc: 89.250% (5712/6400)\n",
      "Test Epoch: 66 | Loss: 0.331 | Acc: 89.200% (5798/6500)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.258% (5891/6600)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.328% (5985/6700)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.265% (6070/6800)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.246% (6158/6900)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.214% (6245/7000)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.197% (6333/7100)\n",
      "Test Epoch: 66 | Loss: 0.333 | Acc: 89.181% (6421/7200)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.247% (6515/7300)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.257% (6605/7400)\n",
      "Test Epoch: 66 | Loss: 0.328 | Acc: 89.320% (6699/7500)\n",
      "Test Epoch: 66 | Loss: 0.328 | Acc: 89.368% (6792/7600)\n",
      "Test Epoch: 66 | Loss: 0.330 | Acc: 89.325% (6878/7700)\n",
      "Test Epoch: 66 | Loss: 0.329 | Acc: 89.372% (6971/7800)\n",
      "Test Epoch: 66 | Loss: 0.328 | Acc: 89.380% (7061/7900)\n",
      "Test Epoch: 66 | Loss: 0.328 | Acc: 89.375% (7150/8000)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.432% (7244/8100)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.427% (7333/8200)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.446% (7424/8300)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.464% (7515/8400)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.447% (7603/8500)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.465% (7694/8600)\n",
      "Test Epoch: 66 | Loss: 0.325 | Acc: 89.483% (7785/8700)\n",
      "Test Epoch: 66 | Loss: 0.326 | Acc: 89.455% (7872/8800)\n",
      "Test Epoch: 66 | Loss: 0.327 | Acc: 89.427% (7959/8900)\n",
      "Test Epoch: 66 | Loss: 0.327 | Acc: 89.456% (8051/9000)\n",
      "Test Epoch: 66 | Loss: 0.325 | Acc: 89.495% (8144/9100)\n",
      "Test Epoch: 66 | Loss: 0.323 | Acc: 89.554% (8239/9200)\n",
      "Test Epoch: 66 | Loss: 0.324 | Acc: 89.505% (8324/9300)\n",
      "Test Epoch: 66 | Loss: 0.324 | Acc: 89.479% (8411/9400)\n",
      "Test Epoch: 66 | Loss: 0.323 | Acc: 89.505% (8503/9500)\n",
      "Test Epoch: 66 | Loss: 0.323 | Acc: 89.500% (8592/9600)\n",
      "Test Epoch: 66 | Loss: 0.321 | Acc: 89.577% (8689/9700)\n",
      "Test Epoch: 66 | Loss: 0.321 | Acc: 89.612% (8782/9800)\n",
      "Test Epoch: 66 | Loss: 0.321 | Acc: 89.596% (8870/9900)\n",
      "Test Epoch: 66 | Loss: 0.321 | Acc: 89.610% (8961/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 67\n",
      "Train Epoch: 67 | Loss: 0.245 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 67 | Loss: 0.285 | Acc: 89.583% (344/384)\n",
      "Train Epoch: 67 | Loss: 0.257 | Acc: 91.016% (466/512)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.031% (589/640)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.927% (706/768)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 92.299% (827/896)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 91.895% (941/1024)\n",
      "Train Epoch: 67 | Loss: 0.248 | Acc: 91.319% (1052/1152)\n",
      "Train Epoch: 67 | Loss: 0.245 | Acc: 91.250% (1168/1280)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.406% (1287/1408)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.406% (1404/1536)\n",
      "Train Epoch: 67 | Loss: 0.234 | Acc: 91.587% (1524/1664)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 91.574% (1641/1792)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 91.875% (1764/1920)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 91.748% (1879/2048)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 91.866% (1999/2176)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 91.753% (2114/2304)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 91.735% (2231/2432)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 91.562% (2344/2560)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.555% (2461/2688)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.655% (2581/2816)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.610% (2697/2944)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.634% (2815/3072)\n",
      "Train Epoch: 67 | Loss: 0.234 | Acc: 91.750% (2936/3200)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.496% (3045/3328)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.638% (3167/3456)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.685% (3286/3584)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.756% (3406/3712)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.667% (3520/3840)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.633% (3636/3968)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.650% (3754/4096)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.667% (3872/4224)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.659% (3989/4352)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.652% (4106/4480)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.732% (4227/4608)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 91.765% (4346/4736)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 91.756% (4463/4864)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 91.807% (4583/4992)\n",
      "Train Epoch: 67 | Loss: 0.234 | Acc: 91.816% (4701/5120)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 91.902% (4823/5248)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 91.983% (4945/5376)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.024% (5065/5504)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.010% (5182/5632)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.049% (5302/5760)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.052% (5420/5888)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.071% (5539/6016)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.122% (5660/6144)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.156% (5780/6272)\n",
      "Train Epoch: 67 | Loss: 0.225 | Acc: 92.219% (5902/6400)\n",
      "Train Epoch: 67 | Loss: 0.225 | Acc: 92.233% (6021/6528)\n",
      "Train Epoch: 67 | Loss: 0.223 | Acc: 92.293% (6143/6656)\n",
      "Train Epoch: 67 | Loss: 0.222 | Acc: 92.305% (6262/6784)\n",
      "Train Epoch: 67 | Loss: 0.223 | Acc: 92.347% (6383/6912)\n",
      "Train Epoch: 67 | Loss: 0.224 | Acc: 92.344% (6501/7040)\n",
      "Train Epoch: 67 | Loss: 0.225 | Acc: 92.299% (6616/7168)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.283% (6733/7296)\n",
      "Train Epoch: 67 | Loss: 0.225 | Acc: 92.322% (6854/7424)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.320% (6972/7552)\n",
      "Train Epoch: 67 | Loss: 0.224 | Acc: 92.370% (7094/7680)\n",
      "Train Epoch: 67 | Loss: 0.225 | Acc: 92.328% (7209/7808)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.288% (7324/7936)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.287% (7442/8064)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.310% (7562/8192)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.260% (7676/8320)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.270% (7795/8448)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.188% (7906/8576)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.176% (8023/8704)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.188% (8142/8832)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.154% (8257/8960)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.143% (8374/9088)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.155% (8493/9216)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.155% (8611/9344)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.198% (8733/9472)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.219% (8853/9600)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.229% (8972/9728)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.259% (9093/9856)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.248% (9210/9984)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.267% (9330/10112)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.246% (9446/10240)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.265% (9566/10368)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.273% (9685/10496)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.282% (9804/10624)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.225% (9916/10752)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.224% (10034/10880)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.242% (10154/11008)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.277% (10276/11136)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.294% (10396/11264)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.354% (10521/11392)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.344% (10638/11520)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.342% (10756/11648)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.349% (10875/11776)\n",
      "Train Epoch: 67 | Loss: 0.226 | Acc: 92.347% (10993/11904)\n",
      "Train Epoch: 67 | Loss: 0.227 | Acc: 92.345% (11111/12032)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.294% (11223/12160)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.293% (11341/12288)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.284% (11458/12416)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.307% (11579/12544)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.361% (11704/12672)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.336% (11819/12800)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.350% (11939/12928)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.295% (12050/13056)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.279% (12166/13184)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.263% (12282/13312)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.262% (12400/13440)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.269% (12519/13568)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.261% (12636/13696)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.260% (12754/13824)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.266% (12873/13952)\n",
      "Train Epoch: 67 | Loss: 0.228 | Acc: 92.294% (12995/14080)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.293% (13113/14208)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.292% (13231/14336)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.291% (13349/14464)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.304% (13469/14592)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.310% (13588/14720)\n",
      "Train Epoch: 67 | Loss: 0.229 | Acc: 92.315% (13707/14848)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.301% (13823/14976)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.300% (13941/15104)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.286% (14057/15232)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.285% (14175/15360)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.317% (14298/15488)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.316% (14416/15616)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 92.251% (14524/15744)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 92.238% (14640/15872)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 92.256% (14761/16000)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 92.281% (14883/16128)\n",
      "Train Epoch: 67 | Loss: 0.230 | Acc: 92.274% (15000/16256)\n",
      "Train Epoch: 67 | Loss: 0.231 | Acc: 92.224% (15110/16384)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 92.200% (15224/16512)\n",
      "Train Epoch: 67 | Loss: 0.232 | Acc: 92.175% (15338/16640)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.164% (15454/16768)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.176% (15574/16896)\n",
      "Train Epoch: 67 | Loss: 0.234 | Acc: 92.158% (15689/17024)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.170% (15809/17152)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.176% (15928/17280)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.176% (16046/17408)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.176% (16164/17536)\n",
      "Train Epoch: 67 | Loss: 0.233 | Acc: 92.176% (16282/17664)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.137% (16393/17792)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.115% (16507/17920)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.110% (16624/18048)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.094% (16739/18176)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.116% (16861/18304)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.068% (16970/18432)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.064% (17087/18560)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.075% (17207/18688)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.087% (17327/18816)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.092% (17446/18944)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.077% (17561/19072)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.094% (17682/19200)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.105% (17802/19328)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.095% (17918/19456)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.101% (18037/19584)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.091% (18153/19712)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.077% (18268/19840)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.087% (18388/19968)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.083% (18505/20096)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.103% (18627/20224)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.084% (18741/20352)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.090% (18860/20480)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.095% (18979/20608)\n",
      "Train Epoch: 67 | Loss: 0.235 | Acc: 92.096% (19097/20736)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.049% (19205/20864)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.059% (19325/20992)\n",
      "Train Epoch: 67 | Loss: 0.236 | Acc: 92.079% (19447/21120)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.060% (19561/21248)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.066% (19680/21376)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.071% (19799/21504)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.058% (19914/21632)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.068% (20034/21760)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.087% (20156/21888)\n",
      "Train Epoch: 67 | Loss: 0.237 | Acc: 92.065% (20269/22016)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 92.052% (20384/22144)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 92.057% (20503/22272)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 92.036% (20616/22400)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 92.001% (20726/22528)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.993% (20842/22656)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.999% (20961/22784)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 92.004% (21080/22912)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.984% (21193/23040)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.993% (21313/23168)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.981% (21428/23296)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.983% (21546/23424)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.979% (21663/23552)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.985% (21782/23680)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.982% (21899/23808)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.974% (22015/23936)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.976% (22133/24064)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.968% (22249/24192)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.978% (22369/24320)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.987% (22489/24448)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.980% (22605/24576)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 91.989% (22725/24704)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.986% (22842/24832)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.979% (22958/24960)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.964% (23072/25088)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.961% (23189/25216)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.967% (23308/25344)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.983% (23430/25472)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.992% (23550/25600)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.985% (23666/25728)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.983% (23783/25856)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.984% (23901/25984)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.965% (24014/26112)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.974% (24134/26240)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.956% (24247/26368)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.950% (24363/26496)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.962% (24484/26624)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.967% (24603/26752)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.972% (24722/26880)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.973% (24840/27008)\n",
      "Train Epoch: 67 | Loss: 0.238 | Acc: 92.003% (24966/27136)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.989% (25080/27264)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.954% (25188/27392)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.959% (25307/27520)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.960% (25425/27648)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.975% (25547/27776)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.972% (25664/27904)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.959% (25778/28032)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.953% (25894/28160)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.922% (26003/28288)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.927% (26122/28416)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.932% (26241/28544)\n",
      "Train Epoch: 67 | Loss: 0.239 | Acc: 91.929% (26358/28672)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.924% (26474/28800)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.911% (26588/28928)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.912% (26706/29056)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.907% (26822/29184)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.901% (26938/29312)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.892% (27053/29440)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.886% (27169/29568)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.884% (27286/29696)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.892% (27406/29824)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.894% (27524/29952)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.882% (27638/30080)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.866% (27751/30208)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.861% (27867/30336)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.859% (27984/30464)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.848% (28098/30592)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.859% (28219/30720)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.860% (28337/30848)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.858% (28454/30976)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.856% (28571/31104)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.867% (28692/31232)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.881% (28814/31360)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.892% (28935/31488)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.890% (29052/31616)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.879% (29166/31744)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.867% (29280/31872)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.866% (29397/32000)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.867% (29515/32128)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.877% (29636/32256)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.882% (29755/32384)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.871% (29869/32512)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.869% (29986/32640)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.858% (30100/32768)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.859% (30218/32896)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.863% (30337/33024)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.862% (30454/33152)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.863% (30572/33280)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.858% (30688/33408)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.865% (30808/33536)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.864% (30925/33664)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.880% (31048/33792)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.878% (31165/33920)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.897% (31289/34048)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.895% (31406/34176)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.878% (31518/34304)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.862% (31630/34432)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.866% (31749/34560)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.850% (31861/34688)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.851% (31979/34816)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.861% (32100/34944)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.868% (32220/35072)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.861% (32335/35200)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.868% (32455/35328)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.869% (32573/35456)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.878% (32694/35584)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.879% (32812/35712)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.864% (32924/35840)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.865% (33042/35968)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.872% (33162/36096)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.859% (33275/36224)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.860% (33393/36352)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.870% (33514/36480)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.876% (33634/36608)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.874% (33751/36736)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.865% (33865/36864)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.866% (33983/36992)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.864% (34100/37120)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.860% (34216/37248)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.856% (34332/37376)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.846% (34446/37504)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.850% (34565/37632)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.849% (34682/37760)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.863% (34805/37888)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.864% (34923/38016)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.870% (35043/38144)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.864% (35158/38272)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.883% (35283/38400)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.889% (35403/38528)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.906% (35527/38656)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.888% (35638/38784)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.910% (35764/38912)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.898% (35877/39040)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.899% (35995/39168)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.905% (36115/39296)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.901% (36231/39424)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.897% (36347/39552)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.905% (36468/39680)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.906% (36586/39808)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.917% (36708/39936)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.918% (36826/40064)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.926% (36947/40192)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.925% (37064/40320)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.920% (37180/40448)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.909% (37293/40576)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.910% (37411/40704)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.906% (37527/40832)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.902% (37643/40960)\n",
      "Train Epoch: 67 | Loss: 0.240 | Acc: 91.891% (37756/41088)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.894% (37875/41216)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.888% (37990/41344)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.876% (38103/41472)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.880% (38222/41600)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.881% (38340/41728)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.882% (38458/41856)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.887% (38578/41984)\n",
      "Train Epoch: 67 | Loss: 0.241 | Acc: 91.881% (38693/42112)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.863% (38803/42240)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.862% (38920/42368)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.865% (39039/42496)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.861% (39155/42624)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.860% (39272/42752)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.863% (39391/42880)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.857% (39506/43008)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.856% (39623/43136)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.850% (39738/43264)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.849% (39855/43392)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.854% (39975/43520)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.837% (40085/43648)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.836% (40202/43776)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.841% (40322/43904)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.835% (40437/44032)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.834% (40554/44160)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.835% (40672/44288)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.836% (40790/44416)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.844% (40911/44544)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.832% (41023/44672)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.835% (41142/44800)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.834% (41259/44928)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.817% (41369/45056)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.827% (41491/45184)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.828% (41609/45312)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.835% (41730/45440)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.830% (41845/45568)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.824% (41960/45696)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.814% (42073/45824)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.813% (42190/45952)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.806% (42304/46080)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.800% (42419/46208)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.797% (42535/46336)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.798% (42653/46464)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.799% (42771/46592)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.796% (42887/46720)\n",
      "Train Epoch: 67 | Loss: 0.242 | Acc: 91.786% (43000/46848)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.783% (43116/46976)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.776% (43230/47104)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.781% (43350/47232)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.769% (43462/47360)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.764% (43577/47488)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.765% (43695/47616)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.764% (43812/47744)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.763% (43929/47872)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.767% (44048/48000)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.755% (44160/48128)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.756% (44278/48256)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.751% (44393/48384)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.761% (44515/48512)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.764% (44634/48640)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.771% (44755/48768)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.766% (44870/48896)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.765% (44987/49024)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.756% (45100/49152)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.761% (45220/49280)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.767% (45340/49408)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.747% (45448/49536)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.743% (45563/49664)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.748% (45683/49792)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.745% (45799/49920)\n",
      "Train Epoch: 67 | Loss: 0.243 | Acc: 91.744% (45872/50000)\n",
      "Test Epoch: 67 | Loss: 0.255 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 67 | Loss: 0.361 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 67 | Loss: 0.341 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 67 | Loss: 0.341 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 67 | Loss: 0.329 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 67 | Loss: 0.311 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 67 | Loss: 0.308 | Acc: 89.571% (627/700)\n",
      "Test Epoch: 67 | Loss: 0.320 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 67 | Loss: 0.345 | Acc: 88.778% (799/900)\n",
      "Test Epoch: 67 | Loss: 0.349 | Acc: 88.500% (885/1000)\n",
      "Test Epoch: 67 | Loss: 0.360 | Acc: 88.636% (975/1100)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.167% (1058/1200)\n",
      "Test Epoch: 67 | Loss: 0.351 | Acc: 88.462% (1150/1300)\n",
      "Test Epoch: 67 | Loss: 0.348 | Acc: 88.500% (1239/1400)\n",
      "Test Epoch: 67 | Loss: 0.359 | Acc: 87.933% (1319/1500)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 87.938% (1407/1600)\n",
      "Test Epoch: 67 | Loss: 0.370 | Acc: 88.000% (1496/1700)\n",
      "Test Epoch: 67 | Loss: 0.371 | Acc: 88.000% (1584/1800)\n",
      "Test Epoch: 67 | Loss: 0.369 | Acc: 88.158% (1675/1900)\n",
      "Test Epoch: 67 | Loss: 0.368 | Acc: 88.400% (1768/2000)\n",
      "Test Epoch: 67 | Loss: 0.372 | Acc: 88.190% (1852/2100)\n",
      "Test Epoch: 67 | Loss: 0.377 | Acc: 87.909% (1934/2200)\n",
      "Test Epoch: 67 | Loss: 0.377 | Acc: 87.826% (2020/2300)\n",
      "Test Epoch: 67 | Loss: 0.373 | Acc: 87.958% (2111/2400)\n",
      "Test Epoch: 67 | Loss: 0.382 | Acc: 87.800% (2195/2500)\n",
      "Test Epoch: 67 | Loss: 0.387 | Acc: 87.654% (2279/2600)\n",
      "Test Epoch: 67 | Loss: 0.384 | Acc: 87.667% (2367/2700)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 87.571% (2452/2800)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 87.586% (2540/2900)\n",
      "Test Epoch: 67 | Loss: 0.386 | Acc: 87.600% (2628/3000)\n",
      "Test Epoch: 67 | Loss: 0.387 | Acc: 87.419% (2710/3100)\n",
      "Test Epoch: 67 | Loss: 0.383 | Acc: 87.438% (2798/3200)\n",
      "Test Epoch: 67 | Loss: 0.384 | Acc: 87.515% (2888/3300)\n",
      "Test Epoch: 67 | Loss: 0.387 | Acc: 87.529% (2976/3400)\n",
      "Test Epoch: 67 | Loss: 0.389 | Acc: 87.543% (3064/3500)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 87.528% (3151/3600)\n",
      "Test Epoch: 67 | Loss: 0.391 | Acc: 87.541% (3239/3700)\n",
      "Test Epoch: 67 | Loss: 0.391 | Acc: 87.632% (3330/3800)\n",
      "Test Epoch: 67 | Loss: 0.387 | Acc: 87.667% (3419/3900)\n",
      "Test Epoch: 67 | Loss: 0.387 | Acc: 87.675% (3507/4000)\n",
      "Test Epoch: 67 | Loss: 0.388 | Acc: 87.659% (3594/4100)\n",
      "Test Epoch: 67 | Loss: 0.386 | Acc: 87.667% (3682/4200)\n",
      "Test Epoch: 67 | Loss: 0.382 | Acc: 87.767% (3774/4300)\n",
      "Test Epoch: 67 | Loss: 0.379 | Acc: 87.909% (3868/4400)\n",
      "Test Epoch: 67 | Loss: 0.379 | Acc: 87.956% (3958/4500)\n",
      "Test Epoch: 67 | Loss: 0.378 | Acc: 87.935% (4045/4600)\n",
      "Test Epoch: 67 | Loss: 0.376 | Acc: 87.957% (4134/4700)\n",
      "Test Epoch: 67 | Loss: 0.379 | Acc: 87.833% (4216/4800)\n",
      "Test Epoch: 67 | Loss: 0.377 | Acc: 87.898% (4307/4900)\n",
      "Test Epoch: 67 | Loss: 0.381 | Acc: 87.840% (4392/5000)\n",
      "Test Epoch: 67 | Loss: 0.378 | Acc: 87.922% (4484/5100)\n",
      "Test Epoch: 67 | Loss: 0.378 | Acc: 87.962% (4574/5200)\n",
      "Test Epoch: 67 | Loss: 0.379 | Acc: 87.887% (4658/5300)\n",
      "Test Epoch: 67 | Loss: 0.376 | Acc: 87.944% (4749/5400)\n",
      "Test Epoch: 67 | Loss: 0.376 | Acc: 87.855% (4832/5500)\n",
      "Test Epoch: 67 | Loss: 0.378 | Acc: 87.821% (4918/5600)\n",
      "Test Epoch: 67 | Loss: 0.376 | Acc: 87.807% (5005/5700)\n",
      "Test Epoch: 67 | Loss: 0.375 | Acc: 87.879% (5097/5800)\n",
      "Test Epoch: 67 | Loss: 0.377 | Acc: 87.797% (5180/5900)\n",
      "Test Epoch: 67 | Loss: 0.374 | Acc: 87.867% (5272/6000)\n",
      "Test Epoch: 67 | Loss: 0.374 | Acc: 87.869% (5360/6100)\n",
      "Test Epoch: 67 | Loss: 0.373 | Acc: 87.887% (5449/6200)\n",
      "Test Epoch: 67 | Loss: 0.371 | Acc: 87.952% (5541/6300)\n",
      "Test Epoch: 67 | Loss: 0.369 | Acc: 88.016% (5633/6400)\n",
      "Test Epoch: 67 | Loss: 0.370 | Acc: 87.954% (5717/6500)\n",
      "Test Epoch: 67 | Loss: 0.367 | Acc: 88.030% (5810/6600)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.119% (5904/6700)\n",
      "Test Epoch: 67 | Loss: 0.367 | Acc: 88.015% (5985/6800)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.043% (6075/6900)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.043% (6163/7000)\n",
      "Test Epoch: 67 | Loss: 0.366 | Acc: 88.028% (6250/7100)\n",
      "Test Epoch: 67 | Loss: 0.367 | Acc: 87.958% (6333/7200)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.014% (6425/7300)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.068% (6517/7400)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.080% (6606/7500)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.118% (6697/7600)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.065% (6781/7700)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.051% (6868/7800)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.101% (6960/7900)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.150% (7052/8000)\n",
      "Test Epoch: 67 | Loss: 0.361 | Acc: 88.222% (7146/8100)\n",
      "Test Epoch: 67 | Loss: 0.360 | Acc: 88.268% (7238/8200)\n",
      "Test Epoch: 67 | Loss: 0.360 | Acc: 88.241% (7324/8300)\n",
      "Test Epoch: 67 | Loss: 0.360 | Acc: 88.238% (7412/8400)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.176% (7495/8500)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.116% (7578/8600)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.126% (7667/8700)\n",
      "Test Epoch: 67 | Loss: 0.366 | Acc: 88.091% (7752/8800)\n",
      "Test Epoch: 67 | Loss: 0.367 | Acc: 88.067% (7838/8900)\n",
      "Test Epoch: 67 | Loss: 0.367 | Acc: 88.078% (7927/9000)\n",
      "Test Epoch: 67 | Loss: 0.366 | Acc: 88.077% (8015/9100)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.109% (8106/9200)\n",
      "Test Epoch: 67 | Loss: 0.365 | Acc: 88.065% (8190/9300)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.128% (8284/9400)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.095% (8369/9500)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.104% (8458/9600)\n",
      "Test Epoch: 67 | Loss: 0.362 | Acc: 88.155% (8551/9700)\n",
      "Test Epoch: 67 | Loss: 0.361 | Acc: 88.194% (8643/9800)\n",
      "Test Epoch: 67 | Loss: 0.363 | Acc: 88.111% (8723/9900)\n",
      "Test Epoch: 67 | Loss: 0.364 | Acc: 88.090% (8809/10000)\n",
      "\n",
      "Epoch: 68\n",
      "Train Epoch: 68 | Loss: 0.270 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 68 | Loss: 0.226 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 68 | Loss: 0.215 | Acc: 92.969% (357/384)\n",
      "Train Epoch: 68 | Loss: 0.214 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 68 | Loss: 0.232 | Acc: 91.875% (588/640)\n",
      "Train Epoch: 68 | Loss: 0.225 | Acc: 92.057% (707/768)\n",
      "Train Epoch: 68 | Loss: 0.236 | Acc: 91.629% (821/896)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.504% (937/1024)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.580% (1055/1152)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.641% (1173/1280)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.690% (1291/1408)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.732% (1409/1536)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.827% (1528/1664)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.685% (1643/1792)\n",
      "Train Epoch: 68 | Loss: 0.232 | Acc: 92.188% (1770/1920)\n",
      "Train Epoch: 68 | Loss: 0.233 | Acc: 91.943% (1883/2048)\n",
      "Train Epoch: 68 | Loss: 0.234 | Acc: 91.820% (1998/2176)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.667% (2112/2304)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.612% (2228/2432)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.680% (2347/2560)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 92.001% (2473/2688)\n",
      "Train Epoch: 68 | Loss: 0.235 | Acc: 92.152% (2595/2816)\n",
      "Train Epoch: 68 | Loss: 0.237 | Acc: 92.086% (2711/2944)\n",
      "Train Epoch: 68 | Loss: 0.235 | Acc: 92.188% (2832/3072)\n",
      "Train Epoch: 68 | Loss: 0.235 | Acc: 92.094% (2947/3200)\n",
      "Train Epoch: 68 | Loss: 0.232 | Acc: 92.157% (3067/3328)\n",
      "Train Epoch: 68 | Loss: 0.233 | Acc: 92.159% (3185/3456)\n",
      "Train Epoch: 68 | Loss: 0.234 | Acc: 92.048% (3299/3584)\n",
      "Train Epoch: 68 | Loss: 0.237 | Acc: 91.918% (3412/3712)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.719% (3522/3840)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.633% (3636/3968)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.772% (3759/4096)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.690% (3873/4224)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.659% (3989/4352)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.808% (4113/4480)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.927% (4236/4608)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.871% (4351/4736)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.859% (4468/4864)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.927% (4589/4992)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.816% (4701/5120)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.921% (4824/5248)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.871% (4939/5376)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.860% (5056/5504)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.903% (5176/5632)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.927% (5295/5760)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.882% (5410/5888)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.838% (5525/6016)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.911% (5647/6144)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.885% (5763/6272)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.906% (5882/6400)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.866% (5997/6528)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.917% (6118/6656)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.878% (6233/6784)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.927% (6354/6912)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.946% (6473/7040)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.922% (6589/7168)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.872% (6703/7296)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.851% (6819/7424)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.856% (6937/7552)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.836% (7053/7680)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.778% (7166/7808)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.797% (7285/7936)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.778% (7401/8064)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.809% (7521/8192)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.851% (7642/8320)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.844% (7759/8448)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.884% (7880/8576)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.831% (7993/8704)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.870% (8114/8832)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.886% (8233/8960)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.802% (8343/9088)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.743% (8455/9216)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.824% (8580/9344)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.881% (8703/9472)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.833% (8816/9600)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.848% (8935/9728)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.832% (9051/9856)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.837% (9169/9984)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.812% (9284/10112)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.797% (9400/10240)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.831% (9521/10368)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.797% (9635/10496)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.802% (9753/10624)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.834% (9874/10752)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.875% (9996/10880)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.870% (10113/11008)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.873% (10231/11136)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.841% (10345/11264)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.871% (10466/11392)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.901% (10587/11520)\n",
      "Train Epoch: 68 | Loss: 0.238 | Acc: 91.913% (10706/11648)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.899% (10822/11776)\n",
      "Train Epoch: 68 | Loss: 0.239 | Acc: 91.868% (10936/11904)\n",
      "Train Epoch: 68 | Loss: 0.240 | Acc: 91.830% (11049/12032)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.785% (11161/12160)\n",
      "Train Epoch: 68 | Loss: 0.241 | Acc: 91.748% (11274/12288)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.672% (11382/12416)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.645% (11496/12544)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.619% (11610/12672)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.625% (11728/12800)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.631% (11846/12928)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.613% (11961/13056)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.588% (12075/13184)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.624% (12197/13312)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.607% (12312/13440)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.642% (12434/13568)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.654% (12553/13696)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.652% (12670/13824)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.600% (12780/13952)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.591% (12896/14080)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.603% (13015/14208)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.622% (13135/14336)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.641% (13255/14464)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.674% (13377/14592)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.637% (13489/14720)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.669% (13611/14848)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.653% (13726/14976)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.651% (13843/15104)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.656% (13961/15232)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.667% (14080/15360)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.645% (14194/15488)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.656% (14313/15616)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.654% (14430/15744)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.602% (14539/15872)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.619% (14659/16000)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.592% (14772/16128)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.597% (14890/16256)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.614% (15010/16384)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.624% (15129/16512)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.635% (15248/16640)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.609% (15361/16768)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.607% (15478/16896)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.618% (15597/17024)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.645% (15719/17152)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.649% (15837/17280)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.653% (15955/17408)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.663% (16074/17536)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.633% (16186/17664)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.659% (16308/17792)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.669% (16427/17920)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.661% (16543/18048)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.692% (16666/18176)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.674% (16780/18304)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.661% (16895/18432)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.616% (17004/18560)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.615% (17121/18688)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.619% (17239/18816)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.596% (17352/18944)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.590% (17468/19072)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.568% (17581/19200)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.577% (17700/19328)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.607% (17823/19456)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.621% (17943/19584)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.614% (18059/19712)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.593% (18172/19840)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.582% (18287/19968)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.585% (18405/20096)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.609% (18527/20224)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.588% (18640/20352)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.602% (18760/20480)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.605% (18878/20608)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.590% (18992/20736)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.564% (19104/20864)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.563% (19221/20992)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.553% (19336/21120)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.566% (19456/21248)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.556% (19571/21376)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.546% (19686/21504)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.559% (19806/21632)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.535% (19918/21760)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.543% (20037/21888)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.533% (20152/22016)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.515% (20265/22144)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.527% (20385/22272)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.536% (20504/22400)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.548% (20624/22528)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.565% (20745/22656)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.569% (20863/22784)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.576% (20982/22912)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.589% (21102/23040)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.605% (21223/23168)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.599% (21339/23296)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.598% (21456/23424)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.602% (21574/23552)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.605% (21692/23680)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.604% (21809/23808)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.611% (21928/23936)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.602% (22043/24064)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.601% (22160/24192)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.604% (22278/24320)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.623% (22400/24448)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.630% (22519/24576)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.653% (22642/24704)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.668% (22763/24832)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.683% (22884/24960)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.685% (23002/25088)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.676% (23117/25216)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.659% (23230/25344)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.658% (23347/25472)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.668% (23467/25600)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.674% (23586/25728)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.673% (23703/25856)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.679% (23822/25984)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.678% (23939/26112)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.662% (24052/26240)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.649% (24166/26368)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.655% (24285/26496)\n",
      "Train Epoch: 68 | Loss: 0.242 | Acc: 91.669% (24406/26624)\n",
      "Train Epoch: 68 | Loss: 0.243 | Acc: 91.638% (24515/26752)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.629% (24630/26880)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.617% (24744/27008)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.602% (24857/27136)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.593% (24972/27264)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.603% (25092/27392)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.595% (25207/27520)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.594% (25324/27648)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.590% (25440/27776)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.600% (25560/27904)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.595% (25676/28032)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.594% (25793/28160)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.590% (25909/28288)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.572% (26021/28416)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.571% (26138/28544)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.567% (26254/28672)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.569% (26372/28800)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.572% (26490/28928)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.585% (26611/29056)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.571% (26724/29184)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.560% (26838/29312)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.559% (26955/29440)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.555% (27071/29568)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.565% (27191/29696)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.537% (27300/29824)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.533% (27416/29952)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.526% (27531/30080)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.506% (27642/30208)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.502% (27758/30336)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.501% (27875/30464)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.491% (27989/30592)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.494% (28107/30720)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.510% (28229/30848)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.506% (28345/30976)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.512% (28464/31104)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.509% (28580/31232)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.521% (28701/31360)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.505% (28813/31488)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.501% (28929/31616)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.513% (29050/31744)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.491% (29160/31872)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.500% (29280/32000)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.493% (29395/32128)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.512% (29518/32256)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.511% (29635/32384)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.511% (29752/32512)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.510% (29869/32640)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.501% (29983/32768)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.504% (30101/32896)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.512% (30221/33024)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.524% (30342/33152)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.523% (30459/33280)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.520% (30575/33408)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.523% (30693/33536)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.531% (30813/33664)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.539% (30933/33792)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.542% (31051/33920)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.541% (31168/34048)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.544% (31286/34176)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.549% (31405/34304)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.546% (31521/34432)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.528% (31632/34560)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.527% (31749/34688)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.524% (31865/34816)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.518% (31980/34944)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.520% (32098/35072)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.514% (32213/35200)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.525% (32334/35328)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.542% (32457/35456)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.544% (32575/35584)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.546% (32693/35712)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.543% (32809/35840)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.537% (32924/35968)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.539% (33042/36096)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.536% (33158/36224)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.527% (33272/36352)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.524% (33388/36480)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.540% (33511/36608)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.537% (33627/36736)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.542% (33746/36864)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.547% (33865/36992)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.557% (33986/37120)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.554% (34102/37248)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.559% (34221/37376)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.550% (34335/37504)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.544% (34450/37632)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.557% (34572/37760)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.551% (34687/37888)\n",
      "Train Epoch: 68 | Loss: 0.244 | Acc: 91.551% (34804/38016)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.540% (34917/38144)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.540% (35034/38272)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.542% (35152/38400)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.544% (35270/38528)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.546% (35388/38656)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.548% (35506/38784)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.542% (35621/38912)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.547% (35740/39040)\n",
      "Train Epoch: 68 | Loss: 0.245 | Acc: 91.536% (35853/39168)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.505% (35958/39296)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.510% (36077/39424)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.510% (36194/39552)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.494% (36305/39680)\n",
      "Train Epoch: 68 | Loss: 0.246 | Acc: 91.487% (36419/39808)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.476% (36532/39936)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.471% (36647/40064)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.461% (36760/40192)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.463% (36878/40320)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.446% (36988/40448)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.448% (37106/40576)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.458% (37227/40704)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.467% (37348/40832)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.470% (37466/40960)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.462% (37580/41088)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.455% (37694/41216)\n",
      "Train Epoch: 68 | Loss: 0.247 | Acc: 91.455% (37811/41344)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.445% (37924/41472)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.452% (38044/41600)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.435% (38154/41728)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.435% (38271/41856)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.428% (38385/41984)\n",
      "Train Epoch: 68 | Loss: 0.248 | Acc: 91.423% (38500/42112)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.416% (38614/42240)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.411% (38729/42368)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.418% (38849/42496)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.411% (38963/42624)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.399% (39075/42752)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.392% (39189/42880)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.399% (39309/43008)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.388% (39421/43136)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.402% (39544/43264)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.399% (39660/43392)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.402% (39778/43520)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.395% (39892/43648)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.388% (40006/43776)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.390% (40124/43904)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.395% (40243/44032)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.368% (40348/44160)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.368% (40465/44288)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.377% (40586/44416)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.388% (40708/44544)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.384% (40823/44672)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.384% (40940/44800)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.388% (41059/44928)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.380% (41172/45056)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.384% (41291/45184)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.384% (41408/45312)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.386% (41526/45440)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.393% (41646/45568)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.391% (41762/45696)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.391% (41879/45824)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.380% (41991/45952)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.378% (42107/46080)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.389% (42229/46208)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.387% (42345/46336)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.391% (42464/46464)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.380% (42576/46592)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.381% (42693/46720)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.387% (42813/46848)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.393% (42933/46976)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.391% (43049/47104)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.400% (43170/47232)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.394% (43284/47360)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.404% (43406/47488)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.396% (43519/47616)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.396% (43636/47744)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.394% (43752/47872)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.381% (43863/48000)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.383% (43981/48128)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.381% (44097/48256)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.375% (44211/48384)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.373% (44327/48512)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.373% (44444/48640)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.373% (44561/48768)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.380% (44681/48896)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.392% (44804/49024)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.396% (44923/49152)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.380% (45032/49280)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.372% (45145/49408)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.374% (45263/49536)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.378% (45382/49664)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.374% (45497/49792)\n",
      "Train Epoch: 68 | Loss: 0.249 | Acc: 91.366% (45610/49920)\n",
      "Train Epoch: 68 | Loss: 0.250 | Acc: 91.360% (45680/50000)\n",
      "Test Epoch: 68 | Loss: 0.403 | Acc: 84.000% (84/100)\n",
      "Test Epoch: 68 | Loss: 0.358 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 68 | Loss: 0.371 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 68 | Loss: 0.340 | Acc: 87.500% (350/400)\n",
      "Test Epoch: 68 | Loss: 0.316 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 68 | Loss: 0.299 | Acc: 89.667% (538/600)\n",
      "Test Epoch: 68 | Loss: 0.304 | Acc: 90.000% (630/700)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.111% (802/900)\n",
      "Test Epoch: 68 | Loss: 0.339 | Acc: 88.900% (889/1000)\n",
      "Test Epoch: 68 | Loss: 0.342 | Acc: 88.818% (977/1100)\n",
      "Test Epoch: 68 | Loss: 0.349 | Acc: 88.833% (1066/1200)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 88.923% (1156/1300)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.143% (1248/1400)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.133% (1337/1500)\n",
      "Test Epoch: 68 | Loss: 0.327 | Acc: 89.312% (1429/1600)\n",
      "Test Epoch: 68 | Loss: 0.327 | Acc: 89.294% (1518/1700)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.056% (1603/1800)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.105% (1693/1900)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.050% (1781/2000)\n",
      "Test Epoch: 68 | Loss: 0.337 | Acc: 88.952% (1868/2100)\n",
      "Test Epoch: 68 | Loss: 0.329 | Acc: 89.227% (1963/2200)\n",
      "Test Epoch: 68 | Loss: 0.338 | Acc: 89.043% (2048/2300)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.160% (2229/2500)\n",
      "Test Epoch: 68 | Loss: 0.345 | Acc: 88.962% (2313/2600)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.074% (2405/2700)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 88.964% (2491/2800)\n",
      "Test Epoch: 68 | Loss: 0.347 | Acc: 88.931% (2579/2900)\n",
      "Test Epoch: 68 | Loss: 0.347 | Acc: 88.933% (2668/3000)\n",
      "Test Epoch: 68 | Loss: 0.350 | Acc: 88.871% (2755/3100)\n",
      "Test Epoch: 68 | Loss: 0.347 | Acc: 88.969% (2847/3200)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 89.030% (2938/3300)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.147% (3031/3400)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.114% (3119/3500)\n",
      "Test Epoch: 68 | Loss: 0.343 | Acc: 89.056% (3206/3600)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 88.946% (3291/3700)\n",
      "Test Epoch: 68 | Loss: 0.345 | Acc: 88.868% (3377/3800)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 88.974% (3470/3900)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 88.950% (3558/4000)\n",
      "Test Epoch: 68 | Loss: 0.346 | Acc: 88.951% (3647/4100)\n",
      "Test Epoch: 68 | Loss: 0.345 | Acc: 88.976% (3737/4200)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 89.047% (3829/4300)\n",
      "Test Epoch: 68 | Loss: 0.342 | Acc: 89.159% (3923/4400)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.156% (4012/4500)\n",
      "Test Epoch: 68 | Loss: 0.344 | Acc: 89.043% (4096/4600)\n",
      "Test Epoch: 68 | Loss: 0.342 | Acc: 89.149% (4190/4700)\n",
      "Test Epoch: 68 | Loss: 0.346 | Acc: 89.042% (4274/4800)\n",
      "Test Epoch: 68 | Loss: 0.343 | Acc: 89.122% (4367/4900)\n",
      "Test Epoch: 68 | Loss: 0.342 | Acc: 89.140% (4457/5000)\n",
      "Test Epoch: 68 | Loss: 0.339 | Acc: 89.275% (4553/5100)\n",
      "Test Epoch: 68 | Loss: 0.340 | Acc: 89.231% (4640/5200)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.170% (4726/5300)\n",
      "Test Epoch: 68 | Loss: 0.338 | Acc: 89.315% (4823/5400)\n",
      "Test Epoch: 68 | Loss: 0.339 | Acc: 89.327% (4913/5500)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.250% (4998/5600)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.246% (5087/5700)\n",
      "Test Epoch: 68 | Loss: 0.338 | Acc: 89.310% (5180/5800)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.186% (5262/5900)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.150% (5349/6000)\n",
      "Test Epoch: 68 | Loss: 0.341 | Acc: 89.131% (5437/6100)\n",
      "Test Epoch: 68 | Loss: 0.340 | Acc: 89.161% (5528/6200)\n",
      "Test Epoch: 68 | Loss: 0.339 | Acc: 89.175% (5618/6300)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.266% (5713/6400)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.323% (5806/6500)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.303% (5894/6600)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.373% (5988/6700)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.338% (6075/6800)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.319% (6163/6900)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.314% (6252/7000)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.282% (6339/7100)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.306% (6430/7200)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.356% (6523/7300)\n",
      "Test Epoch: 68 | Loss: 0.331 | Acc: 89.378% (6614/7400)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.387% (6704/7500)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.408% (6795/7600)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.390% (6883/7700)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.385% (6972/7800)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.354% (7059/7900)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.350% (7148/8000)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.383% (7240/8100)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.415% (7332/8200)\n",
      "Test Epoch: 68 | Loss: 0.332 | Acc: 89.410% (7421/8300)\n",
      "Test Epoch: 68 | Loss: 0.331 | Acc: 89.452% (7514/8400)\n",
      "Test Epoch: 68 | Loss: 0.331 | Acc: 89.412% (7600/8500)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.314% (7681/8600)\n",
      "Test Epoch: 68 | Loss: 0.333 | Acc: 89.299% (7769/8700)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.284% (7857/8800)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.202% (7939/8900)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.178% (8026/9000)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.187% (8116/9100)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.217% (8208/9200)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.226% (8298/9300)\n",
      "Test Epoch: 68 | Loss: 0.335 | Acc: 89.255% (8390/9400)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.253% (8479/9500)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.260% (8569/9600)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.309% (8663/9700)\n",
      "Test Epoch: 68 | Loss: 0.334 | Acc: 89.286% (8750/9800)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.232% (8834/9900)\n",
      "Test Epoch: 68 | Loss: 0.336 | Acc: 89.230% (8923/10000)\n",
      "\n",
      "Epoch: 69\n",
      "Train Epoch: 69 | Loss: 0.217 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.406% (234/256)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.927% (353/384)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 69 | Loss: 0.227 | Acc: 92.500% (592/640)\n",
      "Train Epoch: 69 | Loss: 0.215 | Acc: 92.578% (711/768)\n",
      "Train Epoch: 69 | Loss: 0.217 | Acc: 92.522% (829/896)\n",
      "Train Epoch: 69 | Loss: 0.216 | Acc: 92.773% (950/1024)\n",
      "Train Epoch: 69 | Loss: 0.220 | Acc: 92.535% (1066/1152)\n",
      "Train Epoch: 69 | Loss: 0.217 | Acc: 92.734% (1187/1280)\n",
      "Train Epoch: 69 | Loss: 0.213 | Acc: 93.040% (1310/1408)\n",
      "Train Epoch: 69 | Loss: 0.214 | Acc: 92.969% (1428/1536)\n",
      "Train Epoch: 69 | Loss: 0.215 | Acc: 92.849% (1545/1664)\n",
      "Train Epoch: 69 | Loss: 0.219 | Acc: 92.746% (1662/1792)\n",
      "Train Epoch: 69 | Loss: 0.220 | Acc: 92.604% (1778/1920)\n",
      "Train Epoch: 69 | Loss: 0.222 | Acc: 92.529% (1895/2048)\n",
      "Train Epoch: 69 | Loss: 0.222 | Acc: 92.463% (2012/2176)\n",
      "Train Epoch: 69 | Loss: 0.219 | Acc: 92.535% (2132/2304)\n",
      "Train Epoch: 69 | Loss: 0.220 | Acc: 92.516% (2250/2432)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.461% (2367/2560)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.448% (2485/2688)\n",
      "Train Epoch: 69 | Loss: 0.221 | Acc: 92.472% (2604/2816)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.323% (2718/2944)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.155% (2831/3072)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.250% (2952/3200)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.127% (3066/3328)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.159% (3185/3456)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.271% (3307/3584)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.241% (3424/3712)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.161% (3539/3840)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.162% (3657/3968)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.139% (3774/4096)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.164% (3893/4224)\n",
      "Train Epoch: 69 | Loss: 0.222 | Acc: 92.210% (4013/4352)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.210% (4131/4480)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.209% (4249/4608)\n",
      "Train Epoch: 69 | Loss: 0.222 | Acc: 92.314% (4372/4736)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.352% (4492/4864)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.288% (4607/4992)\n",
      "Train Epoch: 69 | Loss: 0.223 | Acc: 92.305% (4726/5120)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.264% (4842/5248)\n",
      "Train Epoch: 69 | Loss: 0.224 | Acc: 92.225% (4958/5376)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.206% (5075/5504)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.152% (5190/5632)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.153% (5308/5760)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.137% (5425/5888)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.154% (5544/6016)\n",
      "Train Epoch: 69 | Loss: 0.227 | Acc: 92.074% (5657/6144)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.044% (5773/6272)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.016% (5889/6400)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.034% (6008/6528)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.112% (6131/6656)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.114% (6249/6784)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.086% (6365/6912)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.060% (6481/7040)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.062% (6599/7168)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.105% (6720/7296)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.134% (6840/7424)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.201% (6963/7552)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.174% (7079/7680)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.175% (7197/7808)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.213% (7318/7936)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.212% (7436/8064)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.297% (7561/8192)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.308% (7680/8320)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.306% (7798/8448)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.339% (7919/8576)\n",
      "Train Epoch: 69 | Loss: 0.225 | Acc: 92.325% (8036/8704)\n",
      "Train Epoch: 69 | Loss: 0.227 | Acc: 92.210% (8144/8832)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.188% (8260/8960)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.199% (8379/9088)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.198% (8497/9216)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.177% (8613/9344)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.198% (8733/9472)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.208% (8852/9600)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.177% (8967/9728)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.218% (9089/9856)\n",
      "Train Epoch: 69 | Loss: 0.227 | Acc: 92.248% (9210/9984)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.296% (9333/10112)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.295% (9451/10240)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.294% (9569/10368)\n",
      "Train Epoch: 69 | Loss: 0.226 | Acc: 92.273% (9685/10496)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.235% (9799/10624)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.178% (9911/10752)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.206% (10032/10880)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.224% (10152/11008)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.250% (10273/11136)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.214% (10387/11264)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.188% (10502/11392)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.231% (10625/11520)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.256% (10746/11648)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.238% (10862/11776)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.255% (10982/11904)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.237% (11098/12032)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.237% (11216/12160)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.253% (11336/12288)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.244% (11453/12416)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.180% (11563/12544)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.203% (11684/12672)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.211% (11803/12800)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.172% (11916/12928)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.149% (12031/13056)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.142% (12148/13184)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.120% (12263/13312)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.135% (12383/13440)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.129% (12500/13568)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.107% (12615/13696)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.115% (12734/13824)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.130% (12854/13952)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.102% (12968/14080)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.103% (13086/14208)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.104% (13204/14336)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.111% (13323/14464)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.126% (13443/14592)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.160% (13566/14720)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.147% (13682/14848)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.121% (13796/14976)\n",
      "Train Epoch: 69 | Loss: 0.228 | Acc: 92.154% (13919/15104)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.135% (14034/15232)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.116% (14149/15360)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.110% (14266/15488)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.111% (14384/15616)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.092% (14499/15744)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.087% (14616/15872)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.075% (14732/16000)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.088% (14852/16128)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.108% (14973/16256)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.102% (15090/16384)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.091% (15206/16512)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.037% (15315/16640)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.056% (15436/16768)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.057% (15554/16896)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.052% (15671/17024)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.036% (15786/17152)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.025% (15902/17280)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.032% (16021/17408)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.039% (16140/17536)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.046% (16259/17664)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.030% (16374/17792)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.009% (16488/17920)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.010% (16606/18048)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.044% (16730/18176)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.051% (16849/18304)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.025% (16962/18432)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.020% (17079/18560)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.011% (17195/18688)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.028% (17316/18816)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.013% (17431/18944)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 91.993% (17545/19072)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.953% (17655/19200)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.970% (17776/19328)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.987% (17897/19456)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.983% (18014/19584)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.000% (18135/19712)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.986% (18250/19840)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.987% (18368/19968)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.993% (18487/20096)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.009% (18608/20224)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.011% (18726/20352)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.036% (18849/20480)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.027% (18965/20608)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.014% (19080/20736)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.005% (19196/20864)\n",
      "Train Epoch: 69 | Loss: 0.229 | Acc: 92.035% (19320/20992)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.022% (19435/21120)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.023% (19553/21248)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.010% (19668/21376)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.006% (19785/21504)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.007% (19903/21632)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.999% (20019/21760)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 92.018% (20141/21888)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.992% (20253/22016)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.993% (20371/22144)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.981% (20486/22272)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.978% (20603/22400)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.957% (20716/22528)\n",
      "Train Epoch: 69 | Loss: 0.230 | Acc: 91.971% (20837/22656)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.959% (20952/22784)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.974% (21073/22912)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.984% (21193/23040)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.972% (21308/23168)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.977% (21427/23296)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.974% (21544/23424)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.992% (21666/23552)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.964% (21777/23680)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.973% (21897/23808)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.983% (22017/23936)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.984% (22135/24064)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.968% (22249/24192)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.953% (22363/24320)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.963% (22483/24448)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.972% (22603/24576)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.977% (22722/24704)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.978% (22840/24832)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.979% (22958/24960)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.956% (23070/25088)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.965% (23190/25216)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.974% (23310/25344)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.968% (23426/25472)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.977% (23546/25600)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.997% (23669/25728)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.998% (23787/25856)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.987% (23902/25984)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.992% (24021/26112)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.012% (24144/26240)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.005% (24260/26368)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 91.999% (24376/26496)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.992% (24492/26624)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.004% (24613/26752)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.016% (24734/26880)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.010% (24850/27008)\n",
      "Train Epoch: 69 | Loss: 0.231 | Acc: 92.007% (24967/27136)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.997% (25082/27264)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 92.001% (25201/27392)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.988% (25315/27520)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.974% (25429/27648)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.953% (25541/27776)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.962% (25661/27904)\n",
      "Train Epoch: 69 | Loss: 0.232 | Acc: 91.970% (25781/28032)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.960% (25896/28160)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.944% (26009/28288)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.934% (26124/28416)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.939% (26243/28544)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.940% (26361/28672)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.948% (26481/28800)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.942% (26597/28928)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.943% (26715/29056)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.941% (26832/29184)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.949% (26952/29312)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.953% (27071/29440)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.954% (27189/29568)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.955% (27307/29696)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.953% (27424/29824)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.957% (27543/29952)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.945% (27657/30080)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.952% (27777/30208)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.947% (27893/30336)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.941% (28009/30464)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.949% (28129/30592)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.943% (28245/30720)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.948% (28364/30848)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.955% (28484/30976)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.962% (28604/31104)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.957% (28720/31232)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.958% (28838/31360)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.965% (28958/31488)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.953% (29072/31616)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.954% (29190/31744)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.943% (29304/31872)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.941% (29421/32000)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.926% (29534/32128)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.924% (29651/32256)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.931% (29771/32384)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.935% (29890/32512)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.924% (30004/32640)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.931% (30124/32768)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.920% (30238/32896)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.930% (30359/33024)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.937% (30479/33152)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.920% (30591/33280)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.918% (30708/33408)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.922% (30827/33536)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.920% (30944/33664)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.921% (31062/33792)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.919% (31179/33920)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.938% (31303/34048)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.939% (31421/34176)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.940% (31539/34304)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.955% (31662/34432)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.962% (31782/34560)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.971% (31903/34688)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.978% (32023/34816)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.981% (32142/34944)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.982% (32260/35072)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.972% (32374/35200)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.967% (32490/35328)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.962% (32606/35456)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.949% (32719/35584)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.938% (32833/35712)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.920% (32944/35840)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.923% (33063/35968)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.930% (33183/36096)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.939% (33304/36224)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.951% (33426/36352)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.941% (33540/36480)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.944% (33659/36608)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.940% (33775/36736)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.941% (33893/36864)\n",
      "Train Epoch: 69 | Loss: 0.233 | Acc: 91.952% (34015/36992)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.937% (34127/37120)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.932% (34243/37248)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.931% (34360/37376)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.934% (34479/37504)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.927% (34594/37632)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.925% (34711/37760)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.924% (34828/37888)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.922% (34945/38016)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.923% (35063/38144)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.926% (35182/38272)\n",
      "Train Epoch: 69 | Loss: 0.234 | Acc: 91.924% (35299/38400)\n",
      "Train Epoch: 69 | Loss: 0.235 | Acc: 91.915% (35413/38528)\n",
      "Train Epoch: 69 | Loss: 0.235 | Acc: 91.900% (35525/38656)\n",
      "Train Epoch: 69 | Loss: 0.235 | Acc: 91.909% (35646/38784)\n",
      "Train Epoch: 69 | Loss: 0.235 | Acc: 91.902% (35761/38912)\n",
      "Train Epoch: 69 | Loss: 0.235 | Acc: 91.893% (35875/39040)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.881% (35988/39168)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.880% (36105/39296)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.873% (36220/39424)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.882% (36341/39552)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.875% (36456/39680)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.881% (36576/39808)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.882% (36694/39936)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.880% (36811/40064)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.874% (36926/40192)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.870% (37042/40320)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.878% (37163/40448)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.877% (37280/40576)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.875% (37397/40704)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.852% (37505/40832)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.843% (37619/40960)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.837% (37734/41088)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.833% (37850/41216)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.832% (37967/41344)\n",
      "Train Epoch: 69 | Loss: 0.236 | Acc: 91.833% (38085/41472)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.834% (38203/41600)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.830% (38319/41728)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.829% (38436/41856)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.830% (38554/41984)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.829% (38671/42112)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.842% (38794/42240)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.850% (38915/42368)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.846% (39031/42496)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.847% (39149/42624)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.827% (39258/42752)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.833% (39378/42880)\n",
      "Train Epoch: 69 | Loss: 0.237 | Acc: 91.839% (39498/43008)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.821% (39608/43136)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.825% (39727/43264)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.821% (39843/43392)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.818% (39959/43520)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.812% (40074/43648)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.815% (40193/43776)\n",
      "Train Epoch: 69 | Loss: 0.238 | Acc: 91.807% (40307/43904)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.795% (40419/44032)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.787% (40533/44160)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.772% (40644/44288)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.769% (40760/44416)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.765% (40876/44544)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.760% (40991/44672)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.759% (41108/44800)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.760% (41226/44928)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.759% (41343/45056)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.760% (41461/45184)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.757% (41577/45312)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.754% (41693/45440)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.744% (41806/45568)\n",
      "Train Epoch: 69 | Loss: 0.239 | Acc: 91.748% (41925/45696)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.738% (42038/45824)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.726% (42150/45952)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.725% (42267/46080)\n",
      "Train Epoch: 69 | Loss: 0.240 | Acc: 91.716% (42380/46208)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.706% (42493/46336)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.703% (42609/46464)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.700% (42725/46592)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.702% (42843/46720)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.703% (42961/46848)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.704% (43079/46976)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.701% (43195/47104)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.705% (43314/47232)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.710% (43434/47360)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.709% (43551/47488)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.700% (43664/47616)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.693% (43778/47744)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.682% (43890/47872)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.675% (44004/48000)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.678% (44123/48128)\n",
      "Train Epoch: 69 | Loss: 0.242 | Acc: 91.676% (44239/48256)\n",
      "Train Epoch: 69 | Loss: 0.242 | Acc: 91.681% (44359/48384)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.687% (44479/48512)\n",
      "Train Epoch: 69 | Loss: 0.242 | Acc: 91.680% (44593/48640)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.679% (44710/48768)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.680% (44828/48896)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.682% (44946/49024)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.685% (45065/49152)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.680% (45180/49280)\n",
      "Train Epoch: 69 | Loss: 0.242 | Acc: 91.677% (45296/49408)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.683% (45416/49536)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.684% (45534/49664)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.681% (45650/49792)\n",
      "Train Epoch: 69 | Loss: 0.242 | Acc: 91.679% (45766/49920)\n",
      "Train Epoch: 69 | Loss: 0.241 | Acc: 91.684% (45842/50000)\n",
      "Test Epoch: 69 | Loss: 0.314 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 69 | Loss: 0.346 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 69 | Loss: 0.374 | Acc: 86.333% (259/300)\n",
      "Test Epoch: 69 | Loss: 0.349 | Acc: 87.000% (348/400)\n",
      "Test Epoch: 69 | Loss: 0.326 | Acc: 87.800% (439/500)\n",
      "Test Epoch: 69 | Loss: 0.313 | Acc: 88.500% (531/600)\n",
      "Test Epoch: 69 | Loss: 0.319 | Acc: 88.429% (619/700)\n",
      "Test Epoch: 69 | Loss: 0.354 | Acc: 87.875% (703/800)\n",
      "Test Epoch: 69 | Loss: 0.377 | Acc: 87.444% (787/900)\n",
      "Test Epoch: 69 | Loss: 0.371 | Acc: 87.600% (876/1000)\n",
      "Test Epoch: 69 | Loss: 0.386 | Acc: 87.455% (962/1100)\n",
      "Test Epoch: 69 | Loss: 0.386 | Acc: 87.500% (1050/1200)\n",
      "Test Epoch: 69 | Loss: 0.389 | Acc: 87.308% (1135/1300)\n",
      "Test Epoch: 69 | Loss: 0.396 | Acc: 87.143% (1220/1400)\n",
      "Test Epoch: 69 | Loss: 0.398 | Acc: 87.200% (1308/1500)\n",
      "Test Epoch: 69 | Loss: 0.405 | Acc: 86.812% (1389/1600)\n",
      "Test Epoch: 69 | Loss: 0.403 | Acc: 86.824% (1476/1700)\n",
      "Test Epoch: 69 | Loss: 0.412 | Acc: 86.667% (1560/1800)\n",
      "Test Epoch: 69 | Loss: 0.414 | Acc: 86.684% (1647/1900)\n",
      "Test Epoch: 69 | Loss: 0.412 | Acc: 86.700% (1734/2000)\n",
      "Test Epoch: 69 | Loss: 0.414 | Acc: 86.714% (1821/2100)\n",
      "Test Epoch: 69 | Loss: 0.410 | Acc: 86.636% (1906/2200)\n",
      "Test Epoch: 69 | Loss: 0.414 | Acc: 86.522% (1990/2300)\n",
      "Test Epoch: 69 | Loss: 0.406 | Acc: 86.708% (2081/2400)\n",
      "Test Epoch: 69 | Loss: 0.414 | Acc: 86.760% (2169/2500)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 86.654% (2253/2600)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.741% (2342/2700)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 86.571% (2424/2800)\n",
      "Test Epoch: 69 | Loss: 0.425 | Acc: 86.621% (2512/2900)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.700% (2601/3000)\n",
      "Test Epoch: 69 | Loss: 0.429 | Acc: 86.548% (2683/3100)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.688% (2774/3200)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 86.606% (2858/3300)\n",
      "Test Epoch: 69 | Loss: 0.425 | Acc: 86.676% (2947/3400)\n",
      "Test Epoch: 69 | Loss: 0.430 | Acc: 86.514% (3028/3500)\n",
      "Test Epoch: 69 | Loss: 0.427 | Acc: 86.611% (3118/3600)\n",
      "Test Epoch: 69 | Loss: 0.429 | Acc: 86.676% (3207/3700)\n",
      "Test Epoch: 69 | Loss: 0.430 | Acc: 86.684% (3294/3800)\n",
      "Test Epoch: 69 | Loss: 0.428 | Acc: 86.744% (3383/3900)\n",
      "Test Epoch: 69 | Loss: 0.431 | Acc: 86.725% (3469/4000)\n",
      "Test Epoch: 69 | Loss: 0.432 | Acc: 86.707% (3555/4100)\n",
      "Test Epoch: 69 | Loss: 0.430 | Acc: 86.690% (3641/4200)\n",
      "Test Epoch: 69 | Loss: 0.427 | Acc: 86.791% (3732/4300)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 86.909% (3824/4400)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 87.000% (3915/4500)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 87.000% (4002/4600)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 87.064% (4092/4700)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 87.021% (4177/4800)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 87.122% (4269/4900)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 87.000% (4350/5000)\n",
      "Test Epoch: 69 | Loss: 0.422 | Acc: 87.000% (4437/5100)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.885% (4518/5200)\n",
      "Test Epoch: 69 | Loss: 0.426 | Acc: 86.830% (4602/5300)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.926% (4694/5400)\n",
      "Test Epoch: 69 | Loss: 0.425 | Acc: 86.909% (4780/5500)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.911% (4867/5600)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.912% (4954/5700)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.948% (5043/5800)\n",
      "Test Epoch: 69 | Loss: 0.423 | Acc: 86.847% (5124/5900)\n",
      "Test Epoch: 69 | Loss: 0.425 | Acc: 86.767% (5206/6000)\n",
      "Test Epoch: 69 | Loss: 0.427 | Acc: 86.770% (5293/6100)\n",
      "Test Epoch: 69 | Loss: 0.427 | Acc: 86.710% (5376/6200)\n",
      "Test Epoch: 69 | Loss: 0.424 | Acc: 86.794% (5468/6300)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.891% (5561/6400)\n",
      "Test Epoch: 69 | Loss: 0.422 | Acc: 86.846% (5645/6500)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.864% (5733/6600)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 86.925% (5824/6700)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 86.926% (5911/6800)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 86.957% (6000/6900)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 86.971% (6088/7000)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 87.000% (6177/7100)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.944% (6260/7200)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 87.000% (6351/7300)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 87.041% (6441/7400)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 87.000% (6525/7500)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 87.053% (6616/7600)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.987% (6698/7700)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.962% (6783/7800)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.987% (6872/7900)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 86.963% (6957/8000)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 87.062% (7052/8100)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 87.073% (7140/8200)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 87.012% (7222/8300)\n",
      "Test Epoch: 69 | Loss: 0.415 | Acc: 87.071% (7314/8400)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 86.988% (7394/8500)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 86.942% (7477/8600)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 86.943% (7564/8700)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.920% (7649/8800)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.910% (7735/8900)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 86.933% (7824/9000)\n",
      "Test Epoch: 69 | Loss: 0.421 | Acc: 86.945% (7912/9100)\n",
      "Test Epoch: 69 | Loss: 0.419 | Acc: 86.978% (8002/9200)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.978% (8089/9300)\n",
      "Test Epoch: 69 | Loss: 0.420 | Acc: 86.979% (8176/9400)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 87.000% (8265/9500)\n",
      "Test Epoch: 69 | Loss: 0.418 | Acc: 86.979% (8350/9600)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 87.031% (8442/9700)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 87.000% (8526/9800)\n",
      "Test Epoch: 69 | Loss: 0.416 | Acc: 87.040% (8617/9900)\n",
      "Test Epoch: 69 | Loss: 0.417 | Acc: 87.000% (8700/10000)\n",
      "\n",
      "Epoch: 70\n",
      "Train Epoch: 70 | Loss: 0.161 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 70 | Loss: 0.173 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 70 | Loss: 0.206 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 70 | Loss: 0.209 | Acc: 93.555% (479/512)\n",
      "Train Epoch: 70 | Loss: 0.212 | Acc: 93.125% (596/640)\n",
      "Train Epoch: 70 | Loss: 0.220 | Acc: 92.708% (712/768)\n",
      "Train Epoch: 70 | Loss: 0.220 | Acc: 92.411% (828/896)\n",
      "Train Epoch: 70 | Loss: 0.209 | Acc: 92.871% (951/1024)\n",
      "Train Epoch: 70 | Loss: 0.212 | Acc: 92.535% (1066/1152)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.266% (1181/1280)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.116% (1297/1408)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.057% (1414/1536)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.007% (1531/1664)\n",
      "Train Epoch: 70 | Loss: 0.218 | Acc: 92.188% (1652/1792)\n",
      "Train Epoch: 70 | Loss: 0.214 | Acc: 92.240% (1771/1920)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.090% (1886/2048)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.004% (2002/2176)\n",
      "Train Epoch: 70 | Loss: 0.221 | Acc: 92.057% (2121/2304)\n",
      "Train Epoch: 70 | Loss: 0.214 | Acc: 92.393% (2247/2432)\n",
      "Train Epoch: 70 | Loss: 0.213 | Acc: 92.500% (2368/2560)\n",
      "Train Epoch: 70 | Loss: 0.215 | Acc: 92.411% (2484/2688)\n",
      "Train Epoch: 70 | Loss: 0.213 | Acc: 92.401% (2602/2816)\n",
      "Train Epoch: 70 | Loss: 0.211 | Acc: 92.527% (2724/2944)\n",
      "Train Epoch: 70 | Loss: 0.214 | Acc: 92.415% (2839/3072)\n",
      "Train Epoch: 70 | Loss: 0.218 | Acc: 92.250% (2952/3200)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.398% (3075/3328)\n",
      "Train Epoch: 70 | Loss: 0.217 | Acc: 92.419% (3194/3456)\n",
      "Train Epoch: 70 | Loss: 0.218 | Acc: 92.327% (3309/3584)\n",
      "Train Epoch: 70 | Loss: 0.218 | Acc: 92.403% (3430/3712)\n",
      "Train Epoch: 70 | Loss: 0.214 | Acc: 92.526% (3553/3840)\n",
      "Train Epoch: 70 | Loss: 0.214 | Acc: 92.591% (3674/3968)\n",
      "Train Epoch: 70 | Loss: 0.217 | Acc: 92.480% (3788/4096)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.472% (3906/4224)\n",
      "Train Epoch: 70 | Loss: 0.215 | Acc: 92.555% (4028/4352)\n",
      "Train Epoch: 70 | Loss: 0.218 | Acc: 92.433% (4141/4480)\n",
      "Train Epoch: 70 | Loss: 0.220 | Acc: 92.448% (4260/4608)\n",
      "Train Epoch: 70 | Loss: 0.220 | Acc: 92.378% (4375/4736)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.455% (4497/4864)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.388% (4612/4992)\n",
      "Train Epoch: 70 | Loss: 0.221 | Acc: 92.285% (4725/5120)\n",
      "Train Epoch: 70 | Loss: 0.221 | Acc: 92.283% (4843/5248)\n",
      "Train Epoch: 70 | Loss: 0.221 | Acc: 92.299% (4962/5376)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.387% (5085/5504)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.418% (5205/5632)\n",
      "Train Epoch: 70 | Loss: 0.217 | Acc: 92.552% (5331/5760)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.544% (5449/5888)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.570% (5569/6016)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.562% (5687/6144)\n",
      "Train Epoch: 70 | Loss: 0.215 | Acc: 92.602% (5808/6272)\n",
      "Train Epoch: 70 | Loss: 0.213 | Acc: 92.656% (5930/6400)\n",
      "Train Epoch: 70 | Loss: 0.213 | Acc: 92.662% (6049/6528)\n",
      "Train Epoch: 70 | Loss: 0.215 | Acc: 92.608% (6164/6656)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.541% (6278/6784)\n",
      "Train Epoch: 70 | Loss: 0.216 | Acc: 92.506% (6394/6912)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.443% (6508/7040)\n",
      "Train Epoch: 70 | Loss: 0.219 | Acc: 92.425% (6625/7168)\n",
      "Train Epoch: 70 | Loss: 0.220 | Acc: 92.407% (6742/7296)\n",
      "Train Epoch: 70 | Loss: 0.221 | Acc: 92.349% (6856/7424)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.360% (6975/7552)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.305% (7089/7680)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.277% (7205/7808)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.263% (7322/7936)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.262% (7440/8064)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.285% (7560/8192)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.248% (7675/8320)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.259% (7794/8448)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.281% (7914/8576)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.291% (8033/8704)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.278% (8150/8832)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.299% (8270/8960)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.243% (8383/9088)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.253% (8502/9216)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.241% (8619/9344)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.251% (8738/9472)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.250% (8856/9600)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.239% (8973/9728)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.228% (9090/9856)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.218% (9207/9984)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.217% (9325/10112)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.168% (9438/10240)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.149% (9554/10368)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.168% (9674/10496)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.150% (9790/10624)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.169% (9910/10752)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.188% (10030/10880)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.197% (10149/11008)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.223% (10270/11136)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.170% (10382/11264)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.188% (10502/11392)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.179% (10619/11520)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.145% (10733/11648)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.111% (10847/11776)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.120% (10966/11904)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.146% (11087/12032)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.130% (11203/12160)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.147% (11323/12288)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.155% (11442/12416)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.188% (11564/12544)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.132% (11675/12672)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.156% (11796/12800)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.157% (11914/12928)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.157% (12032/13056)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.119% (12145/13184)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.112% (12262/13312)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.165% (12387/13440)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.180% (12507/13568)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.209% (12629/13696)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.188% (12744/13824)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.159% (12858/13952)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.173% (12978/14080)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.152% (13093/14208)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.167% (13213/14336)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.146% (13328/14464)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.133% (13444/14592)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.126% (13561/14720)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.120% (13678/14848)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.127% (13797/14976)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.095% (13910/15104)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.102% (14029/15232)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.129% (14151/15360)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.149% (14272/15488)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.136% (14388/15616)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.143% (14507/15744)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.162% (14628/15872)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.156% (14745/16000)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.150% (14862/16128)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.126% (14976/16256)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.139% (15096/16384)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.151% (15216/16512)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.169% (15337/16640)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.110% (15445/16768)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.099% (15561/16896)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.105% (15680/17024)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.123% (15801/17152)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.135% (15921/17280)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.147% (16041/17408)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.142% (16158/17536)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.154% (16278/17664)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.131% (16392/17792)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.148% (16513/17920)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.121% (16626/18048)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.154% (16750/18176)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.177% (16872/18304)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.166% (16988/18432)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.182% (17109/18560)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.161% (17223/18688)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.177% (17344/18816)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.172% (17461/18944)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.188% (17582/19072)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.198% (17702/19200)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.203% (17821/19328)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.182% (17935/19456)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.142% (18045/19584)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.122% (18159/19712)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.122% (18277/19840)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.132% (18397/19968)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.123% (18513/20096)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.138% (18634/20224)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.143% (18753/20352)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.148% (18872/20480)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.168% (18994/20608)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.173% (19113/20736)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.192% (19235/20864)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.183% (19351/20992)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.192% (19471/21120)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.188% (19588/21248)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.188% (19706/21376)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.188% (19824/21504)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.201% (19945/21632)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.201% (20063/21760)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.224% (20186/21888)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.210% (20301/22016)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.224% (20422/22144)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.232% (20542/22272)\n",
      "Train Epoch: 70 | Loss: 0.222 | Acc: 92.237% (20661/22400)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.227% (20777/22528)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.236% (20897/22656)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.227% (21013/22784)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.227% (21131/22912)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.218% (21247/23040)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.213% (21364/23168)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.209% (21481/23296)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.222% (21602/23424)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.230% (21722/23552)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.230% (21840/23680)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.230% (21958/23808)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.242% (22079/23936)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.237% (22196/24064)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.250% (22317/24192)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.249% (22435/24320)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.261% (22556/24448)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.244% (22670/24576)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.220% (22782/24704)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.220% (22900/24832)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.208% (23015/24960)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.219% (23136/25088)\n",
      "Train Epoch: 70 | Loss: 0.223 | Acc: 92.211% (23252/25216)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.195% (23366/25344)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.199% (23485/25472)\n",
      "Train Epoch: 70 | Loss: 0.224 | Acc: 92.176% (23597/25600)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.164% (23712/25728)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.168% (23831/25856)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.161% (23947/25984)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.168% (24067/26112)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.157% (24182/26240)\n",
      "Train Epoch: 70 | Loss: 0.225 | Acc: 92.161% (24301/26368)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.135% (24412/26496)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.120% (24526/26624)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.146% (24651/26752)\n",
      "Train Epoch: 70 | Loss: 0.226 | Acc: 92.135% (24766/26880)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.132% (24883/27008)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.129% (25000/27136)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.132% (25119/27264)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.122% (25234/27392)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.104% (25347/27520)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.112% (25467/27648)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.105% (25583/27776)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.080% (25694/27904)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.048% (25803/28032)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.063% (25925/28160)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.067% (26044/28288)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.057% (26159/28416)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.061% (26278/28544)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.062% (26396/28672)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.069% (26516/28800)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.067% (26633/28928)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.064% (26750/29056)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.074% (26871/29184)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.054% (26983/29312)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.055% (27101/29440)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.069% (27223/29568)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.090% (27347/29696)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.110% (27471/29824)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.101% (27586/29952)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.104% (27705/30080)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.095% (27820/30208)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.095% (27938/30336)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.089% (28054/30464)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.089% (28172/30592)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.083% (28288/30720)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.081% (28405/30848)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.084% (28524/30976)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.075% (28639/31104)\n",
      "Train Epoch: 70 | Loss: 0.227 | Acc: 92.079% (28758/31232)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.066% (28872/31360)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.067% (28990/31488)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.067% (29108/31616)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.052% (29221/31744)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.046% (29337/31872)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.047% (29455/32000)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.051% (29574/32128)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.026% (29684/32256)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.039% (29806/32384)\n",
      "Train Epoch: 70 | Loss: 0.228 | Acc: 92.037% (29923/32512)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.037% (30041/32640)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.038% (30159/32768)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.039% (30277/32896)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.039% (30395/33024)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.016% (30505/33152)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.004% (30619/33280)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.002% (30736/33408)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.021% (30860/33536)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.024% (30979/33664)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.034% (31100/33792)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.043% (31221/33920)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.047% (31340/34048)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.047% (31458/34176)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.059% (31580/34304)\n",
      "Train Epoch: 70 | Loss: 0.229 | Acc: 92.051% (31695/34432)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.037% (31808/34560)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.035% (31925/34688)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.035% (32043/34816)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.030% (32159/34944)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.039% (32280/35072)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.045% (32400/35200)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.049% (32519/35328)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.052% (32638/35456)\n",
      "Train Epoch: 70 | Loss: 0.231 | Acc: 92.041% (32752/35584)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.033% (32867/35712)\n",
      "Train Epoch: 70 | Loss: 0.230 | Acc: 92.026% (32982/35840)\n",
      "Train Epoch: 70 | Loss: 0.231 | Acc: 92.037% (33104/35968)\n",
      "Train Epoch: 70 | Loss: 0.231 | Acc: 92.024% (33217/36096)\n",
      "Train Epoch: 70 | Loss: 0.231 | Acc: 92.016% (33332/36224)\n",
      "Train Epoch: 70 | Loss: 0.231 | Acc: 92.009% (33447/36352)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.993% (33559/36480)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.999% (33679/36608)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.989% (33793/36736)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.984% (33909/36864)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.977% (34024/36992)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.983% (34144/37120)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.970% (34257/37248)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.957% (34370/37376)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.956% (34487/37504)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.964% (34608/37632)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.976% (34730/37760)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.979% (34849/37888)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.977% (34966/38016)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.983% (35086/38144)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.997% (35209/38272)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.995% (35326/38400)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.990% (35442/38528)\n",
      "Train Epoch: 70 | Loss: 0.232 | Acc: 91.983% (35557/38656)\n",
      "Train Epoch: 70 | Loss: 0.233 | Acc: 91.981% (35674/38784)\n",
      "Train Epoch: 70 | Loss: 0.233 | Acc: 91.964% (35785/38912)\n",
      "Train Epoch: 70 | Loss: 0.233 | Acc: 91.957% (35900/39040)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.937% (36010/39168)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.930% (36125/39296)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.929% (36242/39424)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.942% (36365/39552)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.951% (36486/39680)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.939% (36599/39808)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.927% (36712/39936)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.910% (36823/40064)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.909% (36940/40192)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.890% (37050/40320)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.888% (37167/40448)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.877% (37280/40576)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.880% (37399/40704)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.891% (37521/40832)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.870% (37630/40960)\n",
      "Train Epoch: 70 | Loss: 0.234 | Acc: 91.869% (37747/41088)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.848% (37856/41216)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.846% (37973/41344)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.852% (38093/41472)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.849% (38209/41600)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.838% (38322/41728)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.832% (38437/41856)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.830% (38554/41984)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.827% (38670/42112)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.835% (38791/42240)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.831% (38907/42368)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.837% (39027/42496)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.854% (39152/42624)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.846% (39266/42752)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.842% (39382/42880)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.843% (39500/43008)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.830% (39612/43136)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.827% (39728/43264)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.837% (39850/43392)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.843% (39970/43520)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.842% (40087/43648)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.836% (40202/43776)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.841% (40322/43904)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.842% (40440/44032)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.825% (40550/44160)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.822% (40666/44288)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.816% (40781/44416)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.808% (40895/44544)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.816% (41016/44672)\n",
      "Train Epoch: 70 | Loss: 0.235 | Acc: 91.817% (41134/44800)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.800% (41244/44928)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.792% (41358/45056)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.796% (41477/45184)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.788% (41591/45312)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.789% (41709/45440)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.786% (41825/45568)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.778% (41939/45696)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.773% (42054/45824)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.776% (42173/45952)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.775% (42290/46080)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.778% (42409/46208)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.780% (42527/46336)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.787% (42648/46464)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.795% (42769/46592)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.794% (42886/46720)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.799% (43006/46848)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.800% (43124/46976)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.801% (43242/47104)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.809% (43363/47232)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.805% (43479/47360)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.808% (43598/47488)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.807% (43715/47616)\n",
      "Train Epoch: 70 | Loss: 0.236 | Acc: 91.800% (43829/47744)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.789% (43941/47872)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.794% (44061/48000)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.782% (44173/48128)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.771% (44285/48256)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.772% (44403/48384)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.767% (44518/48512)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.774% (44639/48640)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.777% (44758/48768)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.774% (44874/48896)\n",
      "Train Epoch: 70 | Loss: 0.237 | Acc: 91.767% (44988/49024)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.756% (45100/49152)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.751% (45215/49280)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.748% (45331/49408)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.745% (45447/49536)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.745% (45564/49664)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.746% (45682/49792)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.743% (45798/49920)\n",
      "Train Epoch: 70 | Loss: 0.238 | Acc: 91.746% (45873/50000)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 70 | Loss: 0.370 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 70 | Loss: 0.360 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 70 | Loss: 0.337 | Acc: 88.000% (352/400)\n",
      "Test Epoch: 70 | Loss: 0.325 | Acc: 88.200% (441/500)\n",
      "Test Epoch: 70 | Loss: 0.286 | Acc: 89.833% (539/600)\n",
      "Test Epoch: 70 | Loss: 0.280 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 70 | Loss: 0.306 | Acc: 90.000% (720/800)\n",
      "Test Epoch: 70 | Loss: 0.330 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 70 | Loss: 0.336 | Acc: 89.200% (892/1000)\n",
      "Test Epoch: 70 | Loss: 0.343 | Acc: 89.091% (980/1100)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.167% (1070/1200)\n",
      "Test Epoch: 70 | Loss: 0.341 | Acc: 88.923% (1156/1300)\n",
      "Test Epoch: 70 | Loss: 0.337 | Acc: 88.857% (1244/1400)\n",
      "Test Epoch: 70 | Loss: 0.329 | Acc: 89.133% (1337/1500)\n",
      "Test Epoch: 70 | Loss: 0.331 | Acc: 89.062% (1425/1600)\n",
      "Test Epoch: 70 | Loss: 0.329 | Acc: 89.294% (1518/1700)\n",
      "Test Epoch: 70 | Loss: 0.336 | Acc: 89.222% (1606/1800)\n",
      "Test Epoch: 70 | Loss: 0.337 | Acc: 89.263% (1696/1900)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.050% (1781/2000)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.000% (1869/2100)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.091% (1960/2200)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.130% (2050/2300)\n",
      "Test Epoch: 70 | Loss: 0.340 | Acc: 89.250% (2142/2400)\n",
      "Test Epoch: 70 | Loss: 0.340 | Acc: 89.320% (2233/2500)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.269% (2321/2600)\n",
      "Test Epoch: 70 | Loss: 0.344 | Acc: 89.259% (2410/2700)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.286% (2500/2800)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.207% (2587/2900)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.267% (2678/3000)\n",
      "Test Epoch: 70 | Loss: 0.356 | Acc: 89.194% (2765/3100)\n",
      "Test Epoch: 70 | Loss: 0.353 | Acc: 89.250% (2856/3200)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 89.273% (2946/3300)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 89.324% (3037/3400)\n",
      "Test Epoch: 70 | Loss: 0.353 | Acc: 89.171% (3121/3500)\n",
      "Test Epoch: 70 | Loss: 0.350 | Acc: 89.306% (3215/3600)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.270% (3303/3700)\n",
      "Test Epoch: 70 | Loss: 0.352 | Acc: 89.105% (3386/3800)\n",
      "Test Epoch: 70 | Loss: 0.350 | Acc: 89.154% (3477/3900)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.200% (3568/4000)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 89.171% (3656/4100)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.167% (3745/4200)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.163% (3834/4300)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.250% (3927/4400)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.289% (4018/4500)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 89.174% (4102/4600)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.213% (4193/4700)\n",
      "Test Epoch: 70 | Loss: 0.351 | Acc: 89.125% (4278/4800)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.204% (4371/4900)\n",
      "Test Epoch: 70 | Loss: 0.350 | Acc: 89.140% (4457/5000)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.212% (4639/5200)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.208% (4728/5300)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.296% (4822/5400)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.255% (4909/5500)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.250% (4998/5600)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.281% (5089/5700)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.310% (5180/5800)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.254% (5266/5900)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.233% (5354/6000)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.180% (5440/6100)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.210% (5531/6200)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.270% (5624/6300)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.344% (5718/6400)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.385% (5810/6500)\n",
      "Test Epoch: 70 | Loss: 0.343 | Acc: 89.424% (5902/6600)\n",
      "Test Epoch: 70 | Loss: 0.341 | Acc: 89.493% (5996/6700)\n",
      "Test Epoch: 70 | Loss: 0.344 | Acc: 89.412% (6080/6800)\n",
      "Test Epoch: 70 | Loss: 0.344 | Acc: 89.362% (6166/6900)\n",
      "Test Epoch: 70 | Loss: 0.344 | Acc: 89.329% (6253/7000)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.268% (6338/7100)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.250% (6426/7200)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.315% (6520/7300)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.284% (6607/7400)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.267% (6695/7500)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.289% (6786/7600)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.247% (6872/7700)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.308% (6966/7800)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.291% (7054/7900)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.263% (7141/8000)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.358% (7238/8100)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.378% (7329/8200)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.398% (7420/8300)\n",
      "Test Epoch: 70 | Loss: 0.344 | Acc: 89.405% (7510/8400)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.365% (7596/8500)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.279% (7678/8600)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.264% (7766/8700)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.239% (7853/8800)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.258% (7944/8900)\n",
      "Test Epoch: 70 | Loss: 0.349 | Acc: 89.244% (8032/9000)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.231% (8120/9100)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.250% (8211/9200)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.226% (8298/9300)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.223% (8387/9400)\n",
      "Test Epoch: 70 | Loss: 0.347 | Acc: 89.232% (8477/9500)\n",
      "Test Epoch: 70 | Loss: 0.348 | Acc: 89.219% (8565/9600)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.258% (8658/9700)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.245% (8746/9800)\n",
      "Test Epoch: 70 | Loss: 0.346 | Acc: 89.263% (8837/9900)\n",
      "Test Epoch: 70 | Loss: 0.345 | Acc: 89.280% (8928/10000)\n",
      "\n",
      "Epoch: 71\n",
      "Train Epoch: 71 | Loss: 0.280 | Acc: 88.281% (113/128)\n",
      "Train Epoch: 71 | Loss: 0.225 | Acc: 91.406% (234/256)\n",
      "Train Epoch: 71 | Loss: 0.224 | Acc: 91.667% (352/384)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.188% (472/512)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.797% (705/768)\n",
      "Train Epoch: 71 | Loss: 0.245 | Acc: 91.629% (821/896)\n",
      "Train Epoch: 71 | Loss: 0.247 | Acc: 91.699% (939/1024)\n",
      "Train Epoch: 71 | Loss: 0.246 | Acc: 91.840% (1058/1152)\n",
      "Train Epoch: 71 | Loss: 0.262 | Acc: 91.172% (1167/1280)\n",
      "Train Epoch: 71 | Loss: 0.258 | Acc: 91.406% (1287/1408)\n",
      "Train Epoch: 71 | Loss: 0.258 | Acc: 91.406% (1404/1536)\n",
      "Train Epoch: 71 | Loss: 0.252 | Acc: 91.587% (1524/1664)\n",
      "Train Epoch: 71 | Loss: 0.256 | Acc: 91.574% (1641/1792)\n",
      "Train Epoch: 71 | Loss: 0.247 | Acc: 91.927% (1765/1920)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 92.090% (1886/2048)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 92.142% (2005/2176)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 92.274% (2126/2304)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 92.188% (2242/2432)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 92.266% (2362/2560)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 92.039% (2474/2688)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 92.188% (2596/2816)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.323% (2718/2944)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 92.188% (2832/3072)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 92.125% (2948/3200)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 92.097% (3065/3328)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 92.130% (3184/3456)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 92.188% (3304/3584)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 92.053% (3417/3712)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.031% (3534/3840)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.061% (3653/3968)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.163% (3775/4096)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.093% (3890/4224)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.050% (4006/4352)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.009% (4122/4480)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.970% (4238/4608)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.955% (4355/4736)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.941% (4472/4864)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.967% (4591/4992)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.895% (4705/5120)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.959% (4826/5248)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.871% (4939/5376)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.897% (5058/5504)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.903% (5176/5632)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.944% (5296/5760)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.933% (5413/5888)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.888% (5528/6016)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.829% (5642/6144)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.869% (5762/6272)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.844% (5878/6400)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.866% (5997/6528)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.767% (6108/6656)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.863% (6232/6784)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.898% (6352/6912)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.946% (6473/7040)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.950% (6591/7168)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.941% (6708/7296)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.985% (6829/7424)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.962% (6945/7552)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.992% (7065/7680)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.008% (7184/7808)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.011% (7302/7936)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.014% (7420/8064)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.992% (7536/8192)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 91.971% (7652/8320)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.974% (7770/8448)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.966% (7887/8576)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.935% (8002/8704)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.950% (8121/8832)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.920% (8236/8960)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.879% (8350/9088)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.840% (8464/9216)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.888% (8586/9344)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.881% (8703/9472)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.854% (8818/9600)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.879% (8938/9728)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.903% (9058/9856)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.887% (9174/9984)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.901% (9293/10112)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.963% (9417/10240)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.946% (9533/10368)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.949% (9651/10496)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.962% (9770/10624)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.946% (9886/10752)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.958% (10005/10880)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.969% (10124/11008)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.981% (10243/11136)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.957% (10358/11264)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.959% (10476/11392)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.997% (10598/11520)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.007% (10717/11648)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.018% (10836/11776)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.019% (10954/11904)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.021% (11072/12032)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.965% (11183/12160)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.951% (11299/12288)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.978% (11420/12416)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.948% (11534/12544)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.967% (11654/12672)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.930% (11767/12800)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.894% (11880/12928)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.927% (12002/13056)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.922% (12119/13184)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.940% (12239/13312)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.905% (12352/13440)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.952% (12476/13568)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.961% (12595/13696)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.956% (12712/13824)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.972% (12832/13952)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.996% (12953/14080)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.983% (13069/14208)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.964% (13184/14336)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 91.980% (13304/14464)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.009% (13426/14592)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.031% (13547/14720)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.992% (13659/14848)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.007% (13779/14976)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 91.995% (13895/15104)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.010% (14015/15232)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.038% (14137/15360)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.013% (14251/15488)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.021% (14370/15616)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.029% (14489/15744)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.036% (14608/15872)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.062% (14730/16000)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.076% (14850/16128)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.028% (14960/16256)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.053% (15082/16384)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.060% (15201/16512)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.079% (15322/16640)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.122% (15447/16768)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.134% (15567/16896)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.146% (15687/17024)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.170% (15809/17152)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.182% (15929/17280)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.176% (16046/17408)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.193% (16167/17536)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.188% (16284/17664)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.176% (16400/17792)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.188% (16520/17920)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.138% (16629/18048)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.154% (16750/18176)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.144% (16866/18304)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.160% (16987/18432)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.139% (17101/18560)\n",
      "Train Epoch: 71 | Loss: 0.229 | Acc: 92.155% (17222/18688)\n",
      "Train Epoch: 71 | Loss: 0.230 | Acc: 92.150% (17339/18816)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.103% (17448/18944)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.104% (17566/19072)\n",
      "Train Epoch: 71 | Loss: 0.231 | Acc: 92.104% (17684/19200)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.094% (17800/19328)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.090% (17917/19456)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.090% (18035/19584)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.081% (18151/19712)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.082% (18269/19840)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.067% (18384/19968)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.068% (18502/20096)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.044% (18615/20224)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.045% (18733/20352)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.041% (18850/20480)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.027% (18965/20608)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.028% (19083/20736)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.025% (19200/20864)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.006% (19314/20992)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.989% (19428/21120)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.009% (19550/21248)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.005% (19667/21376)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.006% (19785/21504)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.040% (19910/21632)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.040% (20028/21760)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.041% (20146/21888)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.038% (20263/22016)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.043% (20382/22144)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.044% (20500/22272)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.058% (20621/22400)\n",
      "Train Epoch: 71 | Loss: 0.232 | Acc: 92.072% (20742/22528)\n",
      "Train Epoch: 71 | Loss: 0.233 | Acc: 92.046% (20854/22656)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.016% (20965/22784)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.000% (21079/22912)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.997% (21196/23040)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 91.998% (21314/23168)\n",
      "Train Epoch: 71 | Loss: 0.234 | Acc: 92.007% (21434/23296)\n",
      "Train Epoch: 71 | Loss: 0.235 | Acc: 91.983% (21546/23424)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.962% (21659/23552)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.959% (21776/23680)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.961% (21894/23808)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.974% (22015/23936)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.976% (22133/24064)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.964% (22248/24192)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.974% (22368/24320)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.958% (22482/24448)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.956% (22599/24576)\n",
      "Train Epoch: 71 | Loss: 0.236 | Acc: 91.941% (22713/24704)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.950% (22833/24832)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.943% (22949/24960)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.928% (23063/25088)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.922% (23179/25216)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.907% (23293/25344)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.897% (23408/25472)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.895% (23525/25600)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.884% (23640/25728)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.882% (23757/25856)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.841% (23864/25984)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.858% (23986/26112)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.864% (24105/26240)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.865% (24223/26368)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.889% (24347/26496)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.887% (24464/26624)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.881% (24580/26752)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.897% (24702/26880)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.899% (24820/27008)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.904% (24939/27136)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.894% (25054/27264)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.884% (25169/27392)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.897% (25290/27520)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.898% (25408/27648)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.878% (25520/27776)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.869% (25635/27904)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.863% (25751/28032)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.861% (25868/28160)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.876% (25990/28288)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.878% (26108/28416)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.876% (26225/28544)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.891% (26347/28672)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.882% (26462/28800)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.876% (26578/28928)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.874% (26695/29056)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.865% (26810/29184)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.870% (26929/29312)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.858% (27043/29440)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.859% (27161/29568)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.854% (27277/29696)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.845% (27392/29824)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.850% (27511/29952)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.845% (27627/30080)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.847% (27745/30208)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.841% (27861/30336)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.833% (27976/30464)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.851% (28099/30592)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.839% (28213/30720)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.841% (28331/30848)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.842% (28449/30976)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.834% (28564/31104)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.848% (28686/31232)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.856% (28806/31360)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.860% (28925/31488)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.852% (29040/31616)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.860% (29160/31744)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.880% (29284/31872)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.894% (29406/32000)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.889% (29522/32128)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.893% (29641/32256)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.894% (29759/32384)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.908% (29881/32512)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.903% (29997/32640)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.910% (30117/32768)\n",
      "Train Epoch: 71 | Loss: 0.237 | Acc: 91.899% (30231/32896)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.897% (30348/33024)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.883% (30461/33152)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.890% (30581/33280)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.894% (30700/33408)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.901% (30820/33536)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.893% (30935/33664)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.889% (31051/33792)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.878% (31165/33920)\n",
      "Train Epoch: 71 | Loss: 0.238 | Acc: 91.870% (31280/34048)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.851% (31391/34176)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.844% (31506/34304)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.816% (31614/34432)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.820% (31733/34560)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.824% (31852/34688)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.823% (31969/34816)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.830% (32089/34944)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.840% (32210/35072)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.830% (32324/35200)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.837% (32444/35328)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.829% (32559/35456)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.828% (32676/35584)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.818% (32790/35712)\n",
      "Train Epoch: 71 | Loss: 0.239 | Acc: 91.833% (32913/35840)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.823% (33027/35968)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.822% (33144/36096)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.826% (33263/36224)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.822% (33379/36352)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.817% (33495/36480)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.813% (33611/36608)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.806% (33726/36736)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.802% (33842/36864)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.814% (33964/36992)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.794% (34074/37120)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.785% (34188/37248)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.775% (34302/37376)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.782% (34422/37504)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.789% (34542/37632)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.780% (34656/37760)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.789% (34777/37888)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.777% (34890/38016)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.771% (35005/38144)\n",
      "Train Epoch: 71 | Loss: 0.240 | Acc: 91.777% (35125/38272)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.768% (35239/38400)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.762% (35354/38528)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.771% (35475/38656)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.759% (35588/38784)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.756% (35704/38912)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.737% (35814/39040)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.748% (35936/39168)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.735% (36048/39296)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.716% (36158/39424)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.694% (36267/39552)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.699% (36386/39680)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.700% (36504/39808)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.702% (36622/39936)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.706% (36741/40064)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.715% (36862/40192)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.711% (36978/40320)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.705% (37093/40448)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.700% (37208/40576)\n",
      "Train Epoch: 71 | Loss: 0.241 | Acc: 91.708% (37329/40704)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.698% (37442/40832)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.689% (37556/40960)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.689% (37673/41088)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.688% (37790/41216)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.684% (37906/41344)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.684% (38023/41472)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.678% (38138/41600)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.675% (38254/41728)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.664% (38367/41856)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.671% (38487/41984)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.677% (38607/42112)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.662% (38718/42240)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.661% (38835/42368)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.665% (38954/42496)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.662% (39070/42624)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.654% (39184/42752)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.646% (39298/42880)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.641% (39413/43008)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.643% (39531/43136)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.640% (39647/43264)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.637% (39763/43392)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.638% (39881/43520)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.638% (39998/43648)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.644% (40118/43776)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.636% (40232/43904)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.640% (40351/44032)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.639% (40468/44160)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.628% (40580/44288)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.618% (40693/44416)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.624% (40813/44544)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.628% (40932/44672)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.629% (41050/44800)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.620% (41163/44928)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.633% (41286/45056)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.639% (41406/45184)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.634% (41521/45312)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.635% (41639/45440)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.632% (41755/45568)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.627% (41870/45696)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.627% (41987/45824)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.622% (42102/45952)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.617% (42217/46080)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.618% (42335/46208)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.605% (42446/46336)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.609% (42565/46464)\n",
      "Train Epoch: 71 | Loss: 0.244 | Acc: 91.606% (42681/46592)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.605% (42798/46720)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.613% (42919/46848)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.615% (43037/46976)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.623% (43158/47104)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.599% (43264/47232)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.607% (43385/47360)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.615% (43506/47488)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.627% (43629/47616)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.620% (43743/47744)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.619% (43860/47872)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.617% (43976/48000)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.622% (44096/48128)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.624% (44214/48256)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.619% (44329/48384)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.623% (44448/48512)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.616% (44562/48640)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.615% (44679/48768)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.613% (44795/48896)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.618% (44915/49024)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.612% (45029/49152)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.615% (45148/49280)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.613% (45264/49408)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.612% (45381/49536)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.628% (45506/49664)\n",
      "Train Epoch: 71 | Loss: 0.243 | Acc: 91.627% (45623/49792)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.643% (45748/49920)\n",
      "Train Epoch: 71 | Loss: 0.242 | Acc: 91.650% (45825/50000)\n",
      "Test Epoch: 71 | Loss: 0.303 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 71 | Loss: 0.320 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 71 | Loss: 0.293 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 71 | Loss: 0.312 | Acc: 90.000% (360/400)\n",
      "Test Epoch: 71 | Loss: 0.299 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 71 | Loss: 0.283 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 71 | Loss: 0.292 | Acc: 90.714% (635/700)\n",
      "Test Epoch: 71 | Loss: 0.304 | Acc: 90.000% (720/800)\n",
      "Test Epoch: 71 | Loss: 0.316 | Acc: 89.667% (807/900)\n",
      "Test Epoch: 71 | Loss: 0.315 | Acc: 89.800% (898/1000)\n",
      "Test Epoch: 71 | Loss: 0.332 | Acc: 89.545% (985/1100)\n",
      "Test Epoch: 71 | Loss: 0.336 | Acc: 89.500% (1074/1200)\n",
      "Test Epoch: 71 | Loss: 0.329 | Acc: 89.538% (1164/1300)\n",
      "Test Epoch: 71 | Loss: 0.328 | Acc: 89.286% (1250/1400)\n",
      "Test Epoch: 71 | Loss: 0.322 | Acc: 89.533% (1343/1500)\n",
      "Test Epoch: 71 | Loss: 0.316 | Acc: 89.812% (1437/1600)\n",
      "Test Epoch: 71 | Loss: 0.316 | Acc: 90.059% (1531/1700)\n",
      "Test Epoch: 71 | Loss: 0.321 | Acc: 89.722% (1615/1800)\n",
      "Test Epoch: 71 | Loss: 0.322 | Acc: 89.737% (1705/1900)\n",
      "Test Epoch: 71 | Loss: 0.326 | Acc: 89.700% (1794/2000)\n",
      "Test Epoch: 71 | Loss: 0.327 | Acc: 89.619% (1882/2100)\n",
      "Test Epoch: 71 | Loss: 0.325 | Acc: 89.591% (1971/2200)\n",
      "Test Epoch: 71 | Loss: 0.328 | Acc: 89.391% (2056/2300)\n",
      "Test Epoch: 71 | Loss: 0.328 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 71 | Loss: 0.334 | Acc: 88.960% (2224/2500)\n",
      "Test Epoch: 71 | Loss: 0.344 | Acc: 88.962% (2313/2600)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 89.074% (2405/2700)\n",
      "Test Epoch: 71 | Loss: 0.338 | Acc: 89.107% (2495/2800)\n",
      "Test Epoch: 71 | Loss: 0.344 | Acc: 88.931% (2579/2900)\n",
      "Test Epoch: 71 | Loss: 0.345 | Acc: 88.800% (2664/3000)\n",
      "Test Epoch: 71 | Loss: 0.350 | Acc: 88.710% (2750/3100)\n",
      "Test Epoch: 71 | Loss: 0.348 | Acc: 88.812% (2842/3200)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.848% (2932/3300)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 89.000% (3026/3400)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.943% (3113/3500)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 89.000% (3204/3600)\n",
      "Test Epoch: 71 | Loss: 0.347 | Acc: 88.892% (3289/3700)\n",
      "Test Epoch: 71 | Loss: 0.349 | Acc: 88.737% (3372/3800)\n",
      "Test Epoch: 71 | Loss: 0.350 | Acc: 88.692% (3459/3900)\n",
      "Test Epoch: 71 | Loss: 0.349 | Acc: 88.775% (3551/4000)\n",
      "Test Epoch: 71 | Loss: 0.353 | Acc: 88.610% (3633/4100)\n",
      "Test Epoch: 71 | Loss: 0.352 | Acc: 88.643% (3723/4200)\n",
      "Test Epoch: 71 | Loss: 0.350 | Acc: 88.651% (3812/4300)\n",
      "Test Epoch: 71 | Loss: 0.349 | Acc: 88.705% (3903/4400)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.711% (3992/4500)\n",
      "Test Epoch: 71 | Loss: 0.347 | Acc: 88.696% (4080/4600)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.723% (4170/4700)\n",
      "Test Epoch: 71 | Loss: 0.350 | Acc: 88.688% (4257/4800)\n",
      "Test Epoch: 71 | Loss: 0.347 | Acc: 88.755% (4349/4900)\n",
      "Test Epoch: 71 | Loss: 0.350 | Acc: 88.680% (4434/5000)\n",
      "Test Epoch: 71 | Loss: 0.348 | Acc: 88.706% (4524/5100)\n",
      "Test Epoch: 71 | Loss: 0.347 | Acc: 88.750% (4615/5200)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.698% (4701/5300)\n",
      "Test Epoch: 71 | Loss: 0.345 | Acc: 88.759% (4793/5400)\n",
      "Test Epoch: 71 | Loss: 0.345 | Acc: 88.800% (4884/5500)\n",
      "Test Epoch: 71 | Loss: 0.347 | Acc: 88.804% (4973/5600)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.825% (5063/5700)\n",
      "Test Epoch: 71 | Loss: 0.344 | Acc: 88.845% (5153/5800)\n",
      "Test Epoch: 71 | Loss: 0.346 | Acc: 88.797% (5239/5900)\n",
      "Test Epoch: 71 | Loss: 0.344 | Acc: 88.767% (5326/6000)\n",
      "Test Epoch: 71 | Loss: 0.345 | Acc: 88.672% (5409/6100)\n",
      "Test Epoch: 71 | Loss: 0.345 | Acc: 88.694% (5499/6200)\n",
      "Test Epoch: 71 | Loss: 0.344 | Acc: 88.714% (5589/6300)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.750% (5680/6400)\n",
      "Test Epoch: 71 | Loss: 0.343 | Acc: 88.738% (5768/6500)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.803% (5861/6600)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.821% (5951/6700)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 88.794% (6038/6800)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 88.899% (6134/6900)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 88.900% (6223/7000)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.845% (6308/7100)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.889% (6400/7200)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.904% (6490/7300)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 88.905% (6579/7400)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.893% (6667/7500)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.921% (6758/7600)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 88.935% (6848/7700)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 88.949% (6938/7800)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 88.937% (7026/7900)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 88.900% (7112/8000)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 88.951% (7205/8100)\n",
      "Test Epoch: 71 | Loss: 0.338 | Acc: 89.000% (7298/8200)\n",
      "Test Epoch: 71 | Loss: 0.338 | Acc: 89.000% (7387/8300)\n",
      "Test Epoch: 71 | Loss: 0.337 | Acc: 89.012% (7477/8400)\n",
      "Test Epoch: 71 | Loss: 0.337 | Acc: 89.035% (7568/8500)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 88.953% (7650/8600)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 89.000% (7743/8700)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.955% (7828/8800)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.978% (7919/8900)\n",
      "Test Epoch: 71 | Loss: 0.343 | Acc: 88.933% (8004/9000)\n",
      "Test Epoch: 71 | Loss: 0.342 | Acc: 88.945% (8094/9100)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 89.011% (8189/9200)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 89.022% (8279/9300)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 89.021% (8368/9400)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 89.032% (8458/9500)\n",
      "Test Epoch: 71 | Loss: 0.341 | Acc: 89.010% (8545/9600)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 89.052% (8638/9700)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 89.061% (8728/9800)\n",
      "Test Epoch: 71 | Loss: 0.340 | Acc: 89.040% (8815/9900)\n",
      "Test Epoch: 71 | Loss: 0.339 | Acc: 89.050% (8905/10000)\n",
      "\n",
      "Epoch: 72\n",
      "Train Epoch: 72 | Loss: 0.218 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 72 | Loss: 0.207 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 72 | Loss: 0.207 | Acc: 92.969% (357/384)\n",
      "Train Epoch: 72 | Loss: 0.230 | Acc: 92.969% (476/512)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.969% (595/640)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 93.099% (715/768)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 93.304% (836/896)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.969% (952/1024)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.448% (1065/1152)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.578% (1185/1280)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.827% (1307/1408)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.969% (1428/1536)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 93.029% (1548/1664)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.913% (1665/1792)\n",
      "Train Epoch: 72 | Loss: 0.208 | Acc: 93.125% (1788/1920)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 93.164% (1908/2048)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 93.107% (2026/2176)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.925% (2141/2304)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.640% (2253/2432)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.656% (2372/2560)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.746% (2493/2688)\n",
      "Train Epoch: 72 | Loss: 0.206 | Acc: 92.933% (2617/2816)\n",
      "Train Epoch: 72 | Loss: 0.208 | Acc: 92.697% (2729/2944)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.741% (2849/3072)\n",
      "Train Epoch: 72 | Loss: 0.206 | Acc: 92.844% (2971/3200)\n",
      "Train Epoch: 72 | Loss: 0.207 | Acc: 92.879% (3091/3328)\n",
      "Train Epoch: 72 | Loss: 0.206 | Acc: 92.940% (3212/3456)\n",
      "Train Epoch: 72 | Loss: 0.206 | Acc: 92.941% (3331/3584)\n",
      "Train Epoch: 72 | Loss: 0.208 | Acc: 92.888% (3448/3712)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.760% (3562/3840)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.792% (3682/3968)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.822% (3802/4096)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.756% (3918/4224)\n",
      "Train Epoch: 72 | Loss: 0.208 | Acc: 92.785% (4038/4352)\n",
      "Train Epoch: 72 | Loss: 0.208 | Acc: 92.790% (4157/4480)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.687% (4271/4608)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.673% (4389/4736)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.722% (4510/4864)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.708% (4628/4992)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.754% (4749/5120)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.759% (4868/5248)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.708% (4984/5376)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.787% (5107/5504)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.756% (5224/5632)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.847% (5348/5760)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.765% (5462/5888)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.753% (5580/6016)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.692% (5695/6144)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.634% (5810/6272)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.703% (5933/6400)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.708% (6052/6528)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.728% (6172/6656)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.777% (6294/6784)\n",
      "Train Epoch: 72 | Loss: 0.210 | Acc: 92.810% (6415/6912)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.812% (6534/7040)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.843% (6655/7168)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.845% (6774/7296)\n",
      "Train Epoch: 72 | Loss: 0.209 | Acc: 92.807% (6890/7424)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.757% (7005/7552)\n",
      "Train Epoch: 72 | Loss: 0.211 | Acc: 92.773% (7125/7680)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.713% (7239/7808)\n",
      "Train Epoch: 72 | Loss: 0.212 | Acc: 92.717% (7358/7936)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.597% (7467/8064)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.554% (7582/8192)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.632% (7707/8320)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.649% (7827/8448)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.631% (7944/8576)\n",
      "Train Epoch: 72 | Loss: 0.213 | Acc: 92.647% (8064/8704)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.618% (8180/8832)\n",
      "Train Epoch: 72 | Loss: 0.214 | Acc: 92.623% (8299/8960)\n",
      "Train Epoch: 72 | Loss: 0.216 | Acc: 92.540% (8410/9088)\n",
      "Train Epoch: 72 | Loss: 0.217 | Acc: 92.513% (8526/9216)\n",
      "Train Epoch: 72 | Loss: 0.217 | Acc: 92.466% (8640/9344)\n",
      "Train Epoch: 72 | Loss: 0.219 | Acc: 92.378% (8750/9472)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.333% (8864/9600)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.321% (8981/9728)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.269% (9094/9856)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.288% (9214/9984)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.316% (9335/10112)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.285% (9450/10240)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.303% (9570/10368)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.292% (9687/10496)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.338% (9810/10624)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.336% (9928/10752)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.344% (10047/10880)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.360% (10167/11008)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.394% (10289/11136)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.418% (10410/11264)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.363% (10522/11392)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.318% (10635/11520)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.333% (10755/11648)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.289% (10868/11776)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.322% (10990/11904)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.287% (11104/12032)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.294% (11223/12160)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.269% (11338/12288)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.292% (11459/12416)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.291% (11577/12544)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.290% (11695/12672)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.250% (11808/12800)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.273% (11929/12928)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.264% (12046/13056)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.294% (12168/13184)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.300% (12287/13312)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.284% (12403/13440)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.305% (12524/13568)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.304% (12642/13696)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.332% (12764/13824)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.352% (12885/13952)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.337% (13001/14080)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.342% (13120/14208)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.327% (13236/14336)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.298% (13350/14464)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.304% (13469/14592)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.262% (13581/14720)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.241% (13696/14848)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.254% (13816/14976)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.194% (13925/15104)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.188% (14042/15232)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.181% (14159/15360)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.168% (14275/15488)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.194% (14397/15616)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.213% (14518/15744)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.232% (14639/15872)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.263% (14762/16000)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.281% (14883/16128)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.267% (14999/16256)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.285% (15120/16384)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.278% (15237/16512)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.278% (15355/16640)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.271% (15472/16768)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.264% (15589/16896)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.264% (15707/17024)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.240% (15821/17152)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.257% (15942/17280)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.279% (16064/17408)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.284% (16183/17536)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.278% (16300/17664)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.294% (16421/17792)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.305% (16541/17920)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.326% (16663/18048)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.325% (16781/18176)\n",
      "Train Epoch: 72 | Loss: 0.219 | Acc: 92.340% (16902/18304)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.323% (17017/18432)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.322% (17135/18560)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.316% (17252/18688)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.320% (17371/18816)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.341% (17493/18944)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.334% (17610/19072)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.323% (17726/19200)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.317% (17843/19328)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.311% (17960/19456)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.315% (18079/19584)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.304% (18195/19712)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.303% (18313/19840)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.278% (18426/19968)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.257% (18540/20096)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.237% (18654/20224)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.246% (18774/20352)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.231% (18889/20480)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.217% (19004/20608)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.236% (19126/20736)\n",
      "Train Epoch: 72 | Loss: 0.220 | Acc: 92.245% (19246/20864)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.230% (19361/20992)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.235% (19480/21120)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.235% (19598/21248)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.234% (19716/21376)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.243% (19836/21504)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.220% (19949/21632)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.220% (20067/21760)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.242% (20190/21888)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.210% (20301/22016)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.237% (20425/22144)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.223% (20540/22272)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.246% (20663/22400)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.241% (20780/22528)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.236% (20897/22656)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.231% (21014/22784)\n",
      "Train Epoch: 72 | Loss: 0.221 | Acc: 92.249% (21136/22912)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.244% (21253/23040)\n",
      "Train Epoch: 72 | Loss: 0.222 | Acc: 92.226% (21367/23168)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.222% (21484/23296)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.192% (21595/23424)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.200% (21715/23552)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.188% (21830/23680)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.188% (21948/23808)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.183% (22065/23936)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.175% (22181/24064)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.167% (22297/24192)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.183% (22419/24320)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.171% (22534/24448)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.179% (22654/24576)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.175% (22771/24704)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.171% (22888/24832)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.179% (23008/24960)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.168% (23123/25088)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.180% (23244/25216)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.172% (23360/25344)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.168% (23477/25472)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.160% (23593/25600)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.176% (23715/25728)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.168% (23831/25856)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.161% (23947/25984)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.145% (24061/26112)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.153% (24181/26240)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.150% (24298/26368)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.157% (24418/26496)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.172% (24540/26624)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.199% (24665/26752)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.184% (24779/26880)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.202% (24902/27008)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.202% (25020/27136)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.191% (25135/27264)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.202% (25256/27392)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.202% (25374/27520)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.195% (25490/27648)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.206% (25611/27776)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.223% (25734/27904)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.216% (25850/28032)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.205% (25965/28160)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.198% (26081/28288)\n",
      "Train Epoch: 72 | Loss: 0.223 | Acc: 92.202% (26200/28416)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.191% (26315/28544)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.188% (26432/28672)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.153% (26540/28800)\n",
      "Train Epoch: 72 | Loss: 0.224 | Acc: 92.160% (26660/28928)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.150% (26775/29056)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.143% (26891/29184)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.133% (27006/29312)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.130% (27123/29440)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.144% (27245/29568)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.140% (27362/29696)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.147% (27482/29824)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.154% (27602/29952)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.151% (27719/30080)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.151% (27837/30208)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.145% (27953/30336)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.135% (28068/30464)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.116% (28180/30592)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.132% (28303/30720)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.126% (28419/30848)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.142% (28542/30976)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.142% (28660/31104)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.136% (28776/31232)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.127% (28891/31360)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.124% (29008/31488)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.121% (29125/31616)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.115% (29241/31744)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.109% (29357/31872)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.106% (29474/32000)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.116% (29595/32128)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.125% (29716/32256)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.132% (29836/32384)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.138% (29956/32512)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.126% (30070/32640)\n",
      "Train Epoch: 72 | Loss: 0.225 | Acc: 92.120% (30186/32768)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.118% (30303/32896)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.115% (30420/33024)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.124% (30541/33152)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.127% (30660/33280)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.119% (30775/33408)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.101% (30887/33536)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.104% (31006/33664)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.108% (31125/33792)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.114% (31245/33920)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.117% (31364/34048)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.111% (31480/34176)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.109% (31597/34304)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.121% (31719/34432)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.115% (31835/34560)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.110% (31951/34688)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.116% (32071/34816)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.107% (32186/34944)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.113% (32306/35072)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.111% (32423/35200)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.100% (32537/35328)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.103% (32656/35456)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.098% (32772/35584)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.106% (32893/35712)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.109% (33012/35840)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.118% (33133/35968)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.118% (33251/36096)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.121% (33370/36224)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.124% (33489/36352)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.130% (33609/36480)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.141% (33731/36608)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.133% (33846/36736)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.139% (33966/36864)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.133% (34082/36992)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.123% (34196/37120)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.126% (34315/37248)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.126% (34433/37376)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.121% (34549/37504)\n",
      "Train Epoch: 72 | Loss: 0.226 | Acc: 92.129% (34670/37632)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.121% (34785/37760)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.119% (34902/37888)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.109% (35016/38016)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.106% (35133/38144)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.114% (35254/38272)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.117% (35373/38400)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.120% (35492/38528)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.115% (35608/38656)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.108% (35723/38784)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.116% (35844/38912)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.118% (35963/39040)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.113% (36079/39168)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.111% (36196/39296)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.109% (36313/39424)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.109% (36431/39552)\n",
      "Train Epoch: 72 | Loss: 0.227 | Acc: 92.107% (36548/39680)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.107% (36666/39808)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.100% (36781/39936)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.098% (36898/40064)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.093% (37014/40192)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.091% (37131/40320)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.089% (37248/40448)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.084% (37364/40576)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.104% (37490/40704)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.104% (37608/40832)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.102% (37725/40960)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.093% (37839/41088)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.098% (37959/41216)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.100% (38078/41344)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.081% (38188/41472)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.082% (38306/41600)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.077% (38422/41728)\n",
      "Train Epoch: 72 | Loss: 0.228 | Acc: 92.068% (38536/41856)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.066% (38653/41984)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.062% (38769/42112)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.067% (38889/42240)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.065% (39006/42368)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.070% (39126/42496)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.066% (39242/42624)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.049% (39353/42752)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.057% (39474/42880)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.048% (39588/43008)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.037% (39701/43136)\n",
      "Train Epoch: 72 | Loss: 0.229 | Acc: 92.049% (39824/43264)\n",
      "Train Epoch: 72 | Loss: 0.230 | Acc: 92.035% (39936/43392)\n",
      "Train Epoch: 72 | Loss: 0.230 | Acc: 92.017% (40046/43520)\n",
      "Train Epoch: 72 | Loss: 0.230 | Acc: 92.020% (40165/43648)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 92.016% (40281/43776)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 92.014% (40398/43904)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 92.004% (40511/44032)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.997% (40626/44160)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.984% (40738/44288)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.987% (40857/44416)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.974% (40969/44544)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.977% (41088/44672)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.975% (41205/44800)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.967% (41319/44928)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.968% (41437/45056)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.964% (41553/45184)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.954% (41666/45312)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.956% (41785/45440)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.955% (41902/45568)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.960% (42022/45696)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.967% (42143/45824)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.966% (42260/45952)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.968% (42379/46080)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.973% (42499/46208)\n",
      "Train Epoch: 72 | Loss: 0.231 | Acc: 91.982% (42621/46336)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.972% (42734/46464)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.971% (42851/46592)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.961% (42964/46720)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.955% (43079/46848)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.945% (43192/46976)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.924% (43300/47104)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.929% (43420/47232)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.930% (43538/47360)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.926% (43654/47488)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.919% (43768/47616)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.917% (43885/47744)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.914% (44001/47872)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.925% (44124/48000)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.919% (44239/48128)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.924% (44359/48256)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.919% (44474/48384)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.911% (44588/48512)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.922% (44711/48640)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.923% (44829/48768)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.920% (44945/48896)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.926% (45066/49024)\n",
      "Train Epoch: 72 | Loss: 0.232 | Acc: 91.933% (45187/49152)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.924% (45300/49280)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.914% (45413/49408)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.911% (45529/49536)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.908% (45645/49664)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.912% (45765/49792)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.911% (45882/49920)\n",
      "Train Epoch: 72 | Loss: 0.233 | Acc: 91.918% (45959/50000)\n",
      "Test Epoch: 72 | Loss: 0.313 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 72 | Loss: 0.322 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 72 | Loss: 0.324 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 72 | Loss: 0.313 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 72 | Loss: 0.308 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 72 | Loss: 0.294 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 72 | Loss: 0.285 | Acc: 91.429% (640/700)\n",
      "Test Epoch: 72 | Loss: 0.319 | Acc: 90.500% (724/800)\n",
      "Test Epoch: 72 | Loss: 0.335 | Acc: 89.778% (808/900)\n",
      "Test Epoch: 72 | Loss: 0.329 | Acc: 90.000% (900/1000)\n",
      "Test Epoch: 72 | Loss: 0.339 | Acc: 89.727% (987/1100)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.667% (1076/1200)\n",
      "Test Epoch: 72 | Loss: 0.339 | Acc: 89.692% (1166/1300)\n",
      "Test Epoch: 72 | Loss: 0.334 | Acc: 90.071% (1261/1400)\n",
      "Test Epoch: 72 | Loss: 0.340 | Acc: 89.733% (1346/1500)\n",
      "Test Epoch: 72 | Loss: 0.341 | Acc: 89.750% (1436/1600)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.647% (1524/1700)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.500% (1611/1800)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.474% (1700/1900)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.450% (1789/2000)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.381% (1877/2100)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.318% (1965/2200)\n",
      "Test Epoch: 72 | Loss: 0.339 | Acc: 89.261% (2053/2300)\n",
      "Test Epoch: 72 | Loss: 0.336 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.000% (2225/2500)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 88.846% (2310/2600)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.000% (2403/2700)\n",
      "Test Epoch: 72 | Loss: 0.349 | Acc: 88.964% (2491/2800)\n",
      "Test Epoch: 72 | Loss: 0.351 | Acc: 88.931% (2579/2900)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 88.900% (2667/3000)\n",
      "Test Epoch: 72 | Loss: 0.354 | Acc: 88.839% (2754/3100)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.000% (2848/3200)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.152% (2942/3300)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.059% (3028/3400)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 88.943% (3113/3500)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.083% (3207/3600)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.108% (3297/3700)\n",
      "Test Epoch: 72 | Loss: 0.349 | Acc: 89.079% (3385/3800)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.179% (3478/3900)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.175% (3567/4000)\n",
      "Test Epoch: 72 | Loss: 0.351 | Acc: 89.073% (3652/4100)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 89.119% (3743/4200)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.163% (3834/4300)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.295% (3929/4400)\n",
      "Test Epoch: 72 | Loss: 0.343 | Acc: 89.333% (4020/4500)\n",
      "Test Epoch: 72 | Loss: 0.343 | Acc: 89.326% (4109/4600)\n",
      "Test Epoch: 72 | Loss: 0.339 | Acc: 89.447% (4204/4700)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.458% (4294/4800)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.551% (4388/4900)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.480% (4474/5000)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.431% (4561/5100)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.385% (4648/5200)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.264% (4731/5300)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.296% (4822/5400)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.200% (4906/5500)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 89.143% (4992/5600)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 89.123% (5080/5700)\n",
      "Test Epoch: 72 | Loss: 0.349 | Acc: 89.155% (5171/5800)\n",
      "Test Epoch: 72 | Loss: 0.352 | Acc: 89.068% (5255/5900)\n",
      "Test Epoch: 72 | Loss: 0.351 | Acc: 89.083% (5345/6000)\n",
      "Test Epoch: 72 | Loss: 0.352 | Acc: 89.066% (5433/6100)\n",
      "Test Epoch: 72 | Loss: 0.352 | Acc: 89.097% (5524/6200)\n",
      "Test Epoch: 72 | Loss: 0.350 | Acc: 89.143% (5616/6300)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.219% (5710/6400)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.215% (5799/6500)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.273% (5892/6600)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.343% (5986/6700)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.324% (6074/6800)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.348% (6165/6900)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.314% (6252/7000)\n",
      "Test Epoch: 72 | Loss: 0.349 | Acc: 89.254% (6337/7100)\n",
      "Test Epoch: 72 | Loss: 0.348 | Acc: 89.250% (6426/7200)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.315% (6520/7300)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.297% (6608/7400)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.280% (6696/7500)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.276% (6785/7600)\n",
      "Test Epoch: 72 | Loss: 0.347 | Acc: 89.312% (6877/7700)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.346% (6969/7800)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.342% (7058/7900)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.350% (7148/8000)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.407% (7242/8100)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.378% (7329/8200)\n",
      "Test Epoch: 72 | Loss: 0.343 | Acc: 89.361% (7417/8300)\n",
      "Test Epoch: 72 | Loss: 0.342 | Acc: 89.369% (7507/8400)\n",
      "Test Epoch: 72 | Loss: 0.343 | Acc: 89.318% (7592/8500)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.267% (7677/8600)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.333% (7772/8700)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.284% (7857/8800)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.281% (7946/8900)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.233% (8031/9000)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.242% (8121/9100)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.304% (8216/9200)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.269% (8302/9300)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.255% (8390/9400)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.274% (8481/9500)\n",
      "Test Epoch: 72 | Loss: 0.346 | Acc: 89.271% (8570/9600)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.330% (8665/9700)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.327% (8754/9800)\n",
      "Test Epoch: 72 | Loss: 0.345 | Acc: 89.303% (8841/9900)\n",
      "Test Epoch: 72 | Loss: 0.344 | Acc: 89.350% (8935/10000)\n",
      "\n",
      "Epoch: 73\n",
      "Train Epoch: 73 | Loss: 0.208 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 73 | Loss: 0.209 | Acc: 92.708% (356/384)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.773% (475/512)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 73 | Loss: 0.245 | Acc: 91.276% (701/768)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.299% (827/896)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.285% (945/1024)\n",
      "Train Epoch: 73 | Loss: 0.232 | Acc: 92.101% (1061/1152)\n",
      "Train Epoch: 73 | Loss: 0.239 | Acc: 91.953% (1177/1280)\n",
      "Train Epoch: 73 | Loss: 0.247 | Acc: 91.832% (1293/1408)\n",
      "Train Epoch: 73 | Loss: 0.242 | Acc: 91.992% (1413/1536)\n",
      "Train Epoch: 73 | Loss: 0.244 | Acc: 91.767% (1527/1664)\n",
      "Train Epoch: 73 | Loss: 0.240 | Acc: 91.797% (1645/1792)\n",
      "Train Epoch: 73 | Loss: 0.239 | Acc: 91.823% (1763/1920)\n",
      "Train Epoch: 73 | Loss: 0.235 | Acc: 91.992% (1884/2048)\n",
      "Train Epoch: 73 | Loss: 0.239 | Acc: 91.912% (2000/2176)\n",
      "Train Epoch: 73 | Loss: 0.243 | Acc: 91.840% (2116/2304)\n",
      "Train Epoch: 73 | Loss: 0.240 | Acc: 91.817% (2233/2432)\n",
      "Train Epoch: 73 | Loss: 0.239 | Acc: 91.875% (2352/2560)\n",
      "Train Epoch: 73 | Loss: 0.237 | Acc: 91.890% (2470/2688)\n",
      "Train Epoch: 73 | Loss: 0.234 | Acc: 92.010% (2591/2816)\n",
      "Train Epoch: 73 | Loss: 0.233 | Acc: 92.018% (2709/2944)\n",
      "Train Epoch: 73 | Loss: 0.232 | Acc: 92.090% (2829/3072)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.156% (2949/3200)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.338% (3073/3328)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.419% (3194/3456)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.439% (3313/3584)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.430% (3431/3712)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.474% (3551/3840)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.515% (3671/3968)\n",
      "Train Epoch: 73 | Loss: 0.220 | Acc: 92.505% (3789/4096)\n",
      "Train Epoch: 73 | Loss: 0.219 | Acc: 92.472% (3906/4224)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.440% (4023/4352)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.433% (4141/4480)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.383% (4257/4608)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.230% (4368/4736)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.270% (4488/4864)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.228% (4604/4992)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.168% (4719/5120)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.168% (4837/5248)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.188% (4956/5376)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.151% (5072/5504)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.188% (5192/5632)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.257% (5314/5760)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.306% (5435/5888)\n",
      "Train Epoch: 73 | Loss: 0.220 | Acc: 92.337% (5555/6016)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.269% (5669/6144)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.219% (5784/6272)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.172% (5899/6400)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.188% (6018/6528)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.142% (6133/6656)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.084% (6247/6784)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.086% (6365/6912)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.003% (6477/7040)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.006% (6595/7168)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 91.996% (6712/7296)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.039% (6833/7424)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 91.989% (6947/7552)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.005% (7066/7680)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.034% (7186/7808)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.112% (7310/7936)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.150% (7431/8064)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.163% (7550/8192)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.188% (7670/8320)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.235% (7792/8448)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.211% (7908/8576)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.233% (8028/8704)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.221% (8145/8832)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.221% (8263/8960)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.232% (8382/9088)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.253% (8502/9216)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.273% (8622/9344)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.261% (8739/9472)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.302% (8861/9600)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.239% (8973/9728)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.289% (9096/9856)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.308% (9216/9984)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.306% (9334/10112)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.324% (9454/10240)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.332% (9573/10368)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.330% (9691/10496)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.376% (9814/10624)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.411% (9936/10752)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.399% (10053/10880)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.396% (10171/11008)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.394% (10289/11136)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.392% (10407/11264)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.337% (10519/11392)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.352% (10639/11520)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.299% (10751/11648)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.323% (10872/11776)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.330% (10991/11904)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.354% (11112/12032)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.368% (11232/12160)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.375% (11351/12288)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.381% (11470/12416)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.323% (11581/12544)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.322% (11699/12672)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.320% (11817/12800)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.342% (11938/12928)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.364% (12059/13056)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.392% (12181/13184)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.413% (12302/13312)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.448% (12425/13440)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.445% (12543/13568)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.465% (12664/13696)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.470% (12783/13824)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.467% (12901/13952)\n",
      "Train Epoch: 73 | Loss: 0.221 | Acc: 92.472% (13020/14080)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.455% (13136/14208)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.439% (13252/14336)\n",
      "Train Epoch: 73 | Loss: 0.222 | Acc: 92.429% (13369/14464)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.414% (13485/14592)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.391% (13600/14720)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.383% (13717/14848)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.374% (13834/14976)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.373% (13952/15104)\n",
      "Train Epoch: 73 | Loss: 0.223 | Acc: 92.378% (14071/15232)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.337% (14183/15360)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.317% (14298/15488)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.322% (14417/15616)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.308% (14533/15744)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.295% (14649/15872)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.263% (14762/16000)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.268% (14881/16128)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.261% (14998/16256)\n",
      "Train Epoch: 73 | Loss: 0.224 | Acc: 92.279% (15119/16384)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.260% (15234/16512)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.248% (15350/16640)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.229% (15465/16768)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.235% (15584/16896)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.264% (15707/17024)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.275% (15827/17152)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.263% (15943/17280)\n",
      "Train Epoch: 73 | Loss: 0.225 | Acc: 92.256% (16060/17408)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.250% (16177/17536)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.227% (16291/17664)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.232% (16410/17792)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.215% (16525/17920)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.221% (16644/18048)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.215% (16761/18176)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.193% (16875/18304)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.193% (16993/18432)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.155% (17104/18560)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.145% (17220/18688)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.134% (17336/18816)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.145% (17456/18944)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.167% (17578/19072)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.141% (17691/19200)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.125% (17806/19328)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.141% (17927/19456)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.136% (18044/19584)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.116% (18158/19712)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.107% (18274/19840)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.127% (18396/19968)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.103% (18509/20096)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.098% (18626/20224)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.094% (18743/20352)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.085% (18859/20480)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.095% (18979/20608)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.101% (19098/20736)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.106% (19217/20864)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.107% (19335/20992)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.121% (19456/21120)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.140% (19578/21248)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.145% (19697/21376)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.155% (19817/21504)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.160% (19936/21632)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.174% (20057/21760)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.174% (20175/21888)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.183% (20295/22016)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.165% (20409/22144)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.161% (20526/22272)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.147% (20641/22400)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.130% (20755/22528)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.099% (20866/22656)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.104% (20985/22784)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.105% (21103/22912)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.109% (21222/23040)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.123% (21343/23168)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.136% (21464/23296)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.119% (21578/23424)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.132% (21699/23552)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.149% (21821/23680)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.150% (21939/23808)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.150% (22057/23936)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.150% (22175/24064)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.163% (22296/24192)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.150% (22411/24320)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.155% (22530/24448)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.155% (22648/24576)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.159% (22767/24704)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.167% (22887/24832)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.155% (23002/24960)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.148% (23118/25088)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.148% (23236/25216)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.132% (23350/25344)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.125% (23466/25472)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.129% (23585/25600)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.149% (23708/25728)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.145% (23825/25856)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.141% (23942/25984)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.126% (24056/26112)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.134% (24176/26240)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.131% (24293/26368)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.127% (24410/26496)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.139% (24531/26624)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.139% (24649/26752)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.147% (24769/26880)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.132% (24883/27008)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.114% (24996/27136)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.114% (25114/27264)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.125% (25235/27392)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.118% (25351/27520)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.115% (25468/27648)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.112% (25585/27776)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.109% (25702/27904)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.113% (25821/28032)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.088% (25932/28160)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.096% (26052/28288)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.071% (26163/28416)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.072% (26281/28544)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.058% (26395/28672)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.066% (26515/28800)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.077% (26636/28928)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.074% (26753/29056)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.074% (26871/29184)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.061% (26985/29312)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.048% (27099/29440)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.035% (27213/29568)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.043% (27333/29696)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.043% (27451/29824)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.047% (27570/29952)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.058% (27691/30080)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.052% (27807/30208)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.059% (27927/30336)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.059% (28045/30464)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.040% (28157/30592)\n",
      "Train Epoch: 73 | Loss: 0.232 | Acc: 92.031% (28272/30720)\n",
      "Train Epoch: 73 | Loss: 0.232 | Acc: 92.032% (28390/30848)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.039% (28510/30976)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.027% (28624/31104)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.031% (28743/31232)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.034% (28862/31360)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.045% (28983/31488)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.045% (29101/31616)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.055% (29222/31744)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.053% (29339/31872)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.059% (29459/32000)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.054% (29575/32128)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.051% (29692/32256)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.045% (29808/32384)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.049% (29927/32512)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.053% (30046/32640)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.044% (30161/32768)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.042% (30278/32896)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.054% (30400/33024)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.061% (30520/33152)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.070% (30641/33280)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.065% (30757/33408)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.065% (30875/33536)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.057% (30990/33664)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.060% (31109/33792)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.040% (31220/33920)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.061% (31345/34048)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.065% (31464/34176)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.080% (31587/34304)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.086% (31707/34432)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.083% (31824/34560)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.092% (31945/34688)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.093% (32063/34816)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.102% (32184/34944)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.122% (32309/35072)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.116% (32425/35200)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.128% (32547/35328)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.120% (32662/35456)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.112% (32777/35584)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.117% (32897/35712)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.112% (33013/35840)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.121% (33134/35968)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.124% (33253/36096)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.132% (33374/36224)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.132% (33492/36352)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.124% (33607/36480)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.133% (33728/36608)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.136% (33847/36736)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.139% (33966/36864)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.133% (34082/36992)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.131% (34199/37120)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.131% (34317/37248)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.142% (34439/37376)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.150% (34560/37504)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.153% (34679/37632)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.153% (34797/37760)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.153% (34915/37888)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.151% (35032/38016)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.146% (35148/38144)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.143% (35265/38272)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.135% (35380/38400)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.136% (35498/38528)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.149% (35621/38656)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.146% (35738/38784)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.146% (35856/38912)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.147% (35974/39040)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.147% (36092/39168)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.157% (36214/39296)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.170% (36337/39424)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.180% (36459/39552)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.175% (36575/39680)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.185% (36697/39808)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.182% (36814/39936)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.190% (36935/40064)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.200% (37057/40192)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.202% (37176/40320)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.200% (37293/40448)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.205% (37413/40576)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.202% (37530/40704)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.210% (37651/40832)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.205% (37767/40960)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.185% (37877/41088)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.178% (37992/41216)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.168% (38106/41344)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.163% (38222/41472)\n",
      "Train Epoch: 73 | Loss: 0.226 | Acc: 92.163% (38340/41600)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.164% (38458/41728)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.166% (38577/41856)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.171% (38697/41984)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.161% (38811/42112)\n",
      "Train Epoch: 73 | Loss: 0.227 | Acc: 92.164% (38930/42240)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.143% (39039/42368)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.145% (39158/42496)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.141% (39274/42624)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.134% (39389/42752)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.132% (39506/42880)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.136% (39626/43008)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.130% (39741/43136)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.127% (39858/43264)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.130% (39977/43392)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.130% (40095/43520)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.130% (40213/43648)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.133% (40332/43776)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.126% (40447/43904)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.124% (40564/44032)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.115% (40678/44160)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.118% (40797/44288)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.118% (40915/44416)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.129% (41038/44544)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.127% (41155/44672)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.134% (41276/44800)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.139% (41396/44928)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.150% (41519/45056)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.145% (41635/45184)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.146% (41753/45312)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.143% (41870/45440)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.141% (41987/45568)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.133% (42101/45696)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.133% (42219/45824)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.127% (42334/45952)\n",
      "Train Epoch: 73 | Loss: 0.228 | Acc: 92.122% (42450/46080)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.105% (42560/46208)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.101% (42676/46336)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.091% (42789/46464)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.097% (42910/46592)\n",
      "Train Epoch: 73 | Loss: 0.229 | Acc: 92.089% (43024/46720)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.085% (43140/46848)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.090% (43260/46976)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.083% (43375/47104)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.077% (43490/47232)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.067% (43603/47360)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.067% (43721/47488)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.055% (43833/47616)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.060% (43953/47744)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.058% (44070/47872)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.071% (44194/48000)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.071% (44312/48128)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.059% (44424/48256)\n",
      "Train Epoch: 73 | Loss: 0.231 | Acc: 92.057% (44541/48384)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.068% (44664/48512)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.076% (44786/48640)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.083% (44907/48768)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.073% (45020/48896)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.077% (45140/49024)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.080% (45259/49152)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.074% (45374/49280)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.070% (45490/49408)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.058% (45602/49536)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.061% (45721/49664)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.069% (45843/49792)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.059% (45956/49920)\n",
      "Train Epoch: 73 | Loss: 0.230 | Acc: 92.056% (46028/50000)\n",
      "Test Epoch: 73 | Loss: 0.308 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 73 | Loss: 0.337 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 73 | Loss: 0.320 | Acc: 89.750% (359/400)\n",
      "Test Epoch: 73 | Loss: 0.302 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 73 | Loss: 0.277 | Acc: 90.667% (544/600)\n",
      "Test Epoch: 73 | Loss: 0.275 | Acc: 90.714% (635/700)\n",
      "Test Epoch: 73 | Loss: 0.315 | Acc: 89.500% (716/800)\n",
      "Test Epoch: 73 | Loss: 0.344 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 73 | Loss: 0.334 | Acc: 89.500% (895/1000)\n",
      "Test Epoch: 73 | Loss: 0.335 | Acc: 89.091% (980/1100)\n",
      "Test Epoch: 73 | Loss: 0.334 | Acc: 88.833% (1066/1200)\n",
      "Test Epoch: 73 | Loss: 0.333 | Acc: 88.846% (1155/1300)\n",
      "Test Epoch: 73 | Loss: 0.331 | Acc: 88.786% (1243/1400)\n",
      "Test Epoch: 73 | Loss: 0.332 | Acc: 88.733% (1331/1500)\n",
      "Test Epoch: 73 | Loss: 0.333 | Acc: 88.625% (1418/1600)\n",
      "Test Epoch: 73 | Loss: 0.328 | Acc: 89.000% (1513/1700)\n",
      "Test Epoch: 73 | Loss: 0.342 | Acc: 88.833% (1599/1800)\n",
      "Test Epoch: 73 | Loss: 0.342 | Acc: 88.789% (1687/1900)\n",
      "Test Epoch: 73 | Loss: 0.344 | Acc: 88.850% (1777/2000)\n",
      "Test Epoch: 73 | Loss: 0.349 | Acc: 88.762% (1864/2100)\n",
      "Test Epoch: 73 | Loss: 0.346 | Acc: 88.682% (1951/2200)\n",
      "Test Epoch: 73 | Loss: 0.351 | Acc: 88.565% (2037/2300)\n",
      "Test Epoch: 73 | Loss: 0.348 | Acc: 88.625% (2127/2400)\n",
      "Test Epoch: 73 | Loss: 0.361 | Acc: 88.240% (2206/2500)\n",
      "Test Epoch: 73 | Loss: 0.370 | Acc: 88.077% (2290/2600)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.111% (2379/2700)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.107% (2467/2800)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.103% (2555/2900)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.067% (2642/3000)\n",
      "Test Epoch: 73 | Loss: 0.377 | Acc: 88.065% (2730/3100)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.219% (2823/3200)\n",
      "Test Epoch: 73 | Loss: 0.371 | Acc: 88.152% (2909/3300)\n",
      "Test Epoch: 73 | Loss: 0.371 | Acc: 88.176% (2998/3400)\n",
      "Test Epoch: 73 | Loss: 0.376 | Acc: 88.086% (3083/3500)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.167% (3174/3600)\n",
      "Test Epoch: 73 | Loss: 0.377 | Acc: 88.108% (3260/3700)\n",
      "Test Epoch: 73 | Loss: 0.379 | Acc: 88.079% (3347/3800)\n",
      "Test Epoch: 73 | Loss: 0.375 | Acc: 88.103% (3436/3900)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.150% (3526/4000)\n",
      "Test Epoch: 73 | Loss: 0.375 | Acc: 88.146% (3614/4100)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.167% (3703/4200)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.279% (3796/4300)\n",
      "Test Epoch: 73 | Loss: 0.368 | Acc: 88.386% (3889/4400)\n",
      "Test Epoch: 73 | Loss: 0.369 | Acc: 88.378% (3977/4500)\n",
      "Test Epoch: 73 | Loss: 0.370 | Acc: 88.413% (4067/4600)\n",
      "Test Epoch: 73 | Loss: 0.368 | Acc: 88.447% (4157/4700)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.312% (4239/4800)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.388% (4331/4900)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.300% (4415/5000)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.314% (4504/5100)\n",
      "Test Epoch: 73 | Loss: 0.376 | Acc: 88.192% (4586/5200)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.208% (4675/5300)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.185% (4762/5400)\n",
      "Test Epoch: 73 | Loss: 0.376 | Acc: 88.091% (4845/5500)\n",
      "Test Epoch: 73 | Loss: 0.376 | Acc: 88.107% (4934/5600)\n",
      "Test Epoch: 73 | Loss: 0.375 | Acc: 88.140% (5024/5700)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.190% (5115/5800)\n",
      "Test Epoch: 73 | Loss: 0.374 | Acc: 88.169% (5202/5900)\n",
      "Test Epoch: 73 | Loss: 0.373 | Acc: 88.183% (5291/6000)\n",
      "Test Epoch: 73 | Loss: 0.372 | Acc: 88.180% (5379/6100)\n",
      "Test Epoch: 73 | Loss: 0.371 | Acc: 88.210% (5469/6200)\n",
      "Test Epoch: 73 | Loss: 0.369 | Acc: 88.286% (5562/6300)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.344% (5654/6400)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.323% (5741/6500)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.379% (5833/6600)\n",
      "Test Epoch: 73 | Loss: 0.364 | Acc: 88.418% (5924/6700)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.397% (6011/6800)\n",
      "Test Epoch: 73 | Loss: 0.363 | Acc: 88.435% (6102/6900)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.371% (6186/7000)\n",
      "Test Epoch: 73 | Loss: 0.368 | Acc: 88.338% (6272/7100)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.375% (6363/7200)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.452% (6457/7300)\n",
      "Test Epoch: 73 | Loss: 0.363 | Acc: 88.514% (6550/7400)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.493% (6637/7500)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.526% (6728/7600)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.519% (6816/7700)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.513% (6904/7800)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.519% (6993/7900)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.537% (7083/8000)\n",
      "Test Epoch: 73 | Loss: 0.364 | Acc: 88.568% (7174/8100)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.512% (7258/8200)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.470% (7343/8300)\n",
      "Test Epoch: 73 | Loss: 0.365 | Acc: 88.464% (7431/8400)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.471% (7520/8500)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.407% (7603/8600)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.414% (7692/8700)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.398% (7779/8800)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.393% (7867/8900)\n",
      "Test Epoch: 73 | Loss: 0.367 | Acc: 88.389% (7955/9000)\n",
      "Test Epoch: 73 | Loss: 0.366 | Acc: 88.418% (8046/9100)\n",
      "Test Epoch: 73 | Loss: 0.364 | Acc: 88.467% (8139/9200)\n",
      "Test Epoch: 73 | Loss: 0.364 | Acc: 88.462% (8227/9300)\n",
      "Test Epoch: 73 | Loss: 0.363 | Acc: 88.521% (8321/9400)\n",
      "Test Epoch: 73 | Loss: 0.362 | Acc: 88.547% (8412/9500)\n",
      "Test Epoch: 73 | Loss: 0.363 | Acc: 88.542% (8500/9600)\n",
      "Test Epoch: 73 | Loss: 0.361 | Acc: 88.577% (8592/9700)\n",
      "Test Epoch: 73 | Loss: 0.360 | Acc: 88.592% (8682/9800)\n",
      "Test Epoch: 73 | Loss: 0.360 | Acc: 88.596% (8771/9900)\n",
      "Test Epoch: 73 | Loss: 0.359 | Acc: 88.610% (8861/10000)\n",
      "\n",
      "Epoch: 74\n",
      "Train Epoch: 74 | Loss: 0.167 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 74 | Loss: 0.171 | Acc: 96.094% (246/256)\n",
      "Train Epoch: 74 | Loss: 0.194 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 74 | Loss: 0.178 | Acc: 95.117% (487/512)\n",
      "Train Epoch: 74 | Loss: 0.191 | Acc: 94.844% (607/640)\n",
      "Train Epoch: 74 | Loss: 0.183 | Acc: 94.922% (729/768)\n",
      "Train Epoch: 74 | Loss: 0.177 | Acc: 95.089% (852/896)\n",
      "Train Epoch: 74 | Loss: 0.176 | Acc: 95.020% (973/1024)\n",
      "Train Epoch: 74 | Loss: 0.182 | Acc: 94.705% (1091/1152)\n",
      "Train Epoch: 74 | Loss: 0.189 | Acc: 94.297% (1207/1280)\n",
      "Train Epoch: 74 | Loss: 0.194 | Acc: 94.105% (1325/1408)\n",
      "Train Epoch: 74 | Loss: 0.203 | Acc: 93.750% (1440/1536)\n",
      "Train Epoch: 74 | Loss: 0.204 | Acc: 93.690% (1559/1664)\n",
      "Train Epoch: 74 | Loss: 0.198 | Acc: 93.806% (1681/1792)\n",
      "Train Epoch: 74 | Loss: 0.198 | Acc: 93.854% (1802/1920)\n",
      "Train Epoch: 74 | Loss: 0.199 | Acc: 93.750% (1920/2048)\n",
      "Train Epoch: 74 | Loss: 0.196 | Acc: 93.796% (2041/2176)\n",
      "Train Epoch: 74 | Loss: 0.197 | Acc: 93.663% (2158/2304)\n",
      "Train Epoch: 74 | Loss: 0.203 | Acc: 93.503% (2274/2432)\n",
      "Train Epoch: 74 | Loss: 0.203 | Acc: 93.516% (2394/2560)\n",
      "Train Epoch: 74 | Loss: 0.205 | Acc: 93.304% (2508/2688)\n",
      "Train Epoch: 74 | Loss: 0.206 | Acc: 93.359% (2629/2816)\n",
      "Train Epoch: 74 | Loss: 0.207 | Acc: 93.240% (2745/2944)\n",
      "Train Epoch: 74 | Loss: 0.209 | Acc: 93.164% (2862/3072)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 93.062% (2978/3200)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 93.029% (3096/3328)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.911% (3211/3456)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 92.941% (3331/3584)\n",
      "Train Epoch: 74 | Loss: 0.215 | Acc: 92.780% (3444/3712)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.786% (3563/3840)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 92.767% (3681/3968)\n",
      "Train Epoch: 74 | Loss: 0.210 | Acc: 92.773% (3800/4096)\n",
      "Train Epoch: 74 | Loss: 0.213 | Acc: 92.590% (3911/4224)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 92.670% (4033/4352)\n",
      "Train Epoch: 74 | Loss: 0.210 | Acc: 92.634% (4150/4480)\n",
      "Train Epoch: 74 | Loss: 0.209 | Acc: 92.708% (4272/4608)\n",
      "Train Epoch: 74 | Loss: 0.210 | Acc: 92.673% (4389/4736)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 92.599% (4504/4864)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.608% (4623/4992)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.598% (4741/5120)\n",
      "Train Epoch: 74 | Loss: 0.211 | Acc: 92.588% (4859/5248)\n",
      "Train Epoch: 74 | Loss: 0.213 | Acc: 92.522% (4974/5376)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.551% (5094/5504)\n",
      "Train Epoch: 74 | Loss: 0.212 | Acc: 92.543% (5212/5632)\n",
      "Train Epoch: 74 | Loss: 0.215 | Acc: 92.500% (5328/5760)\n",
      "Train Epoch: 74 | Loss: 0.214 | Acc: 92.527% (5448/5888)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.453% (5562/6016)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.546% (5686/6144)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.586% (5807/6272)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.594% (5926/6400)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.509% (6039/6528)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.488% (6156/6656)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.497% (6275/6784)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.477% (6392/6912)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.443% (6508/7040)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.425% (6625/7168)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.407% (6742/7296)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.336% (6855/7424)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.333% (6973/7552)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.357% (7093/7680)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.328% (7209/7808)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.301% (7325/7936)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.336% (7446/8064)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.297% (7561/8192)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.332% (7682/8320)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.353% (7802/8448)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.351% (7920/8576)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.417% (8044/8704)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.414% (8162/8832)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.422% (8281/8960)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.441% (8401/9088)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.480% (8523/9216)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.519% (8645/9344)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.515% (8763/9472)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.448% (8875/9600)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.414% (8990/9728)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.431% (9110/9856)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.388% (9224/9984)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.366% (9340/10112)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.393% (9461/10240)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.361% (9576/10368)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.416% (9700/10496)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.442% (9821/10624)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.411% (9936/10752)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.381% (10051/10880)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.396% (10171/11008)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.403% (10290/11136)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.365% (10404/11264)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.381% (10524/11392)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.405% (10645/11520)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.419% (10765/11648)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.451% (10887/11776)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.456% (11006/11904)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.462% (11125/12032)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.492% (11247/12160)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.513% (11368/12288)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.502% (11485/12416)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.514% (11605/12544)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.503% (11722/12672)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.508% (11841/12800)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.536% (11963/12928)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.517% (12079/13056)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.536% (12200/13184)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.518% (12316/13312)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.537% (12437/13440)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.549% (12557/13568)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.567% (12678/13696)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.593% (12800/13824)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.575% (12916/13952)\n",
      "Train Epoch: 74 | Loss: 0.216 | Acc: 92.607% (13039/14080)\n",
      "Train Epoch: 74 | Loss: 0.217 | Acc: 92.561% (13151/14208)\n",
      "Train Epoch: 74 | Loss: 0.218 | Acc: 92.543% (13267/14336)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.485% (13377/14464)\n",
      "Train Epoch: 74 | Loss: 0.219 | Acc: 92.503% (13498/14592)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.466% (13611/14720)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.464% (13729/14848)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.415% (13840/14976)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.399% (13956/15104)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.417% (14077/15232)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.441% (14199/15360)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.426% (14315/15488)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.444% (14436/15616)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.448% (14555/15744)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.433% (14671/15872)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.425% (14788/16000)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.442% (14909/16128)\n",
      "Train Epoch: 74 | Loss: 0.220 | Acc: 92.483% (15034/16256)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.487% (15153/16384)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.484% (15271/16512)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.476% (15388/16640)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.486% (15508/16768)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.424% (15616/16896)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.422% (15734/17024)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.421% (15852/17152)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.407% (15968/17280)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.406% (16086/17408)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.421% (16207/17536)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.437% (16328/17664)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.429% (16445/17792)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.427% (16563/17920)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.415% (16679/18048)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.402% (16795/18176)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.411% (16915/18304)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.421% (17035/18432)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.403% (17150/18560)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.396% (17267/18688)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.384% (17383/18816)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.367% (17498/18944)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.392% (17621/19072)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.406% (17742/19200)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.410% (17861/19328)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.424% (17982/19456)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.438% (18103/19584)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.406% (18215/19712)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.389% (18330/19840)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.398% (18450/19968)\n",
      "Train Epoch: 74 | Loss: 0.221 | Acc: 92.396% (18568/20096)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.370% (18681/20224)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.364% (18798/20352)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.373% (18918/20480)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.382% (19038/20608)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.385% (19157/20736)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.389% (19276/20864)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.397% (19396/20992)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.372% (19509/21120)\n",
      "Train Epoch: 74 | Loss: 0.222 | Acc: 92.357% (19624/21248)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.337% (19738/21376)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.313% (19851/21504)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.317% (19970/21632)\n",
      "Train Epoch: 74 | Loss: 0.224 | Acc: 92.307% (20086/21760)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.311% (20205/21888)\n",
      "Train Epoch: 74 | Loss: 0.223 | Acc: 92.315% (20324/22016)\n",
      "Train Epoch: 74 | Loss: 0.224 | Acc: 92.296% (20438/22144)\n",
      "Train Epoch: 74 | Loss: 0.224 | Acc: 92.286% (20554/22272)\n",
      "Train Epoch: 74 | Loss: 0.224 | Acc: 92.272% (20669/22400)\n",
      "Train Epoch: 74 | Loss: 0.224 | Acc: 92.276% (20788/22528)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.223% (20894/22656)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.227% (21013/22784)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.222% (21130/22912)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.209% (21245/23040)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.200% (21361/23168)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.196% (21478/23296)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.196% (21596/23424)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.200% (21715/23552)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.200% (21833/23680)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.209% (21953/23808)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.225% (22075/23936)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.221% (22192/24064)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.204% (22306/24192)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.212% (22426/24320)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.192% (22539/24448)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.196% (22658/24576)\n",
      "Train Epoch: 74 | Loss: 0.225 | Acc: 92.192% (22775/24704)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.159% (22885/24832)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.151% (23001/24960)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.136% (23115/25088)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.128% (23231/25216)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.132% (23350/25344)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.133% (23468/25472)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.109% (23580/25600)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.090% (23693/25728)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.087% (23810/25856)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.091% (23929/25984)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.111% (24052/26112)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.107% (24169/26240)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.115% (24289/26368)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.120% (24408/26496)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.120% (24526/26624)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.113% (24642/26752)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.094% (24755/26880)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.110% (24877/27008)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.103% (24993/27136)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.107% (25112/27264)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.111% (25231/27392)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.097% (25345/27520)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.097% (25463/27648)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.105% (25583/27776)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.091% (25697/27904)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.095% (25816/28032)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.095% (25934/28160)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.092% (26051/28288)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.096% (26170/28416)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.082% (26284/28544)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.083% (26402/28672)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.059% (26513/28800)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.063% (26632/28928)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.070% (26752/29056)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.071% (26870/29184)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.072% (26988/29312)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.069% (27105/29440)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.069% (27223/29568)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.073% (27342/29696)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.087% (27464/29824)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.084% (27581/29952)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.068% (27694/30080)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.072% (27813/30208)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.075% (27932/30336)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.076% (28050/30464)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.086% (28171/30592)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.087% (28289/30720)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.084% (28406/30848)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.081% (28523/30976)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.091% (28644/31104)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.101% (28765/31232)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.111% (28886/31360)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.111% (29004/31488)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.105% (29120/31616)\n",
      "Train Epoch: 74 | Loss: 0.226 | Acc: 92.093% (29234/31744)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.084% (29349/31872)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.100% (29472/32000)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.082% (29584/32128)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.091% (29705/32256)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.083% (29820/32384)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.083% (29938/32512)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.071% (30052/32640)\n",
      "Train Epoch: 74 | Loss: 0.227 | Acc: 92.075% (30171/32768)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.060% (30284/32896)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.054% (30400/33024)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.055% (30518/33152)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.043% (30632/33280)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.038% (30748/33408)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.041% (30867/33536)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.042% (30985/33664)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.040% (31102/33792)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.049% (31223/33920)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.049% (31341/34048)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.041% (31456/34176)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.030% (31570/34304)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.034% (31689/34432)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.034% (31807/34560)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.038% (31926/34688)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.027% (32040/34816)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.036% (32161/34944)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.031% (32277/35072)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.028% (32394/35200)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.029% (32512/35328)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.021% (32627/35456)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.019% (32744/35584)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.000% (32855/35712)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.006% (32975/35840)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.018% (33097/35968)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.007% (33211/36096)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.014% (33331/36224)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.011% (33448/36352)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.020% (33569/36480)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.021% (33687/36608)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.024% (33806/36736)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.033% (33927/36864)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.039% (34047/36992)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.039% (34165/37120)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.045% (34285/37248)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.048% (34404/37376)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.046% (34521/37504)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.052% (34641/37632)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.063% (34763/37760)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.069% (34883/37888)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.077% (35004/38016)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.093% (35128/38144)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.101% (35249/38272)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.104% (35368/38400)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.094% (35482/38528)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.105% (35604/38656)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.110% (35724/38784)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.113% (35843/38912)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.111% (35960/39040)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.124% (36083/39168)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.116% (36198/39296)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.111% (36314/39424)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.104% (36429/39552)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.112% (36550/39680)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.120% (36671/39808)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.125% (36791/39936)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.123% (36908/40064)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.128% (37028/40192)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.116% (37141/40320)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.128% (37264/40448)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.109% (37374/40576)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.111% (37493/40704)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.102% (37607/40832)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.097% (37723/40960)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.093% (37839/41088)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.095% (37958/41216)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.100% (38078/41344)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.106% (38198/41472)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.108% (38317/41600)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.101% (38432/41728)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.101% (38550/41856)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.107% (38670/41984)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.102% (38786/42112)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.109% (38907/42240)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.121% (39030/42368)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.115% (39145/42496)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.119% (39265/42624)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.117% (39382/42752)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.115% (39499/42880)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.108% (39614/43008)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.116% (39735/43136)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.118% (39854/43264)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.116% (39971/43392)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.114% (40088/43520)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.114% (40206/43648)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.110% (40322/43776)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.106% (40438/43904)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.094% (40551/44032)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.101% (40672/44160)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.099% (40789/44288)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.109% (40911/44416)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.104% (41027/44544)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.107% (41146/44672)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.100% (41261/44800)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.112% (41384/44928)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.114% (41503/45056)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.108% (41618/45184)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.117% (41740/45312)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.104% (41852/45440)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.108% (41972/45568)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.098% (42085/45696)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.102% (42205/45824)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.098% (42321/45952)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.101% (42440/46080)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.097% (42556/46208)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.099% (42675/46336)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.093% (42790/46464)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.104% (42913/46592)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.102% (43030/46720)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.106% (43150/46848)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.107% (43268/46976)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.120% (43392/47104)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.101% (43501/47232)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.107% (43622/47360)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.107% (43740/47488)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.118% (43863/47616)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.114% (43979/47744)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.114% (44097/47872)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.108% (44212/48000)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.115% (44333/48128)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.125% (44456/48256)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.125% (44574/48384)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.117% (44688/48512)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.113% (44804/48640)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.110% (44920/48768)\n",
      "Train Epoch: 74 | Loss: 0.228 | Acc: 92.100% (45033/48896)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.090% (45146/49024)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.086% (45262/49152)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.084% (45379/49280)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.080% (45495/49408)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.078% (45612/49536)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.085% (45733/49664)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.073% (45845/49792)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.075% (45964/49920)\n",
      "Train Epoch: 74 | Loss: 0.229 | Acc: 92.070% (46035/50000)\n",
      "Test Epoch: 74 | Loss: 0.330 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 74 | Loss: 0.412 | Acc: 87.500% (175/200)\n",
      "Test Epoch: 74 | Loss: 0.371 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 74 | Loss: 0.350 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 74 | Loss: 0.317 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 74 | Loss: 0.288 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 74 | Loss: 0.280 | Acc: 91.429% (640/700)\n",
      "Test Epoch: 74 | Loss: 0.304 | Acc: 90.500% (724/800)\n",
      "Test Epoch: 74 | Loss: 0.315 | Acc: 90.333% (813/900)\n",
      "Test Epoch: 74 | Loss: 0.323 | Acc: 89.900% (899/1000)\n",
      "Test Epoch: 74 | Loss: 0.331 | Acc: 89.455% (984/1100)\n",
      "Test Epoch: 74 | Loss: 0.326 | Acc: 89.583% (1075/1200)\n",
      "Test Epoch: 74 | Loss: 0.321 | Acc: 89.615% (1165/1300)\n",
      "Test Epoch: 74 | Loss: 0.319 | Acc: 89.643% (1255/1400)\n",
      "Test Epoch: 74 | Loss: 0.319 | Acc: 89.400% (1341/1500)\n",
      "Test Epoch: 74 | Loss: 0.318 | Acc: 89.500% (1432/1600)\n",
      "Test Epoch: 74 | Loss: 0.317 | Acc: 89.647% (1524/1700)\n",
      "Test Epoch: 74 | Loss: 0.320 | Acc: 89.500% (1611/1800)\n",
      "Test Epoch: 74 | Loss: 0.318 | Acc: 89.526% (1701/1900)\n",
      "Test Epoch: 74 | Loss: 0.319 | Acc: 89.550% (1791/2000)\n",
      "Test Epoch: 74 | Loss: 0.318 | Acc: 89.524% (1880/2100)\n",
      "Test Epoch: 74 | Loss: 0.323 | Acc: 89.273% (1964/2200)\n",
      "Test Epoch: 74 | Loss: 0.326 | Acc: 89.217% (2052/2300)\n",
      "Test Epoch: 74 | Loss: 0.322 | Acc: 89.292% (2143/2400)\n",
      "Test Epoch: 74 | Loss: 0.330 | Acc: 89.080% (2227/2500)\n",
      "Test Epoch: 74 | Loss: 0.340 | Acc: 88.885% (2311/2600)\n",
      "Test Epoch: 74 | Loss: 0.336 | Acc: 88.926% (2401/2700)\n",
      "Test Epoch: 74 | Loss: 0.338 | Acc: 89.000% (2492/2800)\n",
      "Test Epoch: 74 | Loss: 0.339 | Acc: 88.966% (2580/2900)\n",
      "Test Epoch: 74 | Loss: 0.341 | Acc: 88.833% (2665/3000)\n",
      "Test Epoch: 74 | Loss: 0.344 | Acc: 88.742% (2751/3100)\n",
      "Test Epoch: 74 | Loss: 0.346 | Acc: 88.656% (2837/3200)\n",
      "Test Epoch: 74 | Loss: 0.346 | Acc: 88.758% (2929/3300)\n",
      "Test Epoch: 74 | Loss: 0.346 | Acc: 88.735% (3017/3400)\n",
      "Test Epoch: 74 | Loss: 0.350 | Acc: 88.657% (3103/3500)\n",
      "Test Epoch: 74 | Loss: 0.347 | Acc: 88.778% (3196/3600)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.703% (3282/3700)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.632% (3368/3800)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.641% (3457/3900)\n",
      "Test Epoch: 74 | Loss: 0.352 | Acc: 88.725% (3549/4000)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.634% (3634/4100)\n",
      "Test Epoch: 74 | Loss: 0.356 | Acc: 88.667% (3724/4200)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.791% (3818/4300)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.864% (3910/4400)\n",
      "Test Epoch: 74 | Loss: 0.350 | Acc: 88.956% (4003/4500)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.870% (4088/4600)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.851% (4176/4700)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.792% (4262/4800)\n",
      "Test Epoch: 74 | Loss: 0.351 | Acc: 88.898% (4356/4900)\n",
      "Test Epoch: 74 | Loss: 0.357 | Acc: 88.820% (4441/5000)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.922% (4535/5100)\n",
      "Test Epoch: 74 | Loss: 0.358 | Acc: 88.846% (4620/5200)\n",
      "Test Epoch: 74 | Loss: 0.358 | Acc: 88.811% (4707/5300)\n",
      "Test Epoch: 74 | Loss: 0.358 | Acc: 88.815% (4796/5400)\n",
      "Test Epoch: 74 | Loss: 0.360 | Acc: 88.764% (4882/5500)\n",
      "Test Epoch: 74 | Loss: 0.363 | Acc: 88.679% (4966/5600)\n",
      "Test Epoch: 74 | Loss: 0.363 | Acc: 88.596% (5050/5700)\n",
      "Test Epoch: 74 | Loss: 0.362 | Acc: 88.655% (5142/5800)\n",
      "Test Epoch: 74 | Loss: 0.364 | Acc: 88.559% (5225/5900)\n",
      "Test Epoch: 74 | Loss: 0.364 | Acc: 88.583% (5315/6000)\n",
      "Test Epoch: 74 | Loss: 0.364 | Acc: 88.607% (5405/6100)\n",
      "Test Epoch: 74 | Loss: 0.365 | Acc: 88.548% (5490/6200)\n",
      "Test Epoch: 74 | Loss: 0.362 | Acc: 88.603% (5582/6300)\n",
      "Test Epoch: 74 | Loss: 0.357 | Acc: 88.766% (5681/6400)\n",
      "Test Epoch: 74 | Loss: 0.358 | Acc: 88.754% (5769/6500)\n",
      "Test Epoch: 74 | Loss: 0.356 | Acc: 88.818% (5862/6600)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.866% (5954/6700)\n",
      "Test Epoch: 74 | Loss: 0.357 | Acc: 88.794% (6038/6800)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.884% (6133/6900)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.843% (6219/7000)\n",
      "Test Epoch: 74 | Loss: 0.356 | Acc: 88.845% (6308/7100)\n",
      "Test Epoch: 74 | Loss: 0.357 | Acc: 88.847% (6397/7200)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.890% (6489/7300)\n",
      "Test Epoch: 74 | Loss: 0.352 | Acc: 88.919% (6580/7400)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.867% (6665/7500)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.868% (6754/7600)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.831% (6840/7700)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.833% (6929/7800)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.873% (7021/7900)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.825% (7106/8000)\n",
      "Test Epoch: 74 | Loss: 0.351 | Acc: 88.840% (7196/8100)\n",
      "Test Epoch: 74 | Loss: 0.352 | Acc: 88.854% (7286/8200)\n",
      "Test Epoch: 74 | Loss: 0.352 | Acc: 88.831% (7373/8300)\n",
      "Test Epoch: 74 | Loss: 0.351 | Acc: 88.845% (7463/8400)\n",
      "Test Epoch: 74 | Loss: 0.351 | Acc: 88.847% (7552/8500)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.779% (7635/8600)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.782% (7724/8700)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.739% (7809/8800)\n",
      "Test Epoch: 74 | Loss: 0.356 | Acc: 88.730% (7897/8900)\n",
      "Test Epoch: 74 | Loss: 0.355 | Acc: 88.733% (7986/9000)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.747% (8076/9100)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.772% (8167/9200)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.763% (8255/9300)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.809% (8348/9400)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.811% (8437/9500)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.823% (8527/9600)\n",
      "Test Epoch: 74 | Loss: 0.354 | Acc: 88.814% (8615/9700)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.837% (8706/9800)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.828% (8794/9900)\n",
      "Test Epoch: 74 | Loss: 0.353 | Acc: 88.840% (8884/10000)\n",
      "\n",
      "Epoch: 75\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 75 | Loss: 0.241 | Acc: 91.667% (352/384)\n",
      "Train Epoch: 75 | Loss: 0.231 | Acc: 92.188% (472/512)\n",
      "Train Epoch: 75 | Loss: 0.232 | Acc: 92.656% (593/640)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.969% (714/768)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.857% (832/896)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.676% (949/1024)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.708% (1068/1152)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.656% (1186/1280)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.614% (1304/1408)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.578% (1422/1536)\n",
      "Train Epoch: 75 | Loss: 0.214 | Acc: 92.788% (1544/1664)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.522% (1658/1792)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.292% (1772/1920)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.188% (1888/2048)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.004% (2002/2176)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.101% (2122/2304)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 91.941% (2236/2432)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 91.992% (2355/2560)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.001% (2473/2688)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.045% (2592/2816)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.289% (2717/2944)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.188% (2832/3072)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.125% (2948/3200)\n",
      "Train Epoch: 75 | Loss: 0.230 | Acc: 92.007% (3062/3328)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.130% (3184/3456)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.243% (3306/3584)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.349% (3428/3712)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.370% (3547/3840)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.288% (3662/3968)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.334% (3782/4096)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.401% (3903/4224)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.348% (4019/4352)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.366% (4138/4480)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.339% (4255/4608)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.441% (4378/4736)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.434% (4496/4864)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.428% (4614/4992)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.422% (4732/5120)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.473% (4853/5248)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.504% (4973/5376)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.424% (5087/5504)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.436% (5206/5632)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.378% (5321/5760)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.340% (5437/5888)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.271% (5551/6016)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.188% (5664/6144)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.203% (5783/6272)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.234% (5903/6400)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.218% (6020/6528)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.278% (6142/6656)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.364% (6266/6784)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.361% (6384/6912)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.415% (6506/7040)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.411% (6624/7168)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.393% (6741/7296)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.443% (6863/7424)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.386% (6977/7552)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.448% (7100/7680)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.431% (7217/7808)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.427% (7335/7936)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.460% (7456/8064)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.468% (7575/8192)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.464% (7693/8320)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.495% (7814/8448)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.502% (7933/8576)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.475% (8049/8704)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.482% (8168/8832)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.489% (8287/8960)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.496% (8406/9088)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.502% (8525/9216)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.476% (8641/9344)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.409% (8753/9472)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.427% (8873/9600)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.465% (8995/9728)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.492% (9116/9856)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.518% (9237/9984)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.455% (9349/10112)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.461% (9468/10240)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.506% (9591/10368)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.473% (9706/10496)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.442% (9821/10624)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.420% (9937/10752)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.426% (10056/10880)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.415% (10173/11008)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.385% (10288/11136)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.383% (10406/11264)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.416% (10528/11392)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.448% (10650/11520)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.436% (10767/11648)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.459% (10888/11776)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.465% (11007/11904)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.520% (11132/12032)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.533% (11252/12160)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.546% (11372/12288)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.590% (11496/12416)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.586% (11614/12544)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.606% (11735/12672)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.602% (11853/12800)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.636% (11976/12928)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.578% (12087/13056)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.605% (12209/13184)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.563% (12322/13312)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.612% (12447/13440)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.585% (12562/13568)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.567% (12678/13696)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.556% (12795/13824)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.553% (12913/13952)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.585% (13036/14080)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.589% (13155/14208)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.578% (13272/14336)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.547% (13386/14464)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.571% (13508/14592)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.561% (13625/14720)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.551% (13742/14848)\n",
      "Train Epoch: 75 | Loss: 0.217 | Acc: 92.541% (13859/14976)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.532% (13976/15104)\n",
      "Train Epoch: 75 | Loss: 0.218 | Acc: 92.509% (14091/15232)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.493% (14207/15360)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.478% (14323/15488)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.456% (14438/15616)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.480% (14560/15744)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.471% (14677/15872)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.463% (14794/16000)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.454% (14911/16128)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.470% (15032/16256)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.474% (15151/16384)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.490% (15272/16512)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.482% (15389/16640)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.468% (15505/16768)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.412% (15614/16896)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.417% (15733/17024)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.427% (15853/17152)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.419% (15970/17280)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.446% (16093/17408)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.444% (16211/17536)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.465% (16333/17664)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.497% (16457/17792)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.467% (16570/17920)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.487% (16692/18048)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.452% (16804/18176)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.466% (16925/18304)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.491% (17048/18432)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.484% (17165/18560)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.487% (17284/18688)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.490% (17403/18816)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.494% (17522/18944)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.513% (17644/19072)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.500% (17760/19200)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.493% (17877/19328)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.496% (17996/19456)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.484% (18112/19584)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.512% (18236/19712)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.510% (18354/19840)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.513% (18473/19968)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.531% (18595/20096)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.514% (18710/20224)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.512% (18828/20352)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.480% (18940/20480)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.498% (19062/20608)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.511% (19183/20736)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.533% (19306/20864)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.535% (19425/20992)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.552% (19547/21120)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.555% (19666/21248)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.538% (19781/21376)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.546% (19901/21504)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.534% (20017/21632)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.537% (20136/21760)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.544% (20256/21888)\n",
      "Train Epoch: 75 | Loss: 0.219 | Acc: 92.560% (20378/22016)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.544% (20493/22144)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.529% (20608/22272)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.531% (20727/22400)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.525% (20844/22528)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.541% (20966/22656)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.556% (21088/22784)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.532% (21201/22912)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.535% (21320/23040)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.520% (21435/23168)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.531% (21556/23296)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.538% (21676/23424)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.531% (21793/23552)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.538% (21913/23680)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.532% (22030/23808)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.538% (22150/23936)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.557% (22273/24064)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.576% (22396/24192)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.566% (22512/24320)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.552% (22627/24448)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.550% (22745/24576)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.572% (22869/24704)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.570% (22987/24832)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.572% (23106/24960)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.574% (23225/25088)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.568% (23342/25216)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.570% (23461/25344)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.576% (23581/25472)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.555% (23694/25600)\n",
      "Train Epoch: 75 | Loss: 0.220 | Acc: 92.565% (23815/25728)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.559% (23932/25856)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.553% (24049/25984)\n",
      "Train Epoch: 75 | Loss: 0.221 | Acc: 92.525% (24160/26112)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.489% (24269/26240)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.491% (24388/26368)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.478% (24503/26496)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.458% (24616/26624)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.445% (24731/26752)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.440% (24848/26880)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.428% (24963/27008)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.427% (25081/27136)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.404% (25193/27264)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.403% (25311/27392)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.402% (25429/27520)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.401% (25547/27648)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.407% (25667/27776)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.403% (25784/27904)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.402% (25902/28032)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.408% (26022/28160)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.410% (26141/28288)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.413% (26260/28416)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.405% (26376/28544)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.414% (26497/28672)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.424% (26618/28800)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.412% (26733/28928)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.401% (26848/29056)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.410% (26969/29184)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.399% (27084/29312)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.405% (27204/29440)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.417% (27326/29568)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.420% (27445/29696)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.409% (27560/29824)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.415% (27680/29952)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.400% (27794/30080)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.380% (27906/30208)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.389% (28027/30336)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.381% (28143/30464)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.384% (28262/30592)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.399% (28385/30720)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.401% (28504/30848)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.401% (28622/30976)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.409% (28743/31104)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.405% (28860/31232)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.395% (28975/31360)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.403% (29096/31488)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.396% (29212/31616)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.392% (29329/31744)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.407% (29452/31872)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.416% (29573/32000)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.412% (29690/32128)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.423% (29812/32256)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.422% (29930/32384)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.427% (30050/32512)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.433% (30170/32640)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.429% (30287/32768)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.412% (30400/32896)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.427% (30523/33024)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.426% (30641/33152)\n",
      "Train Epoch: 75 | Loss: 0.222 | Acc: 92.443% (30765/33280)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.436% (30881/33408)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.432% (30998/33536)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.425% (31114/33664)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.424% (31232/33792)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.406% (31344/33920)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.408% (31463/34048)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.416% (31584/34176)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.409% (31700/34304)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.405% (31817/34432)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.399% (31933/34560)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.404% (32053/34688)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.414% (32175/34816)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.411% (32292/34944)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.413% (32411/35072)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.409% (32528/35200)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.405% (32645/35328)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.416% (32767/35456)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.421% (32887/35584)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.431% (33009/35712)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.416% (33122/35840)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.415% (33240/35968)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.426% (33362/36096)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.430% (33482/36224)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.427% (33599/36352)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.429% (33718/36480)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.433% (33838/36608)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.427% (33954/36736)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.426% (34072/36864)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.428% (34191/36992)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.416% (34305/37120)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.418% (34424/37248)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.410% (34539/37376)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.395% (34652/37504)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.403% (34773/37632)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.405% (34892/37760)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.407% (35011/37888)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.403% (35128/38016)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.402% (35246/38144)\n",
      "Train Epoch: 75 | Loss: 0.223 | Acc: 92.397% (35362/38272)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.391% (35478/38400)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.380% (35592/38528)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.374% (35708/38656)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.371% (35825/38784)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.370% (35943/38912)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.369% (36061/39040)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.371% (36180/39168)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.366% (36296/39296)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.373% (36417/39424)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.382% (36539/39552)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.379% (36656/39680)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.376% (36773/39808)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.380% (36893/39936)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.375% (37009/40064)\n",
      "Train Epoch: 75 | Loss: 0.224 | Acc: 92.362% (37122/40192)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.356% (37238/40320)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.333% (37347/40448)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.338% (37467/40576)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.345% (37588/40704)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.334% (37702/40832)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.339% (37822/40960)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.331% (37937/41088)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.331% (38055/41216)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.333% (38174/41344)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.335% (38293/41472)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.339% (38413/41600)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.336% (38530/41728)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.343% (38651/41856)\n",
      "Train Epoch: 75 | Loss: 0.225 | Acc: 92.340% (38768/41984)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.337% (38885/42112)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.330% (39000/42240)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.327% (39117/42368)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.322% (39233/42496)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.333% (39356/42624)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.316% (39467/42752)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.311% (39583/42880)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.299% (39696/43008)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.285% (39808/43136)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.280% (39924/43264)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.277% (40041/43392)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.270% (40156/43520)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.272% (40275/43648)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.274% (40394/43776)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.279% (40514/43904)\n",
      "Train Epoch: 75 | Loss: 0.226 | Acc: 92.276% (40631/44032)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.280% (40751/44160)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.273% (40866/44288)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.260% (40978/44416)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.266% (41099/44544)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.264% (41216/44672)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.263% (41334/44800)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.259% (41450/44928)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.254% (41566/45056)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.249% (41682/45184)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.245% (41798/45312)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.245% (41916/45440)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.253% (42038/45568)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.249% (42154/45696)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.255% (42275/45824)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.264% (42397/45952)\n",
      "Train Epoch: 75 | Loss: 0.227 | Acc: 92.263% (42515/46080)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.252% (42628/46208)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.235% (42738/46336)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.237% (42857/46464)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.233% (42973/46592)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.230% (43090/46720)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.232% (43209/46848)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.245% (43333/46976)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.251% (43454/47104)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.247% (43570/47232)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.251% (43690/47360)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.261% (43813/47488)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.255% (43928/47616)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.263% (44050/47744)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.254% (44164/47872)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.242% (44276/48000)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.242% (44394/48128)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.243% (44513/48256)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.247% (44633/48384)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.245% (44750/48512)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.253% (44872/48640)\n",
      "Train Epoch: 75 | Loss: 0.228 | Acc: 92.257% (44992/48768)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.247% (45105/48896)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.249% (45224/49024)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.238% (45337/49152)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.244% (45458/49280)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.242% (45575/49408)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.240% (45692/49536)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.236% (45808/49664)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.248% (45932/49792)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.256% (46054/49920)\n",
      "Train Epoch: 75 | Loss: 0.229 | Acc: 92.250% (46125/50000)\n",
      "Test Epoch: 75 | Loss: 0.310 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 75 | Loss: 0.302 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 75 | Loss: 0.297 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 75 | Loss: 0.301 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 75 | Loss: 0.288 | Acc: 91.200% (456/500)\n",
      "Test Epoch: 75 | Loss: 0.277 | Acc: 91.667% (550/600)\n",
      "Test Epoch: 75 | Loss: 0.277 | Acc: 91.429% (640/700)\n",
      "Test Epoch: 75 | Loss: 0.303 | Acc: 90.125% (721/800)\n",
      "Test Epoch: 75 | Loss: 0.308 | Acc: 89.778% (808/900)\n",
      "Test Epoch: 75 | Loss: 0.310 | Acc: 90.000% (900/1000)\n",
      "Test Epoch: 75 | Loss: 0.303 | Acc: 90.091% (991/1100)\n",
      "Test Epoch: 75 | Loss: 0.304 | Acc: 89.750% (1077/1200)\n",
      "Test Epoch: 75 | Loss: 0.291 | Acc: 90.231% (1173/1300)\n",
      "Test Epoch: 75 | Loss: 0.296 | Acc: 90.071% (1261/1400)\n",
      "Test Epoch: 75 | Loss: 0.297 | Acc: 90.000% (1350/1500)\n",
      "Test Epoch: 75 | Loss: 0.297 | Acc: 90.000% (1440/1600)\n",
      "Test Epoch: 75 | Loss: 0.305 | Acc: 90.000% (1530/1700)\n",
      "Test Epoch: 75 | Loss: 0.310 | Acc: 89.778% (1616/1800)\n",
      "Test Epoch: 75 | Loss: 0.307 | Acc: 89.842% (1707/1900)\n",
      "Test Epoch: 75 | Loss: 0.310 | Acc: 89.850% (1797/2000)\n",
      "Test Epoch: 75 | Loss: 0.312 | Acc: 89.810% (1886/2100)\n",
      "Test Epoch: 75 | Loss: 0.310 | Acc: 89.773% (1975/2200)\n",
      "Test Epoch: 75 | Loss: 0.313 | Acc: 89.783% (2065/2300)\n",
      "Test Epoch: 75 | Loss: 0.312 | Acc: 89.708% (2153/2400)\n",
      "Test Epoch: 75 | Loss: 0.318 | Acc: 89.720% (2243/2500)\n",
      "Test Epoch: 75 | Loss: 0.326 | Acc: 89.615% (2330/2600)\n",
      "Test Epoch: 75 | Loss: 0.324 | Acc: 89.593% (2419/2700)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.571% (2508/2800)\n",
      "Test Epoch: 75 | Loss: 0.324 | Acc: 89.690% (2601/2900)\n",
      "Test Epoch: 75 | Loss: 0.329 | Acc: 89.467% (2684/3000)\n",
      "Test Epoch: 75 | Loss: 0.334 | Acc: 89.290% (2768/3100)\n",
      "Test Epoch: 75 | Loss: 0.331 | Acc: 89.375% (2860/3200)\n",
      "Test Epoch: 75 | Loss: 0.329 | Acc: 89.485% (2953/3300)\n",
      "Test Epoch: 75 | Loss: 0.327 | Acc: 89.529% (3044/3400)\n",
      "Test Epoch: 75 | Loss: 0.331 | Acc: 89.400% (3129/3500)\n",
      "Test Epoch: 75 | Loss: 0.333 | Acc: 89.333% (3216/3600)\n",
      "Test Epoch: 75 | Loss: 0.335 | Acc: 89.378% (3307/3700)\n",
      "Test Epoch: 75 | Loss: 0.337 | Acc: 89.263% (3392/3800)\n",
      "Test Epoch: 75 | Loss: 0.333 | Acc: 89.436% (3488/3900)\n",
      "Test Epoch: 75 | Loss: 0.334 | Acc: 89.400% (3576/4000)\n",
      "Test Epoch: 75 | Loss: 0.335 | Acc: 89.415% (3666/4100)\n",
      "Test Epoch: 75 | Loss: 0.335 | Acc: 89.429% (3756/4200)\n",
      "Test Epoch: 75 | Loss: 0.333 | Acc: 89.512% (3849/4300)\n",
      "Test Epoch: 75 | Loss: 0.331 | Acc: 89.614% (3943/4400)\n",
      "Test Epoch: 75 | Loss: 0.328 | Acc: 89.756% (4039/4500)\n",
      "Test Epoch: 75 | Loss: 0.329 | Acc: 89.783% (4130/4600)\n",
      "Test Epoch: 75 | Loss: 0.328 | Acc: 89.830% (4222/4700)\n",
      "Test Epoch: 75 | Loss: 0.329 | Acc: 89.708% (4306/4800)\n",
      "Test Epoch: 75 | Loss: 0.328 | Acc: 89.796% (4400/4900)\n",
      "Test Epoch: 75 | Loss: 0.329 | Acc: 89.800% (4490/5000)\n",
      "Test Epoch: 75 | Loss: 0.327 | Acc: 89.882% (4584/5100)\n",
      "Test Epoch: 75 | Loss: 0.327 | Acc: 89.885% (4674/5200)\n",
      "Test Epoch: 75 | Loss: 0.328 | Acc: 89.830% (4761/5300)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.889% (4854/5400)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.836% (4941/5500)\n",
      "Test Epoch: 75 | Loss: 0.326 | Acc: 89.768% (5027/5600)\n",
      "Test Epoch: 75 | Loss: 0.326 | Acc: 89.719% (5114/5700)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.776% (5207/5800)\n",
      "Test Epoch: 75 | Loss: 0.326 | Acc: 89.746% (5295/5900)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.783% (5387/6000)\n",
      "Test Epoch: 75 | Loss: 0.326 | Acc: 89.705% (5472/6100)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.694% (5561/6200)\n",
      "Test Epoch: 75 | Loss: 0.325 | Acc: 89.714% (5652/6300)\n",
      "Test Epoch: 75 | Loss: 0.322 | Acc: 89.828% (5749/6400)\n",
      "Test Epoch: 75 | Loss: 0.321 | Acc: 89.831% (5839/6500)\n",
      "Test Epoch: 75 | Loss: 0.319 | Acc: 89.879% (5932/6600)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.940% (6026/6700)\n",
      "Test Epoch: 75 | Loss: 0.319 | Acc: 89.897% (6113/6800)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.986% (6209/6900)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 90.000% (6300/7000)\n",
      "Test Epoch: 75 | Loss: 0.321 | Acc: 89.944% (6386/7100)\n",
      "Test Epoch: 75 | Loss: 0.321 | Acc: 89.958% (6477/7200)\n",
      "Test Epoch: 75 | Loss: 0.319 | Acc: 90.014% (6571/7300)\n",
      "Test Epoch: 75 | Loss: 0.316 | Acc: 90.068% (6665/7400)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.080% (6756/7500)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.066% (6845/7600)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.065% (6935/7700)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.103% (7028/7800)\n",
      "Test Epoch: 75 | Loss: 0.316 | Acc: 90.063% (7115/7900)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.050% (7204/8000)\n",
      "Test Epoch: 75 | Loss: 0.314 | Acc: 90.086% (7297/8100)\n",
      "Test Epoch: 75 | Loss: 0.313 | Acc: 90.110% (7389/8200)\n",
      "Test Epoch: 75 | Loss: 0.313 | Acc: 90.060% (7475/8300)\n",
      "Test Epoch: 75 | Loss: 0.313 | Acc: 90.071% (7566/8400)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 89.976% (7648/8500)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.919% (7733/8600)\n",
      "Test Epoch: 75 | Loss: 0.316 | Acc: 89.931% (7824/8700)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.898% (7911/8800)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.933% (8004/8900)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.956% (8096/9000)\n",
      "Test Epoch: 75 | Loss: 0.317 | Acc: 89.956% (8186/9100)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 89.989% (8279/9200)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 89.978% (8368/9300)\n",
      "Test Epoch: 75 | Loss: 0.314 | Acc: 90.011% (8461/9400)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 90.000% (8550/9500)\n",
      "Test Epoch: 75 | Loss: 0.315 | Acc: 89.969% (8637/9600)\n",
      "Test Epoch: 75 | Loss: 0.314 | Acc: 89.979% (8728/9700)\n",
      "Test Epoch: 75 | Loss: 0.313 | Acc: 89.980% (8818/9800)\n",
      "Test Epoch: 75 | Loss: 0.314 | Acc: 89.970% (8907/9900)\n",
      "Test Epoch: 75 | Loss: 0.314 | Acc: 89.940% (8994/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 76\n",
      "Train Epoch: 76 | Loss: 0.237 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 76 | Loss: 0.235 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.969% (476/512)\n",
      "Train Epoch: 76 | Loss: 0.197 | Acc: 93.594% (599/640)\n",
      "Train Epoch: 76 | Loss: 0.192 | Acc: 93.750% (720/768)\n",
      "Train Epoch: 76 | Loss: 0.205 | Acc: 92.969% (833/896)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.383% (946/1024)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.274% (1063/1152)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.614% (1304/1408)\n",
      "Train Epoch: 76 | Loss: 0.203 | Acc: 92.839% (1426/1536)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.849% (1545/1664)\n",
      "Train Epoch: 76 | Loss: 0.206 | Acc: 92.746% (1662/1792)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.552% (1777/1920)\n",
      "Train Epoch: 76 | Loss: 0.203 | Acc: 92.725% (1899/2048)\n",
      "Train Epoch: 76 | Loss: 0.209 | Acc: 92.417% (2011/2176)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.448% (2130/2304)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.516% (2250/2432)\n",
      "Train Epoch: 76 | Loss: 0.203 | Acc: 92.578% (2370/2560)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.560% (2488/2688)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.543% (2606/2816)\n",
      "Train Epoch: 76 | Loss: 0.205 | Acc: 92.561% (2725/2944)\n",
      "Train Epoch: 76 | Loss: 0.202 | Acc: 92.708% (2848/3072)\n",
      "Train Epoch: 76 | Loss: 0.201 | Acc: 92.812% (2970/3200)\n",
      "Train Epoch: 76 | Loss: 0.200 | Acc: 92.879% (3091/3328)\n",
      "Train Epoch: 76 | Loss: 0.201 | Acc: 92.824% (3208/3456)\n",
      "Train Epoch: 76 | Loss: 0.202 | Acc: 92.829% (3327/3584)\n",
      "Train Epoch: 76 | Loss: 0.200 | Acc: 92.888% (3448/3712)\n",
      "Train Epoch: 76 | Loss: 0.200 | Acc: 92.943% (3569/3840)\n",
      "Train Epoch: 76 | Loss: 0.201 | Acc: 92.893% (3686/3968)\n",
      "Train Epoch: 76 | Loss: 0.199 | Acc: 92.993% (3809/4096)\n",
      "Train Epoch: 76 | Loss: 0.199 | Acc: 93.040% (3930/4224)\n",
      "Train Epoch: 76 | Loss: 0.199 | Acc: 93.038% (4049/4352)\n",
      "Train Epoch: 76 | Loss: 0.198 | Acc: 93.080% (4170/4480)\n",
      "Train Epoch: 76 | Loss: 0.200 | Acc: 93.077% (4289/4608)\n",
      "Train Epoch: 76 | Loss: 0.202 | Acc: 93.032% (4406/4736)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.866% (4517/4864)\n",
      "Train Epoch: 76 | Loss: 0.206 | Acc: 92.829% (4634/4992)\n",
      "Train Epoch: 76 | Loss: 0.206 | Acc: 92.812% (4752/5120)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.759% (4868/5248)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.690% (4983/5376)\n",
      "Train Epoch: 76 | Loss: 0.206 | Acc: 92.714% (5103/5504)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.827% (5228/5632)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.830% (5347/5760)\n",
      "Train Epoch: 76 | Loss: 0.204 | Acc: 92.867% (5468/5888)\n",
      "Train Epoch: 76 | Loss: 0.206 | Acc: 92.753% (5580/6016)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.676% (5694/6144)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.618% (5809/6272)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.609% (5927/6400)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.647% (6048/6528)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.653% (6167/6656)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.733% (6291/6784)\n",
      "Train Epoch: 76 | Loss: 0.207 | Acc: 92.708% (6408/6912)\n",
      "Train Epoch: 76 | Loss: 0.208 | Acc: 92.685% (6525/7040)\n",
      "Train Epoch: 76 | Loss: 0.210 | Acc: 92.676% (6643/7168)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.626% (6758/7296)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.605% (6875/7424)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.611% (6994/7552)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.617% (7113/7680)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.559% (7227/7808)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.591% (7348/7936)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.560% (7464/8064)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.590% (7585/8192)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.680% (7711/8320)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.685% (7830/8448)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.689% (7949/8576)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.693% (8068/8704)\n",
      "Train Epoch: 76 | Loss: 0.210 | Acc: 92.708% (8188/8832)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.712% (8307/8960)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.716% (8426/9088)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.719% (8545/9216)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.690% (8661/9344)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.684% (8779/9472)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.698% (8899/9600)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.701% (9018/9728)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.746% (9141/9856)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.788% (9264/9984)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.781% (9382/10112)\n",
      "Train Epoch: 76 | Loss: 0.211 | Acc: 92.754% (9498/10240)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.747% (9616/10368)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.750% (9735/10496)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.733% (9852/10624)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.736% (9971/10752)\n",
      "Train Epoch: 76 | Loss: 0.213 | Acc: 92.739% (10090/10880)\n",
      "Train Epoch: 76 | Loss: 0.212 | Acc: 92.769% (10212/11008)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.744% (10328/11136)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.729% (10445/11264)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.741% (10565/11392)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.743% (10684/11520)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.703% (10798/11648)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.672% (10913/11776)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.675% (11032/11904)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.711% (11155/12032)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.681% (11270/12160)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.676% (11388/12288)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.711% (11511/12416)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.666% (11624/12544)\n",
      "Train Epoch: 76 | Loss: 0.214 | Acc: 92.669% (11743/12672)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.656% (11860/12800)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.675% (11981/12928)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.639% (12095/13056)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.635% (12213/13184)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.638% (12332/13312)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.649% (12452/13440)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.667% (12573/13568)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.640% (12688/13696)\n",
      "Train Epoch: 76 | Loss: 0.215 | Acc: 92.600% (12801/13824)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.567% (12915/13952)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.571% (13034/14080)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.582% (13154/14208)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.557% (13269/14336)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.554% (13387/14464)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.551% (13505/14592)\n",
      "Train Epoch: 76 | Loss: 0.217 | Acc: 92.527% (13620/14720)\n",
      "Train Epoch: 76 | Loss: 0.216 | Acc: 92.544% (13741/14848)\n",
      "Train Epoch: 76 | Loss: 0.217 | Acc: 92.501% (13853/14976)\n",
      "Train Epoch: 76 | Loss: 0.217 | Acc: 92.519% (13974/15104)\n",
      "Train Epoch: 76 | Loss: 0.217 | Acc: 92.529% (14094/15232)\n",
      "Train Epoch: 76 | Loss: 0.217 | Acc: 92.526% (14212/15360)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.459% (14320/15488)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.495% (14444/15616)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.499% (14563/15744)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.477% (14678/15872)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.475% (14796/16000)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.485% (14916/16128)\n",
      "Train Epoch: 76 | Loss: 0.218 | Acc: 92.483% (15034/16256)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.444% (15146/16384)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.442% (15264/16512)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.440% (15382/16640)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.456% (15503/16768)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.460% (15622/16896)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.469% (15742/17024)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.462% (15859/17152)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.471% (15979/17280)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.480% (16099/17408)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.490% (16219/17536)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.465% (16333/17664)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.446% (16448/17792)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.444% (16566/17920)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.442% (16684/18048)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.435% (16801/18176)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.450% (16922/18304)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.448% (17040/18432)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.457% (17160/18560)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.444% (17276/18688)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.437% (17393/18816)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.393% (17503/18944)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.376% (17618/19072)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.365% (17734/19200)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.369% (17853/19328)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.362% (17970/19456)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.371% (18090/19584)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.380% (18210/19712)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.404% (18333/19840)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.403% (18451/19968)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.401% (18569/20096)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.430% (18693/20224)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.438% (18813/20352)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.432% (18930/20480)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.435% (19049/20608)\n",
      "Train Epoch: 76 | Loss: 0.219 | Acc: 92.438% (19168/20736)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.418% (19282/20864)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.416% (19400/20992)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.405% (19516/21120)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.413% (19636/21248)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.407% (19753/21376)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.406% (19871/21504)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.409% (19990/21632)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.390% (20104/21760)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.411% (20227/21888)\n",
      "Train Epoch: 76 | Loss: 0.220 | Acc: 92.401% (20343/22016)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.386% (20458/22144)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.399% (20579/22272)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.379% (20693/22400)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.374% (20810/22528)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.355% (20924/22656)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.350% (21041/22784)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.375% (21165/22912)\n",
      "Train Epoch: 76 | Loss: 0.221 | Acc: 92.348% (21277/23040)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.330% (21391/23168)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.342% (21512/23296)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.341% (21630/23424)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.340% (21748/23552)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.344% (21867/23680)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.326% (21981/23808)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.313% (22096/23936)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.316% (22215/24064)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.328% (22336/24192)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.323% (22453/24320)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.351% (22578/24448)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.346% (22695/24576)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.345% (22813/24704)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.337% (22929/24832)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.328% (23045/24960)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.319% (23161/25088)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.306% (23276/25216)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.314% (23396/25344)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.301% (23511/25472)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.297% (23628/25600)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.273% (23740/25728)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.253% (23853/25856)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.253% (23971/25984)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.264% (24092/26112)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.275% (24213/26240)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.275% (24331/26368)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.271% (24448/26496)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.293% (24572/26624)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.285% (24688/26752)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.273% (24803/26880)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.280% (24923/27008)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.291% (25044/27136)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.283% (25160/27264)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.293% (25281/27392)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.275% (25394/27520)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.278% (25513/27648)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.267% (25628/27776)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.263% (25745/27904)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.277% (25867/28032)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.276% (25985/28160)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.269% (26101/28288)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.265% (26218/28416)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.268% (26337/28544)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.268% (26455/28672)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.271% (26574/28800)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.284% (26696/28928)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.294% (26817/29056)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.277% (26930/29184)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.269% (27046/29312)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.279% (27167/29440)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.272% (27283/29568)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.268% (27400/29696)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.278% (27521/29824)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.284% (27641/29952)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.297% (27763/30080)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.293% (27880/30208)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.313% (28004/30336)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.319% (28124/30464)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.328% (28245/30592)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.311% (28358/30720)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.317% (28478/30848)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.304% (28592/30976)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.303% (28710/31104)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.309% (28830/31232)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.315% (28950/31360)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.299% (29063/31488)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.308% (29184/31616)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.323% (29307/31744)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.338% (29430/31872)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.341% (29549/32000)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.356% (29672/32128)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.358% (29791/32256)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.370% (29913/32384)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.378% (30034/32512)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.374% (30151/32640)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.377% (30270/32768)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.376% (30388/32896)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.381% (30508/33024)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.387% (30628/33152)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.389% (30747/33280)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.394% (30867/33408)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.387% (30983/33536)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.389% (31102/33664)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.383% (31218/33792)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.388% (31338/33920)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.393% (31458/34048)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.389% (31575/34176)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.380% (31690/34304)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.370% (31805/34432)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.367% (31922/34560)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.378% (32044/34688)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.380% (32163/34816)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.388% (32284/34944)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.381% (32400/35072)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.403% (32526/35200)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.397% (32642/35328)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.396% (32760/35456)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.395% (32878/35584)\n",
      "Train Epoch: 76 | Loss: 0.222 | Acc: 92.386% (32993/35712)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.383% (33110/35840)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.374% (33225/35968)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.356% (33337/36096)\n",
      "Train Epoch: 76 | Loss: 0.223 | Acc: 92.350% (33453/36224)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.336% (33566/36352)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.333% (33683/36480)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.327% (33799/36608)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.313% (33912/36736)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.329% (34036/36864)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.323% (34152/36992)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.311% (34266/37120)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.311% (34384/37248)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.313% (34503/37376)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.307% (34619/37504)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.326% (34744/37632)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.325% (34862/37760)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.314% (34976/37888)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.306% (35091/38016)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.311% (35211/38144)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.295% (35323/38272)\n",
      "Train Epoch: 76 | Loss: 0.224 | Acc: 92.312% (35448/38400)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.302% (35562/38528)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.301% (35680/38656)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.283% (35791/38784)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.275% (35906/38912)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.290% (36030/39040)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.277% (36143/39168)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.277% (36261/39296)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.279% (36380/39424)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.284% (36500/39552)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.263% (36610/39680)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.265% (36729/39808)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.255% (36843/39936)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.262% (36964/40064)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.250% (37077/40192)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.245% (37193/40320)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.244% (37311/40448)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.254% (37433/40576)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.251% (37550/40704)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.249% (37667/40832)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.251% (37786/40960)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.248% (37903/41088)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.246% (38020/41216)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.241% (38136/41344)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.241% (38254/41472)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.245% (38374/41600)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.243% (38491/41728)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.250% (38612/41856)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.257% (38733/41984)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.252% (38849/42112)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.254% (38968/42240)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.258% (39088/42368)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.260% (39207/42496)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.265% (39327/42624)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.262% (39444/42752)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.271% (39566/42880)\n",
      "Train Epoch: 76 | Loss: 0.225 | Acc: 92.276% (39686/43008)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.269% (39801/43136)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.280% (39924/43264)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.275% (40040/43392)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.277% (40159/43520)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.284% (40280/43648)\n",
      "Train Epoch: 76 | Loss: 0.226 | Acc: 92.279% (40396/43776)\n",
      "Train Epoch: 76 | Loss: 0.227 | Acc: 92.267% (40509/43904)\n",
      "Train Epoch: 76 | Loss: 0.227 | Acc: 92.262% (40625/44032)\n",
      "Train Epoch: 76 | Loss: 0.227 | Acc: 92.251% (40738/44160)\n",
      "Train Epoch: 76 | Loss: 0.227 | Acc: 92.239% (40851/44288)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.228% (40964/44416)\n",
      "Train Epoch: 76 | Loss: 0.227 | Acc: 92.232% (41084/44544)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.232% (41202/44672)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.217% (41313/44800)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.223% (41434/44928)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.225% (41553/45056)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.227% (41672/45184)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.221% (41787/45312)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.214% (41902/45440)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.201% (42014/45568)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.194% (42129/45696)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.196% (42248/45824)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.198% (42367/45952)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.190% (42481/46080)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.185% (42597/46208)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.188% (42716/46336)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.185% (42833/46464)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.194% (42955/46592)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.198% (43075/46720)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.202% (43195/46848)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.202% (43313/46976)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.192% (43426/47104)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.190% (43543/47232)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.196% (43664/47360)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.200% (43784/47488)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.192% (43898/47616)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.196% (44018/47744)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.185% (44131/47872)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.181% (44247/48000)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.169% (44359/48128)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.173% (44479/48256)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.177% (44599/48384)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.181% (44719/48512)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.175% (44834/48640)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.169% (44949/48768)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.171% (45068/48896)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.161% (45181/49024)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.163% (45300/49152)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.167% (45420/49280)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.165% (45537/49408)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.161% (45653/49536)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.165% (45773/49664)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.161% (45889/49792)\n",
      "Train Epoch: 76 | Loss: 0.229 | Acc: 92.167% (46010/49920)\n",
      "Train Epoch: 76 | Loss: 0.228 | Acc: 92.174% (46087/50000)\n",
      "Test Epoch: 76 | Loss: 0.268 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 76 | Loss: 0.342 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 76 | Loss: 0.325 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 76 | Loss: 0.317 | Acc: 90.000% (360/400)\n",
      "Test Epoch: 76 | Loss: 0.308 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 76 | Loss: 0.305 | Acc: 90.500% (543/600)\n",
      "Test Epoch: 76 | Loss: 0.311 | Acc: 90.143% (631/700)\n",
      "Test Epoch: 76 | Loss: 0.336 | Acc: 89.500% (716/800)\n",
      "Test Epoch: 76 | Loss: 0.350 | Acc: 89.222% (803/900)\n",
      "Test Epoch: 76 | Loss: 0.348 | Acc: 89.300% (893/1000)\n",
      "Test Epoch: 76 | Loss: 0.343 | Acc: 89.455% (984/1100)\n",
      "Test Epoch: 76 | Loss: 0.349 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 76 | Loss: 0.333 | Acc: 89.769% (1167/1300)\n",
      "Test Epoch: 76 | Loss: 0.335 | Acc: 89.571% (1254/1400)\n",
      "Test Epoch: 76 | Loss: 0.331 | Acc: 89.733% (1346/1500)\n",
      "Test Epoch: 76 | Loss: 0.333 | Acc: 89.812% (1437/1600)\n",
      "Test Epoch: 76 | Loss: 0.331 | Acc: 89.882% (1528/1700)\n",
      "Test Epoch: 76 | Loss: 0.338 | Acc: 89.833% (1617/1800)\n",
      "Test Epoch: 76 | Loss: 0.333 | Acc: 89.947% (1709/1900)\n",
      "Test Epoch: 76 | Loss: 0.337 | Acc: 89.850% (1797/2000)\n",
      "Test Epoch: 76 | Loss: 0.339 | Acc: 89.762% (1885/2100)\n",
      "Test Epoch: 76 | Loss: 0.337 | Acc: 89.727% (1974/2200)\n",
      "Test Epoch: 76 | Loss: 0.338 | Acc: 89.739% (2064/2300)\n",
      "Test Epoch: 76 | Loss: 0.334 | Acc: 89.792% (2155/2400)\n",
      "Test Epoch: 76 | Loss: 0.341 | Acc: 89.840% (2246/2500)\n",
      "Test Epoch: 76 | Loss: 0.347 | Acc: 89.769% (2334/2600)\n",
      "Test Epoch: 76 | Loss: 0.344 | Acc: 89.889% (2427/2700)\n",
      "Test Epoch: 76 | Loss: 0.347 | Acc: 89.750% (2513/2800)\n",
      "Test Epoch: 76 | Loss: 0.345 | Acc: 89.724% (2602/2900)\n",
      "Test Epoch: 76 | Loss: 0.349 | Acc: 89.633% (2689/3000)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.484% (2774/3100)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.500% (2864/3200)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.455% (2952/3300)\n",
      "Test Epoch: 76 | Loss: 0.352 | Acc: 89.500% (3043/3400)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.286% (3125/3500)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.361% (3217/3600)\n",
      "Test Epoch: 76 | Loss: 0.359 | Acc: 89.351% (3306/3700)\n",
      "Test Epoch: 76 | Loss: 0.360 | Acc: 89.211% (3390/3800)\n",
      "Test Epoch: 76 | Loss: 0.359 | Acc: 89.333% (3484/3900)\n",
      "Test Epoch: 76 | Loss: 0.360 | Acc: 89.300% (3572/4000)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.293% (3661/4100)\n",
      "Test Epoch: 76 | Loss: 0.364 | Acc: 89.262% (3749/4200)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.395% (3844/4300)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.455% (3936/4400)\n",
      "Test Epoch: 76 | Loss: 0.358 | Acc: 89.533% (4029/4500)\n",
      "Test Epoch: 76 | Loss: 0.360 | Acc: 89.522% (4118/4600)\n",
      "Test Epoch: 76 | Loss: 0.359 | Acc: 89.511% (4207/4700)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.417% (4292/4800)\n",
      "Test Epoch: 76 | Loss: 0.360 | Acc: 89.449% (4383/4900)\n",
      "Test Epoch: 76 | Loss: 0.364 | Acc: 89.340% (4467/5000)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.373% (4558/5100)\n",
      "Test Epoch: 76 | Loss: 0.364 | Acc: 89.250% (4641/5200)\n",
      "Test Epoch: 76 | Loss: 0.363 | Acc: 89.189% (4727/5300)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.222% (4818/5400)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.164% (4904/5500)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.196% (4995/5600)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.193% (5084/5700)\n",
      "Test Epoch: 76 | Loss: 0.359 | Acc: 89.207% (5174/5800)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.119% (5258/5900)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.050% (5343/6000)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 88.984% (5428/6100)\n",
      "Test Epoch: 76 | Loss: 0.362 | Acc: 89.016% (5519/6200)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.048% (5610/6300)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.156% (5706/6400)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.185% (5797/6500)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.227% (5889/6600)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.254% (5980/6700)\n",
      "Test Epoch: 76 | Loss: 0.358 | Acc: 89.132% (6061/6800)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.159% (6152/6900)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.100% (6237/7000)\n",
      "Test Epoch: 76 | Loss: 0.360 | Acc: 89.056% (6323/7100)\n",
      "Test Epoch: 76 | Loss: 0.361 | Acc: 89.028% (6410/7200)\n",
      "Test Epoch: 76 | Loss: 0.359 | Acc: 89.096% (6504/7300)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.122% (6595/7400)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.160% (6687/7500)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.184% (6778/7600)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.143% (6864/7700)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.179% (6956/7800)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.165% (7044/7900)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.175% (7134/8000)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.198% (7225/8100)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.195% (7314/8200)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.157% (7400/8300)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.167% (7490/8400)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.153% (7578/8500)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.151% (7667/8600)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.172% (7758/8700)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.170% (7847/8800)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.169% (7936/8900)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.156% (8024/9000)\n",
      "Test Epoch: 76 | Loss: 0.357 | Acc: 89.143% (8112/9100)\n",
      "Test Epoch: 76 | Loss: 0.356 | Acc: 89.196% (8206/9200)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.226% (8298/9300)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.245% (8389/9400)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.263% (8480/9500)\n",
      "Test Epoch: 76 | Loss: 0.355 | Acc: 89.250% (8568/9600)\n",
      "Test Epoch: 76 | Loss: 0.352 | Acc: 89.309% (8663/9700)\n",
      "Test Epoch: 76 | Loss: 0.353 | Acc: 89.316% (8753/9800)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.283% (8839/9900)\n",
      "Test Epoch: 76 | Loss: 0.354 | Acc: 89.260% (8926/10000)\n",
      "\n",
      "Epoch: 77\n",
      "Train Epoch: 77 | Loss: 0.167 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 77 | Loss: 0.165 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 77 | Loss: 0.205 | Acc: 92.188% (354/384)\n",
      "Train Epoch: 77 | Loss: 0.208 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.031% (589/640)\n",
      "Train Epoch: 77 | Loss: 0.231 | Acc: 91.927% (706/768)\n",
      "Train Epoch: 77 | Loss: 0.230 | Acc: 91.964% (824/896)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 91.992% (942/1024)\n",
      "Train Epoch: 77 | Loss: 0.219 | Acc: 92.101% (1061/1152)\n",
      "Train Epoch: 77 | Loss: 0.212 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 77 | Loss: 0.212 | Acc: 92.472% (1302/1408)\n",
      "Train Epoch: 77 | Loss: 0.213 | Acc: 92.383% (1419/1536)\n",
      "Train Epoch: 77 | Loss: 0.218 | Acc: 92.308% (1536/1664)\n",
      "Train Epoch: 77 | Loss: 0.219 | Acc: 92.299% (1654/1792)\n",
      "Train Epoch: 77 | Loss: 0.218 | Acc: 92.135% (1769/1920)\n",
      "Train Epoch: 77 | Loss: 0.218 | Acc: 92.236% (1889/2048)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.142% (2005/2176)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.274% (2126/2304)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.105% (2240/2432)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.031% (2356/2560)\n",
      "Train Epoch: 77 | Loss: 0.220 | Acc: 92.225% (2479/2688)\n",
      "Train Epoch: 77 | Loss: 0.219 | Acc: 92.330% (2600/2816)\n",
      "Train Epoch: 77 | Loss: 0.219 | Acc: 92.357% (2719/2944)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.415% (2839/3072)\n",
      "Train Epoch: 77 | Loss: 0.220 | Acc: 92.375% (2956/3200)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.308% (3072/3328)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.245% (3188/3456)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.188% (3304/3584)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.214% (3423/3712)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.266% (3543/3840)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.288% (3662/3968)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.261% (3779/4096)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.188% (3894/4224)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.210% (4013/4352)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.232% (4132/4480)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.166% (4247/4608)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.188% (4366/4736)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.208% (4485/4864)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.167% (4601/4992)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.129% (4717/5120)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.073% (4832/5248)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.039% (4948/5376)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.024% (5065/5504)\n",
      "Train Epoch: 77 | Loss: 0.229 | Acc: 91.921% (5177/5632)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.014% (5300/5760)\n",
      "Train Epoch: 77 | Loss: 0.229 | Acc: 92.035% (5419/5888)\n",
      "Train Epoch: 77 | Loss: 0.229 | Acc: 92.005% (5535/6016)\n",
      "Train Epoch: 77 | Loss: 0.229 | Acc: 91.992% (5652/6144)\n",
      "Train Epoch: 77 | Loss: 0.230 | Acc: 91.932% (5766/6272)\n",
      "Train Epoch: 77 | Loss: 0.230 | Acc: 91.859% (5879/6400)\n",
      "Train Epoch: 77 | Loss: 0.231 | Acc: 91.789% (5992/6528)\n",
      "Train Epoch: 77 | Loss: 0.229 | Acc: 91.857% (6114/6656)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 91.907% (6235/6784)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 91.999% (6359/6912)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.045% (6480/7040)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.076% (6600/7168)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.078% (6718/7296)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.080% (6836/7424)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.121% (6957/7552)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.057% (7070/7680)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.085% (7190/7808)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.112% (7310/7936)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.125% (7429/8064)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.102% (7545/8192)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.175% (7669/8320)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.235% (7792/8448)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.188% (7906/8576)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.188% (8024/8704)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.210% (8144/8832)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.221% (8263/8960)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.265% (8385/9088)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.274% (8504/9216)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.305% (8625/9344)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.283% (8741/9472)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.250% (8856/9600)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.290% (8978/9728)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.330% (9100/9856)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.348% (9220/9984)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.306% (9334/10112)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.354% (9457/10240)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.323% (9572/10368)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.254% (9683/10496)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.225% (9798/10624)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.253% (9919/10752)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.289% (10041/10880)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.306% (10161/11008)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.322% (10281/11136)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.276% (10394/11264)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.275% (10512/11392)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.309% (10634/11520)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.333% (10755/11648)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.366% (10877/11776)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.372% (10996/11904)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.412% (11119/12032)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.426% (11239/12160)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.415% (11356/12288)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.429% (11476/12416)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.443% (11596/12544)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.440% (11714/12672)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.383% (11825/12800)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.358% (11940/12928)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.341% (12056/13056)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.294% (12168/13184)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.308% (12288/13312)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.321% (12408/13440)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.269% (12519/13568)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.275% (12638/13696)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.289% (12758/13824)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.295% (12877/13952)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.322% (12999/14080)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.335% (13119/14208)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.348% (13239/14336)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.340% (13356/14464)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.325% (13472/14592)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.337% (13592/14720)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.315% (13707/14848)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.321% (13826/14976)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.346% (13948/15104)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.345% (14066/15232)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.331% (14182/15360)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.330% (14300/15488)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.309% (14415/15616)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.321% (14535/15744)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.314% (14652/15872)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.325% (14772/16000)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.343% (14893/16128)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.347% (15012/16256)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.328% (15127/16384)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.327% (15245/16512)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.338% (15365/16640)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.360% (15487/16768)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.377% (15608/16896)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.405% (15731/17024)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.427% (15853/17152)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.448% (15975/17280)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.475% (16098/17408)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.467% (16215/17536)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.471% (16334/17664)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.497% (16457/17792)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.461% (16569/17920)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.453% (16686/18048)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.446% (16803/18176)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.472% (16926/18304)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.475% (17045/18432)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.489% (17166/18560)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.487% (17284/18688)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.469% (17399/18816)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.451% (17514/18944)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.455% (17633/19072)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.453% (17751/19200)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.441% (17867/19328)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.403% (17978/19456)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.351% (18086/19584)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.340% (18202/19712)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.339% (18320/19840)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.343% (18439/19968)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.377% (18564/20096)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.395% (18686/20224)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.399% (18805/20352)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.397% (18923/20480)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.401% (19042/20608)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.390% (19158/20736)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.379% (19274/20864)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.378% (19392/20992)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.391% (19513/21120)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.395% (19632/21248)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.393% (19750/21376)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.401% (19870/21504)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.396% (19987/21632)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.385% (20103/21760)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.370% (20218/21888)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.369% (20336/22016)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.382% (20457/22144)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.394% (20578/22272)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.406% (20699/22400)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.387% (20813/22528)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.391% (20932/22656)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.394% (21051/22784)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.397% (21170/22912)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.378% (21284/23040)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.403% (21408/23168)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.402% (21526/23296)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.405% (21645/23424)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.421% (21767/23552)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.454% (21893/23680)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.465% (22014/23808)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.459% (22131/23936)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.449% (22247/24064)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.448% (22365/24192)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.451% (22484/24320)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.441% (22600/24448)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.436% (22717/24576)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.438% (22836/24704)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.453% (22958/24832)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.468% (23080/24960)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.459% (23196/25088)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.457% (23314/25216)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.460% (23433/25344)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.443% (23547/25472)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.445% (23666/25600)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.452% (23786/25728)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.450% (23904/25856)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.453% (24023/25984)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.440% (24138/26112)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.450% (24259/26240)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.438% (24374/26368)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.444% (24494/26496)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.450% (24614/26624)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.442% (24730/26752)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.440% (24848/26880)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.439% (24966/27008)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.449% (25087/27136)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.459% (25208/27264)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.461% (25327/27392)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.442% (25440/27520)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.444% (25559/27648)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.429% (25673/27776)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.424% (25790/27904)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.398% (25901/28032)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.393% (26018/28160)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.393% (26136/28288)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.378% (26250/28416)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.373% (26367/28544)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.386% (26489/28672)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.385% (26607/28800)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.378% (26723/28928)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.384% (26843/29056)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.390% (26963/29184)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.389% (27081/29312)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.398% (27202/29440)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.404% (27322/29568)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.423% (27446/29696)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.426% (27565/29824)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.411% (27679/29952)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.417% (27799/30080)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.406% (27914/30208)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.422% (28037/30336)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.424% (28156/30464)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.416% (28272/30592)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.412% (28389/30720)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.411% (28507/30848)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.413% (28626/30976)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.425% (28748/31104)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.412% (28862/31232)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.417% (28982/31360)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.423% (29102/31488)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.415% (29218/31616)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.408% (29334/31744)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.410% (29453/31872)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.397% (29567/32000)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.387% (29682/32128)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.395% (29803/32256)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.394% (29921/32384)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.400% (30041/32512)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.396% (30158/32640)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.416% (30283/32768)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.406% (30398/32896)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.402% (30515/33024)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.387% (30628/33152)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.380% (30744/33280)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.370% (30859/33408)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.369% (30977/33536)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.381% (31099/33664)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.398% (31223/33792)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.391% (31339/33920)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.387% (31456/34048)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.384% (31573/34176)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.371% (31687/34304)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.373% (31806/34432)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.381% (31927/34560)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.386% (32047/34688)\n",
      "Train Epoch: 77 | Loss: 0.221 | Acc: 92.383% (32164/34816)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.374% (32279/34944)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.356% (32391/35072)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.361% (32511/35200)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.357% (32628/35328)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.362% (32748/35456)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.336% (32857/35584)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.330% (32973/35712)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.330% (33091/35840)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.340% (33213/35968)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.345% (33333/36096)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.353% (33454/36224)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.364% (33576/36352)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.366% (33695/36480)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.360% (33811/36608)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.359% (33929/36736)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.364% (34049/36864)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.358% (34165/36992)\n",
      "Train Epoch: 77 | Loss: 0.222 | Acc: 92.360% (34284/37120)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.367% (34405/37248)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.367% (34523/37376)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.363% (34640/37504)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.355% (34755/37632)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.349% (34871/37760)\n",
      "Train Epoch: 77 | Loss: 0.223 | Acc: 92.335% (34984/37888)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.327% (35099/38016)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.305% (35209/38144)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.316% (35331/38272)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.312% (35448/38400)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.304% (35563/38528)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.299% (35679/38656)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.291% (35794/38784)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.270% (35904/38912)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.267% (36021/39040)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.262% (36137/39168)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.246% (36249/39296)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.243% (36366/39424)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.248% (36486/39552)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.251% (36605/39680)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.258% (36726/39808)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.255% (36843/39936)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.252% (36960/40064)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.245% (37075/40192)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.250% (37195/40320)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.252% (37314/40448)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.254% (37433/40576)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.249% (37549/40704)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.246% (37666/40832)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.239% (37781/40960)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.241% (37900/41088)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.243% (38019/41216)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.243% (38137/41344)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.248% (38257/41472)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.255% (38378/41600)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.252% (38495/41728)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.250% (38612/41856)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.249% (38730/41984)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.240% (38844/42112)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.230% (38958/42240)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.228% (39075/42368)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.225% (39192/42496)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.234% (39314/42624)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.237% (39433/42752)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.227% (39547/42880)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.234% (39668/43008)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.236% (39787/43136)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.241% (39907/43264)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.247% (40028/43392)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.245% (40145/43520)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.247% (40264/43648)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.254% (40385/43776)\n",
      "Train Epoch: 77 | Loss: 0.224 | Acc: 92.258% (40505/43904)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.251% (40620/44032)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.246% (40736/44160)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.244% (40853/44288)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.239% (40969/44416)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.223% (41080/44544)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.214% (41194/44672)\n",
      "Train Epoch: 77 | Loss: 0.225 | Acc: 92.230% (41319/44800)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.214% (41430/44928)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.207% (41545/45056)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.201% (41660/45184)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.192% (41774/45312)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.181% (41887/45440)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.177% (42003/45568)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.183% (42124/45696)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.166% (42234/45824)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.181% (42359/45952)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.181% (42477/46080)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.188% (42598/46208)\n",
      "Train Epoch: 77 | Loss: 0.226 | Acc: 92.166% (42706/46336)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.157% (42820/46464)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.153% (42936/46592)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.149% (43052/46720)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.145% (43168/46848)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.136% (43282/46976)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.132% (43398/47104)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.137% (43518/47232)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.141% (43638/47360)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.158% (43764/47488)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.150% (43878/47616)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.154% (43998/47744)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.158% (44118/47872)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.154% (44234/48000)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.150% (44350/48128)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.152% (44469/48256)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.150% (44586/48384)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.155% (44706/48512)\n",
      "Train Epoch: 77 | Loss: 0.227 | Acc: 92.144% (44819/48640)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.144% (44937/48768)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.149% (45057/48896)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.149% (45175/49024)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.151% (45294/49152)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.151% (45412/49280)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.143% (45526/49408)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.145% (45645/49536)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.143% (45762/49664)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.133% (45875/49792)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.143% (45998/49920)\n",
      "Train Epoch: 77 | Loss: 0.228 | Acc: 92.132% (46066/50000)\n",
      "Test Epoch: 77 | Loss: 0.373 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 77 | Loss: 0.380 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 77 | Loss: 0.368 | Acc: 89.333% (268/300)\n",
      "Test Epoch: 77 | Loss: 0.352 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 77 | Loss: 0.331 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 77 | Loss: 0.320 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 77 | Loss: 0.311 | Acc: 89.857% (629/700)\n",
      "Test Epoch: 77 | Loss: 0.351 | Acc: 89.000% (712/800)\n",
      "Test Epoch: 77 | Loss: 0.362 | Acc: 88.889% (800/900)\n",
      "Test Epoch: 77 | Loss: 0.366 | Acc: 88.700% (887/1000)\n",
      "Test Epoch: 77 | Loss: 0.370 | Acc: 88.364% (972/1100)\n",
      "Test Epoch: 77 | Loss: 0.370 | Acc: 88.500% (1062/1200)\n",
      "Test Epoch: 77 | Loss: 0.362 | Acc: 88.615% (1152/1300)\n",
      "Test Epoch: 77 | Loss: 0.371 | Acc: 88.429% (1238/1400)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.533% (1328/1500)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.500% (1416/1600)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.529% (1505/1700)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.444% (1592/1800)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.368% (1679/1900)\n",
      "Test Epoch: 77 | Loss: 0.378 | Acc: 88.250% (1765/2000)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.238% (1853/2100)\n",
      "Test Epoch: 77 | Loss: 0.369 | Acc: 88.455% (1946/2200)\n",
      "Test Epoch: 77 | Loss: 0.373 | Acc: 88.304% (2031/2300)\n",
      "Test Epoch: 77 | Loss: 0.370 | Acc: 88.417% (2122/2400)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.360% (2209/2500)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.231% (2294/2600)\n",
      "Test Epoch: 77 | Loss: 0.380 | Acc: 88.370% (2386/2700)\n",
      "Test Epoch: 77 | Loss: 0.383 | Acc: 88.250% (2471/2800)\n",
      "Test Epoch: 77 | Loss: 0.380 | Acc: 88.345% (2562/2900)\n",
      "Test Epoch: 77 | Loss: 0.379 | Acc: 88.333% (2650/3000)\n",
      "Test Epoch: 77 | Loss: 0.385 | Acc: 88.258% (2736/3100)\n",
      "Test Epoch: 77 | Loss: 0.385 | Acc: 88.219% (2823/3200)\n",
      "Test Epoch: 77 | Loss: 0.384 | Acc: 88.333% (2915/3300)\n",
      "Test Epoch: 77 | Loss: 0.383 | Acc: 88.206% (2999/3400)\n",
      "Test Epoch: 77 | Loss: 0.388 | Acc: 88.000% (3080/3500)\n",
      "Test Epoch: 77 | Loss: 0.386 | Acc: 88.139% (3173/3600)\n",
      "Test Epoch: 77 | Loss: 0.388 | Acc: 88.108% (3260/3700)\n",
      "Test Epoch: 77 | Loss: 0.390 | Acc: 88.079% (3347/3800)\n",
      "Test Epoch: 77 | Loss: 0.388 | Acc: 88.077% (3435/3900)\n",
      "Test Epoch: 77 | Loss: 0.390 | Acc: 88.100% (3524/4000)\n",
      "Test Epoch: 77 | Loss: 0.389 | Acc: 88.024% (3609/4100)\n",
      "Test Epoch: 77 | Loss: 0.389 | Acc: 88.000% (3696/4200)\n",
      "Test Epoch: 77 | Loss: 0.384 | Acc: 88.140% (3790/4300)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.273% (3884/4400)\n",
      "Test Epoch: 77 | Loss: 0.379 | Acc: 88.311% (3974/4500)\n",
      "Test Epoch: 77 | Loss: 0.383 | Acc: 88.174% (4056/4600)\n",
      "Test Epoch: 77 | Loss: 0.384 | Acc: 88.170% (4144/4700)\n",
      "Test Epoch: 77 | Loss: 0.385 | Acc: 88.188% (4233/4800)\n",
      "Test Epoch: 77 | Loss: 0.383 | Acc: 88.245% (4324/4900)\n",
      "Test Epoch: 77 | Loss: 0.384 | Acc: 88.200% (4410/5000)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.255% (4501/5100)\n",
      "Test Epoch: 77 | Loss: 0.381 | Acc: 88.231% (4588/5200)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.208% (4675/5300)\n",
      "Test Epoch: 77 | Loss: 0.381 | Acc: 88.185% (4762/5400)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.145% (4848/5500)\n",
      "Test Epoch: 77 | Loss: 0.384 | Acc: 88.071% (4932/5600)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.105% (5022/5700)\n",
      "Test Epoch: 77 | Loss: 0.380 | Acc: 88.138% (5112/5800)\n",
      "Test Epoch: 77 | Loss: 0.382 | Acc: 88.034% (5194/5900)\n",
      "Test Epoch: 77 | Loss: 0.381 | Acc: 88.000% (5280/6000)\n",
      "Test Epoch: 77 | Loss: 0.381 | Acc: 88.033% (5370/6100)\n",
      "Test Epoch: 77 | Loss: 0.380 | Acc: 88.032% (5458/6200)\n",
      "Test Epoch: 77 | Loss: 0.379 | Acc: 88.095% (5550/6300)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.203% (5645/6400)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.169% (5731/6500)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.227% (5823/6600)\n",
      "Test Epoch: 77 | Loss: 0.371 | Acc: 88.299% (5916/6700)\n",
      "Test Epoch: 77 | Loss: 0.372 | Acc: 88.265% (6002/6800)\n",
      "Test Epoch: 77 | Loss: 0.372 | Acc: 88.261% (6090/6900)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.229% (6176/7000)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.197% (6262/7100)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.139% (6346/7200)\n",
      "Test Epoch: 77 | Loss: 0.372 | Acc: 88.205% (6439/7300)\n",
      "Test Epoch: 77 | Loss: 0.371 | Acc: 88.216% (6528/7400)\n",
      "Test Epoch: 77 | Loss: 0.371 | Acc: 88.267% (6620/7500)\n",
      "Test Epoch: 77 | Loss: 0.371 | Acc: 88.276% (6709/7600)\n",
      "Test Epoch: 77 | Loss: 0.373 | Acc: 88.195% (6791/7700)\n",
      "Test Epoch: 77 | Loss: 0.373 | Acc: 88.218% (6881/7800)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.165% (6965/7900)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.162% (7053/8000)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.247% (7148/8100)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.195% (7232/8200)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.169% (7318/8300)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.179% (7407/8400)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.176% (7495/8500)\n",
      "Test Epoch: 77 | Loss: 0.377 | Acc: 88.140% (7580/8600)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.195% (7673/8700)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.193% (7761/8800)\n",
      "Test Epoch: 77 | Loss: 0.378 | Acc: 88.191% (7849/8900)\n",
      "Test Epoch: 77 | Loss: 0.377 | Acc: 88.211% (7939/9000)\n",
      "Test Epoch: 77 | Loss: 0.376 | Acc: 88.220% (8028/9100)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.304% (8124/9200)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.333% (8215/9300)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.330% (8303/9400)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.316% (8390/9500)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.333% (8480/9600)\n",
      "Test Epoch: 77 | Loss: 0.374 | Acc: 88.361% (8571/9700)\n",
      "Test Epoch: 77 | Loss: 0.373 | Acc: 88.378% (8661/9800)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.333% (8745/9900)\n",
      "Test Epoch: 77 | Loss: 0.375 | Acc: 88.340% (8834/10000)\n",
      "\n",
      "Epoch: 78\n",
      "Train Epoch: 78 | Loss: 0.231 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 78 | Loss: 0.202 | Acc: 94.531% (242/256)\n",
      "Train Epoch: 78 | Loss: 0.196 | Acc: 94.271% (362/384)\n",
      "Train Epoch: 78 | Loss: 0.202 | Acc: 93.750% (480/512)\n",
      "Train Epoch: 78 | Loss: 0.207 | Acc: 93.438% (598/640)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.839% (713/768)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.969% (833/896)\n",
      "Train Epoch: 78 | Loss: 0.228 | Acc: 92.578% (948/1024)\n",
      "Train Epoch: 78 | Loss: 0.231 | Acc: 92.188% (1062/1152)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.422% (1183/1280)\n",
      "Train Epoch: 78 | Loss: 0.226 | Acc: 92.330% (1300/1408)\n",
      "Train Epoch: 78 | Loss: 0.227 | Acc: 92.318% (1418/1536)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.947% (1530/1664)\n",
      "Train Epoch: 78 | Loss: 0.239 | Acc: 91.797% (1645/1792)\n",
      "Train Epoch: 78 | Loss: 0.236 | Acc: 91.875% (1764/1920)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.895% (1882/2048)\n",
      "Train Epoch: 78 | Loss: 0.234 | Acc: 91.774% (1997/2176)\n",
      "Train Epoch: 78 | Loss: 0.238 | Acc: 91.710% (2113/2304)\n",
      "Train Epoch: 78 | Loss: 0.237 | Acc: 91.900% (2235/2432)\n",
      "Train Epoch: 78 | Loss: 0.241 | Acc: 91.680% (2347/2560)\n",
      "Train Epoch: 78 | Loss: 0.245 | Acc: 91.592% (2462/2688)\n",
      "Train Epoch: 78 | Loss: 0.242 | Acc: 91.797% (2585/2816)\n",
      "Train Epoch: 78 | Loss: 0.236 | Acc: 92.018% (2709/2944)\n",
      "Train Epoch: 78 | Loss: 0.232 | Acc: 92.090% (2829/3072)\n",
      "Train Epoch: 78 | Loss: 0.231 | Acc: 92.125% (2948/3200)\n",
      "Train Epoch: 78 | Loss: 0.231 | Acc: 92.097% (3065/3328)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.245% (3188/3456)\n",
      "Train Epoch: 78 | Loss: 0.227 | Acc: 92.299% (3308/3584)\n",
      "Train Epoch: 78 | Loss: 0.228 | Acc: 92.188% (3422/3712)\n",
      "Train Epoch: 78 | Loss: 0.228 | Acc: 92.135% (3538/3840)\n",
      "Train Epoch: 78 | Loss: 0.232 | Acc: 92.011% (3651/3968)\n",
      "Train Epoch: 78 | Loss: 0.232 | Acc: 92.017% (3769/4096)\n",
      "Train Epoch: 78 | Loss: 0.234 | Acc: 91.927% (3883/4224)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.912% (4000/4352)\n",
      "Train Epoch: 78 | Loss: 0.232 | Acc: 91.987% (4121/4480)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.949% (4237/4608)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.997% (4357/4736)\n",
      "Train Epoch: 78 | Loss: 0.233 | Acc: 91.920% (4471/4864)\n",
      "Train Epoch: 78 | Loss: 0.230 | Acc: 92.027% (4594/4992)\n",
      "Train Epoch: 78 | Loss: 0.228 | Acc: 92.109% (4716/5120)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.111% (4834/5248)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.132% (4953/5376)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.115% (5070/5504)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.099% (5187/5632)\n",
      "Train Epoch: 78 | Loss: 0.230 | Acc: 92.118% (5306/5760)\n",
      "Train Epoch: 78 | Loss: 0.229 | Acc: 92.120% (5424/5888)\n",
      "Train Epoch: 78 | Loss: 0.226 | Acc: 92.254% (5550/6016)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.334% (5673/6144)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.315% (5790/6272)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.328% (5909/6400)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.402% (6032/6528)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.383% (6149/6656)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.453% (6272/6784)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.361% (6384/6912)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.429% (6507/7040)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.439% (6626/7168)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.489% (6748/7296)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.484% (6866/7424)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.479% (6984/7552)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.578% (7110/7680)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.533% (7225/7808)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.503% (7341/7936)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.510% (7460/8064)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.529% (7580/8192)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.524% (7698/8320)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.543% (7818/8448)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.491% (7932/8576)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.475% (8049/8704)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.516% (8171/8832)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.567% (8294/8960)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.540% (8410/9088)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.546% (8529/9216)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.541% (8647/9344)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.568% (8768/9472)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.615% (8891/9600)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.650% (9013/9728)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.654% (9132/9856)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.688% (9254/9984)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.712% (9375/10112)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.666% (9489/10240)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.650% (9606/10368)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.654% (9725/10496)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.668% (9845/10624)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.662% (9963/10752)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.684% (10084/10880)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.660% (10200/11008)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.654% (10318/11136)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.658% (10437/11264)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.670% (10557/11392)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.682% (10677/11520)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.625% (10789/11648)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.638% (10909/11776)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.650% (11029/11904)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.645% (11147/12032)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.623% (11263/12160)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.651% (11385/12288)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.622% (11500/12416)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.618% (11618/12544)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.614% (11736/12672)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.609% (11854/12800)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.597% (11971/12928)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.570% (12086/13056)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.590% (12207/13184)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.601% (12327/13312)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.589% (12444/13440)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.556% (12558/13568)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.582% (12680/13696)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.585% (12799/13824)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.582% (12917/13952)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.585% (13036/14080)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.610% (13158/14208)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.613% (13277/14336)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.651% (13401/14464)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.660% (13521/14592)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.663% (13640/14720)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.686% (13762/14848)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.715% (13885/14976)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.724% (14005/15104)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.686% (14118/15232)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.676% (14235/15360)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.652% (14350/15488)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.642% (14467/15616)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.619% (14582/15744)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.597% (14697/15872)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.606% (14817/16000)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.547% (14926/16128)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.532% (15042/16256)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.566% (15166/16384)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.581% (15287/16512)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.566% (15403/16640)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.587% (15525/16768)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.608% (15647/16896)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.622% (15768/17024)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.596% (15882/17152)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.604% (16002/17280)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.601% (16120/17408)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.592% (16237/17536)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.595% (16356/17664)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.632% (16481/17792)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.617% (16597/17920)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.625% (16717/18048)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.633% (16837/18176)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.657% (16960/18304)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.670% (17081/18432)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.699% (17205/18560)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.701% (17324/18688)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.687% (17440/18816)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.694% (17560/18944)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.691% (17678/19072)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.693% (17797/19200)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.674% (17912/19328)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.645% (18025/19456)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.637% (18142/19584)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.649% (18263/19712)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.646% (18381/19840)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.663% (18503/19968)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.670% (18623/20096)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.682% (18744/20224)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.674% (18861/20352)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.656% (18976/20480)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.648% (19093/20608)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.626% (19207/20736)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.624% (19325/20864)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.631% (19445/20992)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.652% (19568/21120)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.668% (19690/21248)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.674% (19810/21376)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.680% (19930/21504)\n",
      "Train Epoch: 78 | Loss: 0.212 | Acc: 92.673% (20047/21632)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.670% (20165/21760)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.654% (20280/21888)\n",
      "Train Epoch: 78 | Loss: 0.213 | Acc: 92.651% (20398/22016)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.635% (20513/22144)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.628% (20630/22272)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.616% (20746/22400)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.618% (20865/22528)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.611% (20982/22656)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.626% (21104/22784)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.620% (21221/22912)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.591% (21333/23040)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.589% (21451/23168)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.582% (21568/23296)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.580% (21686/23424)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.582% (21805/23552)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.584% (21924/23680)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.587% (22043/23808)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.580% (22160/23936)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.586% (22280/24064)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.580% (22397/24192)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.595% (22519/24320)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.597% (22638/24448)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.590% (22755/24576)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.596% (22875/24704)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.602% (22995/24832)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.592% (23111/24960)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.602% (23232/25088)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.604% (23351/25216)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.598% (23468/25344)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.600% (23587/25472)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.602% (23706/25600)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.603% (23825/25728)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.609% (23945/25856)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.611% (24064/25984)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.590% (24177/26112)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.584% (24294/26240)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.578% (24411/26368)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.572% (24528/26496)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.571% (24646/26624)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.584% (24768/26752)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.582% (24886/26880)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.587% (25006/27008)\n",
      "Train Epoch: 78 | Loss: 0.214 | Acc: 92.589% (25125/27136)\n",
      "Train Epoch: 78 | Loss: 0.215 | Acc: 92.565% (25237/27264)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.545% (25350/27392)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.544% (25468/27520)\n",
      "Train Epoch: 78 | Loss: 0.216 | Acc: 92.531% (25583/27648)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.508% (25695/27776)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.506% (25813/27904)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.498% (25929/28032)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.511% (26051/28160)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.506% (26168/28288)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.508% (26287/28416)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.520% (26409/28544)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.512% (26525/28672)\n",
      "Train Epoch: 78 | Loss: 0.217 | Acc: 92.503% (26641/28800)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.478% (26752/28928)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.477% (26870/29056)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.472% (26987/29184)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.491% (27111/29312)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.503% (27233/29440)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.489% (27347/29568)\n",
      "Train Epoch: 78 | Loss: 0.218 | Acc: 92.491% (27466/29696)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.476% (27580/29824)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.468% (27696/29952)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.470% (27815/30080)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.462% (27931/30208)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.458% (28048/30336)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.440% (28161/30464)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.426% (28275/30592)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.409% (28388/30720)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.421% (28510/30848)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.436% (28633/30976)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.448% (28755/31104)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.428% (28867/31232)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.436% (28988/31360)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.432% (29105/31488)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.444% (29227/31616)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.440% (29344/31744)\n",
      "Train Epoch: 78 | Loss: 0.219 | Acc: 92.429% (29459/31872)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.403% (29569/32000)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.396% (29685/32128)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.383% (29799/32256)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.376% (29915/32384)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.369% (30031/32512)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.350% (30143/32640)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.358% (30264/32768)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.364% (30384/32896)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.360% (30501/33024)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.359% (30619/33152)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.368% (30740/33280)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.373% (30860/33408)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.354% (30972/33536)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.372% (31096/33664)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.380% (31217/33792)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.367% (31331/33920)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.361% (31447/34048)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.340% (31558/34176)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.333% (31674/34304)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.333% (31792/34432)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.332% (31910/34560)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.323% (32025/34688)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.320% (32142/34816)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.316% (32259/34944)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.324% (32380/35072)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.335% (32502/35200)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.338% (32621/35328)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.340% (32740/35456)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.350% (32862/35584)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.356% (32982/35712)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.347% (33097/35840)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.352% (33217/35968)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.326% (33326/36096)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.326% (33444/36224)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.333% (33565/36352)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.314% (33676/36480)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.316% (33795/36608)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.326% (33917/36736)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.320% (34033/36864)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.320% (34151/36992)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.311% (34266/37120)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.308% (34383/37248)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.308% (34501/37376)\n",
      "Train Epoch: 78 | Loss: 0.224 | Acc: 92.299% (34616/37504)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.318% (34741/37632)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.320% (34860/37760)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.327% (34981/37888)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.327% (35099/38016)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.326% (35217/38144)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.321% (35333/38272)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.331% (35455/38400)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.335% (35575/38528)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.327% (35690/38656)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.327% (35808/38784)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.334% (35929/38912)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.334% (36047/39040)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.346% (36170/39168)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.348% (36289/39296)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.347% (36407/39424)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.347% (36525/39552)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.341% (36641/39680)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.338% (36758/39808)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.340% (36877/39936)\n",
      "Train Epoch: 78 | Loss: 0.223 | Acc: 92.340% (36995/40064)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.342% (37114/40192)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.346% (37234/40320)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.356% (37356/40448)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.360% (37476/40576)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.364% (37596/40704)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.374% (37718/40832)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.373% (37836/40960)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.390% (37961/41088)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.394% (38081/41216)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.388% (38197/41344)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.380% (38312/41472)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.385% (38432/41600)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.374% (38546/41728)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.374% (38664/41856)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.373% (38782/41984)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.380% (38903/42112)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.389% (39025/42240)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.388% (39143/42368)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.395% (39264/42496)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.401% (39385/42624)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.398% (39502/42752)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.402% (39622/42880)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.411% (39744/43008)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.405% (39860/43136)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.407% (39979/43264)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.402% (40095/43392)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.406% (40215/43520)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.410% (40335/43648)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.402% (40450/43776)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.397% (40566/43904)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.394% (40683/44032)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.403% (40805/44160)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.407% (40925/44288)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.408% (41044/44416)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.410% (41163/44544)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.407% (41280/44672)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.408% (41399/44800)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.403% (41515/44928)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.401% (41632/45056)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.398% (41749/45184)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.402% (41869/45312)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.405% (41989/45440)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.405% (42107/45568)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.400% (42223/45696)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.399% (42341/45824)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.401% (42460/45952)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.402% (42579/46080)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.406% (42699/46208)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.408% (42818/46336)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.411% (42938/46464)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.406% (43054/46592)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.404% (43171/46720)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.409% (43292/46848)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.415% (43413/46976)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.413% (43530/47104)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.414% (43649/47232)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.411% (43766/47360)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.409% (43883/47488)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.421% (44007/47616)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.418% (44124/47744)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.419% (44243/47872)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.417% (44360/48000)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.416% (44478/48128)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.426% (44601/48256)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.427% (44720/48384)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.420% (44835/48512)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.424% (44955/48640)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.421% (45072/48768)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.421% (45190/48896)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.414% (45305/49024)\n",
      "Train Epoch: 78 | Loss: 0.220 | Acc: 92.417% (45425/49152)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.415% (45542/49280)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.408% (45657/49408)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.406% (45774/49536)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.405% (45892/49664)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.394% (46005/49792)\n",
      "Train Epoch: 78 | Loss: 0.221 | Acc: 92.384% (46118/49920)\n",
      "Train Epoch: 78 | Loss: 0.222 | Acc: 92.368% (46184/50000)\n",
      "Test Epoch: 78 | Loss: 0.487 | Acc: 88.000% (88/100)\n",
      "Test Epoch: 78 | Loss: 0.369 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 78 | Loss: 0.372 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 78 | Loss: 0.344 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 78 | Loss: 0.327 | Acc: 91.000% (455/500)\n",
      "Test Epoch: 78 | Loss: 0.325 | Acc: 91.000% (546/600)\n",
      "Test Epoch: 78 | Loss: 0.303 | Acc: 91.571% (641/700)\n",
      "Test Epoch: 78 | Loss: 0.337 | Acc: 90.500% (724/800)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 89.889% (809/900)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.700% (897/1000)\n",
      "Test Epoch: 78 | Loss: 0.367 | Acc: 89.091% (980/1100)\n",
      "Test Epoch: 78 | Loss: 0.374 | Acc: 89.000% (1068/1200)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 89.385% (1162/1300)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 89.500% (1253/1400)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 89.533% (1343/1500)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 89.562% (1433/1600)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.647% (1524/1700)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 89.611% (1613/1800)\n",
      "Test Epoch: 78 | Loss: 0.356 | Acc: 89.684% (1704/1900)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.750% (1795/2000)\n",
      "Test Epoch: 78 | Loss: 0.363 | Acc: 89.429% (1878/2100)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.318% (1965/2200)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 89.304% (2054/2300)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 78 | Loss: 0.365 | Acc: 88.960% (2224/2500)\n",
      "Test Epoch: 78 | Loss: 0.369 | Acc: 88.923% (2312/2600)\n",
      "Test Epoch: 78 | Loss: 0.366 | Acc: 89.074% (2405/2700)\n",
      "Test Epoch: 78 | Loss: 0.363 | Acc: 89.107% (2495/2800)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.138% (2585/2900)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 89.033% (2671/3000)\n",
      "Test Epoch: 78 | Loss: 0.364 | Acc: 88.903% (2756/3100)\n",
      "Test Epoch: 78 | Loss: 0.362 | Acc: 89.000% (2848/3200)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.061% (2939/3300)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.059% (3028/3400)\n",
      "Test Epoch: 78 | Loss: 0.363 | Acc: 89.000% (3115/3500)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 89.111% (3208/3600)\n",
      "Test Epoch: 78 | Loss: 0.363 | Acc: 89.081% (3296/3700)\n",
      "Test Epoch: 78 | Loss: 0.365 | Acc: 89.000% (3382/3800)\n",
      "Test Epoch: 78 | Loss: 0.364 | Acc: 89.051% (3473/3900)\n",
      "Test Epoch: 78 | Loss: 0.364 | Acc: 89.025% (3561/4000)\n",
      "Test Epoch: 78 | Loss: 0.365 | Acc: 88.902% (3645/4100)\n",
      "Test Epoch: 78 | Loss: 0.364 | Acc: 88.929% (3735/4200)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.023% (3828/4300)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.159% (3923/4400)\n",
      "Test Epoch: 78 | Loss: 0.357 | Acc: 89.178% (4013/4500)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 89.087% (4098/4600)\n",
      "Test Epoch: 78 | Loss: 0.358 | Acc: 89.106% (4188/4700)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 89.042% (4274/4800)\n",
      "Test Epoch: 78 | Loss: 0.356 | Acc: 89.102% (4366/4900)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 88.960% (4448/5000)\n",
      "Test Epoch: 78 | Loss: 0.358 | Acc: 88.941% (4536/5100)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 88.827% (4619/5200)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 88.792% (4706/5300)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 88.907% (4801/5400)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 88.891% (4889/5500)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 88.839% (4975/5600)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 88.789% (5061/5700)\n",
      "Test Epoch: 78 | Loss: 0.358 | Acc: 88.810% (5151/5800)\n",
      "Test Epoch: 78 | Loss: 0.361 | Acc: 88.746% (5236/5900)\n",
      "Test Epoch: 78 | Loss: 0.360 | Acc: 88.717% (5323/6000)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 88.689% (5410/6100)\n",
      "Test Epoch: 78 | Loss: 0.359 | Acc: 88.661% (5497/6200)\n",
      "Test Epoch: 78 | Loss: 0.358 | Acc: 88.746% (5591/6300)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.844% (5686/6400)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.862% (5776/6500)\n",
      "Test Epoch: 78 | Loss: 0.351 | Acc: 88.894% (5867/6600)\n",
      "Test Epoch: 78 | Loss: 0.350 | Acc: 88.925% (5958/6700)\n",
      "Test Epoch: 78 | Loss: 0.351 | Acc: 88.853% (6042/6800)\n",
      "Test Epoch: 78 | Loss: 0.351 | Acc: 88.899% (6134/6900)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 88.857% (6220/7000)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.817% (6306/7100)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.778% (6392/7200)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.836% (6485/7300)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.838% (6574/7400)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.800% (6660/7500)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.829% (6751/7600)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.818% (6839/7700)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.833% (6929/7800)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.823% (7017/7900)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.862% (7109/8000)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 88.926% (7203/8100)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.890% (7289/8200)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 88.892% (7378/8300)\n",
      "Test Epoch: 78 | Loss: 0.351 | Acc: 88.905% (7468/8400)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 88.859% (7553/8500)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.802% (7637/8600)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.828% (7728/8700)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.818% (7816/8800)\n",
      "Test Epoch: 78 | Loss: 0.356 | Acc: 88.809% (7904/8900)\n",
      "Test Epoch: 78 | Loss: 0.356 | Acc: 88.789% (7991/9000)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.846% (8085/9100)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.913% (8180/9200)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.882% (8266/9300)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.872% (8354/9400)\n",
      "Test Epoch: 78 | Loss: 0.354 | Acc: 88.863% (8442/9500)\n",
      "Test Epoch: 78 | Loss: 0.355 | Acc: 88.802% (8525/9600)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.835% (8617/9700)\n",
      "Test Epoch: 78 | Loss: 0.352 | Acc: 88.847% (8707/9800)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.859% (8797/9900)\n",
      "Test Epoch: 78 | Loss: 0.353 | Acc: 88.860% (8886/10000)\n",
      "\n",
      "Epoch: 79\n",
      "Train Epoch: 79 | Loss: 0.201 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 79 | Loss: 0.298 | Acc: 90.625% (232/256)\n",
      "Train Epoch: 79 | Loss: 0.272 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 79 | Loss: 0.262 | Acc: 92.188% (472/512)\n",
      "Train Epoch: 79 | Loss: 0.259 | Acc: 92.031% (589/640)\n",
      "Train Epoch: 79 | Loss: 0.256 | Acc: 91.927% (706/768)\n",
      "Train Epoch: 79 | Loss: 0.261 | Acc: 91.853% (823/896)\n",
      "Train Epoch: 79 | Loss: 0.267 | Acc: 91.406% (936/1024)\n",
      "Train Epoch: 79 | Loss: 0.261 | Acc: 91.840% (1058/1152)\n",
      "Train Epoch: 79 | Loss: 0.255 | Acc: 91.797% (1175/1280)\n",
      "Train Epoch: 79 | Loss: 0.254 | Acc: 91.761% (1292/1408)\n",
      "Train Epoch: 79 | Loss: 0.245 | Acc: 92.057% (1414/1536)\n",
      "Train Epoch: 79 | Loss: 0.239 | Acc: 92.308% (1536/1664)\n",
      "Train Epoch: 79 | Loss: 0.242 | Acc: 92.188% (1652/1792)\n",
      "Train Epoch: 79 | Loss: 0.242 | Acc: 92.240% (1771/1920)\n",
      "Train Epoch: 79 | Loss: 0.244 | Acc: 92.285% (1890/2048)\n",
      "Train Epoch: 79 | Loss: 0.236 | Acc: 92.509% (2013/2176)\n",
      "Train Epoch: 79 | Loss: 0.240 | Acc: 92.231% (2125/2304)\n",
      "Train Epoch: 79 | Loss: 0.237 | Acc: 92.229% (2243/2432)\n",
      "Train Epoch: 79 | Loss: 0.233 | Acc: 92.344% (2364/2560)\n",
      "Train Epoch: 79 | Loss: 0.234 | Acc: 92.411% (2484/2688)\n",
      "Train Epoch: 79 | Loss: 0.230 | Acc: 92.578% (2607/2816)\n",
      "Train Epoch: 79 | Loss: 0.234 | Acc: 92.459% (2722/2944)\n",
      "Train Epoch: 79 | Loss: 0.235 | Acc: 92.350% (2837/3072)\n",
      "Train Epoch: 79 | Loss: 0.234 | Acc: 92.469% (2959/3200)\n",
      "Train Epoch: 79 | Loss: 0.233 | Acc: 92.428% (3076/3328)\n",
      "Train Epoch: 79 | Loss: 0.235 | Acc: 92.419% (3194/3456)\n",
      "Train Epoch: 79 | Loss: 0.233 | Acc: 92.439% (3313/3584)\n",
      "Train Epoch: 79 | Loss: 0.230 | Acc: 92.484% (3433/3712)\n",
      "Train Epoch: 79 | Loss: 0.228 | Acc: 92.396% (3548/3840)\n",
      "Train Epoch: 79 | Loss: 0.226 | Acc: 92.465% (3669/3968)\n",
      "Train Epoch: 79 | Loss: 0.227 | Acc: 92.432% (3786/4096)\n",
      "Train Epoch: 79 | Loss: 0.225 | Acc: 92.472% (3906/4224)\n",
      "Train Epoch: 79 | Loss: 0.225 | Acc: 92.371% (4020/4352)\n",
      "Train Epoch: 79 | Loss: 0.225 | Acc: 92.433% (4141/4480)\n",
      "Train Epoch: 79 | Loss: 0.224 | Acc: 92.405% (4258/4608)\n",
      "Train Epoch: 79 | Loss: 0.225 | Acc: 92.399% (4376/4736)\n",
      "Train Epoch: 79 | Loss: 0.223 | Acc: 92.475% (4498/4864)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.508% (4618/4992)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.500% (4736/5120)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.473% (4853/5248)\n",
      "Train Epoch: 79 | Loss: 0.223 | Acc: 92.429% (4969/5376)\n",
      "Train Epoch: 79 | Loss: 0.224 | Acc: 92.460% (5089/5504)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.525% (5211/5632)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.569% (5332/5760)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.544% (5449/5888)\n",
      "Train Epoch: 79 | Loss: 0.222 | Acc: 92.553% (5568/6016)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.546% (5686/6144)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.618% (5809/6272)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.516% (5921/6400)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.433% (6034/6528)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.428% (6152/6656)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.409% (6269/6784)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.419% (6388/6912)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.443% (6508/7040)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.536% (6633/7168)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.599% (6756/7296)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.645% (6878/7424)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.717% (7002/7552)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.682% (7118/7680)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.700% (7238/7808)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.679% (7355/7936)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.584% (7466/8064)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.529% (7580/8192)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.488% (7695/8320)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.495% (7814/8448)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.479% (7931/8576)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.509% (8052/8704)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.561% (8175/8832)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.522% (8290/8960)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.507% (8407/9088)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.502% (8525/9216)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.530% (8646/9344)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.483% (8760/9472)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.490% (8879/9600)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.516% (9000/9728)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.543% (9121/9856)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.588% (9244/9984)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.613% (9365/10112)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.627% (9485/10240)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.622% (9603/10368)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.626% (9722/10496)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.602% (9838/10624)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.569% (9953/10752)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.619% (10077/10880)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.633% (10197/11008)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.645% (10317/11136)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.605% (10431/11264)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.644% (10554/11392)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.630% (10671/11520)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.643% (10791/11648)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.638% (10909/11776)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.608% (11024/11904)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.620% (11144/12032)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.599% (11260/12160)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.635% (11383/12288)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.655% (11504/12416)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.690% (11627/12544)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.669% (11743/12672)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.672% (11862/12800)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.698% (11984/12928)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.693% (12102/13056)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.711% (12223/13184)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.706% (12341/13312)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.716% (12461/13440)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.703% (12578/13568)\n",
      "Train Epoch: 79 | Loss: 0.210 | Acc: 92.742% (12702/13696)\n",
      "Train Epoch: 79 | Loss: 0.210 | Acc: 92.759% (12823/13824)\n",
      "Train Epoch: 79 | Loss: 0.210 | Acc: 92.747% (12940/13952)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.692% (13051/14080)\n",
      "Train Epoch: 79 | Loss: 0.210 | Acc: 92.729% (13175/14208)\n",
      "Train Epoch: 79 | Loss: 0.210 | Acc: 92.711% (13291/14336)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.671% (13404/14464)\n",
      "Train Epoch: 79 | Loss: 0.211 | Acc: 92.674% (13523/14592)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.677% (13642/14720)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.686% (13762/14848)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.682% (13880/14976)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.638% (13992/15104)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.647% (14112/15232)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.669% (14234/15360)\n",
      "Train Epoch: 79 | Loss: 0.212 | Acc: 92.665% (14352/15488)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.649% (14468/15616)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.645% (14586/15744)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.641% (14704/15872)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.625% (14820/16000)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.622% (14938/16128)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.637% (15059/16256)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.609% (15173/16384)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.599% (15290/16512)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.602% (15409/16640)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.587% (15525/16768)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.625% (15650/16896)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.605% (15765/17024)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.625% (15887/17152)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.598% (16001/17280)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.590% (16118/17408)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.598% (16238/17536)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.623% (16361/17664)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.598% (16475/17792)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.600% (16594/17920)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.575% (16708/18048)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.556% (16823/18176)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.548% (16940/18304)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.546% (17058/18432)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.543% (17176/18560)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.535% (17293/18688)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.533% (17411/18816)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.552% (17533/18944)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.544% (17650/19072)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.552% (17770/19200)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.565% (17891/19328)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.558% (18008/19456)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.555% (18126/19584)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.578% (18249/19712)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.550% (18362/19840)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.543% (18479/19968)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.551% (18599/20096)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.568% (18721/20224)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.551% (18836/20352)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.563% (18957/20480)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.561% (19075/20608)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.559% (19193/20736)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.590% (19318/20864)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.592% (19437/20992)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.590% (19555/21120)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.611% (19678/21248)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.632% (19801/21376)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.634% (19920/21504)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.622% (20036/21632)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.633% (20157/21760)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.626% (20274/21888)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.614% (20390/22016)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.626% (20511/22144)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.628% (20630/22272)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.634% (20750/22400)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.627% (20867/22528)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.642% (20989/22656)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.644% (21108/22784)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.650% (21228/22912)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.630% (21342/23040)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.636% (21462/23168)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.643% (21582/23296)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.631% (21698/23424)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.633% (21817/23552)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.644% (21938/23680)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.641% (22056/23808)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.639% (22174/23936)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.649% (22295/24064)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.646% (22413/24192)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.660% (22535/24320)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.650% (22651/24448)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.655% (22771/24576)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.637% (22885/24704)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.639% (23004/24832)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.628% (23120/24960)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.626% (23238/25088)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.648% (23362/25216)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.649% (23481/25344)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.647% (23599/25472)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.668% (23723/25600)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.666% (23841/25728)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.675% (23962/25856)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.665% (24078/25984)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.674% (24199/26112)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.683% (24320/26240)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.681% (24438/26368)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.689% (24559/26496)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.698% (24680/26624)\n",
      "Train Epoch: 79 | Loss: 0.213 | Acc: 92.711% (24802/26752)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.705% (24919/26880)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.702% (25037/27008)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.696% (25154/27136)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.686% (25270/27264)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.684% (25388/27392)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.678% (25505/27520)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.669% (25621/27648)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.674% (25741/27776)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.664% (25857/27904)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.673% (25978/28032)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.663% (26094/28160)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.665% (26213/28288)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.666% (26332/28416)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.671% (26452/28544)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.679% (26573/28672)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.677% (26691/28800)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.668% (26807/28928)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.656% (26922/29056)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.660% (27042/29184)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.648% (27157/29312)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.643% (27274/29440)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.671% (27401/29568)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.683% (27523/29696)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.687% (27643/29824)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.688% (27762/29952)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.673% (27876/30080)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.674% (27995/30208)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.675% (28114/30336)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.677% (28233/30464)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.668% (28349/30592)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.643% (28460/30720)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.658% (28583/30848)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.659% (28702/30976)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.660% (28821/31104)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.658% (28939/31232)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.659% (29058/31360)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.673% (29181/31488)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.675% (29300/31616)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.660% (29414/31744)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.661% (29533/31872)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.641% (29645/32000)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.636% (29762/32128)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.646% (29884/32256)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.641% (30001/32384)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.649% (30122/32512)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.659% (30244/32640)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.654% (30361/32768)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.653% (30479/32896)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.660% (30600/33024)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.676% (30724/33152)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.662% (30838/33280)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.657% (30955/33408)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.659% (31074/33536)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.666% (31195/33664)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.670% (31315/33792)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.680% (31437/33920)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.687% (31558/34048)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.682% (31675/34176)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.674% (31791/34304)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.667% (31907/34432)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.677% (32029/34560)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.672% (32146/34688)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.656% (32259/34816)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.654% (32377/34944)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.649% (32494/35072)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.665% (32618/35200)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.663% (32736/35328)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.639% (32846/35456)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.643% (32966/35584)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.627% (33079/35712)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.634% (33200/35840)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.641% (33321/35968)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.634% (33437/36096)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.632% (33555/36224)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.636% (33675/36352)\n",
      "Train Epoch: 79 | Loss: 0.214 | Acc: 92.634% (33793/36480)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.641% (33914/36608)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.634% (34030/36736)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.635% (34149/36864)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.636% (34268/36992)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.637% (34387/37120)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.630% (34503/37248)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.632% (34622/37376)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.619% (34736/37504)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.621% (34855/37632)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.619% (34973/37760)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.620% (35092/37888)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.614% (35208/38016)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.620% (35329/38144)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.616% (35446/38272)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.615% (35564/38400)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.616% (35683/38528)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.586% (35790/38656)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.582% (35907/38784)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.594% (36030/38912)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.595% (36149/39040)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.576% (36260/39168)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.569% (36376/39296)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.571% (36495/39424)\n",
      "Train Epoch: 79 | Loss: 0.215 | Acc: 92.577% (36616/39552)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.563% (36729/39680)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.564% (36848/39808)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.561% (36965/39936)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.554% (37081/40064)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.548% (37197/40192)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.557% (37319/40320)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.561% (37439/40448)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.560% (37557/40576)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.556% (37674/40704)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.538% (37785/40832)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.546% (37907/40960)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.540% (38023/41088)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.542% (38142/41216)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.555% (38266/41344)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.566% (38389/41472)\n",
      "Train Epoch: 79 | Loss: 0.216 | Acc: 92.565% (38507/41600)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.557% (38622/41728)\n",
      "Train Epoch: 79 | Loss: 0.217 | Acc: 92.551% (38738/41856)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.535% (38850/41984)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.541% (38971/42112)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.526% (39083/42240)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.525% (39201/42368)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.512% (39314/42496)\n",
      "Train Epoch: 79 | Loss: 0.218 | Acc: 92.502% (39428/42624)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.489% (39541/42752)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.491% (39660/42880)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.492% (39779/43008)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.498% (39900/43136)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.495% (40017/43264)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.496% (40136/43392)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.491% (40252/43520)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.492% (40371/43648)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.491% (40489/43776)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.484% (40604/43904)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.490% (40725/44032)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.500% (40848/44160)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.501% (40967/44288)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.509% (41089/44416)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.500% (41203/44544)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.510% (41326/44672)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.513% (41446/44800)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.512% (41564/44928)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.516% (41684/45056)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.511% (41800/45184)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.505% (41916/45312)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.513% (42038/45440)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.510% (42155/45568)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.498% (42268/45696)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.500% (42387/45824)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.501% (42506/45952)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.511% (42629/46080)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.508% (42746/46208)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.516% (42868/46336)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.508% (42983/46464)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.509% (43102/46592)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.513% (43222/46720)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.508% (43338/46848)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.507% (43456/46976)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.506% (43574/47104)\n",
      "Train Epoch: 79 | Loss: 0.219 | Acc: 92.505% (43692/47232)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.489% (43803/47360)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.470% (43912/47488)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.461% (44026/47616)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.447% (44138/47744)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.444% (44255/47872)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.440% (44371/48000)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.447% (44493/48128)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.444% (44610/48256)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.442% (44727/48384)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.441% (44845/48512)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.449% (44967/48640)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.446% (45084/48768)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.449% (45204/48896)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.447% (45321/49024)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.448% (45440/49152)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.451% (45560/49280)\n",
      "Train Epoch: 79 | Loss: 0.220 | Acc: 92.445% (45675/49408)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.432% (45787/49536)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.429% (45904/49664)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.437% (46026/49792)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.430% (46141/49920)\n",
      "Train Epoch: 79 | Loss: 0.221 | Acc: 92.426% (46213/50000)\n",
      "Test Epoch: 79 | Loss: 0.225 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 79 | Loss: 0.311 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 79 | Loss: 0.309 | Acc: 88.000% (264/300)\n",
      "Test Epoch: 79 | Loss: 0.304 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 79 | Loss: 0.318 | Acc: 89.000% (445/500)\n",
      "Test Epoch: 79 | Loss: 0.301 | Acc: 89.833% (539/600)\n",
      "Test Epoch: 79 | Loss: 0.307 | Acc: 89.857% (629/700)\n",
      "Test Epoch: 79 | Loss: 0.331 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 79 | Loss: 0.341 | Acc: 88.778% (799/900)\n",
      "Test Epoch: 79 | Loss: 0.349 | Acc: 88.700% (887/1000)\n",
      "Test Epoch: 79 | Loss: 0.341 | Acc: 88.818% (977/1100)\n",
      "Test Epoch: 79 | Loss: 0.343 | Acc: 88.583% (1063/1200)\n",
      "Test Epoch: 79 | Loss: 0.335 | Acc: 88.538% (1151/1300)\n",
      "Test Epoch: 79 | Loss: 0.334 | Acc: 88.500% (1239/1400)\n",
      "Test Epoch: 79 | Loss: 0.338 | Acc: 88.533% (1328/1500)\n",
      "Test Epoch: 79 | Loss: 0.337 | Acc: 88.625% (1418/1600)\n",
      "Test Epoch: 79 | Loss: 0.337 | Acc: 88.706% (1508/1700)\n",
      "Test Epoch: 79 | Loss: 0.342 | Acc: 88.500% (1593/1800)\n",
      "Test Epoch: 79 | Loss: 0.345 | Acc: 88.474% (1681/1900)\n",
      "Test Epoch: 79 | Loss: 0.345 | Acc: 88.550% (1771/2000)\n",
      "Test Epoch: 79 | Loss: 0.350 | Acc: 88.667% (1862/2100)\n",
      "Test Epoch: 79 | Loss: 0.348 | Acc: 88.682% (1951/2200)\n",
      "Test Epoch: 79 | Loss: 0.351 | Acc: 88.565% (2037/2300)\n",
      "Test Epoch: 79 | Loss: 0.346 | Acc: 88.625% (2127/2400)\n",
      "Test Epoch: 79 | Loss: 0.356 | Acc: 88.520% (2213/2500)\n",
      "Test Epoch: 79 | Loss: 0.368 | Acc: 88.231% (2294/2600)\n",
      "Test Epoch: 79 | Loss: 0.366 | Acc: 88.259% (2383/2700)\n",
      "Test Epoch: 79 | Loss: 0.365 | Acc: 88.250% (2471/2800)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.103% (2555/2900)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 87.900% (2637/3000)\n",
      "Test Epoch: 79 | Loss: 0.376 | Acc: 87.742% (2720/3100)\n",
      "Test Epoch: 79 | Loss: 0.376 | Acc: 87.781% (2809/3200)\n",
      "Test Epoch: 79 | Loss: 0.377 | Acc: 87.788% (2897/3300)\n",
      "Test Epoch: 79 | Loss: 0.377 | Acc: 87.824% (2986/3400)\n",
      "Test Epoch: 79 | Loss: 0.382 | Acc: 87.743% (3071/3500)\n",
      "Test Epoch: 79 | Loss: 0.382 | Acc: 87.778% (3160/3600)\n",
      "Test Epoch: 79 | Loss: 0.382 | Acc: 87.865% (3251/3700)\n",
      "Test Epoch: 79 | Loss: 0.383 | Acc: 87.842% (3338/3800)\n",
      "Test Epoch: 79 | Loss: 0.380 | Acc: 87.949% (3430/3900)\n",
      "Test Epoch: 79 | Loss: 0.378 | Acc: 88.000% (3520/4000)\n",
      "Test Epoch: 79 | Loss: 0.377 | Acc: 88.098% (3612/4100)\n",
      "Test Epoch: 79 | Loss: 0.376 | Acc: 88.167% (3703/4200)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.256% (3795/4300)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.386% (3889/4400)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.400% (3978/4500)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.326% (4063/4600)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.426% (4156/4700)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 88.375% (4242/4800)\n",
      "Test Epoch: 79 | Loss: 0.370 | Acc: 88.490% (4336/4900)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.420% (4421/5000)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.569% (4517/5100)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.615% (4608/5200)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.604% (4696/5300)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.630% (4786/5400)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.673% (4877/5500)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.679% (4966/5600)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.649% (5053/5700)\n",
      "Test Epoch: 79 | Loss: 0.369 | Acc: 88.655% (5142/5800)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.508% (5222/5900)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.517% (5311/6000)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.475% (5397/6100)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.419% (5482/6200)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.460% (5573/6300)\n",
      "Test Epoch: 79 | Loss: 0.369 | Acc: 88.531% (5666/6400)\n",
      "Test Epoch: 79 | Loss: 0.370 | Acc: 88.523% (5754/6500)\n",
      "Test Epoch: 79 | Loss: 0.370 | Acc: 88.530% (5843/6600)\n",
      "Test Epoch: 79 | Loss: 0.368 | Acc: 88.567% (5934/6700)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.485% (6017/6800)\n",
      "Test Epoch: 79 | Loss: 0.370 | Acc: 88.507% (6107/6900)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.457% (6192/7000)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.465% (6281/7100)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 88.458% (6369/7200)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.521% (6462/7300)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.514% (6550/7400)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.480% (6636/7500)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.461% (6723/7600)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 88.468% (6812/7700)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 88.513% (6904/7800)\n",
      "Test Epoch: 79 | Loss: 0.374 | Acc: 88.519% (6993/7900)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.537% (7083/8000)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.617% (7178/8100)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.573% (7263/8200)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.602% (7354/8300)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.631% (7445/8400)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.600% (7531/8500)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.570% (7617/8600)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.563% (7705/8700)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.511% (7789/8800)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.472% (7874/8900)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.467% (7962/9000)\n",
      "Test Epoch: 79 | Loss: 0.375 | Acc: 88.484% (8052/9100)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.533% (8145/9200)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.516% (8232/9300)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.511% (8320/9400)\n",
      "Test Epoch: 79 | Loss: 0.372 | Acc: 88.516% (8409/9500)\n",
      "Test Epoch: 79 | Loss: 0.373 | Acc: 88.500% (8496/9600)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.526% (8587/9700)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.510% (8674/9800)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.535% (8765/9900)\n",
      "Test Epoch: 79 | Loss: 0.371 | Acc: 88.530% (8853/10000)\n",
      "\n",
      "Epoch: 80\n",
      "Train Epoch: 80 | Loss: 0.162 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 80 | Loss: 0.196 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 80 | Loss: 0.188 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.812% (594/640)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.318% (709/768)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.299% (827/896)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.383% (946/1024)\n",
      "Train Epoch: 80 | Loss: 0.202 | Acc: 92.622% (1067/1152)\n",
      "Train Epoch: 80 | Loss: 0.203 | Acc: 92.578% (1185/1280)\n",
      "Train Epoch: 80 | Loss: 0.200 | Acc: 92.756% (1306/1408)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.643% (1423/1536)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.668% (1542/1664)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.634% (1660/1792)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.708% (1780/1920)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.529% (1895/2048)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.463% (2012/2176)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.405% (2129/2304)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.434% (2248/2432)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.461% (2367/2560)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.522% (2487/2688)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.472% (2604/2816)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.595% (2726/2944)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.643% (2846/3072)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.656% (2965/3200)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.728% (3086/3328)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.766% (3206/3456)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.718% (3323/3584)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.672% (3440/3712)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.734% (3561/3840)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.666% (3677/3968)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.480% (3788/4096)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.519% (3908/4224)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.647% (4032/4352)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.634% (4150/4480)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.491% (4262/4608)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.589% (4385/4736)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.640% (4506/4864)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.588% (4622/4992)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.637% (4743/5120)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.664% (4863/5248)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.653% (4981/5376)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.642% (5099/5504)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.649% (5218/5632)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.674% (5338/5760)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.714% (5459/5888)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.769% (5581/6016)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.855% (5705/6144)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.793% (5820/6272)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.750% (5936/6400)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.816% (6059/6528)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.819% (6178/6656)\n",
      "Train Epoch: 80 | Loss: 0.203 | Acc: 92.910% (6303/6784)\n",
      "Train Epoch: 80 | Loss: 0.203 | Acc: 92.911% (6422/6912)\n",
      "Train Epoch: 80 | Loss: 0.203 | Acc: 92.912% (6541/7040)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.871% (6657/7168)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.777% (6769/7296)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.713% (6883/7424)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.704% (7001/7552)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.734% (7122/7680)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.700% (7238/7808)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.654% (7353/7936)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.721% (7477/8064)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.700% (7594/8192)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.740% (7716/8320)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.685% (7830/8448)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.747% (7954/8576)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.785% (8076/8704)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.754% (8192/8832)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.779% (8313/8960)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.859% (8439/9088)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.817% (8554/9216)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.830% (8674/9344)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.821% (8792/9472)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.823% (8911/9600)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.845% (9032/9728)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.857% (9152/9856)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.889% (9274/9984)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.890% (9393/10112)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.910% (9514/10240)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.901% (9632/10368)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.912% (9752/10496)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.903% (9870/10624)\n",
      "Train Epoch: 80 | Loss: 0.203 | Acc: 92.932% (9992/10752)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.904% (10108/10880)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.878% (10224/11008)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.870% (10342/11136)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.862% (10460/11264)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.855% (10578/11392)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.865% (10698/11520)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.874% (10818/11648)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.875% (10937/11776)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.910% (11060/11904)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.886% (11176/12032)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.895% (11296/12160)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.896% (11415/12288)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.888% (11533/12416)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.873% (11650/12544)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.858% (11767/12672)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.883% (11889/12800)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.891% (12009/12928)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.907% (12130/13056)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.908% (12249/13184)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.886% (12365/13312)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.857% (12480/13440)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.888% (12603/13568)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.881% (12721/13696)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.889% (12841/13824)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.861% (12956/13952)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.884% (13078/14080)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.870% (13195/14208)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.892% (13317/14336)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.927% (13441/14464)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.928% (13560/14592)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.921% (13678/14720)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.955% (13802/14848)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.935% (13918/14976)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.949% (14039/15104)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.916% (14153/15232)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.917% (14272/15360)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.936% (14394/15488)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.930% (14512/15616)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.950% (14634/15744)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.931% (14750/15872)\n",
      "Train Epoch: 80 | Loss: 0.204 | Acc: 92.950% (14872/16000)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.932% (14988/16128)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.932% (15107/16256)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.914% (15223/16384)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.902% (15340/16512)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.873% (15454/16640)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.885% (15575/16768)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.898% (15696/16896)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.916% (15818/17024)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.905% (15935/17152)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.911% (16055/17280)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.888% (16170/17408)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.889% (16289/17536)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.895% (16409/17664)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.890% (16527/17792)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.891% (16646/17920)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.880% (16763/18048)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.864% (16879/18176)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.843% (16994/18304)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.844% (17113/18432)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.845% (17232/18560)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.851% (17352/18688)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.847% (17470/18816)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.863% (17592/18944)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.864% (17711/19072)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.859% (17829/19200)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.891% (17954/19328)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.892% (18073/19456)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.907% (18195/19584)\n",
      "Train Epoch: 80 | Loss: 0.205 | Acc: 92.908% (18314/19712)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.888% (18429/19840)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.869% (18544/19968)\n",
      "Train Epoch: 80 | Loss: 0.206 | Acc: 92.864% (18662/20096)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.840% (18776/20224)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.821% (18891/20352)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.798% (19005/20480)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.770% (19118/20608)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.785% (19240/20736)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.782% (19358/20864)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.783% (19477/20992)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.779% (19595/21120)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.790% (19716/21248)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.796% (19836/21376)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.815% (19959/21504)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.812% (20077/21632)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.817% (20197/21760)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.823% (20317/21888)\n",
      "Train Epoch: 80 | Loss: 0.207 | Acc: 92.828% (20437/22016)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.815% (20553/22144)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.798% (20668/22272)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.781% (20783/22400)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.773% (20900/22528)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.757% (21015/22656)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.745% (21131/22784)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.733% (21247/22912)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.726% (21364/23040)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.749% (21488/23168)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.750% (21607/23296)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.755% (21727/23424)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.778% (21851/23552)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.758% (21965/23680)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.780% (22089/23808)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.810% (22215/23936)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.815% (22335/24064)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.803% (22451/24192)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.808% (22571/24320)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.821% (22693/24448)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.810% (22809/24576)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.807% (22927/24704)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.812% (23047/24832)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.817% (23167/24960)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.817% (23286/25088)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.826% (23407/25216)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.811% (23522/25344)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.823% (23644/25472)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.809% (23759/25600)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.802% (23876/25728)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.802% (23995/25856)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.792% (24111/25984)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.777% (24226/26112)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.774% (24344/26240)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.783% (24465/26368)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.791% (24586/26496)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.796% (24706/26624)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.801% (24826/26752)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.798% (24944/26880)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.806% (25065/27008)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.796% (25181/27136)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.807% (25303/27264)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.808% (25422/27392)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.816% (25543/27520)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.810% (25660/27648)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.810% (25779/27776)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.815% (25899/27904)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.812% (26017/28032)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.798% (26132/28160)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.785% (26247/28288)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.789% (26367/28416)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.801% (26489/28544)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.794% (26606/28672)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.799% (26726/28800)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.799% (26845/28928)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.800% (26964/29056)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.811% (27086/29184)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.808% (27204/29312)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.809% (27323/29440)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.820% (27445/29568)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.810% (27561/29696)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.818% (27682/29824)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.825% (27803/29952)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.826% (27922/30080)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.823% (28040/30208)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.814% (28156/30336)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.801% (28271/30464)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.802% (28390/30592)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.799% (28508/30720)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.813% (28631/30848)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.811% (28749/30976)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.798% (28864/31104)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.783% (28978/31232)\n",
      "Train Epoch: 80 | Loss: 0.208 | Acc: 92.784% (29097/31360)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.794% (29219/31488)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.776% (29332/31616)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.780% (29452/31744)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.768% (29567/31872)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.769% (29686/32000)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.757% (29801/32128)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.758% (29920/32256)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.762% (30040/32384)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.766% (30160/32512)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.757% (30276/32640)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.743% (30390/32768)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.753% (30512/32896)\n",
      "Train Epoch: 80 | Loss: 0.209 | Acc: 92.751% (30630/33024)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.746% (30747/33152)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.746% (30866/33280)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.729% (30979/33408)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.706% (31090/33536)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.713% (31211/33664)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.708% (31328/33792)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.703% (31445/33920)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.710% (31566/34048)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.714% (31686/34176)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.698% (31799/34304)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.681% (31912/34432)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.700% (32037/34560)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.695% (32154/34688)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.702% (32275/34816)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.708% (32396/34944)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.704% (32513/35072)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.688% (32626/35200)\n",
      "Train Epoch: 80 | Loss: 0.210 | Acc: 92.691% (32746/35328)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.670% (32857/35456)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.665% (32974/35584)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.666% (33093/35712)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.676% (33215/35840)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.677% (33334/35968)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.675% (33452/36096)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.668% (33568/36224)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.661% (33684/36352)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.654% (33800/36480)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.649% (33917/36608)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.658% (34039/36736)\n",
      "Train Epoch: 80 | Loss: 0.211 | Acc: 92.635% (34149/36864)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.631% (34266/36992)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.635% (34386/37120)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.633% (34504/37248)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.624% (34619/37376)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.625% (34738/37504)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.621% (34855/37632)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.614% (34971/37760)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.605% (35086/37888)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.616% (35209/38016)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.620% (35329/38144)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.621% (35448/38272)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.625% (35568/38400)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.626% (35687/38528)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.627% (35806/38656)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.623% (35923/38784)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.617% (36039/38912)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.613% (36156/39040)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.606% (36272/39168)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.602% (36389/39296)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.593% (36504/39424)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.602% (36626/39552)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.596% (36742/39680)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.602% (36863/39808)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.611% (36985/39936)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.604% (37101/40064)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.603% (37219/40192)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.607% (37339/40320)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.605% (37457/40448)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.609% (37577/40576)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.605% (37694/40704)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.594% (37808/40832)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.603% (37930/40960)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.604% (38049/41088)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.612% (38171/41216)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.608% (38288/41344)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.593% (38400/41472)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.589% (38517/41600)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.597% (38639/41728)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.608% (38762/41856)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.609% (38881/41984)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.598% (38995/42112)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.597% (39113/42240)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.603% (39234/42368)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.599% (39351/42496)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.600% (39470/42624)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.606% (39591/42752)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.607% (39710/42880)\n",
      "Train Epoch: 80 | Loss: 0.212 | Acc: 92.613% (39831/43008)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.612% (39949/43136)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.608% (40066/43264)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.591% (40177/43392)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.606% (40302/43520)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.593% (40415/43648)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.594% (40534/43776)\n",
      "Train Epoch: 80 | Loss: 0.213 | Acc: 92.584% (40648/43904)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.569% (40760/44032)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.572% (40880/44160)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.569% (40997/44288)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.582% (41121/44416)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.580% (41239/44544)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.573% (41354/44672)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.571% (41472/44800)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.564% (41587/44928)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.574% (41710/45056)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.573% (41828/45184)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.574% (41947/45312)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.570% (42064/45440)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.567% (42181/45568)\n",
      "Train Epoch: 80 | Loss: 0.214 | Acc: 92.551% (42292/45696)\n",
      "Train Epoch: 80 | Loss: 0.215 | Acc: 92.541% (42406/45824)\n",
      "Train Epoch: 80 | Loss: 0.215 | Acc: 92.531% (42520/45952)\n",
      "Train Epoch: 80 | Loss: 0.215 | Acc: 92.537% (42641/46080)\n",
      "Train Epoch: 80 | Loss: 0.215 | Acc: 92.529% (42756/46208)\n",
      "Train Epoch: 80 | Loss: 0.216 | Acc: 92.522% (42871/46336)\n",
      "Train Epoch: 80 | Loss: 0.216 | Acc: 92.528% (42992/46464)\n",
      "Train Epoch: 80 | Loss: 0.215 | Acc: 92.527% (43110/46592)\n",
      "Train Epoch: 80 | Loss: 0.216 | Acc: 92.517% (43224/46720)\n",
      "Train Epoch: 80 | Loss: 0.216 | Acc: 92.520% (43344/46848)\n",
      "Train Epoch: 80 | Loss: 0.216 | Acc: 92.509% (43457/46976)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.510% (43576/47104)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.501% (43690/47232)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.498% (43807/47360)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.499% (43926/47488)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.503% (44046/47616)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.483% (44155/47744)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.484% (44274/47872)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.483% (44392/48000)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.489% (44513/48128)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.492% (44633/48256)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.485% (44748/48384)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.482% (44865/48512)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.477% (44981/48640)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.475% (45098/48768)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.470% (45214/48896)\n",
      "Train Epoch: 80 | Loss: 0.218 | Acc: 92.469% (45332/49024)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.474% (45453/49152)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.478% (45573/49280)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.481% (45693/49408)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.482% (45812/49536)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.481% (45930/49664)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.479% (46047/49792)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.484% (46168/49920)\n",
      "Train Epoch: 80 | Loss: 0.217 | Acc: 92.492% (46246/50000)\n",
      "Test Epoch: 80 | Loss: 0.266 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 80 | Loss: 0.263 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 80 | Loss: 0.269 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 80 | Loss: 0.265 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 80 | Loss: 0.252 | Acc: 92.200% (461/500)\n",
      "Test Epoch: 80 | Loss: 0.259 | Acc: 91.833% (551/600)\n",
      "Test Epoch: 80 | Loss: 0.266 | Acc: 91.571% (641/700)\n",
      "Test Epoch: 80 | Loss: 0.299 | Acc: 90.500% (724/800)\n",
      "Test Epoch: 80 | Loss: 0.321 | Acc: 90.333% (813/900)\n",
      "Test Epoch: 80 | Loss: 0.321 | Acc: 90.100% (901/1000)\n",
      "Test Epoch: 80 | Loss: 0.316 | Acc: 90.182% (992/1100)\n",
      "Test Epoch: 80 | Loss: 0.320 | Acc: 90.083% (1081/1200)\n",
      "Test Epoch: 80 | Loss: 0.313 | Acc: 90.154% (1172/1300)\n",
      "Test Epoch: 80 | Loss: 0.322 | Acc: 89.857% (1258/1400)\n",
      "Test Epoch: 80 | Loss: 0.322 | Acc: 89.733% (1346/1500)\n",
      "Test Epoch: 80 | Loss: 0.322 | Acc: 89.688% (1435/1600)\n",
      "Test Epoch: 80 | Loss: 0.323 | Acc: 89.706% (1525/1700)\n",
      "Test Epoch: 80 | Loss: 0.330 | Acc: 89.500% (1611/1800)\n",
      "Test Epoch: 80 | Loss: 0.328 | Acc: 89.526% (1701/1900)\n",
      "Test Epoch: 80 | Loss: 0.334 | Acc: 89.600% (1792/2000)\n",
      "Test Epoch: 80 | Loss: 0.345 | Acc: 89.286% (1875/2100)\n",
      "Test Epoch: 80 | Loss: 0.345 | Acc: 89.318% (1965/2200)\n",
      "Test Epoch: 80 | Loss: 0.345 | Acc: 89.304% (2054/2300)\n",
      "Test Epoch: 80 | Loss: 0.346 | Acc: 89.167% (2140/2400)\n",
      "Test Epoch: 80 | Loss: 0.357 | Acc: 88.920% (2223/2500)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.692% (2306/2600)\n",
      "Test Epoch: 80 | Loss: 0.366 | Acc: 88.778% (2397/2700)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.714% (2484/2800)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.552% (2568/2900)\n",
      "Test Epoch: 80 | Loss: 0.376 | Acc: 88.467% (2654/3000)\n",
      "Test Epoch: 80 | Loss: 0.375 | Acc: 88.452% (2742/3100)\n",
      "Test Epoch: 80 | Loss: 0.372 | Acc: 88.531% (2833/3200)\n",
      "Test Epoch: 80 | Loss: 0.370 | Acc: 88.455% (2919/3300)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.382% (3005/3400)\n",
      "Test Epoch: 80 | Loss: 0.377 | Acc: 88.343% (3092/3500)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.306% (3179/3600)\n",
      "Test Epoch: 80 | Loss: 0.381 | Acc: 88.270% (3266/3700)\n",
      "Test Epoch: 80 | Loss: 0.384 | Acc: 88.132% (3349/3800)\n",
      "Test Epoch: 80 | Loss: 0.383 | Acc: 88.154% (3438/3900)\n",
      "Test Epoch: 80 | Loss: 0.385 | Acc: 88.125% (3525/4000)\n",
      "Test Epoch: 80 | Loss: 0.386 | Acc: 88.024% (3609/4100)\n",
      "Test Epoch: 80 | Loss: 0.387 | Acc: 87.929% (3693/4200)\n",
      "Test Epoch: 80 | Loss: 0.383 | Acc: 88.047% (3786/4300)\n",
      "Test Epoch: 80 | Loss: 0.381 | Acc: 88.136% (3878/4400)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.133% (3966/4500)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.130% (4054/4600)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.085% (4140/4700)\n",
      "Test Epoch: 80 | Loss: 0.383 | Acc: 87.979% (4223/4800)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.102% (4317/4900)\n",
      "Test Epoch: 80 | Loss: 0.385 | Acc: 87.980% (4399/5000)\n",
      "Test Epoch: 80 | Loss: 0.383 | Acc: 88.039% (4490/5100)\n",
      "Test Epoch: 80 | Loss: 0.383 | Acc: 88.058% (4579/5200)\n",
      "Test Epoch: 80 | Loss: 0.381 | Acc: 88.038% (4666/5300)\n",
      "Test Epoch: 80 | Loss: 0.378 | Acc: 88.111% (4758/5400)\n",
      "Test Epoch: 80 | Loss: 0.380 | Acc: 88.055% (4843/5500)\n",
      "Test Epoch: 80 | Loss: 0.381 | Acc: 88.036% (4930/5600)\n",
      "Test Epoch: 80 | Loss: 0.382 | Acc: 88.000% (5016/5700)\n",
      "Test Epoch: 80 | Loss: 0.381 | Acc: 88.034% (5106/5800)\n",
      "Test Epoch: 80 | Loss: 0.380 | Acc: 88.017% (5193/5900)\n",
      "Test Epoch: 80 | Loss: 0.378 | Acc: 88.017% (5281/6000)\n",
      "Test Epoch: 80 | Loss: 0.380 | Acc: 88.000% (5368/6100)\n",
      "Test Epoch: 80 | Loss: 0.379 | Acc: 88.000% (5456/6200)\n",
      "Test Epoch: 80 | Loss: 0.378 | Acc: 88.063% (5548/6300)\n",
      "Test Epoch: 80 | Loss: 0.376 | Acc: 88.188% (5644/6400)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.200% (5733/6500)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.197% (5821/6600)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.254% (5913/6700)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.206% (5998/6800)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.261% (6090/6900)\n",
      "Test Epoch: 80 | Loss: 0.372 | Acc: 88.257% (6178/7000)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.268% (6267/7100)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.278% (6356/7200)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.370% (6451/7300)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.351% (6538/7400)\n",
      "Test Epoch: 80 | Loss: 0.372 | Acc: 88.373% (6628/7500)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.355% (6715/7600)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.299% (6799/7700)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.333% (6890/7800)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.329% (6978/7900)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.325% (7066/8000)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.346% (7156/8100)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.378% (7247/8200)\n",
      "Test Epoch: 80 | Loss: 0.370 | Acc: 88.325% (7331/8300)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.345% (7421/8400)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.247% (7501/8500)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.209% (7586/8600)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.195% (7673/8700)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.182% (7760/8800)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.169% (7847/8900)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.200% (7938/9000)\n",
      "Test Epoch: 80 | Loss: 0.374 | Acc: 88.198% (8026/9100)\n",
      "Test Epoch: 80 | Loss: 0.372 | Acc: 88.217% (8116/9200)\n",
      "Test Epoch: 80 | Loss: 0.373 | Acc: 88.215% (8204/9300)\n",
      "Test Epoch: 80 | Loss: 0.372 | Acc: 88.191% (8290/9400)\n",
      "Test Epoch: 80 | Loss: 0.371 | Acc: 88.221% (8381/9500)\n",
      "Test Epoch: 80 | Loss: 0.370 | Acc: 88.229% (8470/9600)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.299% (8565/9700)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.265% (8650/9800)\n",
      "Test Epoch: 80 | Loss: 0.370 | Acc: 88.283% (8740/9900)\n",
      "Test Epoch: 80 | Loss: 0.369 | Acc: 88.340% (8834/10000)\n",
      "\n",
      "Epoch: 81\n",
      "Train Epoch: 81 | Loss: 0.223 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 81 | Loss: 0.226 | Acc: 93.229% (358/384)\n",
      "Train Epoch: 81 | Loss: 0.236 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 81 | Loss: 0.236 | Acc: 92.500% (592/640)\n",
      "Train Epoch: 81 | Loss: 0.234 | Acc: 92.318% (709/768)\n",
      "Train Epoch: 81 | Loss: 0.234 | Acc: 92.299% (827/896)\n",
      "Train Epoch: 81 | Loss: 0.230 | Acc: 92.480% (947/1024)\n",
      "Train Epoch: 81 | Loss: 0.222 | Acc: 92.795% (1069/1152)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 93.125% (1192/1280)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 93.253% (1313/1408)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 93.034% (1429/1536)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.849% (1545/1664)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.080% (1668/1792)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.917% (1784/1920)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.018% (1905/2048)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.969% (2023/2176)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.969% (2142/2304)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.845% (2258/2432)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.852% (2377/2560)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.708% (2492/2688)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.827% (2614/2816)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.765% (2731/2944)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.969% (2856/3072)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.000% (2976/3200)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.849% (3090/3328)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.795% (3207/3456)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.690% (3322/3584)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.645% (3439/3712)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.708% (3560/3840)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.792% (3682/3968)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.725% (3798/4096)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.850% (3922/4224)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.969% (4046/4352)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.969% (4165/4480)\n",
      "Train Epoch: 81 | Loss: 0.204 | Acc: 93.034% (4287/4608)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.990% (4404/4736)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.010% (4524/4864)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.009% (4643/4992)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.832% (4753/5120)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.797% (4870/5248)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.857% (4992/5376)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.769% (5106/5504)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.773% (5225/5632)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.708% (5340/5760)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.748% (5461/5888)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.736% (5579/6016)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.757% (5699/6144)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.746% (5817/6272)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.734% (5935/6400)\n",
      "Train Epoch: 81 | Loss: 0.215 | Acc: 92.724% (6053/6528)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.698% (6170/6656)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.748% (6292/6784)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.766% (6412/6912)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.741% (6529/7040)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.773% (6650/7168)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.791% (6770/7296)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.794% (6889/7424)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.783% (7007/7552)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.839% (7130/7680)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.777% (7244/7808)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.818% (7366/7936)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.795% (7483/8064)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.798% (7602/8192)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.861% (7726/8320)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.898% (7848/8448)\n",
      "Train Epoch: 81 | Loss: 0.215 | Acc: 92.817% (7960/8576)\n",
      "Train Epoch: 81 | Loss: 0.216 | Acc: 92.796% (8077/8704)\n",
      "Train Epoch: 81 | Loss: 0.215 | Acc: 92.822% (8198/8832)\n",
      "Train Epoch: 81 | Loss: 0.215 | Acc: 92.824% (8317/8960)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.804% (8434/9088)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.849% (8557/9216)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.830% (8674/9344)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.810% (8791/9472)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.812% (8910/9600)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.825% (9030/9728)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.806% (9147/9856)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.819% (9267/9984)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.811% (9385/10112)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.822% (9505/10240)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.814% (9623/10368)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.835% (9744/10496)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.828% (9862/10624)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.839% (9982/10752)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.849% (10102/10880)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.860% (10222/11008)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.879% (10343/11136)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.871% (10461/11264)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.863% (10579/11392)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.786% (10689/11520)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.806% (10810/11648)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.807% (10929/11776)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.834% (11051/11904)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.861% (11173/12032)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.812% (11286/12160)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.839% (11408/12288)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.840% (11527/12416)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.849% (11647/12544)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.882% (11770/12672)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.945% (11897/12800)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.946% (12016/12928)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.930% (12133/13056)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.961% (12256/13184)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.984% (12378/13312)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.961% (12494/13440)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.976% (12615/13568)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.998% (12737/13696)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.012% (12858/13824)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.033% (12980/13952)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.004% (13095/14080)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.990% (13212/14208)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.969% (13328/14336)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.983% (13449/14464)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.989% (13569/14592)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.996% (13689/14720)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 93.002% (13809/14848)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.989% (13926/14976)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.989% (14045/15104)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.995% (14165/15232)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.001% (14285/15360)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.007% (14405/15488)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.988% (14521/15616)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.988% (14640/15744)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.988% (14759/15872)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.987% (14878/16000)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.950% (14991/16128)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.944% (15109/16256)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.950% (15229/16384)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.938% (15346/16512)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.969% (15470/16640)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.987% (15592/16768)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.963% (15707/16896)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.945% (15823/17024)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.951% (15943/17152)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.980% (16067/17280)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.952% (16181/17408)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.963% (16302/17536)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.946% (16418/17664)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.963% (16540/17792)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.946% (16656/17920)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.958% (16777/18048)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.947% (16894/18176)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.931% (17010/18304)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.952% (17133/18432)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.936% (17249/18560)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.931% (17367/18688)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.958% (17491/18816)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.979% (17614/18944)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.974% (17732/19072)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 92.995% (17855/19200)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.015% (17978/19328)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.005% (18095/19456)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.015% (18216/19584)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.025% (18337/19712)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.994% (18450/19840)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.974% (18565/19968)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.979% (18685/20096)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.929% (18794/20224)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.939% (18915/20352)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.964% (19039/20480)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.969% (19159/20608)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.954% (19275/20736)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.950% (19393/20864)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.935% (19509/20992)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.936% (19628/21120)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.964% (19753/21248)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.945% (19868/21376)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.959% (19990/21504)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.950% (20107/21632)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.950% (20226/21760)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.928% (20340/21888)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.919% (20457/22016)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.928% (20578/22144)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.906% (20692/22272)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.902% (20810/22400)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.902% (20929/22528)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.903% (21048/22656)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.916% (21170/22784)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.925% (21291/22912)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.921% (21409/23040)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.934% (21531/23168)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.943% (21652/23296)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.939% (21770/23424)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.935% (21888/23552)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.948% (22010/23680)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.927% (22124/23808)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.914% (22240/23936)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.919% (22360/24064)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.927% (22481/24192)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.915% (22597/24320)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.907% (22714/24448)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.936% (22840/24576)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.961% (22965/24704)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.957% (23083/24832)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.977% (23207/24960)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.981% (23327/25088)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.993% (23449/25216)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.996% (23569/25344)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.020% (23694/25472)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.008% (23810/25600)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.019% (23932/25728)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.019% (24051/25856)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.007% (24167/25984)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.980% (24279/26112)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.992% (24401/26240)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.999% (24522/26368)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.991% (24639/26496)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.991% (24758/26624)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.980% (24874/26752)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.980% (24993/26880)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.987% (25114/27008)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.987% (25233/27136)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.005% (25357/27264)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.002% (25475/27392)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.020% (25599/27520)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.012% (25716/27648)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.001% (25832/27776)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.001% (25951/27904)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.001% (26070/28032)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.994% (26187/28160)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.969% (26299/28288)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.958% (26415/28416)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.969% (26537/28544)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.965% (26655/28672)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.969% (26775/28800)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 92.989% (26900/28928)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.000% (27022/29056)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.010% (27144/29184)\n",
      "Train Epoch: 81 | Loss: 0.205 | Acc: 93.027% (27268/29312)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.020% (27385/29440)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.009% (27501/29568)\n",
      "Train Epoch: 81 | Loss: 0.206 | Acc: 93.009% (27620/29696)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.992% (27734/29824)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.979% (27849/29952)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.975% (27967/30080)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.965% (28083/30208)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.969% (28203/30336)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.962% (28320/30464)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.965% (28440/30592)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.939% (28551/30720)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.943% (28671/30848)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.940% (28789/30976)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.940% (28908/31104)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.943% (29028/31232)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.937% (29145/31360)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.927% (29261/31488)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.905% (29373/31616)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.903% (29491/31744)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.909% (29612/31872)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.906% (29730/32000)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.916% (29852/32128)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.916% (29971/32256)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.904% (30086/32384)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.904% (30205/32512)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.914% (30327/32640)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.929% (30451/32768)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.914% (30565/32896)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.923% (30687/33024)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.930% (30808/33152)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.939% (30930/33280)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.939% (31049/33408)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.948% (31171/33536)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.951% (31291/33664)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.948% (31409/33792)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.945% (31527/33920)\n",
      "Train Epoch: 81 | Loss: 0.207 | Acc: 92.916% (31636/34048)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.907% (31752/34176)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.896% (31867/34304)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.887% (31983/34432)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.882% (32100/34560)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.876% (32217/34688)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.883% (32338/34816)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.880% (32456/34944)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.886% (32577/35072)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.892% (32698/35200)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.895% (32818/35328)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.890% (32935/35456)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.882% (33051/35584)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.876% (33168/35712)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.885% (33290/35840)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (33410/35968)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (33529/36096)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.886% (33647/36224)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.875% (33762/36352)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.867% (33878/36480)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.865% (33996/36608)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.863% (34114/36736)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.874% (34237/36864)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.882% (34359/36992)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (34480/37120)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.891% (34600/37248)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.886% (34717/37376)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.875% (34832/37504)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.884% (34954/37632)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.876% (35070/37760)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.871% (35187/37888)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.869% (35305/38016)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.877% (35427/38144)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.864% (35541/38272)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.865% (35660/38400)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.868% (35780/38528)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.873% (35901/38656)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.886% (36025/38784)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.887% (36144/38912)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.889% (36264/39040)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.884% (36381/39168)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.882% (36499/39296)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (36620/39424)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.883% (36737/39552)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (36858/39680)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.878% (36973/39808)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.864% (37086/39936)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.864% (37205/40064)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.864% (37324/40192)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.855% (37439/40320)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.857% (37559/40448)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.855% (37677/40576)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.863% (37799/40704)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.863% (37918/40832)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.859% (38035/40960)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.857% (38153/41088)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.862% (38274/41216)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.872% (38397/41344)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.875% (38517/41472)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.877% (38637/41600)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.878% (38756/41728)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.883% (38877/41856)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.881% (38995/41984)\n",
      "Train Epoch: 81 | Loss: 0.208 | Acc: 92.888% (39117/42112)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.872% (39229/42240)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.870% (39347/42368)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.875% (39468/42496)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.875% (39587/42624)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.873% (39705/42752)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.875% (39825/42880)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.869% (39941/43008)\n",
      "Train Epoch: 81 | Loss: 0.209 | Acc: 92.862% (40057/43136)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.849% (40170/43264)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.830% (40281/43392)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.826% (40398/43520)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.822% (40515/43648)\n",
      "Train Epoch: 81 | Loss: 0.210 | Acc: 92.820% (40633/43776)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.812% (40748/43904)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.808% (40865/44032)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.801% (40981/44160)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.802% (41100/44288)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.793% (41215/44416)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.782% (41329/44544)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.778% (41446/44672)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.788% (41569/44800)\n",
      "Train Epoch: 81 | Loss: 0.211 | Acc: 92.795% (41691/44928)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.780% (41803/45056)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.774% (41919/45184)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.768% (42035/45312)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.766% (42153/45440)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.762% (42270/45568)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.756% (42386/45696)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.751% (42502/45824)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.753% (42622/45952)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.758% (42743/46080)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.757% (42861/46208)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.755% (42979/46336)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.754% (43097/46464)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.756% (43217/46592)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.761% (43338/46720)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.757% (43455/46848)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.745% (43568/46976)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.746% (43687/47104)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.753% (43809/47232)\n",
      "Train Epoch: 81 | Loss: 0.212 | Acc: 92.753% (43928/47360)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.750% (44045/47488)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.746% (44162/47616)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.734% (44275/47744)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.724% (44389/47872)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.731% (44511/48000)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.726% (44627/48128)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.716% (44741/48256)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.710% (44857/48384)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.713% (44977/48512)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.722% (45100/48640)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.719% (45217/48768)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.717% (45335/48896)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.720% (45455/49024)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.714% (45571/49152)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.721% (45693/49280)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.722% (45812/49408)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.731% (45935/49536)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.717% (46047/49664)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.704% (46159/49792)\n",
      "Train Epoch: 81 | Loss: 0.213 | Acc: 92.706% (46279/49920)\n",
      "Train Epoch: 81 | Loss: 0.214 | Acc: 92.692% (46346/50000)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 81 | Loss: 0.287 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 81 | Loss: 0.270 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 81 | Loss: 0.272 | Acc: 91.500% (366/400)\n",
      "Test Epoch: 81 | Loss: 0.247 | Acc: 92.400% (462/500)\n",
      "Test Epoch: 81 | Loss: 0.241 | Acc: 92.500% (555/600)\n",
      "Test Epoch: 81 | Loss: 0.244 | Acc: 92.286% (646/700)\n",
      "Test Epoch: 81 | Loss: 0.268 | Acc: 91.375% (731/800)\n",
      "Test Epoch: 81 | Loss: 0.291 | Acc: 91.000% (819/900)\n",
      "Test Epoch: 81 | Loss: 0.299 | Acc: 90.700% (907/1000)\n",
      "Test Epoch: 81 | Loss: 0.305 | Acc: 90.636% (997/1100)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 90.250% (1083/1200)\n",
      "Test Epoch: 81 | Loss: 0.309 | Acc: 90.231% (1173/1300)\n",
      "Test Epoch: 81 | Loss: 0.312 | Acc: 90.000% (1260/1400)\n",
      "Test Epoch: 81 | Loss: 0.308 | Acc: 89.867% (1348/1500)\n",
      "Test Epoch: 81 | Loss: 0.306 | Acc: 89.875% (1438/1600)\n",
      "Test Epoch: 81 | Loss: 0.306 | Acc: 90.000% (1530/1700)\n",
      "Test Epoch: 81 | Loss: 0.310 | Acc: 90.000% (1620/1800)\n",
      "Test Epoch: 81 | Loss: 0.304 | Acc: 90.211% (1714/1900)\n",
      "Test Epoch: 81 | Loss: 0.302 | Acc: 90.250% (1805/2000)\n",
      "Test Epoch: 81 | Loss: 0.305 | Acc: 90.000% (1890/2100)\n",
      "Test Epoch: 81 | Loss: 0.299 | Acc: 90.091% (1982/2200)\n",
      "Test Epoch: 81 | Loss: 0.301 | Acc: 90.000% (2070/2300)\n",
      "Test Epoch: 81 | Loss: 0.302 | Acc: 89.917% (2158/2400)\n",
      "Test Epoch: 81 | Loss: 0.305 | Acc: 89.880% (2247/2500)\n",
      "Test Epoch: 81 | Loss: 0.316 | Acc: 89.731% (2333/2600)\n",
      "Test Epoch: 81 | Loss: 0.314 | Acc: 89.778% (2424/2700)\n",
      "Test Epoch: 81 | Loss: 0.316 | Acc: 89.786% (2514/2800)\n",
      "Test Epoch: 81 | Loss: 0.321 | Acc: 89.724% (2602/2900)\n",
      "Test Epoch: 81 | Loss: 0.321 | Acc: 89.600% (2688/3000)\n",
      "Test Epoch: 81 | Loss: 0.323 | Acc: 89.484% (2774/3100)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.500% (2864/3200)\n",
      "Test Epoch: 81 | Loss: 0.323 | Acc: 89.515% (2954/3300)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.647% (3048/3400)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.571% (3135/3500)\n",
      "Test Epoch: 81 | Loss: 0.323 | Acc: 89.556% (3224/3600)\n",
      "Test Epoch: 81 | Loss: 0.325 | Acc: 89.459% (3310/3700)\n",
      "Test Epoch: 81 | Loss: 0.326 | Acc: 89.316% (3394/3800)\n",
      "Test Epoch: 81 | Loss: 0.324 | Acc: 89.359% (3485/3900)\n",
      "Test Epoch: 81 | Loss: 0.324 | Acc: 89.400% (3576/4000)\n",
      "Test Epoch: 81 | Loss: 0.325 | Acc: 89.366% (3664/4100)\n",
      "Test Epoch: 81 | Loss: 0.327 | Acc: 89.333% (3752/4200)\n",
      "Test Epoch: 81 | Loss: 0.325 | Acc: 89.395% (3844/4300)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.523% (3939/4400)\n",
      "Test Epoch: 81 | Loss: 0.321 | Acc: 89.578% (4031/4500)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.543% (4119/4600)\n",
      "Test Epoch: 81 | Loss: 0.319 | Acc: 89.617% (4212/4700)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.500% (4296/4800)\n",
      "Test Epoch: 81 | Loss: 0.317 | Acc: 89.592% (4390/4900)\n",
      "Test Epoch: 81 | Loss: 0.319 | Acc: 89.520% (4476/5000)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.608% (4570/5100)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.596% (4659/5200)\n",
      "Test Epoch: 81 | Loss: 0.319 | Acc: 89.566% (4747/5300)\n",
      "Test Epoch: 81 | Loss: 0.317 | Acc: 89.648% (4841/5400)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.636% (4930/5500)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.589% (5017/5600)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.561% (5105/5700)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.603% (5197/5800)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.508% (5281/5900)\n",
      "Test Epoch: 81 | Loss: 0.321 | Acc: 89.500% (5370/6000)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.443% (5456/6100)\n",
      "Test Epoch: 81 | Loss: 0.322 | Acc: 89.435% (5545/6200)\n",
      "Test Epoch: 81 | Loss: 0.321 | Acc: 89.492% (5638/6300)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.578% (5733/6400)\n",
      "Test Epoch: 81 | Loss: 0.319 | Acc: 89.585% (5823/6500)\n",
      "Test Epoch: 81 | Loss: 0.316 | Acc: 89.667% (5918/6600)\n",
      "Test Epoch: 81 | Loss: 0.315 | Acc: 89.716% (6011/6700)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.691% (6099/6800)\n",
      "Test Epoch: 81 | Loss: 0.317 | Acc: 89.725% (6191/6900)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.686% (6278/7000)\n",
      "Test Epoch: 81 | Loss: 0.319 | Acc: 89.718% (6370/7100)\n",
      "Test Epoch: 81 | Loss: 0.320 | Acc: 89.708% (6459/7200)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.753% (6552/7300)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.770% (6643/7400)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.760% (6732/7500)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.803% (6825/7600)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.792% (6914/7700)\n",
      "Test Epoch: 81 | Loss: 0.317 | Acc: 89.795% (7004/7800)\n",
      "Test Epoch: 81 | Loss: 0.318 | Acc: 89.797% (7094/7900)\n",
      "Test Epoch: 81 | Loss: 0.317 | Acc: 89.825% (7186/8000)\n",
      "Test Epoch: 81 | Loss: 0.315 | Acc: 89.877% (7280/8100)\n",
      "Test Epoch: 81 | Loss: 0.314 | Acc: 89.902% (7372/8200)\n",
      "Test Epoch: 81 | Loss: 0.314 | Acc: 89.904% (7462/8300)\n",
      "Test Epoch: 81 | Loss: 0.313 | Acc: 89.929% (7554/8400)\n",
      "Test Epoch: 81 | Loss: 0.313 | Acc: 89.894% (7641/8500)\n",
      "Test Epoch: 81 | Loss: 0.314 | Acc: 89.849% (7727/8600)\n",
      "Test Epoch: 81 | Loss: 0.313 | Acc: 89.897% (7821/8700)\n",
      "Test Epoch: 81 | Loss: 0.315 | Acc: 89.875% (7909/8800)\n",
      "Test Epoch: 81 | Loss: 0.315 | Acc: 89.865% (7998/8900)\n",
      "Test Epoch: 81 | Loss: 0.313 | Acc: 89.889% (8090/9000)\n",
      "Test Epoch: 81 | Loss: 0.312 | Acc: 89.934% (8184/9100)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.978% (8278/9200)\n",
      "Test Epoch: 81 | Loss: 0.312 | Acc: 89.957% (8366/9300)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.957% (8456/9400)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.937% (8544/9500)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.948% (8635/9600)\n",
      "Test Epoch: 81 | Loss: 0.310 | Acc: 89.979% (8728/9700)\n",
      "Test Epoch: 81 | Loss: 0.310 | Acc: 89.990% (8819/9800)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.949% (8905/9900)\n",
      "Test Epoch: 81 | Loss: 0.311 | Acc: 89.950% (8995/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 82\n",
      "Train Epoch: 82 | Loss: 0.319 | Acc: 89.062% (114/128)\n",
      "Train Epoch: 82 | Loss: 0.284 | Acc: 88.672% (227/256)\n",
      "Train Epoch: 82 | Loss: 0.245 | Acc: 89.844% (345/384)\n",
      "Train Epoch: 82 | Loss: 0.239 | Acc: 90.234% (462/512)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 91.406% (585/640)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 91.406% (702/768)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 91.629% (821/896)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 91.992% (942/1024)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.274% (1063/1152)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.266% (1181/1280)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.543% (1303/1408)\n",
      "Train Epoch: 82 | Loss: 0.200 | Acc: 92.773% (1425/1536)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.728% (1543/1664)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.578% (1659/1792)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.396% (1774/1920)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.432% (1893/2048)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.463% (2012/2176)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.448% (2130/2304)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.516% (2250/2432)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.383% (2365/2560)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.597% (2489/2688)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.436% (2603/2816)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.425% (2721/2944)\n",
      "Train Epoch: 82 | Loss: 0.219 | Acc: 92.253% (2834/3072)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.500% (2960/3200)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.548% (3080/3328)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.506% (3197/3456)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.522% (3316/3584)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.565% (3436/3712)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.526% (3553/3840)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.515% (3671/3968)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.554% (3791/4096)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.637% (3913/4224)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.578% (4029/4352)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.612% (4149/4480)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.665% (4270/4608)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.525% (4382/4736)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.475% (4498/4864)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.448% (4615/4992)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.461% (4734/5120)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.416% (4850/5248)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.504% (4973/5376)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.533% (5093/5504)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.454% (5207/5632)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.448% (5325/5760)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.459% (5444/5888)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.520% (5566/6016)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.464% (5681/6144)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.490% (5801/6272)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.484% (5919/6400)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.555% (6042/6528)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.593% (6163/6656)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.571% (6280/6784)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.607% (6401/6912)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.599% (6519/7040)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.606% (6638/7168)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.599% (6756/7296)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.551% (6871/7424)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.585% (6992/7552)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.617% (7113/7680)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.610% (7231/7808)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.629% (7351/7936)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.622% (7469/8064)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.700% (7594/8192)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.740% (7716/8320)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.696% (7831/8448)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.759% (7955/8576)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.773% (8075/8704)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.810% (8197/8832)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.812% (8316/8960)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.771% (8431/9088)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.763% (8549/9216)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.701% (8662/9344)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.715% (8782/9472)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.688% (8898/9600)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.743% (9022/9728)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.786% (9145/9856)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.808% (9266/9984)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.781% (9382/10112)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.773% (9500/10240)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.766% (9618/10368)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.807% (9741/10496)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.809% (9860/10624)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.820% (9980/10752)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.822% (10099/10880)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.842% (10220/11008)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.816% (10336/11136)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.853% (10459/11264)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.881% (10581/11392)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.899% (10702/11520)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.883% (10819/11648)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.892% (10939/11776)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.893% (11058/11904)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.911% (11179/12032)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.895% (11296/12160)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.912% (11417/12288)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.945% (11540/12416)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.977% (11663/12544)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.969% (11781/12672)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.992% (11903/12800)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.984% (12021/12928)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.022% (12145/13056)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.045% (12267/13184)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.074% (12390/13312)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.058% (12507/13440)\n",
      "Train Epoch: 82 | Loss: 0.201 | Acc: 93.087% (12630/13568)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.086% (12749/13696)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.077% (12867/13824)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.062% (12984/13952)\n",
      "Train Epoch: 82 | Loss: 0.201 | Acc: 93.111% (13110/14080)\n",
      "Train Epoch: 82 | Loss: 0.201 | Acc: 93.110% (13229/14208)\n",
      "Train Epoch: 82 | Loss: 0.201 | Acc: 93.094% (13346/14336)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.093% (13465/14464)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.065% (13580/14592)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.030% (13694/14720)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.029% (13813/14848)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.029% (13932/14976)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.042% (14053/15104)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.028% (14170/15232)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.014% (14287/15360)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.982% (14401/15488)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.988% (14521/15616)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.013% (14644/15744)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.013% (14763/15872)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 93.025% (14884/16000)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.049% (15007/16128)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.043% (15125/16256)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.018% (15240/16384)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.023% (15360/16512)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.017% (15478/16640)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.987% (15592/16768)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.010% (15715/16896)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.016% (15835/17024)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.021% (15955/17152)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.003% (16071/17280)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.986% (16187/17408)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.997% (16308/17536)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.008% (16429/17664)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.031% (16552/17792)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.013% (16668/17920)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.008% (16786/18048)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.024% (16908/18176)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.029% (17028/18304)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.012% (17144/18432)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.017% (17264/18560)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.996% (17379/18688)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.990% (17497/18816)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.969% (17612/18944)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.979% (17733/19072)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.005% (17857/19200)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.000% (17975/19328)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.015% (18097/19456)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.999% (18213/19584)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.979% (18328/19712)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.989% (18449/19840)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.994% (18569/19968)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.989% (18687/20096)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.979% (18804/20224)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.974% (18922/20352)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.983% (19043/20480)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.998% (19165/20608)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.993% (19283/20736)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.012% (19406/20864)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.007% (19524/20992)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 93.002% (19642/21120)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.973% (19755/21248)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.978% (19875/21376)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.969% (19992/21504)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.973% (20112/21632)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.969% (20230/21760)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.982% (20352/21888)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.955% (20465/22016)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.969% (20587/22144)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.951% (20702/22272)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.964% (20824/22400)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.973% (20945/22528)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.982% (21066/22656)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.991% (21187/22784)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 93.004% (21309/22912)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.986% (21424/23040)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.990% (21544/23168)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.977% (21660/23296)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.982% (21780/23424)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.973% (21897/23552)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.960% (22013/23680)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.956% (22131/23808)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.973% (22254/23936)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.960% (22370/24064)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.948% (22486/24192)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.969% (22610/24320)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.969% (22729/24448)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.973% (22849/24576)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.973% (22968/24704)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.981% (23089/24832)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.997% (23212/24960)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.985% (23328/25088)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.993% (23449/25216)\n",
      "Train Epoch: 82 | Loss: 0.202 | Acc: 92.985% (23566/25344)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.953% (23677/25472)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.957% (23797/25600)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.949% (23914/25728)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.930% (24028/25856)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.923% (24145/25984)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.911% (24261/26112)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.908% (24379/26240)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.916% (24500/26368)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.916% (24619/26496)\n",
      "Train Epoch: 82 | Loss: 0.203 | Acc: 92.927% (24741/26624)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.909% (24855/26752)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.913% (24975/26880)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.917% (25095/27008)\n",
      "Train Epoch: 82 | Loss: 0.204 | Acc: 92.899% (25209/27136)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.873% (25321/27264)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.856% (25435/27392)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.852% (25553/27520)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.849% (25671/27648)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.857% (25792/27776)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.861% (25912/27904)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.862% (26031/28032)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.855% (26148/28160)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.866% (26270/28288)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.867% (26389/28416)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.867% (26508/28544)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.854% (26623/28672)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.861% (26744/28800)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.865% (26864/28928)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.879% (26987/29056)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.866% (27102/29184)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.863% (27220/29312)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.860% (27338/29440)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.850% (27454/29568)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.841% (27570/29696)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.855% (27693/29824)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.859% (27813/29952)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.869% (27935/30080)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.889% (28060/30208)\n",
      "Train Epoch: 82 | Loss: 0.205 | Acc: 92.883% (28177/30336)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.864% (28290/30464)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.854% (28406/30592)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.865% (28528/30720)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.862% (28646/30848)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.849% (28761/30976)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.853% (28881/31104)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.850% (28999/31232)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.848% (29117/31360)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.845% (29235/31488)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.849% (29355/31616)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.855% (29476/31744)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.853% (29594/31872)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.856% (29714/32000)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.847% (29830/32128)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.845% (29948/32256)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.830% (30062/32384)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.830% (30181/32512)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.843% (30304/32640)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.834% (30420/32768)\n",
      "Train Epoch: 82 | Loss: 0.206 | Acc: 92.826% (30536/32896)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.823% (30654/33024)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.833% (30776/33152)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.825% (30892/33280)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.825% (31011/33408)\n",
      "Train Epoch: 82 | Loss: 0.207 | Acc: 92.832% (31132/33536)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.805% (31242/33664)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.809% (31362/33792)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.812% (31482/33920)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.804% (31598/34048)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.805% (31717/34176)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.794% (31832/34304)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.789% (31949/34432)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.784% (32066/34560)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.758% (32176/34688)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.768% (32298/34816)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.771% (32418/34944)\n",
      "Train Epoch: 82 | Loss: 0.208 | Acc: 92.778% (32539/35072)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.759% (32651/35200)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.748% (32766/35328)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.746% (32884/35456)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.741% (33001/35584)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.745% (33121/35712)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.743% (33239/35840)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.732% (33354/35968)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.733% (33473/36096)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.737% (33593/36224)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.721% (33706/36352)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.714% (33822/36480)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.723% (33944/36608)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.726% (34064/36736)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.735% (34186/36864)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.731% (34303/36992)\n",
      "Train Epoch: 82 | Loss: 0.209 | Acc: 92.729% (34421/37120)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.708% (34532/37248)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.720% (34655/37376)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.713% (34771/37504)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.719% (34892/37632)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.709% (35007/37760)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.700% (35122/37888)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.708% (35244/38016)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.709% (35363/38144)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.700% (35478/38272)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.703% (35598/38400)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.688% (35711/38528)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.684% (35828/38656)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.670% (35941/38784)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.671% (36060/38912)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.692% (36187/39040)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.680% (36301/39168)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.676% (36418/39296)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.690% (36542/39424)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.683% (36658/39552)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.694% (36781/39680)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.677% (36893/39808)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.686% (37015/39936)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.682% (37132/40064)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.683% (37251/40192)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.679% (37368/40320)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.687% (37490/40448)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.675% (37604/40576)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.684% (37726/40704)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.685% (37845/40832)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.690% (37966/40960)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.691% (38085/41088)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.702% (38208/41216)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.708% (38329/41344)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.711% (38449/41472)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.700% (38563/41600)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.700% (38682/41728)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.701% (38801/41856)\n",
      "Train Epoch: 82 | Loss: 0.210 | Acc: 92.707% (38922/41984)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.698% (39037/42112)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.696% (39155/42240)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.693% (39272/42368)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.689% (39389/42496)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.697% (39511/42624)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.690% (39627/42752)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.698% (39749/42880)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.685% (39862/43008)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.677% (39977/43136)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.668% (40092/43264)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.669% (40211/43392)\n",
      "Train Epoch: 82 | Loss: 0.211 | Acc: 92.661% (40326/43520)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.653% (40441/43648)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.642% (40555/43776)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.636% (40671/43904)\n",
      "Train Epoch: 82 | Loss: 0.212 | Acc: 92.630% (40787/44032)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.618% (40900/44160)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.612% (41016/44288)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.613% (41135/44416)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.607% (41251/44544)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.595% (41364/44672)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.596% (41483/44800)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.599% (41603/44928)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.594% (41719/45056)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.601% (41841/45184)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.602% (41960/45312)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.581% (42069/45440)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.578% (42186/45568)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.575% (42303/45696)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.580% (42424/45824)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.577% (42541/45952)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.585% (42663/46080)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.584% (42781/46208)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.587% (42901/46336)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.592% (43022/46464)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.589% (43139/46592)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.581% (43254/46720)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.580% (43372/46848)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.577% (43489/46976)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.582% (43610/47104)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.586% (43730/47232)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.582% (43847/47360)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.579% (43964/47488)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.587% (44086/47616)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.579% (44201/47744)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.578% (44319/47872)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.577% (44437/48000)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.574% (44554/48128)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.585% (44678/48256)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.580% (44794/48384)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.583% (44914/48512)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.580% (45031/48640)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.581% (45150/48768)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.578% (45267/48896)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.591% (45392/49024)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.590% (45510/49152)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.585% (45626/49280)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.590% (45747/49408)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.591% (45866/49536)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.588% (45983/49664)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.583% (46099/49792)\n",
      "Train Epoch: 82 | Loss: 0.214 | Acc: 92.590% (46221/49920)\n",
      "Train Epoch: 82 | Loss: 0.213 | Acc: 92.594% (46297/50000)\n",
      "Test Epoch: 82 | Loss: 0.406 | Acc: 86.000% (86/100)\n",
      "Test Epoch: 82 | Loss: 0.353 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 82 | Loss: 0.321 | Acc: 89.000% (267/300)\n",
      "Test Epoch: 82 | Loss: 0.339 | Acc: 88.750% (355/400)\n",
      "Test Epoch: 82 | Loss: 0.325 | Acc: 88.800% (444/500)\n",
      "Test Epoch: 82 | Loss: 0.304 | Acc: 89.167% (535/600)\n",
      "Test Epoch: 82 | Loss: 0.282 | Acc: 89.857% (629/700)\n",
      "Test Epoch: 82 | Loss: 0.294 | Acc: 89.500% (716/800)\n",
      "Test Epoch: 82 | Loss: 0.301 | Acc: 89.444% (805/900)\n",
      "Test Epoch: 82 | Loss: 0.305 | Acc: 89.500% (895/1000)\n",
      "Test Epoch: 82 | Loss: 0.313 | Acc: 88.909% (978/1100)\n",
      "Test Epoch: 82 | Loss: 0.332 | Acc: 88.667% (1064/1200)\n",
      "Test Epoch: 82 | Loss: 0.325 | Acc: 88.769% (1154/1300)\n",
      "Test Epoch: 82 | Loss: 0.318 | Acc: 88.714% (1242/1400)\n",
      "Test Epoch: 82 | Loss: 0.315 | Acc: 88.800% (1332/1500)\n",
      "Test Epoch: 82 | Loss: 0.314 | Acc: 88.812% (1421/1600)\n",
      "Test Epoch: 82 | Loss: 0.314 | Acc: 88.941% (1512/1700)\n",
      "Test Epoch: 82 | Loss: 0.314 | Acc: 88.889% (1600/1800)\n",
      "Test Epoch: 82 | Loss: 0.317 | Acc: 88.895% (1689/1900)\n",
      "Test Epoch: 82 | Loss: 0.321 | Acc: 88.900% (1778/2000)\n",
      "Test Epoch: 82 | Loss: 0.327 | Acc: 88.619% (1861/2100)\n",
      "Test Epoch: 82 | Loss: 0.331 | Acc: 88.545% (1948/2200)\n",
      "Test Epoch: 82 | Loss: 0.342 | Acc: 88.304% (2031/2300)\n",
      "Test Epoch: 82 | Loss: 0.339 | Acc: 88.458% (2123/2400)\n",
      "Test Epoch: 82 | Loss: 0.345 | Acc: 88.440% (2211/2500)\n",
      "Test Epoch: 82 | Loss: 0.355 | Acc: 88.308% (2296/2600)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.407% (2387/2700)\n",
      "Test Epoch: 82 | Loss: 0.356 | Acc: 88.464% (2477/2800)\n",
      "Test Epoch: 82 | Loss: 0.356 | Acc: 88.552% (2568/2900)\n",
      "Test Epoch: 82 | Loss: 0.358 | Acc: 88.467% (2654/3000)\n",
      "Test Epoch: 82 | Loss: 0.357 | Acc: 88.516% (2744/3100)\n",
      "Test Epoch: 82 | Loss: 0.355 | Acc: 88.594% (2835/3200)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.727% (2928/3300)\n",
      "Test Epoch: 82 | Loss: 0.350 | Acc: 88.765% (3018/3400)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.657% (3103/3500)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.694% (3193/3600)\n",
      "Test Epoch: 82 | Loss: 0.359 | Acc: 88.595% (3278/3700)\n",
      "Test Epoch: 82 | Loss: 0.362 | Acc: 88.553% (3365/3800)\n",
      "Test Epoch: 82 | Loss: 0.361 | Acc: 88.513% (3452/3900)\n",
      "Test Epoch: 82 | Loss: 0.361 | Acc: 88.500% (3540/4000)\n",
      "Test Epoch: 82 | Loss: 0.362 | Acc: 88.488% (3628/4100)\n",
      "Test Epoch: 82 | Loss: 0.362 | Acc: 88.500% (3717/4200)\n",
      "Test Epoch: 82 | Loss: 0.360 | Acc: 88.581% (3809/4300)\n",
      "Test Epoch: 82 | Loss: 0.360 | Acc: 88.614% (3899/4400)\n",
      "Test Epoch: 82 | Loss: 0.357 | Acc: 88.756% (3994/4500)\n",
      "Test Epoch: 82 | Loss: 0.360 | Acc: 88.652% (4078/4600)\n",
      "Test Epoch: 82 | Loss: 0.360 | Acc: 88.617% (4165/4700)\n",
      "Test Epoch: 82 | Loss: 0.364 | Acc: 88.500% (4248/4800)\n",
      "Test Epoch: 82 | Loss: 0.363 | Acc: 88.469% (4335/4900)\n",
      "Test Epoch: 82 | Loss: 0.366 | Acc: 88.380% (4419/5000)\n",
      "Test Epoch: 82 | Loss: 0.365 | Acc: 88.431% (4510/5100)\n",
      "Test Epoch: 82 | Loss: 0.362 | Acc: 88.481% (4601/5200)\n",
      "Test Epoch: 82 | Loss: 0.362 | Acc: 88.472% (4689/5300)\n",
      "Test Epoch: 82 | Loss: 0.361 | Acc: 88.519% (4780/5400)\n",
      "Test Epoch: 82 | Loss: 0.358 | Acc: 88.545% (4870/5500)\n",
      "Test Epoch: 82 | Loss: 0.357 | Acc: 88.607% (4962/5600)\n",
      "Test Epoch: 82 | Loss: 0.358 | Acc: 88.579% (5049/5700)\n",
      "Test Epoch: 82 | Loss: 0.356 | Acc: 88.586% (5138/5800)\n",
      "Test Epoch: 82 | Loss: 0.359 | Acc: 88.525% (5223/5900)\n",
      "Test Epoch: 82 | Loss: 0.356 | Acc: 88.583% (5315/6000)\n",
      "Test Epoch: 82 | Loss: 0.357 | Acc: 88.541% (5401/6100)\n",
      "Test Epoch: 82 | Loss: 0.357 | Acc: 88.581% (5492/6200)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.683% (5587/6300)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.781% (5682/6400)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.785% (5771/6500)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 88.848% (5864/6600)\n",
      "Test Epoch: 82 | Loss: 0.346 | Acc: 88.955% (5960/6700)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 88.926% (6047/6800)\n",
      "Test Epoch: 82 | Loss: 0.347 | Acc: 88.986% (6140/6900)\n",
      "Test Epoch: 82 | Loss: 0.348 | Acc: 88.914% (6224/7000)\n",
      "Test Epoch: 82 | Loss: 0.350 | Acc: 88.915% (6313/7100)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.944% (6404/7200)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.027% (6499/7300)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.054% (6590/7400)\n",
      "Test Epoch: 82 | Loss: 0.348 | Acc: 89.053% (6679/7500)\n",
      "Test Epoch: 82 | Loss: 0.348 | Acc: 89.053% (6768/7600)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.013% (6854/7700)\n",
      "Test Epoch: 82 | Loss: 0.348 | Acc: 89.051% (6946/7800)\n",
      "Test Epoch: 82 | Loss: 0.350 | Acc: 89.063% (7036/7900)\n",
      "Test Epoch: 82 | Loss: 0.350 | Acc: 89.050% (7124/8000)\n",
      "Test Epoch: 82 | Loss: 0.348 | Acc: 89.123% (7219/8100)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.110% (7307/8200)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.048% (7391/8300)\n",
      "Test Epoch: 82 | Loss: 0.349 | Acc: 89.107% (7485/8400)\n",
      "Test Epoch: 82 | Loss: 0.350 | Acc: 89.035% (7568/8500)\n",
      "Test Epoch: 82 | Loss: 0.353 | Acc: 88.953% (7650/8600)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.954% (7739/8700)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.886% (7822/8800)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.843% (7907/8900)\n",
      "Test Epoch: 82 | Loss: 0.354 | Acc: 88.822% (7994/9000)\n",
      "Test Epoch: 82 | Loss: 0.353 | Acc: 88.846% (8085/9100)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.891% (8178/9200)\n",
      "Test Epoch: 82 | Loss: 0.353 | Acc: 88.892% (8267/9300)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.915% (8358/9400)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.895% (8445/9500)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.885% (8533/9600)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.938% (8627/9700)\n",
      "Test Epoch: 82 | Loss: 0.351 | Acc: 88.959% (8718/9800)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.909% (8802/9900)\n",
      "Test Epoch: 82 | Loss: 0.352 | Acc: 88.920% (8892/10000)\n",
      "\n",
      "Epoch: 83\n",
      "Train Epoch: 83 | Loss: 0.279 | Acc: 87.500% (112/128)\n",
      "Train Epoch: 83 | Loss: 0.237 | Acc: 89.844% (230/256)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 83 | Loss: 0.196 | Acc: 92.383% (473/512)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.448% (710/768)\n",
      "Train Epoch: 83 | Loss: 0.192 | Acc: 92.969% (833/896)\n",
      "Train Epoch: 83 | Loss: 0.189 | Acc: 93.262% (955/1024)\n",
      "Train Epoch: 83 | Loss: 0.187 | Acc: 93.316% (1075/1152)\n",
      "Train Epoch: 83 | Loss: 0.185 | Acc: 93.359% (1195/1280)\n",
      "Train Epoch: 83 | Loss: 0.179 | Acc: 93.750% (1320/1408)\n",
      "Train Epoch: 83 | Loss: 0.179 | Acc: 93.555% (1437/1536)\n",
      "Train Epoch: 83 | Loss: 0.185 | Acc: 93.510% (1556/1664)\n",
      "Train Epoch: 83 | Loss: 0.189 | Acc: 93.471% (1675/1792)\n",
      "Train Epoch: 83 | Loss: 0.196 | Acc: 93.229% (1790/1920)\n",
      "Train Epoch: 83 | Loss: 0.195 | Acc: 93.262% (1910/2048)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.061% (2025/2176)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.056% (2144/2304)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.092% (2264/2432)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.164% (2385/2560)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.229% (2506/2688)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.253% (2626/2816)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.274% (2746/2944)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.294% (2866/3072)\n",
      "Train Epoch: 83 | Loss: 0.198 | Acc: 93.344% (2987/3200)\n",
      "Train Epoch: 83 | Loss: 0.198 | Acc: 93.239% (3103/3328)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.200% (3221/3456)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.248% (3342/3584)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.292% (3463/3712)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.229% (3580/3840)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.070% (3693/3968)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.042% (3811/4096)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.040% (3930/4224)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.061% (4050/4352)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.058% (4169/4480)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.077% (4289/4608)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.990% (4404/4736)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.072% (4527/4864)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.069% (4646/4992)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.105% (4767/5120)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.140% (4888/5248)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.136% (5007/5376)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.169% (5128/5504)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.164% (5247/5632)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.125% (5364/5760)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.054% (5479/5888)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.919% (5590/6016)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.034% (5716/6144)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.048% (5836/6272)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.047% (5955/6400)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.076% (6076/6528)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.059% (6194/6656)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.028% (6311/6784)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.041% (6431/6912)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.040% (6550/7040)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.011% (6667/7168)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 92.996% (6785/7296)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.023% (6906/7424)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.995% (7023/7552)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.060% (7147/7680)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.058% (7266/7808)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.057% (7385/7936)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.043% (7503/8064)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.042% (7622/8192)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.077% (7744/8320)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.087% (7864/8448)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.132% (7987/8576)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.153% (8108/8704)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.127% (8225/8832)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.125% (8344/8960)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.156% (8466/9088)\n",
      "Train Epoch: 83 | Loss: 0.199 | Acc: 93.164% (8586/9216)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.108% (8700/9344)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.095% (8818/9472)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.094% (8937/9600)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.113% (9058/9728)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.101% (9176/9856)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.079% (9293/9984)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.107% (9415/10112)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.135% (9537/10240)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.123% (9655/10368)\n",
      "Train Epoch: 83 | Loss: 0.200 | Acc: 93.112% (9773/10496)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.063% (9887/10624)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.978% (9997/10752)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.950% (10113/10880)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.978% (10235/11008)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.041% (10361/11136)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.031% (10479/11264)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.013% (10596/11392)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.012% (10715/11520)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.029% (10836/11648)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.037% (10956/11776)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.044% (11076/11904)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.068% (11198/12032)\n",
      "Train Epoch: 83 | Loss: 0.201 | Acc: 93.059% (11316/12160)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.034% (11432/12288)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.001% (11547/12416)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 93.017% (11668/12544)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.977% (11782/12672)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 92.969% (11900/12800)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 92.969% (12019/12928)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.946% (12135/13056)\n",
      "Train Epoch: 83 | Loss: 0.202 | Acc: 92.954% (12255/13184)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.954% (12374/13312)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 92.924% (12489/13440)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.910% (12606/13568)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.874% (12720/13696)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.846% (12835/13824)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.818% (12950/13952)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.855% (13074/14080)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.842% (13191/14208)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.850% (13311/14336)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.872% (13433/14464)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.866% (13551/14592)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.867% (13670/14720)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.827% (13783/14848)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.862% (13907/14976)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.856% (14025/15104)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.870% (14146/15232)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.871% (14265/15360)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.833% (14378/15488)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.860% (14501/15616)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.899% (14626/15744)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.899% (14745/15872)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.869% (14859/16000)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.876% (14979/16128)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.870% (15097/16256)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.889% (15219/16384)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.908% (15341/16512)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 92.915% (15461/16640)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.897% (15577/16768)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.898% (15696/16896)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.916% (15818/17024)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.940% (15941/17152)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.934% (16059/17280)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.934% (16178/17408)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.917% (16294/17536)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.929% (16415/17664)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.963% (16540/17792)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.941% (16655/17920)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.980% (16781/18048)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.002% (16904/18176)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.012% (17025/18304)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.023% (17146/18432)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.023% (17265/18560)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.017% (17383/18688)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.022% (17503/18816)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.027% (17623/18944)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.026% (17742/19072)\n",
      "Train Epoch: 83 | Loss: 0.203 | Acc: 93.052% (17866/19200)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.052% (17985/19328)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.041% (18102/19456)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.035% (18220/19584)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.019% (18336/19712)\n",
      "Train Epoch: 83 | Loss: 0.204 | Acc: 93.019% (18455/19840)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.989% (18568/19968)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.974% (18684/20096)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.959% (18800/20224)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.959% (18919/20352)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.959% (19038/20480)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.935% (19152/20608)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.940% (19272/20736)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.930% (19389/20864)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.926% (19507/20992)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.921% (19625/21120)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.926% (19745/21248)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.899% (19858/21376)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.904% (19978/21504)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.909% (20098/21632)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.895% (20214/21760)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.887% (20331/21888)\n",
      "Train Epoch: 83 | Loss: 0.205 | Acc: 92.901% (20453/22016)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.887% (20569/22144)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.857% (20681/22272)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.857% (20800/22400)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.840% (20915/22528)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.841% (21034/22656)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.846% (21154/22784)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.833% (21270/22912)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.830% (21388/23040)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.835% (21508/23168)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.814% (21622/23296)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.815% (21741/23424)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.824% (21862/23552)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.817% (21979/23680)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.813% (22097/23808)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.823% (22218/23936)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.815% (22335/24064)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.816% (22454/24192)\n",
      "Train Epoch: 83 | Loss: 0.206 | Acc: 92.812% (22572/24320)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.813% (22691/24448)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.814% (22810/24576)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.815% (22929/24704)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.824% (23050/24832)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.808% (23165/24960)\n",
      "Train Epoch: 83 | Loss: 0.207 | Acc: 92.797% (23281/25088)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.782% (23396/25216)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.775% (23513/25344)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.769% (23630/25472)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.762% (23747/25600)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.763% (23866/25728)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.772% (23987/25856)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.749% (24100/25984)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.747% (24218/26112)\n",
      "Train Epoch: 83 | Loss: 0.208 | Acc: 92.748% (24337/26240)\n",
      "Train Epoch: 83 | Loss: 0.209 | Acc: 92.734% (24452/26368)\n",
      "Train Epoch: 83 | Loss: 0.209 | Acc: 92.739% (24572/26496)\n",
      "Train Epoch: 83 | Loss: 0.209 | Acc: 92.751% (24694/26624)\n",
      "Train Epoch: 83 | Loss: 0.209 | Acc: 92.759% (24815/26752)\n",
      "Train Epoch: 83 | Loss: 0.209 | Acc: 92.742% (24929/26880)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.721% (25042/27008)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.714% (25159/27136)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.708% (25276/27264)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.710% (25395/27392)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.714% (25515/27520)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.716% (25634/27648)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.702% (25749/27776)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.725% (25874/27904)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.715% (25990/28032)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.710% (26107/28160)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.700% (26223/28288)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.705% (26343/28416)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.695% (26459/28544)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.704% (26580/28672)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.701% (26698/28800)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.713% (26820/28928)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.714% (26939/29056)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.708% (27056/29184)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.703% (27173/29312)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.714% (27295/29440)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.698% (27409/29568)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.699% (27528/29696)\n",
      "Train Epoch: 83 | Loss: 0.210 | Acc: 92.711% (27650/29824)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.705% (27767/29952)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.703% (27885/30080)\n",
      "Train Epoch: 83 | Loss: 0.211 | Acc: 92.671% (27994/30208)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.652% (28107/30336)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.637% (28221/30464)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.616% (28333/30592)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.624% (28454/30720)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.628% (28574/30848)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.627% (28692/30976)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.615% (28807/31104)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.617% (28926/31232)\n",
      "Train Epoch: 83 | Loss: 0.212 | Acc: 92.618% (29045/31360)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.604% (29159/31488)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.596% (29275/31616)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.559% (29382/31744)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.567% (29503/31872)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.550% (29616/32000)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.555% (29736/32128)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.541% (29850/32256)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.536% (29967/32384)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.526% (30082/32512)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.518% (30198/32640)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.499% (30310/32768)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.510% (30432/32896)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.521% (30554/33024)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (30673/33152)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.536% (30796/33280)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.526% (30911/33408)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.521% (31028/33536)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.520% (31146/33664)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (31265/33792)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.518% (31382/33920)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (31502/34048)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.536% (31625/34176)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (31742/34304)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.527% (31859/34432)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.523% (31976/34560)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.513% (32091/34688)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.498% (32204/34816)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.517% (32329/34944)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.524% (32450/35072)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.514% (32565/35200)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (32686/35328)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.512% (32801/35456)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.511% (32919/35584)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.512% (33038/35712)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.503% (33153/35840)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.516% (33276/35968)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.501% (33389/36096)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.502% (33508/36224)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.507% (33628/36352)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.514% (33749/36480)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.513% (33867/36608)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (33989/36736)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.516% (34105/36864)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.528% (34228/36992)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.527% (34346/37120)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (34466/37248)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.533% (34585/37376)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.518% (34698/37504)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.509% (34813/37632)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.503% (34929/37760)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.512% (35051/37888)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.508% (35168/38016)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.515% (35289/38144)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.504% (35403/38272)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.503% (35521/38400)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.499% (35638/38528)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.498% (35756/38656)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.505% (35877/38784)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.509% (35997/38912)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.505% (36114/39040)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (36239/39168)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.529% (36360/39296)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.535% (36481/39424)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.541% (36602/39552)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (36716/39680)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.529% (36834/39808)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.536% (36955/39936)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.529% (37071/40064)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.516% (37184/40192)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.507% (37299/40320)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.511% (37419/40448)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.515% (37539/40576)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.509% (37655/40704)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.503% (37771/40832)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.512% (37893/40960)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.514% (38012/41088)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.503% (38126/41216)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.509% (38247/41344)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.523% (38371/41472)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.536% (38495/41600)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (38611/41728)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.527% (38728/41856)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.523% (38845/41984)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.506% (38956/42112)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.500% (39072/42240)\n",
      "Train Epoch: 83 | Loss: 0.215 | Acc: 92.492% (39187/42368)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.508% (39312/42496)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.509% (39431/42624)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.510% (39550/42752)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.521% (39673/42880)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.527% (39794/43008)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.528% (39913/43136)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.525% (40030/43264)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (40151/43392)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.532% (40270/43520)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (40388/43648)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (40506/43776)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.538% (40628/43904)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (40743/44032)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.532% (40862/44160)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.537% (40983/44288)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.539% (41102/44416)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.540% (41221/44544)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.534% (41337/44672)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (41454/44800)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.526% (41570/44928)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.518% (41685/45056)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.524% (41806/45184)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (41927/45312)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.533% (42047/45440)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (42164/45568)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.527% (42281/45696)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.517% (42395/45824)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.518% (42514/45952)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.513% (42630/46080)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.525% (42754/46208)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.522% (42871/46336)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.512% (42985/46464)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.512% (43103/46592)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.511% (43221/46720)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.514% (43341/46848)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.524% (43464/46976)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.517% (43579/47104)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.516% (43697/47232)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.515% (43815/47360)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.505% (43929/47488)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.524% (44056/47616)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.523% (44174/47744)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.528% (44295/47872)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.525% (44412/48000)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.528% (44532/48128)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.529% (44651/48256)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.535% (44772/48384)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.526% (44886/48512)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (45007/48640)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.530% (45125/48768)\n",
      "Train Epoch: 83 | Loss: 0.214 | Acc: 92.531% (45244/48896)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.538% (45366/49024)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.539% (45485/49152)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.549% (45608/49280)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.546% (45725/49408)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.551% (45846/49536)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.546% (45962/49664)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.551% (46083/49792)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.548% (46200/49920)\n",
      "Train Epoch: 83 | Loss: 0.213 | Acc: 92.540% (46270/50000)\n",
      "Test Epoch: 83 | Loss: 0.220 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 83 | Loss: 0.320 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 83 | Loss: 0.316 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 83 | Loss: 0.319 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 83 | Loss: 0.310 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 83 | Loss: 0.288 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 83 | Loss: 0.283 | Acc: 91.286% (639/700)\n",
      "Test Epoch: 83 | Loss: 0.305 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 83 | Loss: 0.310 | Acc: 89.889% (809/900)\n",
      "Test Epoch: 83 | Loss: 0.312 | Acc: 89.800% (898/1000)\n",
      "Test Epoch: 83 | Loss: 0.309 | Acc: 90.182% (992/1100)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 89.917% (1079/1200)\n",
      "Test Epoch: 83 | Loss: 0.319 | Acc: 89.769% (1167/1300)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 89.643% (1255/1400)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 89.667% (1345/1500)\n",
      "Test Epoch: 83 | Loss: 0.319 | Acc: 89.750% (1436/1600)\n",
      "Test Epoch: 83 | Loss: 0.317 | Acc: 89.941% (1529/1700)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 89.778% (1616/1800)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 89.842% (1707/1900)\n",
      "Test Epoch: 83 | Loss: 0.332 | Acc: 89.700% (1794/2000)\n",
      "Test Epoch: 83 | Loss: 0.331 | Acc: 89.571% (1881/2100)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 89.682% (1973/2200)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 89.609% (2061/2300)\n",
      "Test Epoch: 83 | Loss: 0.320 | Acc: 89.583% (2150/2400)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.520% (2238/2500)\n",
      "Test Epoch: 83 | Loss: 0.331 | Acc: 89.500% (2327/2600)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.667% (2421/2700)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.679% (2511/2800)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 89.690% (2601/2900)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 89.467% (2684/3000)\n",
      "Test Epoch: 83 | Loss: 0.329 | Acc: 89.484% (2774/3100)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.594% (2867/3200)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 89.636% (2958/3300)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 89.647% (3048/3400)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.629% (3137/3500)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 89.639% (3227/3600)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 89.730% (3320/3700)\n",
      "Test Epoch: 83 | Loss: 0.330 | Acc: 89.632% (3406/3800)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 89.667% (3497/3900)\n",
      "Test Epoch: 83 | Loss: 0.330 | Acc: 89.675% (3587/4000)\n",
      "Test Epoch: 83 | Loss: 0.332 | Acc: 89.683% (3677/4100)\n",
      "Test Epoch: 83 | Loss: 0.334 | Acc: 89.738% (3769/4200)\n",
      "Test Epoch: 83 | Loss: 0.330 | Acc: 89.884% (3865/4300)\n",
      "Test Epoch: 83 | Loss: 0.329 | Acc: 89.955% (3958/4400)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.022% (4051/4500)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 90.000% (4140/4600)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.043% (4232/4700)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 90.021% (4321/4800)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.061% (4413/4900)\n",
      "Test Epoch: 83 | Loss: 0.329 | Acc: 89.980% (4499/5000)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 90.039% (4592/5100)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 90.038% (4682/5200)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 90.094% (4775/5300)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 90.093% (4865/5400)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.127% (4957/5500)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 90.107% (5046/5600)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 90.123% (5137/5700)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.172% (5230/5800)\n",
      "Test Epoch: 83 | Loss: 0.328 | Acc: 90.085% (5315/5900)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 90.083% (5405/6000)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 90.049% (5493/6100)\n",
      "Test Epoch: 83 | Loss: 0.327 | Acc: 90.000% (5580/6200)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 90.048% (5673/6300)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.109% (5767/6400)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.077% (5855/6500)\n",
      "Test Epoch: 83 | Loss: 0.320 | Acc: 90.121% (5948/6600)\n",
      "Test Epoch: 83 | Loss: 0.319 | Acc: 90.134% (6039/6700)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.088% (6126/6800)\n",
      "Test Epoch: 83 | Loss: 0.319 | Acc: 90.145% (6220/6900)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.100% (6307/7000)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 90.099% (6397/7100)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.069% (6485/7200)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.110% (6578/7300)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.095% (6667/7400)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.093% (6757/7500)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.039% (6843/7600)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.026% (6932/7700)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.013% (7021/7800)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.025% (7112/7900)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.013% (7201/8000)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.062% (7295/8100)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.012% (7381/8200)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.012% (7471/8300)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.036% (7563/8400)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 89.965% (7647/8500)\n",
      "Test Epoch: 83 | Loss: 0.326 | Acc: 89.895% (7731/8600)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 89.908% (7822/8700)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.886% (7910/8800)\n",
      "Test Epoch: 83 | Loss: 0.325 | Acc: 89.876% (7999/8900)\n",
      "Test Epoch: 83 | Loss: 0.324 | Acc: 89.911% (8092/9000)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 89.956% (8186/9100)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.000% (8280/9200)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 90.000% (8370/9300)\n",
      "Test Epoch: 83 | Loss: 0.323 | Acc: 89.979% (8458/9400)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.011% (8551/9500)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 89.990% (8639/9600)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.041% (8734/9700)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.041% (8824/9800)\n",
      "Test Epoch: 83 | Loss: 0.322 | Acc: 90.000% (8910/9900)\n",
      "Test Epoch: 83 | Loss: 0.321 | Acc: 90.010% (9001/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 84\n",
      "Train Epoch: 84 | Loss: 0.192 | Acc: 90.625% (116/128)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 91.797% (235/256)\n",
      "Train Epoch: 84 | Loss: 0.191 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 84 | Loss: 0.194 | Acc: 92.578% (474/512)\n",
      "Train Epoch: 84 | Loss: 0.188 | Acc: 92.812% (594/640)\n",
      "Train Epoch: 84 | Loss: 0.189 | Acc: 92.969% (714/768)\n",
      "Train Epoch: 84 | Loss: 0.191 | Acc: 92.857% (832/896)\n",
      "Train Epoch: 84 | Loss: 0.192 | Acc: 92.871% (951/1024)\n",
      "Train Epoch: 84 | Loss: 0.186 | Acc: 93.229% (1074/1152)\n",
      "Train Epoch: 84 | Loss: 0.194 | Acc: 93.047% (1191/1280)\n",
      "Train Epoch: 84 | Loss: 0.192 | Acc: 93.182% (1312/1408)\n",
      "Train Epoch: 84 | Loss: 0.190 | Acc: 93.294% (1433/1536)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.209% (1551/1664)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.136% (1669/1792)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 92.917% (1784/1920)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 92.969% (1904/2048)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.015% (2024/2176)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.099% (2145/2304)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.092% (2264/2432)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.203% (2386/2560)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.155% (2504/2688)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.004% (2619/2816)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.003% (2738/2944)\n",
      "Train Epoch: 84 | Loss: 0.205 | Acc: 92.936% (2855/3072)\n",
      "Train Epoch: 84 | Loss: 0.210 | Acc: 92.625% (2964/3200)\n",
      "Train Epoch: 84 | Loss: 0.212 | Acc: 92.608% (3082/3328)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.737% (3205/3456)\n",
      "Train Epoch: 84 | Loss: 0.211 | Acc: 92.634% (3320/3584)\n",
      "Train Epoch: 84 | Loss: 0.210 | Acc: 92.645% (3439/3712)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.760% (3562/3840)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.767% (3681/3968)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.798% (3801/4096)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.898% (3924/4224)\n",
      "Train Epoch: 84 | Loss: 0.204 | Acc: 92.992% (4047/4352)\n",
      "Train Epoch: 84 | Loss: 0.204 | Acc: 93.013% (4167/4480)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.034% (4287/4608)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.074% (4408/4736)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.072% (4527/4864)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.089% (4647/4992)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.242% (4774/5120)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.312% (4897/5248)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.248% (5013/5376)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.278% (5134/5504)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.324% (5256/5632)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.299% (5374/5760)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.291% (5493/5888)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.318% (5614/6016)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.262% (5730/6144)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.208% (5846/6272)\n",
      "Train Epoch: 84 | Loss: 0.194 | Acc: 93.297% (5971/6400)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.244% (6087/6528)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.194% (6203/6656)\n",
      "Train Epoch: 84 | Loss: 0.195 | Acc: 93.264% (6327/6784)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.200% (6442/6912)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.224% (6563/7040)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.150% (6677/7168)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.120% (6794/7296)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.144% (6915/7424)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.141% (7034/7552)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.112% (7151/7680)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.097% (7269/7808)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.082% (7387/7936)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.056% (7504/8064)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.018% (7620/8192)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.005% (7738/8320)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 92.981% (7855/8448)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 92.980% (7974/8576)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.003% (8095/8704)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.025% (8216/8832)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.013% (8334/8960)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.024% (8454/9088)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.001% (8571/9216)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.033% (8693/9344)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.053% (8814/9472)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.083% (8936/9600)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.092% (9056/9728)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.111% (9177/9856)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.119% (9297/9984)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.097% (9414/10112)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.135% (9537/10240)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.152% (9658/10368)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.169% (9779/10496)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.223% (9904/10624)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.238% (10025/10752)\n",
      "Train Epoch: 84 | Loss: 0.196 | Acc: 93.254% (10146/10880)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.187% (10258/11008)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.193% (10378/11136)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.191% (10497/11264)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.197% (10617/11392)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.203% (10737/11520)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.201% (10856/11648)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.224% (10978/11776)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.229% (11098/11904)\n",
      "Train Epoch: 84 | Loss: 0.197 | Acc: 93.235% (11218/12032)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.191% (11332/12160)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.164% (11448/12288)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.146% (11565/12416)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.152% (11685/12544)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.142% (11803/12672)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.133% (11921/12800)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.147% (12042/12928)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.122% (12158/13056)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.120% (12277/13184)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.096% (12393/13312)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.073% (12509/13440)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.101% (12632/13568)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.129% (12755/13696)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.164% (12879/13824)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.177% (13000/13952)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.189% (13121/14080)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.187% (13240/14208)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.171% (13357/14336)\n",
      "Train Epoch: 84 | Loss: 0.198 | Acc: 93.204% (13481/14464)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.167% (13595/14592)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.152% (13712/14720)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.178% (13835/14848)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.176% (13954/14976)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.200% (14077/15104)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.185% (14194/15232)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.177% (14312/15360)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.169% (14430/15488)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.161% (14548/15616)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.166% (14668/15744)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.151% (14785/15872)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.144% (14903/16000)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.173% (15027/16128)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.166% (15145/16256)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.188% (15268/16384)\n",
      "Train Epoch: 84 | Loss: 0.199 | Acc: 93.181% (15386/16512)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.155% (15501/16640)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.154% (15620/16768)\n",
      "Train Epoch: 84 | Loss: 0.200 | Acc: 93.152% (15739/16896)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.121% (15853/17024)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.132% (15974/17152)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.102% (16088/17280)\n",
      "Train Epoch: 84 | Loss: 0.201 | Acc: 93.107% (16208/17408)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.066% (16320/17536)\n",
      "Train Epoch: 84 | Loss: 0.204 | Acc: 93.048% (16436/17664)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.059% (16557/17792)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.047% (16674/17920)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.052% (16794/18048)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.035% (16910/18176)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.045% (17031/18304)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.061% (17153/18432)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.055% (17271/18560)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.044% (17388/18688)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.059% (17510/18816)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.048% (17627/18944)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.058% (17748/19072)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.083% (17872/19200)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.077% (17990/19328)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.056% (18105/19456)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.066% (18226/19584)\n",
      "Train Epoch: 84 | Loss: 0.202 | Acc: 93.040% (18340/19712)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.039% (18459/19840)\n",
      "Train Epoch: 84 | Loss: 0.203 | Acc: 93.049% (18580/19968)\n",
      "Train Epoch: 84 | Loss: 0.204 | Acc: 93.019% (18693/20096)\n",
      "Train Epoch: 84 | Loss: 0.204 | Acc: 93.018% (18812/20224)\n",
      "Train Epoch: 84 | Loss: 0.205 | Acc: 92.974% (18922/20352)\n",
      "Train Epoch: 84 | Loss: 0.205 | Acc: 92.969% (19040/20480)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.969% (19159/20608)\n",
      "Train Epoch: 84 | Loss: 0.205 | Acc: 92.974% (19279/20736)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.954% (19394/20864)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.954% (19513/20992)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.955% (19632/21120)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.964% (19753/21248)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.964% (19872/21376)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.945% (19987/21504)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.932% (20103/21632)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.950% (20226/21760)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.960% (20347/21888)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.941% (20462/22016)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.946% (20582/22144)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.933% (20698/22272)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.964% (20824/22400)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.933% (20936/22528)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.947% (21058/22656)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.947% (21177/22784)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.943% (21295/22912)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.938% (21413/23040)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.943% (21533/23168)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.934% (21650/23296)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.952% (21773/23424)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.956% (21893/23552)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.960% (22013/23680)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.965% (22133/23808)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.956% (22250/23936)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.952% (22368/24064)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.965% (22490/24192)\n",
      "Train Epoch: 84 | Loss: 0.206 | Acc: 92.965% (22609/24320)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.944% (22723/24448)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.924% (22837/24576)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.920% (22955/24704)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.928% (23076/24832)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.929% (23195/24960)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.929% (23314/25088)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.917% (23430/25216)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.917% (23549/25344)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.906% (23665/25472)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.910% (23785/25600)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.903% (23902/25728)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.888% (24017/25856)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.892% (24137/25984)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.881% (24253/26112)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.881% (24372/26240)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.885% (24492/26368)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.893% (24613/26496)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.912% (24737/26624)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.920% (24858/26752)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.913% (24975/26880)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.913% (25094/27008)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.932% (25218/27136)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.906% (25330/27264)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.903% (25448/27392)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.889% (25563/27520)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.900% (25685/27648)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.897% (25803/27776)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.893% (25921/27904)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.901% (26042/28032)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.908% (26163/28160)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.923% (26286/28288)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.891% (26396/28416)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.888% (26514/28544)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.896% (26635/28672)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.899% (26755/28800)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.896% (26873/28928)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.893% (26991/29056)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.890% (27109/29184)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.904% (27232/29312)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.894% (27348/29440)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.901% (27469/29568)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.908% (27590/29696)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.885% (27702/29824)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.889% (27822/29952)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.882% (27939/30080)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.883% (28058/30208)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.876% (28175/30336)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.877% (28294/30464)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.884% (28415/30592)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.897% (28538/30720)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.897% (28657/30848)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.898% (28776/30976)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.904% (28897/31104)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.905% (29016/31232)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.899% (29133/31360)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.915% (29257/31488)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.918% (29377/31616)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.918% (29496/31744)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.934% (29620/31872)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.941% (29741/32000)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.944% (29861/32128)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.947% (29981/32256)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.935% (30096/32384)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.932% (30214/32512)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.932% (30333/32640)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.944% (30456/32768)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.951% (30577/32896)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.935% (30691/33024)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.933% (30809/33152)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.951% (30934/33280)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.951% (31053/33408)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.948% (31171/33536)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.942% (31288/33664)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.936% (31405/33792)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.936% (31524/33920)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.936% (31643/34048)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.934% (31761/34176)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.934% (31880/34304)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.937% (32000/34432)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.943% (32121/34560)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.943% (32240/34688)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.943% (32359/34816)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.934% (32475/34944)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.935% (32594/35072)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.946% (32717/35200)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.935% (32832/35328)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.938% (32952/35456)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.932% (33069/35584)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.924% (33185/35712)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.930% (33306/35840)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.921% (33422/35968)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.933% (33545/36096)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.925% (33661/36224)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.916% (33777/36352)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.919% (33897/36480)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.925% (34018/36608)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.925% (34137/36736)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.920% (34254/36864)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.925% (34375/36992)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.915% (34490/37120)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.912% (34608/37248)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.915% (34728/37376)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.913% (34846/37504)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.916% (34966/37632)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.918% (35086/37760)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.913% (35203/37888)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.911% (35321/38016)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.922% (35444/38144)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.919% (35562/38272)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.919% (35681/38400)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.917% (35799/38528)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.922% (35920/38656)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.917% (36037/38784)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.917% (36156/38912)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.915% (36274/39040)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.918% (36394/39168)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.920% (36514/39296)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.931% (36637/39424)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.931% (36756/39552)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.936% (36877/39680)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.916% (36988/39808)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.909% (37104/39936)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.919% (37227/40064)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.921% (37347/40192)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.927% (37468/40320)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.934% (37590/40448)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.934% (37709/40576)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.927% (37825/40704)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.917% (37940/40832)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.917% (38059/40960)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.923% (38180/41088)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.923% (38299/41216)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.918% (38416/41344)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.916% (38534/41472)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.899% (38646/41600)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.894% (38763/41728)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.888% (38879/41856)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.902% (39004/41984)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.898% (39121/42112)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.895% (39239/42240)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.896% (39358/42368)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.898% (39478/42496)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.905% (39600/42624)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.915% (39723/42752)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.917% (39843/42880)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.920% (39963/43008)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.925% (40084/43136)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.927% (40204/43264)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.930% (40324/43392)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.923% (40440/43520)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.916% (40556/43648)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.914% (40674/43776)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.912% (40792/43904)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.921% (40915/44032)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.923% (41035/44160)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.926% (41155/44288)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.930% (41276/44416)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.926% (41393/44544)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.920% (41509/44672)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.929% (41632/44800)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.929% (41751/44928)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.933% (41872/45056)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.936% (41992/45184)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.942% (42114/45312)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.951% (42237/45440)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.953% (42357/45568)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.953% (42476/45696)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.953% (42595/45824)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.945% (42710/45952)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.949% (42831/46080)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.956% (42953/46208)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.958% (43073/46336)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.958% (43192/46464)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.964% (43314/46592)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.969% (43435/46720)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.962% (43551/46848)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.958% (43668/46976)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.956% (43786/47104)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.952% (43903/47232)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.941% (44017/47360)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.952% (44141/47488)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.960% (44264/47616)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.950% (44378/47744)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.940% (44492/47872)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.927% (44605/48000)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.938% (44729/48128)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.929% (44844/48256)\n",
      "Train Epoch: 84 | Loss: 0.207 | Acc: 92.934% (44965/48384)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.923% (45079/48512)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.926% (45199/48640)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.928% (45319/48768)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.911% (45430/48896)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.912% (45549/49024)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.916% (45670/49152)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.916% (45789/49280)\n",
      "Train Epoch: 84 | Loss: 0.208 | Acc: 92.912% (45906/49408)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.898% (46018/49536)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.900% (46138/49664)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.892% (46253/49792)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.895% (46373/49920)\n",
      "Train Epoch: 84 | Loss: 0.209 | Acc: 92.884% (46442/50000)\n",
      "Test Epoch: 84 | Loss: 0.300 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 84 | Loss: 0.344 | Acc: 88.500% (177/200)\n",
      "Test Epoch: 84 | Loss: 0.348 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 84 | Loss: 0.331 | Acc: 88.500% (354/400)\n",
      "Test Epoch: 84 | Loss: 0.312 | Acc: 88.600% (443/500)\n",
      "Test Epoch: 84 | Loss: 0.296 | Acc: 89.500% (537/600)\n",
      "Test Epoch: 84 | Loss: 0.299 | Acc: 89.857% (629/700)\n",
      "Test Epoch: 84 | Loss: 0.328 | Acc: 89.125% (713/800)\n",
      "Test Epoch: 84 | Loss: 0.338 | Acc: 89.333% (804/900)\n",
      "Test Epoch: 84 | Loss: 0.327 | Acc: 89.600% (896/1000)\n",
      "Test Epoch: 84 | Loss: 0.326 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 89.083% (1069/1200)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 88.923% (1156/1300)\n",
      "Test Epoch: 84 | Loss: 0.325 | Acc: 89.071% (1247/1400)\n",
      "Test Epoch: 84 | Loss: 0.327 | Acc: 89.067% (1336/1500)\n",
      "Test Epoch: 84 | Loss: 0.322 | Acc: 89.062% (1425/1600)\n",
      "Test Epoch: 84 | Loss: 0.323 | Acc: 89.235% (1517/1700)\n",
      "Test Epoch: 84 | Loss: 0.325 | Acc: 89.167% (1605/1800)\n",
      "Test Epoch: 84 | Loss: 0.327 | Acc: 88.947% (1690/1900)\n",
      "Test Epoch: 84 | Loss: 0.333 | Acc: 88.800% (1776/2000)\n",
      "Test Epoch: 84 | Loss: 0.334 | Acc: 88.810% (1865/2100)\n",
      "Test Epoch: 84 | Loss: 0.331 | Acc: 88.909% (1956/2200)\n",
      "Test Epoch: 84 | Loss: 0.335 | Acc: 88.783% (2042/2300)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 89.000% (2136/2400)\n",
      "Test Epoch: 84 | Loss: 0.334 | Acc: 89.040% (2226/2500)\n",
      "Test Epoch: 84 | Loss: 0.345 | Acc: 88.885% (2311/2600)\n",
      "Test Epoch: 84 | Loss: 0.339 | Acc: 89.000% (2403/2700)\n",
      "Test Epoch: 84 | Loss: 0.342 | Acc: 88.929% (2490/2800)\n",
      "Test Epoch: 84 | Loss: 0.342 | Acc: 88.828% (2576/2900)\n",
      "Test Epoch: 84 | Loss: 0.341 | Acc: 88.833% (2665/3000)\n",
      "Test Epoch: 84 | Loss: 0.341 | Acc: 88.871% (2755/3100)\n",
      "Test Epoch: 84 | Loss: 0.338 | Acc: 88.906% (2845/3200)\n",
      "Test Epoch: 84 | Loss: 0.339 | Acc: 88.879% (2933/3300)\n",
      "Test Epoch: 84 | Loss: 0.336 | Acc: 88.912% (3023/3400)\n",
      "Test Epoch: 84 | Loss: 0.338 | Acc: 88.829% (3109/3500)\n",
      "Test Epoch: 84 | Loss: 0.338 | Acc: 88.944% (3202/3600)\n",
      "Test Epoch: 84 | Loss: 0.341 | Acc: 88.892% (3289/3700)\n",
      "Test Epoch: 84 | Loss: 0.344 | Acc: 88.842% (3376/3800)\n",
      "Test Epoch: 84 | Loss: 0.340 | Acc: 88.897% (3467/3900)\n",
      "Test Epoch: 84 | Loss: 0.339 | Acc: 89.000% (3560/4000)\n",
      "Test Epoch: 84 | Loss: 0.341 | Acc: 89.000% (3649/4100)\n",
      "Test Epoch: 84 | Loss: 0.340 | Acc: 89.024% (3739/4200)\n",
      "Test Epoch: 84 | Loss: 0.338 | Acc: 89.093% (3831/4300)\n",
      "Test Epoch: 84 | Loss: 0.336 | Acc: 89.205% (3925/4400)\n",
      "Test Epoch: 84 | Loss: 0.335 | Acc: 89.267% (4017/4500)\n",
      "Test Epoch: 84 | Loss: 0.335 | Acc: 89.196% (4103/4600)\n",
      "Test Epoch: 84 | Loss: 0.333 | Acc: 89.213% (4193/4700)\n",
      "Test Epoch: 84 | Loss: 0.335 | Acc: 89.167% (4280/4800)\n",
      "Test Epoch: 84 | Loss: 0.332 | Acc: 89.245% (4373/4900)\n",
      "Test Epoch: 84 | Loss: 0.333 | Acc: 89.140% (4457/5000)\n",
      "Test Epoch: 84 | Loss: 0.331 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 84 | Loss: 0.331 | Acc: 89.231% (4640/5200)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 89.226% (4729/5300)\n",
      "Test Epoch: 84 | Loss: 0.329 | Acc: 89.259% (4820/5400)\n",
      "Test Epoch: 84 | Loss: 0.329 | Acc: 89.236% (4908/5500)\n",
      "Test Epoch: 84 | Loss: 0.331 | Acc: 89.232% (4997/5600)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 89.263% (5088/5700)\n",
      "Test Epoch: 84 | Loss: 0.328 | Acc: 89.276% (5178/5800)\n",
      "Test Epoch: 84 | Loss: 0.330 | Acc: 89.220% (5264/5900)\n",
      "Test Epoch: 84 | Loss: 0.328 | Acc: 89.317% (5359/6000)\n",
      "Test Epoch: 84 | Loss: 0.329 | Acc: 89.246% (5444/6100)\n",
      "Test Epoch: 84 | Loss: 0.328 | Acc: 89.274% (5535/6200)\n",
      "Test Epoch: 84 | Loss: 0.326 | Acc: 89.349% (5629/6300)\n",
      "Test Epoch: 84 | Loss: 0.324 | Acc: 89.422% (5723/6400)\n",
      "Test Epoch: 84 | Loss: 0.324 | Acc: 89.385% (5810/6500)\n",
      "Test Epoch: 84 | Loss: 0.323 | Acc: 89.439% (5903/6600)\n",
      "Test Epoch: 84 | Loss: 0.321 | Acc: 89.493% (5996/6700)\n",
      "Test Epoch: 84 | Loss: 0.322 | Acc: 89.456% (6083/6800)\n",
      "Test Epoch: 84 | Loss: 0.320 | Acc: 89.536% (6178/6900)\n",
      "Test Epoch: 84 | Loss: 0.318 | Acc: 89.571% (6270/7000)\n",
      "Test Epoch: 84 | Loss: 0.319 | Acc: 89.634% (6364/7100)\n",
      "Test Epoch: 84 | Loss: 0.319 | Acc: 89.667% (6456/7200)\n",
      "Test Epoch: 84 | Loss: 0.316 | Acc: 89.726% (6550/7300)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.716% (6639/7400)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.667% (6725/7500)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.645% (6813/7600)\n",
      "Test Epoch: 84 | Loss: 0.319 | Acc: 89.597% (6899/7700)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.628% (6991/7800)\n",
      "Test Epoch: 84 | Loss: 0.316 | Acc: 89.658% (7083/7900)\n",
      "Test Epoch: 84 | Loss: 0.316 | Acc: 89.662% (7173/8000)\n",
      "Test Epoch: 84 | Loss: 0.314 | Acc: 89.741% (7269/8100)\n",
      "Test Epoch: 84 | Loss: 0.314 | Acc: 89.744% (7359/8200)\n",
      "Test Epoch: 84 | Loss: 0.314 | Acc: 89.711% (7446/8300)\n",
      "Test Epoch: 84 | Loss: 0.313 | Acc: 89.702% (7535/8400)\n",
      "Test Epoch: 84 | Loss: 0.316 | Acc: 89.624% (7618/8500)\n",
      "Test Epoch: 84 | Loss: 0.318 | Acc: 89.558% (7702/8600)\n",
      "Test Epoch: 84 | Loss: 0.318 | Acc: 89.609% (7796/8700)\n",
      "Test Epoch: 84 | Loss: 0.319 | Acc: 89.580% (7883/8800)\n",
      "Test Epoch: 84 | Loss: 0.320 | Acc: 89.551% (7970/8900)\n",
      "Test Epoch: 84 | Loss: 0.319 | Acc: 89.567% (8061/9000)\n",
      "Test Epoch: 84 | Loss: 0.318 | Acc: 89.560% (8150/9100)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.620% (8245/9200)\n",
      "Test Epoch: 84 | Loss: 0.317 | Acc: 89.634% (8336/9300)\n",
      "Test Epoch: 84 | Loss: 0.316 | Acc: 89.660% (8428/9400)\n",
      "Test Epoch: 84 | Loss: 0.315 | Acc: 89.674% (8519/9500)\n",
      "Test Epoch: 84 | Loss: 0.314 | Acc: 89.688% (8610/9600)\n",
      "Test Epoch: 84 | Loss: 0.312 | Acc: 89.763% (8707/9700)\n",
      "Test Epoch: 84 | Loss: 0.312 | Acc: 89.765% (8797/9800)\n",
      "Test Epoch: 84 | Loss: 0.312 | Acc: 89.778% (8888/9900)\n",
      "Test Epoch: 84 | Loss: 0.311 | Acc: 89.780% (8978/10000)\n",
      "\n",
      "Epoch: 85\n",
      "Train Epoch: 85 | Loss: 0.150 | Acc: 94.531% (121/128)\n",
      "Train Epoch: 85 | Loss: 0.185 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.448% (355/384)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 92.773% (475/512)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 92.969% (595/640)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.708% (712/768)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 93.080% (834/896)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 93.066% (953/1024)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 93.316% (1075/1152)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.438% (1196/1280)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.608% (1318/1408)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.750% (1440/1536)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.450% (1555/1664)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.527% (1676/1792)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.490% (1795/1920)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.262% (1910/2048)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.336% (2031/2176)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.273% (2149/2304)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.503% (2274/2432)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.594% (2396/2560)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.378% (2510/2688)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.217% (2625/2816)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.037% (2739/2944)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.969% (2856/3072)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.812% (2970/3200)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.849% (3090/3328)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.911% (3211/3456)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.941% (3331/3584)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.942% (3450/3712)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.917% (3568/3840)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.944% (3688/3968)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.091% (3813/4096)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.040% (3930/4224)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.084% (4051/4352)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.080% (4170/4480)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.099% (4290/4608)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.138% (4411/4736)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.092% (4528/4864)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.089% (4647/4992)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.066% (4765/5120)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.045% (4883/5248)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.173% (5009/5376)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.132% (5126/5504)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.058% (5241/5632)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.056% (5360/5760)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.037% (5478/5888)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.035% (5597/6016)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 92.985% (5713/6144)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 92.985% (5832/6272)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.984% (5951/6400)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 92.923% (6066/6528)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.969% (6188/6656)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.954% (6306/6784)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 92.969% (6426/6912)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.011% (6548/7040)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 92.997% (6666/7168)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.092% (6792/7296)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.063% (6909/7424)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.128% (7033/7552)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.073% (7148/7680)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.097% (7269/7808)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.107% (7389/7936)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.105% (7508/8064)\n",
      "Train Epoch: 85 | Loss: 0.192 | Acc: 93.115% (7628/8192)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.101% (7746/8320)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.040% (7860/8448)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.062% (7981/8576)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.084% (8102/8704)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.048% (8218/8832)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.036% (8336/8960)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.035% (8455/9088)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.066% (8577/9216)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.022% (8692/9344)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 92.979% (8807/9472)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 92.990% (8927/9600)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 92.958% (9043/9728)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 92.969% (9163/9856)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.949% (9280/9984)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.989% (9403/10112)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 92.988% (9522/10240)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.027% (9645/10368)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.035% (9765/10496)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.044% (9885/10624)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.071% (10007/10752)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.116% (10131/10880)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.123% (10251/11008)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.085% (10366/11136)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.084% (10485/11264)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.092% (10605/11392)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.090% (10724/11520)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.098% (10844/11648)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.071% (10960/11776)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.078% (11080/11904)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.052% (11196/12032)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.051% (11315/12160)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.026% (11431/12288)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.065% (11555/12416)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.080% (11676/12544)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.071% (11794/12672)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.070% (11913/12800)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.046% (12029/12928)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.030% (12146/13056)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.014% (12263/13184)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.036% (12385/13312)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.051% (12506/13440)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.006% (12619/13568)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.020% (12740/13696)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.056% (12864/13824)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.055% (12983/13952)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.026% (13098/14080)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.032% (13218/14208)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.039% (13338/14336)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.038% (13457/14464)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.030% (13575/14592)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.043% (13696/14720)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.063% (13818/14848)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.049% (13935/14976)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.088% (14060/15104)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.093% (14180/15232)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.112% (14302/15360)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.104% (14420/15488)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.116% (14541/15616)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.147% (14665/15744)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.120% (14780/15872)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.106% (14897/16000)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.124% (15019/16128)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.147% (15142/16256)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.121% (15257/16384)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.144% (15380/16512)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.149% (15500/16640)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.172% (15623/16768)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.170% (15742/16896)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.157% (15859/17024)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.167% (15980/17152)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.183% (16102/17280)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.199% (16224/17408)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.214% (16346/17536)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.218% (16466/17664)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.227% (16587/17792)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.214% (16704/17920)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.218% (16824/18048)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.233% (16946/18176)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.253% (17069/18304)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.240% (17186/18432)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.244% (17306/18560)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.226% (17422/18688)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.234% (17543/18816)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.233% (17662/18944)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.194% (17774/19072)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.208% (17896/19200)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.191% (18012/19328)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.185% (18130/19456)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.178% (18248/19584)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.197% (18371/19712)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.206% (18492/19840)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.214% (18613/19968)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.208% (18731/20096)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.226% (18854/20224)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.210% (18970/20352)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.198% (19087/20480)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.207% (19208/20608)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.215% (19329/20736)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.232% (19452/20864)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.245% (19574/20992)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.253% (19695/21120)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.237% (19811/21248)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.240% (19931/21376)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.252% (20053/21504)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.237% (20169/21632)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.231% (20287/21760)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.238% (20408/21888)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.228% (20525/22016)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.217% (20642/22144)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.207% (20759/22272)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.210% (20879/22400)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.213% (20999/22528)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.234% (21123/22656)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.254% (21247/22784)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.266% (21369/22912)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.273% (21490/23040)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.271% (21609/23168)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.248% (21723/23296)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.246% (21842/23424)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.249% (21962/23552)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.256% (22083/23680)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.242% (22199/23808)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.215% (22312/23936)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.239% (22437/24064)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.250% (22559/24192)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.244% (22677/24320)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.255% (22799/24448)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.262% (22920/24576)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.276% (23043/24704)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.283% (23164/24832)\n",
      "Train Epoch: 85 | Loss: 0.192 | Acc: 93.297% (23287/24960)\n",
      "Train Epoch: 85 | Loss: 0.192 | Acc: 93.300% (23407/25088)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.294% (23525/25216)\n",
      "Train Epoch: 85 | Loss: 0.192 | Acc: 93.312% (23649/25344)\n",
      "Train Epoch: 85 | Loss: 0.193 | Acc: 93.283% (23761/25472)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.254% (23873/25600)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.260% (23994/25728)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.259% (24113/25856)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.261% (24233/25984)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.260% (24352/26112)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.266% (24473/26240)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.284% (24597/26368)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.297% (24720/26496)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.288% (24837/26624)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.268% (24951/26752)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.285% (25075/26880)\n",
      "Train Epoch: 85 | Loss: 0.194 | Acc: 93.287% (25195/27008)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.264% (25308/27136)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.262% (25427/27264)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.254% (25544/27392)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.270% (25668/27520)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.265% (25786/27648)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.253% (25902/27776)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.263% (26024/27904)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.265% (26144/28032)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.278% (26267/28160)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.266% (26383/28288)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.247% (26497/28416)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.260% (26620/28544)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.258% (26739/28672)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.257% (26858/28800)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.273% (26982/28928)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.251% (27095/29056)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.260% (27217/29184)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.266% (27338/29312)\n",
      "Train Epoch: 85 | Loss: 0.195 | Acc: 93.261% (27456/29440)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.246% (27571/29568)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.248% (27691/29696)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.250% (27811/29824)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.253% (27931/29952)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.265% (28054/30080)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.260% (28172/30208)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.262% (28292/30336)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.271% (28414/30464)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.260% (28530/30592)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.271% (28653/30720)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.264% (28770/30848)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.279% (28894/30976)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.281% (29014/31104)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.279% (29133/31232)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.265% (29248/31360)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.251% (29363/31488)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.257% (29484/31616)\n",
      "Train Epoch: 85 | Loss: 0.196 | Acc: 93.246% (29600/31744)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.242% (29718/31872)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.237% (29836/32000)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.212% (29947/32128)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.198% (30062/32256)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.200% (30182/32384)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.206% (30303/32512)\n",
      "Train Epoch: 85 | Loss: 0.197 | Acc: 93.199% (30420/32640)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.201% (30540/32768)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.197% (30658/32896)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.187% (30774/33024)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.171% (30888/33152)\n",
      "Train Epoch: 85 | Loss: 0.198 | Acc: 93.161% (31004/33280)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.151% (31120/33408)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.142% (31236/33536)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.141% (31355/33664)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.152% (31478/33792)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.146% (31595/33920)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.130% (31709/34048)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.121% (31825/34176)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.126% (31946/34304)\n",
      "Train Epoch: 85 | Loss: 0.199 | Acc: 93.128% (32066/34432)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.108% (32178/34560)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.113% (32299/34688)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.109% (32417/34816)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.112% (32537/34944)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.108% (32655/35072)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.122% (32779/35200)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.113% (32895/35328)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.121% (33017/35456)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.106% (33131/35584)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.114% (33253/35712)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.125% (33376/35840)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.113% (33491/35968)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.121% (33613/36096)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.115% (33730/36224)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.093% (33841/36352)\n",
      "Train Epoch: 85 | Loss: 0.200 | Acc: 93.089% (33959/36480)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.078% (34074/36608)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.075% (34192/36736)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.072% (34310/36864)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.058% (34424/36992)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.052% (34541/37120)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.057% (34662/37248)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.052% (34779/37376)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.051% (34898/37504)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.035% (35011/37632)\n",
      "Train Epoch: 85 | Loss: 0.201 | Acc: 93.051% (35136/37760)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.048% (35254/37888)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.045% (35372/38016)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.045% (35491/38144)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.029% (35604/38272)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.029% (35723/38400)\n",
      "Train Epoch: 85 | Loss: 0.202 | Acc: 93.026% (35841/38528)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.013% (35955/38656)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.013% (36074/38784)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.010% (36192/38912)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.007% (36310/39040)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.999% (36426/39168)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.999% (36545/39296)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.014% (36670/39424)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.017% (36790/39552)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.014% (36908/39680)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.016% (37028/39808)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.004% (37142/39936)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.999% (37259/40064)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.001% (37379/40192)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 93.001% (37498/40320)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.986% (37611/40448)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.981% (37728/40576)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.983% (37848/40704)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.983% (37967/40832)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.979% (38084/40960)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.976% (38202/41088)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.983% (38324/41216)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.971% (38438/41344)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.964% (38554/41472)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.962% (38672/41600)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.957% (38789/41728)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.957% (38908/41856)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.959% (39028/41984)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.962% (39148/42112)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.964% (39268/42240)\n",
      "Train Epoch: 85 | Loss: 0.203 | Acc: 92.966% (39388/42368)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.962% (39505/42496)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.957% (39622/42624)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.962% (39743/42752)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.950% (39857/42880)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.922% (39964/43008)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.925% (40084/43136)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.925% (40203/43264)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.927% (40323/43392)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.925% (40441/43520)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.925% (40560/43648)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.928% (40680/43776)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.930% (40800/43904)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.928% (40918/44032)\n",
      "Train Epoch: 85 | Loss: 0.204 | Acc: 92.919% (41033/44160)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.901% (41144/44288)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.885% (41256/44416)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.886% (41375/44544)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.886% (41494/44672)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.877% (41609/44800)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.875% (41727/44928)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.871% (41844/45056)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.863% (41959/45184)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.861% (42077/45312)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.870% (42200/45440)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.874% (42321/45568)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.870% (42438/45696)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.879% (42561/45824)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.884% (42682/45952)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.888% (42803/46080)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.869% (42913/46208)\n",
      "Train Epoch: 85 | Loss: 0.205 | Acc: 92.863% (43029/46336)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.859% (43146/46464)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.857% (43264/46592)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.849% (43379/46720)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.853% (43500/46848)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.847% (43616/46976)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.843% (43733/47104)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.854% (43857/47232)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.848% (43973/47360)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.838% (44087/47488)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.841% (44207/47616)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.835% (44323/47744)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.829% (44439/47872)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.835% (44561/48000)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.832% (44678/48128)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.828% (44795/48256)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.812% (44906/48384)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.808% (45023/48512)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.808% (45142/48640)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.815% (45264/48768)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.819% (45385/48896)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.830% (45509/49024)\n",
      "Train Epoch: 85 | Loss: 0.206 | Acc: 92.832% (45629/49152)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.827% (45745/49280)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.821% (45861/49408)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.811% (45975/49536)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.812% (46094/49664)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.810% (46212/49792)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.815% (46333/49920)\n",
      "Train Epoch: 85 | Loss: 0.207 | Acc: 92.806% (46403/50000)\n",
      "Test Epoch: 85 | Loss: 0.378 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 85 | Loss: 0.429 | Acc: 87.000% (174/200)\n",
      "Test Epoch: 85 | Loss: 0.389 | Acc: 87.667% (263/300)\n",
      "Test Epoch: 85 | Loss: 0.357 | Acc: 89.000% (356/400)\n",
      "Test Epoch: 85 | Loss: 0.335 | Acc: 89.200% (446/500)\n",
      "Test Epoch: 85 | Loss: 0.314 | Acc: 90.000% (540/600)\n",
      "Test Epoch: 85 | Loss: 0.317 | Acc: 89.714% (628/700)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.250% (714/800)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.556% (806/900)\n",
      "Test Epoch: 85 | Loss: 0.336 | Acc: 89.700% (897/1000)\n",
      "Test Epoch: 85 | Loss: 0.341 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 85 | Loss: 0.333 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 85 | Loss: 0.323 | Acc: 89.615% (1165/1300)\n",
      "Test Epoch: 85 | Loss: 0.316 | Acc: 89.857% (1258/1400)\n",
      "Test Epoch: 85 | Loss: 0.321 | Acc: 89.733% (1346/1500)\n",
      "Test Epoch: 85 | Loss: 0.317 | Acc: 89.812% (1437/1600)\n",
      "Test Epoch: 85 | Loss: 0.320 | Acc: 89.941% (1529/1700)\n",
      "Test Epoch: 85 | Loss: 0.333 | Acc: 89.500% (1611/1800)\n",
      "Test Epoch: 85 | Loss: 0.330 | Acc: 89.526% (1701/1900)\n",
      "Test Epoch: 85 | Loss: 0.329 | Acc: 89.550% (1791/2000)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.238% (1874/2100)\n",
      "Test Epoch: 85 | Loss: 0.335 | Acc: 89.273% (1964/2200)\n",
      "Test Epoch: 85 | Loss: 0.342 | Acc: 89.130% (2050/2300)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.208% (2141/2400)\n",
      "Test Epoch: 85 | Loss: 0.346 | Acc: 89.040% (2226/2500)\n",
      "Test Epoch: 85 | Loss: 0.359 | Acc: 88.846% (2310/2600)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.037% (2404/2700)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.071% (2494/2800)\n",
      "Test Epoch: 85 | Loss: 0.353 | Acc: 89.069% (2583/2900)\n",
      "Test Epoch: 85 | Loss: 0.350 | Acc: 89.067% (2672/3000)\n",
      "Test Epoch: 85 | Loss: 0.352 | Acc: 89.065% (2761/3100)\n",
      "Test Epoch: 85 | Loss: 0.348 | Acc: 89.125% (2852/3200)\n",
      "Test Epoch: 85 | Loss: 0.350 | Acc: 89.152% (2942/3300)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.088% (3029/3400)\n",
      "Test Epoch: 85 | Loss: 0.357 | Acc: 88.971% (3114/3500)\n",
      "Test Epoch: 85 | Loss: 0.356 | Acc: 89.056% (3206/3600)\n",
      "Test Epoch: 85 | Loss: 0.356 | Acc: 89.081% (3296/3700)\n",
      "Test Epoch: 85 | Loss: 0.358 | Acc: 89.000% (3382/3800)\n",
      "Test Epoch: 85 | Loss: 0.355 | Acc: 89.128% (3476/3900)\n",
      "Test Epoch: 85 | Loss: 0.355 | Acc: 89.200% (3568/4000)\n",
      "Test Epoch: 85 | Loss: 0.356 | Acc: 89.220% (3658/4100)\n",
      "Test Epoch: 85 | Loss: 0.357 | Acc: 89.238% (3748/4200)\n",
      "Test Epoch: 85 | Loss: 0.357 | Acc: 89.209% (3836/4300)\n",
      "Test Epoch: 85 | Loss: 0.354 | Acc: 89.341% (3931/4400)\n",
      "Test Epoch: 85 | Loss: 0.352 | Acc: 89.333% (4020/4500)\n",
      "Test Epoch: 85 | Loss: 0.354 | Acc: 89.130% (4100/4600)\n",
      "Test Epoch: 85 | Loss: 0.353 | Acc: 89.170% (4191/4700)\n",
      "Test Epoch: 85 | Loss: 0.357 | Acc: 89.042% (4274/4800)\n",
      "Test Epoch: 85 | Loss: 0.354 | Acc: 89.143% (4368/4900)\n",
      "Test Epoch: 85 | Loss: 0.354 | Acc: 89.140% (4457/5000)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.196% (4549/5100)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.154% (4636/5200)\n",
      "Test Epoch: 85 | Loss: 0.350 | Acc: 89.170% (4726/5300)\n",
      "Test Epoch: 85 | Loss: 0.348 | Acc: 89.241% (4819/5400)\n",
      "Test Epoch: 85 | Loss: 0.349 | Acc: 89.200% (4906/5500)\n",
      "Test Epoch: 85 | Loss: 0.351 | Acc: 89.125% (4991/5600)\n",
      "Test Epoch: 85 | Loss: 0.349 | Acc: 89.175% (5083/5700)\n",
      "Test Epoch: 85 | Loss: 0.349 | Acc: 89.155% (5171/5800)\n",
      "Test Epoch: 85 | Loss: 0.349 | Acc: 89.136% (5259/5900)\n",
      "Test Epoch: 85 | Loss: 0.348 | Acc: 89.167% (5350/6000)\n",
      "Test Epoch: 85 | Loss: 0.349 | Acc: 89.098% (5435/6100)\n",
      "Test Epoch: 85 | Loss: 0.348 | Acc: 89.113% (5525/6200)\n",
      "Test Epoch: 85 | Loss: 0.347 | Acc: 89.206% (5620/6300)\n",
      "Test Epoch: 85 | Loss: 0.344 | Acc: 89.281% (5714/6400)\n",
      "Test Epoch: 85 | Loss: 0.343 | Acc: 89.338% (5807/6500)\n",
      "Test Epoch: 85 | Loss: 0.341 | Acc: 89.333% (5896/6600)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.388% (5989/6700)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.309% (6073/6800)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.333% (6164/6900)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.329% (6253/7000)\n",
      "Test Epoch: 85 | Loss: 0.341 | Acc: 89.338% (6343/7100)\n",
      "Test Epoch: 85 | Loss: 0.341 | Acc: 89.306% (6430/7200)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.384% (6525/7300)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.365% (6613/7400)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.373% (6703/7500)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.382% (6793/7600)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.325% (6878/7700)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.385% (6972/7800)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.354% (7059/7900)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.338% (7147/8000)\n",
      "Test Epoch: 85 | Loss: 0.336 | Acc: 89.358% (7238/8100)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.305% (7323/8200)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.265% (7409/8300)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.262% (7498/8400)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.200% (7582/8500)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.163% (7668/8600)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.161% (7757/8700)\n",
      "Test Epoch: 85 | Loss: 0.341 | Acc: 89.170% (7847/8800)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.213% (7940/8900)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.178% (8026/9000)\n",
      "Test Epoch: 85 | Loss: 0.340 | Acc: 89.198% (8117/9100)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.239% (8210/9200)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.237% (8299/9300)\n",
      "Test Epoch: 85 | Loss: 0.339 | Acc: 89.234% (8388/9400)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.274% (8481/9500)\n",
      "Test Epoch: 85 | Loss: 0.338 | Acc: 89.250% (8568/9600)\n",
      "Test Epoch: 85 | Loss: 0.336 | Acc: 89.299% (8662/9700)\n",
      "Test Epoch: 85 | Loss: 0.336 | Acc: 89.286% (8750/9800)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.293% (8840/9900)\n",
      "Test Epoch: 85 | Loss: 0.337 | Acc: 89.270% (8927/10000)\n",
      "\n",
      "Epoch: 86\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 86 | Loss: 0.242 | Acc: 91.406% (234/256)\n",
      "Train Epoch: 86 | Loss: 0.256 | Acc: 91.146% (350/384)\n",
      "Train Epoch: 86 | Loss: 0.244 | Acc: 91.602% (469/512)\n",
      "Train Epoch: 86 | Loss: 0.220 | Acc: 92.188% (590/640)\n",
      "Train Epoch: 86 | Loss: 0.223 | Acc: 92.057% (707/768)\n",
      "Train Epoch: 86 | Loss: 0.222 | Acc: 91.853% (823/896)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.383% (946/1024)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 92.795% (1069/1152)\n",
      "Train Epoch: 86 | Loss: 0.198 | Acc: 92.969% (1190/1280)\n",
      "Train Epoch: 86 | Loss: 0.200 | Acc: 93.111% (1311/1408)\n",
      "Train Epoch: 86 | Loss: 0.199 | Acc: 93.229% (1432/1536)\n",
      "Train Epoch: 86 | Loss: 0.200 | Acc: 93.089% (1549/1664)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.913% (1665/1792)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.917% (1784/1920)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.822% (1901/2048)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.923% (2022/2176)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.925% (2141/2304)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.763% (2256/2432)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.891% (2378/2560)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 93.006% (2500/2688)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.827% (2614/2816)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.969% (2737/2944)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.936% (2855/3072)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.875% (2972/3200)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.909% (3092/3328)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.911% (3211/3456)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.829% (3327/3584)\n",
      "Train Epoch: 86 | Loss: 0.216 | Acc: 92.753% (3443/3712)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.865% (3566/3840)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.969% (3689/3968)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.920% (3806/4096)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.898% (3924/4224)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.877% (4042/4352)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.835% (4159/4480)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.882% (4280/4608)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.969% (4403/4736)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.907% (4519/4864)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.929% (4639/4992)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.910% (4757/5120)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.835% (4872/5248)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.857% (4992/5376)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.842% (5110/5504)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.880% (5231/5632)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.847% (5348/5760)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.867% (5468/5888)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.936% (5591/6016)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.985% (5713/6144)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.985% (5832/6272)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.938% (5948/6400)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.892% (6064/6528)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.819% (6178/6656)\n",
      "Train Epoch: 86 | Loss: 0.213 | Acc: 92.777% (6294/6784)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.839% (6417/6912)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.784% (6532/7040)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.815% (6653/7168)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.791% (6770/7296)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.821% (6891/7424)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.876% (7014/7552)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.865% (7132/7680)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.789% (7245/7808)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.830% (7367/7936)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.795% (7483/8064)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.810% (7603/8192)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.776% (7719/8320)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.791% (7839/8448)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.771% (7956/8576)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.831% (8080/8704)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.867% (8202/8832)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.891% (8323/8960)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.925% (8445/9088)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.958% (8567/9216)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.915% (8682/9344)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.927% (8802/9472)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.958% (8924/9600)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.958% (9043/9728)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.928% (9159/9856)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.929% (9278/9984)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.959% (9400/10112)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.939% (9517/10240)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.940% (9636/10368)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.893% (9750/10496)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.865% (9866/10624)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.839% (9982/10752)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.812% (10098/10880)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.805% (10216/11008)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.780% (10332/11136)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.809% (10454/11264)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.846% (10577/11392)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.847% (10696/11520)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.840% (10814/11648)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.850% (10934/11776)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.851% (11053/11904)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.844% (11171/12032)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.870% (11293/12160)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.871% (11412/12288)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.872% (11531/12416)\n",
      "Train Epoch: 86 | Loss: 0.212 | Acc: 92.857% (11648/12544)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.866% (11768/12672)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.898% (11891/12800)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.915% (12012/12928)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.915% (12131/13056)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.908% (12249/13184)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.901% (12367/13312)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.887% (12484/13440)\n",
      "Train Epoch: 86 | Loss: 0.211 | Acc: 92.851% (12598/13568)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.874% (12720/13696)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.875% (12839/13824)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.876% (12958/13952)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.905% (13081/14080)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.905% (13200/14208)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.878% (13315/14336)\n",
      "Train Epoch: 86 | Loss: 0.210 | Acc: 92.886% (13435/14464)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.921% (13559/14592)\n",
      "Train Epoch: 86 | Loss: 0.209 | Acc: 92.928% (13679/14720)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.928% (13798/14848)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.935% (13918/14976)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.936% (14037/15104)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.916% (14153/15232)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.904% (14270/15360)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.904% (14389/15488)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.898% (14507/15616)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.880% (14623/15744)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.881% (14742/15872)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.888% (14862/16000)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.894% (14982/16128)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.852% (15094/16256)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.883% (15218/16384)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.848% (15331/16512)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.879% (15455/16640)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.879% (15574/16768)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.874% (15692/16896)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.869% (15810/17024)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.899% (15934/17152)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.894% (16052/17280)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.865% (16166/17408)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.860% (16284/17536)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.873% (16405/17664)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.873% (16524/17792)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.885% (16645/17920)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.852% (16758/18048)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.859% (16878/18176)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.865% (16998/18304)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.887% (17121/18432)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.904% (17243/18560)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.888% (17359/18688)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.905% (17481/18816)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.927% (17604/18944)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.927% (17723/19072)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.932% (17843/19200)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.927% (17961/19328)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.922% (18079/19456)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.953% (18204/19584)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.954% (18323/19712)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.959% (18443/19840)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.974% (18565/19968)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.959% (18681/20096)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.974% (18803/20224)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.003% (18928/20352)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.003% (19047/20480)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.983% (19162/20608)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.978% (19280/20736)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.988% (19401/20864)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.993% (19521/20992)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.964% (19634/21120)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.964% (19753/21248)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.959% (19871/21376)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.969% (19992/21504)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.992% (20116/21632)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.001% (20237/21760)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.001% (20356/21888)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 92.996% (20474/22016)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.005% (20595/22144)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.014% (20716/22272)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.013% (20835/22400)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.018% (20955/22528)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.044% (21080/22656)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.061% (21203/22784)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.069% (21324/22912)\n",
      "Train Epoch: 86 | Loss: 0.201 | Acc: 93.090% (21448/23040)\n",
      "Train Epoch: 86 | Loss: 0.201 | Acc: 93.085% (21566/23168)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.063% (21680/23296)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.054% (21797/23424)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.028% (21910/23552)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.011% (22025/23680)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.011% (22144/23808)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.019% (22265/23936)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.039% (22389/24064)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.031% (22506/24192)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.039% (22627/24320)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.014% (22740/24448)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.030% (22863/24576)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.038% (22984/24704)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.037% (23103/24832)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.033% (23221/24960)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.013% (23335/25088)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.012% (23454/25216)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.004% (23571/25344)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.004% (23690/25472)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.020% (23813/25600)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.015% (23931/25728)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.011% (24049/25856)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.023% (24171/25984)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.034% (24293/26112)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.018% (24408/26240)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.033% (24531/26368)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.040% (24652/26496)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.029% (24768/26624)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.032% (24888/26752)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.036% (25008/26880)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.028% (25125/27008)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.017% (25241/27136)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.020% (25361/27264)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.020% (25480/27392)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.027% (25601/27520)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.016% (25717/27648)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.008% (25834/27776)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.001% (25951/27904)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.012% (26073/28032)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.001% (26189/28160)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.997% (26307/28288)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.007% (26429/28416)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.014% (26550/28544)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.025% (26672/28672)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.021% (26790/28800)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.021% (26909/28928)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.010% (27025/29056)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.017% (27146/29184)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.017% (27265/29312)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.026% (27387/29440)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.040% (27510/29568)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.050% (27632/29696)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.053% (27752/29824)\n",
      "Train Epoch: 86 | Loss: 0.202 | Acc: 93.052% (27871/29952)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.045% (27988/30080)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.025% (28101/30208)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.018% (28218/30336)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.018% (28337/30464)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.021% (28457/30592)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.027% (28578/30720)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.017% (28694/30848)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.011% (28811/30976)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.011% (28930/31104)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.017% (29051/31232)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.010% (29168/31360)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.013% (29288/31488)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.019% (29409/31616)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.022% (29529/31744)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.013% (29645/31872)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.019% (29766/32000)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.025% (29887/32128)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.025% (30006/32256)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.024% (30125/32384)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.036% (30248/32512)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.045% (30370/32640)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.048% (30490/32768)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.045% (30608/32896)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.038% (30725/33024)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.041% (30845/33152)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.035% (30962/33280)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.032% (31080/33408)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.037% (31201/33536)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.040% (31321/33664)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.043% (31441/33792)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.042% (31560/33920)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.039% (31678/34048)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.036% (31796/34176)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.033% (31914/34304)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.033% (32033/34432)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.032% (32152/34560)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.021% (32267/34688)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.020% (32386/34816)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.026% (32507/34944)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.029% (32627/35072)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.023% (32744/35200)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.020% (32862/35328)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.034% (32986/35456)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.033% (33105/35584)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.036% (33225/35712)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.041% (33346/35840)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.055% (33470/35968)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.060% (33591/36096)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.060% (33710/36224)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.068% (33832/36352)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.070% (33952/36480)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.070% (34071/36608)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.061% (34187/36736)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.045% (34300/36864)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.058% (34424/36992)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.050% (34540/37120)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.052% (34660/37248)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.046% (34777/37376)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.014% (34884/37504)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.003% (34999/37632)\n",
      "Train Epoch: 86 | Loss: 0.203 | Acc: 93.003% (35118/37760)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.003% (35237/37888)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.992% (35352/38016)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.977% (35465/38144)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.992% (35590/38272)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.997% (35711/38400)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.005% (35833/38528)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.997% (35949/38656)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.005% (36071/38784)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.010% (36192/38912)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.005% (36309/39040)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.999% (36426/39168)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.009% (36549/39296)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.004% (36666/39424)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.997% (36782/39552)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.009% (36906/39680)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.006% (37024/39808)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.996% (37139/39936)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 93.001% (37260/40064)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.991% (37375/40192)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.986% (37492/40320)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.974% (37606/40448)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.969% (37723/40576)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.956% (37837/40704)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.949% (37953/40832)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.952% (38073/40960)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.954% (38193/41088)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.959% (38314/41216)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.964% (38435/41344)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.962% (38553/41472)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.974% (38677/41600)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.974% (38796/41728)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.978% (38917/41856)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.985% (39039/41984)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.985% (39158/42112)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.966% (39269/42240)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.959% (39385/42368)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.957% (39503/42496)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.957% (39622/42624)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.943% (39735/42752)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.952% (39858/42880)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.948% (39975/43008)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.955% (40097/43136)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.957% (40217/43264)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.955% (40335/43392)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.962% (40457/43520)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.971% (40580/43648)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.964% (40696/43776)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.964% (40815/43904)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.960% (40932/44032)\n",
      "Train Epoch: 86 | Loss: 0.204 | Acc: 92.962% (41052/44160)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.953% (41167/44288)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.960% (41289/44416)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.958% (41407/44544)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.953% (41524/44672)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.955% (41644/44800)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.944% (41758/44928)\n",
      "Train Epoch: 86 | Loss: 0.205 | Acc: 92.944% (41877/45056)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.933% (41991/45184)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.936% (42111/45312)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.929% (42227/45440)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.934% (42348/45568)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.925% (42463/45696)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.923% (42581/45824)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.917% (42697/45952)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.912% (42814/46080)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.910% (42932/46208)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.902% (43047/46336)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.906% (43168/46464)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.909% (43288/46592)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.907% (43406/46720)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.903% (43523/46848)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.901% (43641/46976)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.907% (43763/47104)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.914% (43885/47232)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.914% (44004/47360)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.918% (44125/47488)\n",
      "Train Epoch: 86 | Loss: 0.206 | Acc: 92.916% (44243/47616)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.914% (44361/47744)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.914% (44480/47872)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.917% (44600/48000)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.911% (44716/48128)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.909% (44834/48256)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.909% (44953/48384)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.909% (45072/48512)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.895% (45184/48640)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.905% (45308/48768)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.897% (45423/48896)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.897% (45542/49024)\n",
      "Train Epoch: 86 | Loss: 0.207 | Acc: 92.889% (45657/49152)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.886% (45774/49280)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.884% (45892/49408)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.882% (46010/49536)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.874% (46125/49664)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.870% (46242/49792)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.867% (46359/49920)\n",
      "Train Epoch: 86 | Loss: 0.208 | Acc: 92.864% (46432/50000)\n",
      "Test Epoch: 86 | Loss: 0.349 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 86 | Loss: 0.347 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 86 | Loss: 0.323 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 86 | Loss: 0.301 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 86 | Loss: 0.303 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 86 | Loss: 0.287 | Acc: 90.500% (543/600)\n",
      "Test Epoch: 86 | Loss: 0.290 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 86 | Loss: 0.295 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 86 | Loss: 0.305 | Acc: 90.222% (812/900)\n",
      "Test Epoch: 86 | Loss: 0.313 | Acc: 89.800% (898/1000)\n",
      "Test Epoch: 86 | Loss: 0.310 | Acc: 89.818% (988/1100)\n",
      "Test Epoch: 86 | Loss: 0.309 | Acc: 90.000% (1080/1200)\n",
      "Test Epoch: 86 | Loss: 0.295 | Acc: 90.462% (1176/1300)\n",
      "Test Epoch: 86 | Loss: 0.300 | Acc: 90.357% (1265/1400)\n",
      "Test Epoch: 86 | Loss: 0.295 | Acc: 90.467% (1357/1500)\n",
      "Test Epoch: 86 | Loss: 0.295 | Acc: 90.500% (1448/1600)\n",
      "Test Epoch: 86 | Loss: 0.299 | Acc: 90.588% (1540/1700)\n",
      "Test Epoch: 86 | Loss: 0.307 | Acc: 90.222% (1624/1800)\n",
      "Test Epoch: 86 | Loss: 0.307 | Acc: 90.263% (1715/1900)\n",
      "Test Epoch: 86 | Loss: 0.308 | Acc: 90.100% (1802/2000)\n",
      "Test Epoch: 86 | Loss: 0.311 | Acc: 90.095% (1892/2100)\n",
      "Test Epoch: 86 | Loss: 0.309 | Acc: 90.000% (1980/2200)\n",
      "Test Epoch: 86 | Loss: 0.310 | Acc: 89.913% (2068/2300)\n",
      "Test Epoch: 86 | Loss: 0.308 | Acc: 89.917% (2158/2400)\n",
      "Test Epoch: 86 | Loss: 0.314 | Acc: 89.800% (2245/2500)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.423% (2325/2600)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.556% (2418/2700)\n",
      "Test Epoch: 86 | Loss: 0.328 | Acc: 89.607% (2509/2800)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.517% (2596/2900)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.433% (2683/3000)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 89.290% (2768/3100)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.406% (2861/3200)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.303% (2947/3300)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.235% (3034/3400)\n",
      "Test Epoch: 86 | Loss: 0.341 | Acc: 89.086% (3118/3500)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 89.167% (3210/3600)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 89.162% (3299/3700)\n",
      "Test Epoch: 86 | Loss: 0.342 | Acc: 89.053% (3384/3800)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 89.103% (3475/3900)\n",
      "Test Epoch: 86 | Loss: 0.337 | Acc: 89.225% (3569/4000)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 89.293% (3661/4100)\n",
      "Test Epoch: 86 | Loss: 0.340 | Acc: 89.286% (3750/4200)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.395% (3844/4300)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.477% (3937/4400)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.467% (4026/4500)\n",
      "Test Epoch: 86 | Loss: 0.331 | Acc: 89.435% (4114/4600)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.489% (4206/4700)\n",
      "Test Epoch: 86 | Loss: 0.331 | Acc: 89.333% (4288/4800)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.327% (4377/4900)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.160% (4458/5000)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.118% (4545/5100)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.038% (4630/5200)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 88.981% (4716/5300)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.019% (4807/5400)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.000% (4895/5500)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 88.982% (4983/5600)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.035% (5075/5700)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.069% (5166/5800)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 88.949% (5248/5900)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 88.950% (5337/6000)\n",
      "Test Epoch: 86 | Loss: 0.339 | Acc: 88.869% (5421/6100)\n",
      "Test Epoch: 86 | Loss: 0.338 | Acc: 88.919% (5513/6200)\n",
      "Test Epoch: 86 | Loss: 0.339 | Acc: 88.937% (5603/6300)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.062% (5700/6400)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.031% (5787/6500)\n",
      "Test Epoch: 86 | Loss: 0.337 | Acc: 89.045% (5877/6600)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.134% (5972/6700)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.147% (6062/6800)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.203% (6155/6900)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.171% (6242/7000)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.197% (6333/7100)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.167% (6420/7200)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.219% (6513/7300)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.203% (6601/7400)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.160% (6687/7500)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.132% (6774/7600)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.104% (6861/7700)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.141% (6953/7800)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.152% (7043/7900)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.125% (7130/8000)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.173% (7223/8100)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.146% (7310/8200)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.157% (7400/8300)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.167% (7490/8400)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.141% (7577/8500)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.116% (7664/8600)\n",
      "Test Epoch: 86 | Loss: 0.333 | Acc: 89.115% (7753/8700)\n",
      "Test Epoch: 86 | Loss: 0.336 | Acc: 89.102% (7841/8800)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.135% (7933/8900)\n",
      "Test Epoch: 86 | Loss: 0.335 | Acc: 89.133% (8022/9000)\n",
      "Test Epoch: 86 | Loss: 0.334 | Acc: 89.165% (8114/9100)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.207% (8207/9200)\n",
      "Test Epoch: 86 | Loss: 0.332 | Acc: 89.215% (8297/9300)\n",
      "Test Epoch: 86 | Loss: 0.331 | Acc: 89.191% (8384/9400)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.211% (8475/9500)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.219% (8565/9600)\n",
      "Test Epoch: 86 | Loss: 0.329 | Acc: 89.268% (8659/9700)\n",
      "Test Epoch: 86 | Loss: 0.329 | Acc: 89.286% (8750/9800)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.263% (8837/9900)\n",
      "Test Epoch: 86 | Loss: 0.330 | Acc: 89.250% (8925/10000)\n",
      "\n",
      "Epoch: 87\n",
      "Train Epoch: 87 | Loss: 0.245 | Acc: 91.406% (117/128)\n",
      "Train Epoch: 87 | Loss: 0.222 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 87 | Loss: 0.215 | Acc: 92.969% (357/384)\n",
      "Train Epoch: 87 | Loss: 0.201 | Acc: 93.555% (479/512)\n",
      "Train Epoch: 87 | Loss: 0.203 | Acc: 93.125% (596/640)\n",
      "Train Epoch: 87 | Loss: 0.208 | Acc: 92.969% (714/768)\n",
      "Train Epoch: 87 | Loss: 0.202 | Acc: 93.192% (835/896)\n",
      "Train Epoch: 87 | Loss: 0.210 | Acc: 92.773% (950/1024)\n",
      "Train Epoch: 87 | Loss: 0.214 | Acc: 92.969% (1071/1152)\n",
      "Train Epoch: 87 | Loss: 0.210 | Acc: 92.969% (1190/1280)\n",
      "Train Epoch: 87 | Loss: 0.204 | Acc: 93.111% (1311/1408)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.229% (1432/1536)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.450% (1555/1664)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.415% (1674/1792)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.438% (1794/1920)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.750% (1920/2048)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.796% (2041/2176)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.750% (2160/2304)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.832% (2282/2432)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.789% (2401/2560)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.973% (2526/2688)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 94.070% (2649/2816)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.954% (2766/2944)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.913% (2885/3072)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.906% (3005/3200)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.870% (3124/3328)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 94.010% (3249/3456)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 94.001% (3369/3584)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 94.019% (3490/3712)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 94.036% (3611/3840)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 94.002% (3730/3968)\n",
      "Train Epoch: 87 | Loss: 0.183 | Acc: 93.994% (3850/4096)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.963% (3969/4224)\n",
      "Train Epoch: 87 | Loss: 0.183 | Acc: 93.911% (4087/4352)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 93.884% (4206/4480)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 93.837% (4324/4608)\n",
      "Train Epoch: 87 | Loss: 0.183 | Acc: 93.834% (4444/4736)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.791% (4562/4864)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.810% (4683/4992)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.770% (4801/5120)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.769% (4921/5248)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.750% (5040/5376)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 93.805% (5163/5504)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.768% (5281/5632)\n",
      "Train Epoch: 87 | Loss: 0.184 | Acc: 93.750% (5400/5760)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.716% (5518/5888)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.733% (5639/6016)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.750% (5760/6144)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.718% (5878/6272)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.703% (5997/6400)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.719% (6118/6528)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.675% (6235/6656)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.603% (6350/6784)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.634% (6472/6912)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.693% (6596/7040)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.722% (6718/7168)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.750% (6840/7296)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.750% (6960/7424)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.737% (7079/7552)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.737% (7199/7680)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.712% (7317/7808)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.750% (7440/7936)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.725% (7558/8064)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.701% (7676/8192)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.726% (7798/8320)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.691% (7915/8448)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.715% (8037/8576)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.716% (8157/8704)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.750% (8280/8832)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.728% (8398/8960)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.717% (8517/9088)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.750% (8640/9216)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.771% (8762/9344)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.729% (8878/9472)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.719% (8997/9600)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.678% (9113/9728)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.679% (9233/9856)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.650% (9350/9984)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.651% (9470/10112)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.633% (9588/10240)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.663% (9711/10368)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.655% (9830/10496)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.703% (9955/10624)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.713% (10076/10752)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.732% (10198/10880)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.759% (10321/11008)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.777% (10443/11136)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.794% (10565/11264)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.794% (10685/11392)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.819% (10808/11520)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.802% (10926/11648)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.818% (11048/11776)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.834% (11170/11904)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.850% (11292/12032)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.865% (11414/12160)\n",
      "Train Epoch: 87 | Loss: 0.185 | Acc: 93.880% (11536/12288)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.855% (11653/12416)\n",
      "Train Epoch: 87 | Loss: 0.186 | Acc: 93.838% (11771/12544)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.805% (11887/12672)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.797% (12006/12800)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.773% (12123/12928)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.796% (12246/13056)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.735% (12358/13184)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.720% (12476/13312)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.720% (12596/13440)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.728% (12717/13568)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.692% (12832/13696)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.692% (12952/13824)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.671% (13069/13952)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.643% (13185/14080)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.651% (13306/14208)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.666% (13428/14336)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.653% (13546/14464)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.640% (13664/14592)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.668% (13788/14720)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.696% (13912/14848)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.677% (14029/14976)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.664% (14147/15104)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.625% (14261/15232)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.613% (14379/15360)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.589% (14495/15488)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.558% (14610/15616)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.559% (14730/15744)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.592% (14855/15872)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.562% (14970/16000)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.558% (15089/16128)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.559% (15209/16256)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.567% (15330/16384)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.574% (15451/16512)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.588% (15573/16640)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.583% (15692/16768)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.572% (15810/16896)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.562% (15928/17024)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.558% (16047/17152)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.536% (16163/17280)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.520% (16280/17408)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.516% (16399/17536)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.490% (16514/17664)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.491% (16634/17792)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.488% (16753/17920)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.495% (16874/18048)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.502% (16995/18176)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.482% (17111/18304)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.506% (17235/18432)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.513% (17356/18560)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.493% (17472/18688)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.495% (17592/18816)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.481% (17709/18944)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.488% (17830/19072)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.500% (17952/19200)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.522% (18076/19328)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.514% (18194/19456)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.510% (18313/19584)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.512% (18433/19712)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.508% (18552/19840)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.470% (18664/19968)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.486% (18787/20096)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.493% (18908/20224)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.499% (19029/20352)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.501% (19149/20480)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.507% (19270/20608)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.519% (19392/20736)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.515% (19511/20864)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.540% (19636/20992)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.551% (19758/21120)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.566% (19881/21248)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.558% (19999/21376)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.555% (20118/21504)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.560% (20239/21632)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.571% (20361/21760)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.567% (20480/21888)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.546% (20595/22016)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.529% (20711/22144)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.539% (20833/22272)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.531% (20951/22400)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.537% (21072/22528)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.543% (21193/22656)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.535% (21311/22784)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.545% (21433/22912)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.537% (21551/23040)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.521% (21667/23168)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.527% (21788/23296)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.541% (21911/23424)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.533% (22029/23552)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.552% (22153/23680)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.553% (22273/23808)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.554% (22393/23936)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.567% (22516/24064)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.572% (22637/24192)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.594% (22762/24320)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.599% (22883/24448)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.608% (23005/24576)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.616% (23127/24704)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.637% (23252/24832)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.646% (23374/24960)\n",
      "Train Epoch: 87 | Loss: 0.187 | Acc: 93.662% (23498/25088)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.647% (23614/25216)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.647% (23734/25344)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.644% (23853/25472)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.637% (23971/25600)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.645% (24093/25728)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.642% (24212/25856)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.642% (24332/25984)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.654% (24455/26112)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.632% (24569/26240)\n",
      "Train Epoch: 87 | Loss: 0.188 | Acc: 93.636% (24690/26368)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.618% (24805/26496)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.600% (24920/26624)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.593% (25038/26752)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.590% (25157/26880)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.591% (25277/27008)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.595% (25398/27136)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.611% (25522/27264)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.608% (25641/27392)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.605% (25760/27520)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.598% (25878/27648)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.574% (25991/27776)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.564% (26108/27904)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.572% (26230/28032)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.565% (26348/28160)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.570% (26469/28288)\n",
      "Train Epoch: 87 | Loss: 0.189 | Acc: 93.574% (26590/28416)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.561% (26706/28544)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.558% (26825/28672)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.559% (26945/28800)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.543% (27060/28928)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.540% (27179/29056)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.558% (27304/29184)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.535% (27417/29312)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.546% (27540/29440)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.530% (27655/29568)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.531% (27775/29696)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.532% (27895/29824)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.540% (28017/29952)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.544% (28138/30080)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.535% (28255/30208)\n",
      "Train Epoch: 87 | Loss: 0.190 | Acc: 93.526% (28372/30336)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.514% (28488/30464)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.508% (28606/30592)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.496% (28722/30720)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.494% (28841/30848)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.482% (28957/30976)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.490% (29079/31104)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.487% (29198/31232)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.495% (29320/31360)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.483% (29436/31488)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.494% (29559/31616)\n",
      "Train Epoch: 87 | Loss: 0.191 | Acc: 93.492% (29678/31744)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.477% (29793/31872)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.478% (29913/32000)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.476% (30032/32128)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.477% (30152/32256)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.478% (30272/32384)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.470% (30389/32512)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.471% (30509/32640)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.466% (30627/32768)\n",
      "Train Epoch: 87 | Loss: 0.192 | Acc: 93.449% (30741/32896)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.441% (30858/33024)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.430% (30974/33152)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.416% (31089/33280)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.412% (31207/33408)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.413% (31327/33536)\n",
      "Train Epoch: 87 | Loss: 0.193 | Acc: 93.417% (31448/33664)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.389% (31558/33792)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.367% (31670/33920)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.377% (31793/34048)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.364% (31908/34176)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.365% (32028/34304)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.375% (32151/34432)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.380% (32272/34560)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.381% (32392/34688)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.379% (32511/34816)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.361% (32624/34944)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.359% (32743/35072)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.347% (32858/35200)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.345% (32977/35328)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.335% (33093/35456)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.331% (33211/35584)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.324% (33328/35712)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.320% (33446/35840)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.327% (33568/35968)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.321% (33685/36096)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.317% (33803/36224)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.324% (33925/36352)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.322% (34044/36480)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.324% (34164/36608)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.314% (34280/36736)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.305% (34396/36864)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.299% (34513/36992)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.303% (34634/37120)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.307% (34755/37248)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.303% (34873/37376)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.310% (34995/37504)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.312% (35115/37632)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.324% (35239/37760)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.330% (35361/37888)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.342% (35485/38016)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.341% (35604/38144)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.329% (35719/38272)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.328% (35838/38400)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.330% (35958/38528)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.326% (36076/38656)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.317% (36192/38784)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.316% (36311/38912)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.315% (36430/39040)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.316% (36550/39168)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.320% (36671/39296)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.321% (36791/39424)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.325% (36912/39552)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.324% (37031/39680)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.305% (37143/39808)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.302% (37261/39936)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.301% (37380/40064)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.295% (37497/40192)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.301% (37619/40320)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.315% (37744/40448)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.314% (37863/40576)\n",
      "Train Epoch: 87 | Loss: 0.194 | Acc: 93.315% (37983/40704)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.319% (38104/40832)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.323% (38225/40960)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.322% (38344/41088)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.318% (38462/41216)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.310% (38578/41344)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.311% (38698/41472)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.308% (38816/41600)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.304% (38934/41728)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.313% (39057/41856)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.302% (39172/41984)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.301% (39291/42112)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.303% (39411/42240)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.309% (39533/42368)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.293% (39646/42496)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.290% (39764/42624)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.289% (39883/42752)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.298% (40006/42880)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.290% (40122/43008)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.291% (40242/43136)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.288% (40360/43264)\n",
      "Train Epoch: 87 | Loss: 0.195 | Acc: 93.284% (40478/43392)\n",
      "Train Epoch: 87 | Loss: 0.196 | Acc: 93.279% (40595/43520)\n",
      "Train Epoch: 87 | Loss: 0.196 | Acc: 93.273% (40712/43648)\n",
      "Train Epoch: 87 | Loss: 0.196 | Acc: 93.273% (40831/43776)\n",
      "Train Epoch: 87 | Loss: 0.196 | Acc: 93.247% (40939/43904)\n",
      "Train Epoch: 87 | Loss: 0.196 | Acc: 93.248% (41059/44032)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.243% (41176/44160)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.242% (41295/44288)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.237% (41412/44416)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.247% (41536/44544)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.237% (41651/44672)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.232% (41768/44800)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.240% (41891/44928)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.235% (42008/45056)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.239% (42129/45184)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.238% (42248/45312)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.255% (42375/45440)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.247% (42491/45568)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.247% (42610/45696)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.252% (42732/45824)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.260% (42855/45952)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.257% (42973/46080)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.267% (43097/46208)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.273% (43219/46336)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.272% (43338/46464)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.267% (43455/46592)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.273% (43577/46720)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.263% (43692/46848)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.260% (43810/46976)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.260% (43929/47104)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.259% (44048/47232)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.258% (44167/47360)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.257% (44286/47488)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.254% (44404/47616)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.258% (44525/47744)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.270% (44650/47872)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.265% (44767/48000)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.268% (44888/48128)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.267% (45007/48256)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.256% (45121/48384)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.243% (45234/48512)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.257% (45360/48640)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.252% (45477/48768)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.255% (45598/48896)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.250% (45715/49024)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.237% (45828/49152)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.233% (45945/49280)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.236% (46066/49408)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.241% (46188/49536)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.243% (46308/49664)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.244% (46428/49792)\n",
      "Train Epoch: 87 | Loss: 0.197 | Acc: 93.247% (46549/49920)\n",
      "Train Epoch: 87 | Loss: 0.198 | Acc: 93.242% (46621/50000)\n",
      "Test Epoch: 87 | Loss: 0.343 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 87 | Loss: 0.343 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 87 | Loss: 0.354 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 87 | Loss: 0.348 | Acc: 90.250% (361/400)\n",
      "Test Epoch: 87 | Loss: 0.331 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 87 | Loss: 0.305 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 87 | Loss: 0.305 | Acc: 91.286% (639/700)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.556% (815/900)\n",
      "Test Epoch: 87 | Loss: 0.315 | Acc: 90.900% (909/1000)\n",
      "Test Epoch: 87 | Loss: 0.322 | Acc: 90.455% (995/1100)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.333% (1084/1200)\n",
      "Test Epoch: 87 | Loss: 0.321 | Acc: 90.462% (1176/1300)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.571% (1268/1400)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.533% (1358/1500)\n",
      "Test Epoch: 87 | Loss: 0.313 | Acc: 90.625% (1450/1600)\n",
      "Test Epoch: 87 | Loss: 0.317 | Acc: 90.824% (1544/1700)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.778% (1634/1800)\n",
      "Test Epoch: 87 | Loss: 0.314 | Acc: 90.895% (1727/1900)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.800% (1816/2000)\n",
      "Test Epoch: 87 | Loss: 0.320 | Acc: 90.810% (1907/2100)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.909% (2000/2200)\n",
      "Test Epoch: 87 | Loss: 0.319 | Acc: 90.783% (2088/2300)\n",
      "Test Epoch: 87 | Loss: 0.316 | Acc: 90.833% (2180/2400)\n",
      "Test Epoch: 87 | Loss: 0.318 | Acc: 90.800% (2270/2500)\n",
      "Test Epoch: 87 | Loss: 0.328 | Acc: 90.538% (2354/2600)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.593% (2446/2700)\n",
      "Test Epoch: 87 | Loss: 0.323 | Acc: 90.607% (2537/2800)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.517% (2625/2900)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.467% (2714/3000)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.258% (2798/3100)\n",
      "Test Epoch: 87 | Loss: 0.328 | Acc: 90.281% (2889/3200)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.364% (2982/3300)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.353% (3072/3400)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.343% (3162/3500)\n",
      "Test Epoch: 87 | Loss: 0.329 | Acc: 90.333% (3252/3600)\n",
      "Test Epoch: 87 | Loss: 0.332 | Acc: 90.324% (3342/3700)\n",
      "Test Epoch: 87 | Loss: 0.334 | Acc: 90.289% (3431/3800)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.308% (3522/3900)\n",
      "Test Epoch: 87 | Loss: 0.334 | Acc: 90.325% (3613/4000)\n",
      "Test Epoch: 87 | Loss: 0.338 | Acc: 90.220% (3699/4100)\n",
      "Test Epoch: 87 | Loss: 0.336 | Acc: 90.238% (3790/4200)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.279% (3882/4300)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.341% (3975/4400)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.422% (4069/4500)\n",
      "Test Epoch: 87 | Loss: 0.332 | Acc: 90.348% (4156/4600)\n",
      "Test Epoch: 87 | Loss: 0.331 | Acc: 90.383% (4248/4700)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.333% (4336/4800)\n",
      "Test Epoch: 87 | Loss: 0.329 | Acc: 90.429% (4431/4900)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.400% (4520/5000)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.471% (4614/5100)\n",
      "Test Epoch: 87 | Loss: 0.331 | Acc: 90.481% (4705/5200)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.509% (4797/5300)\n",
      "Test Epoch: 87 | Loss: 0.329 | Acc: 90.556% (4890/5400)\n",
      "Test Epoch: 87 | Loss: 0.328 | Acc: 90.545% (4980/5500)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.536% (5070/5600)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.579% (5163/5700)\n",
      "Test Epoch: 87 | Loss: 0.329 | Acc: 90.534% (5251/5800)\n",
      "Test Epoch: 87 | Loss: 0.332 | Acc: 90.475% (5338/5900)\n",
      "Test Epoch: 87 | Loss: 0.331 | Acc: 90.467% (5428/6000)\n",
      "Test Epoch: 87 | Loss: 0.333 | Acc: 90.393% (5514/6100)\n",
      "Test Epoch: 87 | Loss: 0.334 | Acc: 90.371% (5603/6200)\n",
      "Test Epoch: 87 | Loss: 0.334 | Acc: 90.349% (5692/6300)\n",
      "Test Epoch: 87 | Loss: 0.331 | Acc: 90.438% (5788/6400)\n",
      "Test Epoch: 87 | Loss: 0.330 | Acc: 90.431% (5878/6500)\n",
      "Test Epoch: 87 | Loss: 0.328 | Acc: 90.515% (5974/6600)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.567% (6068/6700)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.559% (6158/6800)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.609% (6252/6900)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.571% (6340/7000)\n",
      "Test Epoch: 87 | Loss: 0.329 | Acc: 90.535% (6428/7100)\n",
      "Test Epoch: 87 | Loss: 0.328 | Acc: 90.500% (6516/7200)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.534% (6609/7300)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.568% (6702/7400)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.533% (6790/7500)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.553% (6882/7600)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.545% (6972/7700)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.538% (7062/7800)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.544% (7153/7900)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.525% (7242/8000)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.580% (7337/8100)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.585% (7428/8200)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.518% (7513/8300)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.488% (7601/8400)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.482% (7691/8500)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.442% (7778/8600)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.471% (7871/8700)\n",
      "Test Epoch: 87 | Loss: 0.327 | Acc: 90.466% (7961/8800)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.506% (8055/8900)\n",
      "Test Epoch: 87 | Loss: 0.326 | Acc: 90.511% (8146/9000)\n",
      "Test Epoch: 87 | Loss: 0.325 | Acc: 90.527% (8238/9100)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.565% (8332/9200)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.548% (8421/9300)\n",
      "Test Epoch: 87 | Loss: 0.324 | Acc: 90.564% (8513/9400)\n",
      "Test Epoch: 87 | Loss: 0.323 | Acc: 90.589% (8606/9500)\n",
      "Test Epoch: 87 | Loss: 0.323 | Acc: 90.562% (8694/9600)\n",
      "Test Epoch: 87 | Loss: 0.322 | Acc: 90.608% (8789/9700)\n",
      "Test Epoch: 87 | Loss: 0.321 | Acc: 90.622% (8881/9800)\n",
      "Test Epoch: 87 | Loss: 0.322 | Acc: 90.596% (8969/9900)\n",
      "Test Epoch: 87 | Loss: 0.321 | Acc: 90.610% (9061/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 88\n",
      "Train Epoch: 88 | Loss: 0.199 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 88 | Loss: 0.138 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 94.010% (361/384)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 94.336% (483/512)\n",
      "Train Epoch: 88 | Loss: 0.170 | Acc: 94.688% (606/640)\n",
      "Train Epoch: 88 | Loss: 0.165 | Acc: 94.401% (725/768)\n",
      "Train Epoch: 88 | Loss: 0.162 | Acc: 94.531% (847/896)\n",
      "Train Epoch: 88 | Loss: 0.164 | Acc: 94.434% (967/1024)\n",
      "Train Epoch: 88 | Loss: 0.168 | Acc: 94.184% (1085/1152)\n",
      "Train Epoch: 88 | Loss: 0.162 | Acc: 94.453% (1209/1280)\n",
      "Train Epoch: 88 | Loss: 0.164 | Acc: 94.531% (1331/1408)\n",
      "Train Epoch: 88 | Loss: 0.163 | Acc: 94.531% (1452/1536)\n",
      "Train Epoch: 88 | Loss: 0.170 | Acc: 94.411% (1571/1664)\n",
      "Train Epoch: 88 | Loss: 0.171 | Acc: 94.364% (1691/1792)\n",
      "Train Epoch: 88 | Loss: 0.175 | Acc: 94.167% (1808/1920)\n",
      "Train Epoch: 88 | Loss: 0.171 | Acc: 94.287% (1931/2048)\n",
      "Train Epoch: 88 | Loss: 0.170 | Acc: 94.301% (2052/2176)\n",
      "Train Epoch: 88 | Loss: 0.168 | Acc: 94.314% (2173/2304)\n",
      "Train Epoch: 88 | Loss: 0.170 | Acc: 94.367% (2295/2432)\n",
      "Train Epoch: 88 | Loss: 0.172 | Acc: 94.336% (2415/2560)\n",
      "Train Epoch: 88 | Loss: 0.175 | Acc: 94.196% (2532/2688)\n",
      "Train Epoch: 88 | Loss: 0.177 | Acc: 94.176% (2652/2816)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 94.056% (2769/2944)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 94.010% (2888/3072)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.969% (3007/3200)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 94.020% (3129/3328)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.895% (3245/3456)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.750% (3360/3584)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.831% (3483/3712)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.932% (3607/3840)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.977% (3729/3968)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.945% (3848/4096)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.892% (3966/4224)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.842% (4084/4352)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.839% (4204/4480)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.793% (4322/4608)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.750% (4440/4736)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.812% (4563/4864)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.790% (4682/4992)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.691% (4797/5120)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.750% (4920/5248)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.769% (5041/5376)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.768% (5161/5504)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.786% (5282/5632)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.802% (5403/5760)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.818% (5524/5888)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.866% (5647/6016)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.848% (5766/6144)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.878% (5888/6272)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.875% (6008/6400)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.919% (6131/6528)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.885% (6249/6656)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.824% (6365/6784)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.808% (6484/6912)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.821% (6605/7040)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.848% (6727/7168)\n",
      "Train Epoch: 88 | Loss: 0.180 | Acc: 93.928% (6853/7296)\n",
      "Train Epoch: 88 | Loss: 0.180 | Acc: 93.952% (6975/7424)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.909% (7092/7552)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.867% (7209/7680)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.891% (7331/7808)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.901% (7452/7936)\n",
      "Train Epoch: 88 | Loss: 0.180 | Acc: 93.911% (7573/8064)\n",
      "Train Epoch: 88 | Loss: 0.180 | Acc: 93.909% (7693/8192)\n",
      "Train Epoch: 88 | Loss: 0.180 | Acc: 93.918% (7814/8320)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.904% (7933/8448)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.855% (8049/8576)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.796% (8164/8704)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.795% (8284/8832)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.772% (8402/8960)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.772% (8522/9088)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.728% (8638/9216)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.729% (8758/9344)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.750% (8880/9472)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.719% (8997/9600)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.688% (9114/9728)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.659% (9231/9856)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.660% (9351/9984)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.701% (9475/10112)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.672% (9592/10240)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.702% (9715/10368)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.731% (9838/10496)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.712% (9956/10624)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.703% (10075/10752)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.722% (10197/10880)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.732% (10318/11008)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.714% (10436/11136)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.732% (10558/11264)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.697% (10674/11392)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.681% (10792/11520)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.698% (10914/11648)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.648% (11028/11776)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.641% (11147/11904)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.667% (11270/12032)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.643% (11387/12160)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.652% (11508/12288)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.637% (11626/12416)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.662% (11749/12544)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.679% (11871/12672)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.680% (11991/12800)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.696% (12113/12928)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.673% (12230/13056)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.667% (12349/13184)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.660% (12468/13312)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.624% (12583/13440)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.639% (12705/13568)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.633% (12824/13696)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.641% (12945/13824)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.678% (13070/13952)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.693% (13192/14080)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.701% (13313/14208)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.729% (13437/14336)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.722% (13556/14464)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.709% (13674/14592)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.743% (13799/14720)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.737% (13918/14848)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.763% (14042/14976)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.757% (14161/15104)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.770% (14283/15232)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.776% (14404/15360)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.789% (14526/15488)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.801% (14648/15616)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.801% (14768/15744)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.794% (14887/15872)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.812% (15010/16000)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.806% (15129/16128)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.793% (15247/16256)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.793% (15367/16384)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.805% (15489/16512)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.804% (15609/16640)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.798% (15728/16768)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.797% (15848/16896)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.791% (15967/17024)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.797% (16088/17152)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.802% (16209/17280)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.807% (16330/17408)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.813% (16451/17536)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.807% (16570/17664)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.806% (16690/17792)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.817% (16812/17920)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.839% (16936/18048)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.855% (17059/18176)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.854% (17179/18304)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.853% (17299/18432)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.863% (17421/18560)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.868% (17542/18688)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.872% (17663/18816)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.845% (17778/18944)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.844% (17898/19072)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.833% (18016/19200)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.833% (18136/19328)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.807% (18251/19456)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.806% (18371/19584)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.826% (18495/19712)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.816% (18613/19840)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.820% (18734/19968)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.825% (18855/20096)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.829% (18976/20224)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.829% (19096/20352)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.833% (19217/20480)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.823% (19335/20608)\n",
      "Train Epoch: 88 | Loss: 0.181 | Acc: 93.832% (19457/20736)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.831% (19577/20864)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.798% (19690/20992)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.774% (19805/21120)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.759% (19922/21248)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.759% (20042/21376)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.773% (20165/21504)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.787% (20288/21632)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.796% (20410/21760)\n",
      "Train Epoch: 88 | Loss: 0.182 | Acc: 93.796% (20530/21888)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.777% (20646/22016)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.773% (20765/22144)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.777% (20886/22272)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.781% (21007/22400)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.781% (21127/22528)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.781% (21247/22656)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.759% (21362/22784)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.776% (21486/22912)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.772% (21605/23040)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.789% (21729/23168)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.784% (21848/23296)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.771% (21965/23424)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.784% (22088/23552)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.788% (22209/23680)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.800% (22332/23808)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.792% (22450/23936)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.792% (22570/24064)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.791% (22690/24192)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.779% (22807/24320)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.775% (22926/24448)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.783% (23048/24576)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.786% (23169/24704)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.782% (23288/24832)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.782% (23408/24960)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.774% (23526/25088)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.770% (23645/25216)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.770% (23765/25344)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.774% (23886/25472)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.754% (24001/25600)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.750% (24120/25728)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.742% (24238/25856)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.750% (24360/25984)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.765% (24484/26112)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.777% (24607/26240)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.773% (24726/26368)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.769% (24845/26496)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.784% (24969/26624)\n",
      "Train Epoch: 88 | Loss: 0.183 | Acc: 93.799% (25093/26752)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.787% (25210/26880)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.772% (25326/27008)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.761% (25443/27136)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.761% (25563/27264)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.761% (25683/27392)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.750% (25800/27520)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.757% (25922/27648)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.764% (26044/27776)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.757% (26162/27904)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.736% (26276/28032)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.743% (26398/28160)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.739% (26517/28288)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.743% (26638/28416)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.750% (26760/28544)\n",
      "Train Epoch: 88 | Loss: 0.184 | Acc: 93.740% (26877/28672)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.722% (26992/28800)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.715% (27110/28928)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.705% (27227/29056)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.702% (27346/29184)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.692% (27463/29312)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.692% (27583/29440)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.689% (27702/29568)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.686% (27821/29696)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.683% (27940/29824)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.683% (28060/29952)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.684% (28180/30080)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.687% (28301/30208)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.697% (28424/30336)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.704% (28546/30464)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.711% (28668/30592)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.711% (28788/30720)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.701% (28905/30848)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.705% (29026/30976)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.695% (29143/31104)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.696% (29263/31232)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.696% (29383/31360)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.699% (29504/31488)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.715% (29629/31616)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.728% (29753/31744)\n",
      "Train Epoch: 88 | Loss: 0.185 | Acc: 93.728% (29873/31872)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.709% (29987/32000)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.716% (30109/32128)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.700% (30224/32256)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.704% (30345/32384)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.701% (30464/32512)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.707% (30586/32640)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.704% (30705/32768)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.704% (30825/32896)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.708% (30946/33024)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.717% (31069/33152)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.720% (31190/33280)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.699% (31303/33408)\n",
      "Train Epoch: 88 | Loss: 0.186 | Acc: 93.699% (31423/33536)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.694% (31541/33664)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.694% (31661/33792)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.694% (31781/33920)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.694% (31901/34048)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.694% (32021/34176)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.700% (32143/34304)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.680% (32256/34432)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.686% (32378/34560)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.666% (32491/34688)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.661% (32609/34816)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.650% (32725/34944)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.645% (32843/35072)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.648% (32964/35200)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.637% (33080/35328)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.632% (33198/35456)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.629% (33317/35584)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.632% (33438/35712)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.630% (33557/35840)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.633% (33678/35968)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.636% (33799/36096)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.645% (33922/36224)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.651% (34044/36352)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.651% (34164/36480)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.646% (34282/36608)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.647% (34402/36736)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.631% (34516/36864)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.639% (34639/36992)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.648% (34762/37120)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.648% (34882/37248)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.646% (35001/37376)\n",
      "Train Epoch: 88 | Loss: 0.187 | Acc: 93.654% (35124/37504)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.630% (35235/37632)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.628% (35354/37760)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.634% (35476/37888)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.637% (35597/38016)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.624% (35712/38144)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.617% (35829/38272)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.625% (35952/38400)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.620% (36070/38528)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.626% (36192/38656)\n",
      "Train Epoch: 88 | Loss: 0.188 | Acc: 93.613% (36307/38784)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.606% (36424/38912)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.596% (36540/39040)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.602% (36662/39168)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.600% (36781/39296)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.593% (36898/39424)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.565% (37007/39552)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.574% (37130/39680)\n",
      "Train Epoch: 88 | Loss: 0.189 | Acc: 93.567% (37247/39808)\n",
      "Train Epoch: 88 | Loss: 0.190 | Acc: 93.562% (37365/39936)\n",
      "Train Epoch: 88 | Loss: 0.190 | Acc: 93.565% (37486/40064)\n",
      "Train Epoch: 88 | Loss: 0.190 | Acc: 93.563% (37605/40192)\n",
      "Train Epoch: 88 | Loss: 0.190 | Acc: 93.559% (37723/40320)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.537% (37834/40448)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.545% (37957/40576)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.526% (38069/40704)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.527% (38189/40832)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.521% (38306/40960)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.519% (38425/41088)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.522% (38546/41216)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.530% (38669/41344)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.523% (38786/41472)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.524% (38906/41600)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.520% (39024/41728)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.523% (39145/41856)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.517% (39262/41984)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.510% (39379/42112)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.511% (39499/42240)\n",
      "Train Epoch: 88 | Loss: 0.191 | Acc: 93.509% (39618/42368)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.496% (39732/42496)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.492% (39850/42624)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.488% (39968/42752)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.477% (40083/42880)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.473% (40201/43008)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.476% (40322/43136)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.482% (40444/43264)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.485% (40565/43392)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.500% (40691/43520)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.500% (40811/43648)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.492% (40927/43776)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.504% (41052/43904)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.516% (41177/44032)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.517% (41297/44160)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.513% (41415/44288)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.507% (41532/44416)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.505% (41651/44544)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.499% (41768/44672)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.491% (41884/44800)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.481% (41999/44928)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.475% (42116/45056)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.480% (42238/45184)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.483% (42359/45312)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.479% (42477/45440)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.469% (42592/45568)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.472% (42713/45696)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.473% (42833/45824)\n",
      "Train Epoch: 88 | Loss: 0.192 | Acc: 93.465% (42949/45952)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.461% (43067/46080)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.460% (43186/46208)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.452% (43302/46336)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.449% (43420/46464)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.445% (43538/46592)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.438% (43654/46720)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.440% (43775/46848)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.437% (43893/46976)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.438% (44013/47104)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.449% (44138/47232)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.450% (44258/47360)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.436% (44371/47488)\n",
      "Train Epoch: 88 | Loss: 0.193 | Acc: 93.435% (44490/47616)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.425% (44605/47744)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.432% (44728/47872)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.421% (44842/48000)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.415% (44959/48128)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.418% (45080/48256)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.417% (45199/48384)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.426% (45323/48512)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.419% (45439/48640)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.410% (45554/48768)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.404% (45671/48896)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.397% (45787/49024)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.390% (45903/49152)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.385% (46020/49280)\n",
      "Train Epoch: 88 | Loss: 0.195 | Acc: 93.382% (46138/49408)\n",
      "Train Epoch: 88 | Loss: 0.194 | Acc: 93.381% (46257/49536)\n",
      "Train Epoch: 88 | Loss: 0.195 | Acc: 93.373% (46373/49664)\n",
      "Train Epoch: 88 | Loss: 0.195 | Acc: 93.368% (46490/49792)\n",
      "Train Epoch: 88 | Loss: 0.195 | Acc: 93.365% (46608/49920)\n",
      "Train Epoch: 88 | Loss: 0.195 | Acc: 93.358% (46679/50000)\n",
      "Test Epoch: 88 | Loss: 0.438 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 88 | Loss: 0.350 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 88 | Loss: 0.353 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 88 | Loss: 0.341 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 88 | Loss: 0.311 | Acc: 91.400% (457/500)\n",
      "Test Epoch: 88 | Loss: 0.296 | Acc: 91.667% (550/600)\n",
      "Test Epoch: 88 | Loss: 0.281 | Acc: 91.857% (643/700)\n",
      "Test Epoch: 88 | Loss: 0.297 | Acc: 91.375% (731/800)\n",
      "Test Epoch: 88 | Loss: 0.309 | Acc: 91.000% (819/900)\n",
      "Test Epoch: 88 | Loss: 0.324 | Acc: 90.700% (907/1000)\n",
      "Test Epoch: 88 | Loss: 0.328 | Acc: 90.455% (995/1100)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.583% (1087/1200)\n",
      "Test Epoch: 88 | Loss: 0.320 | Acc: 90.923% (1182/1300)\n",
      "Test Epoch: 88 | Loss: 0.313 | Acc: 91.143% (1276/1400)\n",
      "Test Epoch: 88 | Loss: 0.311 | Acc: 91.000% (1365/1500)\n",
      "Test Epoch: 88 | Loss: 0.307 | Acc: 90.938% (1455/1600)\n",
      "Test Epoch: 88 | Loss: 0.308 | Acc: 90.824% (1544/1700)\n",
      "Test Epoch: 88 | Loss: 0.310 | Acc: 90.667% (1632/1800)\n",
      "Test Epoch: 88 | Loss: 0.308 | Acc: 90.684% (1723/1900)\n",
      "Test Epoch: 88 | Loss: 0.309 | Acc: 90.750% (1815/2000)\n",
      "Test Epoch: 88 | Loss: 0.311 | Acc: 90.619% (1903/2100)\n",
      "Test Epoch: 88 | Loss: 0.307 | Acc: 90.591% (1993/2200)\n",
      "Test Epoch: 88 | Loss: 0.314 | Acc: 90.522% (2082/2300)\n",
      "Test Epoch: 88 | Loss: 0.315 | Acc: 90.500% (2172/2400)\n",
      "Test Epoch: 88 | Loss: 0.318 | Acc: 90.440% (2261/2500)\n",
      "Test Epoch: 88 | Loss: 0.331 | Acc: 90.269% (2347/2600)\n",
      "Test Epoch: 88 | Loss: 0.328 | Acc: 90.407% (2441/2700)\n",
      "Test Epoch: 88 | Loss: 0.332 | Acc: 90.393% (2531/2800)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.276% (2618/2900)\n",
      "Test Epoch: 88 | Loss: 0.337 | Acc: 90.200% (2706/3000)\n",
      "Test Epoch: 88 | Loss: 0.338 | Acc: 90.129% (2794/3100)\n",
      "Test Epoch: 88 | Loss: 0.336 | Acc: 90.188% (2886/3200)\n",
      "Test Epoch: 88 | Loss: 0.336 | Acc: 90.212% (2977/3300)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.235% (3068/3400)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.171% (3156/3500)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.222% (3248/3600)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 90.270% (3340/3700)\n",
      "Test Epoch: 88 | Loss: 0.338 | Acc: 90.158% (3426/3800)\n",
      "Test Epoch: 88 | Loss: 0.336 | Acc: 90.179% (3517/3900)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.175% (3607/4000)\n",
      "Test Epoch: 88 | Loss: 0.337 | Acc: 90.122% (3695/4100)\n",
      "Test Epoch: 88 | Loss: 0.337 | Acc: 90.143% (3786/4200)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.163% (3877/4300)\n",
      "Test Epoch: 88 | Loss: 0.333 | Acc: 90.227% (3970/4400)\n",
      "Test Epoch: 88 | Loss: 0.332 | Acc: 90.244% (4061/4500)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 90.109% (4145/4600)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 90.106% (4235/4700)\n",
      "Test Epoch: 88 | Loss: 0.336 | Acc: 90.021% (4321/4800)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 90.041% (4412/4900)\n",
      "Test Epoch: 88 | Loss: 0.338 | Acc: 89.940% (4497/5000)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.020% (4591/5100)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 89.981% (4679/5200)\n",
      "Test Epoch: 88 | Loss: 0.336 | Acc: 89.943% (4767/5300)\n",
      "Test Epoch: 88 | Loss: 0.333 | Acc: 90.037% (4862/5400)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 90.000% (4950/5500)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 89.964% (5038/5600)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 89.982% (5129/5700)\n",
      "Test Epoch: 88 | Loss: 0.332 | Acc: 89.966% (5218/5800)\n",
      "Test Epoch: 88 | Loss: 0.337 | Acc: 89.881% (5303/5900)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 89.950% (5397/6000)\n",
      "Test Epoch: 88 | Loss: 0.335 | Acc: 89.967% (5488/6100)\n",
      "Test Epoch: 88 | Loss: 0.334 | Acc: 90.000% (5580/6200)\n",
      "Test Epoch: 88 | Loss: 0.332 | Acc: 90.032% (5672/6300)\n",
      "Test Epoch: 88 | Loss: 0.330 | Acc: 90.109% (5767/6400)\n",
      "Test Epoch: 88 | Loss: 0.329 | Acc: 90.123% (5858/6500)\n",
      "Test Epoch: 88 | Loss: 0.327 | Acc: 90.136% (5949/6600)\n",
      "Test Epoch: 88 | Loss: 0.325 | Acc: 90.149% (6040/6700)\n",
      "Test Epoch: 88 | Loss: 0.327 | Acc: 90.147% (6130/6800)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.174% (6222/6900)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.143% (6310/7000)\n",
      "Test Epoch: 88 | Loss: 0.328 | Acc: 90.155% (6401/7100)\n",
      "Test Epoch: 88 | Loss: 0.329 | Acc: 90.125% (6489/7200)\n",
      "Test Epoch: 88 | Loss: 0.328 | Acc: 90.178% (6583/7300)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.230% (6677/7400)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.240% (6768/7500)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.250% (6859/7600)\n",
      "Test Epoch: 88 | Loss: 0.326 | Acc: 90.234% (6948/7700)\n",
      "Test Epoch: 88 | Loss: 0.324 | Acc: 90.269% (7041/7800)\n",
      "Test Epoch: 88 | Loss: 0.325 | Acc: 90.253% (7130/7900)\n",
      "Test Epoch: 88 | Loss: 0.325 | Acc: 90.237% (7219/8000)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.296% (7314/8100)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.244% (7400/8200)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.193% (7486/8300)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.226% (7579/8400)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.235% (7670/8500)\n",
      "Test Epoch: 88 | Loss: 0.324 | Acc: 90.186% (7756/8600)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.218% (7849/8700)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.205% (7938/8800)\n",
      "Test Epoch: 88 | Loss: 0.324 | Acc: 90.202% (8028/8900)\n",
      "Test Epoch: 88 | Loss: 0.324 | Acc: 90.156% (8114/9000)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.165% (8205/9100)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.207% (8299/9200)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.204% (8389/9300)\n",
      "Test Epoch: 88 | Loss: 0.323 | Acc: 90.234% (8482/9400)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.242% (8573/9500)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.229% (8662/9600)\n",
      "Test Epoch: 88 | Loss: 0.320 | Acc: 90.278% (8757/9700)\n",
      "Test Epoch: 88 | Loss: 0.320 | Acc: 90.286% (8848/9800)\n",
      "Test Epoch: 88 | Loss: 0.322 | Acc: 90.253% (8935/9900)\n",
      "Test Epoch: 88 | Loss: 0.321 | Acc: 90.230% (9023/10000)\n",
      "\n",
      "Epoch: 89\n",
      "Train Epoch: 89 | Loss: 0.103 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 89 | Loss: 0.159 | Acc: 92.969% (238/256)\n",
      "Train Epoch: 89 | Loss: 0.150 | Acc: 93.750% (360/384)\n",
      "Train Epoch: 89 | Loss: 0.158 | Acc: 93.945% (481/512)\n",
      "Train Epoch: 89 | Loss: 0.171 | Acc: 93.594% (599/640)\n",
      "Train Epoch: 89 | Loss: 0.166 | Acc: 94.141% (723/768)\n",
      "Train Epoch: 89 | Loss: 0.169 | Acc: 94.196% (844/896)\n",
      "Train Epoch: 89 | Loss: 0.181 | Acc: 93.848% (961/1024)\n",
      "Train Epoch: 89 | Loss: 0.178 | Acc: 93.837% (1081/1152)\n",
      "Train Epoch: 89 | Loss: 0.179 | Acc: 93.828% (1201/1280)\n",
      "Train Epoch: 89 | Loss: 0.178 | Acc: 93.750% (1320/1408)\n",
      "Train Epoch: 89 | Loss: 0.173 | Acc: 93.880% (1442/1536)\n",
      "Train Epoch: 89 | Loss: 0.173 | Acc: 93.810% (1561/1664)\n",
      "Train Epoch: 89 | Loss: 0.173 | Acc: 93.806% (1681/1792)\n",
      "Train Epoch: 89 | Loss: 0.173 | Acc: 93.958% (1804/1920)\n",
      "Train Epoch: 89 | Loss: 0.172 | Acc: 94.043% (1926/2048)\n",
      "Train Epoch: 89 | Loss: 0.172 | Acc: 93.980% (2045/2176)\n",
      "Train Epoch: 89 | Loss: 0.169 | Acc: 94.010% (2166/2304)\n",
      "Train Epoch: 89 | Loss: 0.171 | Acc: 94.038% (2287/2432)\n",
      "Train Epoch: 89 | Loss: 0.177 | Acc: 93.906% (2404/2560)\n",
      "Train Epoch: 89 | Loss: 0.178 | Acc: 93.973% (2526/2688)\n",
      "Train Epoch: 89 | Loss: 0.178 | Acc: 93.999% (2647/2816)\n",
      "Train Epoch: 89 | Loss: 0.179 | Acc: 93.988% (2767/2944)\n",
      "Train Epoch: 89 | Loss: 0.183 | Acc: 93.913% (2885/3072)\n",
      "Train Epoch: 89 | Loss: 0.182 | Acc: 93.875% (3004/3200)\n",
      "Train Epoch: 89 | Loss: 0.180 | Acc: 93.960% (3127/3328)\n",
      "Train Epoch: 89 | Loss: 0.184 | Acc: 93.837% (3243/3456)\n",
      "Train Epoch: 89 | Loss: 0.184 | Acc: 93.862% (3364/3584)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.804% (3482/3712)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.750% (3600/3840)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.775% (3721/3968)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.750% (3840/4096)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.750% (3960/4224)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.727% (4079/4352)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.705% (4198/4480)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.750% (4320/4608)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.602% (4433/4736)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.668% (4556/4864)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.710% (4678/4992)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.750% (4800/5120)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.788% (4922/5248)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.824% (5044/5376)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.714% (5158/5504)\n",
      "Train Epoch: 89 | Loss: 0.185 | Acc: 93.803% (5283/5632)\n",
      "Train Epoch: 89 | Loss: 0.185 | Acc: 93.767% (5401/5760)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.716% (5518/5888)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.717% (5638/6016)\n",
      "Train Epoch: 89 | Loss: 0.185 | Acc: 93.766% (5761/6144)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.718% (5878/6272)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.703% (5997/6400)\n",
      "Train Epoch: 89 | Loss: 0.186 | Acc: 93.719% (6118/6528)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.675% (6235/6656)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.676% (6355/6784)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.649% (6473/6912)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.665% (6594/7040)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.694% (6716/7168)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.668% (6834/7296)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.696% (6956/7424)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.684% (7075/7552)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.724% (7198/7680)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.724% (7318/7808)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.687% (7435/7936)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.688% (7555/8064)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.701% (7676/8192)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.714% (7797/8320)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.703% (7916/8448)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.668% (8033/8576)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.693% (8155/8704)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.727% (8278/8832)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.739% (8399/8960)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.717% (8517/9088)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.696% (8635/9216)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.664% (8752/9344)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.655% (8871/9472)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.688% (8994/9600)\n",
      "Train Epoch: 89 | Loss: 0.187 | Acc: 93.688% (9114/9728)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.649% (9230/9856)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.640% (9349/9984)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.592% (9464/10112)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.525% (9577/10240)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.538% (9698/10368)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.559% (9820/10496)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.590% (9943/10624)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.601% (10064/10752)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.640% (10188/10880)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.623% (10306/11008)\n",
      "Train Epoch: 89 | Loss: 0.188 | Acc: 93.615% (10425/11136)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.590% (10542/11264)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.618% (10665/11392)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.620% (10785/11520)\n",
      "Train Epoch: 89 | Loss: 0.189 | Acc: 93.613% (10904/11648)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.606% (11023/11776)\n",
      "Train Epoch: 89 | Loss: 0.190 | Acc: 93.574% (11139/11904)\n",
      "Train Epoch: 89 | Loss: 0.191 | Acc: 93.559% (11257/12032)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.536% (11374/12160)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.530% (11493/12288)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.533% (11613/12416)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.527% (11732/12544)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.545% (11854/12672)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.547% (11974/12800)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.526% (12091/12928)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.490% (12206/13056)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.477% (12324/13184)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.457% (12441/13312)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.415% (12555/13440)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.418% (12675/13568)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.429% (12796/13696)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.403% (12912/13824)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.413% (13033/13952)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.402% (13151/14080)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.440% (13276/14208)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.450% (13397/14336)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.446% (13516/14464)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.469% (13639/14592)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.465% (13758/14720)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.454% (13876/14848)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.436% (13993/14976)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.439% (14113/15104)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.461% (14236/15232)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.464% (14356/15360)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.459% (14475/15488)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.475% (14597/15616)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.490% (14719/15744)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.492% (14839/15872)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.494% (14959/16000)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.483% (15077/16128)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.498% (15199/16256)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.469% (15314/16384)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.465% (15433/16512)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.480% (15555/16640)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.494% (15677/16768)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.501% (15798/16896)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.486% (15915/17024)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.493% (16036/17152)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.466% (16151/17280)\n",
      "Train Epoch: 89 | Loss: 0.192 | Acc: 93.480% (16273/17408)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.471% (16391/17536)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.473% (16511/17664)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.452% (16627/17792)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.454% (16747/17920)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.440% (16864/18048)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.458% (16987/18176)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.439% (17103/18304)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.462% (17227/18432)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.486% (17351/18560)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.488% (17471/18688)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.479% (17589/18816)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.465% (17706/18944)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.451% (17823/19072)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.438% (17940/19200)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.465% (18065/19328)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.462% (18184/19456)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.479% (18307/19584)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.435% (18418/19712)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.453% (18541/19840)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.445% (18659/19968)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.441% (18778/20096)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.458% (18901/20224)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.465% (19022/20352)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.442% (19137/20480)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.459% (19260/20608)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.461% (19380/20736)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.458% (19499/20864)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.455% (19618/20992)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.447% (19736/21120)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.458% (19858/21248)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.455% (19977/21376)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.443% (20094/21504)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.431% (20211/21632)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.438% (20332/21760)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.458% (20456/21888)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.450% (20574/22016)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.434% (20690/22144)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.409% (20804/22272)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.388% (20919/22400)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.386% (21038/22528)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.401% (21161/22656)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.390% (21278/22784)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.379% (21395/22912)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.390% (21517/23040)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.387% (21636/23168)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.398% (21758/23296)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.400% (21878/23424)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.406% (21999/23552)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.425% (22123/23680)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.427% (22243/23808)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.420% (22361/23936)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.388% (22473/24064)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.390% (22593/24192)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.396% (22714/24320)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.406% (22836/24448)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.384% (22950/24576)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.390% (23071/24704)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.380% (23188/24832)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.389% (23310/24960)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.391% (23430/25088)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.385% (23548/25216)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.383% (23667/25344)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.377% (23785/25472)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.363% (23901/25600)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.365% (24021/25728)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.375% (24143/25856)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.357% (24258/25984)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.352% (24376/26112)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.338% (24492/26240)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.325% (24608/26368)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.335% (24730/26496)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.352% (24854/26624)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.365% (24977/26752)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.371% (25098/26880)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.372% (25218/27008)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.356% (25333/27136)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.369% (25456/27264)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.370% (25576/27392)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.379% (25698/27520)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.370% (25815/27648)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.365% (25933/27776)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.367% (26053/27904)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.368% (26173/28032)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.342% (26285/28160)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.358% (26409/28288)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.359% (26529/28416)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.361% (26649/28544)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.363% (26769/28672)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.361% (26888/28800)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.359% (27007/28928)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.365% (27128/29056)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.363% (27247/29184)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.354% (27364/29312)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.363% (27486/29440)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.354% (27603/29568)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.363% (27725/29696)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.361% (27844/29824)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.363% (27964/29952)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.358% (28082/30080)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.356% (28201/30208)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.354% (28320/30336)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.366% (28443/30464)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.381% (28567/30592)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.382% (28687/30720)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.384% (28807/30848)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.385% (28927/30976)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.387% (29047/31104)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.388% (29167/31232)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.383% (29285/31360)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.378% (29403/31488)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.374% (29521/31616)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.366% (29638/31744)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.352% (29753/31872)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.359% (29875/32000)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.358% (29994/32128)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.353% (30112/32256)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.364% (30235/32384)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.372% (30357/32512)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.382% (30480/32640)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.369% (30595/32768)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.382% (30719/32896)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.378% (30837/33024)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.388% (30960/33152)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.377% (31076/33280)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.373% (31194/33408)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.368% (31312/33536)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.361% (31429/33664)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.362% (31549/33792)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.373% (31672/33920)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.374% (31792/34048)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.375% (31912/34176)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.383% (32034/34304)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.390% (32156/34432)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.383% (32273/34560)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.384% (32393/34688)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.382% (32512/34816)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.389% (32634/34944)\n",
      "Train Epoch: 89 | Loss: 0.193 | Acc: 93.388% (32753/35072)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.369% (32866/35200)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.354% (32980/35328)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.366% (33104/35456)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.376% (33227/35584)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.378% (33347/35712)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.373% (33465/35840)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.369% (33583/35968)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.368% (33702/36096)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.375% (33824/36224)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.392% (33950/36352)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.402% (34073/36480)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.398% (34191/36608)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.410% (34315/36736)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.414% (34436/36864)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.407% (34553/36992)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.405% (34672/37120)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.412% (34794/37248)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.416% (34915/37376)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.417% (35035/37504)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.415% (35154/37632)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.414% (35273/37760)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.407% (35390/37888)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.405% (35509/38016)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.401% (35627/38144)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.405% (35748/38272)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.401% (35866/38400)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.405% (35987/38528)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.393% (36102/38656)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.389% (36220/38784)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.400% (36344/38912)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.409% (36467/39040)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.416% (36589/39168)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.414% (36708/39296)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.408% (36825/39424)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.406% (36944/39552)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.415% (37067/39680)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.406% (37183/39808)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.414% (37306/39936)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.416% (37426/40064)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.417% (37546/40192)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.415% (37665/40320)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.409% (37782/40448)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.410% (37902/40576)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.404% (38019/40704)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.402% (38138/40832)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.398% (38256/40960)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.392% (38373/41088)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.381% (38488/41216)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.378% (38606/41344)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.381% (38727/41472)\n",
      "Train Epoch: 89 | Loss: 0.194 | Acc: 93.385% (38848/41600)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.371% (38962/41728)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.375% (39083/41856)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.364% (39198/41984)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.349% (39311/42112)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.345% (39429/42240)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.346% (39549/42368)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.350% (39670/42496)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.351% (39790/42624)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.350% (39909/42752)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.344% (40026/42880)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.341% (40144/43008)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.337% (40262/43136)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.339% (40382/43264)\n",
      "Train Epoch: 89 | Loss: 0.195 | Acc: 93.337% (40501/43392)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.336% (40620/43520)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.335% (40739/43648)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.330% (40856/43776)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.333% (40977/43904)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.325% (41093/44032)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.322% (41211/44160)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.319% (41329/44288)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.322% (41450/44416)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.312% (41565/44544)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.309% (41683/44672)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.310% (41803/44800)\n",
      "Train Epoch: 89 | Loss: 0.196 | Acc: 93.298% (41917/44928)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.288% (42032/45056)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.292% (42153/45184)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.287% (42270/45312)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.283% (42388/45440)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.291% (42511/45568)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.288% (42629/45696)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.283% (42746/45824)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.273% (42861/45952)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.275% (42981/46080)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.270% (43098/46208)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.256% (43211/46336)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.251% (43328/46464)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.241% (43443/46592)\n",
      "Train Epoch: 89 | Loss: 0.197 | Acc: 93.247% (43565/46720)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.246% (43684/46848)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.243% (43802/46976)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.238% (43919/47104)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.231% (44035/47232)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.241% (44159/47360)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.238% (44277/47488)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.221% (44388/47616)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.218% (44506/47744)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.213% (44623/47872)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.217% (44744/48000)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.218% (44864/48128)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.219% (44984/48256)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.221% (45104/48384)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.212% (45219/48512)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.211% (45338/48640)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.205% (45454/48768)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.200% (45571/48896)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.203% (45692/49024)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.205% (45812/49152)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.204% (45931/49280)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.204% (46050/49408)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.213% (46174/49536)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.220% (46297/49664)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.228% (46420/49792)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.233% (46542/49920)\n",
      "Train Epoch: 89 | Loss: 0.198 | Acc: 93.238% (46619/50000)\n",
      "Test Epoch: 89 | Loss: 0.323 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 89 | Loss: 0.377 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 89 | Loss: 0.320 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 89 | Loss: 0.298 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 89 | Loss: 0.289 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 89 | Loss: 0.280 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 89 | Loss: 0.275 | Acc: 90.857% (636/700)\n",
      "Test Epoch: 89 | Loss: 0.294 | Acc: 90.250% (722/800)\n",
      "Test Epoch: 89 | Loss: 0.307 | Acc: 89.667% (807/900)\n",
      "Test Epoch: 89 | Loss: 0.304 | Acc: 89.600% (896/1000)\n",
      "Test Epoch: 89 | Loss: 0.310 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 89 | Loss: 0.316 | Acc: 89.333% (1072/1200)\n",
      "Test Epoch: 89 | Loss: 0.309 | Acc: 89.462% (1163/1300)\n",
      "Test Epoch: 89 | Loss: 0.307 | Acc: 89.643% (1255/1400)\n",
      "Test Epoch: 89 | Loss: 0.311 | Acc: 89.667% (1345/1500)\n",
      "Test Epoch: 89 | Loss: 0.312 | Acc: 89.625% (1434/1600)\n",
      "Test Epoch: 89 | Loss: 0.317 | Acc: 89.765% (1526/1700)\n",
      "Test Epoch: 89 | Loss: 0.328 | Acc: 89.444% (1610/1800)\n",
      "Test Epoch: 89 | Loss: 0.325 | Acc: 89.421% (1699/1900)\n",
      "Test Epoch: 89 | Loss: 0.324 | Acc: 89.550% (1791/2000)\n",
      "Test Epoch: 89 | Loss: 0.323 | Acc: 89.571% (1881/2100)\n",
      "Test Epoch: 89 | Loss: 0.323 | Acc: 89.500% (1969/2200)\n",
      "Test Epoch: 89 | Loss: 0.325 | Acc: 89.435% (2057/2300)\n",
      "Test Epoch: 89 | Loss: 0.323 | Acc: 89.667% (2152/2400)\n",
      "Test Epoch: 89 | Loss: 0.328 | Acc: 89.560% (2239/2500)\n",
      "Test Epoch: 89 | Loss: 0.342 | Acc: 89.346% (2323/2600)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.630% (2420/2700)\n",
      "Test Epoch: 89 | Loss: 0.336 | Acc: 89.679% (2511/2800)\n",
      "Test Epoch: 89 | Loss: 0.338 | Acc: 89.621% (2599/2900)\n",
      "Test Epoch: 89 | Loss: 0.338 | Acc: 89.433% (2683/3000)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.355% (2770/3100)\n",
      "Test Epoch: 89 | Loss: 0.337 | Acc: 89.375% (2860/3200)\n",
      "Test Epoch: 89 | Loss: 0.339 | Acc: 89.212% (2944/3300)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.118% (3030/3400)\n",
      "Test Epoch: 89 | Loss: 0.345 | Acc: 89.000% (3115/3500)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.056% (3206/3600)\n",
      "Test Epoch: 89 | Loss: 0.346 | Acc: 89.027% (3294/3700)\n",
      "Test Epoch: 89 | Loss: 0.350 | Acc: 89.000% (3382/3800)\n",
      "Test Epoch: 89 | Loss: 0.348 | Acc: 89.000% (3471/3900)\n",
      "Test Epoch: 89 | Loss: 0.347 | Acc: 89.125% (3565/4000)\n",
      "Test Epoch: 89 | Loss: 0.349 | Acc: 89.146% (3655/4100)\n",
      "Test Epoch: 89 | Loss: 0.350 | Acc: 89.167% (3745/4200)\n",
      "Test Epoch: 89 | Loss: 0.347 | Acc: 89.256% (3838/4300)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.341% (3931/4400)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.333% (4020/4500)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.326% (4109/4600)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.447% (4204/4700)\n",
      "Test Epoch: 89 | Loss: 0.342 | Acc: 89.396% (4291/4800)\n",
      "Test Epoch: 89 | Loss: 0.339 | Acc: 89.510% (4386/4900)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.380% (4469/5000)\n",
      "Test Epoch: 89 | Loss: 0.339 | Acc: 89.451% (4562/5100)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.385% (4648/5200)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.358% (4736/5300)\n",
      "Test Epoch: 89 | Loss: 0.338 | Acc: 89.407% (4828/5400)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.400% (4917/5500)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.411% (5007/5600)\n",
      "Test Epoch: 89 | Loss: 0.342 | Acc: 89.439% (5098/5700)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.483% (5190/5800)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.390% (5274/5900)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.400% (5364/6000)\n",
      "Test Epoch: 89 | Loss: 0.343 | Acc: 89.410% (5454/6100)\n",
      "Test Epoch: 89 | Loss: 0.341 | Acc: 89.403% (5543/6200)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.460% (5636/6300)\n",
      "Test Epoch: 89 | Loss: 0.338 | Acc: 89.531% (5730/6400)\n",
      "Test Epoch: 89 | Loss: 0.340 | Acc: 89.446% (5814/6500)\n",
      "Test Epoch: 89 | Loss: 0.338 | Acc: 89.485% (5906/6600)\n",
      "Test Epoch: 89 | Loss: 0.336 | Acc: 89.507% (5997/6700)\n",
      "Test Epoch: 89 | Loss: 0.337 | Acc: 89.500% (6086/6800)\n",
      "Test Epoch: 89 | Loss: 0.335 | Acc: 89.594% (6182/6900)\n",
      "Test Epoch: 89 | Loss: 0.336 | Acc: 89.586% (6271/7000)\n",
      "Test Epoch: 89 | Loss: 0.336 | Acc: 89.606% (6362/7100)\n",
      "Test Epoch: 89 | Loss: 0.336 | Acc: 89.639% (6454/7200)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.685% (6547/7300)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.689% (6637/7400)\n",
      "Test Epoch: 89 | Loss: 0.335 | Acc: 89.600% (6720/7500)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.592% (6809/7600)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.558% (6896/7700)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.564% (6986/7800)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.557% (7075/7900)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.562% (7165/8000)\n",
      "Test Epoch: 89 | Loss: 0.331 | Acc: 89.593% (7257/8100)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.537% (7342/8200)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.422% (7422/8300)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.476% (7516/8400)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.376% (7597/8500)\n",
      "Test Epoch: 89 | Loss: 0.334 | Acc: 89.349% (7684/8600)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.379% (7776/8700)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.375% (7865/8800)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.404% (7957/8900)\n",
      "Test Epoch: 89 | Loss: 0.333 | Acc: 89.389% (8045/9000)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.407% (8136/9100)\n",
      "Test Epoch: 89 | Loss: 0.331 | Acc: 89.446% (8229/9200)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.398% (8314/9300)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.394% (8403/9400)\n",
      "Test Epoch: 89 | Loss: 0.331 | Acc: 89.400% (8493/9500)\n",
      "Test Epoch: 89 | Loss: 0.332 | Acc: 89.406% (8583/9600)\n",
      "Test Epoch: 89 | Loss: 0.330 | Acc: 89.485% (8680/9700)\n",
      "Test Epoch: 89 | Loss: 0.330 | Acc: 89.490% (8770/9800)\n",
      "Test Epoch: 89 | Loss: 0.330 | Acc: 89.455% (8856/9900)\n",
      "Test Epoch: 89 | Loss: 0.329 | Acc: 89.490% (8949/10000)\n",
      "\n",
      "Epoch: 90\n",
      "Train Epoch: 90 | Loss: 0.200 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 90 | Loss: 0.206 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 90 | Loss: 0.206 | Acc: 93.229% (358/384)\n",
      "Train Epoch: 90 | Loss: 0.211 | Acc: 92.773% (475/512)\n",
      "Train Epoch: 90 | Loss: 0.225 | Acc: 92.500% (592/640)\n",
      "Train Epoch: 90 | Loss: 0.205 | Acc: 92.839% (713/768)\n",
      "Train Epoch: 90 | Loss: 0.210 | Acc: 92.411% (828/896)\n",
      "Train Epoch: 90 | Loss: 0.208 | Acc: 92.285% (945/1024)\n",
      "Train Epoch: 90 | Loss: 0.208 | Acc: 92.014% (1060/1152)\n",
      "Train Epoch: 90 | Loss: 0.201 | Acc: 92.344% (1182/1280)\n",
      "Train Epoch: 90 | Loss: 0.199 | Acc: 92.472% (1302/1408)\n",
      "Train Epoch: 90 | Loss: 0.202 | Acc: 92.448% (1420/1536)\n",
      "Train Epoch: 90 | Loss: 0.200 | Acc: 92.488% (1539/1664)\n",
      "Train Epoch: 90 | Loss: 0.198 | Acc: 92.578% (1659/1792)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 92.760% (1781/1920)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.066% (1906/2048)\n",
      "Train Epoch: 90 | Loss: 0.190 | Acc: 93.061% (2025/2176)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.099% (2145/2304)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.257% (2268/2432)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.203% (2386/2560)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.266% (2507/2688)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.253% (2626/2816)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.173% (2743/2944)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.132% (2861/3072)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.219% (2983/3200)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.329% (3106/3328)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.345% (3226/3456)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.276% (3343/3584)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.319% (3464/3712)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.307% (3583/3840)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.170% (3697/3968)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.140% (3815/4096)\n",
      "Train Epoch: 90 | Loss: 0.196 | Acc: 93.040% (3930/4224)\n",
      "Train Epoch: 90 | Loss: 0.197 | Acc: 92.969% (4046/4352)\n",
      "Train Epoch: 90 | Loss: 0.197 | Acc: 92.924% (4163/4480)\n",
      "Train Epoch: 90 | Loss: 0.200 | Acc: 92.795% (4276/4608)\n",
      "Train Epoch: 90 | Loss: 0.198 | Acc: 92.905% (4400/4736)\n",
      "Train Epoch: 90 | Loss: 0.197 | Acc: 92.928% (4520/4864)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 92.989% (4642/4992)\n",
      "Train Epoch: 90 | Loss: 0.196 | Acc: 92.949% (4759/5120)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.026% (4882/5248)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.080% (5004/5376)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.169% (5128/5504)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.164% (5247/5632)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.229% (5370/5760)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.224% (5489/5888)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.301% (5613/6016)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.229% (5728/6144)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.288% (5851/6272)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.344% (5974/6400)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.352% (6094/6528)\n",
      "Train Epoch: 90 | Loss: 0.190 | Acc: 93.404% (6217/6656)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.470% (6341/6784)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.519% (6464/6912)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.509% (6583/7040)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.541% (6705/7168)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.503% (6822/7296)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.481% (6940/7424)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.512% (7062/7552)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.581% (7187/7680)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.584% (7307/7808)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.548% (7424/7936)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.502% (7540/8064)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.530% (7662/8192)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.486% (7778/8320)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.513% (7900/8448)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.552% (8023/8576)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.578% (8145/8704)\n",
      "Train Epoch: 90 | Loss: 0.184 | Acc: 93.614% (8268/8832)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.594% (8386/8960)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.618% (8508/9088)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.620% (8628/9216)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.611% (8747/9344)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.623% (8868/9472)\n",
      "Train Epoch: 90 | Loss: 0.186 | Acc: 93.625% (8988/9600)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.637% (9109/9728)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.659% (9231/9856)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.670% (9352/9984)\n",
      "Train Epoch: 90 | Loss: 0.185 | Acc: 93.681% (9473/10112)\n",
      "Train Epoch: 90 | Loss: 0.184 | Acc: 93.691% (9594/10240)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.596% (9704/10368)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.579% (9822/10496)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.581% (9942/10624)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.545% (10058/10752)\n",
      "Train Epoch: 90 | Loss: 0.187 | Acc: 93.557% (10179/10880)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.550% (10298/11008)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.490% (10411/11136)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.528% (10535/11264)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.522% (10654/11392)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.533% (10775/11520)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.492% (10890/11648)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.521% (11013/11776)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.532% (11134/11904)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.551% (11256/12032)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.561% (11377/12160)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.571% (11498/12288)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.533% (11613/12416)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.511% (11730/12544)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.490% (11847/12672)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.477% (11965/12800)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.456% (12082/12928)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.459% (12202/13056)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.454% (12321/13184)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.495% (12446/13312)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.512% (12568/13440)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.499% (12686/13568)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.494% (12805/13696)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.468% (12921/13824)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.427% (13035/13952)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.445% (13157/14080)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.476% (13281/14208)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.471% (13400/14336)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.460% (13518/14464)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.490% (13642/14592)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.492% (13762/14720)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.487% (13881/14848)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.483% (14000/14976)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.512% (14124/15104)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.527% (14246/15232)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.522% (14365/15360)\n",
      "Train Epoch: 90 | Loss: 0.188 | Acc: 93.524% (14485/15488)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.526% (14605/15616)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.540% (14727/15744)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.511% (14842/15872)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.525% (14964/16000)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.521% (15083/16128)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.504% (15200/16256)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.518% (15322/16384)\n",
      "Train Epoch: 90 | Loss: 0.189 | Acc: 93.514% (15441/16512)\n",
      "Train Epoch: 90 | Loss: 0.190 | Acc: 93.456% (15551/16640)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.440% (15668/16768)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.407% (15782/16896)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.368% (15895/17024)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.371% (16015/17152)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.385% (16137/17280)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.388% (16257/17408)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.368% (16373/17536)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.388% (16496/17664)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.402% (16618/17792)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.426% (16742/17920)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.462% (16868/18048)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.464% (16988/18176)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.471% (17109/18304)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.468% (17228/18432)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.427% (17340/18560)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.440% (17462/18688)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.431% (17580/18816)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.423% (17698/18944)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.425% (17818/19072)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.443% (17941/19200)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.445% (18061/19328)\n",
      "Train Epoch: 90 | Loss: 0.191 | Acc: 93.452% (18182/19456)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.444% (18300/19584)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.425% (18416/19712)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.412% (18533/19840)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.419% (18654/19968)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.417% (18773/20096)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.429% (18895/20224)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.421% (19013/20352)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.384% (19125/20480)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.391% (19246/20608)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.393% (19366/20736)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.414% (19490/20864)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.412% (19609/20992)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.419% (19730/21120)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.416% (19849/21248)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.413% (19968/21376)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.401% (20085/21504)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.389% (20202/21632)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.396% (20323/21760)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.407% (20445/21888)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.400% (20563/22016)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.420% (20687/22144)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.427% (20808/22272)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.420% (20926/22400)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.395% (21040/22528)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.397% (21160/22656)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.416% (21284/22784)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.414% (21403/22912)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.429% (21526/23040)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.413% (21642/23168)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.389% (21756/23296)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.391% (21876/23424)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.402% (21998/23552)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.412% (22120/23680)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.414% (22240/23808)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.424% (22362/23936)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.409% (22478/24064)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.403% (22596/24192)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.400% (22715/24320)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.427% (22841/24448)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.437% (22963/24576)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.430% (23081/24704)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.440% (23203/24832)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.421% (23318/24960)\n",
      "Train Epoch: 90 | Loss: 0.192 | Acc: 93.419% (23437/25088)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.401% (23552/25216)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.387% (23668/25344)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.385% (23787/25472)\n",
      "Train Epoch: 90 | Loss: 0.193 | Acc: 93.367% (23902/25600)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.354% (24018/25728)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.332% (24132/25856)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.331% (24251/25984)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.348% (24375/26112)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.346% (24494/26240)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.337% (24611/26368)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.327% (24728/26496)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.341% (24851/26624)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.335% (24969/26752)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.330% (25087/26880)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.313% (25202/27008)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.308% (25320/27136)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.303% (25438/27264)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.305% (25558/27392)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.296% (25675/27520)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.309% (25798/27648)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.300% (25915/27776)\n",
      "Train Epoch: 90 | Loss: 0.194 | Acc: 93.302% (26035/27904)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.272% (26146/28032)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.278% (26267/28160)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.262% (26382/28288)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.275% (26505/28416)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.263% (26621/28544)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.269% (26742/28672)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.271% (26862/28800)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.263% (26979/28928)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.268% (27100/29056)\n",
      "Train Epoch: 90 | Loss: 0.195 | Acc: 93.287% (27225/29184)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+100):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.61\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./.conda/envs/default/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tracc_list,'-o')\n",
    "plt.plot(tacc_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trloss_list,'-o')\n",
    "plt.plot(tloss_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Obc8bEGDCY4s",
    "outputId": "4225c6cf-fae5-4119-add7-09628e4d21a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train Epoch: 0 | Loss: 0.239 | Acc: 89.844% (115/128)\n",
      "Train Epoch: 0 | Loss: 0.233 | Acc: 90.625% (232/256)\n",
      "Train Epoch: 0 | Loss: 0.217 | Acc: 91.406% (351/384)\n",
      "Train Epoch: 0 | Loss: 0.220 | Acc: 91.211% (467/512)\n",
      "Train Epoch: 0 | Loss: 0.213 | Acc: 91.719% (587/640)\n",
      "Train Epoch: 0 | Loss: 0.200 | Acc: 92.448% (710/768)\n",
      "Train Epoch: 0 | Loss: 0.210 | Acc: 92.299% (827/896)\n",
      "Train Epoch: 0 | Loss: 0.201 | Acc: 92.578% (948/1024)\n",
      "Train Epoch: 0 | Loss: 0.211 | Acc: 92.448% (1065/1152)\n",
      "Train Epoch: 0 | Loss: 0.210 | Acc: 92.578% (1185/1280)\n",
      "Train Epoch: 0 | Loss: 0.205 | Acc: 92.969% (1309/1408)\n",
      "Train Epoch: 0 | Loss: 0.204 | Acc: 92.904% (1427/1536)\n",
      "Train Epoch: 0 | Loss: 0.206 | Acc: 92.728% (1543/1664)\n",
      "Train Epoch: 0 | Loss: 0.205 | Acc: 92.801% (1663/1792)\n",
      "Train Epoch: 0 | Loss: 0.201 | Acc: 92.969% (1785/1920)\n",
      "Train Epoch: 0 | Loss: 0.197 | Acc: 93.066% (1906/2048)\n",
      "Train Epoch: 0 | Loss: 0.198 | Acc: 93.061% (2025/2176)\n",
      "Train Epoch: 0 | Loss: 0.199 | Acc: 93.012% (2143/2304)\n",
      "Train Epoch: 0 | Loss: 0.197 | Acc: 93.051% (2263/2432)\n",
      "Train Epoch: 0 | Loss: 0.198 | Acc: 92.930% (2379/2560)\n",
      "Train Epoch: 0 | Loss: 0.196 | Acc: 93.043% (2501/2688)\n",
      "Train Epoch: 0 | Loss: 0.194 | Acc: 93.146% (2623/2816)\n",
      "Train Epoch: 0 | Loss: 0.192 | Acc: 93.274% (2746/2944)\n",
      "Train Epoch: 0 | Loss: 0.191 | Acc: 93.262% (2865/3072)\n",
      "Train Epoch: 0 | Loss: 0.191 | Acc: 93.219% (2983/3200)\n",
      "Train Epoch: 0 | Loss: 0.187 | Acc: 93.359% (3107/3328)\n",
      "Train Epoch: 0 | Loss: 0.186 | Acc: 93.432% (3229/3456)\n",
      "Train Epoch: 0 | Loss: 0.188 | Acc: 93.331% (3345/3584)\n",
      "Train Epoch: 0 | Loss: 0.188 | Acc: 93.292% (3463/3712)\n",
      "Train Epoch: 0 | Loss: 0.186 | Acc: 93.385% (3586/3840)\n",
      "Train Epoch: 0 | Loss: 0.185 | Acc: 93.448% (3708/3968)\n",
      "Train Epoch: 0 | Loss: 0.186 | Acc: 93.335% (3823/4096)\n",
      "Train Epoch: 0 | Loss: 0.186 | Acc: 93.300% (3941/4224)\n",
      "Train Epoch: 0 | Loss: 0.185 | Acc: 93.359% (4063/4352)\n",
      "Train Epoch: 0 | Loss: 0.182 | Acc: 93.504% (4189/4480)\n",
      "Train Epoch: 0 | Loss: 0.182 | Acc: 93.555% (4311/4608)\n",
      "Train Epoch: 0 | Loss: 0.180 | Acc: 93.602% (4433/4736)\n",
      "Train Epoch: 0 | Loss: 0.178 | Acc: 93.688% (4557/4864)\n",
      "Train Epoch: 0 | Loss: 0.177 | Acc: 93.750% (4680/4992)\n",
      "Train Epoch: 0 | Loss: 0.177 | Acc: 93.789% (4802/5120)\n",
      "Train Epoch: 0 | Loss: 0.178 | Acc: 93.769% (4921/5248)\n",
      "Train Epoch: 0 | Loss: 0.175 | Acc: 93.880% (5047/5376)\n",
      "Train Epoch: 0 | Loss: 0.176 | Acc: 93.841% (5165/5504)\n",
      "Train Epoch: 0 | Loss: 0.175 | Acc: 93.857% (5286/5632)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.906% (5409/5760)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.937% (5531/5888)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.933% (5651/6016)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.978% (5774/6144)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.021% (5897/6272)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.031% (6018/6400)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.010% (6137/6528)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.066% (6261/6656)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.089% (6383/6784)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.068% (6502/6912)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 94.034% (6620/7040)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.113% (6746/7168)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.093% (6865/7296)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.114% (6987/7424)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.160% (7111/7552)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.167% (7232/7680)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.185% (7354/7808)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.078% (7466/7936)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.060% (7585/8064)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.104% (7709/8192)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.111% (7830/8320)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.070% (7947/8448)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.076% (8068/8576)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.049% (8186/8704)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.931% (8296/8832)\n",
      "Train Epoch: 0 | Loss: 0.174 | Acc: 93.884% (8412/8960)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.882% (8532/9088)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.934% (8657/9216)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.932% (8777/9344)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.919% (8896/9472)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.948% (9019/9600)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.935% (9138/9728)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.943% (9259/9856)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.940% (9379/9984)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.968% (9502/10112)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.975% (9623/10240)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 94.010% (9747/10368)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.969% (9863/10496)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.966% (9983/10624)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.890% (10095/10752)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.906% (10217/10880)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.859% (10332/11008)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.876% (10454/11136)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.874% (10574/11264)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.864% (10693/11392)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.819% (10808/11520)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.802% (10926/11648)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.835% (11050/11776)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.876% (11175/11904)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.891% (11297/12032)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.914% (11420/12160)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.905% (11539/12288)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.943% (11664/12416)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.997% (11791/12544)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.003% (11912/12672)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.023% (12035/12800)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 94.028% (12156/12928)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.056% (12280/13056)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.046% (12399/13184)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.050% (12520/13312)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.055% (12641/13440)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.067% (12763/13568)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.064% (12883/13696)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.061% (13003/13824)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.015% (13117/13952)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.027% (13239/14080)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.046% (13362/14208)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.043% (13482/14336)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.033% (13601/14464)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.010% (13718/14592)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.001% (13837/14720)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.006% (13958/14848)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.990% (14076/14976)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.955% (14191/15104)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.934% (14308/15232)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.926% (14427/15360)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.937% (14549/15488)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.904% (14664/15616)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.902% (14784/15744)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.920% (14907/15872)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.925% (15028/16000)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.936% (15150/16128)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.959% (15274/16256)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.964% (15395/16384)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.968% (15516/16512)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.972% (15637/16640)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.989% (15760/16768)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.993% (15881/16896)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.008% (16004/17024)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.030% (16128/17152)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.028% (16248/17280)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.020% (16367/17408)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.018% (16487/17536)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.022% (16608/17664)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.997% (16724/17792)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.012% (16847/17920)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.005% (16966/18048)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.009% (17087/18176)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.018% (17209/18304)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.021% (17330/18432)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.036% (17453/18560)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.034% (17573/18688)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.037% (17694/18816)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.024% (17812/18944)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.017% (17931/19072)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.005% (18049/19200)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.993% (18167/19328)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.002% (18289/19456)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.985% (18406/19584)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.988% (18527/19712)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.992% (18648/19840)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.010% (18772/19968)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.009% (18892/20096)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.017% (19014/20224)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.025% (19136/20352)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.028% (19257/20480)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.041% (19380/20608)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.039% (19500/20736)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.057% (19624/20864)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.012% (19735/20992)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.001% (19853/21120)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.976% (19968/21248)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.970% (20087/21376)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.983% (20210/21504)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.995% (20333/21632)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.989% (20452/21760)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.988% (20572/21888)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.004% (20696/22016)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.998% (20815/22144)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.997% (20935/22272)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.013% (21059/22400)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.025% (21182/22528)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.024% (21302/22656)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.013% (21420/22784)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.999% (21537/22912)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.997% (21657/23040)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.996% (21777/23168)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.016% (21902/23296)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.015% (22022/23424)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.013% (22142/23552)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.008% (22261/23680)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.010% (22382/23808)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.017% (22504/23936)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.024% (22626/24064)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.043% (22751/24192)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.050% (22873/24320)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.053% (22994/24448)\n",
      "Train Epoch: 0 | Loss: 0.167 | Acc: 94.055% (23115/24576)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.033% (23230/24704)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.028% (23349/24832)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.010% (23465/24960)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.009% (23585/25088)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.016% (23707/25216)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.014% (23827/25344)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 94.005% (23945/25472)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.016% (24068/25600)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.018% (24189/25728)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.025% (24311/25856)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.016% (24429/25984)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.022% (24551/26112)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.028% (24673/26240)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.023% (24792/26368)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.033% (24915/26496)\n",
      "Train Epoch: 0 | Loss: 0.167 | Acc: 94.035% (25036/26624)\n",
      "Train Epoch: 0 | Loss: 0.167 | Acc: 94.023% (25153/26752)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.018% (25272/26880)\n",
      "Train Epoch: 0 | Loss: 0.167 | Acc: 94.024% (25394/27008)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.012% (25511/27136)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 93.999% (25628/27264)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.020% (25754/27392)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.023% (25875/27520)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 94.014% (25993/27648)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 93.998% (26109/27776)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 93.987% (26226/27904)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 93.978% (26344/28032)\n",
      "Train Epoch: 0 | Loss: 0.168 | Acc: 93.977% (26464/28160)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.948% (26576/28288)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.940% (26694/28416)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.932% (26812/28544)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.921% (26929/28672)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.910% (27046/28800)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.919% (27169/28928)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.915% (27288/29056)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.935% (27414/29184)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.934% (27534/29312)\n",
      "Train Epoch: 0 | Loss: 0.169 | Acc: 93.923% (27651/29440)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.909% (27767/29568)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.908% (27887/29696)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.908% (28007/29824)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.917% (28130/29952)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.910% (28248/30080)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.909% (28368/30208)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.898% (28485/30336)\n",
      "Train Epoch: 0 | Loss: 0.170 | Acc: 93.901% (28606/30464)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.891% (28723/30592)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.877% (28839/30720)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.883% (28961/30848)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.895% (29085/30976)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.904% (29208/31104)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.907% (29329/31232)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.897% (29446/31360)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.893% (29565/31488)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.892% (29685/31616)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.895% (29806/31744)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.907% (29930/31872)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.919% (30054/32000)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.909% (30171/32128)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.921% (30295/32256)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.907% (30411/32384)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.891% (30526/32512)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.891% (30646/32640)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.884% (30764/32768)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.878% (30882/32896)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.877% (31002/33024)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.880% (31123/33152)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.879% (31243/33280)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.888% (31366/33408)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.887% (31486/33536)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.875% (31602/33664)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.883% (31725/33792)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.883% (31845/33920)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.891% (31968/34048)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.896% (32090/34176)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.893% (32209/34304)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.887% (32327/34432)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.889% (32448/34560)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.877% (32564/34688)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.865% (32680/34816)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.864% (32800/34944)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.855% (32917/35072)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.858% (33038/35200)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.860% (33159/35328)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.849% (33275/35456)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.846% (33394/35584)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.856% (33518/35712)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.842% (33633/35840)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.858% (33759/35968)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.866% (33882/36096)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.860% (34000/36224)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.863% (34121/36352)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.871% (34244/36480)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.865% (34362/36608)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.862% (34481/36736)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.872% (34605/36864)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.877% (34727/36992)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.871% (34845/37120)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.871% (34965/37248)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.870% (35085/37376)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.862% (35202/37504)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.854% (35319/37632)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.856% (35440/37760)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.848% (35557/37888)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.842% (35675/38016)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.847% (35797/38144)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.852% (35919/38272)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.849% (36038/38400)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.854% (36160/38528)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.861% (36283/38656)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.871% (36407/38784)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.881% (36531/38912)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.883% (36652/39040)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.883% (36772/39168)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.877% (36890/39296)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.882% (37012/39424)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.879% (37131/39552)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.884% (37253/39680)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.873% (37369/39808)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.885% (37494/39936)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.892% (37617/40064)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.897% (37739/40192)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.909% (37864/40320)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.916% (37987/40448)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.918% (38108/40576)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.915% (38227/40704)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.919% (38349/40832)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.914% (38467/40960)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.918% (38589/41088)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.925% (38712/41216)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.929% (38834/41344)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.933% (38956/41472)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.940% (39079/41600)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.935% (39197/41728)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.917% (39310/41856)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.919% (39431/41984)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.923% (39553/42112)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.932% (39677/42240)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.941% (39801/42368)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.943% (39922/42496)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.942% (40042/42624)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.951% (40166/42752)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.951% (40286/42880)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.952% (40407/43008)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.956% (40529/43136)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.963% (40652/43264)\n",
      "Train Epoch: 0 | Loss: 0.171 | Acc: 93.967% (40774/43392)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.952% (40888/43520)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.947% (41006/43648)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.951% (41128/43776)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.955% (41250/43904)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.948% (41367/44032)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.949% (41488/44160)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.955% (41611/44288)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.959% (41733/44416)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.957% (41852/44544)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.956% (41972/44672)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.953% (42091/44800)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.953% (42211/44928)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.950% (42330/45056)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.945% (42448/45184)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.946% (42569/45312)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.957% (42694/45440)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.954% (42813/45568)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.951% (42932/45696)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.953% (43053/45824)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.955% (43174/45952)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.952% (43293/46080)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.956% (43415/46208)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.959% (43537/46336)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.959% (43657/46464)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.958% (43777/46592)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.962% (43899/46720)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.970% (44023/46848)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.961% (44139/46976)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.960% (44259/47104)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.957% (44378/47232)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.946% (44493/47360)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.948% (44614/47488)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.945% (44733/47616)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.943% (44852/47744)\n",
      "Train Epoch: 0 | Loss: 0.172 | Acc: 93.948% (44975/47872)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.950% (45096/48000)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.947% (45215/48128)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.934% (45329/48256)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.922% (45443/48384)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.923% (45564/48512)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.925% (45685/48640)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.916% (45801/48768)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.924% (45925/48896)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.913% (46040/49024)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.919% (46163/49152)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.918% (46283/49280)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.920% (46404/49408)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.918% (46523/49536)\n",
      "Train Epoch: 0 | Loss: 0.173 | Acc: 93.913% (46641/49664)\n",
      "Train Epoch: 0 | Loss: 0.174 | Acc: 93.909% (46759/49792)\n",
      "Train Epoch: 0 | Loss: 0.174 | Acc: 93.910% (46880/49920)\n",
      "Train Epoch: 0 | Loss: 0.174 | Acc: 93.902% (46951/50000)\n",
      "Test Epoch: 0 | Loss: 0.350 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 0 | Loss: 0.381 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 0 | Loss: 0.340 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 0 | Loss: 0.344 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 0 | Loss: 0.330 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 0 | Loss: 0.302 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 0 | Loss: 0.319 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 0 | Loss: 0.343 | Acc: 89.750% (718/800)\n",
      "Test Epoch: 0 | Loss: 0.344 | Acc: 89.667% (807/900)\n",
      "Test Epoch: 0 | Loss: 0.364 | Acc: 89.700% (897/1000)\n",
      "Test Epoch: 0 | Loss: 0.363 | Acc: 89.364% (983/1100)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.500% (1074/1200)\n",
      "Test Epoch: 0 | Loss: 0.347 | Acc: 89.692% (1166/1300)\n",
      "Test Epoch: 0 | Loss: 0.334 | Acc: 90.143% (1262/1400)\n",
      "Test Epoch: 0 | Loss: 0.328 | Acc: 90.200% (1353/1500)\n",
      "Test Epoch: 0 | Loss: 0.335 | Acc: 90.188% (1443/1600)\n",
      "Test Epoch: 0 | Loss: 0.335 | Acc: 90.235% (1534/1700)\n",
      "Test Epoch: 0 | Loss: 0.337 | Acc: 90.167% (1623/1800)\n",
      "Test Epoch: 0 | Loss: 0.348 | Acc: 89.947% (1709/1900)\n",
      "Test Epoch: 0 | Loss: 0.350 | Acc: 89.900% (1798/2000)\n",
      "Test Epoch: 0 | Loss: 0.352 | Acc: 89.762% (1885/2100)\n",
      "Test Epoch: 0 | Loss: 0.354 | Acc: 89.682% (1973/2200)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.609% (2061/2300)\n",
      "Test Epoch: 0 | Loss: 0.362 | Acc: 89.625% (2151/2400)\n",
      "Test Epoch: 0 | Loss: 0.364 | Acc: 89.640% (2241/2500)\n",
      "Test Epoch: 0 | Loss: 0.369 | Acc: 89.423% (2325/2600)\n",
      "Test Epoch: 0 | Loss: 0.365 | Acc: 89.519% (2417/2700)\n",
      "Test Epoch: 0 | Loss: 0.364 | Acc: 89.500% (2506/2800)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.586% (2598/2900)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.567% (2687/3000)\n",
      "Test Epoch: 0 | Loss: 0.362 | Acc: 89.419% (2772/3100)\n",
      "Test Epoch: 0 | Loss: 0.361 | Acc: 89.500% (2864/3200)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.515% (2954/3300)\n",
      "Test Epoch: 0 | Loss: 0.361 | Acc: 89.441% (3041/3400)\n",
      "Test Epoch: 0 | Loss: 0.358 | Acc: 89.429% (3130/3500)\n",
      "Test Epoch: 0 | Loss: 0.358 | Acc: 89.500% (3222/3600)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.351% (3306/3700)\n",
      "Test Epoch: 0 | Loss: 0.366 | Acc: 89.237% (3391/3800)\n",
      "Test Epoch: 0 | Loss: 0.363 | Acc: 89.359% (3485/3900)\n",
      "Test Epoch: 0 | Loss: 0.361 | Acc: 89.325% (3573/4000)\n",
      "Test Epoch: 0 | Loss: 0.358 | Acc: 89.439% (3667/4100)\n",
      "Test Epoch: 0 | Loss: 0.357 | Acc: 89.500% (3759/4200)\n",
      "Test Epoch: 0 | Loss: 0.354 | Acc: 89.581% (3852/4300)\n",
      "Test Epoch: 0 | Loss: 0.355 | Acc: 89.545% (3940/4400)\n",
      "Test Epoch: 0 | Loss: 0.355 | Acc: 89.556% (4030/4500)\n",
      "Test Epoch: 0 | Loss: 0.354 | Acc: 89.500% (4117/4600)\n",
      "Test Epoch: 0 | Loss: 0.354 | Acc: 89.511% (4207/4700)\n",
      "Test Epoch: 0 | Loss: 0.360 | Acc: 89.375% (4290/4800)\n",
      "Test Epoch: 0 | Loss: 0.356 | Acc: 89.490% (4385/4900)\n",
      "Test Epoch: 0 | Loss: 0.359 | Acc: 89.480% (4474/5000)\n",
      "Test Epoch: 0 | Loss: 0.356 | Acc: 89.510% (4565/5100)\n",
      "Test Epoch: 0 | Loss: 0.358 | Acc: 89.423% (4650/5200)\n",
      "Test Epoch: 0 | Loss: 0.359 | Acc: 89.321% (4734/5300)\n",
      "Test Epoch: 0 | Loss: 0.357 | Acc: 89.352% (4825/5400)\n",
      "Test Epoch: 0 | Loss: 0.355 | Acc: 89.364% (4915/5500)\n",
      "Test Epoch: 0 | Loss: 0.353 | Acc: 89.482% (5011/5600)\n",
      "Test Epoch: 0 | Loss: 0.351 | Acc: 89.474% (5100/5700)\n",
      "Test Epoch: 0 | Loss: 0.350 | Acc: 89.500% (5191/5800)\n",
      "Test Epoch: 0 | Loss: 0.352 | Acc: 89.492% (5280/5900)\n",
      "Test Epoch: 0 | Loss: 0.352 | Acc: 89.500% (5370/6000)\n",
      "Test Epoch: 0 | Loss: 0.350 | Acc: 89.541% (5462/6100)\n",
      "Test Epoch: 0 | Loss: 0.350 | Acc: 89.565% (5553/6200)\n",
      "Test Epoch: 0 | Loss: 0.347 | Acc: 89.603% (5645/6300)\n",
      "Test Epoch: 0 | Loss: 0.344 | Acc: 89.703% (5741/6400)\n",
      "Test Epoch: 0 | Loss: 0.346 | Acc: 89.662% (5828/6500)\n",
      "Test Epoch: 0 | Loss: 0.344 | Acc: 89.682% (5919/6600)\n",
      "Test Epoch: 0 | Loss: 0.341 | Acc: 89.746% (6013/6700)\n",
      "Test Epoch: 0 | Loss: 0.343 | Acc: 89.706% (6100/6800)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.739% (6192/6900)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.729% (6281/7000)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.746% (6372/7100)\n",
      "Test Epoch: 0 | Loss: 0.341 | Acc: 89.778% (6464/7200)\n",
      "Test Epoch: 0 | Loss: 0.339 | Acc: 89.836% (6558/7300)\n",
      "Test Epoch: 0 | Loss: 0.338 | Acc: 89.905% (6653/7400)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.893% (6742/7500)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.908% (6833/7600)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.935% (6925/7700)\n",
      "Test Epoch: 0 | Loss: 0.335 | Acc: 89.962% (7017/7800)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.937% (7105/7900)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.950% (7196/8000)\n",
      "Test Epoch: 0 | Loss: 0.334 | Acc: 89.988% (7289/8100)\n",
      "Test Epoch: 0 | Loss: 0.334 | Acc: 89.976% (7378/8200)\n",
      "Test Epoch: 0 | Loss: 0.333 | Acc: 89.976% (7468/8300)\n",
      "Test Epoch: 0 | Loss: 0.333 | Acc: 89.964% (7557/8400)\n",
      "Test Epoch: 0 | Loss: 0.332 | Acc: 89.965% (7647/8500)\n",
      "Test Epoch: 0 | Loss: 0.336 | Acc: 89.872% (7729/8600)\n",
      "Test Epoch: 0 | Loss: 0.337 | Acc: 89.862% (7818/8700)\n",
      "Test Epoch: 0 | Loss: 0.339 | Acc: 89.830% (7905/8800)\n",
      "Test Epoch: 0 | Loss: 0.338 | Acc: 89.831% (7995/8900)\n",
      "Test Epoch: 0 | Loss: 0.339 | Acc: 89.789% (8081/9000)\n",
      "Test Epoch: 0 | Loss: 0.340 | Acc: 89.769% (8169/9100)\n",
      "Test Epoch: 0 | Loss: 0.340 | Acc: 89.793% (8261/9200)\n",
      "Test Epoch: 0 | Loss: 0.343 | Acc: 89.774% (8349/9300)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.787% (8440/9400)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.789% (8530/9500)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.771% (8618/9600)\n",
      "Test Epoch: 0 | Loss: 0.340 | Acc: 89.835% (8714/9700)\n",
      "Test Epoch: 0 | Loss: 0.340 | Acc: 89.827% (8803/9800)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.788% (8889/9900)\n",
      "Test Epoch: 0 | Loss: 0.342 | Acc: 89.770% (8977/10000)\n",
      "\n",
      "Epoch: 1\n",
      "Train Epoch: 1 | Loss: 0.161 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 1 | Loss: 0.187 | Acc: 92.188% (236/256)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 92.969% (357/384)\n",
      "Train Epoch: 1 | Loss: 0.161 | Acc: 93.945% (481/512)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 93.438% (598/640)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.010% (722/768)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.196% (844/896)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.336% (966/1024)\n",
      "Train Epoch: 1 | Loss: 0.177 | Acc: 94.184% (1085/1152)\n",
      "Train Epoch: 1 | Loss: 0.175 | Acc: 94.375% (1208/1280)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.531% (1331/1408)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.466% (1451/1536)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.591% (1574/1664)\n",
      "Train Epoch: 1 | Loss: 0.164 | Acc: 94.810% (1699/1792)\n",
      "Train Epoch: 1 | Loss: 0.158 | Acc: 95.052% (1825/1920)\n",
      "Train Epoch: 1 | Loss: 0.157 | Acc: 95.068% (1947/2048)\n",
      "Train Epoch: 1 | Loss: 0.160 | Acc: 94.853% (2064/2176)\n",
      "Train Epoch: 1 | Loss: 0.158 | Acc: 94.922% (2187/2304)\n",
      "Train Epoch: 1 | Loss: 0.159 | Acc: 94.901% (2308/2432)\n",
      "Train Epoch: 1 | Loss: 0.158 | Acc: 94.961% (2431/2560)\n",
      "Train Epoch: 1 | Loss: 0.159 | Acc: 94.978% (2553/2688)\n",
      "Train Epoch: 1 | Loss: 0.156 | Acc: 95.064% (2677/2816)\n",
      "Train Epoch: 1 | Loss: 0.157 | Acc: 95.041% (2798/2944)\n",
      "Train Epoch: 1 | Loss: 0.156 | Acc: 94.954% (2917/3072)\n",
      "Train Epoch: 1 | Loss: 0.158 | Acc: 94.844% (3035/3200)\n",
      "Train Epoch: 1 | Loss: 0.162 | Acc: 94.772% (3154/3328)\n",
      "Train Epoch: 1 | Loss: 0.161 | Acc: 94.792% (3276/3456)\n",
      "Train Epoch: 1 | Loss: 0.161 | Acc: 94.754% (3396/3584)\n",
      "Train Epoch: 1 | Loss: 0.160 | Acc: 94.801% (3519/3712)\n",
      "Train Epoch: 1 | Loss: 0.163 | Acc: 94.740% (3638/3840)\n",
      "Train Epoch: 1 | Loss: 0.163 | Acc: 94.758% (3760/3968)\n",
      "Train Epoch: 1 | Loss: 0.164 | Acc: 94.702% (3879/4096)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.673% (3999/4224)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.623% (4118/4352)\n",
      "Train Epoch: 1 | Loss: 0.164 | Acc: 94.643% (4240/4480)\n",
      "Train Epoch: 1 | Loss: 0.162 | Acc: 94.683% (4363/4608)\n",
      "Train Epoch: 1 | Loss: 0.164 | Acc: 94.637% (4482/4736)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.552% (4599/4864)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.591% (4722/4992)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.570% (4842/5120)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.474% (4958/5248)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.457% (5078/5376)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.440% (5198/5504)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.389% (5316/5632)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.375% (5436/5760)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.310% (5553/5888)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.315% (5674/6016)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.368% (5798/6144)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.420% (5922/6272)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.422% (6043/6400)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.439% (6165/6528)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.471% (6288/6656)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.428% (6406/6784)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.387% (6524/6912)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.460% (6650/7040)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.475% (6772/7168)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.518% (6896/7296)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.491% (7015/7424)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.492% (7136/7552)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.492% (7257/7680)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.467% (7376/7808)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.519% (7501/7936)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.556% (7625/8064)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.556% (7746/8192)\n",
      "Train Epoch: 1 | Loss: 0.164 | Acc: 94.591% (7870/8320)\n",
      "Train Epoch: 1 | Loss: 0.163 | Acc: 94.638% (7995/8448)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.566% (8110/8576)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.600% (8234/8704)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.543% (8350/8832)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.554% (8472/8960)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.553% (8593/9088)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.586% (8717/9216)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.553% (8835/9344)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.500% (8951/9472)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.521% (9074/9600)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.531% (9196/9728)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.541% (9318/9856)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.521% (9437/9984)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.482% (9554/10112)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.424% (9669/10240)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.435% (9791/10368)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.465% (9915/10496)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.475% (10037/10624)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.448% (10155/10752)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.467% (10278/10880)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.504% (10403/11008)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.504% (10524/11136)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.469% (10641/11264)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.470% (10762/11392)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.462% (10882/11520)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.480% (11005/11648)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.480% (11126/11776)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.472% (11246/11904)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.481% (11368/12032)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.507% (11492/12160)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.531% (11616/12288)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.539% (11738/12416)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.547% (11860/12544)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.531% (11979/12672)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.523% (12099/12800)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.500% (12217/12928)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.485% (12336/13056)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.493% (12458/13184)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.479% (12577/13312)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.494% (12700/13440)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.480% (12819/13568)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.495% (12942/13696)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.473% (13060/13824)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.495% (13184/13952)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.510% (13307/14080)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.524% (13430/14208)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.510% (13549/14336)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.511% (13670/14464)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.497% (13789/14592)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.524% (13914/14720)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.531% (14036/14848)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.525% (14156/14976)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.551% (14281/15104)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.538% (14400/15232)\n",
      "Train Epoch: 1 | Loss: 0.165 | Acc: 94.518% (14518/15360)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.480% (14633/15488)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.448% (14749/15616)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.449% (14870/15744)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.449% (14991/15872)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.450% (15112/16000)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.420% (15228/16128)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.414% (15348/16256)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.409% (15468/16384)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.410% (15589/16512)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.387% (15706/16640)\n",
      "Train Epoch: 1 | Loss: 0.166 | Acc: 94.394% (15828/16768)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.377% (15946/16896)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.349% (16062/17024)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.327% (16179/17152)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.329% (16300/17280)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.347% (16424/17408)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.343% (16544/17536)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.356% (16667/17664)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.351% (16787/17792)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.336% (16905/17920)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.326% (17024/18048)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.322% (17144/18176)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.313% (17263/18304)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.314% (17384/18432)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.327% (17507/18560)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.323% (17627/18688)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.313% (17746/18816)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.320% (17868/18944)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.327% (17990/19072)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.333% (18112/19200)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.345% (18235/19328)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.341% (18355/19456)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.337% (18475/19584)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.344% (18597/19712)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.350% (18719/19840)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.336% (18837/19968)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.347% (18960/20096)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.353% (19082/20224)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.354% (19203/20352)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.341% (19321/20480)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.366% (19447/20608)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.367% (19568/20736)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.373% (19690/20864)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.345% (19805/20992)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.361% (19929/21120)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.352% (20048/21248)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.339% (20166/21376)\n",
      "Train Epoch: 1 | Loss: 0.167 | Acc: 94.345% (20288/21504)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.342% (20408/21632)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.338% (20528/21760)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.344% (20650/21888)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.331% (20768/22016)\n",
      "Train Epoch: 1 | Loss: 0.168 | Acc: 94.310% (20884/22144)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.302% (21003/22272)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.281% (21119/22400)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.265% (21236/22528)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.275% (21359/22656)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.264% (21477/22784)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.278% (21601/22912)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.284% (21723/23040)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.290% (21845/23168)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.282% (21964/23296)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.288% (22086/23424)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.302% (22210/23552)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.295% (22329/23680)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.304% (22452/23808)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.297% (22571/23936)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.299% (22692/24064)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.287% (22810/24192)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.301% (22934/24320)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.294% (23053/24448)\n",
      "Train Epoch: 1 | Loss: 0.169 | Acc: 94.295% (23174/24576)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.272% (23289/24704)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.278% (23411/24832)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.279% (23532/24960)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.272% (23651/25088)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.254% (23767/25216)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.251% (23887/25344)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.256% (24009/25472)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.254% (24129/25600)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.267% (24253/25728)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.257% (24371/25856)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.250% (24490/25984)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.244% (24609/26112)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.230% (24726/26240)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.228% (24846/26368)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.233% (24968/26496)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.246% (25092/26624)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.243% (25212/26752)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.241% (25332/26880)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.239% (25452/27008)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.236% (25572/27136)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.238% (25693/27264)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.221% (25809/27392)\n",
      "Train Epoch: 1 | Loss: 0.170 | Acc: 94.219% (25929/27520)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.213% (26048/27648)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.207% (26167/27776)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.194% (26284/27904)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.178% (26400/28032)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.165% (26517/28160)\n",
      "Train Epoch: 1 | Loss: 0.171 | Acc: 94.181% (26642/28288)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.165% (26758/28416)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.163% (26878/28544)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.169% (27000/28672)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.167% (27120/28800)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.161% (27239/28928)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.160% (27359/29056)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.165% (27481/29184)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.146% (27596/29312)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.147% (27717/29440)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.146% (27837/29568)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.141% (27956/29696)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.139% (28076/29824)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.144% (28198/29952)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.139% (28317/30080)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.134% (28436/30208)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.136% (28557/30336)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.134% (28677/30464)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.119% (28793/30592)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.128% (28916/30720)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.142% (29041/30848)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.134% (29159/30976)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.139% (29281/31104)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.137% (29401/31232)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.136% (29521/31360)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.128% (29639/31488)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.136% (29762/31616)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.141% (29884/31744)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.148% (30007/31872)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.141% (30125/32000)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.130% (30242/32128)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.138% (30365/32256)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.130% (30483/32384)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.128% (30603/32512)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.127% (30723/32640)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.135% (30846/32768)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.145% (30970/32896)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.135% (31087/33024)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.130% (31206/33152)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.129% (31326/33280)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.139% (31450/33408)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.138% (31570/33536)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.124% (31686/33664)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.129% (31808/33792)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.130% (31929/33920)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.141% (32053/34048)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.145% (32175/34176)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.138% (32293/34304)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.113% (32405/34432)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.120% (32528/34560)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.122% (32649/34688)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.123% (32770/34816)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.133% (32894/34944)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.141% (33017/35072)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.134% (33135/35200)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.141% (33258/35328)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.125% (33373/35456)\n",
      "Train Epoch: 1 | Loss: 0.174 | Acc: 94.115% (33490/35584)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.128% (33615/35712)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.127% (33735/35840)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.131% (33857/35968)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.143% (33982/36096)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.150% (34105/36224)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.149% (34225/36352)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.145% (34344/36480)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.138% (34462/36608)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.150% (34587/36736)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.154% (34709/36864)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.166% (34834/36992)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.176% (34958/37120)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.182% (35081/37248)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.183% (35202/37376)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.179% (35321/37504)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.173% (35439/37632)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.174% (35560/37760)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.151% (35672/37888)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.155% (35794/38016)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.148% (35912/38144)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.163% (36038/38272)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.159% (36157/38400)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.160% (36278/38528)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.156% (36397/38656)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.147% (36514/38784)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.138% (36631/38912)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.142% (36753/39040)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.146% (36875/39168)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.144% (36995/39296)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.151% (37118/39424)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.152% (37239/39552)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.151% (37359/39680)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.152% (37480/39808)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.148% (37599/39936)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.152% (37721/40064)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.148% (37840/40192)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.149% (37961/40320)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.148% (38081/40448)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.139% (38198/40576)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.148% (38322/40704)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.147% (38442/40832)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.141% (38560/40960)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.139% (38680/41088)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.136% (38799/41216)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.137% (38920/41344)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.126% (39036/41472)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.127% (39157/41600)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.136% (39281/41728)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.135% (39401/41856)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.131% (39520/41984)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.130% (39640/42112)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.131% (39761/42240)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.135% (39883/42368)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.141% (40006/42496)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.139% (40126/42624)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.134% (40244/42752)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.132% (40364/42880)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.124% (40481/43008)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.130% (40604/43136)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.141% (40729/43264)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.146% (40852/43392)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.148% (40973/43520)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.137% (41089/43648)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.134% (41208/43776)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.130% (41327/43904)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.134% (41449/44032)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.135% (41570/44160)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.136% (41691/44288)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.139% (41813/44416)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.138% (41933/44544)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.144% (42056/44672)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.138% (42174/44800)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.140% (42295/44928)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.134% (42413/45056)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.117% (42526/45184)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.119% (42647/45312)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.109% (42763/45440)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.108% (42883/45568)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.102% (43001/45696)\n",
      "Train Epoch: 1 | Loss: 0.172 | Acc: 94.101% (43121/45824)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.103% (43242/45952)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.093% (43358/46080)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.096% (43480/46208)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.095% (43600/46336)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.090% (43718/46464)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.083% (43835/46592)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.080% (43954/46720)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.083% (44076/46848)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.080% (44195/46976)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.085% (44318/47104)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.080% (44436/47232)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.086% (44559/47360)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.085% (44679/47488)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.084% (44799/47616)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.077% (44916/47744)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.084% (45040/47872)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.092% (45164/48000)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.091% (45284/48128)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.094% (45406/48256)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.101% (45530/48384)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.092% (45646/48512)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.089% (45765/48640)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.097% (45889/48768)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.098% (46010/48896)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.091% (46127/49024)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.096% (46250/49152)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.093% (46369/49280)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.098% (46492/49408)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.099% (46613/49536)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.102% (46735/49664)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.093% (46851/49792)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.093% (46971/49920)\n",
      "Train Epoch: 1 | Loss: 0.173 | Acc: 94.100% (47050/50000)\n",
      "Test Epoch: 1 | Loss: 0.309 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 1 | Loss: 0.342 | Acc: 89.500% (179/200)\n",
      "Test Epoch: 1 | Loss: 0.339 | Acc: 89.667% (269/300)\n",
      "Test Epoch: 1 | Loss: 0.363 | Acc: 89.250% (357/400)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.000% (450/500)\n",
      "Test Epoch: 1 | Loss: 0.287 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 1 | Loss: 0.296 | Acc: 91.286% (639/700)\n",
      "Test Epoch: 1 | Loss: 0.320 | Acc: 90.000% (720/800)\n",
      "Test Epoch: 1 | Loss: 0.317 | Acc: 90.222% (812/900)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.200% (902/1000)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.273% (993/1100)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.250% (1083/1200)\n",
      "Test Epoch: 1 | Loss: 0.316 | Acc: 90.385% (1175/1300)\n",
      "Test Epoch: 1 | Loss: 0.315 | Acc: 90.286% (1264/1400)\n",
      "Test Epoch: 1 | Loss: 0.306 | Acc: 90.333% (1355/1500)\n",
      "Test Epoch: 1 | Loss: 0.312 | Acc: 90.375% (1446/1600)\n",
      "Test Epoch: 1 | Loss: 0.310 | Acc: 90.529% (1539/1700)\n",
      "Test Epoch: 1 | Loss: 0.308 | Acc: 90.667% (1632/1800)\n",
      "Test Epoch: 1 | Loss: 0.315 | Acc: 90.316% (1716/1900)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.100% (1802/2000)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.000% (1890/2100)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 89.909% (1978/2200)\n",
      "Test Epoch: 1 | Loss: 0.326 | Acc: 89.913% (2068/2300)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.833% (2156/2400)\n",
      "Test Epoch: 1 | Loss: 0.333 | Acc: 89.720% (2243/2500)\n",
      "Test Epoch: 1 | Loss: 0.339 | Acc: 89.577% (2329/2600)\n",
      "Test Epoch: 1 | Loss: 0.332 | Acc: 89.815% (2425/2700)\n",
      "Test Epoch: 1 | Loss: 0.336 | Acc: 89.750% (2513/2800)\n",
      "Test Epoch: 1 | Loss: 0.337 | Acc: 89.828% (2605/2900)\n",
      "Test Epoch: 1 | Loss: 0.341 | Acc: 89.667% (2690/3000)\n",
      "Test Epoch: 1 | Loss: 0.344 | Acc: 89.516% (2775/3100)\n",
      "Test Epoch: 1 | Loss: 0.342 | Acc: 89.500% (2864/3200)\n",
      "Test Epoch: 1 | Loss: 0.337 | Acc: 89.636% (2958/3300)\n",
      "Test Epoch: 1 | Loss: 0.336 | Acc: 89.676% (3049/3400)\n",
      "Test Epoch: 1 | Loss: 0.336 | Acc: 89.686% (3139/3500)\n",
      "Test Epoch: 1 | Loss: 0.335 | Acc: 89.750% (3231/3600)\n",
      "Test Epoch: 1 | Loss: 0.336 | Acc: 89.757% (3321/3700)\n",
      "Test Epoch: 1 | Loss: 0.341 | Acc: 89.737% (3410/3800)\n",
      "Test Epoch: 1 | Loss: 0.342 | Acc: 89.667% (3497/3900)\n",
      "Test Epoch: 1 | Loss: 0.341 | Acc: 89.725% (3589/4000)\n",
      "Test Epoch: 1 | Loss: 0.344 | Acc: 89.610% (3674/4100)\n",
      "Test Epoch: 1 | Loss: 0.342 | Acc: 89.643% (3765/4200)\n",
      "Test Epoch: 1 | Loss: 0.338 | Acc: 89.721% (3858/4300)\n",
      "Test Epoch: 1 | Loss: 0.335 | Acc: 89.864% (3954/4400)\n",
      "Test Epoch: 1 | Loss: 0.336 | Acc: 89.911% (4046/4500)\n",
      "Test Epoch: 1 | Loss: 0.333 | Acc: 89.957% (4138/4600)\n",
      "Test Epoch: 1 | Loss: 0.333 | Acc: 89.957% (4228/4700)\n",
      "Test Epoch: 1 | Loss: 0.334 | Acc: 89.938% (4317/4800)\n",
      "Test Epoch: 1 | Loss: 0.332 | Acc: 90.000% (4410/4900)\n",
      "Test Epoch: 1 | Loss: 0.335 | Acc: 89.960% (4498/5000)\n",
      "Test Epoch: 1 | Loss: 0.332 | Acc: 90.020% (4591/5100)\n",
      "Test Epoch: 1 | Loss: 0.333 | Acc: 89.962% (4678/5200)\n",
      "Test Epoch: 1 | Loss: 0.335 | Acc: 89.849% (4762/5300)\n",
      "Test Epoch: 1 | Loss: 0.334 | Acc: 89.815% (4850/5400)\n",
      "Test Epoch: 1 | Loss: 0.332 | Acc: 89.855% (4942/5500)\n",
      "Test Epoch: 1 | Loss: 0.329 | Acc: 89.964% (5038/5600)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.965% (5128/5700)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.966% (5218/5800)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.949% (5307/5900)\n",
      "Test Epoch: 1 | Loss: 0.329 | Acc: 89.933% (5396/6000)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.984% (5489/6100)\n",
      "Test Epoch: 1 | Loss: 0.326 | Acc: 90.081% (5585/6200)\n",
      "Test Epoch: 1 | Loss: 0.325 | Acc: 90.079% (5675/6300)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.172% (5771/6400)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.169% (5861/6500)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.197% (5953/6600)\n",
      "Test Epoch: 1 | Loss: 0.319 | Acc: 90.239% (6046/6700)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.206% (6134/6800)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.174% (6222/6900)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.129% (6309/7000)\n",
      "Test Epoch: 1 | Loss: 0.325 | Acc: 90.141% (6400/7100)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.153% (6491/7200)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.164% (6582/7300)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.189% (6674/7400)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.187% (6764/7500)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.224% (6857/7600)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.221% (6947/7700)\n",
      "Test Epoch: 1 | Loss: 0.320 | Acc: 90.218% (7037/7800)\n",
      "Test Epoch: 1 | Loss: 0.321 | Acc: 90.190% (7125/7900)\n",
      "Test Epoch: 1 | Loss: 0.321 | Acc: 90.188% (7215/8000)\n",
      "Test Epoch: 1 | Loss: 0.320 | Acc: 90.235% (7309/8100)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.134% (7391/8200)\n",
      "Test Epoch: 1 | Loss: 0.322 | Acc: 90.108% (7479/8300)\n",
      "Test Epoch: 1 | Loss: 0.323 | Acc: 90.036% (7563/8400)\n",
      "Test Epoch: 1 | Loss: 0.324 | Acc: 90.024% (7652/8500)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.919% (7733/8600)\n",
      "Test Epoch: 1 | Loss: 0.326 | Acc: 89.954% (7826/8700)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.932% (7914/8800)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.944% (8005/8900)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.956% (8096/9000)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.967% (8187/9100)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 90.000% (8280/9200)\n",
      "Test Epoch: 1 | Loss: 0.330 | Acc: 89.946% (8365/9300)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 89.989% (8459/9400)\n",
      "Test Epoch: 1 | Loss: 0.328 | Acc: 90.011% (8551/9500)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 90.021% (8642/9600)\n",
      "Test Epoch: 1 | Loss: 0.326 | Acc: 90.021% (8732/9700)\n",
      "Test Epoch: 1 | Loss: 0.326 | Acc: 90.010% (8821/9800)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.980% (8908/9900)\n",
      "Test Epoch: 1 | Loss: 0.327 | Acc: 89.990% (8999/10000)\n",
      "\n",
      "Epoch: 2\n",
      "Train Epoch: 2 | Loss: 0.201 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.312% (244/256)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 2 | Loss: 0.139 | Acc: 95.508% (489/512)\n",
      "Train Epoch: 2 | Loss: 0.135 | Acc: 95.781% (613/640)\n",
      "Train Epoch: 2 | Loss: 0.134 | Acc: 95.312% (732/768)\n",
      "Train Epoch: 2 | Loss: 0.138 | Acc: 95.201% (853/896)\n",
      "Train Epoch: 2 | Loss: 0.138 | Acc: 95.508% (978/1024)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.965% (1094/1152)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.078% (1217/1280)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.957% (1337/1408)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.987% (1459/1536)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 95.132% (1583/1664)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.368% (1709/1792)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 95.260% (1829/1920)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 95.312% (1952/2048)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 95.312% (2074/2176)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.399% (2198/2304)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.436% (2321/2432)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.352% (2441/2560)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.350% (2563/2688)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.277% (2683/2816)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.279% (2805/2944)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.345% (2929/3072)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.375% (3052/3200)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.312% (3172/3328)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.284% (3293/3456)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.229% (3413/3584)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.312% (3538/3712)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.312% (3660/3840)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.388% (3785/3968)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.312% (3904/4096)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.289% (4025/4224)\n",
      "Train Epoch: 2 | Loss: 0.149 | Acc: 95.312% (4148/4352)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.268% (4268/4480)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.204% (4387/4608)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.228% (4510/4736)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.251% (4633/4864)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.212% (4753/4992)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.156% (4872/5120)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 95.065% (4989/5248)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 95.071% (5111/5376)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.076% (5233/5504)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.028% (5352/5632)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.035% (5474/5760)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.973% (5592/5888)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 95.013% (5716/6016)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.036% (5839/6144)\n",
      "Train Epoch: 2 | Loss: 0.151 | Acc: 95.041% (5961/6272)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.078% (6085/6400)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.052% (6205/6528)\n",
      "Train Epoch: 2 | Loss: 0.150 | Acc: 95.057% (6327/6656)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.959% (6442/6784)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.965% (6564/6912)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.943% (6684/7040)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.950% (6806/7168)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.942% (6927/7296)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.922% (7047/7424)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.902% (7167/7552)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.883% (7287/7680)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.877% (7408/7808)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.796% (7523/7936)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.754% (7641/8064)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.763% (7763/8192)\n",
      "Train Epoch: 2 | Loss: 0.155 | Acc: 94.820% (7889/8320)\n",
      "Train Epoch: 2 | Loss: 0.155 | Acc: 94.804% (8009/8448)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.764% (8127/8576)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.784% (8250/8704)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.814% (8374/8832)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.833% (8497/8960)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.817% (8617/9088)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.824% (8739/9216)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.831% (8861/9344)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.869% (8986/9472)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.833% (9104/9600)\n",
      "Train Epoch: 2 | Loss: 0.155 | Acc: 94.881% (9230/9728)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.886% (9352/9856)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.892% (9474/9984)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.897% (9596/10112)\n",
      "Train Epoch: 2 | Loss: 0.152 | Acc: 94.932% (9721/10240)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.917% (9841/10368)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.912% (9962/10496)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.927% (10085/10624)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.931% (10207/10752)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.890% (10324/10880)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.904% (10447/11008)\n",
      "Train Epoch: 2 | Loss: 0.153 | Acc: 94.935% (10572/11136)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.877% (10687/11264)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.838% (10804/11392)\n",
      "Train Epoch: 2 | Loss: 0.155 | Acc: 94.818% (10923/11520)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.815% (11044/11648)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.837% (11168/11776)\n",
      "Train Epoch: 2 | Loss: 0.154 | Acc: 94.825% (11288/11904)\n",
      "Train Epoch: 2 | Loss: 0.155 | Acc: 94.797% (11406/12032)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.762% (11523/12160)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.751% (11643/12288)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.741% (11763/12416)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.731% (11883/12544)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.721% (12003/12672)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.734% (12126/12800)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.732% (12247/12928)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.715% (12366/13056)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.706% (12486/13184)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.697% (12606/13312)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.710% (12729/13440)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.701% (12849/13568)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.714% (12972/13696)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.719% (13094/13824)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.732% (13217/13952)\n",
      "Train Epoch: 2 | Loss: 0.156 | Acc: 94.709% (13335/14080)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.672% (13451/14208)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.678% (13573/14336)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.683% (13695/14464)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.668% (13814/14592)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.674% (13936/14720)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.679% (14058/14848)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.692% (14181/14976)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.684% (14301/15104)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.676% (14421/15232)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.642% (14537/15360)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.628% (14656/15488)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.640% (14779/15616)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.658% (14903/15744)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.632% (15020/15872)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.625% (15140/16000)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.612% (15259/16128)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.599% (15378/16256)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.598% (15499/16384)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.616% (15623/16512)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.603% (15742/16640)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.597% (15862/16768)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.596% (15983/16896)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.584% (16102/17024)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.595% (16225/17152)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.601% (16347/17280)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.600% (16468/17408)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.622% (16593/17536)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.627% (16715/17664)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.644% (16839/17792)\n",
      "Train Epoch: 2 | Loss: 0.157 | Acc: 94.660% (16963/17920)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.625% (17078/18048)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.592% (17193/18176)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.591% (17314/18304)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.586% (17434/18432)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.591% (17556/18560)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.579% (17675/18688)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.563% (17793/18816)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.547% (17911/18944)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.557% (18034/19072)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.568% (18157/19200)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.562% (18277/19328)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.531% (18392/19456)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.541% (18515/19584)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.557% (18639/19712)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.556% (18760/19840)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.551% (18880/19968)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.546% (19000/20096)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.531% (19118/20224)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.517% (19236/20352)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.521% (19358/20480)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.531% (19481/20608)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.531% (19602/20736)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.541% (19725/20864)\n",
      "Train Epoch: 2 | Loss: 0.158 | Acc: 94.546% (19847/20992)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.536% (19966/21120)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.527% (20085/21248)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.503% (20201/21376)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.508% (20323/21504)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.527% (20448/21632)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.517% (20567/21760)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.518% (20688/21888)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.513% (20808/22016)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.518% (20930/22144)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.518% (21051/22272)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.513% (21171/22400)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.522% (21294/22528)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.500% (21410/22656)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.505% (21532/22784)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.523% (21657/22912)\n",
      "Train Epoch: 2 | Loss: 0.159 | Acc: 94.501% (21773/23040)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.484% (21890/23168)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.480% (22010/23296)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.489% (22133/23424)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.476% (22251/23552)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.455% (22367/23680)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.460% (22489/23808)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.452% (22608/23936)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.448% (22728/24064)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.453% (22850/24192)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.449% (22970/24320)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.437% (23088/24448)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.430% (23207/24576)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.430% (23328/24704)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.431% (23449/24832)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.435% (23571/24960)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.452% (23696/25088)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.452% (23817/25216)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.460% (23940/25344)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.449% (24058/25472)\n",
      "Train Epoch: 2 | Loss: 0.160 | Acc: 94.445% (24178/25600)\n",
      "Train Epoch: 2 | Loss: 0.161 | Acc: 94.422% (24293/25728)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.400% (24408/25856)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.389% (24526/25984)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.390% (24647/26112)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.394% (24769/26240)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.383% (24887/26368)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.369% (25004/26496)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.370% (25125/26624)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.356% (25242/26752)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.353% (25362/26880)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.346% (25481/27008)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.340% (25600/27136)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.348% (25723/27264)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.349% (25844/27392)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.350% (25965/27520)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.361% (26089/27648)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.362% (26210/27776)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.377% (26335/27904)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.378% (26456/28032)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.386% (26579/28160)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.390% (26701/28288)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.387% (26821/28416)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.367% (26936/28544)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.364% (27056/28672)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.354% (27174/28800)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.355% (27295/28928)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.339% (27411/29056)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.336% (27531/29184)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.344% (27654/29312)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.344% (27775/29440)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.328% (27891/29568)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.339% (28015/29696)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.327% (28132/29824)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.344% (28258/29952)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.348% (28380/30080)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.349% (28501/30208)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.350% (28622/30336)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.351% (28743/30464)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.358% (28866/30592)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.362% (28988/30720)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.366% (29110/30848)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.367% (29231/30976)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.351% (29347/31104)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.362% (29471/31232)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.365% (29593/31360)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.366% (29714/31488)\n",
      "Train Epoch: 2 | Loss: 0.162 | Acc: 94.360% (29833/31616)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.339% (29947/31744)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.330% (30065/31872)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.331% (30186/32000)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.332% (30307/32128)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.311% (30421/32256)\n",
      "Train Epoch: 2 | Loss: 0.163 | Acc: 94.324% (30546/32384)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.291% (30656/32512)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.289% (30776/32640)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.281% (30894/32768)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.273% (31012/32896)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.274% (31133/33024)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.266% (31251/33152)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.267% (31372/33280)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.268% (31493/33408)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.272% (31615/33536)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.270% (31735/33664)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.274% (31857/33792)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.281% (31980/33920)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.282% (32101/34048)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.288% (32224/34176)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.292% (32346/34304)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.281% (32463/34432)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.271% (32580/34560)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.275% (32702/34688)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.267% (32820/34816)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.279% (32945/34944)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.260% (33059/35072)\n",
      "Train Epoch: 2 | Loss: 0.164 | Acc: 94.261% (33180/35200)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.254% (33298/35328)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.246% (33416/35456)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.236% (33533/35584)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.243% (33656/35712)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.241% (33776/35840)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.239% (33896/35968)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.240% (34017/36096)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.233% (34135/36224)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.242% (34259/36352)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.243% (34380/36480)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.231% (34496/36608)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.229% (34616/36736)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.238% (34740/36864)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.239% (34861/36992)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.224% (34976/37120)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.220% (35095/37248)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.210% (35212/37376)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.225% (35338/37504)\n",
      "Train Epoch: 2 | Loss: 0.165 | Acc: 94.226% (35459/37632)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.227% (35580/37760)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.225% (35700/37888)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.213% (35816/38016)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.198% (35931/38144)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.197% (36051/38272)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.201% (36173/38400)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.196% (36292/38528)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.195% (36412/38656)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.206% (36537/38784)\n",
      "Train Epoch: 2 | Loss: 0.166 | Acc: 94.205% (36657/38912)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.191% (36772/39040)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.184% (36890/39168)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.170% (37005/39296)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.171% (37126/39424)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.175% (37248/39552)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.176% (37369/39680)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.167% (37486/39808)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.173% (37609/39936)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.174% (37730/40064)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.168% (37848/40192)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.174% (37971/40320)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.170% (38090/40448)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.179% (38214/40576)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.173% (38332/40704)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.179% (38455/40832)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.172% (38573/40960)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.176% (38695/41088)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.177% (38816/41216)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.166% (38932/41344)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.177% (39057/41472)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.163% (39172/41600)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.160% (39291/41728)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.163% (39413/41856)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.169% (39536/41984)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.168% (39656/42112)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.162% (39774/42240)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.165% (39896/42368)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.169% (40018/42496)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.170% (40139/42624)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.155% (40253/42752)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.170% (40380/42880)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.164% (40498/43008)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.167% (40620/43136)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.164% (40739/43264)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.174% (40864/43392)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.170% (40983/43520)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.174% (41105/43648)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.189% (41232/43776)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.190% (41353/43904)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.193% (41475/44032)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.198% (41598/44160)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.195% (41717/44288)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.203% (41841/44416)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.188% (41955/44544)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.180% (42072/44672)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.179% (42192/44800)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.175% (42311/44928)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.167% (42428/45056)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.168% (42549/45184)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.172% (42671/45312)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.162% (42787/45440)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.169% (42911/45568)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.177% (43035/45696)\n",
      "Train Epoch: 2 | Loss: 0.167 | Acc: 94.165% (43150/45824)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.155% (43266/45952)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.151% (43385/46080)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.153% (43506/46208)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.154% (43627/46336)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.148% (43745/46464)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.147% (43865/46592)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.142% (43983/46720)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.145% (44105/46848)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.148% (44227/46976)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.147% (44347/47104)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.142% (44465/47232)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.139% (44584/47360)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.133% (44702/47488)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.130% (44821/47616)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.133% (44943/47744)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.134% (45064/47872)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.135% (45185/48000)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.130% (45303/48128)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.133% (45425/48256)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.130% (45544/48384)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.129% (45664/48512)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.132% (45786/48640)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.131% (45906/48768)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.126% (46024/48896)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.129% (46146/49024)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.130% (46267/49152)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.129% (46387/49280)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.133% (46509/49408)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.125% (46626/49536)\n",
      "Train Epoch: 2 | Loss: 0.168 | Acc: 94.118% (46743/49664)\n",
      "Train Epoch: 2 | Loss: 0.169 | Acc: 94.101% (46855/49792)\n",
      "Train Epoch: 2 | Loss: 0.169 | Acc: 94.097% (46973/49920)\n",
      "Train Epoch: 2 | Loss: 0.169 | Acc: 94.096% (47048/50000)\n",
      "Test Epoch: 2 | Loss: 0.292 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 2 | Loss: 0.287 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 2 | Loss: 0.291 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 2 | Loss: 0.268 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 2 | Loss: 0.255 | Acc: 90.200% (451/500)\n",
      "Test Epoch: 2 | Loss: 0.241 | Acc: 90.833% (545/600)\n",
      "Test Epoch: 2 | Loss: 0.274 | Acc: 90.286% (632/700)\n",
      "Test Epoch: 2 | Loss: 0.282 | Acc: 89.750% (718/800)\n",
      "Test Epoch: 2 | Loss: 0.292 | Acc: 90.000% (810/900)\n",
      "Test Epoch: 2 | Loss: 0.293 | Acc: 90.000% (900/1000)\n",
      "Test Epoch: 2 | Loss: 0.305 | Acc: 89.727% (987/1100)\n",
      "Test Epoch: 2 | Loss: 0.323 | Acc: 89.417% (1073/1200)\n",
      "Test Epoch: 2 | Loss: 0.310 | Acc: 89.769% (1167/1300)\n",
      "Test Epoch: 2 | Loss: 0.303 | Acc: 90.071% (1261/1400)\n",
      "Test Epoch: 2 | Loss: 0.307 | Acc: 90.067% (1351/1500)\n",
      "Test Epoch: 2 | Loss: 0.304 | Acc: 90.125% (1442/1600)\n",
      "Test Epoch: 2 | Loss: 0.307 | Acc: 90.235% (1534/1700)\n",
      "Test Epoch: 2 | Loss: 0.307 | Acc: 90.056% (1621/1800)\n",
      "Test Epoch: 2 | Loss: 0.316 | Acc: 89.789% (1706/1900)\n",
      "Test Epoch: 2 | Loss: 0.324 | Acc: 89.700% (1794/2000)\n",
      "Test Epoch: 2 | Loss: 0.329 | Acc: 89.476% (1879/2100)\n",
      "Test Epoch: 2 | Loss: 0.331 | Acc: 89.500% (1969/2200)\n",
      "Test Epoch: 2 | Loss: 0.335 | Acc: 89.565% (2060/2300)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.667% (2152/2400)\n",
      "Test Epoch: 2 | Loss: 0.341 | Acc: 89.600% (2240/2500)\n",
      "Test Epoch: 2 | Loss: 0.351 | Acc: 89.500% (2327/2600)\n",
      "Test Epoch: 2 | Loss: 0.344 | Acc: 89.741% (2423/2700)\n",
      "Test Epoch: 2 | Loss: 0.344 | Acc: 89.750% (2513/2800)\n",
      "Test Epoch: 2 | Loss: 0.341 | Acc: 89.897% (2607/2900)\n",
      "Test Epoch: 2 | Loss: 0.342 | Acc: 89.700% (2691/3000)\n",
      "Test Epoch: 2 | Loss: 0.346 | Acc: 89.516% (2775/3100)\n",
      "Test Epoch: 2 | Loss: 0.346 | Acc: 89.531% (2865/3200)\n",
      "Test Epoch: 2 | Loss: 0.341 | Acc: 89.606% (2957/3300)\n",
      "Test Epoch: 2 | Loss: 0.339 | Acc: 89.735% (3051/3400)\n",
      "Test Epoch: 2 | Loss: 0.340 | Acc: 89.686% (3139/3500)\n",
      "Test Epoch: 2 | Loss: 0.336 | Acc: 89.889% (3236/3600)\n",
      "Test Epoch: 2 | Loss: 0.337 | Acc: 89.892% (3326/3700)\n",
      "Test Epoch: 2 | Loss: 0.336 | Acc: 89.895% (3416/3800)\n",
      "Test Epoch: 2 | Loss: 0.335 | Acc: 89.949% (3508/3900)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.975% (3599/4000)\n",
      "Test Epoch: 2 | Loss: 0.335 | Acc: 89.927% (3687/4100)\n",
      "Test Epoch: 2 | Loss: 0.337 | Acc: 89.833% (3773/4200)\n",
      "Test Epoch: 2 | Loss: 0.332 | Acc: 89.953% (3868/4300)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.955% (3958/4400)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.911% (4046/4500)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.826% (4132/4600)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.830% (4222/4700)\n",
      "Test Epoch: 2 | Loss: 0.335 | Acc: 89.750% (4308/4800)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.776% (4399/4900)\n",
      "Test Epoch: 2 | Loss: 0.335 | Acc: 89.760% (4488/5000)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.765% (4578/5100)\n",
      "Test Epoch: 2 | Loss: 0.336 | Acc: 89.712% (4665/5200)\n",
      "Test Epoch: 2 | Loss: 0.337 | Acc: 89.660% (4752/5300)\n",
      "Test Epoch: 2 | Loss: 0.336 | Acc: 89.667% (4842/5400)\n",
      "Test Epoch: 2 | Loss: 0.337 | Acc: 89.600% (4928/5500)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.679% (5022/5600)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.632% (5109/5700)\n",
      "Test Epoch: 2 | Loss: 0.332 | Acc: 89.655% (5200/5800)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.627% (5288/5900)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.583% (5375/6000)\n",
      "Test Epoch: 2 | Loss: 0.334 | Acc: 89.574% (5464/6100)\n",
      "Test Epoch: 2 | Loss: 0.333 | Acc: 89.597% (5555/6200)\n",
      "Test Epoch: 2 | Loss: 0.331 | Acc: 89.698% (5651/6300)\n",
      "Test Epoch: 2 | Loss: 0.329 | Acc: 89.766% (5745/6400)\n",
      "Test Epoch: 2 | Loss: 0.332 | Acc: 89.692% (5830/6500)\n",
      "Test Epoch: 2 | Loss: 0.331 | Acc: 89.742% (5923/6600)\n",
      "Test Epoch: 2 | Loss: 0.329 | Acc: 89.791% (6016/6700)\n",
      "Test Epoch: 2 | Loss: 0.330 | Acc: 89.779% (6105/6800)\n",
      "Test Epoch: 2 | Loss: 0.330 | Acc: 89.783% (6195/6900)\n",
      "Test Epoch: 2 | Loss: 0.331 | Acc: 89.757% (6283/7000)\n",
      "Test Epoch: 2 | Loss: 0.332 | Acc: 89.746% (6372/7100)\n",
      "Test Epoch: 2 | Loss: 0.330 | Acc: 89.764% (6463/7200)\n",
      "Test Epoch: 2 | Loss: 0.328 | Acc: 89.822% (6557/7300)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.892% (6652/7400)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.920% (6744/7500)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.934% (6835/7600)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.961% (6927/7700)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.974% (7018/7800)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.937% (7105/7900)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.938% (7195/8000)\n",
      "Test Epoch: 2 | Loss: 0.324 | Acc: 89.988% (7289/8100)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.939% (7375/8200)\n",
      "Test Epoch: 2 | Loss: 0.324 | Acc: 89.952% (7466/8300)\n",
      "Test Epoch: 2 | Loss: 0.323 | Acc: 89.940% (7555/8400)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.894% (7641/8500)\n",
      "Test Epoch: 2 | Loss: 0.327 | Acc: 89.837% (7726/8600)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.862% (7818/8700)\n",
      "Test Epoch: 2 | Loss: 0.327 | Acc: 89.795% (7902/8800)\n",
      "Test Epoch: 2 | Loss: 0.327 | Acc: 89.820% (7994/8900)\n",
      "Test Epoch: 2 | Loss: 0.328 | Acc: 89.822% (8084/9000)\n",
      "Test Epoch: 2 | Loss: 0.327 | Acc: 89.868% (8178/9100)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.880% (8269/9200)\n",
      "Test Epoch: 2 | Loss: 0.327 | Acc: 89.839% (8355/9300)\n",
      "Test Epoch: 2 | Loss: 0.326 | Acc: 89.883% (8449/9400)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.905% (8541/9500)\n",
      "Test Epoch: 2 | Loss: 0.325 | Acc: 89.885% (8629/9600)\n",
      "Test Epoch: 2 | Loss: 0.323 | Acc: 89.959% (8726/9700)\n",
      "Test Epoch: 2 | Loss: 0.322 | Acc: 89.990% (8819/9800)\n",
      "Test Epoch: 2 | Loss: 0.323 | Acc: 89.980% (8908/9900)\n",
      "Test Epoch: 2 | Loss: 0.323 | Acc: 89.920% (8992/10000)\n",
      "\n",
      "Epoch: 3\n",
      "Train Epoch: 3 | Loss: 0.217 | Acc: 92.188% (118/128)\n",
      "Train Epoch: 3 | Loss: 0.163 | Acc: 94.531% (242/256)\n",
      "Train Epoch: 3 | Loss: 0.143 | Acc: 95.573% (367/384)\n",
      "Train Epoch: 3 | Loss: 0.139 | Acc: 95.312% (488/512)\n",
      "Train Epoch: 3 | Loss: 0.151 | Acc: 95.000% (608/640)\n",
      "Train Epoch: 3 | Loss: 0.143 | Acc: 95.312% (732/768)\n",
      "Train Epoch: 3 | Loss: 0.146 | Acc: 95.312% (854/896)\n",
      "Train Epoch: 3 | Loss: 0.143 | Acc: 95.508% (978/1024)\n",
      "Train Epoch: 3 | Loss: 0.143 | Acc: 95.486% (1100/1152)\n",
      "Train Epoch: 3 | Loss: 0.148 | Acc: 95.312% (1220/1280)\n",
      "Train Epoch: 3 | Loss: 0.150 | Acc: 95.170% (1340/1408)\n",
      "Train Epoch: 3 | Loss: 0.148 | Acc: 95.247% (1463/1536)\n",
      "Train Epoch: 3 | Loss: 0.148 | Acc: 95.252% (1585/1664)\n",
      "Train Epoch: 3 | Loss: 0.147 | Acc: 95.368% (1709/1792)\n",
      "Train Epoch: 3 | Loss: 0.148 | Acc: 95.260% (1829/1920)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 95.020% (1946/2048)\n",
      "Train Epoch: 3 | Loss: 0.154 | Acc: 95.129% (2070/2176)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 95.095% (2191/2304)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 95.107% (2313/2432)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 95.078% (2434/2560)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 95.015% (2554/2688)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 95.099% (2678/2816)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.973% (2796/2944)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.954% (2917/3072)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 95.031% (3041/3200)\n",
      "Train Epoch: 3 | Loss: 0.153 | Acc: 95.102% (3165/3328)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 94.965% (3282/3456)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.978% (3404/3584)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.801% (3519/3712)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.661% (3635/3840)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.582% (3753/3968)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.678% (3878/4096)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.815% (4005/4224)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.761% (4124/4352)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.754% (4245/4480)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.748% (4366/4608)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.742% (4487/4736)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.716% (4607/4864)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.611% (4723/4992)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.629% (4845/5120)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.607% (4965/5248)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.587% (5085/5376)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.640% (5209/5504)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.585% (5327/5632)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.705% (5455/5760)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.718% (5577/5888)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.714% (5698/6016)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.645% (5815/6144)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.627% (5935/6272)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.688% (6060/6400)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.700% (6182/6528)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.712% (6304/6656)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.723% (6426/6784)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.734% (6548/6912)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.716% (6668/7040)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.713% (6789/7168)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.737% (6912/7296)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 94.787% (7037/7424)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.756% (7156/7552)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.753% (7277/7680)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.787% (7401/7808)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 94.808% (7524/7936)\n",
      "Train Epoch: 3 | Loss: 0.155 | Acc: 94.841% (7648/8064)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.800% (7766/8192)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.820% (7889/8320)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.756% (8005/8448)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.683% (8120/8576)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.750% (8247/8704)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.735% (8367/8832)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.743% (8489/8960)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.718% (8608/9088)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.705% (8728/9216)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.660% (8845/9344)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.616% (8962/9472)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.615% (9083/9600)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.603% (9203/9728)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.612% (9325/9856)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.631% (9448/9984)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.640% (9570/10112)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.658% (9693/10240)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.666% (9815/10368)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.665% (9936/10496)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.672% (10058/10624)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.606% (10172/10752)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.651% (10298/10880)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.677% (10422/11008)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.711% (10547/11136)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.673% (10664/11264)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.689% (10787/11392)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.688% (10908/11520)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.712% (11032/11648)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.693% (11151/11776)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.708% (11274/11904)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.722% (11397/12032)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.729% (11519/12160)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.718% (11639/12288)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.749% (11764/12416)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.707% (11880/12544)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.705% (12001/12672)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.688% (12120/12800)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.694% (12242/12928)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.661% (12359/13056)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.683% (12483/13184)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.704% (12607/13312)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.695% (12727/13440)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.701% (12849/13568)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.706% (12971/13696)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.719% (13094/13824)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.725% (13216/13952)\n",
      "Train Epoch: 3 | Loss: 0.156 | Acc: 94.751% (13341/14080)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.749% (13462/14208)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.747% (13583/14336)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.697% (13697/14464)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.668% (13814/14592)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.667% (13935/14720)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.679% (14058/14848)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.678% (14179/14976)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.697% (14303/15104)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.682% (14422/15232)\n",
      "Train Epoch: 3 | Loss: 0.157 | Acc: 94.648% (14538/15360)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.596% (14651/15488)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.621% (14776/15616)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.614% (14896/15744)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.588% (15013/15872)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.581% (15133/16000)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.587% (15255/16128)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.587% (15376/16256)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.586% (15497/16384)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.592% (15619/16512)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.609% (15743/16640)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.615% (15865/16768)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.614% (15986/16896)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.608% (16106/17024)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.625% (16230/17152)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.618% (16350/17280)\n",
      "Train Epoch: 3 | Loss: 0.158 | Acc: 94.617% (16471/17408)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.588% (16587/17536)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.565% (16704/17664)\n",
      "Train Epoch: 3 | Loss: 0.159 | Acc: 94.571% (16826/17792)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.565% (16946/17920)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.537% (17062/18048)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.526% (17181/18176)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.553% (17307/18304)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.542% (17426/18432)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.520% (17543/18560)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.510% (17662/18688)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.510% (17783/18816)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.510% (17904/18944)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.526% (18028/19072)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.510% (18146/19200)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (18268/19328)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.511% (18388/19456)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (18512/19584)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.531% (18634/19712)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.536% (18756/19840)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.536% (18877/19968)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (18996/20096)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (19115/20224)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.512% (19235/20352)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (19359/20480)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.536% (19482/20608)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.541% (19604/20736)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.555% (19728/20864)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.574% (19853/20992)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.583% (19976/21120)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.574% (20095/21248)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.573% (20216/21376)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.582% (20339/21504)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.559% (20455/21632)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.559% (20576/21760)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.559% (20697/21888)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.554% (20817/22016)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.545% (20936/22144)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.536% (21055/22272)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.540% (21177/22400)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.549% (21300/22528)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.553% (21422/22656)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.540% (21540/22784)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (21659/22912)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.544% (21783/23040)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.544% (21904/23168)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (22022/23296)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.527% (22142/23424)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (22264/23552)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (22385/23680)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (22506/23808)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.540% (22629/23936)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.552% (22753/24064)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.556% (22875/24192)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.552% (22995/24320)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.552% (23116/24448)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.552% (23237/24576)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.551% (23358/24704)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.539% (23476/24832)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.539% (23597/24960)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.547% (23720/25088)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.559% (23844/25216)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.559% (23965/25344)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.567% (24088/25472)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.562% (24208/25600)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.570% (24331/25728)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.574% (24453/25856)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.581% (24576/25984)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.589% (24699/26112)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.604% (24824/26240)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.592% (24942/26368)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.588% (25062/26496)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.573% (25179/26624)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.557% (25296/26752)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.561% (25418/26880)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.572% (25542/27008)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.575% (25664/27136)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.590% (25789/27264)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.590% (25910/27392)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.578% (26028/27520)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.589% (26152/27648)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.582% (26271/27776)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.589% (26394/27904)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.574% (26511/28032)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.574% (26632/28160)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.584% (26756/28288)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.577% (26875/28416)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.584% (26998/28544)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.594% (27122/28672)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.608% (27247/28800)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.607% (27368/28928)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.610% (27490/29056)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.610% (27611/29184)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.620% (27735/29312)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.637% (27861/29440)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.639% (27983/29568)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.632% (28102/29696)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.635% (28224/29824)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.621% (28341/29952)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.624% (28463/30080)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.627% (28585/30208)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.630% (28707/30336)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.626% (28827/30464)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.629% (28949/30592)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.642% (29074/30720)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.638% (29194/30848)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.628% (29312/30976)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.631% (29434/31104)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.627% (29554/31232)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.624% (29674/31360)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.607% (29790/31488)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.613% (29913/31616)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.623% (30037/31744)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.619% (30157/31872)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.619% (30278/32000)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.615% (30398/32128)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.603% (30515/32256)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.599% (30635/32384)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.596% (30755/32512)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.602% (30878/32640)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.601% (30999/32768)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.595% (31118/32896)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.592% (31238/33024)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.592% (31359/33152)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.585% (31478/33280)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.567% (31593/33408)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.579% (31718/33536)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.582% (31840/33664)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.593% (31965/33792)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.581% (32082/33920)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.572% (32200/34048)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.575% (32322/34176)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.572% (32442/34304)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.557% (32558/34432)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.557% (32679/34560)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.549% (32797/34688)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.546% (32917/34816)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.548% (33039/34944)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.546% (33159/35072)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.545% (33280/35200)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.548% (33402/35328)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.537% (33519/35456)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.540% (33641/35584)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.542% (33763/35712)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.537% (33882/35840)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.537% (34003/35968)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.540% (34125/36096)\n",
      "Train Epoch: 3 | Loss: 0.160 | Acc: 94.551% (34250/36224)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.542% (34368/36352)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.529% (34484/36480)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.531% (34606/36608)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (34725/36736)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (34846/36864)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.526% (34967/36992)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.539% (35093/37120)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.537% (35213/37248)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.510% (35324/37376)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.513% (35446/37504)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.518% (35569/37632)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.497% (35682/37760)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.500% (35804/37888)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.494% (35923/38016)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.492% (36043/38144)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.497% (36166/38272)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.503% (36289/38400)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.503% (36410/38528)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.511% (36534/38656)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (36657/38784)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (36778/38912)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.513% (36898/39040)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (37020/39168)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.524% (37144/39296)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (37262/39424)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.508% (37380/39552)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (37504/39680)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.516% (37625/39808)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.501% (37740/39936)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.494% (37858/40064)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.491% (37978/40192)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.494% (38100/40320)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.484% (38217/40448)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.477% (38335/40576)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.485% (38459/40704)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.482% (38579/40832)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (38695/40960)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (38816/41088)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.478% (38940/41216)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.476% (39060/41344)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.481% (39183/41472)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.486% (39306/41600)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.476% (39423/41728)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.469% (39541/41856)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.479% (39666/41984)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.486% (39790/42112)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.484% (39910/42240)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.491% (40034/42368)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.487% (40153/42496)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.489% (40275/42624)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.487% (40395/42752)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.478% (40512/42880)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.468% (40629/43008)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.466% (40749/43136)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.473% (40873/43264)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (40994/43392)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.469% (41113/43520)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (41236/43648)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.472% (41356/43776)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (41478/43904)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (41601/44032)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (41718/44160)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (41839/44288)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (41960/44416)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.475% (42083/44544)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.475% (42204/44672)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.473% (42324/44800)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.480% (42448/44928)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.487% (42572/45056)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.491% (42695/45184)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.498% (42819/45312)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.489% (42936/45440)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.481% (43053/45568)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (43173/45696)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.483% (43296/45824)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (43415/45952)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (43536/46080)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (43657/46208)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.484% (43780/46336)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.480% (43899/46464)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.484% (44022/46592)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.482% (44142/46720)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (44259/46848)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (44380/46976)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (44499/47104)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.474% (44622/47232)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (44741/47360)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.470% (44862/47488)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.472% (44984/47616)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.479% (45108/47744)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.483% (45231/47872)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.487% (45354/48000)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.492% (45477/48128)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.488% (45596/48256)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.486% (45716/48384)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.488% (45838/48512)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.482% (45956/48640)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.486% (46079/48768)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.490% (46202/48896)\n",
      "Train Epoch: 3 | Loss: 0.161 | Acc: 94.499% (46327/49024)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.486% (46442/49152)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.491% (46565/49280)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.491% (46686/49408)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.485% (46804/49536)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.487% (46926/49664)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.485% (47046/49792)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.483% (47166/49920)\n",
      "Train Epoch: 3 | Loss: 0.162 | Acc: 94.488% (47244/50000)\n",
      "Test Epoch: 3 | Loss: 0.241 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 3 | Loss: 0.330 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 3 | Loss: 0.320 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 3 | Loss: 0.287 | Acc: 91.400% (457/500)\n",
      "Test Epoch: 3 | Loss: 0.268 | Acc: 92.000% (552/600)\n",
      "Test Epoch: 3 | Loss: 0.277 | Acc: 91.571% (641/700)\n",
      "Test Epoch: 3 | Loss: 0.295 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.111% (811/900)\n",
      "Test Epoch: 3 | Loss: 0.315 | Acc: 89.900% (899/1000)\n",
      "Test Epoch: 3 | Loss: 0.320 | Acc: 89.545% (985/1100)\n",
      "Test Epoch: 3 | Loss: 0.325 | Acc: 89.417% (1073/1200)\n",
      "Test Epoch: 3 | Loss: 0.315 | Acc: 89.462% (1163/1300)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 89.786% (1257/1400)\n",
      "Test Epoch: 3 | Loss: 0.297 | Acc: 90.067% (1351/1500)\n",
      "Test Epoch: 3 | Loss: 0.293 | Acc: 90.250% (1444/1600)\n",
      "Test Epoch: 3 | Loss: 0.294 | Acc: 90.353% (1536/1700)\n",
      "Test Epoch: 3 | Loss: 0.295 | Acc: 90.222% (1624/1800)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.158% (1713/1900)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.200% (1804/2000)\n",
      "Test Epoch: 3 | Loss: 0.308 | Acc: 90.048% (1891/2100)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.136% (1983/2200)\n",
      "Test Epoch: 3 | Loss: 0.309 | Acc: 89.957% (2069/2300)\n",
      "Test Epoch: 3 | Loss: 0.313 | Acc: 89.875% (2157/2400)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 89.840% (2246/2500)\n",
      "Test Epoch: 3 | Loss: 0.324 | Acc: 89.654% (2331/2600)\n",
      "Test Epoch: 3 | Loss: 0.320 | Acc: 89.815% (2425/2700)\n",
      "Test Epoch: 3 | Loss: 0.320 | Acc: 89.821% (2515/2800)\n",
      "Test Epoch: 3 | Loss: 0.318 | Acc: 89.897% (2607/2900)\n",
      "Test Epoch: 3 | Loss: 0.324 | Acc: 89.700% (2691/3000)\n",
      "Test Epoch: 3 | Loss: 0.325 | Acc: 89.548% (2776/3100)\n",
      "Test Epoch: 3 | Loss: 0.322 | Acc: 89.625% (2868/3200)\n",
      "Test Epoch: 3 | Loss: 0.319 | Acc: 89.727% (2961/3300)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 89.824% (3054/3400)\n",
      "Test Epoch: 3 | Loss: 0.317 | Acc: 89.829% (3144/3500)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 89.917% (3237/3600)\n",
      "Test Epoch: 3 | Loss: 0.317 | Acc: 89.946% (3328/3700)\n",
      "Test Epoch: 3 | Loss: 0.318 | Acc: 89.921% (3417/3800)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 89.974% (3509/3900)\n",
      "Test Epoch: 3 | Loss: 0.317 | Acc: 89.950% (3598/4000)\n",
      "Test Epoch: 3 | Loss: 0.320 | Acc: 89.902% (3686/4100)\n",
      "Test Epoch: 3 | Loss: 0.318 | Acc: 89.905% (3776/4200)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 90.000% (3870/4300)\n",
      "Test Epoch: 3 | Loss: 0.314 | Acc: 90.023% (3961/4400)\n",
      "Test Epoch: 3 | Loss: 0.312 | Acc: 90.067% (4053/4500)\n",
      "Test Epoch: 3 | Loss: 0.313 | Acc: 90.022% (4141/4600)\n",
      "Test Epoch: 3 | Loss: 0.313 | Acc: 90.021% (4231/4700)\n",
      "Test Epoch: 3 | Loss: 0.316 | Acc: 89.938% (4317/4800)\n",
      "Test Epoch: 3 | Loss: 0.313 | Acc: 89.980% (4409/4900)\n",
      "Test Epoch: 3 | Loss: 0.314 | Acc: 90.020% (4501/5000)\n",
      "Test Epoch: 3 | Loss: 0.310 | Acc: 90.137% (4597/5100)\n",
      "Test Epoch: 3 | Loss: 0.311 | Acc: 90.096% (4685/5200)\n",
      "Test Epoch: 3 | Loss: 0.314 | Acc: 90.057% (4773/5300)\n",
      "Test Epoch: 3 | Loss: 0.312 | Acc: 90.093% (4865/5400)\n",
      "Test Epoch: 3 | Loss: 0.312 | Acc: 90.055% (4953/5500)\n",
      "Test Epoch: 3 | Loss: 0.311 | Acc: 90.036% (5042/5600)\n",
      "Test Epoch: 3 | Loss: 0.309 | Acc: 90.053% (5133/5700)\n",
      "Test Epoch: 3 | Loss: 0.308 | Acc: 90.086% (5225/5800)\n",
      "Test Epoch: 3 | Loss: 0.309 | Acc: 90.017% (5311/5900)\n",
      "Test Epoch: 3 | Loss: 0.310 | Acc: 90.050% (5403/6000)\n",
      "Test Epoch: 3 | Loss: 0.308 | Acc: 90.082% (5495/6100)\n",
      "Test Epoch: 3 | Loss: 0.307 | Acc: 90.081% (5585/6200)\n",
      "Test Epoch: 3 | Loss: 0.306 | Acc: 90.127% (5678/6300)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.219% (5774/6400)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.215% (5864/6500)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.242% (5956/6600)\n",
      "Test Epoch: 3 | Loss: 0.299 | Acc: 90.328% (6052/6700)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.309% (6141/6800)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.304% (6231/6900)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.329% (6323/7000)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.324% (6413/7100)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.347% (6505/7200)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.411% (6600/7300)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.500% (6697/7400)\n",
      "Test Epoch: 3 | Loss: 0.298 | Acc: 90.533% (6790/7500)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.487% (6877/7600)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.506% (6969/7700)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.513% (7060/7800)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.532% (7152/7900)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.500% (7240/8000)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.543% (7334/8100)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.537% (7424/8200)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.530% (7514/8300)\n",
      "Test Epoch: 3 | Loss: 0.300 | Acc: 90.548% (7606/8400)\n",
      "Test Epoch: 3 | Loss: 0.301 | Acc: 90.482% (7691/8500)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 90.395% (7774/8600)\n",
      "Test Epoch: 3 | Loss: 0.304 | Acc: 90.448% (7869/8700)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 90.386% (7954/8800)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 90.360% (8042/8900)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 90.378% (8134/9000)\n",
      "Test Epoch: 3 | Loss: 0.304 | Acc: 90.374% (8224/9100)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.435% (8320/9200)\n",
      "Test Epoch: 3 | Loss: 0.305 | Acc: 90.376% (8405/9300)\n",
      "Test Epoch: 3 | Loss: 0.304 | Acc: 90.426% (8500/9400)\n",
      "Test Epoch: 3 | Loss: 0.304 | Acc: 90.463% (8594/9500)\n",
      "Test Epoch: 3 | Loss: 0.304 | Acc: 90.469% (8685/9600)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.505% (8779/9700)\n",
      "Test Epoch: 3 | Loss: 0.302 | Acc: 90.490% (8868/9800)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.475% (8957/9900)\n",
      "Test Epoch: 3 | Loss: 0.303 | Acc: 90.490% (9049/10000)\n",
      "\n",
      "Epoch: 4\n",
      "Train Epoch: 4 | Loss: 0.109 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 4 | Loss: 0.119 | Acc: 96.875% (248/256)\n",
      "Train Epoch: 4 | Loss: 0.131 | Acc: 96.615% (371/384)\n",
      "Train Epoch: 4 | Loss: 0.121 | Acc: 96.680% (495/512)\n",
      "Train Epoch: 4 | Loss: 0.125 | Acc: 96.406% (617/640)\n",
      "Train Epoch: 4 | Loss: 0.122 | Acc: 96.615% (742/768)\n",
      "Train Epoch: 4 | Loss: 0.124 | Acc: 96.540% (865/896)\n",
      "Train Epoch: 4 | Loss: 0.139 | Acc: 95.898% (982/1024)\n",
      "Train Epoch: 4 | Loss: 0.140 | Acc: 95.660% (1102/1152)\n",
      "Train Epoch: 4 | Loss: 0.147 | Acc: 95.469% (1222/1280)\n",
      "Train Epoch: 4 | Loss: 0.148 | Acc: 95.170% (1340/1408)\n",
      "Train Epoch: 4 | Loss: 0.147 | Acc: 95.247% (1463/1536)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.952% (1580/1664)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 95.145% (1705/1792)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 95.104% (1826/1920)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.873% (1943/2048)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.945% (2066/2176)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.878% (2186/2304)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.860% (2307/2432)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.922% (2430/2560)\n",
      "Train Epoch: 4 | Loss: 0.148 | Acc: 94.903% (2551/2688)\n",
      "Train Epoch: 4 | Loss: 0.148 | Acc: 94.922% (2673/2816)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.735% (2789/2944)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.661% (2908/3072)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.656% (3029/3200)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.712% (3152/3328)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.676% (3272/3456)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.810% (3398/3584)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.720% (3516/3712)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.661% (3635/3840)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.708% (3758/3968)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.727% (3880/4096)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.744% (4002/4224)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.807% (4126/4352)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.799% (4247/4480)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.813% (4369/4608)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.848% (4492/4736)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.881% (4615/4864)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.812% (4733/4992)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.824% (4855/5120)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.836% (4977/5248)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.773% (5095/5376)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.858% (5221/5504)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.851% (5342/5632)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.826% (5462/5760)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.871% (5586/5888)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.864% (5707/6016)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.824% (5826/6144)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.850% (5949/6272)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.859% (6071/6400)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.899% (6195/6528)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.907% (6317/6656)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.870% (6436/6784)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.835% (6555/6912)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.872% (6679/7040)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.838% (6798/7168)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.805% (6917/7296)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.814% (7039/7424)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.809% (7160/7552)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.792% (7280/7680)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.826% (7404/7808)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.846% (7527/7936)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.841% (7648/8064)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.836% (7769/8192)\n",
      "Train Epoch: 4 | Loss: 0.148 | Acc: 94.880% (7894/8320)\n",
      "Train Epoch: 4 | Loss: 0.148 | Acc: 94.910% (8018/8448)\n",
      "Train Epoch: 4 | Loss: 0.149 | Acc: 94.858% (8135/8576)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.818% (8253/8704)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.780% (8371/8832)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.788% (8493/8960)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.762% (8612/9088)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.748% (8732/9216)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.767% (8855/9344)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.816% (8981/9472)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.812% (9102/9600)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.799% (9222/9728)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.795% (9343/9856)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.822% (9467/9984)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.798% (9586/10112)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.746% (9702/10240)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.743% (9823/10368)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.769% (9947/10496)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.795% (10071/10624)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.792% (10192/10752)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.807% (10315/10880)\n",
      "Train Epoch: 4 | Loss: 0.150 | Acc: 94.831% (10439/11008)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.810% (10558/11136)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.789% (10677/11264)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.786% (10798/11392)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.809% (10922/11520)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.806% (11043/11648)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.811% (11165/11776)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.800% (11285/11904)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.756% (11401/12032)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.762% (11523/12160)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.743% (11642/12288)\n",
      "Train Epoch: 4 | Loss: 0.152 | Acc: 94.741% (11763/12416)\n",
      "Train Epoch: 4 | Loss: 0.151 | Acc: 94.754% (11886/12544)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.721% (12003/12672)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.672% (12118/12800)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.670% (12239/12928)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.661% (12359/13056)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.653% (12479/13184)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.584% (12591/13312)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.591% (12713/13440)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.620% (12838/13568)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.641% (12962/13696)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.647% (13084/13824)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.667% (13208/13952)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.680% (13331/14080)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.672% (13451/14208)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.664% (13571/14336)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.670% (13693/14464)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.668% (13814/14592)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.688% (13938/14720)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.686% (14059/14848)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.678% (14179/14976)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.697% (14303/15104)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.682% (14422/15232)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.668% (14541/15360)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.680% (14664/15488)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.640% (14779/15616)\n",
      "Train Epoch: 4 | Loss: 0.153 | Acc: 94.658% (14903/15744)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.619% (15018/15872)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.631% (15141/16000)\n",
      "Train Epoch: 4 | Loss: 0.154 | Acc: 94.643% (15264/16128)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.611% (15380/16256)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.617% (15502/16384)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.604% (15621/16512)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.615% (15744/16640)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.609% (15864/16768)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.626% (15988/16896)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.619% (16108/17024)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.642% (16233/17152)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.630% (16352/17280)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.594% (16467/17408)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.605% (16590/17536)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.599% (16710/17664)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.610% (16833/17792)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.581% (16949/17920)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.592% (17072/18048)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.581% (17191/18176)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.575% (17311/18304)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.575% (17432/18432)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.596% (17557/18560)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.569% (17673/18688)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.537% (17788/18816)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.547% (17911/18944)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.542% (18031/19072)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.547% (18153/19200)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.557% (18276/19328)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.562% (18398/19456)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.557% (18518/19584)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.546% (18637/19712)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.561% (18761/19840)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.561% (18882/19968)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.561% (19003/20096)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.551% (19122/20224)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.561% (19245/20352)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.570% (19368/20480)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.570% (19489/20608)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.560% (19608/20736)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.584% (19734/20864)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.579% (19854/20992)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.555% (19970/21120)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.545% (20089/21248)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.536% (20208/21376)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.550% (20332/21504)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.545% (20452/21632)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.545% (20573/21760)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.550% (20695/21888)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.545% (20815/22016)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.549% (20937/22144)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.563% (21061/22272)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.558% (21181/22400)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.553% (21301/22528)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.567% (21425/22656)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.562% (21545/22784)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.544% (21662/22912)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.553% (21785/23040)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.570% (21910/23168)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.587% (22035/23296)\n",
      "Train Epoch: 4 | Loss: 0.155 | Acc: 94.587% (22156/23424)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.578% (22275/23552)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.565% (22393/23680)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.565% (22514/23808)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.560% (22634/23936)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.560% (22755/24064)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.564% (22877/24192)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.564% (22998/24320)\n",
      "Train Epoch: 4 | Loss: 0.156 | Acc: 94.568% (23120/24448)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.560% (23239/24576)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.556% (23359/24704)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.551% (23479/24832)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.547% (23599/24960)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.543% (23719/25088)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.543% (23840/25216)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.531% (23958/25344)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.523% (24077/25472)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.504% (24193/25600)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.512% (24316/25728)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.524% (24440/25856)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.527% (24562/25984)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.512% (24679/26112)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.516% (24801/26240)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.520% (24923/26368)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.509% (25041/26496)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.520% (25165/26624)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.516% (25285/26752)\n",
      "Train Epoch: 4 | Loss: 0.157 | Acc: 94.513% (25405/26880)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.513% (25526/27008)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.509% (25646/27136)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.513% (25768/27264)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.513% (25889/27392)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.517% (26011/27520)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.481% (26122/27648)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.484% (26244/27776)\n",
      "Train Epoch: 4 | Loss: 0.158 | Acc: 94.485% (26365/27904)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.467% (26481/28032)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.474% (26604/28160)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.464% (26722/28288)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.450% (26839/28416)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.447% (26959/28544)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.441% (27078/28672)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.441% (27199/28800)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.448% (27322/28928)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.459% (27446/29056)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.459% (27567/29184)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.453% (27686/29312)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.457% (27808/29440)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.460% (27930/29568)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.467% (28053/29696)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.457% (28171/29824)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.448% (28289/29952)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.455% (28412/30080)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.455% (28533/30208)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.449% (28652/30336)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.452% (28774/30464)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.453% (28895/30592)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.460% (29018/30720)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.460% (29139/30848)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.457% (29259/30976)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.461% (29381/31104)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.467% (29504/31232)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.474% (29627/31360)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.465% (29745/31488)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.471% (29868/31616)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.465% (29987/31744)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.453% (30104/31872)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.456% (30226/32000)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.460% (30348/32128)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.466% (30471/32256)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.466% (30592/32384)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.473% (30715/32512)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.479% (30838/32640)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.476% (30958/32768)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.483% (31081/32896)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.480% (31201/33024)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.471% (31319/33152)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.462% (31437/33280)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.462% (31558/33408)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.469% (31681/33536)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.472% (31803/33664)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.469% (31923/33792)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.469% (32044/33920)\n",
      "Train Epoch: 4 | Loss: 0.159 | Acc: 94.473% (32166/34048)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.464% (32284/34176)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.461% (32404/34304)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.456% (32523/34432)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.462% (32646/34560)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.451% (32763/34688)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.457% (32886/34816)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.457% (33007/34944)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.460% (33129/35072)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.452% (33247/35200)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.444% (33365/35328)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.447% (33487/35456)\n",
      "Train Epoch: 4 | Loss: 0.160 | Acc: 94.458% (33612/35584)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.450% (33730/35712)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.456% (33853/35840)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.459% (33975/35968)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.445% (34091/36096)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.435% (34208/36224)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.438% (34330/36352)\n",
      "Train Epoch: 4 | Loss: 0.161 | Acc: 94.427% (34447/36480)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.417% (34564/36608)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.414% (34684/36736)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.404% (34801/36864)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.399% (34920/36992)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.380% (35034/37120)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.370% (35151/37248)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.373% (35273/37376)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.379% (35396/37504)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.382% (35518/37632)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.388% (35641/37760)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.391% (35763/37888)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.392% (35884/38016)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.392% (36005/38144)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.380% (36121/38272)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.380% (36242/38400)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.376% (36361/38528)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.366% (36478/38656)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.371% (36601/38784)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.374% (36723/38912)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.372% (36843/39040)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.381% (36967/39168)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.381% (37088/39296)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.384% (37210/39424)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.390% (37333/39552)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.393% (37455/39680)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.396% (37577/39808)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.391% (37696/39936)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.372% (37809/40064)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.375% (37931/40192)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.370% (38050/40320)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.371% (38171/40448)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.374% (38293/40576)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.362% (38409/40704)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.360% (38529/40832)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.351% (38646/40960)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.351% (38767/41088)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.354% (38889/41216)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.362% (39013/41344)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.358% (39132/41472)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.358% (39253/41600)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.359% (39374/41728)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.347% (39490/41856)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.353% (39613/41984)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.337% (39727/42112)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.347% (39852/42240)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.342% (39971/42368)\n",
      "Train Epoch: 4 | Loss: 0.162 | Acc: 94.355% (40097/42496)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.351% (40216/42624)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.349% (40336/42752)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.356% (40460/42880)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.355% (40580/43008)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.353% (40700/43136)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.353% (40821/43264)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.333% (40933/43392)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.322% (41049/43520)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.327% (41172/43648)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.323% (41291/43776)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.324% (41412/43904)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.331% (41536/44032)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.330% (41656/44160)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.328% (41776/44288)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.329% (41897/44416)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.329% (42018/44544)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.316% (42133/44672)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.312% (42252/44800)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.313% (42373/44928)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.309% (42492/45056)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.314% (42615/45184)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.315% (42736/45312)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.313% (42856/45440)\n",
      "Train Epoch: 4 | Loss: 0.163 | Acc: 94.314% (42977/45568)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.308% (43095/45696)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.304% (43214/45824)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.294% (43330/45952)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.288% (43448/46080)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.291% (43570/46208)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.287% (43689/46336)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.295% (43813/46464)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.293% (43933/46592)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.283% (44049/46720)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.294% (44175/46848)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.291% (44294/46976)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.289% (44414/47104)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.288% (44534/47232)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.286% (44654/47360)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.285% (44774/47488)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.283% (44894/47616)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.278% (45012/47744)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.283% (45135/47872)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.273% (45251/48000)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.278% (45374/48128)\n",
      "Train Epoch: 4 | Loss: 0.164 | Acc: 94.281% (45496/48256)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.277% (45615/48384)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.267% (45731/48512)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.264% (45850/48640)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.259% (45968/48768)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.253% (46086/48896)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.258% (46209/49024)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.255% (46328/49152)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.261% (46452/49280)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.260% (46572/49408)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.259% (46692/49536)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.267% (46817/49664)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.270% (46939/49792)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.267% (47058/49920)\n",
      "Train Epoch: 4 | Loss: 0.165 | Acc: 94.264% (47132/50000)\n",
      "Test Epoch: 4 | Loss: 0.101 | Acc: 98.000% (98/100)\n",
      "Test Epoch: 4 | Loss: 0.204 | Acc: 93.500% (187/200)\n",
      "Test Epoch: 4 | Loss: 0.227 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 4 | Loss: 0.239 | Acc: 92.000% (368/400)\n",
      "Test Epoch: 4 | Loss: 0.238 | Acc: 92.000% (460/500)\n",
      "Test Epoch: 4 | Loss: 0.223 | Acc: 92.500% (555/600)\n",
      "Test Epoch: 4 | Loss: 0.221 | Acc: 92.571% (648/700)\n",
      "Test Epoch: 4 | Loss: 0.248 | Acc: 91.375% (731/800)\n",
      "Test Epoch: 4 | Loss: 0.264 | Acc: 90.778% (817/900)\n",
      "Test Epoch: 4 | Loss: 0.275 | Acc: 90.500% (905/1000)\n",
      "Test Epoch: 4 | Loss: 0.290 | Acc: 90.091% (991/1100)\n",
      "Test Epoch: 4 | Loss: 0.306 | Acc: 89.750% (1077/1200)\n",
      "Test Epoch: 4 | Loss: 0.298 | Acc: 90.077% (1171/1300)\n",
      "Test Epoch: 4 | Loss: 0.288 | Acc: 90.357% (1265/1400)\n",
      "Test Epoch: 4 | Loss: 0.291 | Acc: 90.333% (1355/1500)\n",
      "Test Epoch: 4 | Loss: 0.297 | Acc: 90.188% (1443/1600)\n",
      "Test Epoch: 4 | Loss: 0.300 | Acc: 90.412% (1537/1700)\n",
      "Test Epoch: 4 | Loss: 0.306 | Acc: 90.278% (1625/1800)\n",
      "Test Epoch: 4 | Loss: 0.312 | Acc: 90.105% (1712/1900)\n",
      "Test Epoch: 4 | Loss: 0.317 | Acc: 90.000% (1800/2000)\n",
      "Test Epoch: 4 | Loss: 0.321 | Acc: 89.905% (1888/2100)\n",
      "Test Epoch: 4 | Loss: 0.319 | Acc: 89.955% (1979/2200)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.913% (2068/2300)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.833% (2156/2400)\n",
      "Test Epoch: 4 | Loss: 0.337 | Acc: 89.800% (2245/2500)\n",
      "Test Epoch: 4 | Loss: 0.345 | Acc: 89.769% (2334/2600)\n",
      "Test Epoch: 4 | Loss: 0.340 | Acc: 89.815% (2425/2700)\n",
      "Test Epoch: 4 | Loss: 0.339 | Acc: 89.857% (2516/2800)\n",
      "Test Epoch: 4 | Loss: 0.341 | Acc: 89.828% (2605/2900)\n",
      "Test Epoch: 4 | Loss: 0.342 | Acc: 89.767% (2693/3000)\n",
      "Test Epoch: 4 | Loss: 0.347 | Acc: 89.581% (2777/3100)\n",
      "Test Epoch: 4 | Loss: 0.344 | Acc: 89.594% (2867/3200)\n",
      "Test Epoch: 4 | Loss: 0.344 | Acc: 89.576% (2956/3300)\n",
      "Test Epoch: 4 | Loss: 0.342 | Acc: 89.588% (3046/3400)\n",
      "Test Epoch: 4 | Loss: 0.346 | Acc: 89.543% (3134/3500)\n",
      "Test Epoch: 4 | Loss: 0.345 | Acc: 89.611% (3226/3600)\n",
      "Test Epoch: 4 | Loss: 0.342 | Acc: 89.703% (3319/3700)\n",
      "Test Epoch: 4 | Loss: 0.343 | Acc: 89.684% (3408/3800)\n",
      "Test Epoch: 4 | Loss: 0.340 | Acc: 89.718% (3499/3900)\n",
      "Test Epoch: 4 | Loss: 0.339 | Acc: 89.675% (3587/4000)\n",
      "Test Epoch: 4 | Loss: 0.340 | Acc: 89.610% (3674/4100)\n",
      "Test Epoch: 4 | Loss: 0.338 | Acc: 89.548% (3761/4200)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.605% (3853/4300)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.659% (3945/4400)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.689% (4036/4500)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.717% (4127/4600)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.702% (4216/4700)\n",
      "Test Epoch: 4 | Loss: 0.339 | Acc: 89.562% (4299/4800)\n",
      "Test Epoch: 4 | Loss: 0.337 | Acc: 89.592% (4390/4900)\n",
      "Test Epoch: 4 | Loss: 0.340 | Acc: 89.560% (4478/5000)\n",
      "Test Epoch: 4 | Loss: 0.338 | Acc: 89.588% (4569/5100)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.635% (4661/5200)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.623% (4750/5300)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.630% (4840/5400)\n",
      "Test Epoch: 4 | Loss: 0.337 | Acc: 89.564% (4926/5500)\n",
      "Test Epoch: 4 | Loss: 0.335 | Acc: 89.625% (5019/5600)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.614% (5108/5700)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.552% (5194/5800)\n",
      "Test Epoch: 4 | Loss: 0.338 | Acc: 89.441% (5277/5900)\n",
      "Test Epoch: 4 | Loss: 0.335 | Acc: 89.533% (5372/6000)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.492% (5459/6100)\n",
      "Test Epoch: 4 | Loss: 0.336 | Acc: 89.565% (5553/6200)\n",
      "Test Epoch: 4 | Loss: 0.335 | Acc: 89.619% (5646/6300)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.719% (5742/6400)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.677% (5829/6500)\n",
      "Test Epoch: 4 | Loss: 0.330 | Acc: 89.758% (5924/6600)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.851% (6020/6700)\n",
      "Test Epoch: 4 | Loss: 0.330 | Acc: 89.794% (6106/6800)\n",
      "Test Epoch: 4 | Loss: 0.329 | Acc: 89.841% (6199/6900)\n",
      "Test Epoch: 4 | Loss: 0.330 | Acc: 89.857% (6290/7000)\n",
      "Test Epoch: 4 | Loss: 0.329 | Acc: 89.873% (6381/7100)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.889% (6472/7200)\n",
      "Test Epoch: 4 | Loss: 0.326 | Acc: 89.932% (6565/7300)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.892% (6652/7400)\n",
      "Test Epoch: 4 | Loss: 0.325 | Acc: 89.960% (6747/7500)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.921% (6834/7600)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.896% (6922/7700)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.897% (7012/7800)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.861% (7099/7900)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.875% (7190/8000)\n",
      "Test Epoch: 4 | Loss: 0.325 | Acc: 89.951% (7286/8100)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.915% (7373/8200)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.855% (7458/8300)\n",
      "Test Epoch: 4 | Loss: 0.327 | Acc: 89.810% (7544/8400)\n",
      "Test Epoch: 4 | Loss: 0.328 | Acc: 89.753% (7629/8500)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.709% (7715/8600)\n",
      "Test Epoch: 4 | Loss: 0.330 | Acc: 89.724% (7806/8700)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.716% (7895/8800)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.719% (7985/8900)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.722% (8075/9000)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.736% (8166/9100)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.717% (8254/9200)\n",
      "Test Epoch: 4 | Loss: 0.334 | Acc: 89.699% (8342/9300)\n",
      "Test Epoch: 4 | Loss: 0.335 | Acc: 89.713% (8433/9400)\n",
      "Test Epoch: 4 | Loss: 0.335 | Acc: 89.737% (8525/9500)\n",
      "Test Epoch: 4 | Loss: 0.333 | Acc: 89.771% (8618/9600)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.804% (8711/9700)\n",
      "Test Epoch: 4 | Loss: 0.331 | Acc: 89.827% (8803/9800)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.798% (8890/9900)\n",
      "Test Epoch: 4 | Loss: 0.332 | Acc: 89.810% (8981/10000)\n",
      "\n",
      "Epoch: 5\n",
      "Train Epoch: 5 | Loss: 0.131 | Acc: 95.312% (122/128)\n",
      "Train Epoch: 5 | Loss: 0.191 | Acc: 93.359% (239/256)\n",
      "Train Epoch: 5 | Loss: 0.191 | Acc: 93.490% (359/384)\n",
      "Train Epoch: 5 | Loss: 0.173 | Acc: 93.945% (481/512)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.375% (604/640)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.661% (727/768)\n",
      "Train Epoch: 5 | Loss: 0.146 | Acc: 94.866% (850/896)\n",
      "Train Epoch: 5 | Loss: 0.144 | Acc: 95.215% (975/1024)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.399% (1099/1152)\n",
      "Train Epoch: 5 | Loss: 0.138 | Acc: 95.547% (1223/1280)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.597% (1346/1408)\n",
      "Train Epoch: 5 | Loss: 0.138 | Acc: 95.768% (1471/1536)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.853% (1595/1664)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.815% (1717/1792)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.833% (1840/1920)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.850% (1963/2048)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.910% (2087/2176)\n",
      "Train Epoch: 5 | Loss: 0.137 | Acc: 96.007% (2212/2304)\n",
      "Train Epoch: 5 | Loss: 0.137 | Acc: 96.012% (2335/2432)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.820% (2453/2560)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.759% (2574/2688)\n",
      "Train Epoch: 5 | Loss: 0.142 | Acc: 95.739% (2696/2816)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.788% (2820/2944)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.671% (2939/3072)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.750% (3064/3200)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.673% (3184/3328)\n",
      "Train Epoch: 5 | Loss: 0.138 | Acc: 95.747% (3309/3456)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.675% (3429/3584)\n",
      "Train Epoch: 5 | Loss: 0.142 | Acc: 95.528% (3546/3712)\n",
      "Train Epoch: 5 | Loss: 0.141 | Acc: 95.547% (3669/3840)\n",
      "Train Epoch: 5 | Loss: 0.142 | Acc: 95.539% (3791/3968)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.630% (3917/4096)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.715% (4043/4224)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.657% (4163/4352)\n",
      "Train Epoch: 5 | Loss: 0.139 | Acc: 95.692% (4287/4480)\n",
      "Train Epoch: 5 | Loss: 0.140 | Acc: 95.638% (4407/4608)\n",
      "Train Epoch: 5 | Loss: 0.142 | Acc: 95.566% (4526/4736)\n",
      "Train Epoch: 5 | Loss: 0.143 | Acc: 95.477% (4644/4864)\n",
      "Train Epoch: 5 | Loss: 0.143 | Acc: 95.473% (4766/4992)\n",
      "Train Epoch: 5 | Loss: 0.147 | Acc: 95.352% (4882/5120)\n",
      "Train Epoch: 5 | Loss: 0.146 | Acc: 95.408% (5007/5248)\n",
      "Train Epoch: 5 | Loss: 0.146 | Acc: 95.424% (5130/5376)\n",
      "Train Epoch: 5 | Loss: 0.146 | Acc: 95.403% (5251/5504)\n",
      "Train Epoch: 5 | Loss: 0.147 | Acc: 95.384% (5372/5632)\n",
      "Train Epoch: 5 | Loss: 0.145 | Acc: 95.434% (5497/5760)\n",
      "Train Epoch: 5 | Loss: 0.148 | Acc: 95.312% (5612/5888)\n",
      "Train Epoch: 5 | Loss: 0.148 | Acc: 95.296% (5733/6016)\n",
      "Train Epoch: 5 | Loss: 0.150 | Acc: 95.231% (5851/6144)\n",
      "Train Epoch: 5 | Loss: 0.150 | Acc: 95.233% (5973/6272)\n",
      "Train Epoch: 5 | Loss: 0.150 | Acc: 95.234% (6095/6400)\n",
      "Train Epoch: 5 | Loss: 0.152 | Acc: 95.129% (6210/6528)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 95.057% (6327/6656)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 95.062% (6449/6784)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 95.067% (6571/6912)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 95.043% (6691/7040)\n",
      "Train Epoch: 5 | Loss: 0.152 | Acc: 95.061% (6814/7168)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 95.011% (6932/7296)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.989% (7052/7424)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.902% (7167/7552)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.870% (7286/7680)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.903% (7410/7808)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.897% (7531/7936)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.891% (7652/8064)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.910% (7775/8192)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.916% (7897/8320)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.946% (8021/8448)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.963% (8144/8576)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.945% (8264/8704)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.939% (8385/8832)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.967% (8509/8960)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.949% (8629/9088)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.933% (8749/9216)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.884% (8866/9344)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.859% (8985/9472)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.885% (9109/9600)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.901% (9232/9728)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.937% (9357/9856)\n",
      "Train Epoch: 5 | Loss: 0.152 | Acc: 94.962% (9481/9984)\n",
      "Train Epoch: 5 | Loss: 0.152 | Acc: 94.947% (9601/10112)\n",
      "Train Epoch: 5 | Loss: 0.152 | Acc: 94.912% (9719/10240)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.907% (9840/10368)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.912% (9962/10496)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.898% (10082/10624)\n",
      "Train Epoch: 5 | Loss: 0.153 | Acc: 94.885% (10202/10752)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.835% (10318/10880)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.849% (10441/11008)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.810% (10558/11136)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.806% (10679/11264)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.821% (10802/11392)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.826% (10924/11520)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.823% (11045/11648)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.837% (11168/11776)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.834% (11289/11904)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.822% (11409/12032)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.811% (11529/12160)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.832% (11653/12288)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.853% (11777/12416)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.834% (11896/12544)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.831% (12017/12672)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.828% (12138/12800)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.817% (12258/12928)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.830% (12381/13056)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.812% (12500/13184)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.854% (12627/13312)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.851% (12748/13440)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.856% (12870/13568)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.860% (12992/13696)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.864% (13114/13824)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.854% (13234/13952)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.844% (13354/14080)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.862% (13478/14208)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.831% (13595/14336)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.822% (13715/14464)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.819% (13836/14592)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.837% (13960/14720)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.814% (14078/14848)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.832% (14202/14976)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.809% (14320/15104)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.827% (14444/15232)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.844% (14568/15360)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.841% (14689/15488)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.819% (14807/15616)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.817% (14928/15744)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.821% (15050/15872)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.838% (15174/16000)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.835% (15295/16128)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.833% (15416/16256)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.794% (15531/16384)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.780% (15650/16512)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.796% (15774/16640)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.800% (15896/16768)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.786% (16015/16896)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.807% (16140/17024)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.794% (16259/17152)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.774% (16377/17280)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.784% (16500/17408)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.788% (16622/17536)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.792% (16744/17664)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.762% (16860/17792)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.771% (16983/17920)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.764% (17103/18048)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.762% (17224/18176)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.777% (17348/18304)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.786% (17471/18432)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.779% (17591/18560)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.799% (17716/18688)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.824% (17842/18816)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.837% (17966/18944)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.830% (18086/19072)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.839% (18209/19200)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.842% (18331/19328)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.814% (18447/19456)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.792% (18564/19584)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.780% (18683/19712)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.778% (18804/19840)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.777% (18925/19968)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.770% (19045/20096)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.759% (19164/20224)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.762% (19286/20352)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.761% (19407/20480)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.750% (19526/20608)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.758% (19649/20736)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.752% (19769/20864)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.765% (19893/20992)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.782% (20018/21120)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.781% (20139/21248)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.770% (20258/21376)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.782% (20382/21504)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.776% (20502/21632)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.775% (20623/21760)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.760% (20741/21888)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.767% (20864/22016)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.757% (20983/22144)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.756% (21104/22272)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.763% (21227/22400)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.784% (21353/22528)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.783% (21474/22656)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.786% (21596/22784)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.789% (21718/22912)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.779% (21837/23040)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.777% (21958/23168)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.772% (22078/23296)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.783% (22202/23424)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.790% (22325/23552)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.797% (22448/23680)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.804% (22571/23808)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.799% (22691/23936)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.793% (22811/24064)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.779% (22929/24192)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.778% (23050/24320)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.777% (23171/24448)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.784% (23294/24576)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.786% (23416/24704)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.789% (23538/24832)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.792% (23660/24960)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.790% (23781/25088)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.773% (23898/25216)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.772% (24019/25344)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.771% (24140/25472)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.746% (24255/25600)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.761% (24380/25728)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.763% (24502/25856)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.762% (24623/25984)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.769% (24746/26112)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.756% (24864/26240)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.763% (24987/26368)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.777% (25112/26496)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.779% (25234/26624)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.774% (25354/26752)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.777% (25476/26880)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.779% (25598/27008)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.797% (25724/27136)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.814% (25850/27264)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.823% (25974/27392)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.826% (26096/27520)\n",
      "Train Epoch: 5 | Loss: 0.154 | Acc: 94.824% (26217/27648)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.801% (26332/27776)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.796% (26452/27904)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.792% (26572/28032)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.787% (26692/28160)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.793% (26815/28288)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.795% (26937/28416)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.776% (27053/28544)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.765% (27171/28672)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.760% (27291/28800)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.759% (27412/28928)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.762% (27534/29056)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.757% (27654/29184)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.750% (27773/29312)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.749% (27894/29440)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.754% (28017/29568)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.750% (28137/29696)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.746% (28257/29824)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.748% (28379/29952)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.767% (28506/30080)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.760% (28625/30208)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.739% (28740/30336)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.741% (28862/30464)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.737% (28982/30592)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.736% (29103/30720)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.742% (29226/30848)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.751% (29350/30976)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.743% (29469/31104)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.752% (29593/31232)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.745% (29712/31360)\n",
      "Train Epoch: 5 | Loss: 0.155 | Acc: 94.747% (29834/31488)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.737% (29952/31616)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.723% (30069/31744)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.726% (30191/31872)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.731% (30314/32000)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.724% (30433/32128)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.720% (30553/32256)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.720% (30674/32384)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.725% (30797/32512)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.712% (30914/32640)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.717% (31037/32768)\n",
      "Train Epoch: 5 | Loss: 0.156 | Acc: 94.708% (31155/32896)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.692% (31271/33024)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.664% (31383/33152)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.663% (31504/33280)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.669% (31627/33408)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.662% (31746/33536)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.659% (31866/33664)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.650% (31984/33792)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.652% (32106/33920)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.640% (32223/34048)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.642% (32345/34176)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.645% (32467/34304)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.653% (32591/34432)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.650% (32711/34560)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.649% (32832/34688)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.646% (32952/34816)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.651% (33075/34944)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.648% (33195/35072)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.648% (33316/35200)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.639% (33434/35328)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.638% (33555/35456)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.646% (33679/35584)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.635% (33796/35712)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.637% (33918/35840)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.631% (34037/35968)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.637% (34160/36096)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.650% (34286/36224)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.658% (34410/36352)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.660% (34532/36480)\n",
      "Train Epoch: 5 | Loss: 0.157 | Acc: 94.665% (34655/36608)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.656% (34773/36736)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.642% (34889/36864)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.639% (35009/36992)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.631% (35127/37120)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.628% (35247/37248)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.622% (35366/37376)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.627% (35489/37504)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.622% (35608/37632)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.616% (35727/37760)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.629% (35853/37888)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.623% (35972/38016)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.628% (36095/38144)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.623% (36214/38272)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.622% (36335/38400)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.619% (36455/38528)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.635% (36582/38656)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.632% (36702/38784)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.626% (36821/38912)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.629% (36943/39040)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.621% (37061/39168)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.628% (37185/39296)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.628% (37306/39424)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.622% (37425/39552)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.624% (37547/39680)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.627% (37669/39808)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.626% (37790/39936)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.626% (37911/40064)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.618% (38029/40192)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.618% (38150/40320)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.620% (38272/40448)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.622% (38394/40576)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.627% (38517/40704)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.627% (38638/40832)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.636% (38763/40960)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.636% (38884/41088)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.628% (39002/41216)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.628% (39123/41344)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.630% (39245/41472)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.625% (39364/41600)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.618% (39482/41728)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.608% (39599/41856)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.596% (39715/41984)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.598% (39837/42112)\n",
      "Train Epoch: 5 | Loss: 0.158 | Acc: 94.598% (39958/42240)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.590% (40076/42368)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.585% (40195/42496)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.573% (40311/42624)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.573% (40432/42752)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.569% (40551/42880)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.566% (40671/43008)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.564% (40791/43136)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.564% (40912/43264)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.573% (41037/43392)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.559% (41152/43520)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.554% (41271/43648)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.547% (41389/43776)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.547% (41510/43904)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.561% (41637/44032)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.556% (41756/44160)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.565% (41881/44288)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.567% (42003/44416)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.567% (42124/44544)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.569% (42246/44672)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.562% (42364/44800)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.571% (42489/44928)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.571% (42610/45056)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.564% (42728/45184)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.562% (42848/45312)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.558% (42967/45440)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.551% (43085/45568)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.558% (43209/45696)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.557% (43330/45824)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.557% (43451/45952)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.562% (43574/46080)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.568% (43698/46208)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.577% (43823/46336)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.579% (43945/46464)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.574% (44064/46592)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.574% (44185/46720)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.576% (44307/46848)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.578% (44429/46976)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.578% (44550/47104)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.576% (44670/47232)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.578% (44792/47360)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.571% (44910/47488)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.571% (45031/47616)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.569% (45151/47744)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.575% (45275/47872)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.585% (45401/48000)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.585% (45522/48128)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.577% (45639/48256)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.587% (45765/48384)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.575% (45880/48512)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.572% (46000/48640)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.564% (46117/48768)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.558% (46235/48896)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.556% (46355/49024)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.548% (46472/49152)\n",
      "Train Epoch: 5 | Loss: 0.160 | Acc: 94.552% (46595/49280)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.554% (46717/49408)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.562% (46842/49536)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.559% (46962/49664)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.557% (47082/49792)\n",
      "Train Epoch: 5 | Loss: 0.159 | Acc: 94.555% (47202/49920)\n",
      "Train Epoch: 5 | Loss: 0.160 | Acc: 94.552% (47276/50000)\n",
      "Test Epoch: 5 | Loss: 0.324 | Acc: 90.000% (90/100)\n",
      "Test Epoch: 5 | Loss: 0.305 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 5 | Loss: 0.301 | Acc: 90.667% (272/300)\n",
      "Test Epoch: 5 | Loss: 0.291 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 5 | Loss: 0.291 | Acc: 90.800% (454/500)\n",
      "Test Epoch: 5 | Loss: 0.274 | Acc: 91.333% (548/600)\n",
      "Test Epoch: 5 | Loss: 0.281 | Acc: 91.143% (638/700)\n",
      "Test Epoch: 5 | Loss: 0.290 | Acc: 91.000% (728/800)\n",
      "Test Epoch: 5 | Loss: 0.294 | Acc: 91.000% (819/900)\n",
      "Test Epoch: 5 | Loss: 0.301 | Acc: 90.700% (907/1000)\n",
      "Test Epoch: 5 | Loss: 0.305 | Acc: 90.455% (995/1100)\n",
      "Test Epoch: 5 | Loss: 0.324 | Acc: 90.000% (1080/1200)\n",
      "Test Epoch: 5 | Loss: 0.309 | Acc: 90.385% (1175/1300)\n",
      "Test Epoch: 5 | Loss: 0.300 | Acc: 90.714% (1270/1400)\n",
      "Test Epoch: 5 | Loss: 0.301 | Acc: 90.600% (1359/1500)\n",
      "Test Epoch: 5 | Loss: 0.298 | Acc: 90.750% (1452/1600)\n",
      "Test Epoch: 5 | Loss: 0.300 | Acc: 90.882% (1545/1700)\n",
      "Test Epoch: 5 | Loss: 0.303 | Acc: 90.889% (1636/1800)\n",
      "Test Epoch: 5 | Loss: 0.313 | Acc: 90.684% (1723/1900)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.550% (1811/2000)\n",
      "Test Epoch: 5 | Loss: 0.324 | Acc: 90.381% (1898/2100)\n",
      "Test Epoch: 5 | Loss: 0.321 | Acc: 90.455% (1990/2200)\n",
      "Test Epoch: 5 | Loss: 0.327 | Acc: 90.391% (2079/2300)\n",
      "Test Epoch: 5 | Loss: 0.330 | Acc: 90.417% (2170/2400)\n",
      "Test Epoch: 5 | Loss: 0.336 | Acc: 90.440% (2261/2500)\n",
      "Test Epoch: 5 | Loss: 0.340 | Acc: 90.308% (2348/2600)\n",
      "Test Epoch: 5 | Loss: 0.334 | Acc: 90.481% (2443/2700)\n",
      "Test Epoch: 5 | Loss: 0.337 | Acc: 90.464% (2533/2800)\n",
      "Test Epoch: 5 | Loss: 0.337 | Acc: 90.448% (2623/2900)\n",
      "Test Epoch: 5 | Loss: 0.339 | Acc: 90.333% (2710/3000)\n",
      "Test Epoch: 5 | Loss: 0.340 | Acc: 90.129% (2794/3100)\n",
      "Test Epoch: 5 | Loss: 0.338 | Acc: 90.125% (2884/3200)\n",
      "Test Epoch: 5 | Loss: 0.335 | Acc: 90.212% (2977/3300)\n",
      "Test Epoch: 5 | Loss: 0.332 | Acc: 90.265% (3069/3400)\n",
      "Test Epoch: 5 | Loss: 0.334 | Acc: 90.257% (3159/3500)\n",
      "Test Epoch: 5 | Loss: 0.331 | Acc: 90.333% (3252/3600)\n",
      "Test Epoch: 5 | Loss: 0.333 | Acc: 90.270% (3340/3700)\n",
      "Test Epoch: 5 | Loss: 0.339 | Acc: 90.132% (3425/3800)\n",
      "Test Epoch: 5 | Loss: 0.336 | Acc: 90.231% (3519/3900)\n",
      "Test Epoch: 5 | Loss: 0.332 | Acc: 90.300% (3612/4000)\n",
      "Test Epoch: 5 | Loss: 0.332 | Acc: 90.293% (3702/4100)\n",
      "Test Epoch: 5 | Loss: 0.329 | Acc: 90.286% (3792/4200)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.326% (3884/4300)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.386% (3977/4400)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.378% (4067/4500)\n",
      "Test Epoch: 5 | Loss: 0.325 | Acc: 90.435% (4160/4600)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.383% (4248/4700)\n",
      "Test Epoch: 5 | Loss: 0.328 | Acc: 90.333% (4336/4800)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.327% (4426/4900)\n",
      "Test Epoch: 5 | Loss: 0.329 | Acc: 90.280% (4514/5000)\n",
      "Test Epoch: 5 | Loss: 0.328 | Acc: 90.314% (4606/5100)\n",
      "Test Epoch: 5 | Loss: 0.329 | Acc: 90.250% (4693/5200)\n",
      "Test Epoch: 5 | Loss: 0.330 | Acc: 90.208% (4781/5300)\n",
      "Test Epoch: 5 | Loss: 0.330 | Acc: 90.185% (4870/5400)\n",
      "Test Epoch: 5 | Loss: 0.332 | Acc: 90.164% (4959/5500)\n",
      "Test Epoch: 5 | Loss: 0.330 | Acc: 90.179% (5050/5600)\n",
      "Test Epoch: 5 | Loss: 0.329 | Acc: 90.193% (5141/5700)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.241% (5234/5800)\n",
      "Test Epoch: 5 | Loss: 0.328 | Acc: 90.203% (5322/5900)\n",
      "Test Epoch: 5 | Loss: 0.327 | Acc: 90.183% (5411/6000)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.180% (5501/6100)\n",
      "Test Epoch: 5 | Loss: 0.326 | Acc: 90.194% (5592/6200)\n",
      "Test Epoch: 5 | Loss: 0.323 | Acc: 90.302% (5689/6300)\n",
      "Test Epoch: 5 | Loss: 0.322 | Acc: 90.359% (5783/6400)\n",
      "Test Epoch: 5 | Loss: 0.324 | Acc: 90.308% (5870/6500)\n",
      "Test Epoch: 5 | Loss: 0.322 | Acc: 90.348% (5963/6600)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.403% (6057/6700)\n",
      "Test Epoch: 5 | Loss: 0.321 | Acc: 90.382% (6146/6800)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.391% (6237/6900)\n",
      "Test Epoch: 5 | Loss: 0.321 | Acc: 90.357% (6325/7000)\n",
      "Test Epoch: 5 | Loss: 0.323 | Acc: 90.338% (6414/7100)\n",
      "Test Epoch: 5 | Loss: 0.322 | Acc: 90.361% (6506/7200)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.397% (6599/7300)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.459% (6694/7400)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.453% (6784/7500)\n",
      "Test Epoch: 5 | Loss: 0.318 | Acc: 90.447% (6874/7600)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.429% (6963/7700)\n",
      "Test Epoch: 5 | Loss: 0.318 | Acc: 90.449% (7055/7800)\n",
      "Test Epoch: 5 | Loss: 0.318 | Acc: 90.430% (7144/7900)\n",
      "Test Epoch: 5 | Loss: 0.318 | Acc: 90.412% (7233/8000)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.432% (7325/8100)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.354% (7409/8200)\n",
      "Test Epoch: 5 | Loss: 0.316 | Acc: 90.386% (7502/8300)\n",
      "Test Epoch: 5 | Loss: 0.316 | Acc: 90.381% (7592/8400)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.318% (7677/8500)\n",
      "Test Epoch: 5 | Loss: 0.321 | Acc: 90.221% (7759/8600)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.276% (7854/8700)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.273% (7944/8800)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.292% (8036/8900)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.278% (8125/9000)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.330% (8220/9100)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.315% (8309/9200)\n",
      "Test Epoch: 5 | Loss: 0.321 | Acc: 90.290% (8397/9300)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.309% (8489/9400)\n",
      "Test Epoch: 5 | Loss: 0.320 | Acc: 90.305% (8579/9500)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.312% (8670/9600)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.340% (8763/9700)\n",
      "Test Epoch: 5 | Loss: 0.317 | Acc: 90.347% (8854/9800)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.333% (8943/9900)\n",
      "Test Epoch: 5 | Loss: 0.319 | Acc: 90.320% (9032/10000)\n",
      "\n",
      "Epoch: 6\n",
      "Train Epoch: 6 | Loss: 0.178 | Acc: 93.750% (120/128)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.922% (243/256)\n",
      "Train Epoch: 6 | Loss: 0.135 | Acc: 94.792% (364/384)\n",
      "Train Epoch: 6 | Loss: 0.149 | Acc: 94.141% (482/512)\n",
      "Train Epoch: 6 | Loss: 0.137 | Acc: 94.375% (604/640)\n",
      "Train Epoch: 6 | Loss: 0.128 | Acc: 94.922% (729/768)\n",
      "Train Epoch: 6 | Loss: 0.119 | Acc: 95.536% (856/896)\n",
      "Train Epoch: 6 | Loss: 0.111 | Acc: 95.996% (983/1024)\n",
      "Train Epoch: 6 | Loss: 0.111 | Acc: 95.920% (1105/1152)\n",
      "Train Epoch: 6 | Loss: 0.111 | Acc: 96.094% (1230/1280)\n",
      "Train Epoch: 6 | Loss: 0.118 | Acc: 95.881% (1350/1408)\n",
      "Train Epoch: 6 | Loss: 0.120 | Acc: 95.898% (1473/1536)\n",
      "Train Epoch: 6 | Loss: 0.126 | Acc: 95.673% (1592/1664)\n",
      "Train Epoch: 6 | Loss: 0.123 | Acc: 95.815% (1717/1792)\n",
      "Train Epoch: 6 | Loss: 0.121 | Acc: 95.885% (1841/1920)\n",
      "Train Epoch: 6 | Loss: 0.125 | Acc: 95.752% (1961/2048)\n",
      "Train Epoch: 6 | Loss: 0.127 | Acc: 95.634% (2081/2176)\n",
      "Train Epoch: 6 | Loss: 0.129 | Acc: 95.486% (2200/2304)\n",
      "Train Epoch: 6 | Loss: 0.130 | Acc: 95.518% (2323/2432)\n",
      "Train Epoch: 6 | Loss: 0.132 | Acc: 95.469% (2444/2560)\n",
      "Train Epoch: 6 | Loss: 0.136 | Acc: 95.275% (2561/2688)\n",
      "Train Epoch: 6 | Loss: 0.141 | Acc: 95.064% (2677/2816)\n",
      "Train Epoch: 6 | Loss: 0.141 | Acc: 95.041% (2798/2944)\n",
      "Train Epoch: 6 | Loss: 0.143 | Acc: 95.020% (2919/3072)\n",
      "Train Epoch: 6 | Loss: 0.141 | Acc: 95.125% (3044/3200)\n",
      "Train Epoch: 6 | Loss: 0.139 | Acc: 95.192% (3168/3328)\n",
      "Train Epoch: 6 | Loss: 0.139 | Acc: 95.284% (3293/3456)\n",
      "Train Epoch: 6 | Loss: 0.140 | Acc: 95.312% (3416/3584)\n",
      "Train Epoch: 6 | Loss: 0.140 | Acc: 95.312% (3538/3712)\n",
      "Train Epoch: 6 | Loss: 0.140 | Acc: 95.260% (3658/3840)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.161% (3776/3968)\n",
      "Train Epoch: 6 | Loss: 0.144 | Acc: 95.142% (3897/4096)\n",
      "Train Epoch: 6 | Loss: 0.143 | Acc: 95.147% (4019/4224)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.198% (4143/4352)\n",
      "Train Epoch: 6 | Loss: 0.144 | Acc: 95.156% (4263/4480)\n",
      "Train Epoch: 6 | Loss: 0.143 | Acc: 95.182% (4386/4608)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.207% (4509/4736)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.210% (4631/4864)\n",
      "Train Epoch: 6 | Loss: 0.143 | Acc: 95.092% (4747/4992)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.137% (4871/5120)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.103% (4991/5248)\n",
      "Train Epoch: 6 | Loss: 0.142 | Acc: 95.108% (5113/5376)\n",
      "Train Epoch: 6 | Loss: 0.145 | Acc: 95.040% (5231/5504)\n",
      "Train Epoch: 6 | Loss: 0.145 | Acc: 95.099% (5356/5632)\n",
      "Train Epoch: 6 | Loss: 0.145 | Acc: 95.069% (5476/5760)\n",
      "Train Epoch: 6 | Loss: 0.146 | Acc: 95.024% (5595/5888)\n",
      "Train Epoch: 6 | Loss: 0.146 | Acc: 95.013% (5716/6016)\n",
      "Train Epoch: 6 | Loss: 0.145 | Acc: 95.068% (5841/6144)\n",
      "Train Epoch: 6 | Loss: 0.146 | Acc: 95.089% (5964/6272)\n",
      "Train Epoch: 6 | Loss: 0.147 | Acc: 94.938% (6076/6400)\n",
      "Train Epoch: 6 | Loss: 0.146 | Acc: 94.960% (6199/6528)\n",
      "Train Epoch: 6 | Loss: 0.148 | Acc: 94.937% (6319/6656)\n",
      "Train Epoch: 6 | Loss: 0.149 | Acc: 94.915% (6439/6784)\n",
      "Train Epoch: 6 | Loss: 0.148 | Acc: 94.907% (6560/6912)\n",
      "Train Epoch: 6 | Loss: 0.149 | Acc: 94.872% (6679/7040)\n",
      "Train Epoch: 6 | Loss: 0.149 | Acc: 94.824% (6797/7168)\n",
      "Train Epoch: 6 | Loss: 0.151 | Acc: 94.709% (6910/7296)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.733% (7033/7424)\n",
      "Train Epoch: 6 | Loss: 0.149 | Acc: 94.743% (7155/7552)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.740% (7276/7680)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.736% (7397/7808)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.733% (7518/7936)\n",
      "Train Epoch: 6 | Loss: 0.151 | Acc: 94.767% (7642/8064)\n",
      "Train Epoch: 6 | Loss: 0.150 | Acc: 94.800% (7766/8192)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.712% (7880/8320)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.709% (8001/8448)\n",
      "Train Epoch: 6 | Loss: 0.151 | Acc: 94.753% (8126/8576)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.727% (8245/8704)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.678% (8362/8832)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.632% (8479/8960)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.674% (8604/9088)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.651% (8723/9216)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.617% (8841/9344)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.637% (8964/9472)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.594% (9081/9600)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.593% (9202/9728)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.612% (9325/9856)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.661% (9451/9984)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.680% (9574/10112)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.619% (9689/10240)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.628% (9811/10368)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.588% (9928/10496)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.569% (10047/10624)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.559% (10167/10752)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.605% (10293/10880)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.595% (10413/11008)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.612% (10536/11136)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.585% (10654/11264)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.601% (10777/11392)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.601% (10898/11520)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.626% (11022/11648)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.608% (11141/11776)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.615% (11263/11904)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.589% (11381/12032)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.581% (11501/12160)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.580% (11622/12288)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.563% (11741/12416)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.571% (11863/12544)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.563% (11983/12672)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.547% (12102/12800)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.547% (12223/12928)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.539% (12343/13056)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.562% (12467/13184)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.554% (12587/13312)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.576% (12711/13440)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.568% (12831/13568)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.590% (12955/13696)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.625% (13081/13824)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.624% (13202/13952)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.602% (13320/14080)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.595% (13440/14208)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.615% (13564/14336)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.621% (13686/14464)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.634% (13809/14592)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.647% (13932/14720)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.659% (14055/14848)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.651% (14175/14976)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.657% (14297/15104)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.663% (14419/15232)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.688% (14544/15360)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.712% (14669/15488)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.736% (14794/15616)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.747% (14917/15744)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.764% (15041/15872)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.744% (15159/16000)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.742% (15280/16128)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.728% (15399/16256)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.720% (15519/16384)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.719% (15640/16512)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.712% (15760/16640)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.698% (15879/16768)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.691% (15999/16896)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.696% (16121/17024)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.654% (16235/17152)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.670% (16359/17280)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.663% (16479/17408)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.674% (16602/17536)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.661% (16721/17664)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.666% (16843/17792)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.665% (16964/17920)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.670% (17086/18048)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.680% (17209/18176)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.690% (17332/18304)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.710% (17457/18432)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.714% (17579/18560)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.692% (17696/18688)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.696% (17818/18816)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.711% (17942/18944)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.736% (18068/19072)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.714% (18185/19200)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.733% (18310/19328)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.727% (18430/19456)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.710% (18548/19584)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.719% (18671/19712)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.728% (18794/19840)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.732% (18916/19968)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.735% (19038/20096)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.739% (19160/20224)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.747% (19283/20352)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.741% (19403/20480)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.764% (19529/20608)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.768% (19651/20736)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.771% (19773/20864)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.779% (19896/20992)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.777% (20017/21120)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.771% (20137/21248)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.746% (20253/21376)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.745% (20374/21504)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.749% (20496/21632)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.766% (20621/21760)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.778% (20745/21888)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.763% (20863/22016)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.775% (20987/22144)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.769% (21107/22272)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.777% (21230/22400)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.780% (21352/22528)\n",
      "Train Epoch: 6 | Loss: 0.152 | Acc: 94.774% (21472/22656)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.742% (21586/22784)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.728% (21704/22912)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.727% (21825/23040)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.730% (21947/23168)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.742% (22071/23296)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.728% (22189/23424)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.718% (22308/23552)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.709% (22427/23680)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.695% (22545/23808)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.690% (22665/23936)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.673% (22782/24064)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.676% (22904/24192)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.683% (23027/24320)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.683% (23148/24448)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.674% (23267/24576)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.665% (23386/24704)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.676% (23510/24832)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.679% (23632/24960)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.671% (23751/25088)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.678% (23874/25216)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.685% (23997/25344)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.661% (24112/25472)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.676% (24237/25600)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.687% (24361/25728)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.682% (24481/25856)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.693% (24605/25984)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.696% (24727/26112)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.684% (24845/26240)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.683% (24966/26368)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.667% (25083/26496)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.681% (25208/26624)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.692% (25332/26752)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.695% (25454/26880)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.690% (25574/27008)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.697% (25697/27136)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.689% (25816/27264)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.699% (25940/27392)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.698% (26061/27520)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.683% (26178/27648)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.672% (26296/27776)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.657% (26413/27904)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.649% (26532/28032)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.648% (26653/28160)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.637% (26771/28288)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.651% (26896/28416)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.650% (27017/28544)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.657% (27140/28672)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.653% (27260/28800)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.652% (27381/28928)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.648% (27501/29056)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.651% (27623/29184)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.654% (27745/29312)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.664% (27869/29440)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.673% (27993/29568)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.676% (28115/29696)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.675% (28236/29824)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.681% (28359/29952)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.684% (28481/30080)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.684% (28602/30208)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.673% (28720/30336)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.679% (28843/30464)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.688% (28967/30592)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.697% (29091/30720)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.700% (29213/30848)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.696% (29333/30976)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.689% (29452/31104)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.691% (29574/31232)\n",
      "Train Epoch: 6 | Loss: 0.153 | Acc: 94.688% (29694/31360)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.661% (29807/31488)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.651% (29925/31616)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.645% (30044/31744)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.641% (30164/31872)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.653% (30289/32000)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.662% (30413/32128)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.652% (30531/32256)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.667% (30657/32384)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.660% (30776/32512)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.663% (30898/32640)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.644% (31013/32768)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.653% (31137/32896)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.649% (31257/33024)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.652% (31379/33152)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.651% (31500/33280)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.651% (31621/33408)\n",
      "Train Epoch: 6 | Loss: 0.154 | Acc: 94.642% (31739/33536)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.635% (31858/33664)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.635% (31979/33792)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.637% (32101/33920)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.637% (32222/34048)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.645% (32346/34176)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.648% (32468/34304)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.642% (32587/34432)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.638% (32707/34560)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.647% (32831/34688)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.652% (32954/34816)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.651% (33075/34944)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.654% (33197/35072)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.648% (33316/35200)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.644% (33436/35328)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.638% (33555/35456)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.630% (33673/35584)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.632% (33795/35712)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.634% (33917/35840)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.629% (34036/35968)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.628% (34157/36096)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.620% (34275/36224)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.619% (34396/36352)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.616% (34516/36480)\n",
      "Train Epoch: 6 | Loss: 0.155 | Acc: 94.616% (34637/36608)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.613% (34757/36736)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.588% (34869/36864)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.588% (34990/36992)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.588% (35111/37120)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.580% (35229/37248)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.579% (35350/37376)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.585% (35473/37504)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.587% (35595/37632)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.584% (35715/37760)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.595% (35840/37888)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.586% (35958/38016)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.578% (36076/38144)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.576% (36196/38272)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.568% (36314/38400)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.560% (36432/38528)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.560% (36553/38656)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.557% (36673/38784)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.562% (36796/38912)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.570% (36920/39040)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.559% (37037/39168)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.569% (37162/39296)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.577% (37286/39424)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.574% (37406/39552)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.564% (37523/39680)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.566% (37645/39808)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.556% (37762/39936)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.559% (37884/40064)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.561% (38006/40192)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.551% (38123/40320)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.551% (38244/40448)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.551% (38365/40576)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.556% (38488/40704)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.558% (38610/40832)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.548% (38727/40960)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.541% (38845/41088)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (38962/41216)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.536% (39085/41344)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.538% (39207/41472)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.541% (39329/41600)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.543% (39451/41728)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.546% (39573/41856)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.550% (39696/41984)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.553% (39818/42112)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.557% (39941/42240)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.562% (40064/42368)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.564% (40186/42496)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.573% (40311/42624)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.571% (40431/42752)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.564% (40549/42880)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.568% (40672/43008)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.566% (40792/43136)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.561% (40911/43264)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.566% (41034/43392)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.568% (41156/43520)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.563% (41275/43648)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.572% (41400/43776)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.577% (41523/43904)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.577% (41644/44032)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.577% (41765/44160)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.567% (41882/44288)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.570% (42004/44416)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.567% (42124/44544)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.567% (42245/44672)\n",
      "Train Epoch: 6 | Loss: 0.156 | Acc: 94.574% (42369/44800)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.571% (42489/44928)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.565% (42607/45056)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.562% (42727/45184)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.556% (42845/45312)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.558% (42967/45440)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.558% (43088/45568)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.562% (43211/45696)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.549% (43326/45824)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.546% (43446/45952)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.546% (43567/46080)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.542% (43686/46208)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.544% (43808/46336)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.542% (43928/46464)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.527% (44042/46592)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.538% (44168/46720)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (44286/46848)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.533% (44408/46976)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.533% (44529/47104)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.529% (44648/47232)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.525% (44767/47360)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.527% (44889/47488)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.529% (45011/47616)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.533% (45134/47744)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.533% (45255/47872)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (45375/48000)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.523% (45492/48128)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.525% (45614/48256)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (45738/48384)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.529% (45858/48512)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (45980/48640)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.535% (46103/48768)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.537% (46225/48896)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.531% (46343/49024)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.533% (46465/49152)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.539% (46589/49280)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.539% (46710/49408)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.547% (46835/49536)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.545% (46955/49664)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.547% (47077/49792)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.545% (47197/49920)\n",
      "Train Epoch: 6 | Loss: 0.157 | Acc: 94.548% (47274/50000)\n",
      "Test Epoch: 6 | Loss: 0.250 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 6 | Loss: 0.308 | Acc: 92.500% (185/200)\n",
      "Test Epoch: 6 | Loss: 0.304 | Acc: 91.000% (273/300)\n",
      "Test Epoch: 6 | Loss: 0.295 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 6 | Loss: 0.282 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 6 | Loss: 0.257 | Acc: 91.500% (549/600)\n",
      "Test Epoch: 6 | Loss: 0.276 | Acc: 91.571% (641/700)\n",
      "Test Epoch: 6 | Loss: 0.302 | Acc: 90.750% (726/800)\n",
      "Test Epoch: 6 | Loss: 0.318 | Acc: 90.667% (816/900)\n",
      "Test Epoch: 6 | Loss: 0.327 | Acc: 90.500% (905/1000)\n",
      "Test Epoch: 6 | Loss: 0.338 | Acc: 90.091% (991/1100)\n",
      "Test Epoch: 6 | Loss: 0.342 | Acc: 90.000% (1080/1200)\n",
      "Test Epoch: 6 | Loss: 0.338 | Acc: 90.077% (1171/1300)\n",
      "Test Epoch: 6 | Loss: 0.330 | Acc: 90.286% (1264/1400)\n",
      "Test Epoch: 6 | Loss: 0.324 | Acc: 90.333% (1355/1500)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.375% (1446/1600)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.529% (1539/1700)\n",
      "Test Epoch: 6 | Loss: 0.311 | Acc: 90.500% (1629/1800)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.316% (1716/1900)\n",
      "Test Epoch: 6 | Loss: 0.323 | Acc: 90.200% (1804/2000)\n",
      "Test Epoch: 6 | Loss: 0.325 | Acc: 90.095% (1892/2100)\n",
      "Test Epoch: 6 | Loss: 0.323 | Acc: 90.091% (1982/2200)\n",
      "Test Epoch: 6 | Loss: 0.329 | Acc: 89.957% (2069/2300)\n",
      "Test Epoch: 6 | Loss: 0.330 | Acc: 90.000% (2160/2400)\n",
      "Test Epoch: 6 | Loss: 0.336 | Acc: 89.920% (2248/2500)\n",
      "Test Epoch: 6 | Loss: 0.336 | Acc: 89.962% (2339/2600)\n",
      "Test Epoch: 6 | Loss: 0.336 | Acc: 90.074% (2432/2700)\n",
      "Test Epoch: 6 | Loss: 0.342 | Acc: 90.036% (2521/2800)\n",
      "Test Epoch: 6 | Loss: 0.344 | Acc: 90.103% (2613/2900)\n",
      "Test Epoch: 6 | Loss: 0.345 | Acc: 90.133% (2704/3000)\n",
      "Test Epoch: 6 | Loss: 0.350 | Acc: 89.806% (2784/3100)\n",
      "Test Epoch: 6 | Loss: 0.348 | Acc: 89.844% (2875/3200)\n",
      "Test Epoch: 6 | Loss: 0.345 | Acc: 89.848% (2965/3300)\n",
      "Test Epoch: 6 | Loss: 0.339 | Acc: 90.000% (3060/3400)\n",
      "Test Epoch: 6 | Loss: 0.339 | Acc: 89.943% (3148/3500)\n",
      "Test Epoch: 6 | Loss: 0.336 | Acc: 90.028% (3241/3600)\n",
      "Test Epoch: 6 | Loss: 0.338 | Acc: 89.892% (3326/3700)\n",
      "Test Epoch: 6 | Loss: 0.341 | Acc: 89.842% (3414/3800)\n",
      "Test Epoch: 6 | Loss: 0.337 | Acc: 89.974% (3509/3900)\n",
      "Test Epoch: 6 | Loss: 0.335 | Acc: 90.050% (3602/4000)\n",
      "Test Epoch: 6 | Loss: 0.338 | Acc: 89.976% (3689/4100)\n",
      "Test Epoch: 6 | Loss: 0.336 | Acc: 89.976% (3779/4200)\n",
      "Test Epoch: 6 | Loss: 0.333 | Acc: 90.070% (3873/4300)\n",
      "Test Epoch: 6 | Loss: 0.331 | Acc: 90.159% (3967/4400)\n",
      "Test Epoch: 6 | Loss: 0.326 | Acc: 90.289% (4063/4500)\n",
      "Test Epoch: 6 | Loss: 0.326 | Acc: 90.348% (4156/4600)\n",
      "Test Epoch: 6 | Loss: 0.327 | Acc: 90.340% (4246/4700)\n",
      "Test Epoch: 6 | Loss: 0.328 | Acc: 90.250% (4332/4800)\n",
      "Test Epoch: 6 | Loss: 0.328 | Acc: 90.245% (4422/4900)\n",
      "Test Epoch: 6 | Loss: 0.331 | Acc: 90.180% (4509/5000)\n",
      "Test Epoch: 6 | Loss: 0.332 | Acc: 90.176% (4599/5100)\n",
      "Test Epoch: 6 | Loss: 0.332 | Acc: 90.135% (4687/5200)\n",
      "Test Epoch: 6 | Loss: 0.335 | Acc: 90.094% (4775/5300)\n",
      "Test Epoch: 6 | Loss: 0.333 | Acc: 90.148% (4868/5400)\n",
      "Test Epoch: 6 | Loss: 0.332 | Acc: 90.127% (4957/5500)\n",
      "Test Epoch: 6 | Loss: 0.333 | Acc: 90.107% (5046/5600)\n",
      "Test Epoch: 6 | Loss: 0.332 | Acc: 90.123% (5137/5700)\n",
      "Test Epoch: 6 | Loss: 0.330 | Acc: 90.121% (5227/5800)\n",
      "Test Epoch: 6 | Loss: 0.330 | Acc: 90.169% (5320/5900)\n",
      "Test Epoch: 6 | Loss: 0.330 | Acc: 90.183% (5411/6000)\n",
      "Test Epoch: 6 | Loss: 0.327 | Acc: 90.230% (5504/6100)\n",
      "Test Epoch: 6 | Loss: 0.326 | Acc: 90.210% (5593/6200)\n",
      "Test Epoch: 6 | Loss: 0.323 | Acc: 90.302% (5689/6300)\n",
      "Test Epoch: 6 | Loss: 0.320 | Acc: 90.391% (5785/6400)\n",
      "Test Epoch: 6 | Loss: 0.321 | Acc: 90.338% (5872/6500)\n",
      "Test Epoch: 6 | Loss: 0.320 | Acc: 90.364% (5964/6600)\n",
      "Test Epoch: 6 | Loss: 0.317 | Acc: 90.433% (6059/6700)\n",
      "Test Epoch: 6 | Loss: 0.319 | Acc: 90.412% (6148/6800)\n",
      "Test Epoch: 6 | Loss: 0.319 | Acc: 90.406% (6238/6900)\n",
      "Test Epoch: 6 | Loss: 0.320 | Acc: 90.329% (6323/7000)\n",
      "Test Epoch: 6 | Loss: 0.321 | Acc: 90.310% (6412/7100)\n",
      "Test Epoch: 6 | Loss: 0.321 | Acc: 90.347% (6505/7200)\n",
      "Test Epoch: 6 | Loss: 0.319 | Acc: 90.425% (6601/7300)\n",
      "Test Epoch: 6 | Loss: 0.318 | Acc: 90.459% (6694/7400)\n",
      "Test Epoch: 6 | Loss: 0.317 | Acc: 90.467% (6785/7500)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.487% (6877/7600)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.481% (6967/7700)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.487% (7058/7800)\n",
      "Test Epoch: 6 | Loss: 0.314 | Acc: 90.481% (7148/7900)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.463% (7237/8000)\n",
      "Test Epoch: 6 | Loss: 0.313 | Acc: 90.494% (7330/8100)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.463% (7418/8200)\n",
      "Test Epoch: 6 | Loss: 0.314 | Acc: 90.458% (7508/8300)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.488% (7601/8400)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.506% (7693/8500)\n",
      "Test Epoch: 6 | Loss: 0.317 | Acc: 90.442% (7778/8600)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.448% (7869/8700)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.443% (7959/8800)\n",
      "Test Epoch: 6 | Loss: 0.317 | Acc: 90.393% (8045/8900)\n",
      "Test Epoch: 6 | Loss: 0.316 | Acc: 90.422% (8138/9000)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.462% (8232/9100)\n",
      "Test Epoch: 6 | Loss: 0.313 | Acc: 90.478% (8324/9200)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.452% (8412/9300)\n",
      "Test Epoch: 6 | Loss: 0.315 | Acc: 90.489% (8506/9400)\n",
      "Test Epoch: 6 | Loss: 0.313 | Acc: 90.495% (8597/9500)\n",
      "Test Epoch: 6 | Loss: 0.312 | Acc: 90.490% (8687/9600)\n",
      "Test Epoch: 6 | Loss: 0.310 | Acc: 90.546% (8783/9700)\n",
      "Test Epoch: 6 | Loss: 0.311 | Acc: 90.531% (8872/9800)\n",
      "Test Epoch: 6 | Loss: 0.312 | Acc: 90.525% (8962/9900)\n",
      "Test Epoch: 6 | Loss: 0.312 | Acc: 90.540% (9054/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Train Epoch: 7 | Loss: 0.096 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 7 | Loss: 0.137 | Acc: 95.703% (245/256)\n",
      "Train Epoch: 7 | Loss: 0.140 | Acc: 95.573% (367/384)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.922% (486/512)\n",
      "Train Epoch: 7 | Loss: 0.141 | Acc: 95.156% (609/640)\n",
      "Train Epoch: 7 | Loss: 0.143 | Acc: 94.922% (729/768)\n",
      "Train Epoch: 7 | Loss: 0.138 | Acc: 95.201% (853/896)\n",
      "Train Epoch: 7 | Loss: 0.143 | Acc: 95.117% (974/1024)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.878% (1093/1152)\n",
      "Train Epoch: 7 | Loss: 0.144 | Acc: 95.078% (1217/1280)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.886% (1336/1408)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.987% (1459/1536)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.892% (1579/1664)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.810% (1699/1792)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.635% (1817/1920)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.727% (1940/2048)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.853% (2064/2176)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.792% (2184/2304)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.942% (2309/2432)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.805% (2427/2560)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.717% (2546/2688)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.602% (2664/2816)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.463% (2781/2944)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.531% (2904/3072)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.375% (3020/3200)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.531% (3146/3328)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.358% (3261/3456)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.392% (3383/3584)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.450% (3506/3712)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.479% (3628/3840)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.531% (3751/3968)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.604% (3875/4096)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.460% (3990/4224)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.439% (4110/4352)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.442% (4231/4480)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.444% (4352/4608)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.405% (4471/4736)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.449% (4594/4864)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.391% (4712/4992)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.316% (4829/5120)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.360% (4952/5248)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.308% (5070/5376)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.350% (5193/5504)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.407% (5317/5632)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.392% (5437/5760)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.463% (5562/5888)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.481% (5684/6016)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.515% (5807/6144)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.436% (5923/6272)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.438% (6044/6400)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.501% (6169/6528)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.501% (6290/6656)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.502% (6411/6784)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.502% (6532/6912)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.503% (6653/7040)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.545% (6777/7168)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.518% (6896/7296)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.545% (7019/7424)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.571% (7142/7552)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.583% (7264/7680)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.595% (7386/7808)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.619% (7509/7936)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.643% (7632/8064)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.702% (7758/8192)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.748% (7883/8320)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.804% (8009/8448)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.823% (8132/8576)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.841% (8255/8704)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.814% (8374/8832)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.810% (8495/8960)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.795% (8615/9088)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.792% (8736/9216)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.810% (8859/9344)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.837% (8983/9472)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.812% (9102/9600)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.829% (9225/9728)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.836% (9347/9856)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.892% (9474/9984)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.887% (9595/10112)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.902% (9718/10240)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.888% (9838/10368)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.893% (9960/10496)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.880% (10080/10624)\n",
      "Train Epoch: 7 | Loss: 0.147 | Acc: 94.903% (10204/10752)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.881% (10323/10880)\n",
      "Train Epoch: 7 | Loss: 0.148 | Acc: 94.895% (10446/11008)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.846% (10562/11136)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.806% (10679/11264)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.786% (10798/11392)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.800% (10921/11520)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.772% (11039/11648)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.769% (11160/11776)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.775% (11282/11904)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.797% (11406/12032)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.819% (11530/12160)\n",
      "Train Epoch: 7 | Loss: 0.149 | Acc: 94.840% (11654/12288)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.829% (11774/12416)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.794% (11891/12544)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.800% (12013/12672)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.758% (12129/12800)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.771% (12252/12928)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.776% (12374/13056)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.797% (12498/13184)\n",
      "Train Epoch: 7 | Loss: 0.150 | Acc: 94.787% (12618/13312)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.777% (12738/13440)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.752% (12856/13568)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.728% (12974/13696)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.719% (13094/13824)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.718% (13215/13952)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.723% (13337/14080)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.735% (13460/14208)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.734% (13581/14336)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.725% (13701/14464)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.723% (13822/14592)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.708% (13941/14720)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.713% (14063/14848)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.738% (14188/14976)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.750% (14311/15104)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.735% (14430/15232)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.720% (14549/15360)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.693% (14666/15488)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.691% (14787/15616)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.658% (14903/15744)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.682% (15028/15872)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.688% (15150/16000)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.711% (15275/16128)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.703% (15395/16256)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.678% (15512/16384)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.683% (15634/16512)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.675% (15754/16640)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.698% (15879/16768)\n",
      "Train Epoch: 7 | Loss: 0.151 | Acc: 94.709% (16002/16896)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.690% (16120/17024)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.677% (16239/17152)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.682% (16361/17280)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.692% (16484/17408)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.691% (16605/17536)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.701% (16728/17664)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.711% (16851/17792)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.710% (16972/17920)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.692% (17090/18048)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.691% (17211/18176)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.662% (17327/18304)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.683% (17452/18432)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.682% (17573/18560)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.670% (17692/18688)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.664% (17812/18816)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.663% (17933/18944)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.673% (18056/19072)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.661% (18175/19200)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.666% (18297/19328)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.675% (18420/19456)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.679% (18542/19584)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.638% (18655/19712)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.617% (18772/19840)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.626% (18895/19968)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.636% (19018/20096)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.645% (19141/20224)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.644% (19262/20352)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.639% (19382/20480)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.633% (19502/20608)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.637% (19624/20736)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.656% (19749/20864)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.665% (19872/20992)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.678% (19996/21120)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.682% (20118/21248)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.700% (20243/21376)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.689% (20362/21504)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.693% (20484/21632)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.706% (20608/21760)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.709% (20730/21888)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.699% (20849/22016)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.712% (20973/22144)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.711% (21094/22272)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.719% (21217/22400)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.735% (21342/22528)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.725% (21461/22656)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.720% (21581/22784)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.715% (21701/22912)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.727% (21825/23040)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.730% (21947/23168)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.729% (22068/23296)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.736% (22191/23424)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.735% (22312/23552)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.734% (22433/23680)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.733% (22554/23808)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.736% (22676/23936)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.727% (22795/24064)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.734% (22918/24192)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.725% (23037/24320)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.736% (23161/24448)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.739% (23283/24576)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.742% (23405/24704)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.749% (23528/24832)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.728% (23644/24960)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.723% (23764/25088)\n",
      "Train Epoch: 7 | Loss: 0.152 | Acc: 94.726% (23886/25216)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.717% (24005/25344)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.708% (24124/25472)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.691% (24241/25600)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.683% (24360/25728)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.678% (24480/25856)\n",
      "Train Epoch: 7 | Loss: 0.153 | Acc: 94.666% (24598/25984)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.654% (24716/26112)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.638% (24833/26240)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.641% (24955/26368)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.637% (25075/26496)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.633% (25195/26624)\n",
      "Train Epoch: 7 | Loss: 0.154 | Acc: 94.640% (25318/26752)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.632% (25437/26880)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.631% (25558/27008)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.620% (25676/27136)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.619% (25797/27264)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.615% (25917/27392)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.615% (26038/27520)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.607% (26157/27648)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.592% (26274/27776)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.585% (26393/27904)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.588% (26515/28032)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.599% (26639/28160)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.609% (26763/28288)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.612% (26885/28416)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.619% (27008/28544)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.608% (27126/28672)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.587% (27241/28800)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.600% (27366/28928)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.610% (27490/29056)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.607% (27610/29184)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.606% (27731/29312)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.606% (27852/29440)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.596% (27970/29568)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.609% (28095/29696)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.608% (28216/29824)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.618% (28340/29952)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.621% (28462/30080)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.624% (28584/30208)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.624% (28705/30336)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.633% (28829/30464)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.629% (28949/30592)\n",
      "Train Epoch: 7 | Loss: 0.155 | Acc: 94.619% (29067/30720)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.586% (29178/30848)\n",
      "Train Epoch: 7 | Loss: 0.156 | Acc: 94.583% (29298/30976)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.579% (29418/31104)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.573% (29537/31232)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.573% (29658/31360)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.573% (29779/31488)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.572% (29900/31616)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.563% (30018/31744)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.563% (30139/31872)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.559% (30259/32000)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.556% (30379/32128)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.541% (30495/32256)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.537% (30615/32384)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.537% (30736/32512)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.534% (30856/32640)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.537% (30978/32768)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.546% (31102/32896)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.537% (31220/33024)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.513% (31333/33152)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.510% (31453/33280)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.510% (31574/33408)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.510% (31695/33536)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.519% (31819/33664)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.537% (31946/33792)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.540% (32068/33920)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.534% (32187/34048)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (32303/34176)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (32424/34304)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.511% (32542/34432)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.511% (32663/34560)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.514% (32785/34688)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (32908/34816)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (33029/34944)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.506% (33145/35072)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.517% (33270/35200)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.523% (33393/35328)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (33513/35456)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.517% (33633/35584)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.514% (33753/35712)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.512% (33873/35840)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.517% (33996/35968)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.515% (34116/36096)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.523% (34240/36224)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.523% (34361/36352)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (34481/36480)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.523% (34603/36608)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (34723/36736)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.520% (34844/36864)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.526% (34967/36992)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.529% (35089/37120)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.539% (35214/37248)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.534% (35333/37376)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.537% (35455/37504)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.534% (35575/37632)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.523% (35692/37760)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.529% (35815/37888)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.529% (35936/38016)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.531% (36058/38144)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.550% (36186/38272)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.562% (36312/38400)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.565% (36434/38528)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.565% (36555/38656)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.562% (36675/38784)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (36798/38912)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.580% (36924/39040)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.587% (37048/39168)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.592% (37171/39296)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.577% (37286/39424)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.572% (37405/39552)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (37524/39680)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.561% (37643/39808)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.549% (37759/39936)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.544% (37878/40064)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.549% (38001/40192)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.546% (38121/40320)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.539% (38239/40448)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.536% (38359/40576)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.529% (38477/40704)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.526% (38597/40832)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.526% (38718/40960)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.526% (38839/41088)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.517% (38956/41216)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.514% (39076/41344)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.522% (39200/41472)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.522% (39321/41600)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.519% (39441/41728)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.512% (39559/41856)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.517% (39682/41984)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.512% (39801/42112)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.517% (39924/42240)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.524% (40048/42368)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.529% (40171/42496)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.538% (40296/42624)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.545% (40420/42752)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.538% (40538/42880)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.538% (40659/43008)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.545% (40783/43136)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.547% (40905/43264)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.554% (41029/43392)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.559% (41152/43520)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.563% (41275/43648)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.570% (41399/43776)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.575% (41522/43904)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.581% (41646/44032)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.574% (41764/44160)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (41882/44288)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.565% (42002/44416)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (42124/44544)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (42245/44672)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.571% (42368/44800)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.578% (42492/44928)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.578% (42613/45056)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.573% (42732/45184)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.575% (42854/45312)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.569% (42972/45440)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.571% (43094/45568)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.579% (43219/45696)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.588% (43344/45824)\n",
      "Train Epoch: 7 | Loss: 0.157 | Acc: 94.590% (43466/45952)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.581% (43583/46080)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.572% (43700/46208)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.579% (43824/46336)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.576% (43944/46464)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.566% (44060/46592)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.570% (44183/46720)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.580% (44309/46848)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.582% (44431/46976)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.565% (44544/47104)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.576% (44670/47232)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.578% (44792/47360)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.575% (44912/47488)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.569% (45030/47616)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.567% (45150/47744)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.569% (45272/47872)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.565% (45391/48000)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.571% (45515/48128)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.571% (45636/48256)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.577% (45760/48384)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.577% (45881/48512)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.579% (46003/48640)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.583% (46126/48768)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.582% (46247/48896)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.582% (46368/49024)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.574% (46485/49152)\n",
      "Train Epoch: 7 | Loss: 0.158 | Acc: 94.570% (46604/49280)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.562% (46721/49408)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.560% (46841/49536)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.555% (46960/49664)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.555% (47081/49792)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.559% (47204/49920)\n",
      "Train Epoch: 7 | Loss: 0.159 | Acc: 94.554% (47277/50000)\n",
      "Test Epoch: 7 | Loss: 0.291 | Acc: 89.000% (89/100)\n",
      "Test Epoch: 7 | Loss: 0.290 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 7 | Loss: 0.309 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 7 | Loss: 0.276 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 7 | Loss: 0.272 | Acc: 90.600% (453/500)\n",
      "Test Epoch: 7 | Loss: 0.260 | Acc: 91.000% (546/600)\n",
      "Test Epoch: 7 | Loss: 0.272 | Acc: 90.571% (634/700)\n",
      "Test Epoch: 7 | Loss: 0.292 | Acc: 89.875% (719/800)\n",
      "Test Epoch: 7 | Loss: 0.315 | Acc: 89.333% (804/900)\n",
      "Test Epoch: 7 | Loss: 0.334 | Acc: 89.000% (890/1000)\n",
      "Test Epoch: 7 | Loss: 0.345 | Acc: 88.727% (976/1100)\n",
      "Test Epoch: 7 | Loss: 0.347 | Acc: 88.417% (1061/1200)\n",
      "Test Epoch: 7 | Loss: 0.337 | Acc: 88.846% (1155/1300)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.143% (1248/1400)\n",
      "Test Epoch: 7 | Loss: 0.327 | Acc: 89.067% (1336/1500)\n",
      "Test Epoch: 7 | Loss: 0.332 | Acc: 88.875% (1422/1600)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.059% (1514/1700)\n",
      "Test Epoch: 7 | Loss: 0.332 | Acc: 88.889% (1600/1800)\n",
      "Test Epoch: 7 | Loss: 0.339 | Acc: 88.474% (1681/1900)\n",
      "Test Epoch: 7 | Loss: 0.342 | Acc: 88.550% (1771/2000)\n",
      "Test Epoch: 7 | Loss: 0.345 | Acc: 88.429% (1857/2100)\n",
      "Test Epoch: 7 | Loss: 0.345 | Acc: 88.273% (1942/2200)\n",
      "Test Epoch: 7 | Loss: 0.347 | Acc: 88.130% (2027/2300)\n",
      "Test Epoch: 7 | Loss: 0.344 | Acc: 88.167% (2116/2400)\n",
      "Test Epoch: 7 | Loss: 0.350 | Acc: 88.080% (2202/2500)\n",
      "Test Epoch: 7 | Loss: 0.354 | Acc: 88.154% (2292/2600)\n",
      "Test Epoch: 7 | Loss: 0.348 | Acc: 88.222% (2382/2700)\n",
      "Test Epoch: 7 | Loss: 0.350 | Acc: 88.286% (2472/2800)\n",
      "Test Epoch: 7 | Loss: 0.349 | Acc: 88.345% (2562/2900)\n",
      "Test Epoch: 7 | Loss: 0.350 | Acc: 88.367% (2651/3000)\n",
      "Test Epoch: 7 | Loss: 0.352 | Acc: 88.258% (2736/3100)\n",
      "Test Epoch: 7 | Loss: 0.350 | Acc: 88.281% (2825/3200)\n",
      "Test Epoch: 7 | Loss: 0.348 | Acc: 88.424% (2918/3300)\n",
      "Test Epoch: 7 | Loss: 0.343 | Acc: 88.559% (3011/3400)\n",
      "Test Epoch: 7 | Loss: 0.344 | Acc: 88.543% (3099/3500)\n",
      "Test Epoch: 7 | Loss: 0.340 | Acc: 88.694% (3193/3600)\n",
      "Test Epoch: 7 | Loss: 0.340 | Acc: 88.784% (3285/3700)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 88.789% (3374/3800)\n",
      "Test Epoch: 7 | Loss: 0.337 | Acc: 88.846% (3465/3900)\n",
      "Test Epoch: 7 | Loss: 0.338 | Acc: 88.900% (3556/4000)\n",
      "Test Epoch: 7 | Loss: 0.342 | Acc: 88.805% (3641/4100)\n",
      "Test Epoch: 7 | Loss: 0.345 | Acc: 88.762% (3728/4200)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 88.837% (3820/4300)\n",
      "Test Epoch: 7 | Loss: 0.340 | Acc: 88.977% (3915/4400)\n",
      "Test Epoch: 7 | Loss: 0.337 | Acc: 89.111% (4010/4500)\n",
      "Test Epoch: 7 | Loss: 0.336 | Acc: 89.130% (4100/4600)\n",
      "Test Epoch: 7 | Loss: 0.338 | Acc: 89.064% (4186/4700)\n",
      "Test Epoch: 7 | Loss: 0.342 | Acc: 88.979% (4271/4800)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.041% (4363/4900)\n",
      "Test Epoch: 7 | Loss: 0.342 | Acc: 89.040% (4452/5000)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.098% (4544/5100)\n",
      "Test Epoch: 7 | Loss: 0.345 | Acc: 89.058% (4631/5200)\n",
      "Test Epoch: 7 | Loss: 0.346 | Acc: 89.000% (4717/5300)\n",
      "Test Epoch: 7 | Loss: 0.343 | Acc: 89.093% (4811/5400)\n",
      "Test Epoch: 7 | Loss: 0.344 | Acc: 89.073% (4899/5500)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.196% (4995/5600)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.158% (5082/5700)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.224% (5175/5800)\n",
      "Test Epoch: 7 | Loss: 0.342 | Acc: 89.153% (5260/5900)\n",
      "Test Epoch: 7 | Loss: 0.341 | Acc: 89.167% (5350/6000)\n",
      "Test Epoch: 7 | Loss: 0.338 | Acc: 89.230% (5443/6100)\n",
      "Test Epoch: 7 | Loss: 0.336 | Acc: 89.306% (5537/6200)\n",
      "Test Epoch: 7 | Loss: 0.335 | Acc: 89.333% (5628/6300)\n",
      "Test Epoch: 7 | Loss: 0.332 | Acc: 89.422% (5723/6400)\n",
      "Test Epoch: 7 | Loss: 0.334 | Acc: 89.431% (5813/6500)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.530% (5909/6600)\n",
      "Test Epoch: 7 | Loss: 0.329 | Acc: 89.552% (6000/6700)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.544% (6089/6800)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.536% (6178/6900)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.514% (6266/7000)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.535% (6357/7100)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.556% (6448/7200)\n",
      "Test Epoch: 7 | Loss: 0.329 | Acc: 89.616% (6542/7300)\n",
      "Test Epoch: 7 | Loss: 0.326 | Acc: 89.676% (6636/7400)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.720% (6729/7500)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.737% (6820/7600)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.740% (6910/7700)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.756% (7001/7800)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.734% (7089/7900)\n",
      "Test Epoch: 7 | Loss: 0.325 | Acc: 89.750% (7180/8000)\n",
      "Test Epoch: 7 | Loss: 0.324 | Acc: 89.778% (7272/8100)\n",
      "Test Epoch: 7 | Loss: 0.327 | Acc: 89.720% (7357/8200)\n",
      "Test Epoch: 7 | Loss: 0.326 | Acc: 89.723% (7447/8300)\n",
      "Test Epoch: 7 | Loss: 0.327 | Acc: 89.738% (7538/8400)\n",
      "Test Epoch: 7 | Loss: 0.327 | Acc: 89.741% (7628/8500)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.640% (7709/8600)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.667% (7801/8700)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.636% (7888/8800)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.663% (7980/8900)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.667% (8070/9000)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.692% (8162/9100)\n",
      "Test Epoch: 7 | Loss: 0.329 | Acc: 89.728% (8255/9200)\n",
      "Test Epoch: 7 | Loss: 0.332 | Acc: 89.677% (8340/9300)\n",
      "Test Epoch: 7 | Loss: 0.331 | Acc: 89.723% (8434/9400)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.726% (8524/9500)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.740% (8615/9600)\n",
      "Test Epoch: 7 | Loss: 0.329 | Acc: 89.784% (8709/9700)\n",
      "Test Epoch: 7 | Loss: 0.329 | Acc: 89.796% (8800/9800)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.788% (8889/9900)\n",
      "Test Epoch: 7 | Loss: 0.330 | Acc: 89.790% (8979/10000)\n",
      "\n",
      "Epoch: 8\n",
      "Train Epoch: 8 | Loss: 0.191 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 8 | Loss: 0.204 | Acc: 92.578% (237/256)\n",
      "Train Epoch: 8 | Loss: 0.179 | Acc: 93.229% (358/384)\n",
      "Train Epoch: 8 | Loss: 0.171 | Acc: 93.555% (479/512)\n",
      "Train Epoch: 8 | Loss: 0.170 | Acc: 93.594% (599/640)\n",
      "Train Epoch: 8 | Loss: 0.181 | Acc: 93.490% (718/768)\n",
      "Train Epoch: 8 | Loss: 0.169 | Acc: 93.973% (842/896)\n",
      "Train Epoch: 8 | Loss: 0.164 | Acc: 94.238% (965/1024)\n",
      "Train Epoch: 8 | Loss: 0.168 | Acc: 94.184% (1085/1152)\n",
      "Train Epoch: 8 | Loss: 0.163 | Acc: 94.453% (1209/1280)\n",
      "Train Epoch: 8 | Loss: 0.161 | Acc: 94.460% (1330/1408)\n",
      "Train Epoch: 8 | Loss: 0.158 | Acc: 94.596% (1453/1536)\n",
      "Train Epoch: 8 | Loss: 0.156 | Acc: 94.712% (1576/1664)\n",
      "Train Epoch: 8 | Loss: 0.153 | Acc: 94.866% (1700/1792)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.896% (1822/1920)\n",
      "Train Epoch: 8 | Loss: 0.153 | Acc: 94.629% (1938/2048)\n",
      "Train Epoch: 8 | Loss: 0.151 | Acc: 94.761% (2062/2176)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.792% (2184/2304)\n",
      "Train Epoch: 8 | Loss: 0.155 | Acc: 94.696% (2303/2432)\n",
      "Train Epoch: 8 | Loss: 0.156 | Acc: 94.648% (2423/2560)\n",
      "Train Epoch: 8 | Loss: 0.157 | Acc: 94.531% (2541/2688)\n",
      "Train Epoch: 8 | Loss: 0.158 | Acc: 94.425% (2659/2816)\n",
      "Train Epoch: 8 | Loss: 0.156 | Acc: 94.463% (2781/2944)\n",
      "Train Epoch: 8 | Loss: 0.153 | Acc: 94.629% (2907/3072)\n",
      "Train Epoch: 8 | Loss: 0.152 | Acc: 94.625% (3028/3200)\n",
      "Train Epoch: 8 | Loss: 0.151 | Acc: 94.561% (3147/3328)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.618% (3270/3456)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.615% (3391/3584)\n",
      "Train Epoch: 8 | Loss: 0.154 | Acc: 94.450% (3506/3712)\n",
      "Train Epoch: 8 | Loss: 0.153 | Acc: 94.505% (3629/3840)\n",
      "Train Epoch: 8 | Loss: 0.155 | Acc: 94.506% (3750/3968)\n",
      "Train Epoch: 8 | Loss: 0.154 | Acc: 94.604% (3875/4096)\n",
      "Train Epoch: 8 | Loss: 0.153 | Acc: 94.626% (3997/4224)\n",
      "Train Epoch: 8 | Loss: 0.151 | Acc: 94.738% (4123/4352)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.799% (4247/4480)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.813% (4369/4608)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.827% (4491/4736)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.840% (4613/4864)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.852% (4735/4992)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.863% (4857/5120)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.722% (4971/5248)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.754% (5094/5376)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.804% (5218/5504)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.798% (5339/5632)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.792% (5460/5760)\n",
      "Train Epoch: 8 | Loss: 0.152 | Acc: 94.701% (5576/5888)\n",
      "Train Epoch: 8 | Loss: 0.152 | Acc: 94.714% (5698/6016)\n",
      "Train Epoch: 8 | Loss: 0.152 | Acc: 94.694% (5818/6144)\n",
      "Train Epoch: 8 | Loss: 0.151 | Acc: 94.770% (5944/6272)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.828% (6069/6400)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.822% (6190/6528)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.847% (6313/6656)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.826% (6433/6784)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.835% (6555/6912)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.815% (6675/7040)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.824% (6797/7168)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.860% (6921/7296)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.895% (7045/7424)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.928% (7169/7552)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.896% (7288/7680)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.903% (7410/7808)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.960% (7536/7936)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.953% (7657/8064)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.971% (7780/8192)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.988% (7903/8320)\n",
      "Train Epoch: 8 | Loss: 0.144 | Acc: 95.017% (8027/8448)\n",
      "Train Epoch: 8 | Loss: 0.144 | Acc: 95.009% (8148/8576)\n",
      "Train Epoch: 8 | Loss: 0.144 | Acc: 95.002% (8269/8704)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.950% (8386/8832)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.955% (8508/8960)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.949% (8629/9088)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.900% (8746/9216)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.884% (8866/9344)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.901% (8989/9472)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.875% (9108/9600)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.840% (9226/9728)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.856% (9349/9856)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.842% (9469/9984)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.828% (9589/10112)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.824% (9710/10240)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.859% (9835/10368)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.827% (9953/10496)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.814% (10073/10624)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.792% (10192/10752)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.816% (10316/10880)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.804% (10436/11008)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.801% (10557/11136)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.833% (10682/11264)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.821% (10802/11392)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.818% (10923/11520)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.857% (11049/11648)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.845% (11169/11776)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.850% (11291/11904)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.839% (11411/12032)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.827% (11531/12160)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.816% (11651/12288)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.805% (11771/12416)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.826% (11895/12544)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.839% (12018/12672)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.844% (12140/12800)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.848% (12262/12928)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.853% (12384/13056)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.873% (12508/13184)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.839% (12625/13312)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.829% (12745/13440)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.833% (12867/13568)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.867% (12993/13696)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.864% (13114/13824)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.875% (13237/13952)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.872% (13358/14080)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.869% (13479/14208)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.873% (13601/14336)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.863% (13721/14464)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.874% (13844/14592)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.878% (13966/14720)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.875% (14087/14848)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.905% (14213/14976)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.902% (14334/15104)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.886% (14453/15232)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.896% (14576/15360)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.919% (14701/15488)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.909% (14821/15616)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.900% (14941/15744)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.865% (15057/15872)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.856% (15177/16000)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.847% (15297/16128)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.839% (15417/16256)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.830% (15537/16384)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.864% (15664/16512)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.862% (15785/16640)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.829% (15901/16768)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.851% (16026/16896)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.860% (16149/17024)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.864% (16271/17152)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.826% (16386/17280)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.830% (16508/17408)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.811% (16626/17536)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.780% (16742/17664)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.779% (16863/17792)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.782% (16985/17920)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.781% (17106/18048)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.790% (17229/18176)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.799% (17352/18304)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.813% (17476/18432)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.806% (17596/18560)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.804% (17717/18688)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.797% (17837/18816)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.785% (17956/18944)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.783% (18077/19072)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.781% (18198/19200)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.785% (18320/19328)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.757% (18436/19456)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.781% (18562/19584)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.800% (18687/19712)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.819% (18812/19840)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.822% (18934/19968)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.835% (19058/20096)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.848% (19182/20224)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.836% (19301/20352)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.854% (19426/20480)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.866% (19550/20608)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.864% (19671/20736)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.872% (19794/20864)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.884% (19918/20992)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.882% (20039/21120)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.875% (20159/21248)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.859% (20277/21376)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.834% (20393/21504)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.841% (20516/21632)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.821% (20633/21760)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.805% (20751/21888)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.786% (20868/22016)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.798% (20992/22144)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.792% (21112/22272)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.781% (21231/22400)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.789% (21354/22528)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.792% (21476/22656)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.808% (21601/22784)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.811% (21723/22912)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.822% (21847/23040)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.803% (21964/23168)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.802% (22085/23296)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.809% (22208/23424)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.820% (22332/23552)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.806% (22450/23680)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.817% (22574/23808)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.820% (22696/23936)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.818% (22817/24064)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.829% (22941/24192)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.823% (23061/24320)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.813% (23180/24448)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.820% (23303/24576)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.815% (23423/24704)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.821% (23546/24832)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.820% (23667/24960)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.838% (23793/25088)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.829% (23912/25216)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.827% (24033/25344)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.830% (24155/25472)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.828% (24276/25600)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.842% (24401/25728)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.848% (24524/25856)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.828% (24640/25984)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.826% (24761/26112)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.825% (24882/26240)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.835% (25006/26368)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.852% (25132/26496)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.839% (25250/26624)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.849% (25374/26752)\n",
      "Train Epoch: 8 | Loss: 0.150 | Acc: 94.844% (25494/26880)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.857% (25619/27008)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.874% (25745/27136)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.891% (25871/27264)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.893% (25993/27392)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.873% (26109/27520)\n",
      "Train Epoch: 8 | Loss: 0.149 | Acc: 94.886% (26234/27648)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.898% (26359/27776)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.904% (26482/27904)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.913% (26606/28032)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.915% (26728/28160)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.910% (26848/28288)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.897% (26966/28416)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.889% (27085/28544)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.890% (27207/28672)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.899% (27331/28800)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.901% (27453/28928)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.882% (27569/29056)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.860% (27684/29184)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.872% (27809/29312)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.874% (27931/29440)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.880% (28054/29568)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.885% (28177/29696)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.893% (28301/29824)\n",
      "Train Epoch: 8 | Loss: 0.148 | Acc: 94.899% (28424/29952)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.910% (28549/30080)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.915% (28672/30208)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.917% (28794/30336)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.925% (28918/30464)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.927% (29040/30592)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.932% (29163/30720)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.936% (29286/30848)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.944% (29410/30976)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.936% (29529/31104)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.941% (29652/31232)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.955% (29778/31360)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.954% (29899/31488)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.958% (30022/31616)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.950% (30141/31744)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.955% (30264/31872)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.956% (30386/32000)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.964% (30510/32128)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.953% (30628/32256)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.942% (30746/32384)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.943% (30868/32512)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.951% (30992/32640)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.958% (31116/32768)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.960% (31238/32896)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.967% (31362/33024)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.969% (31484/33152)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.982% (31610/33280)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.986% (31733/33408)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.979% (31852/33536)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.971% (31971/33664)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.975% (32094/33792)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.985% (32219/33920)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.992% (32343/34048)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.996% (32466/34176)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.003% (32590/34304)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.999% (32710/34432)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.997% (32831/34560)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.995% (32952/34688)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.994% (33073/34816)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.003% (33198/34944)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.007% (33321/35072)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.017% (33446/35200)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.021% (33569/35328)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.019% (33690/35456)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.023% (33813/35584)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.027% (33936/35712)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.020% (34055/35840)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.023% (34178/35968)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.019% (34298/36096)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.017% (34419/36224)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.018% (34541/36352)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.025% (34665/36480)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.012% (34782/36608)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.010% (34903/36736)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.009% (35024/36864)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.010% (35146/36992)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.005% (35266/37120)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.001% (35386/37248)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.999% (35507/37376)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.995% (35627/37504)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.994% (35748/37632)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.997% (35871/37760)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.004% (35995/37888)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.997% (36114/38016)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.995% (36235/38144)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.996% (36357/38272)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.992% (36477/38400)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.993% (36599/38528)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.987% (36718/38656)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.990% (36841/38784)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.989% (36962/38912)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.990% (37084/39040)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.981% (37202/39168)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.989% (37327/39296)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.990% (37449/39424)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.989% (37570/39552)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.975% (37686/39680)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.973% (37807/39808)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.967% (37926/39936)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.976% (38051/40064)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.982% (38175/40192)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.978% (38295/40320)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.976% (38416/40448)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.985% (38541/40576)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.988% (38664/40704)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.984% (38784/40832)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.983% (38905/40960)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.977% (39024/41088)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.975% (39145/41216)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.986% (39271/41344)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.992% (39395/41472)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.002% (39521/41600)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.003% (39643/41728)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.997% (39762/41856)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.005% (39887/41984)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.011% (40011/42112)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.009% (40132/42240)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.006% (40252/42368)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.004% (40373/42496)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 95.000% (40493/42624)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.992% (40611/42752)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.993% (40733/42880)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.992% (40854/43008)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.995% (40977/43136)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.984% (41094/43264)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.983% (41215/43392)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.989% (41339/43520)\n",
      "Train Epoch: 8 | Loss: 0.145 | Acc: 94.987% (41460/43648)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.965% (41572/43776)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.964% (41693/43904)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.965% (41815/44032)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.971% (41939/44160)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.976% (42063/44288)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.970% (42182/44416)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.967% (42302/44544)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.970% (42425/44672)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.967% (42545/44800)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.961% (42664/44928)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.962% (42786/45056)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.956% (42905/45184)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.948% (43023/45312)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.943% (43142/45440)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.939% (43262/45568)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.945% (43386/45696)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.952% (43511/45824)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.958% (43635/45952)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.959% (43757/46080)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.955% (43877/46208)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.963% (44002/46336)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.960% (44122/46464)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.958% (44243/46592)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.949% (44360/46720)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.947% (44481/46848)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.936% (44597/46976)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.937% (44719/47104)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.929% (44837/47232)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.932% (44960/47360)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.927% (45079/47488)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.918% (45196/47616)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.921% (45319/47744)\n",
      "Train Epoch: 8 | Loss: 0.146 | Acc: 94.918% (45439/47872)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.910% (45557/48000)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.907% (45677/48128)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.913% (45801/48256)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.907% (45920/48384)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.896% (46036/48512)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.895% (46157/48640)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.892% (46277/48768)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.887% (46396/48896)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.878% (46513/49024)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.883% (46637/49152)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.880% (46757/49280)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.881% (46879/49408)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.885% (47002/49536)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.888% (47125/49664)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.891% (47248/49792)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.888% (47368/49920)\n",
      "Train Epoch: 8 | Loss: 0.147 | Acc: 94.884% (47442/50000)\n",
      "Test Epoch: 8 | Loss: 0.254 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 8 | Loss: 0.277 | Acc: 93.000% (186/200)\n",
      "Test Epoch: 8 | Loss: 0.282 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 8 | Loss: 0.271 | Acc: 92.500% (370/400)\n",
      "Test Epoch: 8 | Loss: 0.265 | Acc: 92.200% (461/500)\n",
      "Test Epoch: 8 | Loss: 0.240 | Acc: 93.167% (559/600)\n",
      "Test Epoch: 8 | Loss: 0.258 | Acc: 92.714% (649/700)\n",
      "Test Epoch: 8 | Loss: 0.270 | Acc: 91.625% (733/800)\n",
      "Test Epoch: 8 | Loss: 0.285 | Acc: 91.444% (823/900)\n",
      "Test Epoch: 8 | Loss: 0.290 | Acc: 91.400% (914/1000)\n",
      "Test Epoch: 8 | Loss: 0.299 | Acc: 91.000% (1001/1100)\n",
      "Test Epoch: 8 | Loss: 0.307 | Acc: 90.917% (1091/1200)\n",
      "Test Epoch: 8 | Loss: 0.308 | Acc: 90.615% (1178/1300)\n",
      "Test Epoch: 8 | Loss: 0.298 | Acc: 90.857% (1272/1400)\n",
      "Test Epoch: 8 | Loss: 0.295 | Acc: 91.000% (1365/1500)\n",
      "Test Epoch: 8 | Loss: 0.291 | Acc: 91.188% (1459/1600)\n",
      "Test Epoch: 8 | Loss: 0.295 | Acc: 91.118% (1549/1700)\n",
      "Test Epoch: 8 | Loss: 0.298 | Acc: 91.056% (1639/1800)\n",
      "Test Epoch: 8 | Loss: 0.307 | Acc: 90.789% (1725/1900)\n",
      "Test Epoch: 8 | Loss: 0.312 | Acc: 90.600% (1812/2000)\n",
      "Test Epoch: 8 | Loss: 0.316 | Acc: 90.429% (1899/2100)\n",
      "Test Epoch: 8 | Loss: 0.314 | Acc: 90.455% (1990/2200)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.348% (2078/2300)\n",
      "Test Epoch: 8 | Loss: 0.322 | Acc: 90.208% (2165/2400)\n",
      "Test Epoch: 8 | Loss: 0.325 | Acc: 90.280% (2257/2500)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.231% (2346/2600)\n",
      "Test Epoch: 8 | Loss: 0.327 | Acc: 90.370% (2440/2700)\n",
      "Test Epoch: 8 | Loss: 0.325 | Acc: 90.429% (2532/2800)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.379% (2621/2900)\n",
      "Test Epoch: 8 | Loss: 0.333 | Acc: 90.400% (2712/3000)\n",
      "Test Epoch: 8 | Loss: 0.335 | Acc: 90.226% (2797/3100)\n",
      "Test Epoch: 8 | Loss: 0.334 | Acc: 90.188% (2886/3200)\n",
      "Test Epoch: 8 | Loss: 0.333 | Acc: 90.212% (2977/3300)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.235% (3068/3400)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.286% (3160/3500)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.361% (3253/3600)\n",
      "Test Epoch: 8 | Loss: 0.334 | Acc: 90.270% (3340/3700)\n",
      "Test Epoch: 8 | Loss: 0.336 | Acc: 90.263% (3430/3800)\n",
      "Test Epoch: 8 | Loss: 0.333 | Acc: 90.385% (3525/3900)\n",
      "Test Epoch: 8 | Loss: 0.332 | Acc: 90.425% (3617/4000)\n",
      "Test Epoch: 8 | Loss: 0.332 | Acc: 90.439% (3708/4100)\n",
      "Test Epoch: 8 | Loss: 0.332 | Acc: 90.405% (3797/4200)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.488% (3891/4300)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.523% (3983/4400)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.622% (4078/4500)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.587% (4167/4600)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.574% (4257/4700)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.500% (4344/4800)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.429% (4431/4900)\n",
      "Test Epoch: 8 | Loss: 0.333 | Acc: 90.380% (4519/5000)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.412% (4611/5100)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.385% (4700/5200)\n",
      "Test Epoch: 8 | Loss: 0.333 | Acc: 90.321% (4787/5300)\n",
      "Test Epoch: 8 | Loss: 0.331 | Acc: 90.370% (4880/5400)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.382% (4971/5500)\n",
      "Test Epoch: 8 | Loss: 0.330 | Acc: 90.375% (5061/5600)\n",
      "Test Epoch: 8 | Loss: 0.329 | Acc: 90.333% (5149/5700)\n",
      "Test Epoch: 8 | Loss: 0.326 | Acc: 90.414% (5244/5800)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.339% (5330/5900)\n",
      "Test Epoch: 8 | Loss: 0.328 | Acc: 90.333% (5420/6000)\n",
      "Test Epoch: 8 | Loss: 0.325 | Acc: 90.393% (5514/6100)\n",
      "Test Epoch: 8 | Loss: 0.324 | Acc: 90.435% (5607/6200)\n",
      "Test Epoch: 8 | Loss: 0.323 | Acc: 90.492% (5701/6300)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.547% (5795/6400)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.554% (5886/6500)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.591% (5979/6600)\n",
      "Test Epoch: 8 | Loss: 0.318 | Acc: 90.642% (6073/6700)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.588% (6160/6800)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.609% (6252/6900)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.586% (6341/7000)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.549% (6429/7100)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.569% (6521/7200)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.589% (6613/7300)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.595% (6704/7400)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.653% (6799/7500)\n",
      "Test Epoch: 8 | Loss: 0.316 | Acc: 90.645% (6889/7600)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.623% (6978/7700)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.590% (7066/7800)\n",
      "Test Epoch: 8 | Loss: 0.318 | Acc: 90.595% (7157/7900)\n",
      "Test Epoch: 8 | Loss: 0.318 | Acc: 90.625% (7250/8000)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.667% (7344/8100)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.659% (7434/8200)\n",
      "Test Epoch: 8 | Loss: 0.316 | Acc: 90.663% (7525/8300)\n",
      "Test Epoch: 8 | Loss: 0.316 | Acc: 90.667% (7616/8400)\n",
      "Test Epoch: 8 | Loss: 0.317 | Acc: 90.624% (7703/8500)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.535% (7786/8600)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.540% (7877/8700)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.523% (7966/8800)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.562% (8060/8900)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.567% (8151/9000)\n",
      "Test Epoch: 8 | Loss: 0.320 | Acc: 90.582% (8243/9100)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.598% (8335/9200)\n",
      "Test Epoch: 8 | Loss: 0.322 | Acc: 90.538% (8420/9300)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.574% (8514/9400)\n",
      "Test Epoch: 8 | Loss: 0.322 | Acc: 90.568% (8604/9500)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.562% (8694/9600)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.608% (8789/9700)\n",
      "Test Epoch: 8 | Loss: 0.319 | Acc: 90.602% (8879/9800)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.556% (8965/9900)\n",
      "Test Epoch: 8 | Loss: 0.321 | Acc: 90.560% (9056/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Train Epoch: 9 | Loss: 0.107 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.531% (242/256)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.508% (489/512)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.156% (609/640)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.052% (730/768)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 94.643% (848/896)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 94.824% (971/1024)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.792% (1092/1152)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.688% (1212/1280)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.602% (1332/1408)\n",
      "Train Epoch: 9 | Loss: 0.156 | Acc: 94.466% (1451/1536)\n",
      "Train Epoch: 9 | Loss: 0.155 | Acc: 94.712% (1576/1664)\n",
      "Train Epoch: 9 | Loss: 0.153 | Acc: 94.699% (1697/1792)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.844% (1821/1920)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.068% (1947/2048)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.945% (2066/2176)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.922% (2187/2304)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.860% (2307/2432)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.883% (2429/2560)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.792% (2548/2688)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.957% (2674/2816)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 94.939% (2795/2944)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.727% (2910/3072)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.781% (3033/3200)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.862% (3157/3328)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.792% (3276/3456)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.810% (3398/3584)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 94.881% (3522/3712)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.000% (3648/3840)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 94.985% (3769/3968)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 94.995% (3891/4096)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.052% (4015/4224)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.037% (4136/4352)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.067% (4259/4480)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.074% (4381/4608)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.059% (4502/4736)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.127% (4627/4864)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.152% (4750/4992)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.059% (4867/5120)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.141% (4993/5248)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.108% (5113/5376)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.058% (5232/5504)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.046% (5353/5632)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.035% (5474/5760)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 94.990% (5593/5888)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.013% (5716/6016)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 94.971% (5835/6144)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.026% (5960/6272)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.031% (6082/6400)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.067% (6206/6528)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.072% (6328/6656)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.077% (6450/6784)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.095% (6573/6912)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.142% (6698/7040)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.173% (6822/7168)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.189% (6945/7296)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.178% (7066/7424)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.180% (7188/7552)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.195% (7311/7680)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.197% (7433/7808)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.186% (7554/7936)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.213% (7678/8064)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.239% (7802/8192)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.252% (7925/8320)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.241% (8046/8448)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.184% (8163/8576)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.152% (8282/8704)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.143% (8403/8832)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.190% (8529/8960)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.224% (8654/9088)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.269% (8780/9216)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.259% (8901/9344)\n",
      "Train Epoch: 9 | Loss: 0.134 | Acc: 95.302% (9027/9472)\n",
      "Train Epoch: 9 | Loss: 0.134 | Acc: 95.302% (9149/9600)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.292% (9270/9728)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.272% (9390/9856)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.252% (9510/9984)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.273% (9634/10112)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.283% (9757/10240)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.303% (9881/10368)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.312% (10004/10496)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.350% (10130/10624)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.350% (10252/10752)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.331% (10372/10880)\n",
      "Train Epoch: 9 | Loss: 0.135 | Acc: 95.340% (10495/11008)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.268% (10609/11136)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.259% (10730/11264)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.269% (10853/11392)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.295% (10978/11520)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.304% (11101/11648)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.287% (11221/11776)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.228% (11336/11904)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.213% (11456/12032)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.238% (11581/12160)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.231% (11702/12288)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.224% (11823/12416)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.225% (11945/12544)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.226% (12067/12672)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.227% (12189/12800)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.251% (12314/12928)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.244% (12435/13056)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.244% (12557/13184)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.260% (12681/13312)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.260% (12803/13440)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.290% (12929/13568)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.305% (13053/13696)\n",
      "Train Epoch: 9 | Loss: 0.136 | Acc: 95.320% (13177/13824)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.320% (13299/13952)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.305% (13419/14080)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.327% (13544/14208)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.333% (13667/14336)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.333% (13789/14464)\n",
      "Train Epoch: 9 | Loss: 0.137 | Acc: 95.312% (13908/14592)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.265% (14023/14720)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.272% (14146/14848)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.279% (14269/14976)\n",
      "Train Epoch: 9 | Loss: 0.138 | Acc: 95.260% (14388/15104)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.214% (14503/15232)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.221% (14626/15360)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.222% (14748/15488)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.210% (14868/15616)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.211% (14990/15744)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.205% (15111/15872)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.213% (15234/16000)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.213% (15356/16128)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.208% (15477/16256)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.215% (15600/16384)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.216% (15722/16512)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.210% (15843/16640)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.229% (15968/16768)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.236% (16091/16896)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.236% (16213/17024)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.248% (16337/17152)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.255% (16460/17280)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.267% (16584/17408)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.255% (16704/17536)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.239% (16823/17664)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.228% (16943/17792)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.229% (17065/17920)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.213% (17184/18048)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.208% (17305/18176)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.203% (17426/18304)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.199% (17547/18432)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.199% (17669/18560)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.205% (17792/18688)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.217% (17916/18816)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.207% (18036/18944)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.192% (18155/19072)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.208% (18280/19200)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.225% (18405/19328)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.235% (18529/19456)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.236% (18651/19584)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.241% (18774/19712)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.242% (18896/19840)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.252% (19020/19968)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.243% (19140/20096)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.233% (19260/20224)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.239% (19383/20352)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.225% (19502/20480)\n",
      "Train Epoch: 9 | Loss: 0.139 | Acc: 95.225% (19624/20608)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.202% (19741/20736)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.197% (19862/20864)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.170% (19978/20992)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.133% (20092/21120)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.129% (20213/21248)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.144% (20338/21376)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.140% (20459/21504)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.160% (20585/21632)\n",
      "Train Epoch: 9 | Loss: 0.140 | Acc: 95.161% (20707/21760)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.143% (20825/21888)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.135% (20945/22016)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.132% (21066/22144)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.137% (21189/22272)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.134% (21310/22400)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.153% (21436/22528)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.154% (21558/22656)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.133% (21675/22784)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.125% (21795/22912)\n",
      "Train Epoch: 9 | Loss: 0.141 | Acc: 95.130% (21918/23040)\n",
      "Train Epoch: 9 | Loss: 0.142 | Acc: 95.123% (22038/23168)\n",
      "Train Epoch: 9 | Loss: 0.142 | Acc: 95.115% (22158/23296)\n",
      "Train Epoch: 9 | Loss: 0.142 | Acc: 95.112% (22279/23424)\n",
      "Train Epoch: 9 | Loss: 0.142 | Acc: 95.100% (22398/23552)\n",
      "Train Epoch: 9 | Loss: 0.142 | Acc: 95.097% (22519/23680)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.086% (22638/23808)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.095% (22762/23936)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.092% (22883/24064)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.081% (23002/24192)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.070% (23121/24320)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.055% (23239/24448)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.064% (23363/24576)\n",
      "Train Epoch: 9 | Loss: 0.143 | Acc: 95.049% (23481/24704)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.039% (23600/24832)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.024% (23718/24960)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.029% (23841/25088)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.027% (23962/25216)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.017% (24081/25344)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.010% (24201/25472)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 95.000% (24320/25600)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 95.009% (24444/25728)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.988% (24560/25856)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.982% (24680/25984)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.995% (24805/26112)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.989% (24925/26240)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 94.994% (25048/26368)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 94.984% (25167/26496)\n",
      "Train Epoch: 9 | Loss: 0.144 | Acc: 94.986% (25289/26624)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.972% (25407/26752)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.967% (25527/26880)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.968% (25649/27008)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.962% (25769/27136)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.960% (25890/27264)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.940% (26006/27392)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.931% (26125/27520)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.929% (26246/27648)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.931% (26368/27776)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.933% (26490/27904)\n",
      "Train Epoch: 9 | Loss: 0.145 | Acc: 94.938% (26613/28032)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.915% (26728/28160)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.913% (26849/28288)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.908% (26969/28416)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.892% (27086/28544)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.894% (27208/28672)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.882% (27326/28800)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.891% (27450/28928)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.893% (27572/29056)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.888% (27692/29184)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.889% (27814/29312)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.891% (27936/29440)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.900% (28060/29568)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.892% (28179/29696)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.907% (28305/29824)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.902% (28425/29952)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.897% (28545/30080)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.892% (28665/30208)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.877% (28782/30336)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.886% (28906/30464)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.888% (29028/30592)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.870% (29144/30720)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.872% (29266/30848)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.880% (29390/30976)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.859% (29505/31104)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.855% (29625/31232)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.850% (29745/31360)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.839% (29863/31488)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.835% (29983/31616)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.840% (30106/31744)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.842% (30228/31872)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.847% (30351/32000)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.855% (30475/32128)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.860% (30598/32256)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.865% (30721/32384)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.879% (30847/32512)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.887% (30971/32640)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.894% (31095/32768)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.902% (31219/32896)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.904% (31341/33024)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.905% (31463/33152)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.907% (31585/33280)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.917% (31710/33408)\n",
      "Train Epoch: 9 | Loss: 0.146 | Acc: 94.913% (31830/33536)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.903% (31948/33664)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.901% (32069/33792)\n",
      "Train Epoch: 9 | Loss: 0.147 | Acc: 94.897% (32189/33920)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.872% (32302/34048)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.874% (32424/34176)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.861% (32541/34304)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.868% (32665/34432)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.870% (32787/34560)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.874% (32910/34688)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.867% (33029/34816)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.855% (33146/34944)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.853% (33267/35072)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.852% (33388/35200)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.857% (33511/35328)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.856% (33632/35456)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.860% (33755/35584)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.873% (33881/35712)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.874% (34003/35840)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.873% (34124/35968)\n",
      "Train Epoch: 9 | Loss: 0.148 | Acc: 94.858% (34240/36096)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.851% (34359/36224)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.837% (34475/36352)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.836% (34596/36480)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.837% (34718/36608)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.850% (34844/36736)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.832% (34959/36864)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.839% (35083/36992)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.841% (35205/37120)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.843% (35327/37248)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.847% (35450/37376)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.859% (35576/37504)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.861% (35698/37632)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.857% (35818/37760)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.851% (35937/37888)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.834% (36052/38016)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.838% (36175/38144)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.845% (36299/38272)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.839% (36418/38400)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.850% (36544/38528)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.857% (36668/38656)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.848% (36786/38784)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.852% (36909/38912)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.859% (37033/39040)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.861% (37155/39168)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.854% (37274/39296)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.861% (37398/39424)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.868% (37522/39552)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.869% (37644/39680)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.863% (37763/39808)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.867% (37886/39936)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.868% (38008/40064)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.870% (38130/40192)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.869% (38251/40320)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.860% (38369/40448)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.852% (38487/40576)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.860% (38612/40704)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.862% (38734/40832)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.861% (38855/40960)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.853% (38973/41088)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.856% (39096/41216)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.858% (39218/41344)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.859% (39340/41472)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.856% (39460/41600)\n",
      "Train Epoch: 9 | Loss: 0.149 | Acc: 94.850% (39579/41728)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.847% (39699/41856)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.834% (39815/41984)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.826% (39933/42112)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.820% (40052/42240)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.817% (40172/42368)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.816% (40293/42496)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.822% (40417/42624)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.812% (40534/42752)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.820% (40659/42880)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.817% (40779/43008)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.819% (40901/43136)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.813% (41020/43264)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.815% (41142/43392)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.807% (41260/43520)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.811% (41383/43648)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.805% (41502/43776)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.807% (41624/43904)\n",
      "Train Epoch: 9 | Loss: 0.150 | Acc: 94.811% (41747/44032)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.801% (41864/44160)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.804% (41987/44288)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.801% (42107/44416)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.803% (42229/44544)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.798% (42348/44672)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.806% (42473/44800)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.803% (42593/44928)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.804% (42715/45056)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.806% (42837/45184)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.800% (42956/45312)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.800% (43077/45440)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.803% (43200/45568)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.800% (43320/45696)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.795% (43439/45824)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.792% (43559/45952)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.783% (43676/46080)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.782% (43797/46208)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.782% (43918/46336)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.790% (44043/46464)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.789% (44164/46592)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.786% (44284/46720)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.790% (44407/46848)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.791% (44529/46976)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.792% (44651/47104)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.794% (44773/47232)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.783% (44889/47360)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.776% (45007/47488)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.773% (45127/47616)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.776% (45250/47744)\n",
      "Train Epoch: 9 | Loss: 0.151 | Acc: 94.782% (45374/47872)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.773% (45491/48000)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.772% (45612/48128)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.767% (45731/48256)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.769% (45853/48384)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.772% (45976/48512)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.776% (46099/48640)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.783% (46224/48768)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.773% (46340/48896)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.758% (46454/49024)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.749% (46571/49152)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.752% (46694/49280)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.754% (46816/49408)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.761% (46941/49536)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.763% (47063/49664)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.758% (47182/49792)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.760% (47304/49920)\n",
      "Train Epoch: 9 | Loss: 0.152 | Acc: 94.760% (47380/50000)\n",
      "Test Epoch: 9 | Loss: 0.308 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 9 | Loss: 0.346 | Acc: 90.500% (181/200)\n",
      "Test Epoch: 9 | Loss: 0.314 | Acc: 90.333% (271/300)\n",
      "Test Epoch: 9 | Loss: 0.298 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 9 | Loss: 0.309 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 9 | Loss: 0.288 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 9 | Loss: 0.297 | Acc: 91.143% (638/700)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.375% (723/800)\n",
      "Test Epoch: 9 | Loss: 0.338 | Acc: 90.444% (814/900)\n",
      "Test Epoch: 9 | Loss: 0.341 | Acc: 90.400% (904/1000)\n",
      "Test Epoch: 9 | Loss: 0.348 | Acc: 90.455% (995/1100)\n",
      "Test Epoch: 9 | Loss: 0.347 | Acc: 90.417% (1085/1200)\n",
      "Test Epoch: 9 | Loss: 0.335 | Acc: 90.462% (1176/1300)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.500% (1267/1400)\n",
      "Test Epoch: 9 | Loss: 0.322 | Acc: 90.600% (1359/1500)\n",
      "Test Epoch: 9 | Loss: 0.317 | Acc: 90.812% (1453/1600)\n",
      "Test Epoch: 9 | Loss: 0.317 | Acc: 90.941% (1546/1700)\n",
      "Test Epoch: 9 | Loss: 0.312 | Acc: 90.944% (1637/1800)\n",
      "Test Epoch: 9 | Loss: 0.320 | Acc: 90.737% (1724/1900)\n",
      "Test Epoch: 9 | Loss: 0.330 | Acc: 90.500% (1810/2000)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.381% (1898/2100)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.364% (1988/2200)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 90.043% (2071/2300)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 90.000% (2160/2400)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 90.000% (2250/2500)\n",
      "Test Epoch: 9 | Loss: 0.344 | Acc: 89.885% (2337/2600)\n",
      "Test Epoch: 9 | Loss: 0.339 | Acc: 90.074% (2432/2700)\n",
      "Test Epoch: 9 | Loss: 0.343 | Acc: 90.000% (2520/2800)\n",
      "Test Epoch: 9 | Loss: 0.344 | Acc: 90.000% (2610/2900)\n",
      "Test Epoch: 9 | Loss: 0.343 | Acc: 89.967% (2699/3000)\n",
      "Test Epoch: 9 | Loss: 0.345 | Acc: 89.871% (2786/3100)\n",
      "Test Epoch: 9 | Loss: 0.345 | Acc: 89.938% (2878/3200)\n",
      "Test Epoch: 9 | Loss: 0.342 | Acc: 90.030% (2971/3300)\n",
      "Test Epoch: 9 | Loss: 0.339 | Acc: 90.029% (3061/3400)\n",
      "Test Epoch: 9 | Loss: 0.338 | Acc: 89.971% (3149/3500)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.083% (3243/3600)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.054% (3332/3700)\n",
      "Test Epoch: 9 | Loss: 0.339 | Acc: 89.974% (3419/3800)\n",
      "Test Epoch: 9 | Loss: 0.334 | Acc: 90.103% (3514/3900)\n",
      "Test Epoch: 9 | Loss: 0.334 | Acc: 90.175% (3607/4000)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.146% (3696/4100)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.143% (3786/4200)\n",
      "Test Epoch: 9 | Loss: 0.334 | Acc: 90.186% (3878/4300)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.227% (3970/4400)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.289% (4063/4500)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.239% (4151/4600)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.234% (4241/4700)\n",
      "Test Epoch: 9 | Loss: 0.335 | Acc: 90.188% (4329/4800)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.265% (4423/4900)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.200% (4510/5000)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.235% (4602/5100)\n",
      "Test Epoch: 9 | Loss: 0.337 | Acc: 90.096% (4685/5200)\n",
      "Test Epoch: 9 | Loss: 0.337 | Acc: 90.075% (4774/5300)\n",
      "Test Epoch: 9 | Loss: 0.337 | Acc: 90.148% (4868/5400)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 90.109% (4956/5500)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 90.089% (5045/5600)\n",
      "Test Epoch: 9 | Loss: 0.338 | Acc: 90.088% (5135/5700)\n",
      "Test Epoch: 9 | Loss: 0.338 | Acc: 90.052% (5223/5800)\n",
      "Test Epoch: 9 | Loss: 0.340 | Acc: 89.983% (5309/5900)\n",
      "Test Epoch: 9 | Loss: 0.339 | Acc: 90.000% (5400/6000)\n",
      "Test Epoch: 9 | Loss: 0.337 | Acc: 90.049% (5493/6100)\n",
      "Test Epoch: 9 | Loss: 0.336 | Acc: 90.048% (5583/6200)\n",
      "Test Epoch: 9 | Loss: 0.335 | Acc: 90.079% (5675/6300)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.156% (5770/6400)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.123% (5858/6500)\n",
      "Test Epoch: 9 | Loss: 0.331 | Acc: 90.182% (5952/6600)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.254% (6047/6700)\n",
      "Test Epoch: 9 | Loss: 0.331 | Acc: 90.221% (6135/6800)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.203% (6224/6900)\n",
      "Test Epoch: 9 | Loss: 0.334 | Acc: 90.143% (6310/7000)\n",
      "Test Epoch: 9 | Loss: 0.333 | Acc: 90.141% (6400/7100)\n",
      "Test Epoch: 9 | Loss: 0.332 | Acc: 90.194% (6494/7200)\n",
      "Test Epoch: 9 | Loss: 0.331 | Acc: 90.247% (6588/7300)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.324% (6684/7400)\n",
      "Test Epoch: 9 | Loss: 0.327 | Acc: 90.333% (6775/7500)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.395% (6870/7600)\n",
      "Test Epoch: 9 | Loss: 0.327 | Acc: 90.390% (6960/7700)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.423% (7053/7800)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.405% (7142/7900)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.425% (7234/8000)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.469% (7328/8100)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.439% (7416/8200)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.458% (7508/8300)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.452% (7598/8400)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.412% (7685/8500)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.360% (7771/8600)\n",
      "Test Epoch: 9 | Loss: 0.327 | Acc: 90.368% (7862/8700)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.307% (7947/8800)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.326% (8039/8900)\n",
      "Test Epoch: 9 | Loss: 0.330 | Acc: 90.311% (8128/9000)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.286% (8216/9100)\n",
      "Test Epoch: 9 | Loss: 0.327 | Acc: 90.359% (8313/9200)\n",
      "Test Epoch: 9 | Loss: 0.329 | Acc: 90.333% (8401/9300)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.362% (8494/9400)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.379% (8586/9500)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.396% (8678/9600)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.443% (8773/9700)\n",
      "Test Epoch: 9 | Loss: 0.326 | Acc: 90.469% (8866/9800)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.424% (8952/9900)\n",
      "Test Epoch: 9 | Loss: 0.328 | Acc: 90.410% (9041/10000)\n",
      "\n",
      "Epoch: 10\n",
      "Train Epoch: 10 | Loss: 0.234 | Acc: 92.969% (119/128)\n",
      "Train Epoch: 10 | Loss: 0.171 | Acc: 94.922% (243/256)\n",
      "Train Epoch: 10 | Loss: 0.154 | Acc: 95.312% (366/384)\n",
      "Train Epoch: 10 | Loss: 0.153 | Acc: 94.922% (486/512)\n",
      "Train Epoch: 10 | Loss: 0.163 | Acc: 94.219% (603/640)\n",
      "Train Epoch: 10 | Loss: 0.167 | Acc: 94.271% (724/768)\n",
      "Train Epoch: 10 | Loss: 0.164 | Acc: 94.196% (844/896)\n",
      "Train Epoch: 10 | Loss: 0.160 | Acc: 94.043% (963/1024)\n",
      "Train Epoch: 10 | Loss: 0.159 | Acc: 94.010% (1083/1152)\n",
      "Train Epoch: 10 | Loss: 0.150 | Acc: 94.375% (1208/1280)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.531% (1331/1408)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.531% (1452/1536)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.471% (1572/1664)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.587% (1695/1792)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.479% (1814/1920)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.434% (1934/2048)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.439% (2055/2176)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.401% (2175/2304)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 94.613% (2301/2432)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 94.766% (2426/2560)\n",
      "Train Epoch: 10 | Loss: 0.139 | Acc: 94.754% (2547/2688)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 94.709% (2667/2816)\n",
      "Train Epoch: 10 | Loss: 0.138 | Acc: 94.803% (2791/2944)\n",
      "Train Epoch: 10 | Loss: 0.136 | Acc: 94.824% (2913/3072)\n",
      "Train Epoch: 10 | Loss: 0.135 | Acc: 94.875% (3036/3200)\n",
      "Train Epoch: 10 | Loss: 0.135 | Acc: 94.922% (3159/3328)\n",
      "Train Epoch: 10 | Loss: 0.134 | Acc: 94.936% (3281/3456)\n",
      "Train Epoch: 10 | Loss: 0.137 | Acc: 94.894% (3401/3584)\n",
      "Train Epoch: 10 | Loss: 0.138 | Acc: 94.908% (3523/3712)\n",
      "Train Epoch: 10 | Loss: 0.138 | Acc: 94.922% (3645/3840)\n",
      "Train Epoch: 10 | Loss: 0.138 | Acc: 94.960% (3768/3968)\n",
      "Train Epoch: 10 | Loss: 0.139 | Acc: 94.922% (3888/4096)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.815% (4005/4224)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 94.830% (4127/4352)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 94.888% (4251/4480)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.900% (4373/4608)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 94.932% (4496/4736)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.840% (4613/4864)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.872% (4736/4992)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.863% (4857/5120)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.874% (4979/5248)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.885% (5101/5376)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.858% (5221/5504)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.869% (5343/5632)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.913% (5467/5760)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.922% (5589/5888)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.963% (5713/6016)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.036% (5839/6144)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.041% (5961/6272)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.000% (6080/6400)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.037% (6204/6528)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.042% (6326/6656)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.091% (6451/6784)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.124% (6575/6912)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.156% (6699/7040)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.159% (6821/7168)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.038% (6934/7296)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.084% (7059/7424)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.101% (7182/7552)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.065% (7301/7680)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.056% (7422/7808)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.035% (7542/7936)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.052% (7665/8064)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.081% (7789/8192)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.108% (7913/8320)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.099% (8034/8448)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.091% (8155/8576)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.106% (8278/8704)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.131% (8402/8832)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.078% (8519/8960)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.070% (8640/9088)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.085% (8763/9216)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.088% (8885/9344)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.112% (9009/9472)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.062% (9126/9600)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.004% (9242/9728)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.049% (9368/9856)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.032% (9488/9984)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.065% (9613/10112)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.039% (9732/10240)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.994% (9849/10368)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.008% (9972/10496)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.002% (10093/10624)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 95.015% (10216/10752)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.028% (10339/10880)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 95.013% (10459/11008)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.998% (10579/11136)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.993% (10700/11264)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.935% (10815/11392)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.931% (10936/11520)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.926% (11057/11648)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.947% (11181/11776)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.960% (11304/11904)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.955% (11425/12032)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.975% (11549/12160)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.971% (11670/12288)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.974% (11792/12416)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.954% (11911/12544)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.942% (12031/12672)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.953% (12154/12800)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.980% (12279/12928)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.975% (12400/13056)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.964% (12520/13184)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.952% (12640/13312)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.955% (12762/13440)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.966% (12885/13568)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.999% (13011/13696)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.973% (13129/13824)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.990% (13253/13952)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.000% (13376/14080)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.996% (13497/14208)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.006% (13620/14336)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.008% (13742/14464)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.018% (13865/14592)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.014% (13986/14720)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.043% (14112/14848)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.072% (14238/14976)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.034% (14354/15104)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.030% (14475/15232)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.033% (14597/15360)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.041% (14720/15488)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.037% (14841/15616)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.008% (14958/15744)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.979% (15075/15872)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.013% (15202/16000)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.015% (15324/16128)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.023% (15447/16256)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.032% (15570/16384)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.010% (15688/16512)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.000% (15808/16640)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.020% (15933/16768)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.028% (16056/16896)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.048% (16181/17024)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.062% (16305/17152)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.069% (16428/17280)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.065% (16549/17408)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.056% (16669/17536)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.058% (16791/17664)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.048% (16911/17792)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.067% (17036/17920)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.063% (17157/18048)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.048% (17276/18176)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.067% (17401/18304)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.047% (17519/18432)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.038% (17639/18560)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.061% (17765/18688)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.052% (17885/18816)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.064% (18009/18944)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.071% (18132/19072)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.083% (18256/19200)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.080% (18377/19328)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.056% (18494/19456)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.057% (18616/19584)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.059% (18738/19712)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.076% (18863/19840)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.082% (18986/19968)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.084% (19108/20096)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.095% (19232/20224)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.086% (19352/20352)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.083% (19473/20480)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.094% (19597/20608)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.091% (19718/20736)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.087% (19839/20864)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.084% (19960/20992)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.095% (20084/21120)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.101% (20207/21248)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.093% (20327/21376)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.103% (20451/21504)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.081% (20568/21632)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.087% (20691/21760)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.084% (20812/21888)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.085% (20934/22016)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.105% (21060/22144)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.084% (21177/22272)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.076% (21297/22400)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.073% (21418/22528)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.083% (21542/22656)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.075% (21662/22784)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.072% (21783/22912)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.056% (21901/23040)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 95.071% (22026/23168)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 95.072% (22148/23296)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.056% (22266/23424)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.053% (22387/23552)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.059% (22510/23680)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 95.060% (22632/23808)\n",
      "Train Epoch: 10 | Loss: 0.140 | Acc: 95.066% (22755/23936)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.063% (22876/24064)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.048% (22994/24192)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.053% (23117/24320)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.043% (23236/24448)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.056% (23361/24576)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.062% (23484/24704)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.047% (23602/24832)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.048% (23724/24960)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.033% (23842/25088)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.019% (23960/25216)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.028% (24084/25344)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.026% (24205/25472)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.031% (24328/25600)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.029% (24449/25728)\n",
      "Train Epoch: 10 | Loss: 0.141 | Acc: 95.042% (24574/25856)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.016% (24689/25984)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.010% (24809/26112)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.004% (24929/26240)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 94.998% (25049/26368)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.007% (25173/26496)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.020% (25298/26624)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.010% (25417/26752)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.015% (25540/26880)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.013% (25661/27008)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.014% (25783/27136)\n",
      "Train Epoch: 10 | Loss: 0.142 | Acc: 95.001% (25901/27264)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.999% (26022/27392)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 95.000% (26144/27520)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.987% (26262/27648)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.992% (26385/27776)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.994% (26507/27904)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.984% (26626/28032)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.975% (26745/28160)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.980% (26868/28288)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.982% (26990/28416)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.980% (27111/28544)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.964% (27228/28672)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.969% (27351/28800)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.960% (27470/28928)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.951% (27589/29056)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.956% (27712/29184)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.947% (27831/29312)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.939% (27950/29440)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.940% (28072/29568)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.939% (28193/29696)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.937% (28314/29824)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.939% (28436/29952)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.950% (28561/30080)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.945% (28681/30208)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.953% (28805/30336)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.961% (28929/30464)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.963% (29051/30592)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.958% (29171/30720)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.969% (29296/30848)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.957% (29414/30976)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.936% (29529/31104)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.941% (29652/31232)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.933% (29771/31360)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.938% (29894/31488)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.952% (30020/31616)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.953% (30142/31744)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.949% (30262/31872)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.944% (30382/32000)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.948% (30505/32128)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.956% (30629/32256)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.951% (30749/32384)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.959% (30873/32512)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.966% (30997/32640)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.983% (31124/32768)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.969% (31241/32896)\n",
      "Train Epoch: 10 | Loss: 0.143 | Acc: 94.970% (31363/33024)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.948% (31477/33152)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.937% (31595/33280)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.932% (31715/33408)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.940% (31839/33536)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.944% (31962/33664)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.946% (32084/33792)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.950% (32207/33920)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.951% (32329/34048)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.950% (32450/34176)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.936% (32567/34304)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.944% (32691/34432)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.951% (32815/34560)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.952% (32937/34688)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.948% (33057/34816)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.946% (33178/34944)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.948% (33300/35072)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.935% (33417/35200)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.933% (33538/35328)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.949% (33665/35456)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.953% (33788/35584)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.954% (33910/35712)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.955% (34032/35840)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.957% (34154/35968)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.952% (34274/36096)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.948% (34394/36224)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.958% (34519/36352)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.959% (34641/36480)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.963% (34764/36608)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.964% (34886/36736)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.963% (35007/36864)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.964% (35129/36992)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.952% (35246/37120)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.937% (35362/37248)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.925% (35479/37376)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.923% (35600/37504)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.917% (35719/37632)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.921% (35842/37760)\n",
      "Train Epoch: 10 | Loss: 0.144 | Acc: 94.930% (35967/37888)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.923% (36086/38016)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.917% (36205/38144)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.902% (36321/38272)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.898% (36441/38400)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.905% (36565/38528)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.901% (36685/38656)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.895% (36804/38784)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.899% (36927/38912)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.903% (37050/39040)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.909% (37174/39168)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.903% (37293/39296)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.904% (37415/39424)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.913% (37540/39552)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.909% (37660/39680)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.911% (37782/39808)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.914% (37905/39936)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.901% (38021/40064)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.907% (38145/40192)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.906% (38266/40320)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.912% (38390/40448)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.906% (38509/40576)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.907% (38631/40704)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.901% (38750/40832)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.897% (38870/40960)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.896% (38991/41088)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.890% (39110/41216)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.894% (39233/41344)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.895% (39355/41472)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.885% (39472/41600)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.881% (39592/41728)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.880% (39713/41856)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.877% (39833/41984)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.876% (39954/42112)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.867% (40072/42240)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.862% (40191/42368)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.858% (40311/42496)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.864% (40435/42624)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.877% (40562/42752)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.879% (40684/42880)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.880% (40806/43008)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.884% (40929/43136)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.890% (41053/43264)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.884% (41172/43392)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.881% (41292/43520)\n",
      "Train Epoch: 10 | Loss: 0.147 | Acc: 94.873% (41410/43648)\n",
      "Train Epoch: 10 | Loss: 0.147 | Acc: 94.865% (41528/43776)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.871% (41652/43904)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.872% (41774/44032)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.873% (41896/44160)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.879% (42020/44288)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.878% (42141/44416)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.884% (42265/44544)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.896% (42392/44672)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.897% (42514/44800)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.894% (42634/44928)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.889% (42753/45056)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.890% (42875/45184)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.895% (42999/45312)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.892% (43119/45440)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.898% (43243/45568)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.903% (43367/45696)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.913% (43493/45824)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.916% (43616/45952)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.918% (43738/46080)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.916% (43859/46208)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.922% (43983/46336)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.923% (44105/46464)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.928% (44229/46592)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.927% (44350/46720)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.928% (44472/46848)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.931% (44595/46976)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.932% (44717/47104)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.936% (44840/47232)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.932% (44960/47360)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.931% (45081/47488)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.928% (45201/47616)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.925% (45321/47744)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.920% (45440/47872)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.919% (45561/48000)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.909% (45678/48128)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.902% (45796/48256)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.912% (45922/48384)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.911% (46043/48512)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.916% (46167/48640)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.909% (46285/48768)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.916% (46410/48896)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.921% (46534/49024)\n",
      "Train Epoch: 10 | Loss: 0.145 | Acc: 94.918% (46654/49152)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.907% (46770/49280)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.904% (46890/49408)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.909% (47014/49536)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.914% (47138/49664)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.913% (47259/49792)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.918% (47383/49920)\n",
      "Train Epoch: 10 | Loss: 0.146 | Acc: 94.922% (47461/50000)\n",
      "Test Epoch: 10 | Loss: 0.241 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 10 | Loss: 0.312 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 10 | Loss: 0.288 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 10 | Loss: 0.271 | Acc: 90.500% (362/400)\n",
      "Test Epoch: 10 | Loss: 0.279 | Acc: 90.400% (452/500)\n",
      "Test Epoch: 10 | Loss: 0.252 | Acc: 91.167% (547/600)\n",
      "Test Epoch: 10 | Loss: 0.250 | Acc: 91.429% (640/700)\n",
      "Test Epoch: 10 | Loss: 0.283 | Acc: 90.750% (726/800)\n",
      "Test Epoch: 10 | Loss: 0.297 | Acc: 90.778% (817/900)\n",
      "Test Epoch: 10 | Loss: 0.311 | Acc: 90.300% (903/1000)\n",
      "Test Epoch: 10 | Loss: 0.320 | Acc: 89.727% (987/1100)\n",
      "Test Epoch: 10 | Loss: 0.315 | Acc: 89.750% (1077/1200)\n",
      "Test Epoch: 10 | Loss: 0.303 | Acc: 90.077% (1171/1300)\n",
      "Test Epoch: 10 | Loss: 0.299 | Acc: 90.143% (1262/1400)\n",
      "Test Epoch: 10 | Loss: 0.295 | Acc: 90.067% (1351/1500)\n",
      "Test Epoch: 10 | Loss: 0.293 | Acc: 90.188% (1443/1600)\n",
      "Test Epoch: 10 | Loss: 0.298 | Acc: 90.294% (1535/1700)\n",
      "Test Epoch: 10 | Loss: 0.300 | Acc: 90.278% (1625/1800)\n",
      "Test Epoch: 10 | Loss: 0.305 | Acc: 90.000% (1710/1900)\n",
      "Test Epoch: 10 | Loss: 0.320 | Acc: 89.750% (1795/2000)\n",
      "Test Epoch: 10 | Loss: 0.319 | Acc: 89.571% (1881/2100)\n",
      "Test Epoch: 10 | Loss: 0.313 | Acc: 89.773% (1975/2200)\n",
      "Test Epoch: 10 | Loss: 0.318 | Acc: 89.739% (2064/2300)\n",
      "Test Epoch: 10 | Loss: 0.318 | Acc: 89.750% (2154/2400)\n",
      "Test Epoch: 10 | Loss: 0.328 | Acc: 89.720% (2243/2500)\n",
      "Test Epoch: 10 | Loss: 0.329 | Acc: 89.769% (2334/2600)\n",
      "Test Epoch: 10 | Loss: 0.323 | Acc: 89.963% (2429/2700)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.036% (2521/2800)\n",
      "Test Epoch: 10 | Loss: 0.333 | Acc: 90.000% (2610/2900)\n",
      "Test Epoch: 10 | Loss: 0.337 | Acc: 90.000% (2700/3000)\n",
      "Test Epoch: 10 | Loss: 0.343 | Acc: 89.871% (2786/3100)\n",
      "Test Epoch: 10 | Loss: 0.343 | Acc: 89.906% (2877/3200)\n",
      "Test Epoch: 10 | Loss: 0.344 | Acc: 89.788% (2963/3300)\n",
      "Test Epoch: 10 | Loss: 0.342 | Acc: 89.882% (3056/3400)\n",
      "Test Epoch: 10 | Loss: 0.343 | Acc: 89.829% (3144/3500)\n",
      "Test Epoch: 10 | Loss: 0.340 | Acc: 89.917% (3237/3600)\n",
      "Test Epoch: 10 | Loss: 0.341 | Acc: 89.811% (3323/3700)\n",
      "Test Epoch: 10 | Loss: 0.341 | Acc: 89.789% (3412/3800)\n",
      "Test Epoch: 10 | Loss: 0.336 | Acc: 89.897% (3506/3900)\n",
      "Test Epoch: 10 | Loss: 0.337 | Acc: 89.925% (3597/4000)\n",
      "Test Epoch: 10 | Loss: 0.338 | Acc: 89.854% (3684/4100)\n",
      "Test Epoch: 10 | Loss: 0.340 | Acc: 89.810% (3772/4200)\n",
      "Test Epoch: 10 | Loss: 0.337 | Acc: 89.953% (3868/4300)\n",
      "Test Epoch: 10 | Loss: 0.335 | Acc: 90.068% (3963/4400)\n",
      "Test Epoch: 10 | Loss: 0.336 | Acc: 90.044% (4052/4500)\n",
      "Test Epoch: 10 | Loss: 0.334 | Acc: 90.087% (4144/4600)\n",
      "Test Epoch: 10 | Loss: 0.337 | Acc: 90.064% (4233/4700)\n",
      "Test Epoch: 10 | Loss: 0.339 | Acc: 90.021% (4321/4800)\n",
      "Test Epoch: 10 | Loss: 0.337 | Acc: 90.102% (4415/4900)\n",
      "Test Epoch: 10 | Loss: 0.340 | Acc: 90.080% (4504/5000)\n",
      "Test Epoch: 10 | Loss: 0.338 | Acc: 90.176% (4599/5100)\n",
      "Test Epoch: 10 | Loss: 0.339 | Acc: 90.115% (4686/5200)\n",
      "Test Epoch: 10 | Loss: 0.339 | Acc: 90.113% (4776/5300)\n",
      "Test Epoch: 10 | Loss: 0.336 | Acc: 90.130% (4867/5400)\n",
      "Test Epoch: 10 | Loss: 0.336 | Acc: 90.127% (4957/5500)\n",
      "Test Epoch: 10 | Loss: 0.334 | Acc: 90.125% (5047/5600)\n",
      "Test Epoch: 10 | Loss: 0.333 | Acc: 90.140% (5138/5700)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.138% (5228/5800)\n",
      "Test Epoch: 10 | Loss: 0.333 | Acc: 90.051% (5313/5900)\n",
      "Test Epoch: 10 | Loss: 0.333 | Acc: 90.017% (5401/6000)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.066% (5494/6100)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.097% (5586/6200)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.143% (5679/6300)\n",
      "Test Epoch: 10 | Loss: 0.326 | Acc: 90.172% (5771/6400)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.138% (5859/6500)\n",
      "Test Epoch: 10 | Loss: 0.326 | Acc: 90.167% (5951/6600)\n",
      "Test Epoch: 10 | Loss: 0.322 | Acc: 90.284% (6049/6700)\n",
      "Test Epoch: 10 | Loss: 0.325 | Acc: 90.279% (6139/6800)\n",
      "Test Epoch: 10 | Loss: 0.325 | Acc: 90.261% (6228/6900)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.229% (6316/7000)\n",
      "Test Epoch: 10 | Loss: 0.326 | Acc: 90.268% (6409/7100)\n",
      "Test Epoch: 10 | Loss: 0.326 | Acc: 90.319% (6503/7200)\n",
      "Test Epoch: 10 | Loss: 0.324 | Acc: 90.397% (6599/7300)\n",
      "Test Epoch: 10 | Loss: 0.324 | Acc: 90.405% (6690/7400)\n",
      "Test Epoch: 10 | Loss: 0.323 | Acc: 90.453% (6784/7500)\n",
      "Test Epoch: 10 | Loss: 0.323 | Acc: 90.447% (6874/7600)\n",
      "Test Epoch: 10 | Loss: 0.324 | Acc: 90.429% (6963/7700)\n",
      "Test Epoch: 10 | Loss: 0.324 | Acc: 90.449% (7055/7800)\n",
      "Test Epoch: 10 | Loss: 0.325 | Acc: 90.418% (7143/7900)\n",
      "Test Epoch: 10 | Loss: 0.326 | Acc: 90.375% (7230/8000)\n",
      "Test Epoch: 10 | Loss: 0.325 | Acc: 90.432% (7325/8100)\n",
      "Test Epoch: 10 | Loss: 0.328 | Acc: 90.341% (7408/8200)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.361% (7500/8300)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.345% (7589/8400)\n",
      "Test Epoch: 10 | Loss: 0.327 | Acc: 90.341% (7679/8500)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.314% (7767/8600)\n",
      "Test Epoch: 10 | Loss: 0.329 | Acc: 90.333% (7859/8700)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.330% (7949/8800)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.337% (8040/8900)\n",
      "Test Epoch: 10 | Loss: 0.332 | Acc: 90.322% (8129/9000)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.352% (8222/9100)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.413% (8318/9200)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.387% (8406/9300)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.394% (8497/9400)\n",
      "Test Epoch: 10 | Loss: 0.330 | Acc: 90.411% (8589/9500)\n",
      "Test Epoch: 10 | Loss: 0.329 | Acc: 90.406% (8679/9600)\n",
      "Test Epoch: 10 | Loss: 0.328 | Acc: 90.433% (8772/9700)\n",
      "Test Epoch: 10 | Loss: 0.328 | Acc: 90.439% (8863/9800)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.394% (8949/9900)\n",
      "Test Epoch: 10 | Loss: 0.331 | Acc: 90.400% (9040/10000)\n",
      "\n",
      "Epoch: 11\n",
      "Train Epoch: 11 | Loss: 0.171 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 11 | Loss: 0.182 | Acc: 94.922% (243/256)\n",
      "Train Epoch: 11 | Loss: 0.162 | Acc: 95.052% (365/384)\n",
      "Train Epoch: 11 | Loss: 0.157 | Acc: 94.531% (484/512)\n",
      "Train Epoch: 11 | Loss: 0.156 | Acc: 95.000% (608/640)\n",
      "Train Epoch: 11 | Loss: 0.159 | Acc: 94.661% (727/768)\n",
      "Train Epoch: 11 | Loss: 0.160 | Acc: 94.866% (850/896)\n",
      "Train Epoch: 11 | Loss: 0.156 | Acc: 95.020% (973/1024)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 95.312% (1098/1152)\n",
      "Train Epoch: 11 | Loss: 0.150 | Acc: 95.234% (1219/1280)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.455% (1344/1408)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 95.378% (1465/1536)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.493% (1589/1664)\n",
      "Train Epoch: 11 | Loss: 0.152 | Acc: 95.201% (1706/1792)\n",
      "Train Epoch: 11 | Loss: 0.151 | Acc: 95.156% (1827/1920)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 95.215% (1950/2048)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 95.221% (2072/2176)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.399% (2198/2304)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.271% (2317/2432)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.234% (2438/2560)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.312% (2562/2688)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.348% (2685/2816)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.312% (2806/2944)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.247% (2926/3072)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.188% (3046/3200)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.282% (3171/3328)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.312% (3294/3456)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.257% (3414/3584)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.339% (3539/3712)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.365% (3662/3840)\n",
      "Train Epoch: 11 | Loss: 0.137 | Acc: 95.464% (3788/3968)\n",
      "Train Epoch: 11 | Loss: 0.136 | Acc: 95.483% (3911/4096)\n",
      "Train Epoch: 11 | Loss: 0.136 | Acc: 95.502% (4034/4224)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.404% (4152/4352)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.446% (4276/4480)\n",
      "Train Epoch: 11 | Loss: 0.137 | Acc: 95.508% (4401/4608)\n",
      "Train Epoch: 11 | Loss: 0.135 | Acc: 95.566% (4526/4736)\n",
      "Train Epoch: 11 | Loss: 0.135 | Acc: 95.539% (4647/4864)\n",
      "Train Epoch: 11 | Loss: 0.137 | Acc: 95.353% (4760/4992)\n",
      "Train Epoch: 11 | Loss: 0.136 | Acc: 95.410% (4885/5120)\n",
      "Train Epoch: 11 | Loss: 0.135 | Acc: 95.427% (5008/5248)\n",
      "Train Epoch: 11 | Loss: 0.135 | Acc: 95.424% (5130/5376)\n",
      "Train Epoch: 11 | Loss: 0.134 | Acc: 95.476% (5255/5504)\n",
      "Train Epoch: 11 | Loss: 0.135 | Acc: 95.419% (5374/5632)\n",
      "Train Epoch: 11 | Loss: 0.136 | Acc: 95.417% (5496/5760)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.414% (5618/5888)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.462% (5743/6016)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.410% (5862/6144)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.424% (5985/6272)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.422% (6107/6400)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.466% (6232/6528)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.448% (6353/6656)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.416% (6473/6784)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.443% (6597/6912)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.469% (6721/7040)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.438% (6841/7168)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.422% (6962/7296)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.380% (7081/7424)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.405% (7205/7552)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.365% (7324/7680)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.351% (7445/7808)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.363% (7568/7936)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.375% (7691/8064)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.337% (7810/8192)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.361% (7934/8320)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.348% (8055/8448)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.359% (8178/8576)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.358% (8300/8704)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.301% (8417/8832)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.279% (8537/8960)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.301% (8661/9088)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.312% (8784/9216)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.312% (8906/9344)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.334% (9030/9472)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.312% (9150/9600)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.302% (9271/9728)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.241% (9387/9856)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.252% (9510/9984)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.243% (9631/10112)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.215% (9750/10240)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.235% (9874/10368)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.255% (9998/10496)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.256% (10120/10624)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.266% (10243/10752)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.257% (10364/10880)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.276% (10488/11008)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.241% (10606/11136)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.215% (10725/11264)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.251% (10851/11392)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.286% (10977/11520)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.261% (11096/11648)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.262% (11218/11776)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.262% (11340/11904)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.254% (11461/12032)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.296% (11588/12160)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.329% (11714/12288)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.337% (11837/12416)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.336% (11959/12544)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.344% (12082/12672)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.344% (12204/12800)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.351% (12327/12928)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.366% (12451/13056)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.343% (12570/13184)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.365% (12695/13312)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.357% (12816/13440)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.349% (12937/13568)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.364% (13061/13696)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.327% (13178/13824)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.348% (13303/13952)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.327% (13422/14080)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.305% (13541/14208)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.306% (13663/14336)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.299% (13784/14464)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.292% (13905/14592)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.306% (14029/14720)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.279% (14147/14848)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.272% (14268/14976)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.286% (14392/15104)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.299% (14516/15232)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.306% (14639/15360)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.287% (14758/15488)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.300% (14882/15616)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.300% (15004/15744)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.312% (15128/15872)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.312% (15250/16000)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.319% (15373/16128)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.337% (15498/16256)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.343% (15621/16384)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.343% (15743/16512)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.361% (15868/16640)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.360% (15990/16768)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.360% (16112/16896)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.371% (16236/17024)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.353% (16355/17152)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.347% (16476/17280)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.347% (16598/17408)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.352% (16721/17536)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.346% (16842/17664)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.363% (16967/17792)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.379% (17092/17920)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.385% (17215/18048)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.395% (17339/18176)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.394% (17461/18304)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.399% (17584/18432)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.372% (17701/18560)\n",
      "Train Epoch: 11 | Loss: 0.138 | Acc: 95.398% (17828/18688)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.382% (17947/18816)\n",
      "Train Epoch: 11 | Loss: 0.139 | Acc: 95.365% (18066/18944)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.349% (18185/19072)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.349% (18307/19200)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.318% (18423/19328)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.338% (18549/19456)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.328% (18669/19584)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.338% (18793/19712)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.338% (18915/19840)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.333% (19036/19968)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.347% (19161/20096)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.352% (19284/20224)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.367% (19409/20352)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.371% (19532/20480)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.366% (19653/20608)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.351% (19772/20736)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.360% (19896/20864)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.346% (20015/20992)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.303% (20128/21120)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.312% (20252/21248)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.298% (20371/21376)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.299% (20493/21504)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.303% (20616/21632)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.312% (20740/21760)\n",
      "Train Epoch: 11 | Loss: 0.140 | Acc: 95.312% (20862/21888)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.276% (20976/22016)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.285% (21100/22144)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.286% (21222/22272)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.281% (21343/22400)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.286% (21466/22528)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.277% (21586/22656)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.291% (21711/22784)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.295% (21834/22912)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.291% (21955/23040)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.300% (22079/23168)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.295% (22200/23296)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.287% (22320/23424)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.274% (22439/23552)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.291% (22565/23680)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.283% (22685/23808)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.275% (22805/23936)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.275% (22927/24064)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.288% (23052/24192)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.280% (23172/24320)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.259% (23289/24448)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.251% (23409/24576)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.252% (23531/24704)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.244% (23651/24832)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.248% (23774/24960)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.233% (23892/25088)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.229% (24013/25216)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.218% (24132/25344)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.203% (24250/25472)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.199% (24371/25600)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.192% (24491/25728)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.193% (24613/25856)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.201% (24737/25984)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.201% (24859/26112)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.210% (24983/26240)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.206% (25104/26368)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.203% (25225/26496)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.211% (25349/26624)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.215% (25472/26752)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.208% (25592/26880)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.205% (25713/27008)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.220% (25839/27136)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.228% (25963/27264)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.229% (26085/27392)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.240% (26210/27520)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.237% (26331/27648)\n",
      "Train Epoch: 11 | Loss: 0.141 | Acc: 95.248% (26456/27776)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.248% (26578/27904)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.241% (26698/28032)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.234% (26818/28160)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.231% (26939/28288)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.228% (27060/28416)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.211% (27177/28544)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.197% (27295/28672)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.205% (27419/28800)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.198% (27539/28928)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.213% (27665/29056)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.210% (27786/29184)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.203% (27906/29312)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.200% (28027/29440)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.194% (28147/29568)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.188% (28267/29696)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.198% (28392/29824)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.192% (28512/29952)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.189% (28633/30080)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.183% (28753/30208)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.197% (28879/30336)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.198% (29001/30464)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.192% (29121/30592)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.189% (29242/30720)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.189% (29364/30848)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.196% (29488/30976)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.203% (29612/31104)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.207% (29735/31232)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.204% (29856/31360)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.205% (29978/31488)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.199% (30098/31616)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.209% (30223/31744)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.203% (30343/31872)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.203% (30465/32000)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.204% (30587/32128)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.192% (30705/32256)\n",
      "Train Epoch: 11 | Loss: 0.142 | Acc: 95.189% (30826/32384)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.189% (30948/32512)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.178% (31066/32640)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.178% (31188/32768)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.182% (31311/32896)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.179% (31432/33024)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.162% (31548/33152)\n",
      "Train Epoch: 11 | Loss: 0.143 | Acc: 95.168% (31672/33280)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.151% (31788/33408)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.140% (31906/33536)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.155% (32033/33664)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.141% (32150/33792)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.136% (32270/33920)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.136% (32392/34048)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.137% (32514/34176)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.126% (32632/34304)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.118% (32751/34432)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.124% (32875/34560)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.128% (32998/34688)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.120% (33117/34816)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.129% (33242/34944)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.139% (33367/35072)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.136% (33488/35200)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.140% (33611/35328)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.152% (33737/35456)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.147% (33857/35584)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.144% (33978/35712)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.142% (34099/35840)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.137% (34219/35968)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.132% (34339/36096)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.122% (34457/36224)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.123% (34579/36352)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.121% (34700/36480)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.110% (34818/36608)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.114% (34941/36736)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.123% (35066/36864)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.115% (35185/36992)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.110% (35305/37120)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.108% (35426/37248)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.101% (35545/37376)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.110% (35670/37504)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.113% (35793/37632)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.114% (35915/37760)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.107% (36034/37888)\n",
      "Train Epoch: 11 | Loss: 0.144 | Acc: 95.115% (36159/38016)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.105% (36277/38144)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.088% (36392/38272)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.086% (36513/38400)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.089% (36636/38528)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.087% (36757/38656)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.078% (36875/38784)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.079% (36997/38912)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.074% (37117/39040)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.078% (37240/39168)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.078% (37362/39296)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.077% (37483/39424)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.080% (37606/39552)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.088% (37731/39680)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.071% (37846/39808)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.065% (37965/39936)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.060% (38085/40064)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.061% (38207/40192)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.057% (38327/40320)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.053% (38447/40448)\n",
      "Train Epoch: 11 | Loss: 0.145 | Acc: 95.059% (38571/40576)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.047% (38688/40704)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.053% (38812/40832)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.054% (38934/40960)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.037% (39049/41088)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.043% (39173/41216)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.046% (39296/41344)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.042% (39416/41472)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.043% (39538/41600)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.044% (39660/41728)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.033% (39777/41856)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.031% (39898/41984)\n",
      "Train Epoch: 11 | Loss: 0.146 | Acc: 95.023% (40016/42112)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 95.017% (40135/42240)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 95.010% (40254/42368)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 95.004% (40373/42496)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 94.998% (40492/42624)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 94.994% (40612/42752)\n",
      "Train Epoch: 11 | Loss: 0.147 | Acc: 94.984% (40729/42880)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.978% (40848/43008)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.981% (40971/43136)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.977% (41091/43264)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.965% (41207/43392)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.966% (41329/43520)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.960% (41448/43648)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.956% (41568/43776)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.955% (41689/43904)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.960% (41813/44032)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.950% (41930/44160)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.951% (42052/44288)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.957% (42176/44416)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.951% (42295/44544)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.959% (42420/44672)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.964% (42544/44800)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.952% (42660/44928)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.946% (42779/45056)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.945% (42900/45184)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.937% (43018/45312)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.943% (43142/45440)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.948% (43266/45568)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.945% (43386/45696)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.946% (43508/45824)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.940% (43627/45952)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.931% (43744/46080)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.932% (43866/46208)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.935% (43989/46336)\n",
      "Train Epoch: 11 | Loss: 0.148 | Acc: 94.944% (44115/46464)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.939% (44234/46592)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.932% (44352/46720)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.928% (44472/46848)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.925% (44592/46976)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.926% (44714/47104)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.931% (44838/47232)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.930% (44959/47360)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.938% (45084/47488)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.943% (45208/47616)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.946% (45331/47744)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.949% (45454/47872)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.948% (45575/48000)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.949% (45697/48128)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.952% (45820/48256)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.953% (45942/48384)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.941% (46058/48512)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.938% (46178/48640)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.937% (46299/48768)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.934% (46419/48896)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.935% (46541/49024)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.936% (46663/49152)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.929% (46781/49280)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.928% (46902/49408)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.927% (47023/49536)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.934% (47148/49664)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.931% (47268/49792)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.938% (47393/49920)\n",
      "Train Epoch: 11 | Loss: 0.149 | Acc: 94.936% (47468/50000)\n",
      "Test Epoch: 11 | Loss: 0.208 | Acc: 91.000% (91/100)\n",
      "Test Epoch: 11 | Loss: 0.222 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 11 | Loss: 0.226 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 11 | Loss: 0.242 | Acc: 91.500% (366/400)\n",
      "Test Epoch: 11 | Loss: 0.246 | Acc: 91.200% (456/500)\n",
      "Test Epoch: 11 | Loss: 0.227 | Acc: 92.000% (552/600)\n",
      "Test Epoch: 11 | Loss: 0.229 | Acc: 92.143% (645/700)\n",
      "Test Epoch: 11 | Loss: 0.252 | Acc: 91.750% (734/800)\n",
      "Test Epoch: 11 | Loss: 0.257 | Acc: 91.778% (826/900)\n",
      "Test Epoch: 11 | Loss: 0.278 | Acc: 91.700% (917/1000)\n",
      "Test Epoch: 11 | Loss: 0.286 | Acc: 91.364% (1005/1100)\n",
      "Test Epoch: 11 | Loss: 0.291 | Acc: 91.083% (1093/1200)\n",
      "Test Epoch: 11 | Loss: 0.286 | Acc: 91.000% (1183/1300)\n",
      "Test Epoch: 11 | Loss: 0.286 | Acc: 91.071% (1275/1400)\n",
      "Test Epoch: 11 | Loss: 0.277 | Acc: 91.133% (1367/1500)\n",
      "Test Epoch: 11 | Loss: 0.281 | Acc: 90.875% (1454/1600)\n",
      "Test Epoch: 11 | Loss: 0.286 | Acc: 90.941% (1546/1700)\n",
      "Test Epoch: 11 | Loss: 0.284 | Acc: 90.944% (1637/1800)\n",
      "Test Epoch: 11 | Loss: 0.293 | Acc: 90.579% (1721/1900)\n",
      "Test Epoch: 11 | Loss: 0.302 | Acc: 90.450% (1809/2000)\n",
      "Test Epoch: 11 | Loss: 0.303 | Acc: 90.381% (1898/2100)\n",
      "Test Epoch: 11 | Loss: 0.300 | Acc: 90.455% (1990/2200)\n",
      "Test Epoch: 11 | Loss: 0.304 | Acc: 90.304% (2077/2300)\n",
      "Test Epoch: 11 | Loss: 0.306 | Acc: 90.333% (2168/2400)\n",
      "Test Epoch: 11 | Loss: 0.312 | Acc: 90.360% (2259/2500)\n",
      "Test Epoch: 11 | Loss: 0.313 | Acc: 90.423% (2351/2600)\n",
      "Test Epoch: 11 | Loss: 0.310 | Acc: 90.444% (2442/2700)\n",
      "Test Epoch: 11 | Loss: 0.312 | Acc: 90.393% (2531/2800)\n",
      "Test Epoch: 11 | Loss: 0.317 | Acc: 90.414% (2622/2900)\n",
      "Test Epoch: 11 | Loss: 0.320 | Acc: 90.367% (2711/3000)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.258% (2798/3100)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 90.188% (2886/3200)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.333% (2981/3300)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.235% (3068/3400)\n",
      "Test Epoch: 11 | Loss: 0.326 | Acc: 90.229% (3158/3500)\n",
      "Test Epoch: 11 | Loss: 0.330 | Acc: 90.250% (3249/3600)\n",
      "Test Epoch: 11 | Loss: 0.331 | Acc: 90.081% (3333/3700)\n",
      "Test Epoch: 11 | Loss: 0.334 | Acc: 89.868% (3415/3800)\n",
      "Test Epoch: 11 | Loss: 0.331 | Acc: 89.974% (3509/3900)\n",
      "Test Epoch: 11 | Loss: 0.332 | Acc: 90.025% (3601/4000)\n",
      "Test Epoch: 11 | Loss: 0.334 | Acc: 90.000% (3690/4100)\n",
      "Test Epoch: 11 | Loss: 0.336 | Acc: 89.881% (3775/4200)\n",
      "Test Epoch: 11 | Loss: 0.333 | Acc: 89.930% (3867/4300)\n",
      "Test Epoch: 11 | Loss: 0.333 | Acc: 90.023% (3961/4400)\n",
      "Test Epoch: 11 | Loss: 0.331 | Acc: 90.111% (4055/4500)\n",
      "Test Epoch: 11 | Loss: 0.329 | Acc: 90.130% (4146/4600)\n",
      "Test Epoch: 11 | Loss: 0.330 | Acc: 90.106% (4235/4700)\n",
      "Test Epoch: 11 | Loss: 0.333 | Acc: 90.000% (4320/4800)\n",
      "Test Epoch: 11 | Loss: 0.331 | Acc: 90.020% (4411/4900)\n",
      "Test Epoch: 11 | Loss: 0.336 | Acc: 89.940% (4497/5000)\n",
      "Test Epoch: 11 | Loss: 0.334 | Acc: 89.961% (4588/5100)\n",
      "Test Epoch: 11 | Loss: 0.337 | Acc: 89.885% (4674/5200)\n",
      "Test Epoch: 11 | Loss: 0.337 | Acc: 89.887% (4764/5300)\n",
      "Test Epoch: 11 | Loss: 0.336 | Acc: 89.907% (4855/5400)\n",
      "Test Epoch: 11 | Loss: 0.335 | Acc: 89.891% (4944/5500)\n",
      "Test Epoch: 11 | Loss: 0.334 | Acc: 89.911% (5035/5600)\n",
      "Test Epoch: 11 | Loss: 0.337 | Acc: 89.860% (5122/5700)\n",
      "Test Epoch: 11 | Loss: 0.335 | Acc: 89.914% (5215/5800)\n",
      "Test Epoch: 11 | Loss: 0.336 | Acc: 89.831% (5300/5900)\n",
      "Test Epoch: 11 | Loss: 0.335 | Acc: 89.817% (5389/6000)\n",
      "Test Epoch: 11 | Loss: 0.333 | Acc: 89.836% (5480/6100)\n",
      "Test Epoch: 11 | Loss: 0.332 | Acc: 89.871% (5572/6200)\n",
      "Test Epoch: 11 | Loss: 0.331 | Acc: 89.905% (5664/6300)\n",
      "Test Epoch: 11 | Loss: 0.329 | Acc: 89.969% (5758/6400)\n",
      "Test Epoch: 11 | Loss: 0.329 | Acc: 89.954% (5847/6500)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 89.985% (5939/6600)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.075% (6035/6700)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 90.044% (6123/6800)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 90.014% (6211/6900)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 90.029% (6302/7000)\n",
      "Test Epoch: 11 | Loss: 0.329 | Acc: 90.028% (6392/7100)\n",
      "Test Epoch: 11 | Loss: 0.328 | Acc: 90.042% (6483/7200)\n",
      "Test Epoch: 11 | Loss: 0.326 | Acc: 90.082% (6576/7300)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.135% (6670/7400)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.160% (6762/7500)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.158% (6852/7600)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.208% (6946/7700)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.218% (7037/7800)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.215% (7127/7900)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.213% (7217/8000)\n",
      "Test Epoch: 11 | Loss: 0.322 | Acc: 90.235% (7309/8100)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.207% (7397/8200)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.181% (7485/8300)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.202% (7577/8400)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.141% (7662/8500)\n",
      "Test Epoch: 11 | Loss: 0.327 | Acc: 90.047% (7744/8600)\n",
      "Test Epoch: 11 | Loss: 0.326 | Acc: 90.080% (7837/8700)\n",
      "Test Epoch: 11 | Loss: 0.327 | Acc: 90.091% (7928/8800)\n",
      "Test Epoch: 11 | Loss: 0.326 | Acc: 90.124% (8021/8900)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.156% (8114/9000)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.154% (8204/9100)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.228% (8301/9200)\n",
      "Test Epoch: 11 | Loss: 0.325 | Acc: 90.215% (8390/9300)\n",
      "Test Epoch: 11 | Loss: 0.324 | Acc: 90.223% (8481/9400)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.232% (8572/9500)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.229% (8662/9600)\n",
      "Test Epoch: 11 | Loss: 0.321 | Acc: 90.299% (8759/9700)\n",
      "Test Epoch: 11 | Loss: 0.321 | Acc: 90.316% (8851/9800)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.283% (8938/9900)\n",
      "Test Epoch: 11 | Loss: 0.323 | Acc: 90.290% (9029/10000)\n",
      "\n",
      "Epoch: 12\n",
      "Train Epoch: 12 | Loss: 0.139 | Acc: 95.312% (122/128)\n",
      "Train Epoch: 12 | Loss: 0.148 | Acc: 94.141% (241/256)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 94.792% (364/384)\n",
      "Train Epoch: 12 | Loss: 0.147 | Acc: 95.312% (488/512)\n",
      "Train Epoch: 12 | Loss: 0.148 | Acc: 95.312% (610/640)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.573% (734/768)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.312% (854/896)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.020% (973/1024)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.226% (1097/1152)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.844% (1214/1280)\n",
      "Train Epoch: 12 | Loss: 0.152 | Acc: 94.389% (1329/1408)\n",
      "Train Epoch: 12 | Loss: 0.156 | Acc: 94.010% (1444/1536)\n",
      "Train Epoch: 12 | Loss: 0.155 | Acc: 94.111% (1566/1664)\n",
      "Train Epoch: 12 | Loss: 0.159 | Acc: 93.973% (1684/1792)\n",
      "Train Epoch: 12 | Loss: 0.157 | Acc: 94.167% (1808/1920)\n",
      "Train Epoch: 12 | Loss: 0.159 | Acc: 94.043% (1926/2048)\n",
      "Train Epoch: 12 | Loss: 0.155 | Acc: 94.301% (2052/2176)\n",
      "Train Epoch: 12 | Loss: 0.155 | Acc: 94.314% (2173/2304)\n",
      "Train Epoch: 12 | Loss: 0.154 | Acc: 94.367% (2295/2432)\n",
      "Train Epoch: 12 | Loss: 0.155 | Acc: 94.336% (2415/2560)\n",
      "Train Epoch: 12 | Loss: 0.154 | Acc: 94.420% (2538/2688)\n",
      "Train Epoch: 12 | Loss: 0.153 | Acc: 94.460% (2660/2816)\n",
      "Train Epoch: 12 | Loss: 0.152 | Acc: 94.497% (2782/2944)\n",
      "Train Epoch: 12 | Loss: 0.152 | Acc: 94.499% (2903/3072)\n",
      "Train Epoch: 12 | Loss: 0.149 | Acc: 94.594% (3027/3200)\n",
      "Train Epoch: 12 | Loss: 0.150 | Acc: 94.531% (3146/3328)\n",
      "Train Epoch: 12 | Loss: 0.149 | Acc: 94.560% (3268/3456)\n",
      "Train Epoch: 12 | Loss: 0.147 | Acc: 94.671% (3393/3584)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.774% (3518/3712)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.844% (3642/3840)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.834% (3763/3968)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.800% (3883/4096)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.792% (4004/4224)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.807% (4126/4352)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.799% (4247/4480)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.813% (4369/4608)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.785% (4489/4736)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.778% (4610/4864)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.772% (4731/4992)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.785% (4853/5120)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.779% (4974/5248)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.792% (5096/5376)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.731% (5214/5504)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.727% (5335/5632)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.722% (5456/5760)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.769% (5580/5888)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.781% (5702/6016)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.792% (5824/6144)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.786% (5945/6272)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.781% (6066/6400)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.807% (6189/6528)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.802% (6310/6656)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.752% (6428/6784)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.763% (6550/6912)\n",
      "Train Epoch: 12 | Loss: 0.146 | Acc: 94.744% (6670/7040)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.782% (6794/7168)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.778% (6915/7296)\n",
      "Train Epoch: 12 | Loss: 0.145 | Acc: 94.787% (7037/7424)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.796% (7159/7552)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.831% (7283/7680)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.839% (7405/7808)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 94.859% (7528/7936)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.841% (7648/8064)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.812% (7767/8192)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.832% (7890/8320)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 94.827% (8011/8448)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.834% (8133/8576)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.773% (8249/8704)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.758% (8369/8832)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.788% (8493/8960)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.806% (8616/9088)\n",
      "Train Epoch: 12 | Loss: 0.144 | Acc: 94.770% (8734/9216)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.799% (8858/9344)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.806% (8980/9472)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 94.823% (9103/9600)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 94.850% (9227/9728)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 94.897% (9353/9856)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 94.912% (9476/9984)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 94.937% (9600/10112)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 94.951% (9723/10240)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 94.965% (9846/10368)\n",
      "Train Epoch: 12 | Loss: 0.139 | Acc: 94.979% (9969/10496)\n",
      "Train Epoch: 12 | Loss: 0.139 | Acc: 94.992% (10092/10624)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.015% (10216/10752)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.028% (10339/10880)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.049% (10463/11008)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.061% (10586/11136)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.082% (10710/11264)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.111% (10835/11392)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.130% (10959/11520)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.141% (11082/11648)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.160% (11206/11776)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.153% (11327/11904)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.163% (11450/12032)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.140% (11569/12160)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.142% (11691/12288)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.184% (11818/12416)\n",
      "Train Epoch: 12 | Loss: 0.134 | Acc: 95.201% (11942/12544)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.139% (12056/12672)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.125% (12176/12800)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.135% (12299/12928)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.090% (12415/13056)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.093% (12537/13184)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.102% (12660/13312)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.112% (12783/13440)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.106% (12904/13568)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.130% (13029/13696)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.153% (13154/13824)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.155% (13276/13952)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.163% (13399/14080)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.186% (13524/14208)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.194% (13647/14336)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.174% (13766/14464)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.155% (13885/14592)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.143% (14005/14720)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.124% (14124/14848)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.126% (14246/14976)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.127% (14368/15104)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.129% (14490/15232)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.137% (14613/15360)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.151% (14737/15488)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.140% (14857/15616)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.160% (14982/15744)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.168% (15105/15872)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.181% (15229/16000)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.182% (15351/16128)\n",
      "Train Epoch: 12 | Loss: 0.135 | Acc: 95.189% (15474/16256)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.178% (15594/16384)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.185% (15717/16512)\n",
      "Train Epoch: 12 | Loss: 0.136 | Acc: 95.162% (15835/16640)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.140% (15953/16768)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.147% (16076/16896)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.142% (16197/17024)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.149% (16320/17152)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.179% (16447/17280)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.169% (16567/17408)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.187% (16692/17536)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.194% (16815/17664)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.194% (16937/17792)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.179% (17056/17920)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.185% (17179/18048)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.186% (17301/18176)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.198% (17425/18304)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.215% (17550/18432)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.221% (17673/18560)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.211% (17793/18688)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.201% (17913/18816)\n",
      "Train Epoch: 12 | Loss: 0.137 | Acc: 95.202% (18035/18944)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.176% (18152/19072)\n",
      "Train Epoch: 12 | Loss: 0.138 | Acc: 95.167% (18272/19200)\n",
      "Train Epoch: 12 | Loss: 0.139 | Acc: 95.142% (18389/19328)\n",
      "Train Epoch: 12 | Loss: 0.139 | Acc: 95.117% (18506/19456)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 95.103% (18625/19584)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 95.099% (18746/19712)\n",
      "Train Epoch: 12 | Loss: 0.140 | Acc: 95.081% (18864/19840)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.052% (18980/19968)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.059% (19103/20096)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.060% (19225/20224)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.037% (19342/20352)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.039% (19464/20480)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.060% (19590/20608)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.067% (19713/20736)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.068% (19835/20864)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.070% (19957/20992)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.066% (20078/21120)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.054% (20197/21248)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.046% (20317/21376)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.038% (20437/21504)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.044% (20560/21632)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.037% (20680/21760)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.043% (20803/21888)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.054% (20927/22016)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.055% (21049/22144)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.057% (21171/22272)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.045% (21290/22400)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.059% (21415/22528)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.070% (21539/22656)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.071% (21661/22784)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.086% (21786/22912)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.100% (21911/23040)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.092% (22031/23168)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.102% (22155/23296)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.108% (22278/23424)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.126% (22404/23552)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.127% (22526/23680)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.119% (22646/23808)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.112% (22766/23936)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.105% (22886/24064)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.081% (23002/24192)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.078% (23123/24320)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.075% (23244/24448)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.072% (23365/24576)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.086% (23490/24704)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.095% (23614/24832)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.096% (23736/24960)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.105% (23860/25088)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.114% (23984/25216)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.119% (24107/25344)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.112% (24227/25472)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.117% (24350/25600)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.106% (24469/25728)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.104% (24590/25856)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.109% (24713/25984)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.113% (24836/26112)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.126% (24961/26240)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.127% (25083/26368)\n",
      "Train Epoch: 12 | Loss: 0.141 | Acc: 95.120% (25203/26496)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.102% (25320/26624)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.084% (25437/26752)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.089% (25560/26880)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.094% (25683/27008)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.091% (25804/27136)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.096% (25927/27264)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.086% (26046/27392)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.094% (26170/27520)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.085% (26289/27648)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.082% (26410/27776)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.087% (26533/27904)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.081% (26653/28032)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.075% (26773/28160)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.072% (26894/28288)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.073% (27016/28416)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.074% (27138/28544)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.065% (27257/28672)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.073% (27381/28800)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.084% (27506/28928)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.092% (27630/29056)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.093% (27752/29184)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.098% (27875/29312)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.095% (27996/29440)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.089% (28116/29568)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.080% (28235/29696)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.081% (28357/29824)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.089% (28481/29952)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.086% (28602/30080)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.084% (28723/30208)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.082% (28844/30336)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.086% (28967/30464)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.074% (29085/30592)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.065% (29204/30720)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.069% (29327/30848)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.061% (29446/30976)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.062% (29568/31104)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.066% (29691/31232)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.070% (29814/31360)\n",
      "Train Epoch: 12 | Loss: 0.142 | Acc: 95.081% (29939/31488)\n",
      "Train Epoch: 12 | Loss: 0.143 | Acc: 95.072% (30058/31616)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_110/3182561213.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_110/2985266092.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    277\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mforeach\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                                 \u001b[0mper_device_and_dtype_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for epoch in range(start_epoch, start_epoch+50):\n",
    "    #train(epoch)\n",
    "    #test(epoch)\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trloss_list,'-o')\n",
    "plt.plot(tloss_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tracc_list,'-o')\n",
    "plt.plot(tacc_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trloss_list,'-o')\n",
    "plt.plot(tloss_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Obc8bEGDCY4s",
    "outputId": "4225c6cf-fae5-4119-add7-09628e4d21a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
      "Test Epoch: 39 | Loss: 0.321 | Acc: 90.667% (2992/3300)\n",
      "Test Epoch: 39 | Loss: 0.322 | Acc: 90.588% (3080/3400)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.571% (3170/3500)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.639% (3263/3600)\n",
      "Test Epoch: 39 | Loss: 0.327 | Acc: 90.595% (3352/3700)\n",
      "Test Epoch: 39 | Loss: 0.329 | Acc: 90.526% (3440/3800)\n",
      "Test Epoch: 39 | Loss: 0.327 | Acc: 90.615% (3534/3900)\n",
      "Test Epoch: 39 | Loss: 0.327 | Acc: 90.700% (3628/4000)\n",
      "Test Epoch: 39 | Loss: 0.330 | Acc: 90.585% (3714/4100)\n",
      "Test Epoch: 39 | Loss: 0.332 | Acc: 90.548% (3803/4200)\n",
      "Test Epoch: 39 | Loss: 0.330 | Acc: 90.651% (3898/4300)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.750% (3993/4400)\n",
      "Test Epoch: 39 | Loss: 0.322 | Acc: 90.822% (4087/4500)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.739% (4174/4600)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.723% (4264/4700)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.646% (4351/4800)\n",
      "Test Epoch: 39 | Loss: 0.324 | Acc: 90.714% (4445/4900)\n",
      "Test Epoch: 39 | Loss: 0.329 | Acc: 90.640% (4532/5000)\n",
      "Test Epoch: 39 | Loss: 0.327 | Acc: 90.706% (4626/5100)\n",
      "Test Epoch: 39 | Loss: 0.327 | Acc: 90.615% (4712/5200)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.642% (4804/5300)\n",
      "Test Epoch: 39 | Loss: 0.325 | Acc: 90.704% (4898/5400)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.691% (4988/5500)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.768% (5083/5600)\n",
      "Test Epoch: 39 | Loss: 0.324 | Acc: 90.772% (5174/5700)\n",
      "Test Epoch: 39 | Loss: 0.322 | Acc: 90.810% (5267/5800)\n",
      "Test Epoch: 39 | Loss: 0.326 | Acc: 90.746% (5354/5900)\n",
      "Test Epoch: 39 | Loss: 0.325 | Acc: 90.783% (5447/6000)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.836% (5541/6100)\n",
      "Test Epoch: 39 | Loss: 0.324 | Acc: 90.823% (5631/6200)\n",
      "Test Epoch: 39 | Loss: 0.323 | Acc: 90.857% (5724/6300)\n",
      "Test Epoch: 39 | Loss: 0.320 | Acc: 90.906% (5818/6400)\n",
      "Test Epoch: 39 | Loss: 0.321 | Acc: 90.892% (5908/6500)\n",
      "Test Epoch: 39 | Loss: 0.320 | Acc: 90.894% (5999/6600)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 90.881% (6089/6700)\n",
      "Test Epoch: 39 | Loss: 0.320 | Acc: 90.824% (6176/6800)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 90.913% (6273/6900)\n",
      "Test Epoch: 39 | Loss: 0.321 | Acc: 90.857% (6360/7000)\n",
      "Test Epoch: 39 | Loss: 0.322 | Acc: 90.915% (6455/7100)\n",
      "Test Epoch: 39 | Loss: 0.321 | Acc: 90.931% (6547/7200)\n",
      "Test Epoch: 39 | Loss: 0.319 | Acc: 90.973% (6641/7300)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 91.027% (6736/7400)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 90.987% (6824/7500)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 90.987% (6915/7600)\n",
      "Test Epoch: 39 | Loss: 0.319 | Acc: 90.948% (7003/7700)\n",
      "Test Epoch: 39 | Loss: 0.318 | Acc: 90.962% (7095/7800)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 90.975% (7187/7900)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 90.963% (7277/8000)\n",
      "Test Epoch: 39 | Loss: 0.313 | Acc: 91.012% (7372/8100)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 90.988% (7461/8200)\n",
      "Test Epoch: 39 | Loss: 0.313 | Acc: 91.060% (7558/8300)\n",
      "Test Epoch: 39 | Loss: 0.313 | Acc: 91.071% (7650/8400)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 91.012% (7736/8500)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 91.000% (7826/8600)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 91.034% (7920/8700)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 90.989% (8007/8800)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 90.989% (8098/8900)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 90.978% (8188/9000)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 91.022% (8283/9100)\n",
      "Test Epoch: 39 | Loss: 0.314 | Acc: 91.065% (8378/9200)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 91.065% (8469/9300)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 91.043% (8558/9400)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 91.053% (8650/9500)\n",
      "Test Epoch: 39 | Loss: 0.317 | Acc: 91.104% (8746/9600)\n",
      "Test Epoch: 39 | Loss: 0.315 | Acc: 91.124% (8839/9700)\n",
      "Test Epoch: 39 | Loss: 0.313 | Acc: 91.143% (8932/9800)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 91.071% (9016/9900)\n",
      "Test Epoch: 39 | Loss: 0.316 | Acc: 91.090% (9109/10000)\n",
      "\n",
      "Epoch: 40\n",
      "Train Epoch: 40 | Loss: 0.033 | Acc: 98.438% (126/128)\n",
      "Train Epoch: 40 | Loss: 0.063 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 40 | Loss: 0.058 | Acc: 97.396% (374/384)\n",
      "Train Epoch: 40 | Loss: 0.058 | Acc: 97.461% (499/512)\n",
      "Train Epoch: 40 | Loss: 0.059 | Acc: 97.656% (625/640)\n",
      "Train Epoch: 40 | Loss: 0.055 | Acc: 97.786% (751/768)\n",
      "Train Epoch: 40 | Loss: 0.059 | Acc: 97.656% (875/896)\n",
      "Train Epoch: 40 | Loss: 0.057 | Acc: 97.754% (1001/1024)\n",
      "Train Epoch: 40 | Loss: 0.062 | Acc: 97.569% (1124/1152)\n",
      "Train Epoch: 40 | Loss: 0.060 | Acc: 97.812% (1252/1280)\n",
      "Train Epoch: 40 | Loss: 0.058 | Acc: 97.940% (1379/1408)\n",
      "Train Epoch: 40 | Loss: 0.061 | Acc: 97.852% (1503/1536)\n",
      "Train Epoch: 40 | Loss: 0.059 | Acc: 97.957% (1630/1664)\n",
      "Train Epoch: 40 | Loss: 0.058 | Acc: 97.991% (1756/1792)\n",
      "Train Epoch: 40 | Loss: 0.059 | Acc: 97.917% (1880/1920)\n",
      "Train Epoch: 40 | Loss: 0.062 | Acc: 97.754% (2002/2048)\n",
      "Train Epoch: 40 | Loss: 0.065 | Acc: 97.702% (2126/2176)\n",
      "Train Epoch: 40 | Loss: 0.067 | Acc: 97.656% (2250/2304)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.615% (2374/2432)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.656% (2500/2560)\n",
      "Train Epoch: 40 | Loss: 0.068 | Acc: 97.693% (2626/2688)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.727% (2752/2816)\n",
      "Train Epoch: 40 | Loss: 0.068 | Acc: 97.724% (2877/2944)\n",
      "Train Epoch: 40 | Loss: 0.067 | Acc: 97.754% (3003/3072)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.688% (3126/3200)\n",
      "Train Epoch: 40 | Loss: 0.068 | Acc: 97.686% (3251/3328)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.685% (3376/3456)\n",
      "Train Epoch: 40 | Loss: 0.068 | Acc: 97.740% (3503/3584)\n",
      "Train Epoch: 40 | Loss: 0.067 | Acc: 97.764% (3629/3712)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.682% (3751/3840)\n",
      "Train Epoch: 40 | Loss: 0.067 | Acc: 97.732% (3878/3968)\n",
      "Train Epoch: 40 | Loss: 0.068 | Acc: 97.705% (4002/4096)\n",
      "Train Epoch: 40 | Loss: 0.069 | Acc: 97.680% (4126/4224)\n",
      "Train Epoch: 40 | Loss: 0.070 | Acc: 97.656% (4250/4352)\n",
      "Train Epoch: 40 | Loss: 0.070 | Acc: 97.656% (4375/4480)\n",
      "Train Epoch: 40 | Loss: 0.070 | Acc: 97.678% (4501/4608)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.677% (4626/4736)\n",
      "Train Epoch: 40 | Loss: 0.070 | Acc: 97.697% (4752/4864)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.656% (4875/4992)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.656% (5000/5120)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.675% (5126/5248)\n",
      "Train Epoch: 40 | Loss: 0.070 | Acc: 97.712% (5253/5376)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.656% (5375/5504)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.638% (5499/5632)\n",
      "Train Epoch: 40 | Loss: 0.071 | Acc: 97.622% (5623/5760)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.588% (5746/5888)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.540% (5868/6016)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.542% (5993/6144)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.592% (6121/6272)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.562% (6244/6400)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.534% (6367/6528)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.551% (6493/6656)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.583% (6620/6784)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.627% (6748/6912)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.656% (6875/7040)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.684% (7002/7168)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.697% (7128/7296)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.697% (7253/7424)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.669% (7376/7552)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.643% (7499/7680)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.643% (7624/7808)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.669% (7751/7936)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.693% (7878/8064)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.668% (8001/8192)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.668% (8126/8320)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.668% (8251/8448)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.680% (8377/8576)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.668% (8501/8704)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.668% (8626/8832)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.679% (8752/8960)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.667% (8876/9088)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.645% (8999/9216)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.603% (9120/9344)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.582% (9243/9472)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.562% (9366/9600)\n",
      "Train Epoch: 40 | Loss: 0.072 | Acc: 97.574% (9492/9728)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.565% (9616/9856)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.586% (9743/9984)\n",
      "Train Epoch: 40 | Loss: 0.073 | Acc: 97.587% (9868/10112)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.559% (9990/10240)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.569% (10116/10368)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.532% (10237/10496)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.543% (10363/10624)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.545% (10488/10752)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.518% (10610/10880)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.520% (10735/11008)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.531% (10861/11136)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.541% (10987/11264)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.533% (11111/11392)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.535% (11236/11520)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.527% (11360/11648)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.520% (11484/11776)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.530% (11610/11904)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.523% (11734/12032)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.500% (11856/12160)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.493% (11980/12288)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.519% (12108/12416)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.521% (12233/12544)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.546% (12361/12672)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.555% (12487/12800)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.548% (12611/12928)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.526% (12733/13056)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.512% (12856/13184)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.529% (12983/13312)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.552% (13111/13440)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.538% (13234/13568)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.532% (13358/13696)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.533% (13483/13824)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.527% (13607/13952)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.528% (13732/14080)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.523% (13856/14208)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.531% (13982/14336)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.553% (14110/14464)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.547% (14234/14592)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.554% (14360/14720)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.569% (14487/14848)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.556% (14610/14976)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.557% (14735/15104)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.558% (14860/15232)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.578% (14988/15360)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.579% (15113/15488)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.567% (15236/15616)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.548% (15358/15744)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.549% (15483/15872)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.550% (15608/16000)\n",
      "Train Epoch: 40 | Loss: 0.074 | Acc: 97.551% (15733/16128)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.521% (15853/16256)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.516% (15977/16384)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.511% (16101/16512)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.506% (16225/16640)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.489% (16347/16768)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.491% (16472/16896)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.492% (16597/17024)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.505% (16724/17152)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.500% (16848/17280)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.518% (16976/17408)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.514% (17100/17536)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.509% (17224/17664)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.510% (17349/17792)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.500% (17472/17920)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.507% (17598/18048)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.508% (17723/18176)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.509% (17848/18304)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.510% (17973/18432)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.505% (18097/18560)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.506% (18222/18688)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.502% (18346/18816)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.482% (18467/18944)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.478% (18591/19072)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.490% (18718/19200)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.470% (18839/19328)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.471% (18964/19456)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.457% (19086/19584)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.448% (19209/19712)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.465% (19337/19840)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.471% (19463/19968)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.477% (19589/20096)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.463% (19711/20224)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.455% (19834/20352)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.446% (19957/20480)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.448% (20082/20608)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.449% (20207/20736)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.445% (20331/20864)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.442% (20455/20992)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.438% (20579/21120)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.444% (20705/21248)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.450% (20831/21376)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.447% (20955/21504)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.457% (21082/21632)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.449% (21205/21760)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.451% (21330/21888)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.443% (21453/22016)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.444% (21578/22144)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.454% (21705/22272)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.460% (21831/22400)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.470% (21958/22528)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.471% (22083/22656)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.476% (22209/22784)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.482% (22335/22912)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.474% (22458/23040)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.471% (22582/23168)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.476% (22708/23296)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.473% (22832/23424)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.469% (22956/23552)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.470% (23081/23680)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.455% (23202/23808)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.452% (23326/23936)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.448% (23450/24064)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.437% (23572/24192)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.430% (23695/24320)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.431% (23820/24448)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.416% (23941/24576)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.417% (24066/24704)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.415% (24190/24832)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.424% (24317/24960)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.429% (24443/25088)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.430% (24568/25216)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.431% (24693/25344)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.432% (24818/25472)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.441% (24945/25600)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.439% (25069/25728)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.436% (25193/25856)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.437% (25318/25984)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.438% (25443/26112)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.439% (25568/26240)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.444% (25694/26368)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.441% (25818/26496)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.442% (25943/26624)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.443% (26068/26752)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.444% (26193/26880)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.441% (26317/27008)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.446% (26443/27136)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.447% (26568/27264)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.448% (26693/27392)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.460% (26821/27520)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.465% (26947/27648)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.465% (27072/27776)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.470% (27198/27904)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.474% (27324/28032)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.457% (27444/28160)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.465% (27571/28288)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.466% (27696/28416)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.464% (27820/28544)\n",
      "Train Epoch: 40 | Loss: 0.075 | Acc: 97.471% (27947/28672)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.469% (28071/28800)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.463% (28194/28928)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.460% (28318/29056)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.461% (28443/29184)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.441% (28562/29312)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.442% (28687/29440)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.433% (28809/29568)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.437% (28935/29696)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.438% (29060/29824)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.423% (29180/29952)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.427% (29306/30080)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.428% (29431/30208)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.416% (29552/30336)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.423% (29679/30464)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.431% (29806/30592)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.432% (29931/30720)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.436% (30057/30848)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.433% (30181/30976)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (30302/31104)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.419% (30426/31232)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.414% (30549/31360)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.412% (30673/31488)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.413% (30798/31616)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.411% (30922/31744)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.415% (31048/31872)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.425% (31176/32000)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.420% (31299/32128)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.414% (31422/32256)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.418% (31548/32384)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.413% (31671/32512)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.417% (31797/32640)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.415% (31921/32768)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.413% (32045/32896)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.417% (32171/33024)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.415% (32295/33152)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (32422/33280)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.414% (32544/33408)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.418% (32670/33536)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.419% (32795/33664)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.420% (32920/33792)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.412% (33042/33920)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.421% (33170/34048)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (33295/34176)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.426% (33421/34304)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.427% (33546/34432)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.436% (33674/34560)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.429% (33796/34688)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.432% (33922/34816)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.433% (34047/34944)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.437% (34173/35072)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.440% (34299/35200)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.438% (34423/35328)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.428% (34544/35456)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.431% (34670/35584)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.438% (34797/35712)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.436% (34921/35840)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.428% (35043/35968)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.435% (35170/36096)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.435% (35295/36224)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.436% (35420/36352)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.437% (35545/36480)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.440% (35671/36608)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.447% (35798/36736)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.445% (35922/36864)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.440% (36045/36992)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.446% (36172/37120)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.444% (36296/37248)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.445% (36421/37376)\n",
      "Train Epoch: 40 | Loss: 0.076 | Acc: 97.448% (36547/37504)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.433% (36666/37632)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.434% (36791/37760)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.435% (36916/37888)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.433% (37040/38016)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.426% (37162/38144)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.429% (37288/38272)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.427% (37412/38400)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.430% (37538/38528)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.429% (37662/38656)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.432% (37788/38784)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.435% (37914/38912)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.436% (38039/39040)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.439% (38165/39168)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.430% (38286/39296)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.428% (38410/39424)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.429% (38535/39552)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (38657/39680)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.418% (38780/39808)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.416% (38904/39936)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.417% (39029/40064)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.420% (39155/40192)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.416% (39278/40320)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.424% (39406/40448)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.427% (39532/40576)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.428% (39657/40704)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.419% (39778/40832)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (39904/40960)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.420% (40028/41088)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.423% (40154/41216)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.422% (40278/41344)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.418% (40401/41472)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.416% (40525/41600)\n",
      "Train Epoch: 40 | Loss: 0.077 | Acc: 97.407% (40646/41728)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.398% (40767/41856)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.406% (40895/41984)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.402% (41018/42112)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.401% (41142/42240)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.401% (41267/42368)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.402% (41392/42496)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.391% (41512/42624)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.392% (41637/42752)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.397% (41764/42880)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.398% (41889/43008)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.404% (42016/43136)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.404% (42141/43264)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.405% (42266/43392)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.397% (42387/43520)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.390% (42509/43648)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.378% (42628/43776)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.378% (42753/43904)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.377% (42877/44032)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.375% (43001/44160)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.376% (43126/44288)\n",
      "Train Epoch: 40 | Loss: 0.078 | Acc: 97.370% (43248/44416)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.364% (43370/44544)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.361% (43493/44672)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.362% (43618/44800)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.360% (43742/44928)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.352% (43863/45056)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.349% (43986/45184)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.356% (44114/45312)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.355% (44238/45440)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.356% (44363/45568)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.359% (44489/45696)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.359% (44614/45824)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.358% (44738/45952)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.355% (44861/46080)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.353% (44985/46208)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.350% (45108/46336)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.348% (45232/46464)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.345% (45355/46592)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.344% (45479/46720)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.345% (45604/46848)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.339% (45726/46976)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.342% (45852/47104)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.343% (45977/47232)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.342% (46101/47360)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.336% (46223/47488)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.343% (46351/47616)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.336% (46472/47744)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.335% (46596/47872)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.340% (46723/48000)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.338% (46847/48128)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.341% (46973/48256)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.344% (47099/48384)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.343% (47223/48512)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.344% (47348/48640)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.345% (47473/48768)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.347% (47599/48896)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.348% (47724/49024)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.347% (47848/49152)\n",
      "Train Epoch: 40 | Loss: 0.079 | Acc: 97.342% (47970/49280)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.341% (48094/49408)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.335% (48216/49536)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.334% (48340/49664)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.333% (48464/49792)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.328% (48586/49920)\n",
      "Train Epoch: 40 | Loss: 0.080 | Acc: 97.326% (48663/50000)\n",
      "Test Epoch: 40 | Loss: 0.238 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 40 | Loss: 0.292 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 40 | Loss: 0.302 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 40 | Loss: 0.269 | Acc: 92.750% (371/400)\n",
      "Test Epoch: 40 | Loss: 0.263 | Acc: 93.000% (465/500)\n",
      "Test Epoch: 40 | Loss: 0.236 | Acc: 93.500% (561/600)\n",
      "Test Epoch: 40 | Loss: 0.243 | Acc: 93.143% (652/700)\n",
      "Test Epoch: 40 | Loss: 0.280 | Acc: 92.500% (740/800)\n",
      "Test Epoch: 40 | Loss: 0.289 | Acc: 92.333% (831/900)\n",
      "Test Epoch: 40 | Loss: 0.288 | Acc: 92.200% (922/1000)\n",
      "Test Epoch: 40 | Loss: 0.291 | Acc: 92.000% (1012/1100)\n",
      "Test Epoch: 40 | Loss: 0.305 | Acc: 91.833% (1102/1200)\n",
      "Test Epoch: 40 | Loss: 0.296 | Acc: 92.000% (1196/1300)\n",
      "Test Epoch: 40 | Loss: 0.292 | Acc: 92.071% (1289/1400)\n",
      "Test Epoch: 40 | Loss: 0.291 | Acc: 92.133% (1382/1500)\n",
      "Test Epoch: 40 | Loss: 0.289 | Acc: 92.312% (1477/1600)\n",
      "Test Epoch: 40 | Loss: 0.288 | Acc: 92.471% (1572/1700)\n",
      "Test Epoch: 40 | Loss: 0.292 | Acc: 92.389% (1663/1800)\n",
      "Test Epoch: 40 | Loss: 0.296 | Acc: 92.316% (1754/1900)\n",
      "Test Epoch: 40 | Loss: 0.305 | Acc: 92.150% (1843/2000)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.905% (1930/2100)\n",
      "Test Epoch: 40 | Loss: 0.313 | Acc: 91.727% (2018/2200)\n",
      "Test Epoch: 40 | Loss: 0.312 | Acc: 91.522% (2105/2300)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.542% (2197/2400)\n",
      "Test Epoch: 40 | Loss: 0.311 | Acc: 91.520% (2288/2500)\n",
      "Test Epoch: 40 | Loss: 0.328 | Acc: 91.385% (2376/2600)\n",
      "Test Epoch: 40 | Loss: 0.321 | Acc: 91.519% (2471/2700)\n",
      "Test Epoch: 40 | Loss: 0.320 | Acc: 91.464% (2561/2800)\n",
      "Test Epoch: 40 | Loss: 0.320 | Acc: 91.448% (2652/2900)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.533% (2746/3000)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.613% (2840/3100)\n",
      "Test Epoch: 40 | Loss: 0.311 | Acc: 91.781% (2937/3200)\n",
      "Test Epoch: 40 | Loss: 0.310 | Acc: 91.758% (3028/3300)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.735% (3119/3400)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.714% (3210/3500)\n",
      "Test Epoch: 40 | Loss: 0.309 | Acc: 91.694% (3301/3600)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.568% (3388/3700)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.553% (3479/3800)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.513% (3569/3900)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.550% (3662/4000)\n",
      "Test Epoch: 40 | Loss: 0.320 | Acc: 91.390% (3747/4100)\n",
      "Test Epoch: 40 | Loss: 0.324 | Acc: 91.333% (3836/4200)\n",
      "Test Epoch: 40 | Loss: 0.322 | Acc: 91.419% (3931/4300)\n",
      "Test Epoch: 40 | Loss: 0.319 | Acc: 91.500% (4026/4400)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.489% (4117/4500)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.370% (4203/4600)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.404% (4296/4700)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.417% (4388/4800)\n",
      "Test Epoch: 40 | Loss: 0.315 | Acc: 91.510% (4484/4900)\n",
      "Test Epoch: 40 | Loss: 0.319 | Acc: 91.380% (4569/5000)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.490% (4666/5100)\n",
      "Test Epoch: 40 | Loss: 0.319 | Acc: 91.365% (4751/5200)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.396% (4844/5300)\n",
      "Test Epoch: 40 | Loss: 0.316 | Acc: 91.352% (4933/5400)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.327% (5023/5500)\n",
      "Test Epoch: 40 | Loss: 0.319 | Acc: 91.339% (5115/5600)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.368% (5208/5700)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.414% (5302/5800)\n",
      "Test Epoch: 40 | Loss: 0.321 | Acc: 91.390% (5392/5900)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.467% (5488/6000)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.492% (5581/6100)\n",
      "Test Epoch: 40 | Loss: 0.318 | Acc: 91.452% (5670/6200)\n",
      "Test Epoch: 40 | Loss: 0.317 | Acc: 91.460% (5762/6300)\n",
      "Test Epoch: 40 | Loss: 0.313 | Acc: 91.562% (5860/6400)\n",
      "Test Epoch: 40 | Loss: 0.314 | Acc: 91.538% (5950/6500)\n",
      "Test Epoch: 40 | Loss: 0.312 | Acc: 91.576% (6044/6600)\n",
      "Test Epoch: 40 | Loss: 0.311 | Acc: 91.597% (6137/6700)\n",
      "Test Epoch: 40 | Loss: 0.312 | Acc: 91.515% (6223/6800)\n",
      "Test Epoch: 40 | Loss: 0.310 | Acc: 91.551% (6317/6900)\n",
      "Test Epoch: 40 | Loss: 0.310 | Acc: 91.543% (6408/7000)\n",
      "Test Epoch: 40 | Loss: 0.312 | Acc: 91.507% (6497/7100)\n",
      "Test Epoch: 40 | Loss: 0.312 | Acc: 91.500% (6588/7200)\n",
      "Test Epoch: 40 | Loss: 0.311 | Acc: 91.534% (6682/7300)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.581% (6777/7400)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.560% (6867/7500)\n",
      "Test Epoch: 40 | Loss: 0.309 | Acc: 91.553% (6958/7600)\n",
      "Test Epoch: 40 | Loss: 0.310 | Acc: 91.506% (7046/7700)\n",
      "Test Epoch: 40 | Loss: 0.309 | Acc: 91.513% (7138/7800)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.544% (7232/7900)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.500% (7320/8000)\n",
      "Test Epoch: 40 | Loss: 0.306 | Acc: 91.519% (7413/8100)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.488% (7502/8200)\n",
      "Test Epoch: 40 | Loss: 0.305 | Acc: 91.542% (7598/8300)\n",
      "Test Epoch: 40 | Loss: 0.306 | Acc: 91.536% (7689/8400)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.518% (7779/8500)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.488% (7868/8600)\n",
      "Test Epoch: 40 | Loss: 0.306 | Acc: 91.506% (7961/8700)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.466% (8049/8800)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.461% (8140/8900)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.433% (8229/9000)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.451% (8322/9100)\n",
      "Test Epoch: 40 | Loss: 0.306 | Acc: 91.457% (8414/9200)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.441% (8504/9300)\n",
      "Test Epoch: 40 | Loss: 0.308 | Acc: 91.457% (8597/9400)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.463% (8689/9500)\n",
      "Test Epoch: 40 | Loss: 0.307 | Acc: 91.479% (8782/9600)\n",
      "Test Epoch: 40 | Loss: 0.305 | Acc: 91.515% (8877/9700)\n",
      "Test Epoch: 40 | Loss: 0.304 | Acc: 91.541% (8971/9800)\n",
      "Test Epoch: 40 | Loss: 0.305 | Acc: 91.495% (9058/9900)\n",
      "Test Epoch: 40 | Loss: 0.306 | Acc: 91.520% (9152/10000)\n",
      "\n",
      "Epoch: 41\n",
      "Train Epoch: 41 | Loss: 0.033 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 41 | Loss: 0.043 | Acc: 98.438% (252/256)\n",
      "Train Epoch: 41 | Loss: 0.062 | Acc: 98.177% (377/384)\n",
      "Train Epoch: 41 | Loss: 0.055 | Acc: 98.438% (504/512)\n",
      "Train Epoch: 41 | Loss: 0.051 | Acc: 98.594% (631/640)\n",
      "Train Epoch: 41 | Loss: 0.053 | Acc: 98.438% (756/768)\n",
      "Train Epoch: 41 | Loss: 0.059 | Acc: 98.103% (879/896)\n",
      "Train Epoch: 41 | Loss: 0.067 | Acc: 97.852% (1002/1024)\n",
      "Train Epoch: 41 | Loss: 0.064 | Acc: 98.003% (1129/1152)\n",
      "Train Epoch: 41 | Loss: 0.061 | Acc: 98.125% (1256/1280)\n",
      "Train Epoch: 41 | Loss: 0.060 | Acc: 98.224% (1383/1408)\n",
      "Train Epoch: 41 | Loss: 0.064 | Acc: 98.112% (1507/1536)\n",
      "Train Epoch: 41 | Loss: 0.066 | Acc: 97.957% (1630/1664)\n",
      "Train Epoch: 41 | Loss: 0.066 | Acc: 97.935% (1755/1792)\n",
      "Train Epoch: 41 | Loss: 0.066 | Acc: 97.812% (1878/1920)\n",
      "Train Epoch: 41 | Loss: 0.068 | Acc: 97.803% (2003/2048)\n",
      "Train Epoch: 41 | Loss: 0.067 | Acc: 97.840% (2129/2176)\n",
      "Train Epoch: 41 | Loss: 0.068 | Acc: 97.786% (2253/2304)\n",
      "Train Epoch: 41 | Loss: 0.068 | Acc: 97.821% (2379/2432)\n",
      "Train Epoch: 41 | Loss: 0.067 | Acc: 97.891% (2506/2560)\n",
      "Train Epoch: 41 | Loss: 0.066 | Acc: 97.917% (2632/2688)\n",
      "Train Epoch: 41 | Loss: 0.070 | Acc: 97.798% (2754/2816)\n",
      "Train Epoch: 41 | Loss: 0.070 | Acc: 97.758% (2878/2944)\n",
      "Train Epoch: 41 | Loss: 0.071 | Acc: 97.754% (3003/3072)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.688% (3126/3200)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.626% (3249/3328)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.627% (3374/3456)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.489% (3494/3584)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.468% (3618/3712)\n",
      "Train Epoch: 41 | Loss: 0.079 | Acc: 97.448% (3742/3840)\n",
      "Train Epoch: 41 | Loss: 0.079 | Acc: 97.480% (3868/3968)\n",
      "Train Epoch: 41 | Loss: 0.079 | Acc: 97.437% (3991/4096)\n",
      "Train Epoch: 41 | Loss: 0.079 | Acc: 97.443% (4116/4224)\n",
      "Train Epoch: 41 | Loss: 0.078 | Acc: 97.495% (4243/4352)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.522% (4369/4480)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.548% (4495/4608)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.572% (4621/4736)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.533% (4744/4864)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.496% (4867/4992)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.480% (4991/5120)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.466% (5115/5248)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.470% (5240/5376)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.420% (5362/5504)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.408% (5486/5632)\n",
      "Train Epoch: 41 | Loss: 0.077 | Acc: 97.413% (5611/5760)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.435% (5737/5888)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.407% (5860/6016)\n",
      "Train Epoch: 41 | Loss: 0.076 | Acc: 97.428% (5986/6144)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.433% (6111/6272)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.469% (6238/6400)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.472% (6363/6528)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.461% (6487/6656)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.479% (6613/6784)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.468% (6737/6912)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.457% (6861/7040)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.447% (6985/7168)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.464% (7111/7296)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.468% (7236/7424)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.497% (7363/7552)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.500% (7488/7680)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.503% (7613/7808)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.480% (7736/7936)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.520% (7864/8064)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.510% (7988/8192)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.500% (8112/8320)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.491% (8236/8448)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.505% (8362/8576)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.507% (8487/8704)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.532% (8614/8832)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.511% (8737/8960)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.502% (8861/9088)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (8987/9216)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.528% (9113/9344)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.540% (9239/9472)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.552% (9365/9600)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.574% (9492/9728)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.595% (9619/9856)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.586% (9743/9984)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.577% (9867/10112)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.549% (9989/10240)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.521% (10111/10368)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.523% (10236/10496)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (10360/10624)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.517% (10485/10752)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.491% (10607/10880)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.502% (10733/11008)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.531% (10861/11136)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.541% (10987/11264)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.551% (11113/11392)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.561% (11239/11520)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.562% (11364/11648)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.563% (11489/11776)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.564% (11614/11904)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.565% (11739/12032)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.558% (11863/12160)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.550% (11987/12288)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.560% (12113/12416)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.561% (12238/12544)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.538% (12360/12672)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.508% (12481/12800)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.532% (12609/12928)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.534% (12734/13056)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.527% (12858/13184)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.514% (12981/13312)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.507% (13105/13440)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.509% (13230/13568)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.510% (13355/13696)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.512% (13480/13824)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.527% (13607/13952)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.536% (13733/14080)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.523% (13856/14208)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.517% (13980/14336)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.476% (14099/14464)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.492% (14226/14592)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.507% (14353/14720)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.501% (14477/14848)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.516% (14604/14976)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.530% (14731/15104)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.532% (14856/15232)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.546% (14983/15360)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.540% (15107/15488)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.547% (15233/15616)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.548% (15358/15744)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.549% (15483/15872)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.544% (15607/16000)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.532% (15730/16128)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.539% (15856/16256)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.534% (15980/16384)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.529% (16104/16512)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.518% (16227/16640)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.513% (16351/16768)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.508% (16475/16896)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (16601/17024)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.510% (16725/17152)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.529% (16853/17280)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.536% (16979/17408)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.554% (17107/17536)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.560% (17233/17664)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.572% (17360/17792)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.556% (17482/17920)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.551% (17606/18048)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.546% (17730/18176)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.552% (17856/18304)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.548% (17980/18432)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.559% (18107/18560)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.565% (18233/18688)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.577% (18360/18816)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.582% (18486/18944)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.599% (18614/19072)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.594% (18738/19200)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.610% (18866/19328)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.600% (18989/19456)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.610% (19116/19584)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.616% (19242/19712)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.626% (19369/19840)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.606% (19490/19968)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.611% (19616/20096)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.612% (19741/20224)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.617% (19867/20352)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.612% (19991/20480)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.617% (20117/20608)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.618% (20242/20736)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.627% (20369/20864)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.618% (20492/20992)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.614% (20616/21120)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.614% (20741/21248)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.595% (20862/21376)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.586% (20985/21504)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.592% (21111/21632)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.583% (21234/21760)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.583% (21359/21888)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.593% (21486/22016)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.589% (21610/22144)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.593% (21736/22272)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.598% (21862/22400)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.585% (21984/22528)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.594% (22111/22656)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.599% (22237/22784)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.600% (22362/22912)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.591% (22485/23040)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.592% (22610/23168)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.588% (22734/23296)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.588% (22859/23424)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.584% (22983/23552)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.593% (23110/23680)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.597% (23236/23808)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.598% (23361/23936)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.590% (23484/24064)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.594% (23610/24192)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.595% (23735/24320)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.587% (23858/24448)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.587% (23983/24576)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.591% (24109/24704)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.592% (24234/24832)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.596% (24360/24960)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.581% (24481/25088)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.573% (24604/25216)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.577% (24730/25344)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.578% (24855/25472)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.570% (24978/25600)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.559% (25100/25728)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.567% (25227/25856)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.572% (25353/25984)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.576% (25479/26112)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.588% (25607/26240)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.592% (25733/26368)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.588% (25857/26496)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.596% (25984/26624)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.589% (26107/26752)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.582% (26230/26880)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.582% (26355/27008)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.579% (26479/27136)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.583% (26605/27264)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.587% (26731/27392)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.591% (26857/27520)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.595% (26983/27648)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.595% (27108/27776)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.599% (27234/27904)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.596% (27358/28032)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.599% (27484/28160)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.600% (27609/28288)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.603% (27735/28416)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.600% (27859/28544)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.607% (27986/28672)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.615% (28113/28800)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.611% (28237/28928)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.601% (28359/29056)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.598% (28483/29184)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.598% (28608/29312)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.609% (28736/29440)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.616% (28863/29568)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.616% (28988/29696)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.613% (29112/29824)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.603% (29234/29952)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.606% (29360/30080)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.607% (29485/30208)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.604% (29609/30336)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.597% (29732/30464)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.601% (29858/30592)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.594% (29981/30720)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.601% (30108/30848)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.605% (30234/30976)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.608% (30360/31104)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.602% (30483/31232)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.592% (30605/31360)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.599% (30732/31488)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.602% (30858/31616)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.606% (30984/31744)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.597% (31106/31872)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.588% (31228/32000)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.588% (31353/32128)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.594% (31480/32256)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.594% (31605/32384)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.595% (31730/32512)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.595% (31855/32640)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.586% (31977/32768)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.580% (32100/32896)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.581% (32225/33024)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.584% (32351/33152)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.584% (32476/33280)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.590% (32603/33408)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.591% (32728/33536)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.591% (32853/33664)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.594% (32979/33792)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.591% (33103/33920)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.595% (33229/34048)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.592% (33353/34176)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.598% (33480/34304)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.604% (33607/34432)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.601% (33731/34560)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.607% (33858/34688)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.602% (33981/34816)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.599% (34105/34944)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.596% (34229/35072)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.597% (34354/35200)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.585% (34475/35328)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.586% (34600/35456)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.566% (34718/35584)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.564% (34842/35712)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.561% (34966/35840)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.565% (35092/35968)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.562% (35216/36096)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.554% (35338/36224)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.552% (35462/36352)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.558% (35589/36480)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.558% (35714/36608)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.547% (35835/36736)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.556% (35963/36864)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.554% (36087/36992)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.554% (36212/37120)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.552% (36336/37248)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.555% (36462/37376)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.558% (36588/37504)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.561% (36714/37632)\n",
      "Train Epoch: 41 | Loss: 0.072 | Acc: 97.564% (36840/37760)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.561% (36964/37888)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.556% (37087/38016)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.546% (37208/38144)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.541% (37331/38272)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.542% (37456/38400)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.545% (37582/38528)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.540% (37705/38656)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.540% (37830/38784)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.533% (37952/38912)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.533% (38077/39040)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.534% (38202/39168)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.534% (38327/39296)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.529% (38450/39424)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.525% (38573/39552)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.530% (38700/39680)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.533% (38826/39808)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.521% (38946/39936)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.516% (39069/40064)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.517% (39194/40192)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.515% (39318/40320)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.523% (39446/40448)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.521% (39570/40576)\n",
      "Train Epoch: 41 | Loss: 0.073 | Acc: 97.519% (39694/40704)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.517% (39818/40832)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (39942/40960)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.513% (40066/41088)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.516% (40192/41216)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.516% (40317/41344)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.514% (40441/41472)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.519% (40568/41600)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.517% (40692/41728)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (40816/41856)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.516% (40941/41984)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.511% (41064/42112)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.512% (41189/42240)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.512% (41314/42368)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.506% (41436/42496)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.511% (41563/42624)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.509% (41687/42752)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.514% (41814/42880)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.517% (41940/43008)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.524% (42068/43136)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.525% (42193/43264)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.523% (42317/43392)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.521% (42441/43520)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.521% (42566/43648)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (42688/43776)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.515% (42813/43904)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.509% (42935/44032)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.514% (43062/44160)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.507% (43184/44288)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.496% (43304/44416)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.488% (43425/44544)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.486% (43549/44672)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.482% (43672/44800)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.489% (43800/44928)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.492% (43926/45056)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.492% (44051/45184)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.491% (44175/45312)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.487% (44298/45440)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.481% (44420/45568)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.483% (44546/45696)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.479% (44669/45824)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.480% (44794/45952)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.480% (44919/46080)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.485% (45046/46208)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.484% (45170/46336)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.484% (45295/46464)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.474% (45415/46592)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.479% (45542/46720)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.479% (45667/46848)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.480% (45792/46976)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.482% (45918/47104)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.485% (46044/47232)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.485% (46169/47360)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.481% (46292/47488)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.474% (46413/47616)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.474% (46538/47744)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.470% (46661/47872)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.473% (46787/48000)\n",
      "Train Epoch: 41 | Loss: 0.074 | Acc: 97.475% (46913/48128)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.470% (47035/48256)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.468% (47159/48384)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.469% (47284/48512)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.467% (47408/48640)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.472% (47535/48768)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.468% (47658/48896)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.473% (47785/49024)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.465% (47906/49152)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.466% (48031/49280)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.472% (48159/49408)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.473% (48284/49536)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.473% (48409/49664)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.480% (48537/49792)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.478% (48661/49920)\n",
      "Train Epoch: 41 | Loss: 0.075 | Acc: 97.476% (48738/50000)\n",
      "Test Epoch: 41 | Loss: 0.193 | Acc: 95.000% (95/100)\n",
      "Test Epoch: 41 | Loss: 0.330 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 41 | Loss: 0.285 | Acc: 93.000% (372/400)\n",
      "Test Epoch: 41 | Loss: 0.289 | Acc: 93.200% (466/500)\n",
      "Test Epoch: 41 | Loss: 0.258 | Acc: 93.833% (563/600)\n",
      "Test Epoch: 41 | Loss: 0.266 | Acc: 93.714% (656/700)\n",
      "Test Epoch: 41 | Loss: 0.299 | Acc: 93.250% (746/800)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 93.111% (838/900)\n",
      "Test Epoch: 41 | Loss: 0.297 | Acc: 93.000% (930/1000)\n",
      "Test Epoch: 41 | Loss: 0.291 | Acc: 93.000% (1023/1100)\n",
      "Test Epoch: 41 | Loss: 0.295 | Acc: 92.833% (1114/1200)\n",
      "Test Epoch: 41 | Loss: 0.284 | Acc: 92.923% (1208/1300)\n",
      "Test Epoch: 41 | Loss: 0.280 | Acc: 93.071% (1303/1400)\n",
      "Test Epoch: 41 | Loss: 0.279 | Acc: 93.067% (1396/1500)\n",
      "Test Epoch: 41 | Loss: 0.275 | Acc: 93.188% (1491/1600)\n",
      "Test Epoch: 41 | Loss: 0.279 | Acc: 93.176% (1584/1700)\n",
      "Test Epoch: 41 | Loss: 0.280 | Acc: 93.167% (1677/1800)\n",
      "Test Epoch: 41 | Loss: 0.284 | Acc: 92.895% (1765/1900)\n",
      "Test Epoch: 41 | Loss: 0.292 | Acc: 92.800% (1856/2000)\n",
      "Test Epoch: 41 | Loss: 0.296 | Acc: 92.429% (1941/2100)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 92.227% (2029/2200)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 92.087% (2118/2300)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 92.167% (2212/2400)\n",
      "Test Epoch: 41 | Loss: 0.309 | Acc: 92.200% (2305/2500)\n",
      "Test Epoch: 41 | Loss: 0.320 | Acc: 91.962% (2391/2600)\n",
      "Test Epoch: 41 | Loss: 0.314 | Acc: 92.000% (2484/2700)\n",
      "Test Epoch: 41 | Loss: 0.316 | Acc: 92.000% (2576/2800)\n",
      "Test Epoch: 41 | Loss: 0.312 | Acc: 92.103% (2671/2900)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 92.233% (2767/3000)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 92.194% (2858/3100)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 92.156% (2949/3200)\n",
      "Test Epoch: 41 | Loss: 0.306 | Acc: 92.182% (3042/3300)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 92.147% (3133/3400)\n",
      "Test Epoch: 41 | Loss: 0.307 | Acc: 92.000% (3220/3500)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 92.083% (3315/3600)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 91.973% (3403/3700)\n",
      "Test Epoch: 41 | Loss: 0.315 | Acc: 91.868% (3491/3800)\n",
      "Test Epoch: 41 | Loss: 0.311 | Acc: 91.872% (3583/3900)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 91.975% (3679/4000)\n",
      "Test Epoch: 41 | Loss: 0.314 | Acc: 91.756% (3762/4100)\n",
      "Test Epoch: 41 | Loss: 0.316 | Acc: 91.738% (3853/4200)\n",
      "Test Epoch: 41 | Loss: 0.315 | Acc: 91.721% (3944/4300)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.795% (4039/4400)\n",
      "Test Epoch: 41 | Loss: 0.311 | Acc: 91.800% (4131/4500)\n",
      "Test Epoch: 41 | Loss: 0.311 | Acc: 91.783% (4222/4600)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.723% (4311/4700)\n",
      "Test Epoch: 41 | Loss: 0.316 | Acc: 91.667% (4400/4800)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.776% (4497/4900)\n",
      "Test Epoch: 41 | Loss: 0.316 | Acc: 91.720% (4586/5000)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.765% (4680/5100)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.750% (4771/5200)\n",
      "Test Epoch: 41 | Loss: 0.313 | Acc: 91.679% (4859/5300)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.778% (4956/5400)\n",
      "Test Epoch: 41 | Loss: 0.311 | Acc: 91.745% (5046/5500)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 91.786% (5140/5600)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.842% (5235/5700)\n",
      "Test Epoch: 41 | Loss: 0.307 | Acc: 91.828% (5326/5800)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 91.814% (5417/5900)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.833% (5510/6000)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.836% (5602/6100)\n",
      "Test Epoch: 41 | Loss: 0.310 | Acc: 91.823% (5693/6200)\n",
      "Test Epoch: 41 | Loss: 0.309 | Acc: 91.810% (5784/6300)\n",
      "Test Epoch: 41 | Loss: 0.306 | Acc: 91.906% (5882/6400)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.862% (5971/6500)\n",
      "Test Epoch: 41 | Loss: 0.306 | Acc: 91.894% (6065/6600)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 91.910% (6158/6700)\n",
      "Test Epoch: 41 | Loss: 0.307 | Acc: 91.853% (6246/6800)\n",
      "Test Epoch: 41 | Loss: 0.307 | Acc: 91.841% (6337/6900)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.800% (6426/7000)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.789% (6517/7100)\n",
      "Test Epoch: 41 | Loss: 0.308 | Acc: 91.792% (6609/7200)\n",
      "Test Epoch: 41 | Loss: 0.306 | Acc: 91.822% (6703/7300)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.892% (6800/7400)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.893% (6892/7500)\n",
      "Test Epoch: 41 | Loss: 0.304 | Acc: 91.882% (6983/7600)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 91.870% (7074/7700)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 91.872% (7166/7800)\n",
      "Test Epoch: 41 | Loss: 0.305 | Acc: 91.886% (7259/7900)\n",
      "Test Epoch: 41 | Loss: 0.304 | Acc: 91.838% (7347/8000)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.864% (7441/8100)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.805% (7528/8200)\n",
      "Test Epoch: 41 | Loss: 0.301 | Acc: 91.831% (7622/8300)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.786% (7710/8400)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.753% (7799/8500)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.779% (7893/8600)\n",
      "Test Epoch: 41 | Loss: 0.301 | Acc: 91.828% (7989/8700)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.784% (8077/8800)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.798% (8170/8900)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.789% (8261/9000)\n",
      "Test Epoch: 41 | Loss: 0.301 | Acc: 91.835% (8357/9100)\n",
      "Test Epoch: 41 | Loss: 0.301 | Acc: 91.870% (8452/9200)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.849% (8542/9300)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.862% (8635/9400)\n",
      "Test Epoch: 41 | Loss: 0.302 | Acc: 91.863% (8727/9500)\n",
      "Test Epoch: 41 | Loss: 0.303 | Acc: 91.865% (8819/9600)\n",
      "Test Epoch: 41 | Loss: 0.300 | Acc: 91.918% (8916/9700)\n",
      "Test Epoch: 41 | Loss: 0.299 | Acc: 91.969% (9013/9800)\n",
      "Test Epoch: 41 | Loss: 0.301 | Acc: 91.949% (9103/9900)\n",
      "Test Epoch: 41 | Loss: 0.300 | Acc: 91.960% (9196/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 42\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 42 | Loss: 0.063 | Acc: 97.656% (250/256)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.396% (374/384)\n",
      "Train Epoch: 42 | Loss: 0.079 | Acc: 97.266% (498/512)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.500% (624/640)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.656% (750/768)\n",
      "Train Epoch: 42 | Loss: 0.077 | Acc: 97.545% (874/896)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.852% (1002/1024)\n",
      "Train Epoch: 42 | Loss: 0.069 | Acc: 97.830% (1127/1152)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.734% (1251/1280)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.727% (1376/1408)\n",
      "Train Epoch: 42 | Loss: 0.068 | Acc: 97.852% (1503/1536)\n",
      "Train Epoch: 42 | Loss: 0.067 | Acc: 97.897% (1629/1664)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.935% (1755/1792)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.865% (1879/1920)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.998% (2007/2048)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.978% (2132/2176)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.960% (2257/2304)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.985% (2383/2432)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 98.008% (2509/2560)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.991% (2634/2688)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.940% (2758/2816)\n",
      "Train Epoch: 42 | Loss: 0.069 | Acc: 97.962% (2884/2944)\n",
      "Train Epoch: 42 | Loss: 0.069 | Acc: 97.949% (3009/3072)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.781% (3129/3200)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.746% (3253/3328)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.801% (3380/3456)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.824% (3506/3584)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.764% (3629/3712)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.734% (3753/3840)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.757% (3879/3968)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.754% (4004/4096)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.727% (4128/4224)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.725% (4253/4352)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.679% (4376/4480)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.635% (4499/4608)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.677% (4626/4736)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.718% (4753/4864)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.756% (4880/4992)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.695% (5002/5120)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.752% (5130/5248)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.749% (5255/5376)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.783% (5382/5504)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.745% (5505/5632)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.726% (5629/5760)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.690% (5752/5888)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.689% (5877/6016)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.656% (6000/6144)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.672% (6126/6272)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.672% (6251/6400)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.656% (6375/6528)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.671% (6501/6656)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.671% (6626/6784)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.656% (6750/6912)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.670% (6876/7040)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.712% (7004/7168)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.684% (7127/7296)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.643% (7249/7424)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.590% (7370/7552)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.617% (7497/7680)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.618% (7622/7808)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.593% (7745/7936)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.569% (7868/8064)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.522% (7989/8192)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.524% (8114/8320)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.550% (8241/8448)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.540% (8365/8576)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.553% (8491/8704)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.577% (8618/8832)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.578% (8743/8960)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.557% (8866/9088)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.569% (8992/9216)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.581% (9118/9344)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.614% (9246/9472)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.625% (9372/9600)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.615% (9496/9728)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.636% (9623/9856)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.636% (9748/9984)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.607% (9870/10112)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.627% (9997/10240)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.637% (10123/10368)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.637% (10248/10496)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.628% (10372/10624)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.638% (10498/10752)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.629% (10622/10880)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.629% (10747/11008)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.647% (10874/11136)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.656% (11000/11264)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.630% (11122/11392)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.639% (11248/11520)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.648% (11374/11648)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.622% (11496/11776)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.639% (11623/11904)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.615% (11745/12032)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.623% (11871/12160)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.640% (11998/12288)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.648% (12124/12416)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.656% (12250/12544)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.648% (12374/12672)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.648% (12499/12800)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.641% (12623/12928)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.656% (12750/13056)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.641% (12873/13184)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.596% (12992/13312)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.589% (13116/13440)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.597% (13242/13568)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.583% (13365/13696)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.591% (13491/13824)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.563% (13612/13952)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.571% (13738/14080)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.558% (13861/14208)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.552% (13985/14336)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.573% (14113/14464)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.547% (14234/14592)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.541% (14358/14720)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.555% (14485/14848)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.563% (14611/14976)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.557% (14735/15104)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.571% (14862/15232)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.559% (14985/15360)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.572% (15112/15488)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.560% (15235/15616)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.555% (15359/15744)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.562% (15485/15872)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.569% (15611/16000)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.557% (15734/16128)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.558% (15859/16256)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.559% (15984/16384)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.565% (16110/16512)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.560% (16234/16640)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.573% (16361/16768)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.573% (16486/16896)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.580% (16612/17024)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.586% (16738/17152)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.587% (16863/17280)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.576% (16986/17408)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.542% (17105/17536)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.560% (17233/17664)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.544% (17355/17792)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.550% (17481/17920)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.557% (17607/18048)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.557% (17732/18176)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.552% (17856/18304)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.548% (17980/18432)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.548% (18105/18560)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.560% (18232/18688)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.550% (18355/18816)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.556% (18481/18944)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.557% (18606/19072)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.562% (18732/19200)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.573% (18859/19328)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.584% (18986/19456)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.575% (19109/19584)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.570% (19233/19712)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.581% (19360/19840)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.596% (19488/19968)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.597% (19613/20096)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.602% (19739/20224)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.597% (19863/20352)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.593% (19987/20480)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.603% (20114/20608)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.603% (20239/20736)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.613% (20366/20864)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.604% (20489/20992)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.609% (20615/21120)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.609% (20740/21248)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.609% (20865/21376)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.610% (20990/21504)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.624% (21118/21632)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.629% (21244/21760)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.629% (21369/21888)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.638% (21496/22016)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.647% (21623/22144)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.656% (21750/22272)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.652% (21874/22400)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.643% (21997/22528)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.647% (22123/22656)\n",
      "Train Epoch: 42 | Loss: 0.069 | Acc: 97.656% (22250/22784)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.656% (22375/22912)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.656% (22500/23040)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.661% (22626/23168)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.652% (22749/23296)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.652% (22874/23424)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.644% (22997/23552)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.639% (23121/23680)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.635% (23245/23808)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.635% (23370/23936)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.615% (23490/24064)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.615% (23615/24192)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.615% (23740/24320)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.615% (23865/24448)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.616% (23990/24576)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.616% (24115/24704)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.620% (24241/24832)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.628% (24368/24960)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.636% (24495/25088)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.636% (24620/25216)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.633% (24744/25344)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.637% (24870/25472)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.645% (24997/25600)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.641% (25121/25728)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.637% (25245/25856)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.629% (25368/25984)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.626% (25492/26112)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.630% (25618/26240)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.622% (25741/26368)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.622% (25866/26496)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.622% (25991/26624)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.626% (26117/26752)\n",
      "Train Epoch: 42 | Loss: 0.070 | Acc: 97.623% (26241/26880)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.616% (26364/27008)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.619% (26490/27136)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.623% (26616/27264)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.627% (26742/27392)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.631% (26868/27520)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.642% (26996/27648)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.645% (27122/27776)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.642% (27246/27904)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.649% (27373/28032)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.638% (27495/28160)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.639% (27620/28288)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.632% (27743/28416)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.635% (27869/28544)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.635% (27994/28672)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.628% (28117/28800)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.636% (28244/28928)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.629% (28367/29056)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.629% (28492/29184)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.619% (28614/29312)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.605% (28735/29440)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.612% (28862/29568)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.616% (28988/29696)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.619% (29114/29824)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.620% (29239/29952)\n",
      "Train Epoch: 42 | Loss: 0.071 | Acc: 97.610% (29361/30080)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.600% (29483/30208)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.597% (29607/30336)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.594% (29731/30464)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.588% (29854/30592)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.591% (29980/30720)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.591% (30105/30848)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.592% (30230/30976)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.589% (30354/31104)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.579% (30476/31232)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.586% (30603/31360)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.583% (30727/31488)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.584% (30852/31616)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.584% (30977/31744)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.575% (31099/31872)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.569% (31222/32000)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.569% (31347/32128)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.566% (31471/32256)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.557% (31593/32384)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.561% (31719/32512)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.567% (31846/32640)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.568% (31971/32768)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.556% (32092/32896)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.553% (32216/33024)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.554% (32341/33152)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.563% (32469/33280)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.560% (32593/33408)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.558% (32717/33536)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.558% (32842/33664)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.559% (32967/33792)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.559% (33092/33920)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.565% (33219/34048)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.557% (33341/34176)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.566% (33469/34304)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.563% (33593/34432)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.561% (33717/34560)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.567% (33844/34688)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.573% (33971/34816)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.568% (34094/34944)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.568% (34219/35072)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.565% (34343/35200)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.563% (34467/35328)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.572% (34595/35456)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.572% (34720/35584)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.578% (34847/35712)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.573% (34970/35840)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.565% (35092/35968)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.565% (35217/36096)\n",
      "Train Epoch: 42 | Loss: 0.072 | Acc: 97.557% (35339/36224)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.554% (35463/36352)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.549% (35586/36480)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.547% (35710/36608)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.545% (35834/36736)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.529% (35953/36864)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.518% (36074/36992)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.524% (36201/37120)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.525% (36326/37248)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.522% (36450/37376)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.523% (36575/37504)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.521% (36699/37632)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.529% (36827/37760)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.532% (36953/37888)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.538% (37080/38016)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.536% (37204/38144)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.531% (37327/38272)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.534% (37453/38400)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.529% (37576/38528)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.524% (37699/38656)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.525% (37824/38784)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.517% (37946/38912)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.518% (38071/39040)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.513% (38194/39168)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.509% (38317/39296)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.509% (38442/39424)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.510% (38567/39552)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.513% (38693/39680)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.513% (38818/39808)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.514% (38943/39936)\n",
      "Train Epoch: 42 | Loss: 0.073 | Acc: 97.516% (39069/40064)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.512% (39192/40192)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.510% (39316/40320)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.510% (39441/40448)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.511% (39566/40576)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.501% (39687/40704)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.500% (39811/40832)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.493% (39933/40960)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.491% (40057/41088)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.489% (40181/41216)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.487% (40305/41344)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.487% (40430/41472)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.490% (40556/41600)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.493% (40682/41728)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.489% (40805/41856)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.487% (40929/41984)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.490% (41055/42112)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.486% (41178/42240)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.486% (41303/42368)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.480% (41425/42496)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.471% (41546/42624)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.474% (41672/42752)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.470% (41795/42880)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.473% (41921/43008)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.464% (42042/43136)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.467% (42168/43264)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (42295/43392)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.468% (42418/43520)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.457% (42538/43648)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.455% (42662/43776)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.454% (42786/43904)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.459% (42913/44032)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.462% (43039/44160)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.467% (43166/44288)\n",
      "Train Epoch: 42 | Loss: 0.075 | Acc: 97.467% (43291/44416)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.465% (43415/44544)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.466% (43540/44672)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.467% (43665/44800)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.469% (43791/44928)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (43917/45056)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.475% (44043/45184)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.480% (44170/45312)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.480% (44295/45440)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.485% (44422/45568)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.479% (44544/45696)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.477% (44668/45824)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.478% (44793/45952)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.470% (44914/46080)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (45040/46208)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.471% (45164/46336)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.465% (45286/46464)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.465% (45411/46592)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.464% (45535/46720)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.468% (45662/46848)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.467% (45786/46976)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (45913/47104)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.468% (46036/47232)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.470% (46162/47360)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.477% (46290/47488)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.471% (46412/47616)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (46537/47744)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.475% (46663/47872)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.471% (46786/48000)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.471% (46911/48128)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.468% (47034/48256)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.472% (47161/48384)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.469% (47284/48512)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.469% (47409/48640)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.466% (47532/48768)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.466% (47657/48896)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.465% (47781/49024)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.463% (47905/49152)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.457% (48027/49280)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.458% (48152/49408)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.464% (48280/49536)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.469% (48407/49664)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.465% (48530/49792)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.460% (48652/49920)\n",
      "Train Epoch: 42 | Loss: 0.074 | Acc: 97.462% (48731/50000)\n",
      "Test Epoch: 42 | Loss: 0.250 | Acc: 95.000% (95/100)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 93.500% (187/200)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 42 | Loss: 0.265 | Acc: 93.750% (375/400)\n",
      "Test Epoch: 42 | Loss: 0.254 | Acc: 94.000% (470/500)\n",
      "Test Epoch: 42 | Loss: 0.239 | Acc: 94.167% (565/600)\n",
      "Test Epoch: 42 | Loss: 0.256 | Acc: 93.429% (654/700)\n",
      "Test Epoch: 42 | Loss: 0.282 | Acc: 93.000% (744/800)\n",
      "Test Epoch: 42 | Loss: 0.280 | Acc: 92.667% (834/900)\n",
      "Test Epoch: 42 | Loss: 0.271 | Acc: 92.700% (927/1000)\n",
      "Test Epoch: 42 | Loss: 0.271 | Acc: 92.909% (1022/1100)\n",
      "Test Epoch: 42 | Loss: 0.287 | Acc: 92.667% (1112/1200)\n",
      "Test Epoch: 42 | Loss: 0.284 | Acc: 92.538% (1203/1300)\n",
      "Test Epoch: 42 | Loss: 0.277 | Acc: 92.643% (1297/1400)\n",
      "Test Epoch: 42 | Loss: 0.276 | Acc: 92.800% (1392/1500)\n",
      "Test Epoch: 42 | Loss: 0.275 | Acc: 92.938% (1487/1600)\n",
      "Test Epoch: 42 | Loss: 0.277 | Acc: 93.000% (1581/1700)\n",
      "Test Epoch: 42 | Loss: 0.276 | Acc: 93.000% (1674/1800)\n",
      "Test Epoch: 42 | Loss: 0.277 | Acc: 92.789% (1763/1900)\n",
      "Test Epoch: 42 | Loss: 0.283 | Acc: 92.550% (1851/2000)\n",
      "Test Epoch: 42 | Loss: 0.291 | Acc: 92.286% (1938/2100)\n",
      "Test Epoch: 42 | Loss: 0.296 | Acc: 92.091% (2026/2200)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.957% (2115/2300)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 92.042% (2209/2400)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.960% (2299/2500)\n",
      "Test Epoch: 42 | Loss: 0.308 | Acc: 91.808% (2387/2600)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.852% (2480/2700)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.857% (2572/2800)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.897% (2665/2900)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 91.900% (2757/3000)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.903% (2849/3100)\n",
      "Test Epoch: 42 | Loss: 0.296 | Acc: 92.000% (2944/3200)\n",
      "Test Epoch: 42 | Loss: 0.293 | Acc: 92.061% (3038/3300)\n",
      "Test Epoch: 42 | Loss: 0.292 | Acc: 92.118% (3132/3400)\n",
      "Test Epoch: 42 | Loss: 0.294 | Acc: 92.114% (3224/3500)\n",
      "Test Epoch: 42 | Loss: 0.296 | Acc: 92.194% (3319/3600)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 92.108% (3408/3700)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 92.053% (3498/3800)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 92.128% (3593/3900)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 92.150% (3686/4000)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 92.049% (3774/4100)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.976% (3863/4200)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 91.977% (3955/4300)\n",
      "Test Epoch: 42 | Loss: 0.298 | Acc: 91.955% (4046/4400)\n",
      "Test Epoch: 42 | Loss: 0.294 | Acc: 91.956% (4138/4500)\n",
      "Test Epoch: 42 | Loss: 0.294 | Acc: 91.935% (4229/4600)\n",
      "Test Epoch: 42 | Loss: 0.292 | Acc: 91.936% (4321/4700)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 91.875% (4410/4800)\n",
      "Test Epoch: 42 | Loss: 0.295 | Acc: 91.939% (4505/4900)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.800% (4590/5000)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 91.863% (4685/5100)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.731% (4770/5200)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.717% (4861/5300)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 91.741% (4954/5400)\n",
      "Test Epoch: 42 | Loss: 0.301 | Acc: 91.655% (5041/5500)\n",
      "Test Epoch: 42 | Loss: 0.301 | Acc: 91.696% (5135/5600)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.684% (5226/5700)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 91.741% (5321/5800)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.729% (5412/5900)\n",
      "Test Epoch: 42 | Loss: 0.301 | Acc: 91.767% (5506/6000)\n",
      "Test Epoch: 42 | Loss: 0.300 | Acc: 91.820% (5601/6100)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.806% (5692/6200)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.825% (5785/6300)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.891% (5881/6400)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.877% (5972/6500)\n",
      "Test Epoch: 42 | Loss: 0.297 | Acc: 91.894% (6065/6600)\n",
      "Test Epoch: 42 | Loss: 0.299 | Acc: 91.836% (6153/6700)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.779% (6241/6800)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.768% (6332/6900)\n",
      "Test Epoch: 42 | Loss: 0.307 | Acc: 91.729% (6421/7000)\n",
      "Test Epoch: 42 | Loss: 0.309 | Acc: 91.690% (6510/7100)\n",
      "Test Epoch: 42 | Loss: 0.309 | Acc: 91.681% (6601/7200)\n",
      "Test Epoch: 42 | Loss: 0.308 | Acc: 91.671% (6692/7300)\n",
      "Test Epoch: 42 | Loss: 0.306 | Acc: 91.743% (6789/7400)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.733% (6880/7500)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.724% (6971/7600)\n",
      "Test Epoch: 42 | Loss: 0.307 | Acc: 91.675% (7059/7700)\n",
      "Test Epoch: 42 | Loss: 0.306 | Acc: 91.692% (7152/7800)\n",
      "Test Epoch: 42 | Loss: 0.306 | Acc: 91.709% (7245/7900)\n",
      "Test Epoch: 42 | Loss: 0.306 | Acc: 91.688% (7335/8000)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.704% (7428/8100)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.683% (7518/8200)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.735% (7614/8300)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.762% (7708/8400)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.706% (7795/8500)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.698% (7886/8600)\n",
      "Test Epoch: 42 | Loss: 0.301 | Acc: 91.736% (7981/8700)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.705% (8070/8800)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.674% (8159/8900)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.644% (8248/9000)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.692% (8344/9100)\n",
      "Test Epoch: 42 | Loss: 0.303 | Acc: 91.707% (8437/9200)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.677% (8526/9300)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.691% (8619/9400)\n",
      "Test Epoch: 42 | Loss: 0.305 | Acc: 91.663% (8708/9500)\n",
      "Test Epoch: 42 | Loss: 0.306 | Acc: 91.677% (8801/9600)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.722% (8897/9700)\n",
      "Test Epoch: 42 | Loss: 0.302 | Acc: 91.765% (8993/9800)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.747% (9083/9900)\n",
      "Test Epoch: 42 | Loss: 0.304 | Acc: 91.770% (9177/10000)\n",
      "\n",
      "Epoch: 43\n",
      "Train Epoch: 43 | Loss: 0.051 | Acc: 98.438% (126/128)\n",
      "Train Epoch: 43 | Loss: 0.079 | Acc: 97.266% (249/256)\n",
      "Train Epoch: 43 | Loss: 0.080 | Acc: 97.656% (375/384)\n",
      "Train Epoch: 43 | Loss: 0.088 | Acc: 97.070% (497/512)\n",
      "Train Epoch: 43 | Loss: 0.086 | Acc: 97.344% (623/640)\n",
      "Train Epoch: 43 | Loss: 0.084 | Acc: 97.396% (748/768)\n",
      "Train Epoch: 43 | Loss: 0.082 | Acc: 97.321% (872/896)\n",
      "Train Epoch: 43 | Loss: 0.083 | Acc: 97.168% (995/1024)\n",
      "Train Epoch: 43 | Loss: 0.079 | Acc: 97.396% (1122/1152)\n",
      "Train Epoch: 43 | Loss: 0.079 | Acc: 97.500% (1248/1280)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.656% (1375/1408)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.852% (1503/1536)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.957% (1630/1664)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.991% (1756/1792)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.969% (1881/1920)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.949% (2006/2048)\n",
      "Train Epoch: 43 | Loss: 0.068 | Acc: 97.886% (2130/2176)\n",
      "Train Epoch: 43 | Loss: 0.067 | Acc: 97.960% (2257/2304)\n",
      "Train Epoch: 43 | Loss: 0.068 | Acc: 97.903% (2381/2432)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.773% (2503/2560)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.768% (2628/2688)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.763% (2753/2816)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.724% (2877/2944)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.754% (3003/3072)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.750% (3128/3200)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.776% (3254/3328)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.743% (3378/3456)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.740% (3503/3584)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.764% (3629/3712)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.760% (3754/3840)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.782% (3880/3968)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.803% (4006/4096)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.846% (4133/4224)\n",
      "Train Epoch: 43 | Loss: 0.070 | Acc: 97.886% (4260/4352)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.924% (4387/4480)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.917% (4512/4608)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.952% (4639/4736)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.924% (4763/4864)\n",
      "Train Epoch: 43 | Loss: 0.068 | Acc: 97.937% (4889/4992)\n",
      "Train Epoch: 43 | Loss: 0.069 | Acc: 97.852% (5010/5120)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.771% (5131/5248)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.675% (5251/5376)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.693% (5377/5504)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.710% (5503/5632)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.708% (5628/5760)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.724% (5754/5888)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.706% (5878/6016)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.705% (6003/6144)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.672% (6126/6272)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.641% (6249/6400)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.595% (6371/6528)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.596% (6496/6656)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.553% (6618/6784)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.598% (6746/6912)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.642% (6874/7040)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.642% (6999/7168)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.643% (7124/7296)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.616% (7247/7424)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.617% (7372/7552)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.617% (7497/7680)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.631% (7623/7808)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.644% (7749/7936)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.631% (7873/8064)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.656% (8000/8192)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.584% (8119/8320)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.573% (8243/8448)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.575% (8368/8576)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.587% (8494/8704)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.577% (8618/8832)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.556% (8741/8960)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.546% (8865/9088)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.548% (8990/9216)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.539% (9114/9344)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.530% (9238/9472)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.562% (9366/9600)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.553% (9490/9728)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.585% (9618/9856)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.576% (9742/9984)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.567% (9866/10112)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.578% (9992/10240)\n",
      "Train Epoch: 43 | Loss: 0.071 | Acc: 97.569% (10116/10368)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.532% (10237/10496)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.534% (10362/10624)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.554% (10489/10752)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.555% (10614/10880)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.565% (10740/11008)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.557% (10864/11136)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.541% (10987/11264)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.560% (11114/11392)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.543% (11237/11520)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.553% (11363/11648)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.546% (11487/11776)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.555% (11613/11904)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.557% (11738/12032)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.549% (11862/12160)\n",
      "Train Epoch: 43 | Loss: 0.072 | Acc: 97.567% (11989/12288)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.568% (12114/12416)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.553% (12237/12544)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.554% (12362/12672)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.555% (12487/12800)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.540% (12610/12928)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.541% (12735/13056)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.527% (12858/13184)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.514% (12981/13312)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.522% (13107/13440)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.524% (13232/13568)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.539% (13359/13696)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.519% (13481/13824)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.520% (13606/13952)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.493% (13727/14080)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.487% (13851/14208)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.496% (13977/14336)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.497% (14102/14464)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.478% (14224/14592)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.466% (14347/14720)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.468% (14472/14848)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.476% (14598/14976)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.477% (14723/15104)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.492% (14850/15232)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.487% (14974/15360)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.469% (15096/15488)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.464% (15220/15616)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.478% (15347/15744)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.499% (15475/15872)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.500% (15600/16000)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.501% (15725/16128)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.502% (15850/16256)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.491% (15973/16384)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.499% (16099/16512)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.506% (16225/16640)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.519% (16352/16768)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.496% (16473/16896)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.492% (16597/17024)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.493% (16722/17152)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.494% (16847/17280)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.495% (16972/17408)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.485% (17095/17536)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.486% (17220/17664)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.482% (17344/17792)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.483% (17469/17920)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.490% (17595/18048)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.486% (17719/18176)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.476% (17842/18304)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.488% (17969/18432)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.484% (18093/18560)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.469% (18215/18688)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.481% (18342/18816)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.466% (18464/18944)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.473% (18590/19072)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.479% (18716/19200)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.496% (18844/19328)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.492% (18968/19456)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.493% (19093/19584)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.494% (19218/19712)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.485% (19341/19840)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.486% (19466/19968)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.487% (19591/20096)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.478% (19714/20224)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.479% (19839/20352)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.485% (19965/20480)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.496% (20092/20608)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.497% (20217/20736)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.508% (20344/20864)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.509% (20469/20992)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.519% (20596/21120)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.529% (20723/21248)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.539% (20850/21376)\n",
      "Train Epoch: 43 | Loss: 0.073 | Acc: 97.535% (20974/21504)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (21098/21632)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (21223/21760)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.496% (21340/21888)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.470% (21459/22016)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.453% (21580/22144)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.463% (21707/22272)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.469% (21833/22400)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.465% (21957/22528)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.462% (22081/22656)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.459% (22205/22784)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.451% (22328/22912)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.452% (22453/23040)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.466% (22581/23168)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.463% (22705/23296)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.464% (22830/23424)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.452% (22952/23552)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.454% (23077/23680)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.455% (23202/23808)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.456% (23327/23936)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.457% (23452/24064)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.458% (23577/24192)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.459% (23702/24320)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.464% (23828/24448)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.461% (23952/24576)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.450% (24074/24704)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.447% (24198/24832)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.444% (24322/24960)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.437% (24445/25088)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.438% (24570/25216)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.443% (24696/25344)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.444% (24821/25472)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.457% (24949/25600)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.450% (25072/25728)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.459% (25199/25856)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.464% (25325/25984)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.453% (25447/26112)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.458% (25573/26240)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.463% (25699/26368)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.460% (25823/26496)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.465% (25949/26624)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.462% (26073/26752)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.455% (26196/26880)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.453% (26320/27008)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.457% (26446/27136)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.469% (26574/27264)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.470% (26699/27392)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.471% (26824/27520)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.472% (26949/27648)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.483% (27077/27776)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.481% (27201/27904)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.489% (27328/28032)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.489% (27453/28160)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.494% (27579/28288)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.487% (27702/28416)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.488% (27827/28544)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.492% (27953/28672)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.483% (28075/28800)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.487% (28201/28928)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.484% (28325/29056)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.488% (28451/29184)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.492% (28577/29312)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.500% (28704/29440)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.501% (28829/29568)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.508% (28956/29696)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.509% (29081/29824)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.503% (29204/29952)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.503% (29329/30080)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.497% (29452/30208)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.491% (29575/30336)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.499% (29702/30464)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.493% (29825/30592)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.490% (29949/30720)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.491% (30074/30848)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.488% (30198/30976)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.489% (30323/31104)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.480% (30445/31232)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.481% (30570/31360)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.485% (30696/31488)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.495% (30824/31616)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.492% (30948/31744)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.487% (31071/31872)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.491% (31197/32000)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.482% (31319/32128)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.480% (31443/32256)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.490% (31571/32384)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.481% (31693/32512)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.479% (31817/32640)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.473% (31940/32768)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.471% (32064/32896)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.475% (32190/33024)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.469% (32313/33152)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.476% (32440/33280)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.480% (32566/33408)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.486% (32693/33536)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.493% (32820/33664)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.496% (32946/33792)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.500% (33072/33920)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (33200/34048)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.513% (33326/34176)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.516% (33452/34304)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.520% (33578/34432)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.523% (33704/34560)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.521% (33828/34688)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.527% (33955/34816)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.525% (34079/34944)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (34206/35072)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (34331/35200)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.529% (34455/35328)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.527% (34579/35456)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.516% (34700/35584)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.513% (34824/35712)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.517% (34950/35840)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.517% (35075/35968)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.515% (35199/36096)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.518% (35325/36224)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.524% (35452/36352)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.522% (35576/36480)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.528% (35703/36608)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.528% (35828/36736)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.534% (35955/36864)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (36079/36992)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (36204/37120)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.535% (36330/37248)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (36453/37376)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.536% (36580/37504)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.534% (36704/37632)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (36828/37760)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (36953/37888)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.530% (37077/38016)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.538% (37205/38144)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (37327/38272)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.536% (37454/38400)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (37577/38528)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.535% (37703/38656)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.538% (37829/38784)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.541% (37955/38912)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (38076/39040)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.534% (38202/39168)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.534% (38327/39296)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.522% (38447/39424)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.525% (38573/39552)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.533% (38701/39680)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.536% (38827/39808)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.536% (38952/39936)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (39075/40064)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.532% (39200/40192)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.530% (39324/40320)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.533% (39450/40448)\n",
      "Train Epoch: 43 | Loss: 0.074 | Acc: 97.531% (39574/40576)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.526% (39697/40704)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.526% (39822/40832)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.520% (39944/40960)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.518% (40068/41088)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.513% (40191/41216)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (40314/41344)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (40439/41472)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.512% (40565/41600)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.520% (40693/41728)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.518% (40817/41856)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.520% (40943/41984)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.523% (41069/42112)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.517% (41191/42240)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.517% (41316/42368)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.520% (41442/42496)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.515% (41565/42624)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.518% (41691/42752)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.514% (41814/42880)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.517% (41940/43008)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.519% (42066/43136)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.515% (42189/43264)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.518% (42315/43392)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.521% (42441/43520)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.523% (42567/43648)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.524% (42692/43776)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.529% (42819/43904)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.534% (42946/44032)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.532% (43070/44160)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.521% (43190/44288)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.508% (43309/44416)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.508% (43434/44544)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (43557/44672)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.507% (43683/44800)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (43809/44928)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.508% (43933/45056)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.506% (44057/45184)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.508% (44183/45312)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (44308/45440)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (44433/45568)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.512% (44559/45696)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.519% (44687/45824)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.515% (44810/45952)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.507% (44931/46080)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.511% (45058/46208)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (45182/46336)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.512% (45308/46464)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.506% (45430/46592)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.509% (45556/46720)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.511% (45682/46848)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.511% (45807/46976)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.512% (45932/47104)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.514% (46058/47232)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (46178/47360)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.507% (46304/47488)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.505% (46428/47616)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.505% (46553/47744)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (46677/47872)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.502% (46801/48000)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.500% (46925/48128)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.505% (47052/48256)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.505% (47177/48384)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.510% (47304/48512)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.502% (47425/48640)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.500% (47549/48768)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.501% (47674/48896)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.505% (47801/49024)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (47925/49152)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.496% (48046/49280)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.498% (48172/49408)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.493% (48294/49536)\n",
      "Train Epoch: 43 | Loss: 0.076 | Acc: 97.493% (48419/49664)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.498% (48546/49792)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (48674/49920)\n",
      "Train Epoch: 43 | Loss: 0.075 | Acc: 97.504% (48752/50000)\n",
      "Test Epoch: 43 | Loss: 0.242 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 43 | Loss: 0.312 | Acc: 90.000% (180/200)\n",
      "Test Epoch: 43 | Loss: 0.298 | Acc: 90.000% (270/300)\n",
      "Test Epoch: 43 | Loss: 0.275 | Acc: 90.750% (363/400)\n",
      "Test Epoch: 43 | Loss: 0.256 | Acc: 91.200% (456/500)\n",
      "Test Epoch: 43 | Loss: 0.228 | Acc: 92.167% (553/600)\n",
      "Test Epoch: 43 | Loss: 0.236 | Acc: 92.143% (645/700)\n",
      "Test Epoch: 43 | Loss: 0.279 | Acc: 91.125% (729/800)\n",
      "Test Epoch: 43 | Loss: 0.282 | Acc: 91.111% (820/900)\n",
      "Test Epoch: 43 | Loss: 0.278 | Acc: 91.200% (912/1000)\n",
      "Test Epoch: 43 | Loss: 0.283 | Acc: 91.000% (1001/1100)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 90.750% (1089/1200)\n",
      "Test Epoch: 43 | Loss: 0.295 | Acc: 91.000% (1183/1300)\n",
      "Test Epoch: 43 | Loss: 0.296 | Acc: 91.143% (1276/1400)\n",
      "Test Epoch: 43 | Loss: 0.296 | Acc: 91.133% (1367/1500)\n",
      "Test Epoch: 43 | Loss: 0.288 | Acc: 91.438% (1463/1600)\n",
      "Test Epoch: 43 | Loss: 0.294 | Acc: 91.471% (1555/1700)\n",
      "Test Epoch: 43 | Loss: 0.294 | Acc: 91.389% (1645/1800)\n",
      "Test Epoch: 43 | Loss: 0.297 | Acc: 91.368% (1736/1900)\n",
      "Test Epoch: 43 | Loss: 0.302 | Acc: 91.300% (1826/2000)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.190% (1915/2100)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.091% (2004/2200)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 91.000% (2093/2300)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.125% (2187/2400)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.200% (2280/2500)\n",
      "Test Epoch: 43 | Loss: 0.320 | Acc: 90.923% (2364/2600)\n",
      "Test Epoch: 43 | Loss: 0.319 | Acc: 90.963% (2456/2700)\n",
      "Test Epoch: 43 | Loss: 0.320 | Acc: 91.036% (2549/2800)\n",
      "Test Epoch: 43 | Loss: 0.319 | Acc: 91.000% (2639/2900)\n",
      "Test Epoch: 43 | Loss: 0.317 | Acc: 91.000% (2730/3000)\n",
      "Test Epoch: 43 | Loss: 0.318 | Acc: 91.000% (2821/3100)\n",
      "Test Epoch: 43 | Loss: 0.313 | Acc: 91.062% (2914/3200)\n",
      "Test Epoch: 43 | Loss: 0.311 | Acc: 91.030% (3004/3300)\n",
      "Test Epoch: 43 | Loss: 0.311 | Acc: 91.059% (3096/3400)\n",
      "Test Epoch: 43 | Loss: 0.314 | Acc: 90.971% (3184/3500)\n",
      "Test Epoch: 43 | Loss: 0.314 | Acc: 91.056% (3278/3600)\n",
      "Test Epoch: 43 | Loss: 0.318 | Acc: 91.000% (3367/3700)\n",
      "Test Epoch: 43 | Loss: 0.319 | Acc: 91.000% (3458/3800)\n",
      "Test Epoch: 43 | Loss: 0.315 | Acc: 91.128% (3554/3900)\n",
      "Test Epoch: 43 | Loss: 0.312 | Acc: 91.200% (3648/4000)\n",
      "Test Epoch: 43 | Loss: 0.315 | Acc: 91.122% (3736/4100)\n",
      "Test Epoch: 43 | Loss: 0.318 | Acc: 91.119% (3827/4200)\n",
      "Test Epoch: 43 | Loss: 0.315 | Acc: 91.186% (3921/4300)\n",
      "Test Epoch: 43 | Loss: 0.312 | Acc: 91.273% (4016/4400)\n",
      "Test Epoch: 43 | Loss: 0.308 | Acc: 91.311% (4109/4500)\n",
      "Test Epoch: 43 | Loss: 0.310 | Acc: 91.239% (4197/4600)\n",
      "Test Epoch: 43 | Loss: 0.308 | Acc: 91.255% (4289/4700)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 91.229% (4379/4800)\n",
      "Test Epoch: 43 | Loss: 0.308 | Acc: 91.306% (4474/4900)\n",
      "Test Epoch: 43 | Loss: 0.313 | Acc: 91.220% (4561/5000)\n",
      "Test Epoch: 43 | Loss: 0.311 | Acc: 91.235% (4653/5100)\n",
      "Test Epoch: 43 | Loss: 0.312 | Acc: 91.135% (4739/5200)\n",
      "Test Epoch: 43 | Loss: 0.312 | Acc: 91.094% (4828/5300)\n",
      "Test Epoch: 43 | Loss: 0.310 | Acc: 91.130% (4921/5400)\n",
      "Test Epoch: 43 | Loss: 0.310 | Acc: 91.109% (5011/5500)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 91.125% (5103/5600)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.228% (5200/5700)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.207% (5290/5800)\n",
      "Test Epoch: 43 | Loss: 0.310 | Acc: 91.186% (5380/5900)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.250% (5475/6000)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.246% (5566/6100)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 91.242% (5657/6200)\n",
      "Test Epoch: 43 | Loss: 0.309 | Acc: 91.270% (5750/6300)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.359% (5847/6400)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.354% (5938/6500)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.424% (6034/6600)\n",
      "Test Epoch: 43 | Loss: 0.303 | Acc: 91.418% (6125/6700)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.368% (6213/6800)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.420% (6308/6900)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.400% (6398/7000)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.352% (6486/7100)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.347% (6577/7200)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.370% (6670/7300)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.405% (6764/7400)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.400% (6855/7500)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.408% (6947/7600)\n",
      "Test Epoch: 43 | Loss: 0.308 | Acc: 91.403% (7038/7700)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.410% (7130/7800)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.443% (7224/7900)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.450% (7316/8000)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.494% (7411/8100)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.402% (7495/8200)\n",
      "Test Epoch: 43 | Loss: 0.303 | Acc: 91.470% (7592/8300)\n",
      "Test Epoch: 43 | Loss: 0.303 | Acc: 91.464% (7683/8400)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.447% (7773/8500)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.419% (7862/8600)\n",
      "Test Epoch: 43 | Loss: 0.303 | Acc: 91.448% (7956/8700)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.386% (8042/8800)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.360% (8131/8900)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.344% (8221/9000)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.396% (8317/9100)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.402% (8409/9200)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.409% (8501/9300)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.394% (8591/9400)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.368% (8680/9500)\n",
      "Test Epoch: 43 | Loss: 0.307 | Acc: 91.375% (8772/9600)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.412% (8867/9700)\n",
      "Test Epoch: 43 | Loss: 0.304 | Acc: 91.439% (8961/9800)\n",
      "Test Epoch: 43 | Loss: 0.305 | Acc: 91.414% (9050/9900)\n",
      "Test Epoch: 43 | Loss: 0.306 | Acc: 91.410% (9141/10000)\n",
      "\n",
      "Epoch: 44\n",
      "Train Epoch: 44 | Loss: 0.048 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 44 | Loss: 0.047 | Acc: 98.828% (253/256)\n",
      "Train Epoch: 44 | Loss: 0.048 | Acc: 98.438% (378/384)\n",
      "Train Epoch: 44 | Loss: 0.047 | Acc: 98.633% (505/512)\n",
      "Train Epoch: 44 | Loss: 0.050 | Acc: 98.438% (630/640)\n",
      "Train Epoch: 44 | Loss: 0.051 | Acc: 98.307% (755/768)\n",
      "Train Epoch: 44 | Loss: 0.059 | Acc: 97.879% (877/896)\n",
      "Train Epoch: 44 | Loss: 0.060 | Acc: 97.949% (1003/1024)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.743% (1126/1152)\n",
      "Train Epoch: 44 | Loss: 0.061 | Acc: 97.969% (1254/1280)\n",
      "Train Epoch: 44 | Loss: 0.060 | Acc: 98.082% (1381/1408)\n",
      "Train Epoch: 44 | Loss: 0.062 | Acc: 97.982% (1505/1536)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.897% (1629/1664)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.824% (1753/1792)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.865% (1879/1920)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.852% (2004/2048)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.794% (2128/2176)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.917% (2256/2304)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.944% (2382/2432)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.930% (2507/2560)\n",
      "Train Epoch: 44 | Loss: 0.062 | Acc: 98.028% (2635/2688)\n",
      "Train Epoch: 44 | Loss: 0.063 | Acc: 97.940% (2758/2816)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.894% (2882/2944)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.949% (3009/3072)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.969% (3135/3200)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.867% (3257/3328)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.830% (3381/3456)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.879% (3508/3584)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.926% (3635/3712)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.891% (3759/3840)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.908% (3885/3968)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.876% (4009/4096)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.893% (4135/4224)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.863% (4259/4352)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.902% (4386/4480)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.895% (4511/4608)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.910% (4637/4736)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.882% (4761/4864)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.917% (4888/4992)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.930% (5014/5120)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.923% (5139/5248)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.879% (5262/5376)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.929% (5390/5504)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.958% (5517/5632)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.934% (5641/5760)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.894% (5764/5888)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.922% (5891/6016)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.949% (6018/6144)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.895% (6140/6272)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.938% (6268/6400)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.963% (6395/6528)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.957% (6520/6656)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.981% (6647/6784)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.917% (6768/6912)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.898% (6892/7040)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.921% (7019/7168)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.903% (7143/7296)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.885% (7267/7424)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.868% (7391/7552)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.878% (7517/7680)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.861% (7641/7808)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.845% (7765/7936)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.805% (7887/8064)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.827% (8014/8192)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.849% (8141/8320)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.881% (8269/8448)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.854% (8392/8576)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.840% (8516/8704)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.849% (8642/8832)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.846% (8767/8960)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.854% (8893/9088)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.873% (9020/9216)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.892% (9147/9344)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.910% (9274/9472)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.917% (9400/9600)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.893% (9523/9728)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.910% (9650/9856)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.917% (9776/9984)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.923% (9902/10112)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.939% (10029/10240)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.936% (10154/10368)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.923% (10278/10496)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.939% (10405/10624)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.945% (10531/10752)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.923% (10654/10880)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.938% (10781/11008)\n",
      "Train Epoch: 44 | Loss: 0.064 | Acc: 97.953% (10908/11136)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.940% (11032/11264)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.946% (11158/11392)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.960% (11285/11520)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.940% (11408/11648)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.945% (11534/11776)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.942% (11659/11904)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.939% (11784/12032)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.911% (11906/12160)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.917% (12032/12288)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.906% (12156/12416)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.887% (12279/12544)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.885% (12404/12672)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.898% (12531/12800)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.904% (12657/12928)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.894% (12781/13056)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.907% (12908/13184)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.904% (13033/13312)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.902% (13158/13440)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.907% (13284/13568)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.926% (13412/13696)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.946% (13540/13824)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.957% (13667/13952)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.940% (13790/14080)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.938% (13915/14208)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.921% (14038/14336)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.933% (14165/14464)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.937% (14291/14592)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.948% (14418/14720)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.939% (14542/14848)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.923% (14665/14976)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.934% (14792/15104)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.925% (14916/15232)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.923% (15041/15360)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.934% (15168/15488)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.932% (15293/15616)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.942% (15420/15744)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.940% (15545/15872)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.950% (15672/16000)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.966% (15800/16128)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.970% (15926/16256)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.974% (16052/16384)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.977% (16178/16512)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.987% (16305/16640)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.996% (16432/16768)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 98.000% (16558/16896)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.985% (16681/17024)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.989% (16807/17152)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.986% (16932/17280)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.978% (17056/17408)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.993% (17184/17536)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 98.002% (17311/17664)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.977% (17432/17792)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.969% (17556/17920)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.972% (17682/18048)\n",
      "Train Epoch: 44 | Loss: 0.065 | Acc: 97.975% (17808/18176)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.962% (17931/18304)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.965% (18057/18432)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.942% (18178/18560)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.945% (18304/18688)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.949% (18430/18816)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.957% (18557/18944)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.955% (18682/19072)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.948% (18806/19200)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.946% (18931/19328)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.949% (19057/19456)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.958% (19184/19584)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.956% (19309/19712)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.969% (19437/19840)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.957% (19560/19968)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.945% (19683/20096)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.958% (19811/20224)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.961% (19937/20352)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.954% (20061/20480)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.952% (20186/20608)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.946% (20310/20736)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.949% (20436/20864)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.956% (20563/20992)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.950% (20687/21120)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.948% (20812/21248)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.956% (20939/21376)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.959% (21065/21504)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.952% (21189/21632)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.964% (21317/21760)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.962% (21442/21888)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.951% (21565/22016)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.954% (21691/22144)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.962% (21818/22272)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.951% (21941/22400)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.954% (22067/22528)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.952% (22192/22656)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.955% (22318/22784)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.944% (22441/22912)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.943% (22566/23040)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.920% (22686/23168)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.931% (22814/23296)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.938% (22941/23424)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.915% (23061/23552)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.918% (23187/23680)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.917% (23312/23808)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.915% (23437/23936)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.914% (23562/24064)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.908% (23686/24192)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.911% (23812/24320)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.914% (23938/24448)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.921% (24065/24576)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.923% (24191/24704)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.926% (24317/24832)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.905% (24437/24960)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.907% (24563/25088)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.906% (24688/25216)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.901% (24812/25344)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.900% (24937/25472)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.906% (25064/25600)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.901% (25188/25728)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.900% (25313/25856)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.895% (25437/25984)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.890% (25561/26112)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.893% (25687/26240)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.899% (25814/26368)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.902% (25940/26496)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.897% (26064/26624)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.895% (26189/26752)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.894% (26314/26880)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.890% (26438/27008)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.892% (26564/27136)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.891% (26689/27264)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.879% (26811/27392)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.867% (26933/27520)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.877% (27061/27648)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.887% (27189/27776)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.886% (27314/27904)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.892% (27441/28032)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.901% (27569/28160)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.882% (27689/28288)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.881% (27814/28416)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.884% (27940/28544)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.883% (28065/28672)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.889% (28192/28800)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.891% (28318/28928)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.897% (28445/29056)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.900% (28571/29184)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.905% (28698/29312)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.908% (28824/29440)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.910% (28950/29568)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.912% (29076/29696)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.914% (29202/29824)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.913% (29327/29952)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.912% (29452/30080)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.911% (29577/30208)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.917% (29704/30336)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.909% (29827/30464)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.905% (29951/30592)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.907% (30077/30720)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.912% (30204/30848)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.915% (30330/30976)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.910% (30454/31104)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.903% (30577/31232)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.899% (30701/31360)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.894% (30825/31488)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.897% (30951/31616)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.896% (31076/31744)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.898% (31202/31872)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.900% (31328/32000)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.890% (31450/32128)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.889% (31575/32256)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.891% (31701/32384)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.893% (31827/32512)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.898% (31954/32640)\n",
      "Train Epoch: 44 | Loss: 0.066 | Acc: 97.900% (32080/32768)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.890% (32202/32896)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.895% (32329/33024)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.889% (32452/33152)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.882% (32575/33280)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.878% (32699/33408)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.877% (32824/33536)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.873% (32948/33664)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.863% (33070/33792)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.866% (33196/33920)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.862% (33320/34048)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.861% (33445/34176)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.854% (33568/34304)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.854% (33693/34432)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.856% (33819/34560)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.852% (33943/34688)\n",
      "Train Epoch: 44 | Loss: 0.067 | Acc: 97.857% (34070/34816)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.839% (34189/34944)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.830% (34311/35072)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.835% (34438/35200)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.829% (34561/35328)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.831% (34687/35456)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.819% (34808/35584)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.810% (34930/35712)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.807% (35054/35840)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.804% (35178/35968)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.800% (35302/36096)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.803% (35428/36224)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.808% (35555/36352)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.804% (35679/36480)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.809% (35806/36608)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.811% (35932/36736)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.811% (36057/36864)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.805% (36180/36992)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.807% (36306/37120)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.804% (36430/37248)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.798% (36553/37376)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.798% (36678/37504)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.794% (36802/37632)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.799% (36929/37760)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.799% (37054/37888)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.798% (37179/38016)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.782% (37298/38144)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.782% (37423/38272)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.776% (37546/38400)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.778% (37672/38528)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.778% (37797/38656)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.785% (37925/38784)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.774% (38046/38912)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.777% (38172/39040)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.771% (38295/39168)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.771% (38420/39296)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.773% (38546/39424)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.773% (38671/39552)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.775% (38797/39680)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.779% (38924/39808)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.781% (39050/39936)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.781% (39175/40064)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.783% (39301/40192)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.778% (39424/40320)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.785% (39552/40448)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.792% (39680/40576)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.782% (39801/40704)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.784% (39927/40832)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.786% (40053/40960)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.785% (40178/41088)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.787% (40304/41216)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.782% (40427/41344)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.782% (40552/41472)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.779% (40676/41600)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.774% (40799/41728)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.773% (40924/41856)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.773% (41049/41984)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.775% (41175/42112)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.772% (41299/42240)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.774% (41425/42368)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.774% (41550/42496)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.778% (41677/42624)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.773% (41800/42752)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.768% (41923/42880)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.768% (42048/43008)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.765% (42172/43136)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.767% (42298/43264)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.769% (42424/43392)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.767% (42548/43520)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.762% (42671/43648)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.761% (42796/43776)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.759% (42920/43904)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.758% (43045/44032)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.754% (43168/44160)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.753% (43293/44288)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.753% (43418/44416)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.751% (43542/44544)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.753% (43668/44672)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (43790/44800)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.745% (43915/44928)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.738% (44037/45056)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.731% (44159/45184)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.733% (44285/45312)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.735% (44411/45440)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.731% (44534/45568)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.733% (44660/45696)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.728% (44783/45824)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.730% (44909/45952)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.730% (45034/46080)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.730% (45159/46208)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.730% (45284/46336)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.729% (45409/46464)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.736% (45537/46592)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.742% (45665/46720)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (45792/46848)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (45917/46976)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.745% (46042/47104)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.739% (46164/47232)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.743% (46291/47360)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.743% (46416/47488)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.744% (46542/47616)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.742% (46666/47744)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (46793/47872)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.744% (46917/48000)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.737% (47039/48128)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.737% (47164/48256)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.741% (47291/48384)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.745% (47418/48512)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.749% (47545/48640)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.749% (47670/48768)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.742% (47792/48896)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (47919/49024)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.744% (48043/49152)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (48169/49280)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.745% (48294/49408)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.743% (48418/49536)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.743% (48543/49664)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.743% (48668/49792)\n",
      "Train Epoch: 44 | Loss: 0.069 | Acc: 97.746% (48795/49920)\n",
      "Train Epoch: 44 | Loss: 0.068 | Acc: 97.750% (48875/50000)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 93.000% (93/100)\n",
      "Test Epoch: 44 | Loss: 0.330 | Acc: 92.500% (185/200)\n",
      "Test Epoch: 44 | Loss: 0.333 | Acc: 92.333% (277/300)\n",
      "Test Epoch: 44 | Loss: 0.316 | Acc: 92.250% (369/400)\n",
      "Test Epoch: 44 | Loss: 0.292 | Acc: 92.800% (464/500)\n",
      "Test Epoch: 44 | Loss: 0.258 | Acc: 93.167% (559/600)\n",
      "Test Epoch: 44 | Loss: 0.258 | Acc: 93.000% (651/700)\n",
      "Test Epoch: 44 | Loss: 0.276 | Acc: 92.625% (741/800)\n",
      "Test Epoch: 44 | Loss: 0.280 | Acc: 92.333% (831/900)\n",
      "Test Epoch: 44 | Loss: 0.280 | Acc: 92.200% (922/1000)\n",
      "Test Epoch: 44 | Loss: 0.284 | Acc: 92.091% (1013/1100)\n",
      "Test Epoch: 44 | Loss: 0.294 | Acc: 92.000% (1104/1200)\n",
      "Test Epoch: 44 | Loss: 0.286 | Acc: 92.231% (1199/1300)\n",
      "Test Epoch: 44 | Loss: 0.277 | Acc: 92.357% (1293/1400)\n",
      "Test Epoch: 44 | Loss: 0.281 | Acc: 92.467% (1387/1500)\n",
      "Test Epoch: 44 | Loss: 0.270 | Acc: 92.875% (1486/1600)\n",
      "Test Epoch: 44 | Loss: 0.272 | Acc: 92.941% (1580/1700)\n",
      "Test Epoch: 44 | Loss: 0.273 | Acc: 92.833% (1671/1800)\n",
      "Test Epoch: 44 | Loss: 0.275 | Acc: 92.684% (1761/1900)\n",
      "Test Epoch: 44 | Loss: 0.284 | Acc: 92.600% (1852/2000)\n",
      "Test Epoch: 44 | Loss: 0.289 | Acc: 92.238% (1937/2100)\n",
      "Test Epoch: 44 | Loss: 0.290 | Acc: 92.136% (2027/2200)\n",
      "Test Epoch: 44 | Loss: 0.292 | Acc: 92.087% (2118/2300)\n",
      "Test Epoch: 44 | Loss: 0.288 | Acc: 92.083% (2210/2400)\n",
      "Test Epoch: 44 | Loss: 0.293 | Acc: 92.080% (2302/2500)\n",
      "Test Epoch: 44 | Loss: 0.304 | Acc: 91.885% (2389/2600)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 92.000% (2484/2700)\n",
      "Test Epoch: 44 | Loss: 0.303 | Acc: 91.893% (2573/2800)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.966% (2667/2900)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 92.000% (2760/3000)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.935% (2850/3100)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.938% (2942/3200)\n",
      "Test Epoch: 44 | Loss: 0.294 | Acc: 91.970% (3035/3300)\n",
      "Test Epoch: 44 | Loss: 0.293 | Acc: 91.971% (3127/3400)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 91.886% (3216/3500)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 92.000% (3312/3600)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.892% (3400/3700)\n",
      "Test Epoch: 44 | Loss: 0.302 | Acc: 91.842% (3490/3800)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.897% (3584/3900)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.900% (3676/4000)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.902% (3768/4100)\n",
      "Test Epoch: 44 | Loss: 0.303 | Acc: 91.833% (3857/4200)\n",
      "Test Epoch: 44 | Loss: 0.302 | Acc: 91.930% (3953/4300)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 92.045% (4050/4400)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 92.089% (4144/4500)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 92.022% (4233/4600)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 92.000% (4324/4700)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.875% (4410/4800)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.898% (4503/4900)\n",
      "Test Epoch: 44 | Loss: 0.303 | Acc: 91.840% (4592/5000)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.882% (4686/5100)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.769% (4772/5200)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.792% (4865/5300)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.852% (4960/5400)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.800% (5049/5500)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.839% (5143/5600)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.860% (5236/5700)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.879% (5329/5800)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.847% (5419/5900)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.900% (5514/6000)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.918% (5607/6100)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.871% (5696/6200)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.857% (5787/6300)\n",
      "Test Epoch: 44 | Loss: 0.294 | Acc: 91.906% (5882/6400)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 91.877% (5972/6500)\n",
      "Test Epoch: 44 | Loss: 0.293 | Acc: 91.879% (6064/6600)\n",
      "Test Epoch: 44 | Loss: 0.292 | Acc: 91.896% (6157/6700)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 91.824% (6244/6800)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 91.855% (6338/6900)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.786% (6425/7000)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.732% (6513/7100)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.736% (6605/7200)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.767% (6699/7300)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.811% (6794/7400)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.813% (6886/7500)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.803% (6977/7600)\n",
      "Test Epoch: 44 | Loss: 0.301 | Acc: 91.779% (7067/7700)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.808% (7161/7800)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.835% (7255/7900)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.850% (7348/8000)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.889% (7443/8100)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.902% (7536/8200)\n",
      "Test Epoch: 44 | Loss: 0.295 | Acc: 91.940% (7631/8300)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.917% (7721/8400)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.871% (7809/8500)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.849% (7899/8600)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.851% (7991/8700)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.841% (8082/8800)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.843% (8174/8900)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.789% (8261/9000)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.824% (8356/9100)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.848% (8450/9200)\n",
      "Test Epoch: 44 | Loss: 0.299 | Acc: 91.828% (8540/9300)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.819% (8631/9400)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.811% (8722/9500)\n",
      "Test Epoch: 44 | Loss: 0.300 | Acc: 91.823% (8815/9600)\n",
      "Test Epoch: 44 | Loss: 0.297 | Acc: 91.887% (8913/9700)\n",
      "Test Epoch: 44 | Loss: 0.296 | Acc: 91.939% (9010/9800)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.848% (9093/9900)\n",
      "Test Epoch: 44 | Loss: 0.298 | Acc: 91.840% (9184/10000)\n",
      "\n",
      "Epoch: 45\n",
      "Train Epoch: 45 | Loss: 0.103 | Acc: 96.875% (124/128)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 98.438% (252/256)\n",
      "Train Epoch: 45 | Loss: 0.082 | Acc: 97.917% (376/384)\n",
      "Train Epoch: 45 | Loss: 0.076 | Acc: 97.852% (501/512)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.656% (625/640)\n",
      "Train Epoch: 45 | Loss: 0.084 | Acc: 97.526% (749/768)\n",
      "Train Epoch: 45 | Loss: 0.076 | Acc: 97.656% (875/896)\n",
      "Train Epoch: 45 | Loss: 0.079 | Acc: 97.656% (1000/1024)\n",
      "Train Epoch: 45 | Loss: 0.078 | Acc: 97.656% (1125/1152)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.734% (1251/1280)\n",
      "Train Epoch: 45 | Loss: 0.082 | Acc: 97.585% (1374/1408)\n",
      "Train Epoch: 45 | Loss: 0.081 | Acc: 97.526% (1498/1536)\n",
      "Train Epoch: 45 | Loss: 0.080 | Acc: 97.536% (1623/1664)\n",
      "Train Epoch: 45 | Loss: 0.078 | Acc: 97.600% (1749/1792)\n",
      "Train Epoch: 45 | Loss: 0.076 | Acc: 97.604% (1874/1920)\n",
      "Train Epoch: 45 | Loss: 0.082 | Acc: 97.559% (1998/2048)\n",
      "Train Epoch: 45 | Loss: 0.080 | Acc: 97.656% (2125/2176)\n",
      "Train Epoch: 45 | Loss: 0.078 | Acc: 97.700% (2251/2304)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.656% (2375/2432)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.656% (2500/2560)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.619% (2624/2688)\n",
      "Train Epoch: 45 | Loss: 0.077 | Acc: 97.585% (2748/2816)\n",
      "Train Epoch: 45 | Loss: 0.076 | Acc: 97.588% (2873/2944)\n",
      "Train Epoch: 45 | Loss: 0.075 | Acc: 97.656% (3000/3072)\n",
      "Train Epoch: 45 | Loss: 0.073 | Acc: 97.719% (3127/3200)\n",
      "Train Epoch: 45 | Loss: 0.073 | Acc: 97.686% (3251/3328)\n",
      "Train Epoch: 45 | Loss: 0.074 | Acc: 97.656% (3375/3456)\n",
      "Train Epoch: 45 | Loss: 0.072 | Acc: 97.712% (3502/3584)\n",
      "Train Epoch: 45 | Loss: 0.072 | Acc: 97.710% (3627/3712)\n",
      "Train Epoch: 45 | Loss: 0.072 | Acc: 97.656% (3750/3840)\n",
      "Train Epoch: 45 | Loss: 0.072 | Acc: 97.631% (3874/3968)\n",
      "Train Epoch: 45 | Loss: 0.071 | Acc: 97.681% (4001/4096)\n",
      "Train Epoch: 45 | Loss: 0.071 | Acc: 97.727% (4128/4224)\n",
      "Train Epoch: 45 | Loss: 0.070 | Acc: 97.725% (4253/4352)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.790% (4381/4480)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.786% (4506/4608)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.804% (4632/4736)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.759% (4755/4864)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.716% (4878/4992)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.715% (5003/5120)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.713% (5128/5248)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.675% (5251/5376)\n",
      "Train Epoch: 45 | Loss: 0.070 | Acc: 97.674% (5376/5504)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.710% (5503/5632)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.691% (5627/5760)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.690% (5752/5888)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.656% (5875/6016)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.673% (6001/6144)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.704% (6128/6272)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.719% (6254/6400)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.733% (6380/6528)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.731% (6505/6656)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.745% (6631/6784)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.729% (6755/6912)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.741% (6881/7040)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.740% (7006/7168)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.725% (7130/7296)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.724% (7255/7424)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.749% (7382/7552)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.721% (7505/7680)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.720% (7630/7808)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.719% (7755/7936)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.718% (7880/8064)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.693% (8003/8192)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.716% (8130/8320)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.668% (8251/8448)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.656% (8375/8576)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.668% (8501/8704)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.679% (8627/8832)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.667% (8751/8960)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.667% (8876/9088)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.689% (9003/9216)\n",
      "Train Epoch: 45 | Loss: 0.070 | Acc: 97.667% (9126/9344)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.698% (9254/9472)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.708% (9380/9600)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.718% (9506/9728)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.717% (9631/9856)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.696% (9754/9984)\n",
      "Train Epoch: 45 | Loss: 0.069 | Acc: 97.716% (9881/10112)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.715% (10006/10240)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.743% (10134/10368)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.761% (10261/10496)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.760% (10386/10624)\n",
      "Train Epoch: 45 | Loss: 0.068 | Acc: 97.749% (10510/10752)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.757% (10636/10880)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.747% (10760/11008)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.764% (10887/11136)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.781% (11014/11264)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.797% (11141/11392)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.804% (11267/11520)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.802% (11392/11648)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.801% (11517/11776)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (11645/11904)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (11771/12032)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.829% (11896/12160)\n",
      "Train Epoch: 45 | Loss: 0.067 | Acc: 97.835% (12022/12288)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.841% (12148/12416)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.856% (12275/12544)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.869% (12402/12672)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.867% (12527/12800)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.865% (12652/12928)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.863% (12777/13056)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.853% (12901/13184)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.859% (13027/13312)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.865% (13153/13440)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.863% (13278/13568)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.868% (13404/13696)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.873% (13530/13824)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.893% (13658/13952)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.876% (13781/14080)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.881% (13907/14208)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.879% (14032/14336)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.850% (14153/14464)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.841% (14277/14592)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.846% (14403/14720)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.852% (14529/14848)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.857% (14655/14976)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (14781/15104)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.840% (14903/15232)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.845% (15029/15360)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.856% (15156/15488)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (15282/15616)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.853% (15406/15744)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.858% (15532/15872)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.869% (15659/16000)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.879% (15786/16128)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.878% (15911/16256)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.882% (16037/16384)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.880% (16162/16512)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.873% (16286/16640)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.883% (16413/16768)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.875% (16537/16896)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.879% (16663/17024)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.884% (16789/17152)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.888% (16915/17280)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.875% (17038/17408)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.873% (17163/17536)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.849% (17284/17664)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.859% (17411/17792)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.868% (17538/17920)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.867% (17663/18048)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.860% (17787/18176)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.853% (17911/18304)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.857% (18037/18432)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (18163/18560)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.849% (18286/18688)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (18407/18816)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (18534/18944)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.845% (18661/19072)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.844% (18786/19200)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.853% (18913/19328)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.857% (19039/19456)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.866% (19166/19584)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.869% (19292/19712)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.878% (19419/19840)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.872% (19543/19968)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.870% (19668/20096)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.874% (19794/20224)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.877% (19920/20352)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.891% (20048/20480)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.884% (20172/20608)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.868% (20294/20736)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.872% (20420/20864)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.885% (20548/20992)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.884% (20673/21120)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.873% (20796/21248)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.881% (20923/21376)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.893% (21051/21504)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.883% (21174/21632)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.895% (21302/21760)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.885% (21425/21888)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.870% (21547/22016)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.882% (21675/22144)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.885% (21801/22272)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.875% (21924/22400)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.869% (22048/22528)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.881% (22176/22656)\n",
      "Train Epoch: 45 | Loss: 0.064 | Acc: 97.889% (22303/22784)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.883% (22427/22912)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.869% (22549/23040)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.855% (22671/23168)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.849% (22795/23296)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.853% (22921/23424)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.856% (23047/23552)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.859% (23173/23680)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.849% (23296/23808)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (23424/23936)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.860% (23549/24064)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.859% (23674/24192)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.854% (23798/24320)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (23925/24448)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.852% (24048/24576)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.855% (24174/24704)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.866% (24302/24832)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.869% (24428/24960)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.868% (24553/25088)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.855% (24675/25216)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.846% (24798/25344)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.856% (24926/25472)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.863% (25053/25600)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.862% (25178/25728)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.853% (25301/25856)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.856% (25427/25984)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.863% (25554/26112)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.870% (25681/26240)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.861% (25804/26368)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.860% (25929/26496)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.859% (26054/26624)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.866% (26181/26752)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.857% (26304/26880)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.852% (26428/27008)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.844% (26551/27136)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.840% (26675/27264)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.842% (26801/27392)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.838% (26925/27520)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.830% (27048/27648)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.829% (27173/27776)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.825% (27297/27904)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (27424/28032)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.837% (27551/28160)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (27675/28288)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (27801/28416)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (27922/28544)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (28049/28672)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.823% (28173/28800)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (28299/28928)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (28426/29056)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (28549/29184)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (28675/29312)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (28800/29440)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.812% (28921/29568)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (29049/29696)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (29175/29824)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.823% (29300/29952)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (29426/30080)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (29553/30208)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.828% (29677/30336)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (29805/30464)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.839% (29931/30592)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.848% (30059/30720)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.848% (30184/30848)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.856% (30312/30976)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.856% (30437/31104)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.855% (30562/31232)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.854% (30687/31360)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.850% (30811/31488)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.846% (30935/31616)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.845% (31060/31744)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.845% (31185/31872)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.841% (31309/32000)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.840% (31434/32128)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.848% (31562/32256)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.854% (31689/32384)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.850% (31813/32512)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.849% (31938/32640)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.855% (32065/32768)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.854% (32190/32896)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.853% (32315/33024)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.852% (32440/33152)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.855% (32566/33280)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.860% (32693/33408)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.853% (32816/33536)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.855% (32942/33664)\n",
      "Train Epoch: 45 | Loss: 0.065 | Acc: 97.855% (33067/33792)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.854% (33192/33920)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.844% (33314/34048)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.838% (33437/34176)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.828% (33559/34304)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (33685/34432)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (33810/34560)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.818% (33931/34688)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (34059/34816)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.828% (34185/34944)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (34313/35072)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (34438/35200)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (34564/35328)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.842% (34691/35456)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (34813/35584)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (34937/35712)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (35064/35840)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.840% (35191/35968)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.839% (35316/36096)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (35438/36224)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (35562/36352)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (35685/36480)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.817% (35809/36608)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.825% (35937/36736)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (36065/36864)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.829% (36189/36992)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (36315/37120)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.825% (36438/37248)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.822% (36562/37376)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.822% (36687/37504)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (36812/37632)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (36939/37760)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.825% (37064/37888)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (37191/38016)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (37315/38144)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (37443/38272)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (37567/38400)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (37693/38528)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (37818/38656)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (37943/38784)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (38070/38912)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.838% (38196/39040)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (38320/39168)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.822% (38440/39296)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (38566/39424)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.823% (38691/39552)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (38815/39680)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (38940/39808)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (39067/39936)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (39195/40064)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (39321/40192)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (39446/40320)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (39572/40448)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (39697/40576)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (39823/40704)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (39946/40832)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (40071/40960)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (40195/41088)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.829% (40321/41216)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (40447/41344)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (40571/41472)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (40693/41600)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.819% (40818/41728)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.819% (40943/41856)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.816% (41067/41984)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.815% (41192/42112)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (41319/42240)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.814% (41442/42368)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.814% (41567/42496)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.816% (41693/42624)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.818% (41819/42752)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.817% (41944/42880)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.819% (42070/43008)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (42196/43136)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.823% (42322/43264)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.824% (42448/43392)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (42574/43520)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.826% (42699/43648)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.825% (42824/43776)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (42950/43904)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (43077/44032)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (43203/44160)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (43330/44288)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (43454/44416)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.829% (43577/44544)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.829% (43702/44672)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (43829/44800)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (43954/44928)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (44080/45056)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (44205/45184)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (44332/45312)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (44456/45440)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (44581/45568)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (44706/45696)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (44830/45824)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.830% (44955/45952)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (45082/46080)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.827% (45204/46208)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.831% (45331/46336)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (45458/46464)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.841% (45586/46592)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.838% (45710/46720)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (45834/46848)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (45959/46976)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (46084/47104)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (46210/47232)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.836% (46335/47360)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (46461/47488)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.839% (46587/47616)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.834% (46710/47744)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (46834/47872)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.833% (46960/48000)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.835% (47086/48128)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.837% (47212/48256)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.832% (47335/48384)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.817% (47453/48512)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.821% (47580/48640)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (47705/48768)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.818% (47829/48896)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.817% (47954/49024)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.817% (48079/49152)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.819% (48205/49280)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.820% (48331/49408)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.818% (48455/49536)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.813% (48578/49664)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.815% (48704/49792)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.815% (48829/49920)\n",
      "Train Epoch: 45 | Loss: 0.066 | Acc: 97.814% (48907/50000)\n",
      "Test Epoch: 45 | Loss: 0.357 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 45 | Loss: 0.384 | Acc: 91.000% (182/200)\n",
      "Test Epoch: 45 | Loss: 0.352 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 45 | Loss: 0.302 | Acc: 92.250% (369/400)\n",
      "Test Epoch: 45 | Loss: 0.289 | Acc: 92.600% (463/500)\n",
      "Test Epoch: 45 | Loss: 0.258 | Acc: 93.333% (560/600)\n",
      "Test Epoch: 45 | Loss: 0.255 | Acc: 93.143% (652/700)\n",
      "Test Epoch: 45 | Loss: 0.278 | Acc: 92.625% (741/800)\n",
      "Test Epoch: 45 | Loss: 0.280 | Acc: 92.556% (833/900)\n",
      "Test Epoch: 45 | Loss: 0.275 | Acc: 92.500% (925/1000)\n",
      "Test Epoch: 45 | Loss: 0.275 | Acc: 92.455% (1017/1100)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 92.083% (1105/1200)\n",
      "Test Epoch: 45 | Loss: 0.285 | Acc: 92.308% (1200/1300)\n",
      "Test Epoch: 45 | Loss: 0.276 | Acc: 92.429% (1294/1400)\n",
      "Test Epoch: 45 | Loss: 0.276 | Acc: 92.467% (1387/1500)\n",
      "Test Epoch: 45 | Loss: 0.269 | Acc: 92.625% (1482/1600)\n",
      "Test Epoch: 45 | Loss: 0.271 | Acc: 92.765% (1577/1700)\n",
      "Test Epoch: 45 | Loss: 0.270 | Acc: 92.722% (1669/1800)\n",
      "Test Epoch: 45 | Loss: 0.277 | Acc: 92.368% (1755/1900)\n",
      "Test Epoch: 45 | Loss: 0.282 | Acc: 92.250% (1845/2000)\n",
      "Test Epoch: 45 | Loss: 0.287 | Acc: 91.952% (1931/2100)\n",
      "Test Epoch: 45 | Loss: 0.291 | Acc: 91.773% (2019/2200)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.739% (2110/2300)\n",
      "Test Epoch: 45 | Loss: 0.289 | Acc: 91.833% (2204/2400)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.680% (2292/2500)\n",
      "Test Epoch: 45 | Loss: 0.303 | Acc: 91.615% (2382/2600)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.593% (2473/2700)\n",
      "Test Epoch: 45 | Loss: 0.301 | Acc: 91.571% (2564/2800)\n",
      "Test Epoch: 45 | Loss: 0.299 | Acc: 91.552% (2655/2900)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.667% (2750/3000)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.710% (2843/3100)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.812% (2938/3200)\n",
      "Test Epoch: 45 | Loss: 0.289 | Acc: 91.848% (3031/3300)\n",
      "Test Epoch: 45 | Loss: 0.290 | Acc: 91.824% (3122/3400)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.657% (3208/3500)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.722% (3302/3600)\n",
      "Test Epoch: 45 | Loss: 0.299 | Acc: 91.649% (3391/3700)\n",
      "Test Epoch: 45 | Loss: 0.302 | Acc: 91.632% (3482/3800)\n",
      "Test Epoch: 45 | Loss: 0.299 | Acc: 91.718% (3577/3900)\n",
      "Test Epoch: 45 | Loss: 0.301 | Acc: 91.725% (3669/4000)\n",
      "Test Epoch: 45 | Loss: 0.304 | Acc: 91.634% (3757/4100)\n",
      "Test Epoch: 45 | Loss: 0.306 | Acc: 91.571% (3846/4200)\n",
      "Test Epoch: 45 | Loss: 0.303 | Acc: 91.651% (3941/4300)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.750% (4037/4400)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.844% (4133/4500)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.804% (4223/4600)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.766% (4313/4700)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.667% (4400/4800)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.735% (4495/4900)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.700% (4585/5000)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.765% (4680/5100)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.654% (4766/5200)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.679% (4859/5300)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.741% (4954/5400)\n",
      "Test Epoch: 45 | Loss: 0.301 | Acc: 91.691% (5043/5500)\n",
      "Test Epoch: 45 | Loss: 0.301 | Acc: 91.696% (5135/5600)\n",
      "Test Epoch: 45 | Loss: 0.300 | Acc: 91.737% (5229/5700)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.776% (5323/5800)\n",
      "Test Epoch: 45 | Loss: 0.302 | Acc: 91.712% (5411/5900)\n",
      "Test Epoch: 45 | Loss: 0.299 | Acc: 91.750% (5505/6000)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.770% (5598/6100)\n",
      "Test Epoch: 45 | Loss: 0.299 | Acc: 91.790% (5691/6200)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.825% (5785/6300)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.891% (5881/6400)\n",
      "Test Epoch: 45 | Loss: 0.298 | Acc: 91.877% (5972/6500)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.939% (6068/6600)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.940% (6160/6700)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.897% (6249/6800)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.942% (6344/6900)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.886% (6432/7000)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.831% (6520/7100)\n",
      "Test Epoch: 45 | Loss: 0.297 | Acc: 91.861% (6614/7200)\n",
      "Test Epoch: 45 | Loss: 0.296 | Acc: 91.877% (6707/7300)\n",
      "Test Epoch: 45 | Loss: 0.294 | Acc: 91.919% (6802/7400)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.880% (6891/7500)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.868% (6982/7600)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.896% (7076/7700)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.936% (7171/7800)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.975% (7266/7900)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.987% (7359/8000)\n",
      "Test Epoch: 45 | Loss: 0.290 | Acc: 92.062% (7457/8100)\n",
      "Test Epoch: 45 | Loss: 0.291 | Acc: 92.012% (7545/8200)\n",
      "Test Epoch: 45 | Loss: 0.290 | Acc: 92.036% (7639/8300)\n",
      "Test Epoch: 45 | Loss: 0.290 | Acc: 92.012% (7729/8400)\n",
      "Test Epoch: 45 | Loss: 0.291 | Acc: 91.988% (7819/8500)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.942% (7907/8600)\n",
      "Test Epoch: 45 | Loss: 0.291 | Acc: 91.977% (8002/8700)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.932% (8090/8800)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.933% (8182/8900)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.922% (8273/9000)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.956% (8368/9100)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.967% (8461/9200)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.957% (8552/9300)\n",
      "Test Epoch: 45 | Loss: 0.294 | Acc: 91.947% (8643/9400)\n",
      "Test Epoch: 45 | Loss: 0.295 | Acc: 91.926% (8733/9500)\n",
      "Test Epoch: 45 | Loss: 0.294 | Acc: 91.927% (8825/9600)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.979% (8922/9700)\n",
      "Test Epoch: 45 | Loss: 0.291 | Acc: 92.031% (9019/9800)\n",
      "Test Epoch: 45 | Loss: 0.293 | Acc: 91.970% (9105/9900)\n",
      "Test Epoch: 45 | Loss: 0.292 | Acc: 91.980% (9198/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 46\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.656% (125/128)\n",
      "Train Epoch: 46 | Loss: 0.076 | Acc: 98.047% (251/256)\n",
      "Train Epoch: 46 | Loss: 0.081 | Acc: 97.656% (375/384)\n",
      "Train Epoch: 46 | Loss: 0.086 | Acc: 97.070% (497/512)\n",
      "Train Epoch: 46 | Loss: 0.082 | Acc: 97.500% (624/640)\n",
      "Train Epoch: 46 | Loss: 0.090 | Acc: 97.266% (747/768)\n",
      "Train Epoch: 46 | Loss: 0.090 | Acc: 97.210% (871/896)\n",
      "Train Epoch: 46 | Loss: 0.090 | Acc: 97.168% (995/1024)\n",
      "Train Epoch: 46 | Loss: 0.087 | Acc: 97.309% (1121/1152)\n",
      "Train Epoch: 46 | Loss: 0.080 | Acc: 97.578% (1249/1280)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.656% (1375/1408)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.656% (1500/1536)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.716% (1626/1664)\n",
      "Train Epoch: 46 | Loss: 0.074 | Acc: 97.768% (1752/1792)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.708% (1876/1920)\n",
      "Train Epoch: 46 | Loss: 0.079 | Acc: 97.559% (1998/2048)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.610% (2124/2176)\n",
      "Train Epoch: 46 | Loss: 0.079 | Acc: 97.526% (2247/2304)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.533% (2372/2432)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.422% (2494/2560)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.545% (2622/2688)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.514% (2746/2816)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.385% (2867/2944)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.396% (2992/3072)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.375% (3116/3200)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.356% (3240/3328)\n",
      "Train Epoch: 46 | Loss: 0.079 | Acc: 97.309% (3363/3456)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.349% (3489/3584)\n",
      "Train Epoch: 46 | Loss: 0.078 | Acc: 97.333% (3613/3712)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.370% (3739/3840)\n",
      "Train Epoch: 46 | Loss: 0.077 | Acc: 97.379% (3864/3968)\n",
      "Train Epoch: 46 | Loss: 0.076 | Acc: 97.412% (3990/4096)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.443% (4116/4224)\n",
      "Train Epoch: 46 | Loss: 0.074 | Acc: 97.472% (4242/4352)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.500% (4368/4480)\n",
      "Train Epoch: 46 | Loss: 0.075 | Acc: 97.483% (4492/4608)\n",
      "Train Epoch: 46 | Loss: 0.073 | Acc: 97.551% (4620/4736)\n",
      "Train Epoch: 46 | Loss: 0.073 | Acc: 97.574% (4746/4864)\n",
      "Train Epoch: 46 | Loss: 0.074 | Acc: 97.516% (4868/4992)\n",
      "Train Epoch: 46 | Loss: 0.074 | Acc: 97.539% (4994/5120)\n",
      "Train Epoch: 46 | Loss: 0.074 | Acc: 97.523% (5118/5248)\n",
      "Train Epoch: 46 | Loss: 0.073 | Acc: 97.563% (5245/5376)\n",
      "Train Epoch: 46 | Loss: 0.073 | Acc: 97.584% (5371/5504)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.621% (5498/5632)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.674% (5626/5760)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.656% (5750/5888)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.673% (5876/6016)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.656% (6000/6144)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.640% (6124/6272)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.594% (6246/6400)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.641% (6374/6528)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.626% (6498/6656)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.597% (6621/6784)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.584% (6745/6912)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.585% (6870/7040)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.586% (6995/7168)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.588% (7120/7296)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.602% (7246/7424)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.617% (7372/7552)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.630% (7498/7680)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.605% (7621/7808)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.581% (7744/7936)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.607% (7871/8064)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.595% (7995/8192)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.584% (8119/8320)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.585% (8244/8448)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.621% (8372/8576)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.656% (8500/8704)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.690% (8628/8832)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.690% (8753/8960)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.645% (8874/9088)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.645% (8999/9216)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.678% (9127/9344)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.677% (9252/9472)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.688% (9378/9600)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.646% (9499/9728)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.636% (9623/9856)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.616% (9746/9984)\n",
      "Train Epoch: 46 | Loss: 0.072 | Acc: 97.617% (9871/10112)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.627% (9997/10240)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.627% (10122/10368)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.637% (10248/10496)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.647% (10374/10624)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.656% (10500/10752)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.665% (10626/10880)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.674% (10752/11008)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.683% (10878/11136)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.710% (11006/11264)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.718% (11132/11392)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.708% (11256/11520)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.699% (11380/11648)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.673% (11502/11776)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.690% (11629/11904)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.698% (11755/12032)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.722% (11883/12160)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.721% (12008/12288)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.729% (12134/12416)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.736% (12260/12544)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.735% (12385/12672)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.750% (12512/12800)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.757% (12638/12928)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.756% (12763/13056)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.755% (12888/13184)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.724% (13009/13312)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.723% (13134/13440)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.708% (13257/13568)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.722% (13384/13696)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.736% (13511/13824)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.721% (13634/13952)\n",
      "Train Epoch: 46 | Loss: 0.071 | Acc: 97.720% (13759/14080)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.720% (13884/14208)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.726% (14010/14336)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.725% (14135/14464)\n",
      "Train Epoch: 46 | Loss: 0.070 | Acc: 97.732% (14261/14592)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.745% (14388/14720)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.744% (14513/14848)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.743% (14638/14976)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.756% (14765/15104)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.755% (14890/15232)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.767% (15017/15360)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.779% (15144/15488)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.784% (15270/15616)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.796% (15397/15744)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.795% (15522/15872)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.775% (15644/16000)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.768% (15768/16128)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.785% (15896/16256)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.791% (16022/16384)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.783% (16146/16512)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.788% (16272/16640)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.805% (16400/16768)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.804% (16525/16896)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.809% (16651/17024)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.819% (16778/17152)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.801% (16900/17280)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.800% (17025/17408)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.793% (17149/17536)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.809% (17277/17664)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.814% (17403/17792)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.796% (17525/17920)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.795% (17650/18048)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.794% (17775/18176)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.798% (17901/18304)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.803% (18027/18432)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.818% (18155/18560)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.822% (18281/18688)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.821% (18406/18816)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.815% (18530/18944)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.814% (18655/19072)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.807% (18779/19200)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.817% (18906/19328)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.800% (19028/19456)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.799% (19153/19584)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.803% (19279/19712)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.802% (19404/19840)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.817% (19532/19968)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.815% (19657/20096)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.824% (19784/20224)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.828% (19910/20352)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.827% (20035/20480)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.831% (20161/20608)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.835% (20287/20736)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.838% (20413/20864)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.847% (20540/20992)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.846% (20665/21120)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.840% (20789/21248)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.843% (20915/21376)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.828% (21037/21504)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.827% (21162/21632)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.817% (21285/21760)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.825% (21412/21888)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.824% (21537/22016)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.828% (21663/22144)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.822% (21787/22272)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.812% (21910/22400)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.825% (22038/22528)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.828% (22164/22656)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.823% (22288/22784)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.831% (22415/22912)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.839% (22542/23040)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.842% (22668/23168)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.841% (22793/23296)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.844% (22919/23424)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.847% (23045/23552)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.834% (23167/23680)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.824% (23290/23808)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.828% (23416/23936)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.822% (23540/24064)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.817% (23664/24192)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.825% (23791/24320)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.824% (23916/24448)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.819% (24040/24576)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.822% (24166/24704)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.817% (24290/24832)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.808% (24413/24960)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.812% (24539/25088)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.815% (24665/25216)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.810% (24789/25344)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.802% (24912/25472)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.793% (25035/25600)\n",
      "Train Epoch: 46 | Loss: 0.067 | Acc: 97.788% (25159/25728)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.784% (25283/25856)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.779% (25407/25984)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.775% (25531/26112)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.771% (25655/26240)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.778% (25782/26368)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.785% (25909/26496)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.780% (26033/26624)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.776% (26157/26752)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.779% (26283/26880)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.778% (26408/27008)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.778% (26533/27136)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.759% (26653/27264)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.751% (26776/27392)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.754% (26902/27520)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.750% (27026/27648)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.757% (27153/27776)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (27274/27904)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.745% (27400/28032)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.749% (27526/28160)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.741% (27649/28288)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.730% (27771/28416)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.733% (27897/28544)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.719% (28018/28672)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.719% (28143/28800)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.722% (28269/28928)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.722% (28394/29056)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.721% (28519/29184)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.724% (28645/29312)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.724% (28770/29440)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.734% (28898/29568)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (29025/29696)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.743% (29151/29824)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (29275/29952)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.743% (29401/30080)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (29524/30208)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (29651/30336)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (29775/30464)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.735% (29899/30592)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.741% (30026/30720)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.741% (30151/30848)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.747% (30278/30976)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.749% (30404/31104)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.743% (30527/31232)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (30650/31360)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.739% (30776/31488)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (30901/31616)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.735% (31025/31744)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.728% (31148/31872)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.728% (31273/32000)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.725% (31397/32128)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.728% (31523/32256)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.724% (31647/32384)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.724% (31772/32512)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.718% (31895/32640)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.723% (32022/32768)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.720% (32146/32896)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.729% (32274/33024)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.723% (32397/33152)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.716% (32520/33280)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.716% (32645/33408)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.707% (32767/33536)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.710% (32893/33664)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.718% (33021/33792)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.718% (33146/33920)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.727% (33274/34048)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.721% (33397/34176)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.717% (33521/34304)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.720% (33647/34432)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.711% (33769/34560)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.705% (33892/34688)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.705% (34017/34816)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.705% (34142/34944)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.702% (34266/35072)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.699% (34390/35200)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.696% (34514/35328)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.701% (34641/35456)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.704% (34767/35584)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.701% (34891/35712)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.704% (35017/35840)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.706% (35143/35968)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.706% (35268/36096)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.711% (35395/36224)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.714% (35521/36352)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.706% (35643/36480)\n",
      "Train Epoch: 46 | Loss: 0.069 | Acc: 97.703% (35767/36608)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.708% (35894/36736)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.708% (36019/36864)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.708% (36144/36992)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.710% (36270/37120)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.715% (36397/37248)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.712% (36521/37376)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.715% (36647/37504)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.715% (36772/37632)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.717% (36898/37760)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.720% (37024/37888)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.722% (37150/38016)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.719% (37274/38144)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.722% (37400/38272)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.721% (37525/38400)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.721% (37650/38528)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.713% (37772/38656)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.710% (37896/38784)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.713% (38022/38912)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.713% (38147/39040)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.712% (38272/39168)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.715% (38398/39296)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.715% (38523/39424)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.712% (38647/39552)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.712% (38772/39680)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.712% (38897/39808)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.711% (39022/39936)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.711% (39147/40064)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.713% (39273/40192)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.713% (39398/40320)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.721% (39526/40448)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.718% (39650/40576)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.720% (39776/40704)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.727% (39904/40832)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.722% (40027/40960)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.724% (40153/41088)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.727% (40279/41216)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.729% (40405/41344)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (40533/41472)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (40659/41600)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.735% (40783/41728)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.737% (40909/41856)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (41036/41984)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (41161/42112)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.741% (41286/42240)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.744% (41412/42368)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (41534/42496)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (41660/42624)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (41784/42752)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.743% (41912/42880)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (42037/43008)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (42161/43136)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (42287/43264)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.739% (42411/43392)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.746% (42539/43520)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.750% (42666/43648)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.748% (42790/43776)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.752% (42917/43904)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.749% (43041/44032)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (43162/44160)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (43288/44288)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.735% (43410/44416)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.730% (43533/44544)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.732% (43659/44672)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.737% (43786/44800)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.730% (43908/44928)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.732% (44034/45056)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.734% (44160/45184)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (44288/45312)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.740% (44413/45440)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.744% (44540/45568)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (44664/45696)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.739% (44788/45824)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.741% (44914/45952)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.745% (45041/46080)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.745% (45166/46208)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (45288/46336)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (45412/46464)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (45538/46592)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (45663/46720)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.733% (45786/46848)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.737% (45913/46976)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.739% (46039/47104)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.739% (46164/47232)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (46288/47360)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (46413/47488)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.736% (46538/47616)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.738% (46664/47744)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.742% (46791/47872)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.746% (46918/48000)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.748% (47044/48128)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.750% (47170/48256)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.747% (47294/48384)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.751% (47421/48512)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.753% (47547/48640)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.755% (47673/48768)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.756% (47799/48896)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.760% (47926/49024)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.758% (48050/49152)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.762% (48177/49280)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.759% (48301/49408)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.757% (48425/49536)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.759% (48551/49664)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.755% (48674/49792)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.758% (48801/49920)\n",
      "Train Epoch: 46 | Loss: 0.068 | Acc: 97.754% (48877/50000)\n",
      "Test Epoch: 46 | Loss: 0.188 | Acc: 96.000% (96/100)\n",
      "Test Epoch: 46 | Loss: 0.297 | Acc: 94.000% (188/200)\n",
      "Test Epoch: 46 | Loss: 0.293 | Acc: 93.000% (279/300)\n",
      "Test Epoch: 46 | Loss: 0.267 | Acc: 93.250% (373/400)\n",
      "Test Epoch: 46 | Loss: 0.255 | Acc: 93.000% (465/500)\n",
      "Test Epoch: 46 | Loss: 0.231 | Acc: 93.333% (560/600)\n",
      "Test Epoch: 46 | Loss: 0.230 | Acc: 93.286% (653/700)\n",
      "Test Epoch: 46 | Loss: 0.247 | Acc: 93.000% (744/800)\n",
      "Test Epoch: 46 | Loss: 0.261 | Acc: 92.556% (833/900)\n",
      "Test Epoch: 46 | Loss: 0.254 | Acc: 92.700% (927/1000)\n",
      "Test Epoch: 46 | Loss: 0.266 | Acc: 92.455% (1017/1100)\n",
      "Test Epoch: 46 | Loss: 0.290 | Acc: 92.167% (1106/1200)\n",
      "Test Epoch: 46 | Loss: 0.278 | Acc: 92.385% (1201/1300)\n",
      "Test Epoch: 46 | Loss: 0.274 | Acc: 92.429% (1294/1400)\n",
      "Test Epoch: 46 | Loss: 0.272 | Acc: 92.467% (1387/1500)\n",
      "Test Epoch: 46 | Loss: 0.267 | Acc: 92.688% (1483/1600)\n",
      "Test Epoch: 46 | Loss: 0.271 | Acc: 92.647% (1575/1700)\n",
      "Test Epoch: 46 | Loss: 0.271 | Acc: 92.667% (1668/1800)\n",
      "Test Epoch: 46 | Loss: 0.276 | Acc: 92.526% (1758/1900)\n",
      "Test Epoch: 46 | Loss: 0.284 | Acc: 92.300% (1846/2000)\n",
      "Test Epoch: 46 | Loss: 0.288 | Acc: 92.095% (1934/2100)\n",
      "Test Epoch: 46 | Loss: 0.286 | Acc: 92.000% (2024/2200)\n",
      "Test Epoch: 46 | Loss: 0.293 | Acc: 91.826% (2112/2300)\n",
      "Test Epoch: 46 | Loss: 0.288 | Acc: 91.917% (2206/2400)\n",
      "Test Epoch: 46 | Loss: 0.298 | Acc: 91.800% (2295/2500)\n",
      "Test Epoch: 46 | Loss: 0.310 | Acc: 91.615% (2382/2600)\n",
      "Test Epoch: 46 | Loss: 0.307 | Acc: 91.704% (2476/2700)\n",
      "Test Epoch: 46 | Loss: 0.309 | Acc: 91.714% (2568/2800)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.690% (2659/2900)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.733% (2752/3000)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.677% (2842/3100)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.688% (2934/3200)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.606% (3023/3300)\n",
      "Test Epoch: 46 | Loss: 0.311 | Acc: 91.647% (3116/3400)\n",
      "Test Epoch: 46 | Loss: 0.311 | Acc: 91.629% (3207/3500)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.722% (3302/3600)\n",
      "Test Epoch: 46 | Loss: 0.316 | Acc: 91.676% (3392/3700)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.579% (3480/3800)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.590% (3572/3900)\n",
      "Test Epoch: 46 | Loss: 0.323 | Acc: 91.600% (3664/4000)\n",
      "Test Epoch: 46 | Loss: 0.326 | Acc: 91.512% (3752/4100)\n",
      "Test Epoch: 46 | Loss: 0.330 | Acc: 91.405% (3839/4200)\n",
      "Test Epoch: 46 | Loss: 0.327 | Acc: 91.488% (3934/4300)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.614% (4031/4400)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.667% (4125/4500)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 91.630% (4215/4600)\n",
      "Test Epoch: 46 | Loss: 0.316 | Acc: 91.681% (4309/4700)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.688% (4401/4800)\n",
      "Test Epoch: 46 | Loss: 0.316 | Acc: 91.755% (4496/4900)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.700% (4585/5000)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.784% (4681/5100)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.692% (4768/5200)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.660% (4858/5300)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 91.704% (4952/5400)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.655% (5041/5500)\n",
      "Test Epoch: 46 | Loss: 0.319 | Acc: 91.714% (5136/5600)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 91.789% (5232/5700)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 91.776% (5323/5800)\n",
      "Test Epoch: 46 | Loss: 0.322 | Acc: 91.678% (5409/5900)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.683% (5501/6000)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.689% (5593/6100)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.629% (5681/6200)\n",
      "Test Epoch: 46 | Loss: 0.322 | Acc: 91.603% (5771/6300)\n",
      "Test Epoch: 46 | Loss: 0.319 | Acc: 91.688% (5868/6400)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.631% (5956/6500)\n",
      "Test Epoch: 46 | Loss: 0.319 | Acc: 91.652% (6049/6600)\n",
      "Test Epoch: 46 | Loss: 0.317 | Acc: 91.687% (6143/6700)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.647% (6232/6800)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.681% (6326/6900)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.629% (6414/7000)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.592% (6503/7100)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.556% (6592/7200)\n",
      "Test Epoch: 46 | Loss: 0.320 | Acc: 91.575% (6685/7300)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.635% (6781/7400)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.600% (6870/7500)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.579% (6960/7600)\n",
      "Test Epoch: 46 | Loss: 0.322 | Acc: 91.545% (7049/7700)\n",
      "Test Epoch: 46 | Loss: 0.321 | Acc: 91.526% (7139/7800)\n",
      "Test Epoch: 46 | Loss: 0.319 | Acc: 91.570% (7234/7900)\n",
      "Test Epoch: 46 | Loss: 0.318 | Acc: 91.525% (7322/8000)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.568% (7417/8100)\n",
      "Test Epoch: 46 | Loss: 0.316 | Acc: 91.524% (7505/8200)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.554% (7599/8300)\n",
      "Test Epoch: 46 | Loss: 0.313 | Acc: 91.607% (7695/8400)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.529% (7780/8500)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.523% (7871/8600)\n",
      "Test Epoch: 46 | Loss: 0.313 | Acc: 91.552% (7965/8700)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.523% (8054/8800)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.506% (8144/8900)\n",
      "Test Epoch: 46 | Loss: 0.316 | Acc: 91.467% (8232/9000)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.484% (8325/9100)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.511% (8419/9200)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.495% (8509/9300)\n",
      "Test Epoch: 46 | Loss: 0.315 | Acc: 91.521% (8603/9400)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.526% (8695/9500)\n",
      "Test Epoch: 46 | Loss: 0.314 | Acc: 91.531% (8787/9600)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.557% (8881/9700)\n",
      "Test Epoch: 46 | Loss: 0.310 | Acc: 91.612% (8978/9800)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.576% (9066/9900)\n",
      "Test Epoch: 46 | Loss: 0.312 | Acc: 91.580% (9158/10000)\n",
      "\n",
      "Epoch: 47\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 98.828% (253/256)\n",
      "Train Epoch: 47 | Loss: 0.053 | Acc: 98.698% (379/384)\n",
      "Train Epoch: 47 | Loss: 0.050 | Acc: 98.633% (505/512)\n",
      "Train Epoch: 47 | Loss: 0.048 | Acc: 98.750% (632/640)\n",
      "Train Epoch: 47 | Loss: 0.054 | Acc: 98.568% (757/768)\n",
      "Train Epoch: 47 | Loss: 0.055 | Acc: 98.549% (883/896)\n",
      "Train Epoch: 47 | Loss: 0.054 | Acc: 98.535% (1009/1024)\n",
      "Train Epoch: 47 | Loss: 0.056 | Acc: 98.351% (1133/1152)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.969% (1254/1280)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.869% (1378/1408)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.786% (1502/1536)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.776% (1627/1664)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.768% (1752/1792)\n",
      "Train Epoch: 47 | Loss: 0.069 | Acc: 97.500% (1872/1920)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.510% (1997/2048)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.610% (2124/2176)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.613% (2249/2304)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.738% (2377/2432)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.656% (2500/2560)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.582% (2623/2688)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.692% (2751/2816)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.724% (2877/2944)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.656% (3000/3072)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.750% (3128/3200)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.746% (3253/3328)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.801% (3380/3456)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.824% (3506/3584)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.710% (3627/3712)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.708% (3752/3840)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.757% (3879/3968)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.754% (4004/4096)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.751% (4129/4224)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.748% (4254/4352)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.768% (4380/4480)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.721% (4503/4608)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.762% (4630/4736)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.800% (4757/4864)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.817% (4883/4992)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.812% (5008/5120)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.866% (5136/5248)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.842% (5260/5376)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.820% (5384/5504)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.798% (5508/5632)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.778% (5632/5760)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.792% (5758/5888)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.773% (5882/6016)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.803% (6009/6144)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.800% (6134/6272)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.844% (6262/6400)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.809% (6385/6528)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.822% (6511/6656)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.818% (6636/6784)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.844% (6763/6912)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.869% (6890/7040)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.838% (7013/7168)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.876% (7141/7296)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.899% (7268/7424)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.908% (7394/7552)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.917% (7520/7680)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 97.925% (7646/7808)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 97.908% (7770/7936)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.904% (7895/8064)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.888% (8019/8192)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 97.897% (8145/8320)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 97.917% (8272/8448)\n",
      "Train Epoch: 47 | Loss: 0.060 | Acc: 97.924% (8398/8576)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.909% (8522/8704)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.917% (8648/8832)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.902% (8772/8960)\n",
      "Train Epoch: 47 | Loss: 0.061 | Acc: 97.909% (8898/9088)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.906% (9023/9216)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.870% (9145/9344)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.889% (9272/9472)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.896% (9398/9600)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.903% (9524/9728)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.910% (9650/9856)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.887% (9773/9984)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.894% (9899/10112)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.900% (10025/10240)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.888% (10149/10368)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.866% (10272/10496)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.882% (10399/10624)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.898% (10526/10752)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.895% (10651/10880)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.911% (10778/11008)\n",
      "Train Epoch: 47 | Loss: 0.062 | Acc: 97.917% (10904/11136)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.905% (11028/11264)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.893% (11152/11392)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.873% (11275/11520)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.871% (11400/11648)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.877% (11526/11776)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.891% (11653/11904)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.881% (11777/12032)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.887% (11903/12160)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.892% (12029/12288)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.874% (12152/12416)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.864% (12276/12544)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.854% (12400/12672)\n",
      "Train Epoch: 47 | Loss: 0.063 | Acc: 97.867% (12527/12800)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.850% (12650/12928)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.863% (12777/13056)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.869% (12903/13184)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.837% (13024/13312)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.835% (13149/13440)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.833% (13274/13568)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.831% (13399/13696)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.844% (13526/13824)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.821% (13648/13952)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.812% (13772/14080)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.790% (13894/14208)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.810% (14022/14336)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.822% (14149/14464)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.821% (14274/14592)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.819% (14399/14720)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.811% (14523/14848)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.830% (14651/14976)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.822% (14775/15104)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.814% (14899/15232)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.826% (15026/15360)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.831% (15152/15488)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.823% (15276/15616)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.809% (15399/15744)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.807% (15524/15872)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.800% (15648/16000)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.793% (15772/16128)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.792% (15897/16256)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.784% (16021/16384)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.802% (16149/16512)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.800% (16274/16640)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.799% (16399/16768)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.810% (16526/16896)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.815% (16652/17024)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.808% (16776/17152)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.807% (16901/17280)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.823% (17029/17408)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.833% (17156/17536)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.837% (17282/17664)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.842% (17408/17792)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.852% (17535/17920)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.850% (17660/18048)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.849% (17785/18176)\n",
      "Train Epoch: 47 | Loss: 0.064 | Acc: 97.858% (17912/18304)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.841% (18034/18432)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.845% (18160/18560)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.827% (18282/18688)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.826% (18407/18816)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.830% (18533/18944)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.814% (18655/19072)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.823% (18782/19200)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.822% (18907/19328)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.821% (19032/19456)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.825% (19158/19584)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.819% (19282/19712)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.828% (19409/19840)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.832% (19535/19968)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.820% (19658/20096)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.819% (19783/20224)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.818% (19908/20352)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.822% (20034/20480)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.831% (20161/20608)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.835% (20287/20736)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.848% (20415/20864)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.842% (20539/20992)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.841% (20664/21120)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.840% (20789/21248)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.848% (20916/21376)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.847% (21041/21504)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.837% (21164/21632)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.835% (21289/21760)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.830% (21413/21888)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.820% (21536/22016)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.814% (21660/22144)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.818% (21786/22272)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.817% (21911/22400)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.820% (22037/22528)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.824% (22163/22656)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.819% (22287/22784)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.813% (22411/22912)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.821% (22538/23040)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.816% (22662/23168)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.819% (22788/23296)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.818% (22913/23424)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.826% (23040/23552)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.821% (23164/23680)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.820% (23289/23808)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.815% (23413/23936)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.810% (23537/24064)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.813% (23663/24192)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.817% (23789/24320)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.820% (23915/24448)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.819% (24040/24576)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.822% (24166/24704)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.817% (24290/24832)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.800% (24411/24960)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.800% (24536/25088)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.799% (24661/25216)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.802% (24787/25344)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.805% (24913/25472)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.816% (25041/25600)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.812% (25165/25728)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.811% (25290/25856)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.818% (25417/25984)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.809% (25540/26112)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.805% (25664/26240)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.797% (25787/26368)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.788% (25910/26496)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.791% (26036/26624)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.795% (26162/26752)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.794% (26287/26880)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.793% (26412/27008)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.796% (26538/27136)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.788% (26661/27264)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.780% (26784/27392)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.773% (26907/27520)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.768% (27031/27648)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.779% (27159/27776)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.775% (27283/27904)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.781% (27410/28032)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.784% (27536/28160)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.787% (27662/28288)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.783% (27786/28416)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.786% (27912/28544)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.782% (28036/28672)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.774% (28159/28800)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.781% (28286/28928)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.773% (28409/29056)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.780% (28536/29184)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.769% (28658/29312)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.765% (28782/29440)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.768% (28908/29568)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (29032/29696)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.757% (29155/29824)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.763% (29282/29952)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.759% (29406/30080)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.752% (29529/30208)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.755% (29655/30336)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.758% (29781/30464)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.761% (29907/30592)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.760% (30032/30720)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.766% (30159/30848)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.769% (30285/30976)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.762% (30408/31104)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.762% (30533/31232)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.765% (30659/31360)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.767% (30785/31488)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (30909/31616)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.760% (31033/31744)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.757% (31157/31872)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.759% (31283/32000)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.756% (31407/32128)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.759% (31533/32256)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (31660/32384)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (31785/32512)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.757% (31908/32640)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.748% (32030/32768)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.750% (32156/32896)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.753% (32282/33024)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.759% (32409/33152)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (32536/33280)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.758% (32659/33408)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.755% (32783/33536)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.757% (32909/33664)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.754% (33033/33792)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.756% (33159/33920)\n",
      "Train Epoch: 47 | Loss: 0.068 | Acc: 97.753% (33283/34048)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.756% (33409/34176)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.764% (33537/34304)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.772% (33665/34432)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.769% (33789/34560)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.777% (33917/34688)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.774% (34041/34816)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.779% (34168/34944)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.770% (34290/35072)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.770% (34415/35200)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.769% (34540/35328)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.766% (34664/35456)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.771% (34791/35584)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.774% (34917/35712)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.779% (35044/35840)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.781% (35170/35968)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.781% (35295/36096)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.786% (35422/36224)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.791% (35549/36352)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.793% (35675/36480)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.796% (35801/36608)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.801% (35928/36736)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.800% (36053/36864)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.797% (36177/36992)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.796% (36302/37120)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.799% (36428/37248)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.795% (36552/37376)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.790% (36675/37504)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.792% (36801/37632)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.789% (36925/37760)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.793% (37052/37888)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.790% (37176/38016)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.790% (37301/38144)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.797% (37429/38272)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.797% (37554/38400)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.802% (37681/38528)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.801% (37806/38656)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.808% (37934/38784)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.813% (38061/38912)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.812% (38186/39040)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.817% (38313/39168)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.814% (38437/39296)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.819% (38564/39424)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.816% (38688/39552)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.807% (38810/39680)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.797% (38931/39808)\n",
      "Train Epoch: 47 | Loss: 0.067 | Acc: 97.799% (39057/39936)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.806% (39185/40064)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.808% (39311/40192)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.812% (39438/40320)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.810% (39562/40448)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.809% (39687/40576)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.809% (39812/40704)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.813% (39939/40832)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.820% (40067/40960)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.822% (40193/41088)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.816% (40316/41216)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.821% (40443/41344)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.827% (40571/41472)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.829% (40697/41600)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.831% (40823/41728)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.835% (40950/41856)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.833% (41074/41984)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.834% (41200/42112)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.836% (41326/42240)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.836% (41451/42368)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.828% (41573/42496)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.823% (41696/42624)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.822% (41821/42752)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.822% (41946/42880)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.819% (42070/43008)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.821% (42196/43136)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.823% (42322/43264)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.829% (42450/43392)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.826% (42574/43520)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.830% (42701/43648)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.830% (42826/43776)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.834% (42953/43904)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.836% (43079/44032)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.833% (43203/44160)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.837% (43330/44288)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.830% (43452/44416)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.831% (43578/44544)\n",
      "Train Epoch: 47 | Loss: 0.066 | Acc: 97.835% (43705/44672)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.839% (43832/44800)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.841% (43958/44928)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.845% (44085/45056)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.851% (44213/45184)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.846% (44336/45312)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.839% (44458/45440)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.843% (44585/45568)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.847% (44712/45696)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.846% (44837/45824)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.852% (44965/45952)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.849% (45089/46080)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.851% (45215/46208)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.853% (45341/46336)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.852% (45466/46464)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.852% (45591/46592)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.855% (45718/46720)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.857% (45844/46848)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.854% (45968/46976)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.849% (46091/47104)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.847% (46215/47232)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.848% (46341/47360)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.850% (46467/47488)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.854% (46594/47616)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.855% (46720/47744)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.857% (46846/47872)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.854% (46970/48000)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.860% (47098/48128)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.857% (47222/48256)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.853% (47345/48384)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.854% (47471/48512)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.858% (47598/48640)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.851% (47720/48768)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.848% (47844/48896)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.846% (47968/49024)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.852% (48096/49152)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.853% (48222/49280)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.853% (48347/49408)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.850% (48471/49536)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.846% (48594/49664)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.847% (48720/49792)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.847% (48845/49920)\n",
      "Train Epoch: 47 | Loss: 0.065 | Acc: 97.842% (48921/50000)\n",
      "Test Epoch: 47 | Loss: 0.246 | Acc: 95.000% (95/100)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 93.000% (186/200)\n",
      "Test Epoch: 47 | Loss: 0.276 | Acc: 92.667% (278/300)\n",
      "Test Epoch: 47 | Loss: 0.243 | Acc: 93.000% (372/400)\n",
      "Test Epoch: 47 | Loss: 0.239 | Acc: 93.600% (468/500)\n",
      "Test Epoch: 47 | Loss: 0.215 | Acc: 94.000% (564/600)\n",
      "Test Epoch: 47 | Loss: 0.227 | Acc: 93.714% (656/700)\n",
      "Test Epoch: 47 | Loss: 0.253 | Acc: 92.875% (743/800)\n",
      "Test Epoch: 47 | Loss: 0.259 | Acc: 92.667% (834/900)\n",
      "Test Epoch: 47 | Loss: 0.256 | Acc: 92.700% (927/1000)\n",
      "Test Epoch: 47 | Loss: 0.259 | Acc: 92.727% (1020/1100)\n",
      "Test Epoch: 47 | Loss: 0.276 | Acc: 92.417% (1109/1200)\n",
      "Test Epoch: 47 | Loss: 0.268 | Acc: 92.462% (1202/1300)\n",
      "Test Epoch: 47 | Loss: 0.262 | Acc: 92.571% (1296/1400)\n",
      "Test Epoch: 47 | Loss: 0.266 | Acc: 92.600% (1389/1500)\n",
      "Test Epoch: 47 | Loss: 0.264 | Acc: 92.625% (1482/1600)\n",
      "Test Epoch: 47 | Loss: 0.269 | Acc: 92.529% (1573/1700)\n",
      "Test Epoch: 47 | Loss: 0.268 | Acc: 92.500% (1665/1800)\n",
      "Test Epoch: 47 | Loss: 0.271 | Acc: 92.316% (1754/1900)\n",
      "Test Epoch: 47 | Loss: 0.280 | Acc: 92.200% (1844/2000)\n",
      "Test Epoch: 47 | Loss: 0.289 | Acc: 91.810% (1928/2100)\n",
      "Test Epoch: 47 | Loss: 0.293 | Acc: 91.727% (2018/2200)\n",
      "Test Epoch: 47 | Loss: 0.298 | Acc: 91.652% (2108/2300)\n",
      "Test Epoch: 47 | Loss: 0.293 | Acc: 91.708% (2201/2400)\n",
      "Test Epoch: 47 | Loss: 0.296 | Acc: 91.720% (2293/2500)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.577% (2381/2600)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.593% (2473/2700)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.571% (2564/2800)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.586% (2656/2900)\n",
      "Test Epoch: 47 | Loss: 0.299 | Acc: 91.733% (2752/3000)\n",
      "Test Epoch: 47 | Loss: 0.300 | Acc: 91.710% (2843/3100)\n",
      "Test Epoch: 47 | Loss: 0.297 | Acc: 91.750% (2936/3200)\n",
      "Test Epoch: 47 | Loss: 0.295 | Acc: 91.727% (3027/3300)\n",
      "Test Epoch: 47 | Loss: 0.294 | Acc: 91.765% (3120/3400)\n",
      "Test Epoch: 47 | Loss: 0.293 | Acc: 91.743% (3211/3500)\n",
      "Test Epoch: 47 | Loss: 0.292 | Acc: 91.861% (3307/3600)\n",
      "Test Epoch: 47 | Loss: 0.296 | Acc: 91.811% (3397/3700)\n",
      "Test Epoch: 47 | Loss: 0.301 | Acc: 91.605% (3481/3800)\n",
      "Test Epoch: 47 | Loss: 0.297 | Acc: 91.667% (3575/3900)\n",
      "Test Epoch: 47 | Loss: 0.298 | Acc: 91.675% (3667/4000)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.585% (3755/4100)\n",
      "Test Epoch: 47 | Loss: 0.307 | Acc: 91.548% (3845/4200)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.651% (3941/4300)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.727% (4036/4400)\n",
      "Test Epoch: 47 | Loss: 0.300 | Acc: 91.800% (4131/4500)\n",
      "Test Epoch: 47 | Loss: 0.299 | Acc: 91.826% (4224/4600)\n",
      "Test Epoch: 47 | Loss: 0.297 | Acc: 91.851% (4317/4700)\n",
      "Test Epoch: 47 | Loss: 0.300 | Acc: 91.750% (4404/4800)\n",
      "Test Epoch: 47 | Loss: 0.299 | Acc: 91.857% (4501/4900)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.800% (4590/5000)\n",
      "Test Epoch: 47 | Loss: 0.298 | Acc: 91.824% (4683/5100)\n",
      "Test Epoch: 47 | Loss: 0.299 | Acc: 91.808% (4774/5200)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.698% (4860/5300)\n",
      "Test Epoch: 47 | Loss: 0.300 | Acc: 91.741% (4954/5400)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.691% (5043/5500)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.696% (5135/5600)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.737% (5229/5700)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.724% (5320/5800)\n",
      "Test Epoch: 47 | Loss: 0.308 | Acc: 91.678% (5409/5900)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.717% (5503/6000)\n",
      "Test Epoch: 47 | Loss: 0.308 | Acc: 91.738% (5596/6100)\n",
      "Test Epoch: 47 | Loss: 0.309 | Acc: 91.694% (5685/6200)\n",
      "Test Epoch: 47 | Loss: 0.308 | Acc: 91.683% (5776/6300)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.750% (5872/6400)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.723% (5962/6500)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.773% (6057/6600)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.791% (6150/6700)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.721% (6237/6800)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.754% (6331/6900)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.671% (6417/7000)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.676% (6509/7100)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.694% (6602/7200)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.685% (6693/7300)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.743% (6789/7400)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.720% (6879/7500)\n",
      "Test Epoch: 47 | Loss: 0.307 | Acc: 91.658% (6966/7600)\n",
      "Test Epoch: 47 | Loss: 0.308 | Acc: 91.649% (7057/7700)\n",
      "Test Epoch: 47 | Loss: 0.307 | Acc: 91.692% (7152/7800)\n",
      "Test Epoch: 47 | Loss: 0.307 | Acc: 91.709% (7245/7900)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.713% (7337/8000)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.741% (7431/8100)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.732% (7522/8200)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.723% (7613/8300)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.774% (7709/8400)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.729% (7797/8500)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.709% (7887/8600)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.770% (7984/8700)\n",
      "Test Epoch: 47 | Loss: 0.307 | Acc: 91.727% (8072/8800)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.753% (8166/8900)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.756% (8258/9000)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.769% (8351/9100)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.783% (8444/9200)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.753% (8533/9300)\n",
      "Test Epoch: 47 | Loss: 0.306 | Acc: 91.755% (8625/9400)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.758% (8717/9500)\n",
      "Test Epoch: 47 | Loss: 0.305 | Acc: 91.760% (8809/9600)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.794% (8904/9700)\n",
      "Test Epoch: 47 | Loss: 0.302 | Acc: 91.837% (9000/9800)\n",
      "Test Epoch: 47 | Loss: 0.303 | Acc: 91.818% (9090/9900)\n",
      "Test Epoch: 47 | Loss: 0.304 | Acc: 91.840% (9184/10000)\n",
      "\n",
      "Epoch: 48\n",
      "Train Epoch: 48 | Loss: 0.072 | Acc: 96.094% (123/128)\n",
      "Train Epoch: 48 | Loss: 0.080 | Acc: 96.484% (247/256)\n",
      "Train Epoch: 48 | Loss: 0.085 | Acc: 96.354% (370/384)\n",
      "Train Epoch: 48 | Loss: 0.076 | Acc: 96.875% (496/512)\n",
      "Train Epoch: 48 | Loss: 0.070 | Acc: 97.188% (622/640)\n",
      "Train Epoch: 48 | Loss: 0.067 | Acc: 97.266% (747/768)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.545% (874/896)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 97.754% (1001/1024)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 97.743% (1126/1152)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.812% (1252/1280)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.727% (1376/1408)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.721% (1501/1536)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.837% (1628/1664)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 97.991% (1756/1792)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.021% (1882/1920)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 97.998% (2007/2048)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 98.070% (2134/2176)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.177% (2262/2304)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.232% (2389/2432)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.203% (2514/2560)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.177% (2639/2688)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.189% (2765/2816)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.166% (2890/2944)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.177% (3016/3072)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 98.125% (3140/3200)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 98.137% (3266/3328)\n",
      "Train Epoch: 48 | Loss: 0.059 | Acc: 98.177% (3393/3456)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.214% (3520/3584)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.249% (3647/3712)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.255% (3773/3840)\n",
      "Train Epoch: 48 | Loss: 0.056 | Acc: 98.286% (3900/3968)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.291% (4026/4096)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.201% (4148/4224)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.231% (4275/4352)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.281% (4403/4480)\n",
      "Train Epoch: 48 | Loss: 0.056 | Acc: 98.307% (4530/4608)\n",
      "Train Epoch: 48 | Loss: 0.056 | Acc: 98.290% (4655/4736)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.252% (4779/4864)\n",
      "Train Epoch: 48 | Loss: 0.057 | Acc: 98.257% (4905/4992)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.223% (5029/5120)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.209% (5154/5248)\n",
      "Train Epoch: 48 | Loss: 0.058 | Acc: 98.214% (5280/5376)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 98.147% (5402/5504)\n",
      "Train Epoch: 48 | Loss: 0.060 | Acc: 98.153% (5528/5632)\n",
      "Train Epoch: 48 | Loss: 0.059 | Acc: 98.142% (5653/5760)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.047% (5773/5888)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 97.989% (5895/6016)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.900% (6015/6144)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.927% (6142/6272)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.891% (6265/6400)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.855% (6388/6528)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.852% (6513/6656)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.877% (6640/6784)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.873% (6765/6912)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.855% (6889/7040)\n",
      "Train Epoch: 48 | Loss: 0.066 | Acc: 97.838% (7013/7168)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.862% (7140/7296)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.899% (7268/7424)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (7395/7552)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.930% (7521/7680)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.964% (7649/7808)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.971% (7775/7936)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.003% (7903/8064)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.022% (8030/8192)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.041% (8157/8320)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.059% (8284/8448)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.053% (8409/8576)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.047% (8534/8704)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.030% (8658/8832)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 98.025% (8783/8960)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.030% (8909/9088)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.025% (9034/9216)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.999% (9157/9344)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.973% (9280/9472)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 98.000% (9408/9600)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.016% (9535/9728)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.991% (9658/9856)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.997% (9784/9984)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.973% (9907/10112)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.959% (10031/10240)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.965% (10157/10368)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.971% (10283/10496)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.986% (10410/10624)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.963% (10533/10752)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.987% (10661/10880)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.011% (10789/11008)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.024% (10916/11136)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.029% (11042/11264)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.042% (11169/11392)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.021% (11292/11520)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.017% (11417/11648)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.004% (11541/11776)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.984% (11664/11904)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.989% (11790/12032)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.985% (11915/12160)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.974% (12039/12288)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.995% (12167/12416)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.991% (12292/12544)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.996% (12418/12672)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.008% (12545/12800)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.989% (12668/12928)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.001% (12795/13056)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.020% (12923/13184)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.024% (13049/13312)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.006% (13172/13440)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.017% (13299/13568)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.007% (13423/13696)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.003% (13548/13824)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.007% (13674/13952)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.018% (13801/14080)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.015% (13926/14208)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.026% (14053/14336)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.037% (14180/14464)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.054% (14308/14592)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.043% (14432/14720)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.027% (14555/14848)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.017% (14679/14976)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.027% (14806/15104)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.037% (14933/15232)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.034% (15058/15360)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.044% (15185/15488)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.034% (15309/15616)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.044% (15436/15744)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 98.034% (15560/15872)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.037% (15686/16000)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.041% (15812/16128)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.056% (15940/16256)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.059% (16066/16384)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.056% (16191/16512)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.071% (16319/16640)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.074% (16445/16768)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.071% (16570/16896)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.073% (16696/17024)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.082% (16823/17152)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.090% (16950/17280)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.093% (17076/17408)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.095% (17202/17536)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.092% (17327/17664)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.067% (17448/17792)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.052% (17571/17920)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.055% (17697/18048)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.052% (17822/18176)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.050% (17947/18304)\n",
      "Train Epoch: 48 | Loss: 0.061 | Acc: 98.047% (18072/18432)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.039% (18196/18560)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.036% (18321/18688)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.023% (18444/18816)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.031% (18571/18944)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.018% (18694/19072)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.026% (18821/19200)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.029% (18947/19328)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.021% (19071/19456)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.034% (19199/19584)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.037% (19325/19712)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.044% (19452/19840)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.047% (19578/19968)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.034% (19701/20096)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.042% (19828/20224)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.035% (19952/20352)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.032% (20077/20480)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.020% (20200/20608)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.032% (20328/20736)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.030% (20453/20864)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.028% (20578/20992)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.021% (20702/21120)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.009% (20825/21248)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.012% (20951/21376)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.014% (21077/21504)\n",
      "Train Epoch: 48 | Loss: 0.062 | Acc: 98.012% (21202/21632)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.987% (21322/21760)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.971% (21444/21888)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.979% (21571/22016)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.981% (21697/22144)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.980% (21822/22272)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.964% (21944/22400)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.963% (22069/22528)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.965% (22195/22656)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.968% (22321/22784)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.979% (22449/22912)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.964% (22571/23040)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.954% (22694/23168)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.952% (22819/23296)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.947% (22943/23424)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.936% (23066/23552)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.943% (23193/23680)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.946% (23319/23808)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.940% (23443/23936)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.947% (23570/24064)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.950% (23696/24192)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.952% (23822/24320)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.959% (23949/24448)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.953% (24073/24576)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.948% (24197/24704)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.950% (24323/24832)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.953% (24449/24960)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.963% (24577/25088)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.970% (24704/25216)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.968% (24829/25344)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.970% (24955/25472)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.961% (25078/25600)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.963% (25204/25728)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.966% (25330/25856)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.968% (25456/25984)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.970% (25582/26112)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.965% (25706/26240)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.971% (25833/26368)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.973% (25959/26496)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.983% (26087/26624)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.989% (26214/26752)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.991% (26340/26880)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.986% (26464/27008)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.995% (26592/27136)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.990% (26716/27264)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.992% (26842/27392)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.983% (26965/27520)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.982% (27090/27648)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.987% (27217/27776)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.982% (27341/27904)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.981% (27466/28032)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.972% (27589/28160)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.967% (27713/28288)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.969% (27839/28416)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.954% (27960/28544)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.960% (28087/28672)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.965% (28214/28800)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.964% (28339/28928)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.959% (28463/29056)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.968% (28591/29184)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.963% (28715/29312)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.969% (28842/29440)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.971% (28968/29568)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.969% (29093/29696)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.975% (29220/29824)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.980% (29347/29952)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.979% (29472/30080)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.974% (29596/30208)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.976% (29722/30336)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.978% (29848/30464)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.977% (29973/30592)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.979% (30099/30720)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.980% (30225/30848)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.982% (30351/30976)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.978% (30475/31104)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.967% (30597/31232)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.969% (30723/31360)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.964% (30847/31488)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.960% (30971/31616)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.959% (31096/31744)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.964% (31223/31872)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.966% (31349/32000)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.955% (31471/32128)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.948% (31594/32256)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.940% (31717/32384)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.939% (31842/32512)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.944% (31969/32640)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.946% (32095/32768)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.939% (32218/32896)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.923% (32338/33024)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (32462/33152)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.906% (32583/33280)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.908% (32709/33408)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.904% (32833/33536)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.891% (32954/33664)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.887% (33078/33792)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.886% (33203/33920)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.885% (33328/34048)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.876% (33450/34176)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.872% (33574/34304)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.868% (33698/34432)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.873% (33825/34560)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.878% (33952/34688)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.880% (34078/34816)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.885% (34205/34944)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.887% (34331/35072)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.895% (34459/35200)\n",
      "Train Epoch: 48 | Loss: 0.065 | Acc: 97.897% (34585/35328)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.902% (34712/35456)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.909% (34840/35584)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.908% (34965/35712)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.913% (35092/35840)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.915% (35218/35968)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (35345/36096)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.924% (35472/36224)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.920% (35596/36352)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.928% (35724/36480)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.927% (35849/36608)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.926% (35974/36736)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.925% (36099/36864)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (36222/36992)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (36347/37120)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.911% (36470/37248)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.916% (36597/37376)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.910% (36720/37504)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.917% (36848/37632)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (36974/37760)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.912% (37097/37888)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.909% (37221/38016)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.908% (37346/38144)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.912% (37473/38272)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.914% (37599/38400)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (37726/38528)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.920% (37852/38656)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.927% (37980/38784)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.926% (38105/38912)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.915% (38226/39040)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.922% (38354/39168)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (38479/39296)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.920% (38604/39424)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.924% (38731/39552)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.923% (38856/39680)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.928% (38983/39808)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (39105/39936)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (39231/40064)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.915% (39354/40192)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.912% (39478/40320)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.911% (39603/40448)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.915% (39730/40576)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (39857/40704)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (39983/40832)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.922% (40109/40960)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.924% (40235/41088)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.928% (40362/41216)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.932% (40489/41344)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.934% (40615/41472)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.935% (40741/41600)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.925% (40862/41728)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (40985/41856)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (41111/41984)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.920% (41236/42112)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.921% (41362/42240)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (41486/42368)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.922% (41613/42496)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (41740/42624)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.930% (41867/42752)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.929% (41992/42880)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (42113/43008)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (42241/43136)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.927% (42367/43264)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.924% (42491/43392)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.923% (42616/43520)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.927% (42743/43648)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (42865/43776)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (42993/43904)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.922% (43117/44032)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.917% (43240/44160)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.923% (43368/44288)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (43495/44416)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (43620/44544)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (43745/44672)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (43871/44800)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.923% (43995/44928)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.918% (44118/45056)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.924% (44246/45184)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.930% (44374/45312)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.927% (44498/45440)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.924% (44622/45568)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.928% (44749/45696)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.927% (44874/45824)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (44999/45952)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.919% (45121/46080)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.920% (45247/46208)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (45375/46336)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.930% (45502/46464)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.927% (45626/46592)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.924% (45750/46720)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.921% (45874/46848)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.924% (46001/46976)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.913% (46121/47104)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.912% (46246/47232)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.914% (46372/47360)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.919% (46500/47488)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.917% (46624/47616)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.916% (46749/47744)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.919% (46876/47872)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.919% (47001/48000)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.916% (47125/48128)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.917% (47251/48256)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.915% (47375/48384)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.914% (47500/48512)\n",
      "Train Epoch: 48 | Loss: 0.064 | Acc: 97.911% (47624/48640)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.915% (47751/48768)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.916% (47877/48896)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.917% (48003/49024)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.919% (48129/49152)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.920% (48255/49280)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (48383/49408)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (48508/49536)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.924% (48633/49664)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.921% (48757/49792)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.925% (48884/49920)\n",
      "Train Epoch: 48 | Loss: 0.063 | Acc: 97.926% (48963/50000)\n",
      "Test Epoch: 48 | Loss: 0.296 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 48 | Loss: 0.327 | Acc: 91.500% (183/200)\n",
      "Test Epoch: 48 | Loss: 0.312 | Acc: 91.333% (274/300)\n",
      "Test Epoch: 48 | Loss: 0.294 | Acc: 91.000% (364/400)\n",
      "Test Epoch: 48 | Loss: 0.275 | Acc: 91.400% (457/500)\n",
      "Test Epoch: 48 | Loss: 0.247 | Acc: 92.333% (554/600)\n",
      "Test Epoch: 48 | Loss: 0.254 | Acc: 92.143% (645/700)\n",
      "Test Epoch: 48 | Loss: 0.279 | Acc: 91.625% (733/800)\n",
      "Test Epoch: 48 | Loss: 0.287 | Acc: 91.667% (825/900)\n",
      "Test Epoch: 48 | Loss: 0.282 | Acc: 91.700% (917/1000)\n",
      "Test Epoch: 48 | Loss: 0.283 | Acc: 91.545% (1007/1100)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.500% (1098/1200)\n",
      "Test Epoch: 48 | Loss: 0.293 | Acc: 91.692% (1192/1300)\n",
      "Test Epoch: 48 | Loss: 0.287 | Acc: 91.857% (1286/1400)\n",
      "Test Epoch: 48 | Loss: 0.282 | Acc: 92.067% (1381/1500)\n",
      "Test Epoch: 48 | Loss: 0.276 | Acc: 92.375% (1478/1600)\n",
      "Test Epoch: 48 | Loss: 0.277 | Acc: 92.471% (1572/1700)\n",
      "Test Epoch: 48 | Loss: 0.278 | Acc: 92.444% (1664/1800)\n",
      "Test Epoch: 48 | Loss: 0.286 | Acc: 92.368% (1755/1900)\n",
      "Test Epoch: 48 | Loss: 0.297 | Acc: 92.350% (1847/2000)\n",
      "Test Epoch: 48 | Loss: 0.300 | Acc: 92.095% (1934/2100)\n",
      "Test Epoch: 48 | Loss: 0.301 | Acc: 91.864% (2021/2200)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.739% (2110/2300)\n",
      "Test Epoch: 48 | Loss: 0.296 | Acc: 91.875% (2205/2400)\n",
      "Test Epoch: 48 | Loss: 0.298 | Acc: 91.920% (2298/2500)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.615% (2382/2600)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.630% (2474/2700)\n",
      "Test Epoch: 48 | Loss: 0.312 | Acc: 91.607% (2565/2800)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.552% (2655/2900)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.567% (2747/3000)\n",
      "Test Epoch: 48 | Loss: 0.313 | Acc: 91.548% (2838/3100)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.656% (2933/3200)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.667% (3025/3300)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.676% (3117/3400)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.686% (3209/3500)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.778% (3304/3600)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.757% (3395/3700)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.684% (3484/3800)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.795% (3580/3900)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.850% (3674/4000)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.756% (3762/4100)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.690% (3851/4200)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.744% (3945/4300)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.818% (4040/4400)\n",
      "Test Epoch: 48 | Loss: 0.300 | Acc: 91.933% (4137/4500)\n",
      "Test Epoch: 48 | Loss: 0.299 | Acc: 91.891% (4227/4600)\n",
      "Test Epoch: 48 | Loss: 0.298 | Acc: 91.894% (4319/4700)\n",
      "Test Epoch: 48 | Loss: 0.300 | Acc: 91.833% (4408/4800)\n",
      "Test Epoch: 48 | Loss: 0.299 | Acc: 91.857% (4501/4900)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.800% (4590/5000)\n",
      "Test Epoch: 48 | Loss: 0.300 | Acc: 91.843% (4684/5100)\n",
      "Test Epoch: 48 | Loss: 0.302 | Acc: 91.808% (4774/5200)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.736% (4862/5300)\n",
      "Test Epoch: 48 | Loss: 0.302 | Acc: 91.759% (4955/5400)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.727% (5045/5500)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.714% (5136/5600)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.719% (5228/5700)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.707% (5319/5800)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.627% (5406/5900)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.683% (5501/6000)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.639% (5590/6100)\n",
      "Test Epoch: 48 | Loss: 0.310 | Acc: 91.645% (5682/6200)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.667% (5775/6300)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.750% (5872/6400)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.723% (5962/6500)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.773% (6057/6600)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.791% (6150/6700)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.750% (6239/6800)\n",
      "Test Epoch: 48 | Loss: 0.303 | Acc: 91.797% (6334/6900)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.757% (6423/7000)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.704% (6511/7100)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.736% (6605/7200)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.740% (6697/7300)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.784% (6792/7400)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.747% (6881/7500)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.737% (6972/7600)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.727% (7063/7700)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.756% (7157/7800)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.772% (7250/7900)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.763% (7341/8000)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.802% (7436/8100)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.793% (7527/8200)\n",
      "Test Epoch: 48 | Loss: 0.305 | Acc: 91.819% (7621/8300)\n",
      "Test Epoch: 48 | Loss: 0.304 | Acc: 91.833% (7714/8400)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.776% (7801/8500)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.709% (7887/8600)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.724% (7980/8700)\n",
      "Test Epoch: 48 | Loss: 0.306 | Acc: 91.739% (8073/8800)\n",
      "Test Epoch: 48 | Loss: 0.307 | Acc: 91.730% (8164/8900)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.678% (8251/9000)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.681% (8343/9100)\n",
      "Test Epoch: 48 | Loss: 0.309 | Acc: 91.707% (8437/9200)\n",
      "Test Epoch: 48 | Loss: 0.310 | Acc: 91.710% (8529/9300)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.713% (8621/9400)\n",
      "Test Epoch: 48 | Loss: 0.312 | Acc: 91.663% (8708/9500)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.656% (8799/9600)\n",
      "Test Epoch: 48 | Loss: 0.310 | Acc: 91.649% (8890/9700)\n",
      "Test Epoch: 48 | Loss: 0.308 | Acc: 91.684% (8985/9800)\n",
      "Test Epoch: 48 | Loss: 0.311 | Acc: 91.657% (9074/9900)\n",
      "Test Epoch: 48 | Loss: 0.310 | Acc: 91.670% (9167/10000)\n",
      "\n",
      "Epoch: 49\n",
      "Train Epoch: 49 | Loss: 0.047 | Acc: 99.219% (127/128)\n",
      "Train Epoch: 49 | Loss: 0.041 | Acc: 99.609% (255/256)\n",
      "Train Epoch: 49 | Loss: 0.064 | Acc: 98.958% (380/384)\n",
      "Train Epoch: 49 | Loss: 0.067 | Acc: 98.633% (505/512)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.906% (633/640)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 99.089% (761/768)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.772% (885/896)\n",
      "Train Epoch: 49 | Loss: 0.065 | Acc: 98.340% (1007/1024)\n",
      "Train Epoch: 49 | Loss: 0.066 | Acc: 98.438% (1134/1152)\n",
      "Train Epoch: 49 | Loss: 0.067 | Acc: 98.359% (1259/1280)\n",
      "Train Epoch: 49 | Loss: 0.065 | Acc: 98.438% (1386/1408)\n",
      "Train Epoch: 49 | Loss: 0.064 | Acc: 98.307% (1510/1536)\n",
      "Train Epoch: 49 | Loss: 0.066 | Acc: 98.197% (1634/1664)\n",
      "Train Epoch: 49 | Loss: 0.067 | Acc: 98.214% (1760/1792)\n",
      "Train Epoch: 49 | Loss: 0.066 | Acc: 98.229% (1886/1920)\n",
      "Train Epoch: 49 | Loss: 0.064 | Acc: 98.242% (2012/2048)\n",
      "Train Epoch: 49 | Loss: 0.064 | Acc: 98.300% (2139/2176)\n",
      "Train Epoch: 49 | Loss: 0.062 | Acc: 98.351% (2266/2304)\n",
      "Train Epoch: 49 | Loss: 0.062 | Acc: 98.396% (2393/2432)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.438% (2520/2560)\n",
      "Train Epoch: 49 | Loss: 0.062 | Acc: 98.326% (2643/2688)\n",
      "Train Epoch: 49 | Loss: 0.064 | Acc: 98.224% (2766/2816)\n",
      "Train Epoch: 49 | Loss: 0.063 | Acc: 98.268% (2893/2944)\n",
      "Train Epoch: 49 | Loss: 0.062 | Acc: 98.340% (3021/3072)\n",
      "Train Epoch: 49 | Loss: 0.061 | Acc: 98.375% (3148/3200)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.377% (3274/3328)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.322% (3398/3456)\n",
      "Train Epoch: 49 | Loss: 0.061 | Acc: 98.298% (3523/3584)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.276% (3648/3712)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.307% (3775/3840)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.311% (3901/3968)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.291% (4026/4096)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.319% (4153/4224)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.323% (4279/4352)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.348% (4406/4480)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.329% (4531/4608)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.353% (4658/4736)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.335% (4783/4864)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.337% (4909/4992)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.379% (5037/5120)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.380% (5163/5248)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 98.382% (5289/5376)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 98.401% (5416/5504)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 98.402% (5542/5632)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 98.368% (5666/5760)\n",
      "Train Epoch: 49 | Loss: 0.056 | Acc: 98.370% (5792/5888)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.354% (5917/6016)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.340% (6042/6144)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.342% (6168/6272)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.344% (6294/6400)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.361% (6421/6528)\n",
      "Train Epoch: 49 | Loss: 0.057 | Acc: 98.347% (6546/6656)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.290% (6668/6784)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.307% (6795/6912)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.267% (6918/7040)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.284% (7045/7168)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.273% (7170/7296)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.249% (7294/7424)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.239% (7419/7552)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.216% (7543/7680)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.233% (7670/7808)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.236% (7796/7936)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.239% (7922/8064)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.230% (8047/8192)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.245% (8174/8320)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.260% (8301/8448)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.251% (8426/8576)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.265% (8553/8704)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.256% (8678/8832)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.270% (8805/8960)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.283% (8932/9088)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.275% (9057/9216)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.256% (9181/9344)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.247% (9306/9472)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.219% (9429/9600)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.211% (9554/9728)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.214% (9680/9856)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.207% (9805/9984)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.230% (9933/10112)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.242% (10060/10240)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.245% (10186/10368)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.237% (10311/10496)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.240% (10437/10624)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.214% (10560/10752)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.226% (10687/10880)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.219% (10812/11008)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.231% (10939/11136)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.224% (11064/11264)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.227% (11190/11392)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.212% (11314/11520)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.223% (11441/11648)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.234% (11568/11776)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.219% (11692/11904)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.221% (11818/12032)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.215% (11943/12160)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.218% (12069/12288)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.228% (12196/12416)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.214% (12320/12544)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.217% (12446/12672)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.211% (12571/12800)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.175% (12692/12928)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.185% (12819/13056)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.202% (12947/13184)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.212% (13074/13312)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.214% (13200/13440)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.231% (13328/13568)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.240% (13455/13696)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.206% (13576/13824)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.208% (13702/13952)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.168% (13822/14080)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.177% (13949/14208)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.165% (14073/14336)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.154% (14197/14464)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.170% (14325/14592)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.159% (14449/14720)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.168% (14576/14848)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.170% (14702/14976)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.166% (14827/15104)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.168% (14953/15232)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.171% (15079/15360)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.160% (15203/15488)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.149% (15327/15616)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.152% (15453/15744)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.141% (15577/15872)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.150% (15704/16000)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.152% (15830/16128)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.148% (15955/16256)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.157% (16082/16384)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.153% (16207/16512)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.155% (16333/16640)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.163% (16460/16768)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.171% (16587/16896)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.161% (16711/17024)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.169% (16838/17152)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.171% (16964/17280)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.168% (17089/17408)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.169% (17215/17536)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.160% (17339/17664)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.162% (17465/17792)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.153% (17589/17920)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.155% (17715/18048)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.168% (17843/18176)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.175% (17970/18304)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.183% (18097/18432)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.173% (18221/18560)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.165% (18345/18688)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.156% (18469/18816)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.147% (18593/18944)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.144% (18718/19072)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.135% (18842/19200)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.132% (18967/19328)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (19093/19456)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.111% (19214/19584)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.118% (19341/19712)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.120% (19467/19840)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.112% (19591/19968)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.119% (19718/20096)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (19845/20224)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.118% (19969/20352)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.115% (20094/20480)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.117% (20220/20608)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.119% (20346/20736)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.107% (20469/20864)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.095% (20592/20992)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.097% (20718/21120)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.080% (20840/21248)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.087% (20967/21376)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.098% (21095/21504)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (21222/21632)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.116% (21350/21760)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.127% (21478/21888)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (21605/22016)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.135% (21731/22144)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.146% (21859/22272)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.129% (21981/22400)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.127% (22106/22528)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (22233/22656)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.139% (22360/22784)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.136% (22485/22912)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.129% (22609/23040)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (22735/23168)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.141% (22863/23296)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.143% (22989/23424)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.145% (23115/23552)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.138% (23239/23680)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (23363/23808)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.124% (23487/23936)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.122% (23612/24064)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.132% (23740/24192)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.133% (23866/24320)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.139% (23993/24448)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.140% (24119/24576)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.142% (24245/24704)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.148% (24372/24832)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.153% (24499/24960)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.154% (24625/25088)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.152% (24750/25216)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.153% (24876/25344)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.159% (25003/25472)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.160% (25129/25600)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.162% (25255/25728)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.151% (25378/25856)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.137% (25500/25984)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.135% (25625/26112)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.117% (25746/26240)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.119% (25872/26368)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.120% (25998/26496)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.118% (26123/26624)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.124% (26250/26752)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.118% (26374/26880)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.119% (26500/27008)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.113% (26624/27136)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.118% (26751/27264)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.124% (26878/27392)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.125% (27004/27520)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.119% (27128/27648)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.124% (27255/27776)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (27383/27904)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.131% (27508/28032)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.136% (27635/28160)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.137% (27761/28288)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.121% (27882/28416)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (28009/28544)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.127% (28135/28672)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.132% (28262/28800)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (28388/28928)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.135% (28514/29056)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.143% (28642/29184)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.137% (28766/29312)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.142% (28893/29440)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.136% (29017/29568)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (29141/29696)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.129% (29266/29824)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (29393/29952)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.132% (29518/30080)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.130% (29643/30208)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.121% (29766/30336)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.113% (29889/30464)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.107% (30013/30592)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.112% (30140/30720)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.107% (30264/30848)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.099% (30387/30976)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.097% (30512/31104)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.082% (30633/31232)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.087% (30760/31360)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.082% (30884/31488)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.086% (31011/31616)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.082% (31135/31744)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.080% (31260/31872)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.084% (31387/32000)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.089% (31514/32128)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.096% (31642/32256)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.098% (31768/32384)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.102% (31895/32512)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.110% (32023/32640)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (32147/32768)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.109% (32274/32896)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.098% (32396/33024)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.100% (32522/33152)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.104% (32649/33280)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (32775/33408)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.112% (32903/33536)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.117% (33030/33664)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.112% (33154/33792)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.116% (33281/33920)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.109% (33404/34048)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.113% (33531/34176)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.117% (33658/34304)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.118% (33784/34432)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.119% (33910/34560)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.115% (34034/34688)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.113% (34159/34816)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.114% (34285/34944)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.121% (34413/35072)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.125% (34540/35200)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.120% (34664/35328)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.122% (34790/35456)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.123% (34916/35584)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.124% (35042/35712)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.122% (35167/35840)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (35294/35968)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.127% (35420/36096)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (35545/36224)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.127% (35671/36352)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.125% (35796/36480)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.121% (35920/36608)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.116% (36044/36736)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.115% (36169/36864)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.113% (36294/36992)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.112% (36419/37120)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (36542/37248)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.103% (36667/37376)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.107% (36794/37504)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.111% (36921/37632)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.117% (37049/37760)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.115% (37174/37888)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.114% (37299/38016)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.118% (37426/38144)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.114% (37550/38272)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.107% (37673/38400)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (37798/38528)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.099% (37921/38656)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.102% (38048/38784)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.101% (38173/38912)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.105% (38300/39040)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.106% (38426/39168)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.107% (38552/39296)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.105% (38677/39424)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.109% (38804/39552)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.102% (38927/39680)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.098% (39051/39808)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.099% (39177/39936)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.106% (39305/40064)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.107% (39431/40192)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.110% (39558/40320)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.111% (39684/40448)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.115% (39811/40576)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.118% (39938/40704)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.124% (40066/40832)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.123% (40191/40960)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.124% (40317/41088)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.122% (40442/41216)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.118% (40566/41344)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.122% (40693/41472)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.123% (40819/41600)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.124% (40945/41728)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.122% (41070/41856)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.123% (41196/41984)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.122% (41321/42112)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.123% (41447/42240)\n",
      "Train Epoch: 49 | Loss: 0.060 | Acc: 98.119% (41571/42368)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.125% (41699/42496)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.130% (41827/42624)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (41951/42752)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.130% (42078/42880)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (42205/43008)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (42330/43136)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.128% (42454/43264)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.124% (42578/43392)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.127% (42705/43520)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (42830/43648)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.129% (42957/43776)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.128% (43082/43904)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (43209/44032)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (43336/44160)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.137% (43463/44288)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.140% (43590/44416)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.139% (43715/44544)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.140% (43841/44672)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.143% (43968/44800)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (44089/44928)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (44214/45056)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (44341/45184)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.129% (44464/45312)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.129% (44590/45440)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.126% (44714/45568)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.129% (44841/45696)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.130% (44967/45824)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.131% (45093/45952)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (45220/46080)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.135% (45346/46208)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.138% (45473/46336)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.136% (45598/46464)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (45722/46592)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.134% (45848/46720)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.132% (45973/46848)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.133% (46099/46976)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.132% (46224/47104)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.135% (46351/47232)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.140% (46479/47360)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.143% (46606/47488)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.146% (46733/47616)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.146% (46859/47744)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.147% (46985/47872)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.150% (47112/48000)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.151% (47238/48128)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.154% (47365/48256)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.156% (47492/48384)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.155% (47617/48512)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.156% (47743/48640)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.157% (47869/48768)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.157% (47995/48896)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.156% (48120/49024)\n",
      "Train Epoch: 49 | Loss: 0.059 | Acc: 98.157% (48246/49152)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.162% (48374/49280)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.162% (48500/49408)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.161% (48625/49536)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.164% (48752/49664)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.164% (48878/49792)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.167% (49005/49920)\n",
      "Train Epoch: 49 | Loss: 0.058 | Acc: 98.166% (49083/50000)\n",
      "Test Epoch: 49 | Loss: 0.296 | Acc: 92.000% (92/100)\n",
      "Test Epoch: 49 | Loss: 0.337 | Acc: 92.000% (184/200)\n",
      "Test Epoch: 49 | Loss: 0.293 | Acc: 91.667% (275/300)\n",
      "Test Epoch: 49 | Loss: 0.271 | Acc: 92.250% (369/400)\n",
      "Test Epoch: 49 | Loss: 0.265 | Acc: 92.000% (460/500)\n",
      "Test Epoch: 49 | Loss: 0.234 | Acc: 93.000% (558/600)\n",
      "Test Epoch: 49 | Loss: 0.238 | Acc: 92.714% (649/700)\n",
      "Test Epoch: 49 | Loss: 0.263 | Acc: 92.125% (737/800)\n",
      "Test Epoch: 49 | Loss: 0.270 | Acc: 92.000% (828/900)\n",
      "Test Epoch: 49 | Loss: 0.260 | Acc: 92.200% (922/1000)\n",
      "Test Epoch: 49 | Loss: 0.255 | Acc: 92.364% (1016/1100)\n",
      "Test Epoch: 49 | Loss: 0.260 | Acc: 92.333% (1108/1200)\n",
      "Test Epoch: 49 | Loss: 0.247 | Acc: 92.692% (1205/1300)\n",
      "Test Epoch: 49 | Loss: 0.246 | Acc: 92.786% (1299/1400)\n",
      "Test Epoch: 49 | Loss: 0.248 | Acc: 92.800% (1392/1500)\n",
      "Test Epoch: 49 | Loss: 0.244 | Acc: 93.062% (1489/1600)\n",
      "Test Epoch: 49 | Loss: 0.243 | Acc: 93.176% (1584/1700)\n",
      "Test Epoch: 49 | Loss: 0.246 | Acc: 93.278% (1679/1800)\n",
      "Test Epoch: 49 | Loss: 0.249 | Acc: 93.158% (1770/1900)\n",
      "Test Epoch: 49 | Loss: 0.258 | Acc: 93.050% (1861/2000)\n",
      "Test Epoch: 49 | Loss: 0.260 | Acc: 92.857% (1950/2100)\n",
      "Test Epoch: 49 | Loss: 0.264 | Acc: 92.682% (2039/2200)\n",
      "Test Epoch: 49 | Loss: 0.272 | Acc: 92.522% (2128/2300)\n",
      "Test Epoch: 49 | Loss: 0.270 | Acc: 92.542% (2221/2400)\n",
      "Test Epoch: 49 | Loss: 0.274 | Acc: 92.440% (2311/2500)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 92.115% (2395/2600)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 92.148% (2488/2700)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 92.179% (2581/2800)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 92.069% (2670/2900)\n",
      "Test Epoch: 49 | Loss: 0.288 | Acc: 92.000% (2760/3000)\n",
      "Test Epoch: 49 | Loss: 0.288 | Acc: 91.968% (2851/3100)\n",
      "Test Epoch: 49 | Loss: 0.282 | Acc: 92.125% (2948/3200)\n",
      "Test Epoch: 49 | Loss: 0.279 | Acc: 92.121% (3040/3300)\n",
      "Test Epoch: 49 | Loss: 0.277 | Acc: 92.118% (3132/3400)\n",
      "Test Epoch: 49 | Loss: 0.279 | Acc: 92.086% (3223/3500)\n",
      "Test Epoch: 49 | Loss: 0.276 | Acc: 92.222% (3320/3600)\n",
      "Test Epoch: 49 | Loss: 0.281 | Acc: 92.189% (3411/3700)\n",
      "Test Epoch: 49 | Loss: 0.283 | Acc: 92.079% (3499/3800)\n",
      "Test Epoch: 49 | Loss: 0.282 | Acc: 92.077% (3591/3900)\n",
      "Test Epoch: 49 | Loss: 0.281 | Acc: 92.100% (3684/4000)\n",
      "Test Epoch: 49 | Loss: 0.285 | Acc: 92.024% (3773/4100)\n",
      "Test Epoch: 49 | Loss: 0.288 | Acc: 91.976% (3863/4200)\n",
      "Test Epoch: 49 | Loss: 0.286 | Acc: 92.047% (3958/4300)\n",
      "Test Epoch: 49 | Loss: 0.284 | Acc: 92.114% (4053/4400)\n",
      "Test Epoch: 49 | Loss: 0.280 | Acc: 92.200% (4149/4500)\n",
      "Test Epoch: 49 | Loss: 0.280 | Acc: 92.196% (4241/4600)\n",
      "Test Epoch: 49 | Loss: 0.282 | Acc: 92.085% (4328/4700)\n",
      "Test Epoch: 49 | Loss: 0.285 | Acc: 91.958% (4414/4800)\n",
      "Test Epoch: 49 | Loss: 0.284 | Acc: 92.000% (4508/4900)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 91.940% (4597/5000)\n",
      "Test Epoch: 49 | Loss: 0.288 | Acc: 91.941% (4689/5100)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.865% (4777/5200)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.811% (4866/5300)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 91.852% (4960/5400)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.818% (5050/5500)\n",
      "Test Epoch: 49 | Loss: 0.294 | Acc: 91.821% (5142/5600)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.825% (5234/5700)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.862% (5328/5800)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.797% (5416/5900)\n",
      "Test Epoch: 49 | Loss: 0.293 | Acc: 91.800% (5508/6000)\n",
      "Test Epoch: 49 | Loss: 0.294 | Acc: 91.787% (5599/6100)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.742% (5688/6200)\n",
      "Test Epoch: 49 | Loss: 0.294 | Acc: 91.794% (5783/6300)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.828% (5877/6400)\n",
      "Test Epoch: 49 | Loss: 0.294 | Acc: 91.815% (5968/6500)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.879% (6064/6600)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.851% (6154/6700)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.794% (6242/6800)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.783% (6333/6900)\n",
      "Test Epoch: 49 | Loss: 0.293 | Acc: 91.714% (6420/7000)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.704% (6511/7100)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.694% (6602/7200)\n",
      "Test Epoch: 49 | Loss: 0.293 | Acc: 91.753% (6698/7300)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.784% (6792/7400)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.800% (6885/7500)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.776% (6975/7600)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.792% (7068/7700)\n",
      "Test Epoch: 49 | Loss: 0.295 | Acc: 91.821% (7162/7800)\n",
      "Test Epoch: 49 | Loss: 0.294 | Acc: 91.861% (7257/7900)\n",
      "Test Epoch: 49 | Loss: 0.293 | Acc: 91.850% (7348/8000)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.877% (7442/8100)\n",
      "Test Epoch: 49 | Loss: 0.292 | Acc: 91.841% (7531/8200)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.892% (7627/8300)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.869% (7717/8400)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.847% (7807/8500)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.826% (7897/8600)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.851% (7991/8700)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.830% (8081/8800)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.831% (8173/8900)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.789% (8261/9000)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 91.824% (8356/9100)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 91.837% (8449/9200)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.806% (8538/9300)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.819% (8631/9400)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.800% (8721/9500)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.812% (8814/9600)\n",
      "Test Epoch: 49 | Loss: 0.290 | Acc: 91.825% (8907/9700)\n",
      "Test Epoch: 49 | Loss: 0.289 | Acc: 91.857% (9002/9800)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.828% (9091/9900)\n",
      "Test Epoch: 49 | Loss: 0.291 | Acc: 91.850% (9185/10000)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+50):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS-WMnGMEXh8",
    "outputId": "67a4ee87-fbad-4c6a-be82-a6c9dc4bca1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.98\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "dIJfKleXwn7o",
    "outputId": "59fd895b-63aa-45df-b981-ac6d26579628"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tracc_list,'-o')\n",
    "plt.plot(tacc_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MNkc-KNtwox5",
    "outputId": "132c4ebd-acb2-494e-8d91-75a0bd5c25b3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trloss_list,'-o')\n",
    "plt.plot(tloss_list,'-o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Train','Test'])\n",
    "plt.title('Train vs Test Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qj_FyeZtx4p6",
    "outputId": "29e4b593-4f93-41c4-ceba-f2ba111f6533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "54dc99739b5f4e66886019cd26f3333a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee770e905eb248b8be2667e66d711dc9",
       "IPY_MODEL_8fe755f3b46f43068ac098adbc75332a",
       "IPY_MODEL_7972acdcd007407090fc1b2b12dcebcb"
      ],
      "layout": "IPY_MODEL_6ab11b6e072d40a392fdfb60406edc89"
     }
    },
    "6ab11b6e072d40a392fdfb60406edc89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761a17ec6f2a491a8620f6245f2ff26e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7972acdcd007407090fc1b2b12dcebcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_761a17ec6f2a491a8620f6245f2ff26e",
      "placeholder": "​",
      "style": "IPY_MODEL_e250b821e69349f8a70b7fe6e40b9da2",
      "value": " 170498071/170498071 [00:13&lt;00:00, 13293097.76it/s]"
     }
    },
    "80ace7fb1c834f59adc7db9dd690681d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "816e32d4bca64a8baae1c0c7a7c39ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8fe755f3b46f43068ac098adbc75332a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80ace7fb1c834f59adc7db9dd690681d",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_816e32d4bca64a8baae1c0c7a7c39ced",
      "value": 170498071
     }
    },
    "9bf986f336904eecb7b929ec3f34d077": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e161d1b0132542aeb21ef2b7a24c62dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e250b821e69349f8a70b7fe6e40b9da2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee770e905eb248b8be2667e66d711dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bf986f336904eecb7b929ec3f34d077",
      "placeholder": "​",
      "style": "IPY_MODEL_e161d1b0132542aeb21ef2b7a24c62dc",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
